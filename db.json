{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/matery/source/favicon.png","path":"favicon.png","modified":1,"renderable":1},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":1,"renderable":1},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":1,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/logo.png","path":"medias/logo.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","path":"libs/codeBlock/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/fireworks.js","path":"libs/others/fireworks.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/snow.js","path":"libs/others/snow.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/text.js","path":"libs/others/text.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/explosion.min.js","path":"libs/others/explosion.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ajin.jpg","path":"medias/avatars/ajin.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/babyq.png","path":"medias/avatars/babyq.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/cww97.jpg","path":"medias/avatars/cww97.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/feibar.jpg","path":"medias/avatars/feibar.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/hael.jpg","path":"medias/avatars/hael.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/fun4go.png","path":"medias/avatars/fun4go.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/huaji.jpg","path":"medias/avatars/huaji.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/hzwer.jpg","path":"medias/avatars/hzwer.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ids2.jpg","path":"medias/avatars/ids2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/kewlgrl.jpg","path":"medias/avatars/kewlgrl.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ldy.jpg","path":"medias/avatars/ldy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lijiaqian.png","path":"medias/avatars/lijiaqian.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/liyangzone.jpg","path":"medias/avatars/liyangzone.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/masterx.jpg","path":"medias/avatars/masterx.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/michael.jpg","path":"medias/avatars/michael.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mouse.jpg","path":"medias/avatars/mouse.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mpy634.png","path":"medias/avatars/mpy634.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/liyucheng.jpg","path":"medias/avatars/liyucheng.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qiqiang.jpg","path":"medias/avatars/qiqiang.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/spacesac.png","path":"medias/avatars/spacesac.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/sunchangzhi.jpg","path":"medias/avatars/sunchangzhi.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/taotao.jpg","path":"medias/avatars/taotao.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/taowei.jpg","path":"medias/avatars/taowei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/tawn.jpg","path":"medias/avatars/tawn.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/yezijie.png","path":"medias/avatars/yezijie.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","path":"libs/jquery/jquery-2.2.0.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/antnlp.ico","path":"medias/avatars/antnlp.ico","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/duyupei.jpg","path":"medias/avatars/duyupei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/gsy.jpg","path":"medias/avatars/gsy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jiejie.jpg","path":"medias/avatars/jiejie.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/milyyy.jpg","path":"medias/avatars/milyyy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qiandongwei.jpg","path":"medias/avatars/qiandongwei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mizunashi.png","path":"medias/avatars/mizunashi.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","path":"medias/avatars/myzhihu.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/xiejiadong.jpg","path":"medias/avatars/xiejiadong.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/xuzhongyou.jpg","path":"medias/avatars/xuzhongyou.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhaokangzhe.jpg","path":"medias/avatars/zhaokangzhe.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhangting.jpg","path":"medias/avatars/zhangting.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","path":"libs/awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","path":"medias/music/avatars/tiantangdemogui.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","path":"medias/music/avatars/yiluxiangbei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","path":"medias/music/avatars/yequ.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/0xbird.png","path":"medias/avatars/0xbird.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zzw.jpg","path":"medias/avatars/zzw.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lyn-draw.jpg","path":"medias/avatars/lyn-draw.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qianqian.png","path":"medias/avatars/qianqian.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jitao.jpg","path":"medias/avatars/jitao.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/feibar.png","path":"medias/avatars/feibar.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lzh.png","path":"medias/avatars/lzh.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mashiro.jpg","path":"medias/avatars/mashiro.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/25.jpg","path":"medias/featureimages/25.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/28.jpg","path":"medias/featureimages/28.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhangyi.jpg","path":"medias/avatars/zhangyi.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","path":"libs/awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/26.jpg","path":"medias/featureimages/26.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jingjing.jpg","path":"medias/avatars/jingjing.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","path":"libs/awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","path":"libs/awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","path":"libs/awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","path":"libs/awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","path":"medias/music/avatars/daoshu.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/27.jpg","path":"medias/featureimages/27.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/24.jpg","path":"medias/featureimages/24.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/myphoto.jpg","path":"medias/avatars/myphoto.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","path":"libs/awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/404.md","hash":"d97f69ff63501de89cfd341c68e4d6ed5c8a5b3a","modified":1586000622000},{"_id":"themes/matery/.gitignore","hash":"eaa3d84cb77d92a21b111fd1e37f53edc1ff9de0","modified":1586000622000},{"_id":"themes/matery/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1586000622000},{"_id":"themes/matery/README.md","hash":"7ef16198a2c5ff580f006582286354caf160c7fe","modified":1586000622000},{"_id":"themes/matery/README_CN.md","hash":"a94324950e0299bcfcbc106cf2ca65c93e1fe843","modified":1586000622000},{"_id":"themes/matery/_config.yml","hash":"ae89fade84450b8ab59b50c35776152a126358dd","modified":1617318110207},{"_id":"source/_data/friends.json","hash":"c43c4d3a74db36e032cf2e7f7490c5d4d34e9210","modified":1617318109586},{"_id":"source/_data/musics.json","hash":"32bc061f34721b4ff55f880de1d0ec5787acd2f9","modified":1586000622000},{"_id":"source/_posts/InnoDB-LRU-优化.md","hash":"ac3647c5326b0a6079a816399e1baf5aaeee10a0","modified":1619618811135},{"_id":"source/_posts/KafkaAdminClient.md","hash":"02846459b13fd6ec50782753dada61304ff03386","modified":1617369179201},{"_id":"source/_posts/flask面试.md","hash":"d4c04ff6c8a5b33150aff9fc95fbe1741120f179","modified":1620775591387},{"_id":"source/_posts/count优化.md","hash":"c8093b8fac9beca41ccffc96bc66ddfce71505e8","modified":1620738063601},{"_id":"source/_posts/join优化.md","hash":"86fa1b2c788b094f6854cafd6549ac2c582bb6c5","modified":1620737702781},{"_id":"source/_posts/kafka-Broker请求处理.md","hash":"da19aa09377e0b9182a88aeefb8e154a063ce175","modified":1617318109676},{"_id":"source/_posts/kafka主题管理.md","hash":"8a3300750c865730fe4b1c8f355073ca1c3157d7","modified":1617369057097},{"_id":"source/_posts/kafka思维导图.md","hash":"0d545b23c5fa82e1955c11f16d0bf871e056b8d0","modified":1617369689499},{"_id":"source/_posts/Kafka控制器.md","hash":"0147b921f85a1cd294f1e0791438b50c5352e3c3","modified":1617372108263},{"_id":"source/_posts/kafka副本.md","hash":"c864245d7dfaec37e9f51e1f00036e9d707a29a5","modified":1617318109716},{"_id":"source/_posts/kafka拦截器.md","hash":"7a331ee08a3a286a0fa07c24fb4a3f4e176ffcab","modified":1617318109716},{"_id":"source/_posts/kafka授权.md","hash":"6d5c141b699b85b195724e4c2456c4c347004764","modified":1617318109726},{"_id":"source/_posts/MVCC.md","hash":"ba4f95c69a4c6293b2910ecf08cbaf1154e8cbcd","modified":1619653718597},{"_id":"source/_posts/kafka消息丢失.md","hash":"c482fd10284dcd5c0547c10566a4a4430ae0d084","modified":1620732809544},{"_id":"source/_posts/kafka消费者.md","hash":"0fbebb3f862e378f013b7d25199663c39f7f481c","modified":1619524220338},{"_id":"source/_posts/kafka生产者.md","hash":"f491b22969509f75793398ea3764299a8bf0905d","modified":1619524189131},{"_id":"source/_posts/kafka认证.md","hash":"d86deed02701dcb74ff454b9bb569e56f9181e60","modified":1617371185827},{"_id":"source/_posts/kafka精确一次.md","hash":"f1d5df81ad1aea7e956b61577341ecabec291c53","modified":1617318109856},{"_id":"source/_posts/kafka调优.md","hash":"63537ddfa42511ae6ff804d1af61ad01c86233f8","modified":1617369377846},{"_id":"source/_posts/kafka集群配置.md","hash":"be360773a2c4c54afdf2ab8393e23cf50f765f6a","modified":1619613502204},{"_id":"source/_posts/kafka脚本.md","hash":"21479bec12b34350f97b38c6c431f194f2077f3b","modified":1619613849831},{"_id":"source/_posts/mysql思维导图.md","hash":"70b86f9dd9047515f01a82f6e32f4895589008d5","modified":1617370199029},{"_id":"source/_posts/kafka高水位和Leader-Epoch.md","hash":"7db37808727b5d40f16264d43e9c08bd3682229d","modified":1617320316364},{"_id":"source/_posts/kafka面试.md","hash":"0402dee568c441eadbe20f72f2fe3888495d3e97","modified":1621374764088},{"_id":"source/_posts/mysql数据类型.md","hash":"273612456eed77f31b3854c8eae47a8df4c0aa87","modified":1620738594160},{"_id":"source/_posts/mysql存储引擎.md","hash":"99a273f3eead8e884f53ffe3722d6700fc4f4ffe","modified":1620732809561},{"_id":"source/_posts/order-group-by优化.md","hash":"a1aa0774e494599f5ad390198b95c7c9701d74ed","modified":1620734813619},{"_id":"source/_posts/mysql面试.md","hash":"827186223fb3256dc0c9698113536e02766e7c42","modified":1621422582123},{"_id":"source/_posts/rabbitmq思维导图.md","hash":"772cce03cda1e49674d981fe4e4f66572ecb6f21","modified":1617519585233},{"_id":"source/_posts/mysql日志系统.md","hash":"ab9735eff0aa6fcdf854982764c3f3dea3804dea","modified":1619654922008},{"_id":"source/_posts/rabbitmq客户端开发.md","hash":"78540047e8d6fcdf5b8d370452b724de879de509","modified":1617456623423},{"_id":"source/_posts/python面试.md","hash":"e9501f82a586039060aa6804c0da1ad134fed709","modified":1621382440520},{"_id":"source/_posts/rabbitmq消息消费.md","hash":"f4682e75c1bc1656087189455026b5b689d54f80","modified":1620732809589},{"_id":"source/_posts/rabbitmq消息路由.md","hash":"32ebb600fb44cdeaee74c7a30fa1480c6f98d9fa","modified":1620732809590},{"_id":"source/_posts/rabbitmq概念.md","hash":"b14349c975b84d4a49f1508246d42ff4e5aec584","modified":1620732809565},{"_id":"source/_posts/rabbitmq消息发布.md","hash":"1c921678ff88e99c57330090f129f1e894637549","modified":1620732809575},{"_id":"source/_posts/rabbitmq进阶.md","hash":"99a3f8be23fafb46dee89ba32c40ee71390cb99b","modified":1617512526522},{"_id":"source/_posts/rabbitmq集群.md","hash":"3aade54627ab1f19ec09691072cb5397da84266b","modified":1617318109986},{"_id":"source/_posts/rabbitmq消息重复.md","hash":"c4ce418e68fe93c5b1ae94f9392c1667dd234ffe","modified":1617318109986},{"_id":"source/_posts/redis-AOF机制.md","hash":"7605dd9b3846e89af35763aa047c0c7d03c3e2be","modified":1621252078078},{"_id":"source/_posts/redis-RDB机制.md","hash":"dff6cc08412fbcab0a2e7b6b6b7094c507b9842a","modified":1621252078108},{"_id":"source/_posts/redis6-0.md","hash":"967227b89624d77ab88ed4eb63b0811269bfb166","modified":1621252078128},{"_id":"source/_posts/redis主从同步.md","hash":"504a8d6726809b19f5a37403545f950efb23c4b5","modified":1620568340230},{"_id":"source/_posts/redis内存碎片.md","hash":"0e6c54f4ffb18a372f0d3f100734564a096be3bd","modified":1617318110047},{"_id":"source/_posts/rabbitmq面试.md","hash":"dfb1b6c088e46da43097d8a5b39464dc6b2cd46c","modified":1621374764112},{"_id":"source/_posts/rabbitmq消息可靠性.md","hash":"6b30d314da243c1fd9eaf400484d8a41c6a777c0","modified":1620732809587},{"_id":"source/_posts/redis事务.md","hash":"4e9d882f2cc47923390e9aefc13601afe1a8906f","modified":1617318110047},{"_id":"source/_posts/redis分布式锁.md","hash":"2820af05b305fe50ef59a67135bb33742966ac92","modified":1621422582123},{"_id":"source/_posts/redis切片集群.md","hash":"385c8f2afbf741b8300be6cb01cfae3840846289","modified":1620568340245},{"_id":"source/_posts/redis思维导图.md","hash":"0f88b7f4b4c0977076244faca5945c9374e98691","modified":1617369745489},{"_id":"source/_posts/redis哨兵机制.md","hash":"c63d80ca3a75092b4b084a66d41467b114cae4f4","modified":1620741540145},{"_id":"source/_posts/redis应用.md","hash":"a48d470207437b4414cbfa1ee52253f6cb1dd1be","modified":1619524341242},{"_id":"source/_posts/redis数据结构.md","hash":"447baafbc5f9561747b8c54880b0b8e193d071bb","modified":1620732809606},{"_id":"source/_posts/redis消息队列.md","hash":"19edf5182b8eeb94c6e6187111c33b05d7c0d04b","modified":1620775660459},{"_id":"source/_posts/redis缓存.md","hash":"623944aebfa141c738d1db121f5258254ab988fb","modified":1620732809607},{"_id":"source/_posts/redis变慢以及优化方法.md","hash":"9c56f8a9d0f3baa306a5b634fbdc8350d261e990","modified":1621252078128},{"_id":"source/_posts/redis阻塞及解决办法.md","hash":"2909c2abfdf76dfb0e2d51f1592efca5528780a5","modified":1620568340251},{"_id":"source/_posts/redis网络IO模型.md","hash":"dcafef778f31bce6234b04f4fa195ef8304db14f","modified":1617318110117},{"_id":"source/_posts/事务.md","hash":"0508ebd07128238a452a749d188961b10c553e23","modified":1620822213154},{"_id":"source/_posts/redis面试.md","hash":"4b99ee9e1aec61b9ff60676ef2f77d9e28b234fd","modified":1621422582133},{"_id":"source/_posts/分库分表.md","hash":"6d9d084712f4d57f25b47a1b28ea20afdd3040f3","modified":1619698542883},{"_id":"source/_posts/基础架构.md","hash":"9f6ebeab0b6d671e5bddefe0e7b8aadcec598841","modified":1619698862476},{"_id":"source/_posts/sort-algorithms.md","hash":"d0672536d3f6e8ff8d3d3a39a470d6e60343ac65","modified":1617318110127},{"_id":"source/_posts/基于多CPU多核架构的redis性能优化.md","hash":"23a3ed9399e007f4d336a0eb0e35e02943955229","modified":1617318110137},{"_id":"source/_posts/批量数据导入优化.md","hash":"bf08af3ca3c5dd458da44d3d5d0fec3ef3dcce02","modified":1620734947137},{"_id":"source/_posts/慢查询定位与分析.md","hash":"1cc8f43b82b3e55aeda5131d1573222ea2e0a68b","modified":1619701886025},{"_id":"source/_posts/分页查询优化.md","hash":"3b8a1072320007013aab33eb5941991264b7c6ad","modified":1620737817258},{"_id":"source/_posts/数据恢复.md","hash":"080cfafa46e73daf7d98c1c02fd93bd5ffa4fe70","modified":1619705972274},{"_id":"source/_posts/网络.md","hash":"1bf9050c0770c216afef4088d8fc8f8630ef6c6a","modified":1621469339155},{"_id":"source/_posts/操作规范.md","hash":"2ccde511560cc7d35c0922b7ad936dbb69c7162a","modified":1619696704907},{"_id":"source/_posts/索引.md","hash":"7f8d086bc12c6245785bc47588f80bcd6e82dfc5","modified":1619707030068},{"_id":"source/about/index.md","hash":"a4ad6be6bdba3debe7108373729bc6ebdd405091","modified":1617318110207},{"_id":"source/archives/index.md","hash":"30a0e3a59be650ae34d7bb86ac7da53e21e9cf5b","modified":1586000622000},{"_id":"source/categories/index.md","hash":"67687d3f908737f7c680f096b3e80d9412f23b0e","modified":1586000622000},{"_id":"source/contact/index.md","hash":"19978439f7c1d202d1a792f687604642936fffe1","modified":1617318110207},{"_id":"source/tags/index.md","hash":"fe3d7ecc91b81b062a6a60c06859dc24b9d704ac","modified":1586000622000},{"_id":"source/friends/index.md","hash":"6cedb9ebc46ecbcf44f1ccdb8c0c6d74f265ed08","modified":1617318110207},{"_id":"source/_posts/索引失效.md","hash":"b788f033fa88340cdb906d01fd56a022ed29fc7e","modified":1619707077747},{"_id":"source/_posts/锁.md","hash":"e9d0be47a5346f813619ff1c3bf95cd68e65d046","modified":1620820428536},{"_id":"themes/matery/layout/about.ejs","hash":"e87752e59f021b5139b1155a264da11ab469a9aa","modified":1586000622000},{"_id":"themes/matery/layout/categories.ejs","hash":"c431e772d0f7700592228bbd9502793bdc28a893","modified":1586000622000},{"_id":"themes/matery/layout/archive.ejs","hash":"1b5023571894404d75caffa28128fc9c49f9095d","modified":1586000622000},{"_id":"themes/matery/layout/category.ejs","hash":"2d421e10c3b8fd2c4f725e5eaa967c4a1429c707","modified":1586000622000},{"_id":"themes/matery/layout/contact.ejs","hash":"1513c5a40b7cc0b6e5854cf8c3253958bcb486cb","modified":1586000622000},{"_id":"source/_posts/读写分离.md","hash":"0dd7cca915e1255493a1cf34af63e6921b93738b","modified":1619698257202},{"_id":"themes/matery/layout/index.ejs","hash":"7fc5a6c4f0229c0be43b7d1315524c468346fbb8","modified":1586000622000},{"_id":"themes/matery/layout/friends.ejs","hash":"895e40a864796680fbef581e4b09f252fbdd963a","modified":1586000622000},{"_id":"themes/matery/layout/layout.ejs","hash":"2ba4110dc596424b1220a259c8e594da774e7f59","modified":1586000622000},{"_id":"themes/matery/layout/tags.ejs","hash":"851c0ee599e91e7b1d657673859e8b6ff79cf50b","modified":1586000622000},{"_id":"themes/matery/layout/post.ejs","hash":"f1a35f32e5901e167ae9a750e7cb3635549cea2e","modified":1586000622000},{"_id":"themes/matery/layout/tag.ejs","hash":"5cdf3a1d72f54285ee9cb826fd0e4a0449093215","modified":1586000622000},{"_id":"themes/matery/languages/default.yml","hash":"527c795b8c41fe62bf35603ffebfa6d4a7929a2c","modified":1586000622000},{"_id":"themes/matery/layout/404.ejs","hash":"f08a0f507b36f3652520a41381f71167488405c7","modified":1586000622000},{"_id":"themes/matery/languages/zh-CN.yml","hash":"d92db4b986bb6f0d228e9a8249383103bf56342d","modified":1586000622000},{"_id":"themes/matery/source/favicon.png","hash":"979ccca1f7334916e1407716ef8a79736997535a","modified":1617318110218},{"_id":"source/_posts/kafka集群配置/atoconfig.png","hash":"0648ff94d92bc6832ba0e9d96a6af4e51975adfb","modified":1617318109926},{"_id":"source/_posts/redis消息队列/stream.jpg","hash":"8abb860ea69a87d2106c44436c171e93f7a3378b","modified":1617318110087},{"_id":"source/_posts/网络/huishou.jpg","hash":"dab40f5a8c19cb12f16dae9a475689b10548ae43","modified":1621466629717},{"_id":"source/_posts/网络/woshou.jpg","hash":"87b679be2ee114177b71e0f93e73496c43f58c80","modified":1621465938092},{"_id":"themes/matery/source/css/gitment.css","hash":"d5ef623065d1fbc897119f7b70ccf7563e329917","modified":1586000622000},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"4e3e855767ac5a48b13af1d6a42df13d8975e03f","modified":1586000622000},{"_id":"themes/matery/source/css/matery.css","hash":"0d345a72318fd7aadcb6fcaa6f3abac94b91001c","modified":1586000622000},{"_id":"themes/matery/source/css/my.css","hash":"37683a9f11c68903a53e2b8593ca8c095a721896","modified":1586000622000},{"_id":"source/_posts/sort-algorithms/1.png","hash":"cb9865eb782b293168e69406b212a0f3097b82a4","modified":1586000622000},{"_id":"themes/matery/source/js/matery.js","hash":"208b7806caa943c115aa0825c9c72a0781404775","modified":1586000622000},{"_id":"themes/matery/source/js/search.js","hash":"77ecae23dd3edd8ad962c5b12954652bb2f7a1b6","modified":1586000622000},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"cb99dc352397ec5d0765794d7b8884972e61973b","modified":1586000622000},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"d5a7b9bb96e04c0a3485dd873748f19c50a6a04f","modified":1586000622000},{"_id":"themes/matery/source/medias/logo.png","hash":"979ccca1f7334916e1407716ef8a79736997535a","modified":1617318110229},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"ab610754bf6aea844b5ae0802ed37c73b5f1dc9f","modified":1586000622000},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"fd4034bca2eb3987dcf113e6477260bee97eb1e7","modified":1586000622000},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"42dda8e67f7f09d148347887e52f18aea546df26","modified":1586000622000},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"d8c40dbc8106b5bc53ceb727ad968c1d8f234261","modified":1586000622000},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"a3a140e6aeeb6f289e4b821a577ef548267f3de1","modified":1586000622000},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"d3333a22bc29b36f216fddec0f089dffe1f89c0c","modified":1617372496038},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"890c8f04c1f4905dfceb3ea9fd6efdd040d79c01","modified":1586000622000},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"821e1af65990521c9e0288178d8e5b18c73a9cab","modified":1586000622000},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"9007283743db3361c026a9879eb2376c41ff9c6c","modified":1617318110207},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"d4042e5521ceb5f3255cd4455ac7ccd227fee6df","modified":1586000622000},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"e761f0104fbf431671bbe6bebc91ca82f737f4d2","modified":1586000622000},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"42728561c09589f79b698eb059ab4def53ed3642","modified":1586000622000},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"3a82fcb6f31d69971cb564985842c14ac02cdca0","modified":1586000622000},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"dfdeea9c59d157acb851d4bf44bf95f81787523c","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"166c0b9753f3f913bd801e82ad5b268004be198d","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"82cb8090cde663fa7ad67418a802997b3057e957","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"3f208f33e4e12becdb8323e6e64e20ad60c3fb2a","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"3b42900247d5ea4ea5b68e2be44420a0d54785ad","modified":1586000622000},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"e859fe6e0259e0c123cb7ceda6e4cac836318ffc","modified":1586000622000},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"0f2e1e27d21492cf228e786daead985b1e1dcea4","modified":1586000622000},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"4e73f10eacb5d00a0681cb44fe5c039cd8ab03cd","modified":1586000622000},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"f85a222ec3f9bc27eb7978015e63a16514b38791","modified":1586000622000},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"73624d9db81e87ff0c12310bb873fbd0b5221021","modified":1586000622000},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"e2865b3003ec07892e9112692e7ec786ee926ae8","modified":1586000622000},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"c3039180ddb2eb17e724b8441e5f93e79859aef7","modified":1586000622000},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"b2b22d4fc4e46b051f67216c391f629f4ff552b5","modified":1586000622000},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"6ae58a57b83a5999d0b6a737ec868f084d208f89","modified":1586000622000},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"5284712d84bbaa4f0d88026ac3ec5a8c13e00056","modified":1586000622000},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"9ea672db65f1e5b8fad1ffafb1614f25adc97e63","modified":1586000622000},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"fc50cb4bbc1f4d0e4c9f5941f1c3c74bea742db7","modified":1586000622000},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"785cb588a31215876f6737213054ba0e8552fff0","modified":1586000622000},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"c6f713316ce75ad08ac5d1587bd8ce42e894e9ae","modified":1586000622000},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"4608af6151f0e32f668c89f09343748340021478","modified":1586000622000},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"0aaf0a111b9aa07ff37f6286eeac5506283f47f8","modified":1586000622000},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"d439d86818de179d64965d4f7f5fa56147fd9221","modified":1586000622000},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"6310903eb0e434d6f9a59ca669aab7fae38d4797","modified":1586000622000},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"bf604fe9c435f0fb9a559cac9c35772579b590e8","modified":1586000622000},{"_id":"source/_posts/kafka消费者/state.jpeg","hash":"f158aceee4f56f0349c231014f3706bd4dc2c923","modified":1617318109826},{"_id":"source/_posts/网络/baowen.jpg","hash":"31af854bf7bc606db63180fbaa62db44e125069f","modified":1621465632872},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"05f5e2acace5730cdf7bed650375ad88f6b5d1b7","modified":1586000622000},{"_id":"source/_posts/kafka消费者/groups_shell.png","hash":"2874043395d38ec6050236abeee92317de4438d9","modified":1617318109766},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"ded9739f803d114c9168d3351fded72b3b478b4c","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","hash":"b74a381adf6ef8404d6a0452c2b9f44b47219c80","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","hash":"ea8b51e4d75e7b2cd63e4d5bcb8db2cf7f23f5db","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","hash":"215910dc8f63fd50b97957e5fcdc8480aa2728cb","modified":1586000622000},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"5a8e6d07ffa55642418ab3fd4b263aa08284b77a","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","hash":"9cd57c67fbd3e3067f80793ef8445f5ff7783563","modified":1586000622000},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"7f4f8913f2d46ade2def5134e2cc8684a4b87939","modified":1586000622000},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"5d52d3b34fceb9d7e11f1beaf7ed380b4249dec4","modified":1586000622000},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"33810b2b757fc4327bc1d3b83bb5e0d3dc1fec5b","modified":1586000622000},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"70c0c4a9bf698747b7c058c21287ad617355e5dd","modified":1586000622000},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"021898a16279ac2ffe75af4f902fab2a0a39f11a","modified":1586000622000},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"a0625d8b432af8bdc820f8768d36cde439e7257c","modified":1586000622000},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"26849509f196a2d21bbfd15696e5d5153163b8f1","modified":1586000622000},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"4e6538c8312aeeab845d361c37a8c1a0931241f0","modified":1586000622000},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"f81cd7bfcf7aa2d043bd3e6077df42656fc44b82","modified":1586000622000},{"_id":"themes/matery/source/libs/others/fireworks.js","hash":"53981959bc6def4a85bbbb41b07e4b1474a2124d","modified":1586000622000},{"_id":"themes/matery/source/libs/others/snow.js","hash":"b393f069781eef788a0ae66b2681cece8fea2851","modified":1586000622000},{"_id":"themes/matery/source/libs/others/text.js","hash":"1791782cde0d1e4197f2ed58ecb7dd6aefddd169","modified":1586000622000},{"_id":"themes/matery/source/libs/others/explosion.min.js","hash":"417b68e2cf2c6de2119c57626f4412105a8457f5","modified":1586000622000},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1586000622000},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"f646f2bb75bcd1eb65b2788ac7bf15d4fd243ce9","modified":1586000622000},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1586000622000},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1586000622000},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1586000622000},{"_id":"themes/matery/source/medias/reward/alipay.jpg","hash":"105c06576d1a1136bdf3a81905c7ddcc43ede294","modified":1617318110239},{"_id":"themes/matery/source/medias/featureimages/5.jpg","hash":"c4cc724f4572a9bcede7443a4f4c0393d3073868","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/0.jpg","hash":"1f8bbfbd625448b4b2a748b75636e456b826dcd3","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/ajin.jpg","hash":"76cb8e872472ff47a1b061c3bcff1c03f30c02b8","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/babyq.png","hash":"be5432588003e5a52c02e690622eec72b5f7346c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/cww97.jpg","hash":"6af987cafc55d8d031534dd5e0f722fff19f70ec","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/feibar.jpg","hash":"343f47cb5c83cd866a1c824cbe2a112d02516d06","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/hael.jpg","hash":"e66ccedab38bb2e8fc45fac024e234ab8e7b9d54","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/fun4go.png","hash":"0f4333973a972a629cfbabf601bc7c192b65376c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/huaji.jpg","hash":"86be7eed2a491455ccfe3e7da46366ff477765ca","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/hzwer.jpg","hash":"53a66bb5e65d2abd5b7412edf094c1e0b1094492","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/ids2.jpg","hash":"2c8d3ac6ab5ac6196bac83766fde975daca91c32","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/kewlgrl.jpg","hash":"3af0fd1029a1511bb3c0e90871e41b35e714b01f","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/ldy.jpg","hash":"906ef214d1f2fe52a663738340ad5623f826bd82","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/lijiaqian.png","hash":"9d96b3838acfae9a23b6e290fcfafceff0419c63","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/liyangzone.jpg","hash":"febab557e4c0d859ab4cc14b57d8106f5e3fccfb","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/masterx.jpg","hash":"c9f7e83d895fa241cefd6e742f356106b35f1b89","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/michael.jpg","hash":"331a2ab20c299196f5a3089b8445fc8f55346cb6","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mouse.jpg","hash":"2eae273885b9859150a1f98f74b3df12ca9a207c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mpy634.png","hash":"30f88e09c02b37c2dc684d4ee3237e327bb23f8b","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/liyucheng.jpg","hash":"12055a27fa667c87d2319475968056e1a8ad0f08","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/qiqiang.jpg","hash":"081459866f922d9558a88cd4d7155d91fa730322","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/spacesac.png","hash":"ff1bdb058f1f0499312da1a082ba97d78590db1a","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/sunchangzhi.jpg","hash":"bbe2a15fd474ab62dbd14fea72deb1113a4fb005","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/taotao.jpg","hash":"e668254375ddd40a684ff4669c3421851bebd36e","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/taowei.jpg","hash":"e58b03b70656aa7a27238be38dac3896d9d16f10","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/tawn.jpg","hash":"68a1cbacbb2370912b000c9d8d2b16196c918a50","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/yezijie.png","hash":"8a53537eb69f749115e512b6da061e7f23cd04e5","modified":1586000622000},{"_id":"source/_posts/redis主从同步/duxiefenli.jpg","hash":"c42908d4a016e55ca0e85a69c7c4509e1b0ebfc9","modified":1617318110026},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"5dfcbcee866e9dc564916416281885f3e320871e","modified":1586000622000},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"82276be41d2001e820020a219b90ad5b026302d1","modified":1586000622000},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","hash":"7a551393b8360731104fdef1af36a6f3638f5855","modified":1586000622000},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"5a13983930b019450e4fe01a407c64b3dd316be4","modified":1586000622000},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"f1558f12d96a352e490166d543a8e821dd3bb2bc","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/1.jpg","hash":"309f484b6e69e877de6a7fb847d66497d22bbd65","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/antnlp.ico","hash":"29475f350b989331cebd702a315f020917d06ed8","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/duyupei.jpg","hash":"3c02ed4cf57dc37e4f4b8314bf5094833a854cb0","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/gsy.jpg","hash":"6a175e2ba56a2280d40a2e654b559be41c3a0a48","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/jiejie.jpg","hash":"a52476e25bec2391674e77a889a89341fbb29791","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/milyyy.jpg","hash":"ac2826d9c28346efeb967df01465a2c74d9041fe","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/qiandongwei.jpg","hash":"6873551596a4513d01898ad866c4073c68270c57","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mizunashi.png","hash":"5fc300701d3b4250a307ed70e3a3aa0d5395c808","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","hash":"992e0d803160d2ae867be5eb0032d324d1cedffb","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/xiejiadong.jpg","hash":"f1a31f89426bd4dccdaba2170f4fc701336702e1","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/xuzhongyou.jpg","hash":"1db4dfaf23cf250f222a398326562d4170d3aaa1","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/zhaokangzhe.jpg","hash":"c8242bd13f08a9ddb97e26f216bc729b12ed9058","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/zhangting.jpg","hash":"10ee25ae3531f046a8bd3696c1cc8a16f0f25e1b","modified":1586000622000},{"_id":"source/_posts/kafka认证/compare.jpg","hash":"ee042251e517eda5a971e780aa33c3bfb571c05c","modified":1617318109896},{"_id":"source/_posts/rabbitmq概念/moxin.png","hash":"1ef43d749bffcb0f6e82af7e1b72bbbe115b9852","modified":1617447279897},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1586000622000},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"f63c7c489524ccb5d95e74fcd6618116c58fb305","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"f8cd48e1fff82ecd54a7ce3e69de8dba7c92d113","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1586000622000},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"7126de5cec8371e580b7b1f22512da0985cc39e5","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1586000622000},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c843f0dc497314574c608ca28cc742bb041786d5","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/0.jpg","hash":"d4db93afdff4ce889dd8271bcf9e80eb3c0bf866","modified":1586000622000},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1586000622000},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1586000622000},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"2c27939768606603bee3b5e6c8a722596a667e60","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","hash":"f005578ddb4d3d731838db89a708f39f18d50e60","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/6.jpg","hash":"4fcbc9dd8ec0316e9dd5bfd0caf86f1520b10b3f","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/2.jpg","hash":"280fa1c6493d7fdccfc18bd486446bacd9afe623","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","hash":"01b12e3aca7385a88412c12539e1a608a78896fa","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","hash":"103beb9ab33434b434fa37a30aecdb29db633024","modified":1586000622000},{"_id":"themes/matery/source/medias/reward/wechat.png","hash":"b22124cb6498bf1b896b28f7a8edad2d4bc95d68","modified":1617318110249},{"_id":"themes/matery/source/medias/featureimages/13.jpg","hash":"d8cc7a730668943dcb0776cfa240a0cf76826363","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/0xbird.png","hash":"f9d597dfcb49e1e2be06138b24028291f5638610","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/22.jpg","hash":"02ec4566225102778c3837f08b24de02faf460a6","modified":1586000622000},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"04c6b2782ce4610c429563110f6a20a47432fc4c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/zzw.jpg","hash":"5d385b5732644b07b937a4919abc83cb95e14513","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/lyn-draw.jpg","hash":"837d5d5df4dcb086d2da114d0d85084b4ec18768","modified":1586000622000},{"_id":"source/_posts/kafka高水位和Leader-Epoch/water.jpg","hash":"3d073059ee3de487ba7780979c2f10efc0b2b1c0","modified":1617318109936},{"_id":"themes/matery/source/medias/avatars/qianqian.png","hash":"fed254c4e7eb58ee22d647acb83f1d08f4508f8f","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/14.jpg","hash":"1c1063c29f827cf52eeef7ca8dc2d7e4efa31a76","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/12.jpg","hash":"c2892770fd5617418fd33d6f834879e05b2cdafd","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/jitao.jpg","hash":"5934b9baccebccbc2be2ead5d84ad32dd41f9559","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/feibar.png","hash":"eceaefcbbca1bf49b582eaa649d311cf4fe69dd6","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/lzh.png","hash":"8ffcbf19d6b38b891dbe408d9a4e9513b56f247e","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mashiro.jpg","hash":"250e911c16eeb6acb1e6214ad3e6a3d762850a8e","modified":1586000622000},{"_id":"source/_posts/kafka消费者/transport.jpg","hash":"1054da2267e08446511c1066e7ac1fc6064c9dd8","modified":1617318109856},{"_id":"source/_posts/kafka高水位和Leader-Epoch/bad.jpg","hash":"f0b3341ee83b34a8ffbc71ed8d4d317fd501d117","modified":1617320070668},{"_id":"themes/matery/source/medias/banner/5.jpg","hash":"6ddd1bcbb62a2d28c5be3b9acb7418849d60b2e7","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/4.jpg","hash":"a3cfdee2120195ab36b2fdd074d5558852e69297","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/2.jpg","hash":"1d8863277d744e1a18a2778ac26041bda5b03a98","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/25.jpg","hash":"d0668539783fc615f14178644e486a6befb90c0c","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/28.jpg","hash":"c73036359640a67a8b17db7ba0e968c088957ab8","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/zhangyi.jpg","hash":"c9130036aac9a7ac8d62e33550a9d64896cdc364","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1586000622000},{"_id":"source/_posts/redis主从同步/master_slave_slave.jpg","hash":"08d5a49519bf88de6d9596593c4bc56ea7a28aa9","modified":1617318110037},{"_id":"themes/matery/source/medias/banner/3.jpg","hash":"255aaa4375da855bd80b38cfcc253de892a9d4cf","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/17.jpg","hash":"11a6de283124964370dbfaf0e74f2f1e9ac8394d","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/20.jpg","hash":"84ba9cf61045de789426eeb6333910266ce29b8c","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/26.jpg","hash":"c66a4e7a2e670b63759a091f9428ee7f971d7b56","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/23.jpg","hash":"ee598933707f8bb98ecbf36925f24e8a1c4bd2d6","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/3.jpg","hash":"ceb8e0c195a7fe7420334efa114e98cd0e1c6523","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/jingjing.jpg","hash":"bfcab0139edb2509de984cb0a9b156879c355158","modified":1586000622000},{"_id":"source/_posts/kafka高水位和Leader-Epoch/good.jpg","hash":"e3721bbb3f844930f232f16f1c7212a427dfe3fc","modified":1617320314235},{"_id":"source/_posts/redis-AOF机制/aof.jpg","hash":"4c324b5894fb8dbdb3fce2fbe83d4a15c73591ce","modified":1621252078088},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/10.jpg","hash":"66de48d963e7f221931e550b2442da0cd40cbaa8","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/16.jpg","hash":"0801e96a2f4cbd14b2ad44547e5ffbb23822e751","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/21.jpg","hash":"a77810cc2224446f5d4e1a857a8d480f21e81f83","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/6.jpg","hash":"698fc46e97428d73c9d4e3d254e88b9b66fb38cd","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1586000622000},{"_id":"source/_posts/Kafka控制器/zookeeper.jpg","hash":"326d2bf2ed33838c5385d265fc42ea40b5aa91f3","modified":1617318109656},{"_id":"source/_posts/redis缓存/buyizhi2.jpg","hash":"a6450b90fe504f52318ac5163bcf7ee6e8913366","modified":1617318110117},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","hash":"eee120fdf5ccbe86aa7d51826c4c773e76e6357f","modified":1586000622000},{"_id":"source/_posts/redis思维导图/redis.png","hash":"316e710e31e0f9e9d6c32fc3a27f93facc6f8034","modified":1617318110057},{"_id":"themes/matery/source/medias/featureimages/1.jpg","hash":"f1d720039d654d693c32150c06c78cfc3663b0b4","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/27.jpg","hash":"7ea6f890cc59def8b1c9f393e4ae77cd16c79aad","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/7.jpg","hash":"bd400da9123424afe7ba6c839be9ad7697c1245b","modified":1586000622000},{"_id":"source/_posts/KafkaAdminClient/yuanli.jpg","hash":"b33c9a9f9235c216f78b405061c10579df31ebb9","modified":1617318109626},{"_id":"source/_posts/kafka-Broker请求处理/work.jpg","hash":"0d2ff3cf192c5796b0702f659395cf573bae61d5","modified":1617318109696},{"_id":"source/_posts/kafka思维导图/kafka.png","hash":"b74906e98d780baa859f9c83b83b75e1f0e6fe5c","modified":1617369532420},{"_id":"source/_posts/kafka消费者/plan1.jpg","hash":"f2a78bd9297b4e6b6391c17f28232e8a71c24e2e","modified":1617318109796},{"_id":"source/_posts/rabbitmq思维导图/rabbitmq.png","hash":"f1dcc6d138bbf4aeaddf7bc3d73ee46022851ec9","modified":1617519540892},{"_id":"source/_posts/redis-RDB机制/rdb.jpg","hash":"da8d2c0c37085bc7c749ce642c6dd2397b939f90","modified":1621252078118},{"_id":"themes/matery/source/medias/featureimages/11.jpg","hash":"2b30186c6d78ed76fa5f278be57290c1bd22c96a","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/18.jpg","hash":"c74ce6fa4eee122e147ec55532744f34a87ae2bf","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/24.jpg","hash":"72bc68fb0673b84ab9f863d2979396cdc268a76c","modified":1586000622000},{"_id":"source/_posts/kafka消费者/comsumedown.jpg","hash":"f6e8762b6f1d057a3268daafb73d45f22fda79c9","modified":1617318109746},{"_id":"themes/matery/source/medias/avatars/myphoto.jpg","hash":"669f8b38abb3ded420786054c86f95fef9ef4527","modified":1617318110229},{"_id":"themes/matery/source/medias/featureimages/19.jpg","hash":"2a47d1123d9c4c6255b7b4817a582d2fa9aea808","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/8.jpg","hash":"f81e97edf705ab45b989b2b15d6a13c005ccaa32","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1586000622000},{"_id":"source/_posts/kafka-Broker请求处理/reactor.jpg","hash":"ecc58bdb597b9438004a2036b4b769bbfc0c6f48","modified":1617318109686},{"_id":"source/_posts/Kafka控制器/data.jpg","hash":"5ef7a438b505613befe402feaf45ae4ee956211e","modified":1617318109656},{"_id":"source/_posts/kafka消费者/plan2.jpg","hash":"4c372732d8adda9285c477db4649b70c0c7e99fe","modified":1617318109806},{"_id":"source/_posts/kafka消费者/leavegroup.jpg","hash":"c3224fb7eb35028b3225a202a0a19b2428d82ad8","modified":1617318109786},{"_id":"source/_posts/redis主从同步/zhucongtongbu.jpg","hash":"09776048a670719e96d92ef2f14ee62f082167c3","modified":1617318110047},{"_id":"source/_posts/redis6-0/acl_cmd.jpg","hash":"450f8fc436cabfa7fc6fdc4685fac3b96617c458","modified":1617318110006},{"_id":"source/_posts/redis缓存/buyizhi.jpg","hash":"2e01f8fa0c307cdd02731705115a8f4e0751f50a","modified":1617318110107},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"8789b5e4daf0029a6c88f238f10e54d01c4fce82","modified":1586000622000},{"_id":"source/_posts/Kafka控制器/Failover.jpg","hash":"32652c973bbdebece0c6baa92bd4270cd874a595","modified":1617318109646},{"_id":"themes/matery/source/medias/featureimages/15.jpg","hash":"aff885598033614639944c7559b4849f883e2b34","modified":1586000622000},{"_id":"source/_posts/kafka消费者/newadd.jpg","hash":"2e60ac2598fff0a9d162504063beb64e4dc0c30a","modified":1617318109796},{"_id":"themes/matery/source/medias/featureimages/9.jpg","hash":"cd54b116609f5741cc7db0f7f49bf56ac356ddfb","modified":1586000622000},{"_id":"source/_posts/kafka消费者/stragey.jpg","hash":"28af504b239bb0e24597f9b4348c1a4021199b6a","modified":1617318109846},{"_id":"themes/matery/source/medias/featureimages/4.jpg","hash":"e06afe32a867f7a6e861618e0b5ac9d93cd71d05","modified":1586000622000},{"_id":"source/_posts/kafka消费者/compare.jpg","hash":"12d59e4df857edd4971b28fb49b9eebe0f81f236","modified":1617318109736},{"_id":"source/_posts/kafka高水位和Leader-Epoch/watertime.jpg","hash":"a4614413d175521e3744cdb2e9f661da1148df21","modified":1617318109966}],"Category":[{"name":"mysql","_id":"ckowss6kk0003q4ufl0haowgf"},{"name":"kafka","_id":"ckowss6l60008q4ufofkp6zzw"},{"name":"interview","_id":"ckowss6lv000fq4ufkqwtxhz5"},{"name":"rabbitmq","_id":"ckowss6xa002qq4ufnwgp5wbq"},{"name":"redis","_id":"ckowss72b003nq4uf6klybocc"},{"name":"算法","_id":"ckowss787005oq4uf6m56iojt"}],"Data":[{"_id":"friends","data":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]},{"_id":"musics","data":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}],"Page":[{"title":"404","date":"2019-07-19T08:41:10.000Z","type":"404","layout":"404","description":"你来到了没有知识的荒原 :(","_content":"","source":"404.md","raw":"---\ntitle: 404\ndate: 2019-07-19 16:41:10\ntype: \"404\"\nlayout: \"404\"\ndescription: \"你来到了没有知识的荒原 :(\"\n---\n","updated":"2020-04-04T11:43:42.000Z","path":"404.html","comments":1,"_id":"ckowss5kk0000q4ufkekzt254","content":"","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"about","date":"2021-03-07T08:41:10.000Z","type":"about","layout":"about","_content":"\n\n## 教育经历\n* <b>硕士 信号与信息处理</b>\n西安电子科技大学\n2015/06 - 2018-06\n* <b>本科 电子信息工程</b>\n苏州大学\n2011/09 - 2015/06\n\n## 联系方式\n* <b>电子邮箱</b>\n2276505170@qq.com\n\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2021-03-07 16:41:10\ntype: \"about\"\nlayout: \"about\"\n---\n\n\n## 教育经历\n* <b>硕士 信号与信息处理</b>\n西安电子科技大学\n2015/06 - 2018-06\n* <b>本科 电子信息工程</b>\n苏州大学\n2011/09 - 2015/06\n\n## 联系方式\n* <b>电子邮箱</b>\n2276505170@qq.com\n\n","updated":"2021-04-01T23:01:50.207Z","path":"about/index.html","comments":1,"_id":"ckowss6uf001tq4ufvgdx7xuq","content":"<h2 id=\"教育经历\"><a href=\"#教育经历\" class=\"headerlink\" title=\"教育经历\"></a>教育经历</h2><ul>\n<li><b>硕士 信号与信息处理</b><br>西安电子科技大学<br>2015/06 - 2018-06</li>\n<li><b>本科 电子信息工程</b><br>苏州大学<br>2011/09 - 2015/06</li>\n</ul>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li><b>电子邮箱</b><br><a href=\"mailto:2276505170@qq.com\" target=\"_blank\" rel=\"noopener\">2276505170@qq.com</a></li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"教育经历\"><a href=\"#教育经历\" class=\"headerlink\" title=\"教育经历\"></a>教育经历</h2><ul>\n<li><b>硕士 信号与信息处理</b><br>西安电子科技大学<br>2015/06 - 2018-06</li>\n<li><b>本科 电子信息工程</b><br>苏州大学<br>2011/09 - 2015/06</li>\n</ul>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li><b>电子邮箱</b><br><a href=\"mailto:2276505170@qq.com\" target=\"_blank\" rel=\"noopener\">2276505170@qq.com</a></li>\n</ul>\n"},{"title":"archives","date":"2019-07-19T08:39:20.000Z","type":"archives","layout":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-07-19 16:39:20\ntype: \"archives\"\nlayout: \"archives\"\n---","updated":"2020-04-04T11:43:42.000Z","path":"archives/index.html","comments":1,"_id":"ckowss6uq001vq4uf3cl0iyzm","content":"","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"categories","date":"2019-07-19T08:39:20.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-07-19 16:39:20\ntype: \"categories\"\nlayout: \"categories\"\n---","updated":"2020-04-04T11:43:42.000Z","path":"categories/index.html","comments":1,"_id":"ckowss6v4001yq4ufvrb7k18s","content":"","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"contact","date":"2021-03-07T08:04:02.000Z","type":"contact","layout":"contact","_content":"\n# 欢迎留言\n大家有任何问题，都可以在评论区给我留言。\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在评论区留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n* \n","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2021-03-07 16:04:02\ntype: \"contact\"\nlayout: \"contact\"\n---\n\n# 欢迎留言\n大家有任何问题，都可以在评论区给我留言。\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在评论区留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n* \n","updated":"2021-04-01T23:01:50.207Z","path":"contact/index.html","comments":1,"_id":"ckowss6vd0022q4ufg0q5flgt","content":"<h1 id=\"欢迎留言\"><a href=\"#欢迎留言\" class=\"headerlink\" title=\"欢迎留言\"></a>欢迎留言</h1><p>大家有任何问题，都可以在评论区给我留言。</p>\n<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在评论区留言，留言格式：</p>\n<ul>\n<li><p><strong>名称：</strong>你的博客名称</p>\n</li>\n<li><p><strong>地址：</strong>你的博客地址</p>\n</li>\n<li><p><strong>简介：</strong>一句话简介</p>\n</li>\n<li><p><strong>头像：</strong>你的头像地址</p>\n</li>\n<li></li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"欢迎留言\"><a href=\"#欢迎留言\" class=\"headerlink\" title=\"欢迎留言\"></a>欢迎留言</h1><p>大家有任何问题，都可以在评论区给我留言。</p>\n<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在评论区留言，留言格式：</p>\n<ul>\n<li><p><strong>名称：</strong>你的博客名称</p>\n</li>\n<li><p><strong>地址：</strong>你的博客地址</p>\n</li>\n<li><p><strong>简介：</strong>一句话简介</p>\n</li>\n<li><p><strong>头像：</strong>你的头像地址</p>\n</li>\n<li></li>\n</ul>\n"},{"title":"tags","date":"2019-07-19T08:40:27.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-07-19 16:40:27\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2020-04-04T11:43:42.000Z","path":"tags/index.html","comments":1,"_id":"ckowss6vn0026q4uf0v1a3ult","content":"","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"friends","date":"2021-03-07T07:53:10.000Z","type":"friends","layout":"friends","_content":"\n# 友链交换\n想要交换友链的小伙伴，欢迎在留言板留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2021-03-07 15:53:10\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在留言板留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n","updated":"2021-04-01T23:01:50.207Z","path":"friends/index.html","comments":1,"_id":"ckowss6vw002aq4uf50vlqtp6","content":"<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在留言板留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在留言板留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n"}],"Post":[{"title":"InnoDB LRU 优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-21T12:42:36.000Z","password":null,"summary":null,"_content":"\nInnoDB内存管理用的是最近最少使用 （Least Recently Used）算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。\n\n在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。\n\n1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部\n\n2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。\n\n3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：\n\n- 若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；\n- 如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。","source":"_posts/InnoDB-LRU-优化.md","raw":"---\ntitle: InnoDB LRU 优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-21 20:42:36\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\nInnoDB内存管理用的是最近最少使用 （Least Recently Used）算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。\n\n在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。\n\n1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部\n\n2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。\n\n3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：\n\n- 若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；\n- 如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。","slug":"InnoDB-LRU-优化","published":1,"updated":"2021-04-28T14:06:51.135Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ju0001q4ufbxsegzv1","content":"<p>InnoDB内存管理用的是最近最少使用 （Least Recently Used）算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。</p>\n<p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。</p>\n<p>1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部</p>\n<p>2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p>\n<p>3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p>\n<ul>\n<li>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</li>\n<li>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>InnoDB内存管理用的是最近最少使用 （Least Recently Used）算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。</p>\n<p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。</p>\n<p>1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部</p>\n<p>2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p>\n<p>3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p>\n<ul>\n<li>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</li>\n<li>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。</li>\n</ul>\n"},{"title":"KafkaAdminClient","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T12:54:48.000Z","password":null,"summary":null,"_content":"\n## 功能\n\n主题管理：包括主题的创建、删除和查询。\n\n权限管理：包括具体权限的配置与删除。\n\n配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。\n\n副本日志管理：包括副本底层日志路径的变更和详情查询。\n\n分区管理：即创建额外的主题分区。\n\n消息删除：即删除指定位移之前的分区消息。\n\nDelegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。\n\n消费者组管理：包括消费者组的查询、位移查询和删除。\n\nPreferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。\n\n## 工作原理\n\nAdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。\n\n前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；\n\n而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。\n\n![](yuanli.jpg)\n\n## 应用\n\n### 创建实例\n\n```java\nProperties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka-host:port\");\nprops.put(\"request.timeout.ms\", 600000);\n\ntry (AdminClient client = AdminClient.create(props)) {\n    // 执行你要做的操作……\n}\n```\n\n### 创建主题\n\n```java\nString newTopicName = \"test-topic\";\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 3); //主题名称、分区数和副本数\n    CreateTopicsResult result = client.createTopics(Arrays.asList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}\n```\n\n### 查询消费者组位移\n\n```java\nString groupID = \"test-group\";\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n    Map<TopicPartition, OffsetAndMetadata> offsets = \n        result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}\n```\n\n### 获取 Broker 磁盘占用\n\n```java\n\ntry (AdminClient client = AdminClient.create(props)) {\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(targetBrokerId)); // 指定Broker id\n    long size = 0L;\n    for (Map<String, DescribeLogDirsResponse.LogDirInfo> logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -> logDirInfo.replicaInfos).flatMap(\n            topicPartitionReplicaInfoMap ->\n            topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -> replicaInfo.size))\n            .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size);\n}\n```\n\n","source":"_posts/KafkaAdminClient.md","raw":"---\ntitle: KafkaAdminClient\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 20:54:48\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 功能\n\n主题管理：包括主题的创建、删除和查询。\n\n权限管理：包括具体权限的配置与删除。\n\n配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。\n\n副本日志管理：包括副本底层日志路径的变更和详情查询。\n\n分区管理：即创建额外的主题分区。\n\n消息删除：即删除指定位移之前的分区消息。\n\nDelegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。\n\n消费者组管理：包括消费者组的查询、位移查询和删除。\n\nPreferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。\n\n## 工作原理\n\nAdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。\n\n前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；\n\n而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。\n\n![](yuanli.jpg)\n\n## 应用\n\n### 创建实例\n\n```java\nProperties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka-host:port\");\nprops.put(\"request.timeout.ms\", 600000);\n\ntry (AdminClient client = AdminClient.create(props)) {\n    // 执行你要做的操作……\n}\n```\n\n### 创建主题\n\n```java\nString newTopicName = \"test-topic\";\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 3); //主题名称、分区数和副本数\n    CreateTopicsResult result = client.createTopics(Arrays.asList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}\n```\n\n### 查询消费者组位移\n\n```java\nString groupID = \"test-group\";\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n    Map<TopicPartition, OffsetAndMetadata> offsets = \n        result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}\n```\n\n### 获取 Broker 磁盘占用\n\n```java\n\ntry (AdminClient client = AdminClient.create(props)) {\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(targetBrokerId)); // 指定Broker id\n    long size = 0L;\n    for (Map<String, DescribeLogDirsResponse.LogDirInfo> logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -> logDirInfo.replicaInfos).flatMap(\n            topicPartitionReplicaInfoMap ->\n            topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -> replicaInfo.size))\n            .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size);\n}\n```\n\n","slug":"KafkaAdminClient","published":1,"updated":"2021-04-02T13:12:59.201Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6kf0002q4ufroc7dwge","content":"<h2 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h2><p>主题管理：包括主题的创建、删除和查询。</p>\n<p>权限管理：包括具体权限的配置与删除。</p>\n<p>配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。</p>\n<p>副本日志管理：包括副本底层日志路径的变更和详情查询。</p>\n<p>分区管理：即创建额外的主题分区。</p>\n<p>消息删除：即删除指定位移之前的分区消息。</p>\n<p>Delegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。</p>\n<p>消费者组管理：包括消费者组的查询、位移查询和删除。</p>\n<p>Preferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。</p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>AdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。</p>\n<p>前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；</p>\n<p>而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。</p>\n<p><img src=\"yuanli.jpg\" alt></p>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><h3 id=\"创建实例\"><a href=\"#创建实例\" class=\"headerlink\" title=\"创建实例\"></a>创建实例</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>AdminClientConfig<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token string\">\"kafka-host:port\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"request.timeout.ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">600000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\" spellcheck=\"true\">// 执行你要做的操作……</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"创建主题\"><a href=\"#创建主题\" class=\"headerlink\" title=\"创建主题\"></a>创建主题</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">String newTopicName <span class=\"token operator\">=</span> <span class=\"token string\">\"test-topic\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    NewTopic newTopic <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">NewTopic</span><span class=\"token punctuation\">(</span>newTopicName<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">short</span><span class=\"token punctuation\">)</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//主题名称、分区数和副本数</span>\n    CreateTopicsResult result <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">createTopics</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>newTopic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    result<span class=\"token punctuation\">.</span><span class=\"token function\">all</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>SECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"查询消费者组位移\"><a href=\"#查询消费者组位移\" class=\"headerlink\" title=\"查询消费者组位移\"></a>查询消费者组位移</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">String groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"test-group\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ListConsumerGroupOffsetsResult result <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">listConsumerGroupOffsets</span><span class=\"token punctuation\">(</span>groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets <span class=\"token operator\">=</span> \n        result<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsToOffsetAndMetadata</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>SECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"获取-Broker-磁盘占用\"><a href=\"#获取-Broker-磁盘占用\" class=\"headerlink\" title=\"获取 Broker 磁盘占用\"></a>获取 Broker 磁盘占用</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    DescribeLogDirsResult ret <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">describeLogDirs</span><span class=\"token punctuation\">(</span>Collections<span class=\"token punctuation\">.</span><span class=\"token function\">singletonList</span><span class=\"token punctuation\">(</span>targetBrokerId<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 指定Broker id</span>\n    <span class=\"token keyword\">long</span> size <span class=\"token operator\">=</span> 0L<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> DescribeLogDirsResponse<span class=\"token punctuation\">.</span>LogDirInfo<span class=\"token operator\">></span> logDirInfoMap <span class=\"token operator\">:</span> ret<span class=\"token punctuation\">.</span><span class=\"token function\">all</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        size <span class=\"token operator\">+=</span> logDirInfoMap<span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>logDirInfo <span class=\"token operator\">-</span><span class=\"token operator\">></span> logDirInfo<span class=\"token punctuation\">.</span>replicaInfos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">flatMap</span><span class=\"token punctuation\">(</span>\n            topicPartitionReplicaInfoMap <span class=\"token operator\">-</span><span class=\"token operator\">></span>\n            topicPartitionReplicaInfoMap<span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>replicaInfo <span class=\"token operator\">-</span><span class=\"token operator\">></span> replicaInfo<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">.</span><span class=\"token function\">mapToLong</span><span class=\"token punctuation\">(</span>Long<span class=\"token operator\">:</span><span class=\"token operator\">:</span>longValue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h2><p>主题管理：包括主题的创建、删除和查询。</p>\n<p>权限管理：包括具体权限的配置与删除。</p>\n<p>配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。</p>\n<p>副本日志管理：包括副本底层日志路径的变更和详情查询。</p>\n<p>分区管理：即创建额外的主题分区。</p>\n<p>消息删除：即删除指定位移之前的分区消息。</p>\n<p>Delegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。</p>\n<p>消费者组管理：包括消费者组的查询、位移查询和删除。</p>\n<p>Preferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。</p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>AdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。</p>\n<p>前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；</p>\n<p>而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。</p>\n<p><img src=\"yuanli.jpg\" alt></p>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><h3 id=\"创建实例\"><a href=\"#创建实例\" class=\"headerlink\" title=\"创建实例\"></a>创建实例</h3><pre><code class=\"java\">Properties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;kafka-host:port&quot;);\nprops.put(&quot;request.timeout.ms&quot;, 600000);\n\ntry (AdminClient client = AdminClient.create(props)) {\n    // 执行你要做的操作……\n}</code></pre>\n<h3 id=\"创建主题\"><a href=\"#创建主题\" class=\"headerlink\" title=\"创建主题\"></a>创建主题</h3><pre><code class=\"java\">String newTopicName = &quot;test-topic&quot;;\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 3); //主题名称、分区数和副本数\n    CreateTopicsResult result = client.createTopics(Arrays.asList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}</code></pre>\n<h3 id=\"查询消费者组位移\"><a href=\"#查询消费者组位移\" class=\"headerlink\" title=\"查询消费者组位移\"></a>查询消费者组位移</h3><pre><code class=\"java\">String groupID = &quot;test-group&quot;;\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n    Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = \n        result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}</code></pre>\n<h3 id=\"获取-Broker-磁盘占用\"><a href=\"#获取-Broker-磁盘占用\" class=\"headerlink\" title=\"获取 Broker 磁盘占用\"></a>获取 Broker 磁盘占用</h3><pre><code class=\"java\">\ntry (AdminClient client = AdminClient.create(props)) {\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(targetBrokerId)); // 指定Broker id\n    long size = 0L;\n    for (Map&lt;String, DescribeLogDirsResponse.LogDirInfo&gt; logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -&gt; logDirInfo.replicaInfos).flatMap(\n            topicPartitionReplicaInfoMap -&gt;\n            topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -&gt; replicaInfo.size))\n            .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size);\n}</code></pre>\n"},{"title":"flask","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-22T12:23:24.000Z","password":null,"summary":null,"_content":"\n# Flask框架\n\n## WEB框架\n\n它们接收 HTTP 请求，然后分发任务，并生成 HTML，然后返回包含 HTML 的 HTTP 应答。\n\n## 应用启动过程\n\n- `run` 方法启动了 Flask 应用\n\n- `run` 方法调用werkzeug 的 `run_simple` 方法，启动了服务器 `BaseWSGIServer`。在调用 run_simple 时，Flask 对象把自己 `self` 作为参数传进去了，在收到请求的时候，就知道调用谁的 `__call__` 方法。\n\n## 请求处理过程\n\n- 默认使用 `WSGIRequestHandler `类来作为 request handler，在接收到请求时这个类在被 `BaseWSGIServer` 调用时，会执行`execute`函数\n\n- `execute`函数中，把 `environ` 和 `start_response` 传入，调用 `app`的`__call__` 。\n- `app`的`__call__`中，调用了 `wsgi_app`方法（为了中间件）。\n\n> 该方法最终返回的`response(environ, start_response)`中的response 是`werkzueg.response` 类的一个实例，是可调用的对象，负责生成最终的可遍历的响应体，并调用 `start_response` 形成响应头\n\n-  `wsgi_app`方法中 调用 `request_context(environ)`函数建立了一个 `RequestContext` **请求上下文对象**\n   -   `RequestContext`初始化根据传入的 `environ` 创建一个 `werkzeug.Request` 的实例\n   \n-  把请求上下文 `RequestContext`，调用`push`，压入`_request_ctx_stack` 栈。（这些操作是为了 flask 在处理多个请求的时候不会混淆）。\n   \n   -  `_request_ctx_stack` 是一个 `LocalStack` 类的实例，通过**Local实现线程隔离**，隔离是使用了`get_ident`,属性被保存到每个线程id对应的字典中了。\n   \n-  `wsgi_app`方法中 调用  `full_dispatch_request`方法**请求分发**，开始实际的请求处理过程，这个过程中会生成 `response`对象来返回给服务器。\n\n   -  调用 `try_trigger_before_first_request_functions` 方法尝试调用 `before_first_request` 列表中的函数，只会执行一次\n   -  调用 `preprocess_request` 方法，调用 `before_request_funcs` 列表中所有的方法。（可以检测用户是否登录，未登录使用`abort`返回错误，则后续不会分发）\n   -  调用 `dispatch_request` 方法进行业务请求分发。\n   \n        -  `_request_ctx_stack.top.request`获取请求上下文\n        -  获取请求上下文在的`rule`\n        -  调用 `view_functions` 中相应的**视图函数**（`rule.endpoint` 作为键值）并把参数值传入（`**req.view_args`），视图函数就是开发人员写的API接口了。视图函数的返回值或者错误处理视图函数的返回值会作为`rv`返回给`full_dispatch_request`。\n   \n     -  调用`finalize_request`根据 `rv` 生成响应\n       - 调用`make_response` 方法会查看 rv 是否是要求的返回值类型，否则生成正确的返回类型。\n       -  调用`process_response` 方法，实现`after_request`方法的调用\n       - 返回`response`\n\n\n- 如果当中出错，就生成相应的错误信息。\n\n- 把**请求上下文**出栈。\n\n## 视图函数注册\n\n在程序加载业务代码时，用修饰器 `route `注册视图函数，并实现 URL 到视图函数的映射。在` route` 方法中，调用了` add_url_rule `方法。主要流程如下：\n\n- 准备好一个视图函数所支持的 HTTP 方法\n- 通过 `url_rule_class` 创建一个 `rule` 对象，并把这个对象添加到自己的 `url_map`\n\n> `rule` 对象是一个保存合法的（Flask 应用所支持的） URL、方法、`endpoint`（在 `**options` 中） 及它们的对应关系的数据结构\n>\n>  `url_map` 是保存`rule` 对象的集合\n\n- `view_functions`中加入`endpoint`、视图函数的映射关系\n\n在 Flask 应用收到请求时，这些被绑定到 url_map 上的 Rule 会被查看，来找到它们对应的视图函数。在 `dispatch_request` 方法中，从 `_request_ctx_stack.top.request` 得到 `rule` 并从这个 `rule` 找到 `endpoint`，最终找到用来处理该请求的正确的视图函数的。\n\n## 请求的过程总结\n\n- 在请求发出之前，Flask 注册好了所有的视图函数和 URL映射，服务器在自己身上注册了 Flask 应用。\n\n- 请求到达服务器，服务器准备好 environ 和 make_response 函数，然后调用了自己身上注册的 Flask 应用。\n\n- 通过 `__call__ `中转到 wsgi_app 的方法。它首先通过 environ 创建了请求上下文，并将它推入栈，使得 flask 在处理当前请求的过程中都可以访问到这个请求上下文。\n\n-  `full_dispatch_request`中开始处理这个请求，依次调用 `before_first_request_funcs` `before_request_funcs view_functions `中的函数，并最终通过 `finalize_request` 生成一个 `response `对象，调用`after_request_funcs `进行 response 生成后的后处理。\n\n- Flask 调用这个 response 对象，最终调用了 make_response 函数，并返回了一个可遍历的响应内容。\n\n- 服务器发送响应。\n\n## Flask 和 werkzeug关系\n\nFlask 和 werkzeug 是强耦合的，一些非常细节的工作，其实都是 werkzeug 库完成的：\n\n- 封装 Response 和 Request 类型供 Flask 使用，在实际开发中，我们在请求和响应对象上的操作，调用的其实是 werkzeug 的方法。\n\n- 实现 URL到视图函数的映射，并且能把 URL中的参数传给该视图函数。我们看到了 Flask 的 url_map 属性并且看到了它如何绑定视图函数和错误处理函数，但是具体的映射规则的实现，和在响应过程中的 URL解析，都是由 werkzeug 完成的。\n\n- 通过 _request_ctx_stack 对 Flask 实现线程保护。\n\n## 默认session处理机制?\n\nflask的session是基于cookie的会话保持。**简单的原理**即：\n\n当客户端进行第一次请求时，客户端的HTTP request（cookie为空）到服务端，服务端创建session，视图函数中填写session，请求结束时，session内容填写入response的cookie中并返回给客户端，客户端的cookie中便保存了用户的数据。\n\n当同一客户端再次请求时， 客户端的HTTP request中cookie已经携带数据，视图函数根据cookie中值做相应操作（如已经携带用户名和密码就可以直接登陆）。\n\n**请求第一次来时，session是什么时候生成的？存放在哪里？**\n\n- 客户端的请求进来时，会生成RequestContext对象。其中定义了session，且初值为None。\n\n- 在ctx.push()函数中，所有和 session 有关的调用，都转发到 `session_interface` 的方法调用上，而默认的 `session_inerface`为`SecureCookieSessionInterface()`\n  - 执行`SecureCookieSessionInterface.open_session()`来生成默认session对象\n    - 获取session签名的算法\n    - 获取*request.cookies*，请求第一次来时，**request.cookies为空**，即返回`SecureCookieSession`,session就是一个特殊的字典\n\n**当请求第二次来时，session生成的是什么？**\n\n**request.cookies不为空**，, 获取cookie的有效时长，如果cookie依然有效，通过与写入时同样的签名算法将cookie中的值解密出来并写入字典并返回中，若cookie已经失效，则仍然返回'空字典'。\n\n**特殊的SecureCookieSession字典有那些功能？如何实现的？**\n\n`permanent`（flask 插件会用到这个变量）、`modified`（表明实例是否被更新过，如果更新过就要重新计算并设置 cookie，因为计算过程比较贵，所以如果对象没有被修改，就直接跳过）\n\n`SecureCookieSession` 是基于 `CallbackDict` 实现的，这个类可以指定一个函数作为 on_update 参数，每次有字典操作的时候（`__setitem__`、`__delitem__`、clear、popitem、update、pop、setdefault）会调用这个函数。\n**session什么时候写入cookie中？session的生命周期？**\n\n`process_response`判断session是否为空，如果不为空，则执行`save_session()`，其中通过`response.set_cookie`将session写入。这样便完成session的写入response工作，并由response返回至客户端。\n\n## 上下文\n\n### **flask上下文种类**\n\ncurrent_app、g 是应用上下文。 request、session 是请求上下文。\n\n### 为什么要用上下文\n\nflask从客户端获取到请求时，要让视图函数能访问一些对象，这样才能处理请求。例如请求对象就是一个很好的例子。要让视图函数访问请求对象，一个显而易见的方法就是将其作为参数传入视图函数，不过这回导致程序中的每个视图函数都增加一个参数，为了避免大量可有可无才参数把视图函数弄得一团糟，flask使用上下文临时把某些对象变为全局可访问（只是当前线程的全局可访问）。\n\n### **请求上下文和应用上下文两者区别**\n\n请求上下文:保存了客户端和服务器交互的数据。request处理http请求，session  处理用户信息。LocalStack用来存储请求上下文\n\n应用上下文:flask 应用程序运行过程中，保存一些配置信息，比如程序名、数据库连接、应用信息等。\n\ng 用来存储开发者自定义的一些数据，不用通过传参的方式获取参数了。current_app 当前激活程序的程序实例。LocalStack用来存储应用上下文。\n\n### **生命周期** \n\n- current_app的生命周期最长，只要当前程序实例还在运行，都不会失效。\n- Request和g的生命周期为一次请求期间，当请求处理完成后，生命周期也就完结了\n- Session就是传统意义上的session了。只要它还未失效（用户未关闭浏览器、没有超过设定的失效时间），那么不同的请求会共用同样的session。\n\n### **为什么上下文需要放在栈中？**\n\n1.应用上下文：\n\nFlask底层是基于werkzeug，werkzeug是可以包含多个app的，所以这时候用一个栈来保存，如果你在使用app1，那么app1应该是要在栈的顶部，如果用完了app1那么app应该从栈中删除，方便其他代码使用下面的app。\n\n2.请求上下文：\n\n如果在写测试代码，或者离线脚本的时候，我们有时候可能需要创建多个请求上下文，这时候就需要存放到一个栈中了。使用哪个请求上下文的时候，就把对应的请求上下文放到栈的顶部，用完了就要把这个请求上下文从栈中移除掉。\n\n### 上下文管理流程?\n\n每次有请求过来的时候，flask 会先创建当前线程或者进程需要处理的两个重要上下文对象，把它们保存到隔离的栈里面，这样视图函数进行处理的时候就能直接从栈上获取这些信息。\n\n1.请求到来时，将session和request封装到ctx对象中；\n\n2.对session作补充；\n\n3.将包含了request和session的ctx对象放到一个容器中（每一个请求都会根据线程/协程加一个惟一标识）；\n\n4.视图函数使用的时候须要根据当前线程或协程的惟一标识，获取ctx对象，再取ctx对象中取request和session（视图函数使用的时候，须要根据当前线程获取数据。）\n\n5.请求结束时，根据当前线程/协程的惟一标记，将这个容器上的数据移除。\n\n###  为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？\n\n虽然在实际运行中，每个请求对应一个 request context 和一个 application context，但是在测试或者 python shell 中运行的时候，用户可以单独创建 request context 或者 application context，这种灵活度方便用户的不同的使用场景\n\n### 为什么Local对象中的stack 维护成一个列表？\n\n测试的时候可以添加多个上下文，另外一个原因是 flask 可以[多个 application 同时运行](http://flask.pocoo.org/docs/0.12/patterns/appdispatch/#combining-applications)\n\n### Flask中多app应用是怎么完成？\n\n请求进来时，可以根据URL的不同，交给不同的APP处理。\n\n使用Flask类建立不一样的app对象，而后借助DispatcherMiddleware类来实现。\n\n### Local对象和threading.local对象的区别\n\nThread Local 则是一种特殊的对象，它的“状态”对线程隔离 —— 也就是说每个线程对一个 Thread Local 对象的修改都不会影响其他线程。原理也非常简单，只要以线程的 ID 来保存多份状态字典即可。\n\nwerkzeug.local.Local和threading.local**区别**如下：\n\n（1）werkzeug使用了自定义的`__storage__`保存不同线程下的状态\n\n（2）werkzeug提供了释放本地线程的release_local方法\n\n（3）werkzeug通过get_ident函数来获得线程标识符\n\n#### **为什么造轮子**\n\nWSGI不保证每个请求必须由一个线程来处理，如果WSGI服务器不是每个线程派发一个请求，而是每个协程派发一个请求，thread local变量可能会造成请求间数据相互干扰，因为一个线程中存在多个请求。\n\n#### 除 了Local \n\nWerkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。\n\nLocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。\n\nLocalProxy用于代理Local对象和LocalStack对象，而所谓代理就是作为中间的代理人来处理所有针对被代理对象的操作。LocalStack无法再动态更新了，而使用Proxy实现了动态更新。重载了绝大多数操作符，以便在调用LocalProxy的相应操作时，通过`_get_current_object` method来获取真正代理的对象，然后再进行相应操作\n\n## 蓝图\n\n### 作用\n\n- 将不同的功能模块化，构建大型应用\n\n- 优化项目结构\n\n- 增强可读性,易于维护\n\n###  使用\n\n- 新增了一个xxx.py的文件，实例化Blueprint应用\n- xxx.py编写视图函数，使用Blueprint应用示例设置路由\n- run.py中，注册蓝图示例\n\n## 如何在Flask中访问会话?\n\n用户第一次请求后，将产生的状态信息保存在session中，这时可以把session当做一个容器，它保存了正在使用的所有用户的状态信息；这段状态信息分配了一个唯一的标识符用来标识用户的身份，将其保存在响应对象的cookie中；当第二次请求时，解析cookie中的标识符，拿到标识符后去session找到对应的用户的信息。\n\n在flask中，如果我们想要获取session信息，直接通过flask的session获取就可以了，这是因为session是一个代理对象，代理当前请求上下文的session属性。\n\n## wsgi\n\nWeb服务器和Web应用程序或框架之间的一种简单而通用的接口。描述了web server如何与web application交互、web application如何处理请求。\n\n**应用程序端**\n\nWSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了`__call__` 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。\n\n## Werkzeug\n\nHTTP 和 WSGI 相关的工具集，可以用来编写 web 框架，可以直接使用它提供的一些帮助函数。\n\nwerkzeug 提供了 python web WSGI 开发相关的功能：\n\n- 路由处理：如何根据请求 URL 找到对应的视图函数\n\n- request 和 response 封装: 提供更好的方式处理request和生成response对象\n\n- 自带的 WSGI server: 测试环境运行WSGI应用\n\n## RESTful\n\nREST的名称\"表现层状态转化\"中，省略了主语。\"表现层\"其实指的是\"资源\"（Resources）的\"表现层\"。\n\n（1）每一个URI代表一种资源；\n\n（2）客户端和服务器之间，传递这种资源的某种表现层；\n\n（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现\"表现层状态转化\"。\n\n\"资源\"是一种信息实体，它可以有多种外在表现形式。**我们把\"资源\"具体呈现出来的形式，叫做它的\"表现层\"（Representation）。**\n\n所有的状态都保存在服务器端。因此，**如果客户端想要操作服务器，必须通过某种手段，让服务器端发生\"状态转化\"（State Transfer）。而这种转化是建立在表现层之上的，所以就是\"表现层状态转化\"。**\n\n## 参考资料\n\nhttps://juejin.im/post/6844903533238566925#heading-10\n\nhttp://www.pythondoc.com/flask/appcontext.html\n\nhttp://www.pythondoc.com/flask/reqcontext.html\n\nhttps://cizixs.com/2017/01/12/flask-insight-routing/\n\nhttps://www.cnblogs.com/kendrick/p/7649772.html\n\nhttps://www.cnblogs.com/panlq/p/13266426.html","source":"_posts/flask面试.md","raw":"---\ntitle: flask\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-22 20:23:24\npassword:\nsummary:\ntags:\n- interview\ncategories:\n- interview\n---\n\n# Flask框架\n\n## WEB框架\n\n它们接收 HTTP 请求，然后分发任务，并生成 HTML，然后返回包含 HTML 的 HTTP 应答。\n\n## 应用启动过程\n\n- `run` 方法启动了 Flask 应用\n\n- `run` 方法调用werkzeug 的 `run_simple` 方法，启动了服务器 `BaseWSGIServer`。在调用 run_simple 时，Flask 对象把自己 `self` 作为参数传进去了，在收到请求的时候，就知道调用谁的 `__call__` 方法。\n\n## 请求处理过程\n\n- 默认使用 `WSGIRequestHandler `类来作为 request handler，在接收到请求时这个类在被 `BaseWSGIServer` 调用时，会执行`execute`函数\n\n- `execute`函数中，把 `environ` 和 `start_response` 传入，调用 `app`的`__call__` 。\n- `app`的`__call__`中，调用了 `wsgi_app`方法（为了中间件）。\n\n> 该方法最终返回的`response(environ, start_response)`中的response 是`werkzueg.response` 类的一个实例，是可调用的对象，负责生成最终的可遍历的响应体，并调用 `start_response` 形成响应头\n\n-  `wsgi_app`方法中 调用 `request_context(environ)`函数建立了一个 `RequestContext` **请求上下文对象**\n   -   `RequestContext`初始化根据传入的 `environ` 创建一个 `werkzeug.Request` 的实例\n   \n-  把请求上下文 `RequestContext`，调用`push`，压入`_request_ctx_stack` 栈。（这些操作是为了 flask 在处理多个请求的时候不会混淆）。\n   \n   -  `_request_ctx_stack` 是一个 `LocalStack` 类的实例，通过**Local实现线程隔离**，隔离是使用了`get_ident`,属性被保存到每个线程id对应的字典中了。\n   \n-  `wsgi_app`方法中 调用  `full_dispatch_request`方法**请求分发**，开始实际的请求处理过程，这个过程中会生成 `response`对象来返回给服务器。\n\n   -  调用 `try_trigger_before_first_request_functions` 方法尝试调用 `before_first_request` 列表中的函数，只会执行一次\n   -  调用 `preprocess_request` 方法，调用 `before_request_funcs` 列表中所有的方法。（可以检测用户是否登录，未登录使用`abort`返回错误，则后续不会分发）\n   -  调用 `dispatch_request` 方法进行业务请求分发。\n   \n        -  `_request_ctx_stack.top.request`获取请求上下文\n        -  获取请求上下文在的`rule`\n        -  调用 `view_functions` 中相应的**视图函数**（`rule.endpoint` 作为键值）并把参数值传入（`**req.view_args`），视图函数就是开发人员写的API接口了。视图函数的返回值或者错误处理视图函数的返回值会作为`rv`返回给`full_dispatch_request`。\n   \n     -  调用`finalize_request`根据 `rv` 生成响应\n       - 调用`make_response` 方法会查看 rv 是否是要求的返回值类型，否则生成正确的返回类型。\n       -  调用`process_response` 方法，实现`after_request`方法的调用\n       - 返回`response`\n\n\n- 如果当中出错，就生成相应的错误信息。\n\n- 把**请求上下文**出栈。\n\n## 视图函数注册\n\n在程序加载业务代码时，用修饰器 `route `注册视图函数，并实现 URL 到视图函数的映射。在` route` 方法中，调用了` add_url_rule `方法。主要流程如下：\n\n- 准备好一个视图函数所支持的 HTTP 方法\n- 通过 `url_rule_class` 创建一个 `rule` 对象，并把这个对象添加到自己的 `url_map`\n\n> `rule` 对象是一个保存合法的（Flask 应用所支持的） URL、方法、`endpoint`（在 `**options` 中） 及它们的对应关系的数据结构\n>\n>  `url_map` 是保存`rule` 对象的集合\n\n- `view_functions`中加入`endpoint`、视图函数的映射关系\n\n在 Flask 应用收到请求时，这些被绑定到 url_map 上的 Rule 会被查看，来找到它们对应的视图函数。在 `dispatch_request` 方法中，从 `_request_ctx_stack.top.request` 得到 `rule` 并从这个 `rule` 找到 `endpoint`，最终找到用来处理该请求的正确的视图函数的。\n\n## 请求的过程总结\n\n- 在请求发出之前，Flask 注册好了所有的视图函数和 URL映射，服务器在自己身上注册了 Flask 应用。\n\n- 请求到达服务器，服务器准备好 environ 和 make_response 函数，然后调用了自己身上注册的 Flask 应用。\n\n- 通过 `__call__ `中转到 wsgi_app 的方法。它首先通过 environ 创建了请求上下文，并将它推入栈，使得 flask 在处理当前请求的过程中都可以访问到这个请求上下文。\n\n-  `full_dispatch_request`中开始处理这个请求，依次调用 `before_first_request_funcs` `before_request_funcs view_functions `中的函数，并最终通过 `finalize_request` 生成一个 `response `对象，调用`after_request_funcs `进行 response 生成后的后处理。\n\n- Flask 调用这个 response 对象，最终调用了 make_response 函数，并返回了一个可遍历的响应内容。\n\n- 服务器发送响应。\n\n## Flask 和 werkzeug关系\n\nFlask 和 werkzeug 是强耦合的，一些非常细节的工作，其实都是 werkzeug 库完成的：\n\n- 封装 Response 和 Request 类型供 Flask 使用，在实际开发中，我们在请求和响应对象上的操作，调用的其实是 werkzeug 的方法。\n\n- 实现 URL到视图函数的映射，并且能把 URL中的参数传给该视图函数。我们看到了 Flask 的 url_map 属性并且看到了它如何绑定视图函数和错误处理函数，但是具体的映射规则的实现，和在响应过程中的 URL解析，都是由 werkzeug 完成的。\n\n- 通过 _request_ctx_stack 对 Flask 实现线程保护。\n\n## 默认session处理机制?\n\nflask的session是基于cookie的会话保持。**简单的原理**即：\n\n当客户端进行第一次请求时，客户端的HTTP request（cookie为空）到服务端，服务端创建session，视图函数中填写session，请求结束时，session内容填写入response的cookie中并返回给客户端，客户端的cookie中便保存了用户的数据。\n\n当同一客户端再次请求时， 客户端的HTTP request中cookie已经携带数据，视图函数根据cookie中值做相应操作（如已经携带用户名和密码就可以直接登陆）。\n\n**请求第一次来时，session是什么时候生成的？存放在哪里？**\n\n- 客户端的请求进来时，会生成RequestContext对象。其中定义了session，且初值为None。\n\n- 在ctx.push()函数中，所有和 session 有关的调用，都转发到 `session_interface` 的方法调用上，而默认的 `session_inerface`为`SecureCookieSessionInterface()`\n  - 执行`SecureCookieSessionInterface.open_session()`来生成默认session对象\n    - 获取session签名的算法\n    - 获取*request.cookies*，请求第一次来时，**request.cookies为空**，即返回`SecureCookieSession`,session就是一个特殊的字典\n\n**当请求第二次来时，session生成的是什么？**\n\n**request.cookies不为空**，, 获取cookie的有效时长，如果cookie依然有效，通过与写入时同样的签名算法将cookie中的值解密出来并写入字典并返回中，若cookie已经失效，则仍然返回'空字典'。\n\n**特殊的SecureCookieSession字典有那些功能？如何实现的？**\n\n`permanent`（flask 插件会用到这个变量）、`modified`（表明实例是否被更新过，如果更新过就要重新计算并设置 cookie，因为计算过程比较贵，所以如果对象没有被修改，就直接跳过）\n\n`SecureCookieSession` 是基于 `CallbackDict` 实现的，这个类可以指定一个函数作为 on_update 参数，每次有字典操作的时候（`__setitem__`、`__delitem__`、clear、popitem、update、pop、setdefault）会调用这个函数。\n**session什么时候写入cookie中？session的生命周期？**\n\n`process_response`判断session是否为空，如果不为空，则执行`save_session()`，其中通过`response.set_cookie`将session写入。这样便完成session的写入response工作，并由response返回至客户端。\n\n## 上下文\n\n### **flask上下文种类**\n\ncurrent_app、g 是应用上下文。 request、session 是请求上下文。\n\n### 为什么要用上下文\n\nflask从客户端获取到请求时，要让视图函数能访问一些对象，这样才能处理请求。例如请求对象就是一个很好的例子。要让视图函数访问请求对象，一个显而易见的方法就是将其作为参数传入视图函数，不过这回导致程序中的每个视图函数都增加一个参数，为了避免大量可有可无才参数把视图函数弄得一团糟，flask使用上下文临时把某些对象变为全局可访问（只是当前线程的全局可访问）。\n\n### **请求上下文和应用上下文两者区别**\n\n请求上下文:保存了客户端和服务器交互的数据。request处理http请求，session  处理用户信息。LocalStack用来存储请求上下文\n\n应用上下文:flask 应用程序运行过程中，保存一些配置信息，比如程序名、数据库连接、应用信息等。\n\ng 用来存储开发者自定义的一些数据，不用通过传参的方式获取参数了。current_app 当前激活程序的程序实例。LocalStack用来存储应用上下文。\n\n### **生命周期** \n\n- current_app的生命周期最长，只要当前程序实例还在运行，都不会失效。\n- Request和g的生命周期为一次请求期间，当请求处理完成后，生命周期也就完结了\n- Session就是传统意义上的session了。只要它还未失效（用户未关闭浏览器、没有超过设定的失效时间），那么不同的请求会共用同样的session。\n\n### **为什么上下文需要放在栈中？**\n\n1.应用上下文：\n\nFlask底层是基于werkzeug，werkzeug是可以包含多个app的，所以这时候用一个栈来保存，如果你在使用app1，那么app1应该是要在栈的顶部，如果用完了app1那么app应该从栈中删除，方便其他代码使用下面的app。\n\n2.请求上下文：\n\n如果在写测试代码，或者离线脚本的时候，我们有时候可能需要创建多个请求上下文，这时候就需要存放到一个栈中了。使用哪个请求上下文的时候，就把对应的请求上下文放到栈的顶部，用完了就要把这个请求上下文从栈中移除掉。\n\n### 上下文管理流程?\n\n每次有请求过来的时候，flask 会先创建当前线程或者进程需要处理的两个重要上下文对象，把它们保存到隔离的栈里面，这样视图函数进行处理的时候就能直接从栈上获取这些信息。\n\n1.请求到来时，将session和request封装到ctx对象中；\n\n2.对session作补充；\n\n3.将包含了request和session的ctx对象放到一个容器中（每一个请求都会根据线程/协程加一个惟一标识）；\n\n4.视图函数使用的时候须要根据当前线程或协程的惟一标识，获取ctx对象，再取ctx对象中取request和session（视图函数使用的时候，须要根据当前线程获取数据。）\n\n5.请求结束时，根据当前线程/协程的惟一标记，将这个容器上的数据移除。\n\n###  为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？\n\n虽然在实际运行中，每个请求对应一个 request context 和一个 application context，但是在测试或者 python shell 中运行的时候，用户可以单独创建 request context 或者 application context，这种灵活度方便用户的不同的使用场景\n\n### 为什么Local对象中的stack 维护成一个列表？\n\n测试的时候可以添加多个上下文，另外一个原因是 flask 可以[多个 application 同时运行](http://flask.pocoo.org/docs/0.12/patterns/appdispatch/#combining-applications)\n\n### Flask中多app应用是怎么完成？\n\n请求进来时，可以根据URL的不同，交给不同的APP处理。\n\n使用Flask类建立不一样的app对象，而后借助DispatcherMiddleware类来实现。\n\n### Local对象和threading.local对象的区别\n\nThread Local 则是一种特殊的对象，它的“状态”对线程隔离 —— 也就是说每个线程对一个 Thread Local 对象的修改都不会影响其他线程。原理也非常简单，只要以线程的 ID 来保存多份状态字典即可。\n\nwerkzeug.local.Local和threading.local**区别**如下：\n\n（1）werkzeug使用了自定义的`__storage__`保存不同线程下的状态\n\n（2）werkzeug提供了释放本地线程的release_local方法\n\n（3）werkzeug通过get_ident函数来获得线程标识符\n\n#### **为什么造轮子**\n\nWSGI不保证每个请求必须由一个线程来处理，如果WSGI服务器不是每个线程派发一个请求，而是每个协程派发一个请求，thread local变量可能会造成请求间数据相互干扰，因为一个线程中存在多个请求。\n\n#### 除 了Local \n\nWerkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。\n\nLocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。\n\nLocalProxy用于代理Local对象和LocalStack对象，而所谓代理就是作为中间的代理人来处理所有针对被代理对象的操作。LocalStack无法再动态更新了，而使用Proxy实现了动态更新。重载了绝大多数操作符，以便在调用LocalProxy的相应操作时，通过`_get_current_object` method来获取真正代理的对象，然后再进行相应操作\n\n## 蓝图\n\n### 作用\n\n- 将不同的功能模块化，构建大型应用\n\n- 优化项目结构\n\n- 增强可读性,易于维护\n\n###  使用\n\n- 新增了一个xxx.py的文件，实例化Blueprint应用\n- xxx.py编写视图函数，使用Blueprint应用示例设置路由\n- run.py中，注册蓝图示例\n\n## 如何在Flask中访问会话?\n\n用户第一次请求后，将产生的状态信息保存在session中，这时可以把session当做一个容器，它保存了正在使用的所有用户的状态信息；这段状态信息分配了一个唯一的标识符用来标识用户的身份，将其保存在响应对象的cookie中；当第二次请求时，解析cookie中的标识符，拿到标识符后去session找到对应的用户的信息。\n\n在flask中，如果我们想要获取session信息，直接通过flask的session获取就可以了，这是因为session是一个代理对象，代理当前请求上下文的session属性。\n\n## wsgi\n\nWeb服务器和Web应用程序或框架之间的一种简单而通用的接口。描述了web server如何与web application交互、web application如何处理请求。\n\n**应用程序端**\n\nWSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了`__call__` 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。\n\n## Werkzeug\n\nHTTP 和 WSGI 相关的工具集，可以用来编写 web 框架，可以直接使用它提供的一些帮助函数。\n\nwerkzeug 提供了 python web WSGI 开发相关的功能：\n\n- 路由处理：如何根据请求 URL 找到对应的视图函数\n\n- request 和 response 封装: 提供更好的方式处理request和生成response对象\n\n- 自带的 WSGI server: 测试环境运行WSGI应用\n\n## RESTful\n\nREST的名称\"表现层状态转化\"中，省略了主语。\"表现层\"其实指的是\"资源\"（Resources）的\"表现层\"。\n\n（1）每一个URI代表一种资源；\n\n（2）客户端和服务器之间，传递这种资源的某种表现层；\n\n（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现\"表现层状态转化\"。\n\n\"资源\"是一种信息实体，它可以有多种外在表现形式。**我们把\"资源\"具体呈现出来的形式，叫做它的\"表现层\"（Representation）。**\n\n所有的状态都保存在服务器端。因此，**如果客户端想要操作服务器，必须通过某种手段，让服务器端发生\"状态转化\"（State Transfer）。而这种转化是建立在表现层之上的，所以就是\"表现层状态转化\"。**\n\n## 参考资料\n\nhttps://juejin.im/post/6844903533238566925#heading-10\n\nhttp://www.pythondoc.com/flask/appcontext.html\n\nhttp://www.pythondoc.com/flask/reqcontext.html\n\nhttps://cizixs.com/2017/01/12/flask-insight-routing/\n\nhttps://www.cnblogs.com/kendrick/p/7649772.html\n\nhttps://www.cnblogs.com/panlq/p/13266426.html","slug":"flask面试","published":1,"updated":"2021-05-11T23:26:31.387Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6kr0005q4uf5sxz3zf9","content":"<h1 id=\"Flask框架\"><a href=\"#Flask框架\" class=\"headerlink\" title=\"Flask框架\"></a>Flask框架</h1><h2 id=\"WEB框架\"><a href=\"#WEB框架\" class=\"headerlink\" title=\"WEB框架\"></a>WEB框架</h2><p>它们接收 HTTP 请求，然后分发任务，并生成 HTML，然后返回包含 HTML 的 HTTP 应答。</p>\n<h2 id=\"应用启动过程\"><a href=\"#应用启动过程\" class=\"headerlink\" title=\"应用启动过程\"></a>应用启动过程</h2><ul>\n<li><p><code>run</code> 方法启动了 Flask 应用</p>\n</li>\n<li><p><code>run</code> 方法调用werkzeug 的 <code>run_simple</code> 方法，启动了服务器 <code>BaseWSGIServer</code>。在调用 run_simple 时，Flask 对象把自己 <code>self</code> 作为参数传进去了，在收到请求的时候，就知道调用谁的 <code>__call__</code> 方法。</p>\n</li>\n</ul>\n<h2 id=\"请求处理过程\"><a href=\"#请求处理过程\" class=\"headerlink\" title=\"请求处理过程\"></a>请求处理过程</h2><ul>\n<li><p>默认使用 <code>WSGIRequestHandler</code>类来作为 request handler，在接收到请求时这个类在被 <code>BaseWSGIServer</code> 调用时，会执行<code>execute</code>函数</p>\n</li>\n<li><p><code>execute</code>函数中，把 <code>environ</code> 和 <code>start_response</code> 传入，调用 <code>app</code>的<code>__call__</code> 。</p>\n</li>\n<li><p><code>app</code>的<code>__call__</code>中，调用了 <code>wsgi_app</code>方法（为了中间件）。</p>\n</li>\n</ul>\n<blockquote>\n<p>该方法最终返回的<code>response(environ, start_response)</code>中的response 是<code>werkzueg.response</code> 类的一个实例，是可调用的对象，负责生成最终的可遍历的响应体，并调用 <code>start_response</code> 形成响应头</p>\n</blockquote>\n<ul>\n<li><p><code>wsgi_app</code>方法中 调用 <code>request_context(environ)</code>函数建立了一个 <code>RequestContext</code> <strong>请求上下文对象</strong></p>\n<ul>\n<li><code>RequestContext</code>初始化根据传入的 <code>environ</code> 创建一个 <code>werkzeug.Request</code> 的实例</li>\n</ul>\n</li>\n<li><p>把请求上下文 <code>RequestContext</code>，调用<code>push</code>，压入<code>_request_ctx_stack</code> 栈。（这些操作是为了 flask 在处理多个请求的时候不会混淆）。</p>\n<ul>\n<li><code>_request_ctx_stack</code> 是一个 <code>LocalStack</code> 类的实例，通过<strong>Local实现线程隔离</strong>，隔离是使用了<code>get_ident</code>,属性被保存到每个线程id对应的字典中了。</li>\n</ul>\n</li>\n<li><p><code>wsgi_app</code>方法中 调用  <code>full_dispatch_request</code>方法<strong>请求分发</strong>，开始实际的请求处理过程，这个过程中会生成 <code>response</code>对象来返回给服务器。</p>\n<ul>\n<li><p>调用 <code>try_trigger_before_first_request_functions</code> 方法尝试调用 <code>before_first_request</code> 列表中的函数，只会执行一次</p>\n</li>\n<li><p>调用 <code>preprocess_request</code> 方法，调用 <code>before_request_funcs</code> 列表中所有的方法。（可以检测用户是否登录，未登录使用<code>abort</code>返回错误，则后续不会分发）</p>\n</li>\n<li><p>调用 <code>dispatch_request</code> 方法进行业务请求分发。</p>\n<ul>\n<li><code>_request_ctx_stack.top.request</code>获取请求上下文</li>\n<li>获取请求上下文在的<code>rule</code></li>\n<li>调用 <code>view_functions</code> 中相应的<strong>视图函数</strong>（<code>rule.endpoint</code> 作为键值）并把参数值传入（<code>**req.view_args</code>），视图函数就是开发人员写的API接口了。视图函数的返回值或者错误处理视图函数的返回值会作为<code>rv</code>返回给<code>full_dispatch_request</code>。</li>\n</ul>\n<ul>\n<li>调用<code>finalize_request</code>根据 <code>rv</code> 生成响应<ul>\n<li>调用<code>make_response</code> 方法会查看 rv 是否是要求的返回值类型，否则生成正确的返回类型。</li>\n<li>调用<code>process_response</code> 方法，实现<code>after_request</code>方法的调用</li>\n<li>返回<code>response</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>如果当中出错，就生成相应的错误信息。</p>\n</li>\n<li><p>把<strong>请求上下文</strong>出栈。</p>\n</li>\n</ul>\n<h2 id=\"视图函数注册\"><a href=\"#视图函数注册\" class=\"headerlink\" title=\"视图函数注册\"></a>视图函数注册</h2><p>在程序加载业务代码时，用修饰器 <code>route</code>注册视图函数，并实现 URL 到视图函数的映射。在<code>route</code> 方法中，调用了<code>add_url_rule</code>方法。主要流程如下：</p>\n<ul>\n<li>准备好一个视图函数所支持的 HTTP 方法</li>\n<li>通过 <code>url_rule_class</code> 创建一个 <code>rule</code> 对象，并把这个对象添加到自己的 <code>url_map</code></li>\n</ul>\n<blockquote>\n<p><code>rule</code> 对象是一个保存合法的（Flask 应用所支持的） URL、方法、<code>endpoint</code>（在 <code>**options</code> 中） 及它们的对应关系的数据结构</p>\n<p> <code>url_map</code> 是保存<code>rule</code> 对象的集合</p>\n</blockquote>\n<ul>\n<li><code>view_functions</code>中加入<code>endpoint</code>、视图函数的映射关系</li>\n</ul>\n<p>在 Flask 应用收到请求时，这些被绑定到 url_map 上的 Rule 会被查看，来找到它们对应的视图函数。在 <code>dispatch_request</code> 方法中，从 <code>_request_ctx_stack.top.request</code> 得到 <code>rule</code> 并从这个 <code>rule</code> 找到 <code>endpoint</code>，最终找到用来处理该请求的正确的视图函数的。</p>\n<h2 id=\"请求的过程总结\"><a href=\"#请求的过程总结\" class=\"headerlink\" title=\"请求的过程总结\"></a>请求的过程总结</h2><ul>\n<li><p>在请求发出之前，Flask 注册好了所有的视图函数和 URL映射，服务器在自己身上注册了 Flask 应用。</p>\n</li>\n<li><p>请求到达服务器，服务器准备好 environ 和 make_response 函数，然后调用了自己身上注册的 Flask 应用。</p>\n</li>\n<li><p>通过 <code>__call__</code>中转到 wsgi_app 的方法。它首先通过 environ 创建了请求上下文，并将它推入栈，使得 flask 在处理当前请求的过程中都可以访问到这个请求上下文。</p>\n</li>\n<li><p><code>full_dispatch_request</code>中开始处理这个请求，依次调用 <code>before_first_request_funcs</code> <code>before_request_funcs view_functions</code>中的函数，并最终通过 <code>finalize_request</code> 生成一个 <code>response</code>对象，调用<code>after_request_funcs</code>进行 response 生成后的后处理。</p>\n</li>\n<li><p>Flask 调用这个 response 对象，最终调用了 make_response 函数，并返回了一个可遍历的响应内容。</p>\n</li>\n<li><p>服务器发送响应。</p>\n</li>\n</ul>\n<h2 id=\"Flask-和-werkzeug关系\"><a href=\"#Flask-和-werkzeug关系\" class=\"headerlink\" title=\"Flask 和 werkzeug关系\"></a>Flask 和 werkzeug关系</h2><p>Flask 和 werkzeug 是强耦合的，一些非常细节的工作，其实都是 werkzeug 库完成的：</p>\n<ul>\n<li><p>封装 Response 和 Request 类型供 Flask 使用，在实际开发中，我们在请求和响应对象上的操作，调用的其实是 werkzeug 的方法。</p>\n</li>\n<li><p>实现 URL到视图函数的映射，并且能把 URL中的参数传给该视图函数。我们看到了 Flask 的 url_map 属性并且看到了它如何绑定视图函数和错误处理函数，但是具体的映射规则的实现，和在响应过程中的 URL解析，都是由 werkzeug 完成的。</p>\n</li>\n<li><p>通过 _request_ctx_stack 对 Flask 实现线程保护。</p>\n</li>\n</ul>\n<h2 id=\"默认session处理机制\"><a href=\"#默认session处理机制\" class=\"headerlink\" title=\"默认session处理机制?\"></a>默认session处理机制?</h2><p>flask的session是基于cookie的会话保持。<strong>简单的原理</strong>即：</p>\n<p>当客户端进行第一次请求时，客户端的HTTP request（cookie为空）到服务端，服务端创建session，视图函数中填写session，请求结束时，session内容填写入response的cookie中并返回给客户端，客户端的cookie中便保存了用户的数据。</p>\n<p>当同一客户端再次请求时， 客户端的HTTP request中cookie已经携带数据，视图函数根据cookie中值做相应操作（如已经携带用户名和密码就可以直接登陆）。</p>\n<p><strong>请求第一次来时，session是什么时候生成的？存放在哪里？</strong></p>\n<ul>\n<li><p>客户端的请求进来时，会生成RequestContext对象。其中定义了session，且初值为None。</p>\n</li>\n<li><p>在ctx.push()函数中，所有和 session 有关的调用，都转发到 <code>session_interface</code> 的方法调用上，而默认的 <code>session_inerface</code>为<code>SecureCookieSessionInterface()</code></p>\n<ul>\n<li>执行<code>SecureCookieSessionInterface.open_session()</code>来生成默认session对象<ul>\n<li>获取session签名的算法</li>\n<li>获取<em>request.cookies</em>，请求第一次来时，<strong>request.cookies为空</strong>，即返回<code>SecureCookieSession</code>,session就是一个特殊的字典</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>当请求第二次来时，session生成的是什么？</strong></p>\n<p><strong>request.cookies不为空</strong>，, 获取cookie的有效时长，如果cookie依然有效，通过与写入时同样的签名算法将cookie中的值解密出来并写入字典并返回中，若cookie已经失效，则仍然返回’空字典’。</p>\n<p><strong>特殊的SecureCookieSession字典有那些功能？如何实现的？</strong></p>\n<p><code>permanent</code>（flask 插件会用到这个变量）、<code>modified</code>（表明实例是否被更新过，如果更新过就要重新计算并设置 cookie，因为计算过程比较贵，所以如果对象没有被修改，就直接跳过）</p>\n<p><code>SecureCookieSession</code> 是基于 <code>CallbackDict</code> 实现的，这个类可以指定一个函数作为 on_update 参数，每次有字典操作的时候（<code>__setitem__</code>、<code>__delitem__</code>、clear、popitem、update、pop、setdefault）会调用这个函数。<br><strong>session什么时候写入cookie中？session的生命周期？</strong></p>\n<p><code>process_response</code>判断session是否为空，如果不为空，则执行<code>save_session()</code>，其中通过<code>response.set_cookie</code>将session写入。这样便完成session的写入response工作，并由response返回至客户端。</p>\n<h2 id=\"上下文\"><a href=\"#上下文\" class=\"headerlink\" title=\"上下文\"></a>上下文</h2><h3 id=\"flask上下文种类\"><a href=\"#flask上下文种类\" class=\"headerlink\" title=\"flask上下文种类\"></a><strong>flask上下文种类</strong></h3><p>current_app、g 是应用上下文。 request、session 是请求上下文。</p>\n<h3 id=\"为什么要用上下文\"><a href=\"#为什么要用上下文\" class=\"headerlink\" title=\"为什么要用上下文\"></a>为什么要用上下文</h3><p>flask从客户端获取到请求时，要让视图函数能访问一些对象，这样才能处理请求。例如请求对象就是一个很好的例子。要让视图函数访问请求对象，一个显而易见的方法就是将其作为参数传入视图函数，不过这回导致程序中的每个视图函数都增加一个参数，为了避免大量可有可无才参数把视图函数弄得一团糟，flask使用上下文临时把某些对象变为全局可访问（只是当前线程的全局可访问）。</p>\n<h3 id=\"请求上下文和应用上下文两者区别\"><a href=\"#请求上下文和应用上下文两者区别\" class=\"headerlink\" title=\"请求上下文和应用上下文两者区别\"></a><strong>请求上下文和应用上下文两者区别</strong></h3><p>请求上下文:保存了客户端和服务器交互的数据。request处理http请求，session  处理用户信息。LocalStack用来存储请求上下文</p>\n<p>应用上下文:flask 应用程序运行过程中，保存一些配置信息，比如程序名、数据库连接、应用信息等。</p>\n<p>g 用来存储开发者自定义的一些数据，不用通过传参的方式获取参数了。current_app 当前激活程序的程序实例。LocalStack用来存储应用上下文。</p>\n<h3 id=\"生命周期\"><a href=\"#生命周期\" class=\"headerlink\" title=\"生命周期\"></a><strong>生命周期</strong></h3><ul>\n<li>current_app的生命周期最长，只要当前程序实例还在运行，都不会失效。</li>\n<li>Request和g的生命周期为一次请求期间，当请求处理完成后，生命周期也就完结了</li>\n<li>Session就是传统意义上的session了。只要它还未失效（用户未关闭浏览器、没有超过设定的失效时间），那么不同的请求会共用同样的session。</li>\n</ul>\n<h3 id=\"为什么上下文需要放在栈中？\"><a href=\"#为什么上下文需要放在栈中？\" class=\"headerlink\" title=\"为什么上下文需要放在栈中？\"></a><strong>为什么上下文需要放在栈中？</strong></h3><p>1.应用上下文：</p>\n<p>Flask底层是基于werkzeug，werkzeug是可以包含多个app的，所以这时候用一个栈来保存，如果你在使用app1，那么app1应该是要在栈的顶部，如果用完了app1那么app应该从栈中删除，方便其他代码使用下面的app。</p>\n<p>2.请求上下文：</p>\n<p>如果在写测试代码，或者离线脚本的时候，我们有时候可能需要创建多个请求上下文，这时候就需要存放到一个栈中了。使用哪个请求上下文的时候，就把对应的请求上下文放到栈的顶部，用完了就要把这个请求上下文从栈中移除掉。</p>\n<h3 id=\"上下文管理流程\"><a href=\"#上下文管理流程\" class=\"headerlink\" title=\"上下文管理流程?\"></a>上下文管理流程?</h3><p>每次有请求过来的时候，flask 会先创建当前线程或者进程需要处理的两个重要上下文对象，把它们保存到隔离的栈里面，这样视图函数进行处理的时候就能直接从栈上获取这些信息。</p>\n<p>1.请求到来时，将session和request封装到ctx对象中；</p>\n<p>2.对session作补充；</p>\n<p>3.将包含了request和session的ctx对象放到一个容器中（每一个请求都会根据线程/协程加一个惟一标识）；</p>\n<p>4.视图函数使用的时候须要根据当前线程或协程的惟一标识，获取ctx对象，再取ctx对象中取request和session（视图函数使用的时候，须要根据当前线程获取数据。）</p>\n<p>5.请求结束时，根据当前线程/协程的惟一标记，将这个容器上的数据移除。</p>\n<h3 id=\"为什么要把-request-context-和-application-context-分开？每个请求不是都同时拥有这两个上下文信息吗？\"><a href=\"#为什么要把-request-context-和-application-context-分开？每个请求不是都同时拥有这两个上下文信息吗？\" class=\"headerlink\" title=\"为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？\"></a>为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？</h3><p>虽然在实际运行中，每个请求对应一个 request context 和一个 application context，但是在测试或者 python shell 中运行的时候，用户可以单独创建 request context 或者 application context，这种灵活度方便用户的不同的使用场景</p>\n<h3 id=\"为什么Local对象中的stack-维护成一个列表？\"><a href=\"#为什么Local对象中的stack-维护成一个列表？\" class=\"headerlink\" title=\"为什么Local对象中的stack 维护成一个列表？\"></a>为什么Local对象中的stack 维护成一个列表？</h3><p>测试的时候可以添加多个上下文，另外一个原因是 flask 可以<a href=\"http://flask.pocoo.org/docs/0.12/patterns/appdispatch/#combining-applications\" target=\"_blank\" rel=\"noopener\">多个 application 同时运行</a></p>\n<h3 id=\"Flask中多app应用是怎么完成？\"><a href=\"#Flask中多app应用是怎么完成？\" class=\"headerlink\" title=\"Flask中多app应用是怎么完成？\"></a>Flask中多app应用是怎么完成？</h3><p>请求进来时，可以根据URL的不同，交给不同的APP处理。</p>\n<p>使用Flask类建立不一样的app对象，而后借助DispatcherMiddleware类来实现。</p>\n<h3 id=\"Local对象和threading-local对象的区别\"><a href=\"#Local对象和threading-local对象的区别\" class=\"headerlink\" title=\"Local对象和threading.local对象的区别\"></a>Local对象和threading.local对象的区别</h3><p>Thread Local 则是一种特殊的对象，它的“状态”对线程隔离 —— 也就是说每个线程对一个 Thread Local 对象的修改都不会影响其他线程。原理也非常简单，只要以线程的 ID 来保存多份状态字典即可。</p>\n<p>werkzeug.local.Local和threading.local<strong>区别</strong>如下：</p>\n<p>（1）werkzeug使用了自定义的<code>__storage__</code>保存不同线程下的状态</p>\n<p>（2）werkzeug提供了释放本地线程的release_local方法</p>\n<p>（3）werkzeug通过get_ident函数来获得线程标识符</p>\n<h4 id=\"为什么造轮子\"><a href=\"#为什么造轮子\" class=\"headerlink\" title=\"为什么造轮子\"></a><strong>为什么造轮子</strong></h4><p>WSGI不保证每个请求必须由一个线程来处理，如果WSGI服务器不是每个线程派发一个请求，而是每个协程派发一个请求，thread local变量可能会造成请求间数据相互干扰，因为一个线程中存在多个请求。</p>\n<h4 id=\"除-了Local\"><a href=\"#除-了Local\" class=\"headerlink\" title=\"除 了Local\"></a>除 了Local</h4><p>Werkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。</p>\n<p>LocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。</p>\n<p>LocalProxy用于代理Local对象和LocalStack对象，而所谓代理就是作为中间的代理人来处理所有针对被代理对象的操作。LocalStack无法再动态更新了，而使用Proxy实现了动态更新。重载了绝大多数操作符，以便在调用LocalProxy的相应操作时，通过<code>_get_current_object</code> method来获取真正代理的对象，然后再进行相应操作</p>\n<h2 id=\"蓝图\"><a href=\"#蓝图\" class=\"headerlink\" title=\"蓝图\"></a>蓝图</h2><h3 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h3><ul>\n<li><p>将不同的功能模块化，构建大型应用</p>\n</li>\n<li><p>优化项目结构</p>\n</li>\n<li><p>增强可读性,易于维护</p>\n</li>\n</ul>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><ul>\n<li>新增了一个xxx.py的文件，实例化Blueprint应用</li>\n<li>xxx.py编写视图函数，使用Blueprint应用示例设置路由</li>\n<li>run.py中，注册蓝图示例</li>\n</ul>\n<h2 id=\"如何在Flask中访问会话\"><a href=\"#如何在Flask中访问会话\" class=\"headerlink\" title=\"如何在Flask中访问会话?\"></a>如何在Flask中访问会话?</h2><p>用户第一次请求后，将产生的状态信息保存在session中，这时可以把session当做一个容器，它保存了正在使用的所有用户的状态信息；这段状态信息分配了一个唯一的标识符用来标识用户的身份，将其保存在响应对象的cookie中；当第二次请求时，解析cookie中的标识符，拿到标识符后去session找到对应的用户的信息。</p>\n<p>在flask中，如果我们想要获取session信息，直接通过flask的session获取就可以了，这是因为session是一个代理对象，代理当前请求上下文的session属性。</p>\n<h2 id=\"wsgi\"><a href=\"#wsgi\" class=\"headerlink\" title=\"wsgi\"></a>wsgi</h2><p>Web服务器和Web应用程序或框架之间的一种简单而通用的接口。描述了web server如何与web application交互、web application如何处理请求。</p>\n<p><strong>应用程序端</strong></p>\n<p>WSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了<code>__call__</code> 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。</p>\n<h2 id=\"Werkzeug\"><a href=\"#Werkzeug\" class=\"headerlink\" title=\"Werkzeug\"></a>Werkzeug</h2><p>HTTP 和 WSGI 相关的工具集，可以用来编写 web 框架，可以直接使用它提供的一些帮助函数。</p>\n<p>werkzeug 提供了 python web WSGI 开发相关的功能：</p>\n<ul>\n<li><p>路由处理：如何根据请求 URL 找到对应的视图函数</p>\n</li>\n<li><p>request 和 response 封装: 提供更好的方式处理request和生成response对象</p>\n</li>\n<li><p>自带的 WSGI server: 测试环境运行WSGI应用</p>\n</li>\n</ul>\n<h2 id=\"RESTful\"><a href=\"#RESTful\" class=\"headerlink\" title=\"RESTful\"></a>RESTful</h2><p>REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。</p>\n<p>（1）每一个URI代表一种资源；</p>\n<p>（2）客户端和服务器之间，传递这种资源的某种表现层；</p>\n<p>（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。</p>\n<p>“资源”是一种信息实体，它可以有多种外在表现形式。<strong>我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。</strong></p>\n<p>所有的状态都保存在服务器端。因此，<strong>如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。</strong></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://juejin.im/post/6844903533238566925#heading-10\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/6844903533238566925#heading-10</a></p>\n<p><a href=\"http://www.pythondoc.com/flask/appcontext.html\" target=\"_blank\" rel=\"noopener\">http://www.pythondoc.com/flask/appcontext.html</a></p>\n<p><a href=\"http://www.pythondoc.com/flask/reqcontext.html\" target=\"_blank\" rel=\"noopener\">http://www.pythondoc.com/flask/reqcontext.html</a></p>\n<p><a href=\"https://cizixs.com/2017/01/12/flask-insight-routing/\" target=\"_blank\" rel=\"noopener\">https://cizixs.com/2017/01/12/flask-insight-routing/</a></p>\n<p><a href=\"https://www.cnblogs.com/kendrick/p/7649772.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/kendrick/p/7649772.html</a></p>\n<p><a href=\"https://www.cnblogs.com/panlq/p/13266426.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/panlq/p/13266426.html</a></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h1 id=\"Flask框架\"><a href=\"#Flask框架\" class=\"headerlink\" title=\"Flask框架\"></a>Flask框架</h1><h2 id=\"WEB框架\"><a href=\"#WEB框架\" class=\"headerlink\" title=\"WEB框架\"></a>WEB框架</h2><p>它们接收 HTTP 请求，然后分发任务，并生成 HTML，然后返回包含 HTML 的 HTTP 应答。</p>\n<h2 id=\"应用启动过程\"><a href=\"#应用启动过程\" class=\"headerlink\" title=\"应用启动过程\"></a>应用启动过程</h2><ul>\n<li><p><code>run</code> 方法启动了 Flask 应用</p>\n</li>\n<li><p><code>run</code> 方法调用werkzeug 的 <code>run_simple</code> 方法，启动了服务器 <code>BaseWSGIServer</code>。在调用 run_simple 时，Flask 对象把自己 <code>self</code> 作为参数传进去了，在收到请求的时候，就知道调用谁的 <code>__call__</code> 方法。</p>\n</li>\n</ul>\n<h2 id=\"请求处理过程\"><a href=\"#请求处理过程\" class=\"headerlink\" title=\"请求处理过程\"></a>请求处理过程</h2><ul>\n<li><p>默认使用 <code>WSGIRequestHandler</code>类来作为 request handler，在接收到请求时这个类在被 <code>BaseWSGIServer</code> 调用时，会执行<code>execute</code>函数</p>\n</li>\n<li><p><code>execute</code>函数中，把 <code>environ</code> 和 <code>start_response</code> 传入，调用 <code>app</code>的<code>__call__</code> 。</p>\n</li>\n<li><p><code>app</code>的<code>__call__</code>中，调用了 <code>wsgi_app</code>方法（为了中间件）。</p>\n</li>\n</ul>\n<blockquote>\n<p>该方法最终返回的<code>response(environ, start_response)</code>中的response 是<code>werkzueg.response</code> 类的一个实例，是可调用的对象，负责生成最终的可遍历的响应体，并调用 <code>start_response</code> 形成响应头</p>\n</blockquote>\n<ul>\n<li><p><code>wsgi_app</code>方法中 调用 <code>request_context(environ)</code>函数建立了一个 <code>RequestContext</code> <strong>请求上下文对象</strong></p>\n<ul>\n<li><code>RequestContext</code>初始化根据传入的 <code>environ</code> 创建一个 <code>werkzeug.Request</code> 的实例</li>\n</ul>\n</li>\n<li><p>把请求上下文 <code>RequestContext</code>，调用<code>push</code>，压入<code>_request_ctx_stack</code> 栈。（这些操作是为了 flask 在处理多个请求的时候不会混淆）。</p>\n<ul>\n<li><code>_request_ctx_stack</code> 是一个 <code>LocalStack</code> 类的实例，通过<strong>Local实现线程隔离</strong>，隔离是使用了<code>get_ident</code>,属性被保存到每个线程id对应的字典中了。</li>\n</ul>\n</li>\n<li><p><code>wsgi_app</code>方法中 调用  <code>full_dispatch_request</code>方法<strong>请求分发</strong>，开始实际的请求处理过程，这个过程中会生成 <code>response</code>对象来返回给服务器。</p>\n<ul>\n<li><p>调用 <code>try_trigger_before_first_request_functions</code> 方法尝试调用 <code>before_first_request</code> 列表中的函数，只会执行一次</p>\n</li>\n<li><p>调用 <code>preprocess_request</code> 方法，调用 <code>before_request_funcs</code> 列表中所有的方法。（可以检测用户是否登录，未登录使用<code>abort</code>返回错误，则后续不会分发）</p>\n</li>\n<li><p>调用 <code>dispatch_request</code> 方法进行业务请求分发。</p>\n<ul>\n<li><code>_request_ctx_stack.top.request</code>获取请求上下文</li>\n<li>获取请求上下文在的<code>rule</code></li>\n<li>调用 <code>view_functions</code> 中相应的<strong>视图函数</strong>（<code>rule.endpoint</code> 作为键值）并把参数值传入（<code>**req.view_args</code>），视图函数就是开发人员写的API接口了。视图函数的返回值或者错误处理视图函数的返回值会作为<code>rv</code>返回给<code>full_dispatch_request</code>。</li>\n</ul>\n<ul>\n<li>调用<code>finalize_request</code>根据 <code>rv</code> 生成响应<ul>\n<li>调用<code>make_response</code> 方法会查看 rv 是否是要求的返回值类型，否则生成正确的返回类型。</li>\n<li>调用<code>process_response</code> 方法，实现<code>after_request</code>方法的调用</li>\n<li>返回<code>response</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>如果当中出错，就生成相应的错误信息。</p>\n</li>\n<li><p>把<strong>请求上下文</strong>出栈。</p>\n</li>\n</ul>\n<h2 id=\"视图函数注册\"><a href=\"#视图函数注册\" class=\"headerlink\" title=\"视图函数注册\"></a>视图函数注册</h2><p>在程序加载业务代码时，用修饰器 <code>route</code>注册视图函数，并实现 URL 到视图函数的映射。在<code>route</code> 方法中，调用了<code>add_url_rule</code>方法。主要流程如下：</p>\n<ul>\n<li>准备好一个视图函数所支持的 HTTP 方法</li>\n<li>通过 <code>url_rule_class</code> 创建一个 <code>rule</code> 对象，并把这个对象添加到自己的 <code>url_map</code></li>\n</ul>\n<blockquote>\n<p><code>rule</code> 对象是一个保存合法的（Flask 应用所支持的） URL、方法、<code>endpoint</code>（在 <code>**options</code> 中） 及它们的对应关系的数据结构</p>\n<p> <code>url_map</code> 是保存<code>rule</code> 对象的集合</p>\n</blockquote>\n<ul>\n<li><code>view_functions</code>中加入<code>endpoint</code>、视图函数的映射关系</li>\n</ul>\n<p>在 Flask 应用收到请求时，这些被绑定到 url_map 上的 Rule 会被查看，来找到它们对应的视图函数。在 <code>dispatch_request</code> 方法中，从 <code>_request_ctx_stack.top.request</code> 得到 <code>rule</code> 并从这个 <code>rule</code> 找到 <code>endpoint</code>，最终找到用来处理该请求的正确的视图函数的。</p>\n<h2 id=\"请求的过程总结\"><a href=\"#请求的过程总结\" class=\"headerlink\" title=\"请求的过程总结\"></a>请求的过程总结</h2><ul>\n<li><p>在请求发出之前，Flask 注册好了所有的视图函数和 URL映射，服务器在自己身上注册了 Flask 应用。</p>\n</li>\n<li><p>请求到达服务器，服务器准备好 environ 和 make_response 函数，然后调用了自己身上注册的 Flask 应用。</p>\n</li>\n<li><p>通过 <code>__call__</code>中转到 wsgi_app 的方法。它首先通过 environ 创建了请求上下文，并将它推入栈，使得 flask 在处理当前请求的过程中都可以访问到这个请求上下文。</p>\n</li>\n<li><p><code>full_dispatch_request</code>中开始处理这个请求，依次调用 <code>before_first_request_funcs</code> <code>before_request_funcs view_functions</code>中的函数，并最终通过 <code>finalize_request</code> 生成一个 <code>response</code>对象，调用<code>after_request_funcs</code>进行 response 生成后的后处理。</p>\n</li>\n<li><p>Flask 调用这个 response 对象，最终调用了 make_response 函数，并返回了一个可遍历的响应内容。</p>\n</li>\n<li><p>服务器发送响应。</p>\n</li>\n</ul>\n<h2 id=\"Flask-和-werkzeug关系\"><a href=\"#Flask-和-werkzeug关系\" class=\"headerlink\" title=\"Flask 和 werkzeug关系\"></a>Flask 和 werkzeug关系</h2><p>Flask 和 werkzeug 是强耦合的，一些非常细节的工作，其实都是 werkzeug 库完成的：</p>\n<ul>\n<li><p>封装 Response 和 Request 类型供 Flask 使用，在实际开发中，我们在请求和响应对象上的操作，调用的其实是 werkzeug 的方法。</p>\n</li>\n<li><p>实现 URL到视图函数的映射，并且能把 URL中的参数传给该视图函数。我们看到了 Flask 的 url_map 属性并且看到了它如何绑定视图函数和错误处理函数，但是具体的映射规则的实现，和在响应过程中的 URL解析，都是由 werkzeug 完成的。</p>\n</li>\n<li><p>通过 _request_ctx_stack 对 Flask 实现线程保护。</p>\n</li>\n</ul>\n<h2 id=\"默认session处理机制\"><a href=\"#默认session处理机制\" class=\"headerlink\" title=\"默认session处理机制?\"></a>默认session处理机制?</h2><p>flask的session是基于cookie的会话保持。<strong>简单的原理</strong>即：</p>\n<p>当客户端进行第一次请求时，客户端的HTTP request（cookie为空）到服务端，服务端创建session，视图函数中填写session，请求结束时，session内容填写入response的cookie中并返回给客户端，客户端的cookie中便保存了用户的数据。</p>\n<p>当同一客户端再次请求时， 客户端的HTTP request中cookie已经携带数据，视图函数根据cookie中值做相应操作（如已经携带用户名和密码就可以直接登陆）。</p>\n<p><strong>请求第一次来时，session是什么时候生成的？存放在哪里？</strong></p>\n<ul>\n<li><p>客户端的请求进来时，会生成RequestContext对象。其中定义了session，且初值为None。</p>\n</li>\n<li><p>在ctx.push()函数中，所有和 session 有关的调用，都转发到 <code>session_interface</code> 的方法调用上，而默认的 <code>session_inerface</code>为<code>SecureCookieSessionInterface()</code></p>\n<ul>\n<li>执行<code>SecureCookieSessionInterface.open_session()</code>来生成默认session对象<ul>\n<li>获取session签名的算法</li>\n<li>获取<em>request.cookies</em>，请求第一次来时，<strong>request.cookies为空</strong>，即返回<code>SecureCookieSession</code>,session就是一个特殊的字典</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>当请求第二次来时，session生成的是什么？</strong></p>\n<p><strong>request.cookies不为空</strong>，, 获取cookie的有效时长，如果cookie依然有效，通过与写入时同样的签名算法将cookie中的值解密出来并写入字典并返回中，若cookie已经失效，则仍然返回’空字典’。</p>\n<p><strong>特殊的SecureCookieSession字典有那些功能？如何实现的？</strong></p>\n<p><code>permanent</code>（flask 插件会用到这个变量）、<code>modified</code>（表明实例是否被更新过，如果更新过就要重新计算并设置 cookie，因为计算过程比较贵，所以如果对象没有被修改，就直接跳过）</p>\n<p><code>SecureCookieSession</code> 是基于 <code>CallbackDict</code> 实现的，这个类可以指定一个函数作为 on_update 参数，每次有字典操作的时候（<code>__setitem__</code>、<code>__delitem__</code>、clear、popitem、update、pop、setdefault）会调用这个函数。<br><strong>session什么时候写入cookie中？session的生命周期？</strong></p>\n<p><code>process_response</code>判断session是否为空，如果不为空，则执行<code>save_session()</code>，其中通过<code>response.set_cookie</code>将session写入。这样便完成session的写入response工作，并由response返回至客户端。</p>\n<h2 id=\"上下文\"><a href=\"#上下文\" class=\"headerlink\" title=\"上下文\"></a>上下文</h2><h3 id=\"flask上下文种类\"><a href=\"#flask上下文种类\" class=\"headerlink\" title=\"flask上下文种类\"></a><strong>flask上下文种类</strong></h3><p>current_app、g 是应用上下文。 request、session 是请求上下文。</p>\n<h3 id=\"为什么要用上下文\"><a href=\"#为什么要用上下文\" class=\"headerlink\" title=\"为什么要用上下文\"></a>为什么要用上下文</h3><p>flask从客户端获取到请求时，要让视图函数能访问一些对象，这样才能处理请求。例如请求对象就是一个很好的例子。要让视图函数访问请求对象，一个显而易见的方法就是将其作为参数传入视图函数，不过这回导致程序中的每个视图函数都增加一个参数，为了避免大量可有可无才参数把视图函数弄得一团糟，flask使用上下文临时把某些对象变为全局可访问（只是当前线程的全局可访问）。</p>\n<h3 id=\"请求上下文和应用上下文两者区别\"><a href=\"#请求上下文和应用上下文两者区别\" class=\"headerlink\" title=\"请求上下文和应用上下文两者区别\"></a><strong>请求上下文和应用上下文两者区别</strong></h3><p>请求上下文:保存了客户端和服务器交互的数据。request处理http请求，session  处理用户信息。LocalStack用来存储请求上下文</p>\n<p>应用上下文:flask 应用程序运行过程中，保存一些配置信息，比如程序名、数据库连接、应用信息等。</p>\n<p>g 用来存储开发者自定义的一些数据，不用通过传参的方式获取参数了。current_app 当前激活程序的程序实例。LocalStack用来存储应用上下文。</p>\n<h3 id=\"生命周期\"><a href=\"#生命周期\" class=\"headerlink\" title=\"生命周期\"></a><strong>生命周期</strong></h3><ul>\n<li>current_app的生命周期最长，只要当前程序实例还在运行，都不会失效。</li>\n<li>Request和g的生命周期为一次请求期间，当请求处理完成后，生命周期也就完结了</li>\n<li>Session就是传统意义上的session了。只要它还未失效（用户未关闭浏览器、没有超过设定的失效时间），那么不同的请求会共用同样的session。</li>\n</ul>\n<h3 id=\"为什么上下文需要放在栈中？\"><a href=\"#为什么上下文需要放在栈中？\" class=\"headerlink\" title=\"为什么上下文需要放在栈中？\"></a><strong>为什么上下文需要放在栈中？</strong></h3><p>1.应用上下文：</p>\n<p>Flask底层是基于werkzeug，werkzeug是可以包含多个app的，所以这时候用一个栈来保存，如果你在使用app1，那么app1应该是要在栈的顶部，如果用完了app1那么app应该从栈中删除，方便其他代码使用下面的app。</p>\n<p>2.请求上下文：</p>\n<p>如果在写测试代码，或者离线脚本的时候，我们有时候可能需要创建多个请求上下文，这时候就需要存放到一个栈中了。使用哪个请求上下文的时候，就把对应的请求上下文放到栈的顶部，用完了就要把这个请求上下文从栈中移除掉。</p>\n<h3 id=\"上下文管理流程\"><a href=\"#上下文管理流程\" class=\"headerlink\" title=\"上下文管理流程?\"></a>上下文管理流程?</h3><p>每次有请求过来的时候，flask 会先创建当前线程或者进程需要处理的两个重要上下文对象，把它们保存到隔离的栈里面，这样视图函数进行处理的时候就能直接从栈上获取这些信息。</p>\n<p>1.请求到来时，将session和request封装到ctx对象中；</p>\n<p>2.对session作补充；</p>\n<p>3.将包含了request和session的ctx对象放到一个容器中（每一个请求都会根据线程/协程加一个惟一标识）；</p>\n<p>4.视图函数使用的时候须要根据当前线程或协程的惟一标识，获取ctx对象，再取ctx对象中取request和session（视图函数使用的时候，须要根据当前线程获取数据。）</p>\n<p>5.请求结束时，根据当前线程/协程的惟一标记，将这个容器上的数据移除。</p>\n<h3 id=\"为什么要把-request-context-和-application-context-分开？每个请求不是都同时拥有这两个上下文信息吗？\"><a href=\"#为什么要把-request-context-和-application-context-分开？每个请求不是都同时拥有这两个上下文信息吗？\" class=\"headerlink\" title=\"为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？\"></a>为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？</h3><p>虽然在实际运行中，每个请求对应一个 request context 和一个 application context，但是在测试或者 python shell 中运行的时候，用户可以单独创建 request context 或者 application context，这种灵活度方便用户的不同的使用场景</p>\n<h3 id=\"为什么Local对象中的stack-维护成一个列表？\"><a href=\"#为什么Local对象中的stack-维护成一个列表？\" class=\"headerlink\" title=\"为什么Local对象中的stack 维护成一个列表？\"></a>为什么Local对象中的stack 维护成一个列表？</h3><p>测试的时候可以添加多个上下文，另外一个原因是 flask 可以<a href=\"http://flask.pocoo.org/docs/0.12/patterns/appdispatch/#combining-applications\" target=\"_blank\" rel=\"noopener\">多个 application 同时运行</a></p>\n<h3 id=\"Flask中多app应用是怎么完成？\"><a href=\"#Flask中多app应用是怎么完成？\" class=\"headerlink\" title=\"Flask中多app应用是怎么完成？\"></a>Flask中多app应用是怎么完成？</h3><p>请求进来时，可以根据URL的不同，交给不同的APP处理。</p>\n<p>使用Flask类建立不一样的app对象，而后借助DispatcherMiddleware类来实现。</p>\n<h3 id=\"Local对象和threading-local对象的区别\"><a href=\"#Local对象和threading-local对象的区别\" class=\"headerlink\" title=\"Local对象和threading.local对象的区别\"></a>Local对象和threading.local对象的区别</h3><p>Thread Local 则是一种特殊的对象，它的“状态”对线程隔离 —— 也就是说每个线程对一个 Thread Local 对象的修改都不会影响其他线程。原理也非常简单，只要以线程的 ID 来保存多份状态字典即可。</p>\n<p>werkzeug.local.Local和threading.local<strong>区别</strong>如下：</p>\n<p>（1）werkzeug使用了自定义的<code>__storage__</code>保存不同线程下的状态</p>\n<p>（2）werkzeug提供了释放本地线程的release_local方法</p>\n<p>（3）werkzeug通过get_ident函数来获得线程标识符</p>\n<h4 id=\"为什么造轮子\"><a href=\"#为什么造轮子\" class=\"headerlink\" title=\"为什么造轮子\"></a><strong>为什么造轮子</strong></h4><p>WSGI不保证每个请求必须由一个线程来处理，如果WSGI服务器不是每个线程派发一个请求，而是每个协程派发一个请求，thread local变量可能会造成请求间数据相互干扰，因为一个线程中存在多个请求。</p>\n<h4 id=\"除-了Local\"><a href=\"#除-了Local\" class=\"headerlink\" title=\"除 了Local\"></a>除 了Local</h4><p>Werkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。</p>\n<p>LocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。</p>\n<p>LocalProxy用于代理Local对象和LocalStack对象，而所谓代理就是作为中间的代理人来处理所有针对被代理对象的操作。LocalStack无法再动态更新了，而使用Proxy实现了动态更新。重载了绝大多数操作符，以便在调用LocalProxy的相应操作时，通过<code>_get_current_object</code> method来获取真正代理的对象，然后再进行相应操作</p>\n<h2 id=\"蓝图\"><a href=\"#蓝图\" class=\"headerlink\" title=\"蓝图\"></a>蓝图</h2><h3 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h3><ul>\n<li><p>将不同的功能模块化，构建大型应用</p>\n</li>\n<li><p>优化项目结构</p>\n</li>\n<li><p>增强可读性,易于维护</p>\n</li>\n</ul>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><ul>\n<li>新增了一个xxx.py的文件，实例化Blueprint应用</li>\n<li>xxx.py编写视图函数，使用Blueprint应用示例设置路由</li>\n<li>run.py中，注册蓝图示例</li>\n</ul>\n<h2 id=\"如何在Flask中访问会话\"><a href=\"#如何在Flask中访问会话\" class=\"headerlink\" title=\"如何在Flask中访问会话?\"></a>如何在Flask中访问会话?</h2><p>用户第一次请求后，将产生的状态信息保存在session中，这时可以把session当做一个容器，它保存了正在使用的所有用户的状态信息；这段状态信息分配了一个唯一的标识符用来标识用户的身份，将其保存在响应对象的cookie中；当第二次请求时，解析cookie中的标识符，拿到标识符后去session找到对应的用户的信息。</p>\n<p>在flask中，如果我们想要获取session信息，直接通过flask的session获取就可以了，这是因为session是一个代理对象，代理当前请求上下文的session属性。</p>\n<h2 id=\"wsgi\"><a href=\"#wsgi\" class=\"headerlink\" title=\"wsgi\"></a>wsgi</h2><p>Web服务器和Web应用程序或框架之间的一种简单而通用的接口。描述了web server如何与web application交互、web application如何处理请求。</p>\n<p><strong>应用程序端</strong></p>\n<p>WSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了<code>__call__</code> 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。</p>\n<h2 id=\"Werkzeug\"><a href=\"#Werkzeug\" class=\"headerlink\" title=\"Werkzeug\"></a>Werkzeug</h2><p>HTTP 和 WSGI 相关的工具集，可以用来编写 web 框架，可以直接使用它提供的一些帮助函数。</p>\n<p>werkzeug 提供了 python web WSGI 开发相关的功能：</p>\n<ul>\n<li><p>路由处理：如何根据请求 URL 找到对应的视图函数</p>\n</li>\n<li><p>request 和 response 封装: 提供更好的方式处理request和生成response对象</p>\n</li>\n<li><p>自带的 WSGI server: 测试环境运行WSGI应用</p>\n</li>\n</ul>\n<h2 id=\"RESTful\"><a href=\"#RESTful\" class=\"headerlink\" title=\"RESTful\"></a>RESTful</h2><p>REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。</p>\n<p>（1）每一个URI代表一种资源；</p>\n<p>（2）客户端和服务器之间，传递这种资源的某种表现层；</p>\n<p>（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。</p>\n<p>“资源”是一种信息实体，它可以有多种外在表现形式。<strong>我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。</strong></p>\n<p>所有的状态都保存在服务器端。因此，<strong>如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。</strong></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://juejin.im/post/6844903533238566925#heading-10\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/6844903533238566925#heading-10</a></p>\n<p><a href=\"http://www.pythondoc.com/flask/appcontext.html\" target=\"_blank\" rel=\"noopener\">http://www.pythondoc.com/flask/appcontext.html</a></p>\n<p><a href=\"http://www.pythondoc.com/flask/reqcontext.html\" target=\"_blank\" rel=\"noopener\">http://www.pythondoc.com/flask/reqcontext.html</a></p>\n<p><a href=\"https://cizixs.com/2017/01/12/flask-insight-routing/\" target=\"_blank\" rel=\"noopener\">https://cizixs.com/2017/01/12/flask-insight-routing/</a></p>\n<p><a href=\"https://www.cnblogs.com/kendrick/p/7649772.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/kendrick/p/7649772.html</a></p>\n<p><a href=\"https://www.cnblogs.com/panlq/p/13266426.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/panlq/p/13266426.html</a></p>\n"},{"title":"count优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T10:30:14.000Z","password":null,"summary":null,"_content":"\n## count说明\n\n### count（a） 和 count（*）\n\n当 count 统计某一列时，比如` count(a)`，a 表示列名，是不统计 null 的。\n\n而 `count(*) `无论是否包含空值，都会统计。\n\n### MyISAM/InnoDB count（*）\n\n MyISAM：如果没有 where 子句，也没检索其它列，`count(*) `会非常快。 MyISAM 引擎会把表的总行数存在磁盘上。\n\nInnoDB ：不会保留表中的行数，因为并发事务可能同时读取到不同的行数。执行` count(*) `时都是临时去计算的，会比 MyISAM 慢很多。\n\n### MySQL 5.7.18 前后 count（*） 的区别\n\nMySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理` count(*) `语句。\n\nMySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 `count(*) `语句。\n\n优化器基于成本的考虑，优先选择的是二级索引。所以` count(主键)` 其实没` count (*)`快。\n\n### count（1）   count（*）\n\n执行计划相同，速度没有明显差别\n\n## count 优化\n\n1、`show table status`,Rows 这列就表示这张表的行数。\n\n```mysql\nshow table status like 't1';\n```\n\n估算值，可能与实际值相差 40% 到 50%。\n\n2、用 Redis 做计数器\n\nredis 和数据库访问存在时间先后，可能会读到错误的值。\n\n3、增加计数表\n\n维持了计数的准确性\n\n","source":"_posts/count优化.md","raw":"---\ntitle: count优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 18:30:14\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## count说明\n\n### count（a） 和 count（*）\n\n当 count 统计某一列时，比如` count(a)`，a 表示列名，是不统计 null 的。\n\n而 `count(*) `无论是否包含空值，都会统计。\n\n### MyISAM/InnoDB count（*）\n\n MyISAM：如果没有 where 子句，也没检索其它列，`count(*) `会非常快。 MyISAM 引擎会把表的总行数存在磁盘上。\n\nInnoDB ：不会保留表中的行数，因为并发事务可能同时读取到不同的行数。执行` count(*) `时都是临时去计算的，会比 MyISAM 慢很多。\n\n### MySQL 5.7.18 前后 count（*） 的区别\n\nMySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理` count(*) `语句。\n\nMySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 `count(*) `语句。\n\n优化器基于成本的考虑，优先选择的是二级索引。所以` count(主键)` 其实没` count (*)`快。\n\n### count（1）   count（*）\n\n执行计划相同，速度没有明显差别\n\n## count 优化\n\n1、`show table status`,Rows 这列就表示这张表的行数。\n\n```mysql\nshow table status like 't1';\n```\n\n估算值，可能与实际值相差 40% 到 50%。\n\n2、用 Redis 做计数器\n\nredis 和数据库访问存在时间先后，可能会读到错误的值。\n\n3、增加计数表\n\n维持了计数的准确性\n\n","slug":"count优化","published":1,"updated":"2021-05-11T13:01:03.601Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ky0006q4ufed5z7qnj","content":"<h2 id=\"count说明\"><a href=\"#count说明\" class=\"headerlink\" title=\"count说明\"></a>count说明</h2><h3 id=\"count（a）-和-count（-）\"><a href=\"#count（a）-和-count（-）\" class=\"headerlink\" title=\"count（a） 和 count（*）\"></a>count（a） 和 count（*）</h3><p>当 count 统计某一列时，比如<code>count(a)</code>，a 表示列名，是不统计 null 的。</p>\n<p>而 <code>count(*)</code>无论是否包含空值，都会统计。</p>\n<h3 id=\"MyISAM-InnoDB-count（-）\"><a href=\"#MyISAM-InnoDB-count（-）\" class=\"headerlink\" title=\"MyISAM/InnoDB count（*）\"></a>MyISAM/InnoDB count（*）</h3><p> MyISAM：如果没有 where 子句，也没检索其它列，<code>count(*)</code>会非常快。 MyISAM 引擎会把表的总行数存在磁盘上。</p>\n<p>InnoDB ：不会保留表中的行数，因为并发事务可能同时读取到不同的行数。执行<code>count(*)</code>时都是临时去计算的，会比 MyISAM 慢很多。</p>\n<h3 id=\"MySQL-5-7-18-前后-count（-）-的区别\"><a href=\"#MySQL-5-7-18-前后-count（-）-的区别\" class=\"headerlink\" title=\"MySQL 5.7.18 前后 count（*） 的区别\"></a>MySQL 5.7.18 前后 count（*） 的区别</h3><p>MySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理<code>count(*)</code>语句。</p>\n<p>MySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 <code>count(*)</code>语句。</p>\n<p>优化器基于成本的考虑，优先选择的是二级索引。所以<code>count(主键)</code> 其实没<code>count (*)</code>快。</p>\n<h3 id=\"count（1）-count（-）\"><a href=\"#count（1）-count（-）\" class=\"headerlink\" title=\"count（1）   count（*）\"></a>count（1）   count（*）</h3><p>执行计划相同，速度没有明显差别</p>\n<h2 id=\"count-优化\"><a href=\"#count-优化\" class=\"headerlink\" title=\"count 优化\"></a>count 优化</h2><p>1、<code>show table status</code>,Rows 这列就表示这张表的行数。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">show table status like 't1';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>估算值，可能与实际值相差 40% 到 50%。</p>\n<p>2、用 Redis 做计数器</p>\n<p>redis 和数据库访问存在时间先后，可能会读到错误的值。</p>\n<p>3、增加计数表</p>\n<p>维持了计数的准确性</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"count说明\"><a href=\"#count说明\" class=\"headerlink\" title=\"count说明\"></a>count说明</h2><h3 id=\"count（a）-和-count（-）\"><a href=\"#count（a）-和-count（-）\" class=\"headerlink\" title=\"count（a） 和 count（*）\"></a>count（a） 和 count（*）</h3><p>当 count 统计某一列时，比如<code>count(a)</code>，a 表示列名，是不统计 null 的。</p>\n<p>而 <code>count(*)</code>无论是否包含空值，都会统计。</p>\n<h3 id=\"MyISAM-InnoDB-count（-）\"><a href=\"#MyISAM-InnoDB-count（-）\" class=\"headerlink\" title=\"MyISAM/InnoDB count（*）\"></a>MyISAM/InnoDB count（*）</h3><p> MyISAM：如果没有 where 子句，也没检索其它列，<code>count(*)</code>会非常快。 MyISAM 引擎会把表的总行数存在磁盘上。</p>\n<p>InnoDB ：不会保留表中的行数，因为并发事务可能同时读取到不同的行数。执行<code>count(*)</code>时都是临时去计算的，会比 MyISAM 慢很多。</p>\n<h3 id=\"MySQL-5-7-18-前后-count（-）-的区别\"><a href=\"#MySQL-5-7-18-前后-count（-）-的区别\" class=\"headerlink\" title=\"MySQL 5.7.18 前后 count（*） 的区别\"></a>MySQL 5.7.18 前后 count（*） 的区别</h3><p>MySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理<code>count(*)</code>语句。</p>\n<p>MySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 <code>count(*)</code>语句。</p>\n<p>优化器基于成本的考虑，优先选择的是二级索引。所以<code>count(主键)</code> 其实没<code>count (*)</code>快。</p>\n<h3 id=\"count（1）-count（-）\"><a href=\"#count（1）-count（-）\" class=\"headerlink\" title=\"count（1）   count（*）\"></a>count（1）   count（*）</h3><p>执行计划相同，速度没有明显差别</p>\n<h2 id=\"count-优化\"><a href=\"#count-优化\" class=\"headerlink\" title=\"count 优化\"></a>count 优化</h2><p>1、<code>show table status</code>,Rows 这列就表示这张表的行数。</p>\n<pre><code class=\"mysql\">show table status like &#39;t1&#39;;</code></pre>\n<p>估算值，可能与实际值相差 40% 到 50%。</p>\n<p>2、用 Redis 做计数器</p>\n<p>redis 和数据库访问存在时间先后，可能会读到错误的值。</p>\n<p>3、增加计数表</p>\n<p>维持了计数的准确性</p>\n"},{"title":"join优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T09:35:27.000Z","password":null,"summary":null,"_content":"\n## 关联查询\n\n### Nested-Loop Join\n\n**思想**\n\n一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。[manual](https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html)\n\n> 在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。\n>\n> 一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ\n\n### Block Nested-Loop Join \n\n**思想**：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。[manual](https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization.html)\n\n> join_buffer减少了磁盘扫描次数。\n\n**主要影响**\n\n1. 可能会多次扫描被驱动表，占用磁盘IO资源；\n2. 判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；\n3. 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。\n\n### Batched Key Access\n\n> **MRR**\n>\n> 尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n>\n> MRR能够提升性能的核心在于，查询语句在索引的是范围查询，可以得到足够多的主键id。排序后，再去主键索引查数据，才能体现出“顺序性”的优势。\n\n**思想**\n\n结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read（MRR） 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。\n\n```mysql\nset optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/\n```\n\n> Extra显示Using join buffer （Batched Key Access）\n\n## 优化关联查询\n\n### 关联字段添加索引\n\n被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。\n\n### 小表做驱动表\n\n复杂度是低于大表做驱动表的。\n\n### 临时表\n\n> 某条关联查询只是临时查一次，再去添加索引会浪费资源。\n\n尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。\n\n\n\n","source":"_posts/join优化.md","raw":"---\ntitle: join优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 17:35:27\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 关联查询\n\n### Nested-Loop Join\n\n**思想**\n\n一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。[manual](https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html)\n\n> 在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。\n>\n> 一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ\n\n### Block Nested-Loop Join \n\n**思想**：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。[manual](https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization.html)\n\n> join_buffer减少了磁盘扫描次数。\n\n**主要影响**\n\n1. 可能会多次扫描被驱动表，占用磁盘IO资源；\n2. 判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；\n3. 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。\n\n### Batched Key Access\n\n> **MRR**\n>\n> 尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n>\n> MRR能够提升性能的核心在于，查询语句在索引的是范围查询，可以得到足够多的主键id。排序后，再去主键索引查数据，才能体现出“顺序性”的优势。\n\n**思想**\n\n结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read（MRR） 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。\n\n```mysql\nset optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/\n```\n\n> Extra显示Using join buffer （Batched Key Access）\n\n## 优化关联查询\n\n### 关联字段添加索引\n\n被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。\n\n### 小表做驱动表\n\n复杂度是低于大表做驱动表的。\n\n### 临时表\n\n> 某条关联查询只是临时查一次，再去添加索引会浪费资源。\n\n尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。\n\n\n\n","slug":"join优化","published":1,"updated":"2021-05-11T12:55:02.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6l30007q4ufwc0flyy8","content":"<h2 id=\"关联查询\"><a href=\"#关联查询\" class=\"headerlink\" title=\"关联查询\"></a>关联查询</h2><h3 id=\"Nested-Loop-Join\"><a href=\"#Nested-Loop-Join\" class=\"headerlink\" title=\"Nested-Loop Join\"></a>Nested-Loop Join</h3><p><strong>思想</strong></p>\n<p>一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。<a href=\"https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html\" target=\"_blank\" rel=\"noopener\">manual</a></p>\n<blockquote>\n<p>在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。</p>\n<p>一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ</p>\n</blockquote>\n<h3 id=\"Block-Nested-Loop-Join\"><a href=\"#Block-Nested-Loop-Join\" class=\"headerlink\" title=\"Block Nested-Loop Join\"></a>Block Nested-Loop Join</h3><p><strong>思想</strong>：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。<a href=\"https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization.html\" target=\"_blank\" rel=\"noopener\">manual</a></p>\n<blockquote>\n<p>join_buffer减少了磁盘扫描次数。</p>\n</blockquote>\n<p><strong>主要影响</strong></p>\n<ol>\n<li>可能会多次扫描被驱动表，占用磁盘IO资源；</li>\n<li>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</li>\n<li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</li>\n</ol>\n<h3 id=\"Batched-Key-Access\"><a href=\"#Batched-Key-Access\" class=\"headerlink\" title=\"Batched Key Access\"></a>Batched Key Access</h3><blockquote>\n<p><strong>MRR</strong></p>\n<p>尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p>\n<p>MRR能够提升性能的核心在于，查询语句在索引的是范围查询，可以得到足够多的主键id。排序后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>\n</blockquote>\n<p><strong>思想</strong></p>\n<p>结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read（MRR） 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<blockquote>\n<p>Extra显示Using join buffer （Batched Key Access）</p>\n</blockquote>\n<h2 id=\"优化关联查询\"><a href=\"#优化关联查询\" class=\"headerlink\" title=\"优化关联查询\"></a>优化关联查询</h2><h3 id=\"关联字段添加索引\"><a href=\"#关联字段添加索引\" class=\"headerlink\" title=\"关联字段添加索引\"></a>关联字段添加索引</h3><p>被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。</p>\n<h3 id=\"小表做驱动表\"><a href=\"#小表做驱动表\" class=\"headerlink\" title=\"小表做驱动表\"></a>小表做驱动表</h3><p>复杂度是低于大表做驱动表的。</p>\n<h3 id=\"临时表\"><a href=\"#临时表\" class=\"headerlink\" title=\"临时表\"></a>临时表</h3><blockquote>\n<p>某条关联查询只是临时查一次，再去添加索引会浪费资源。</p>\n</blockquote>\n<p>尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"关联查询\"><a href=\"#关联查询\" class=\"headerlink\" title=\"关联查询\"></a>关联查询</h2><h3 id=\"Nested-Loop-Join\"><a href=\"#Nested-Loop-Join\" class=\"headerlink\" title=\"Nested-Loop Join\"></a>Nested-Loop Join</h3><p><strong>思想</strong></p>\n<p>一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。<a href=\"https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html\" target=\"_blank\" rel=\"noopener\">manual</a></p>\n<blockquote>\n<p>在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。</p>\n<p>一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ</p>\n</blockquote>\n<h3 id=\"Block-Nested-Loop-Join\"><a href=\"#Block-Nested-Loop-Join\" class=\"headerlink\" title=\"Block Nested-Loop Join\"></a>Block Nested-Loop Join</h3><p><strong>思想</strong>：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。<a href=\"https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization.html\" target=\"_blank\" rel=\"noopener\">manual</a></p>\n<blockquote>\n<p>join_buffer减少了磁盘扫描次数。</p>\n</blockquote>\n<p><strong>主要影响</strong></p>\n<ol>\n<li>可能会多次扫描被驱动表，占用磁盘IO资源；</li>\n<li>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</li>\n<li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</li>\n</ol>\n<h3 id=\"Batched-Key-Access\"><a href=\"#Batched-Key-Access\" class=\"headerlink\" title=\"Batched Key Access\"></a>Batched Key Access</h3><blockquote>\n<p><strong>MRR</strong></p>\n<p>尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p>\n<p>MRR能够提升性能的核心在于，查询语句在索引的是范围查询，可以得到足够多的主键id。排序后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>\n</blockquote>\n<p><strong>思想</strong></p>\n<p>结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read（MRR） 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。</p>\n<pre><code class=\"mysql\">set optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;/*开启BKA*/</code></pre>\n<blockquote>\n<p>Extra显示Using join buffer （Batched Key Access）</p>\n</blockquote>\n<h2 id=\"优化关联查询\"><a href=\"#优化关联查询\" class=\"headerlink\" title=\"优化关联查询\"></a>优化关联查询</h2><h3 id=\"关联字段添加索引\"><a href=\"#关联字段添加索引\" class=\"headerlink\" title=\"关联字段添加索引\"></a>关联字段添加索引</h3><p>被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。</p>\n<h3 id=\"小表做驱动表\"><a href=\"#小表做驱动表\" class=\"headerlink\" title=\"小表做驱动表\"></a>小表做驱动表</h3><p>复杂度是低于大表做驱动表的。</p>\n<h3 id=\"临时表\"><a href=\"#临时表\" class=\"headerlink\" title=\"临时表\"></a>临时表</h3><blockquote>\n<p>某条关联查询只是临时查一次，再去添加索引会浪费资源。</p>\n</blockquote>\n<p>尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。</p>\n"},{"title":"kafka Broker请求处理","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T09:58:17.000Z","password":null,"summary":null,"_content":"\n所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。\n\nKafka 使用的是 Reactor 模式处理请求。\n\n**Reactor 模式**是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。\n\n![](reactor.jpg)\n\nKafka 提供了 Broker 端参数 `num.network.threads`，用于调整该**网络线程池**的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 **个网络线程**，专门处理客户端发送的请求。\n\n![](work.jpg)\n\n当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个**共享请求队列**中。Broker 端还有个 **IO 线程池**，负责从该队列中取出请求，执行真正的处理--如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。\n\nBroker 端参数 `num.io.threads` 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。\n\n**Purgatory**\n\n缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。\n\n比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 `acks=all`，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。","source":"_posts/kafka-Broker请求处理.md","raw":"---\ntitle: kafka Broker请求处理\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 17:58:17\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。\n\nKafka 使用的是 Reactor 模式处理请求。\n\n**Reactor 模式**是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。\n\n![](reactor.jpg)\n\nKafka 提供了 Broker 端参数 `num.network.threads`，用于调整该**网络线程池**的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 **个网络线程**，专门处理客户端发送的请求。\n\n![](work.jpg)\n\n当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个**共享请求队列**中。Broker 端还有个 **IO 线程池**，负责从该队列中取出请求，执行真正的处理--如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。\n\nBroker 端参数 `num.io.threads` 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。\n\n**Purgatory**\n\n缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。\n\n比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 `acks=all`，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。","slug":"kafka-Broker请求处理","published":1,"updated":"2021-04-01T23:01:49.676Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ld000bq4ufmtghgzb4","content":"<p>所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。</p>\n<p>Kafka 使用的是 Reactor 模式处理请求。</p>\n<p><strong>Reactor 模式</strong>是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。</p>\n<p><img src=\"reactor.jpg\" alt></p>\n<p>Kafka 提供了 Broker 端参数 <code>num.network.threads</code>，用于调整该<strong>网络线程池</strong>的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 <strong>个网络线程</strong>，专门处理客户端发送的请求。</p>\n<p><img src=\"work.jpg\" alt></p>\n<p>当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个<strong>共享请求队列</strong>中。Broker 端还有个 <strong>IO 线程池</strong>，负责从该队列中取出请求，执行真正的处理–如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。</p>\n<p>Broker 端参数 <code>num.io.threads</code> 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。</p>\n<p><strong>Purgatory</strong></p>\n<p>缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。</p>\n<p>比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 <code>acks=all</code>，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。</p>\n<p>Kafka 使用的是 Reactor 模式处理请求。</p>\n<p><strong>Reactor 模式</strong>是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。</p>\n<p><img src=\"reactor.jpg\" alt></p>\n<p>Kafka 提供了 Broker 端参数 <code>num.network.threads</code>，用于调整该<strong>网络线程池</strong>的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 <strong>个网络线程</strong>，专门处理客户端发送的请求。</p>\n<p><img src=\"work.jpg\" alt></p>\n<p>当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个<strong>共享请求队列</strong>中。Broker 端还有个 <strong>IO 线程池</strong>，负责从该队列中取出请求，执行真正的处理–如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。</p>\n<p>Broker 端参数 <code>num.io.threads</code> 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。</p>\n<p><strong>Purgatory</strong></p>\n<p>缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。</p>\n<p>比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 <code>acks=all</code>，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。</p>\n"},{"title":"kafka主题管理","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T13:49:14.000Z","password":null,"summary":null,"_content":"\n## **主题增删改查**\n\n### 创建\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1\n```\n\n从 Kafka 2.2 版本开始，社区推荐用 --bootstrap-server 参数替换 --zookeeper 参数\n\n### 查询\n\n```shell\n# 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name>\n```\n\n### 修改\n\n```shell\n# 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数>\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{\"version\":1, \"partitions\":[\n {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n  {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]},\n  ...\n  {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions\n```\n\n### 删除\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name>\n```\n\n## 特殊主体管理\n\n### 查看消费者组提交的位移数\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning\n```\n\n### 查看消费者组的状态信息\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning\n```\n\n## 常见主题错误处理\n\n### 主题删除失败\n\n- 副本所在的 Broker 宕机了；--重启即可\n- 待删除主题的部分分区依然在执行迁移过程\n\n**解决**\n\n第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。\n\n第 2 步，手动删除该主题在磁盘上的分区目录。\n\n第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。--非必须，可能造成大面积的分区 Leader 重选举\n\n### __consumer_offsets 占用太多的磁盘\n\n jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。\n\n","source":"_posts/kafka主题管理.md","raw":"---\ntitle: kafka主题管理\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 21:49:14\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## **主题增删改查**\n\n### 创建\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1\n```\n\n从 Kafka 2.2 版本开始，社区推荐用 --bootstrap-server 参数替换 --zookeeper 参数\n\n### 查询\n\n```shell\n# 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name>\n```\n\n### 修改\n\n```shell\n# 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数>\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{\"version\":1, \"partitions\":[\n {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n  {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]},\n  ...\n  {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions\n```\n\n### 删除\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name>\n```\n\n## 特殊主体管理\n\n### 查看消费者组提交的位移数\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning\n```\n\n### 查看消费者组的状态信息\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning\n```\n\n## 常见主题错误处理\n\n### 主题删除失败\n\n- 副本所在的 Broker 宕机了；--重启即可\n- 待删除主题的部分分区依然在执行迁移过程\n\n**解决**\n\n第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。\n\n第 2 步，手动删除该主题在磁盘上的分区目录。\n\n第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。--非必须，可能造成大面积的分区 Leader 重选举\n\n### __consumer_offsets 占用太多的磁盘\n\n jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。\n\n","slug":"kafka主题管理","published":1,"updated":"2021-04-02T13:10:57.097Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6lm000dq4ufl44kt2pz","content":"<h2 id=\"主题增删改查\"><a href=\"#主题增删改查\" class=\"headerlink\" title=\"主题增删改查\"></a><strong>主题增删改查</strong></h2><h3 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a>创建</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>从 Kafka 2.2 版本开始，社区推荐用 –bootstrap-server 参数替换 –zookeeper 参数</p>\n<h3 id=\"查询\"><a href=\"#查询\" class=\"headerlink\" title=\"查询\"></a>查询</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"修改\"><a href=\"#修改\" class=\"headerlink\" title=\"修改\"></a>修改</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数>\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{\"version\":1, \"partitions\":[\n {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n  {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]},\n  ...\n  {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"特殊主体管理\"><a href=\"#特殊主体管理\" class=\"headerlink\" title=\"特殊主体管理\"></a>特殊主体管理</h2><h3 id=\"查看消费者组提交的位移数\"><a href=\"#查看消费者组提交的位移数\" class=\"headerlink\" title=\"查看消费者组提交的位移数\"></a>查看消费者组提交的位移数</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"查看消费者组的状态信息\"><a href=\"#查看消费者组的状态信息\" class=\"headerlink\" title=\"查看消费者组的状态信息\"></a>查看消费者组的状态信息</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"常见主题错误处理\"><a href=\"#常见主题错误处理\" class=\"headerlink\" title=\"常见主题错误处理\"></a>常见主题错误处理</h2><h3 id=\"主题删除失败\"><a href=\"#主题删除失败\" class=\"headerlink\" title=\"主题删除失败\"></a>主题删除失败</h3><ul>\n<li>副本所在的 Broker 宕机了；–重启即可</li>\n<li>待删除主题的部分分区依然在执行迁移过程</li>\n</ul>\n<p><strong>解决</strong></p>\n<p>第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。</p>\n<p>第 2 步，手动删除该主题在磁盘上的分区目录。</p>\n<p>第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。–非必须，可能造成大面积的分区 Leader 重选举</p>\n<h3 id=\"consumer-offsets-占用太多的磁盘\"><a href=\"#consumer-offsets-占用太多的磁盘\" class=\"headerlink\" title=\"__consumer_offsets 占用太多的磁盘\"></a>__consumer_offsets 占用太多的磁盘</h3><p> jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"主题增删改查\"><a href=\"#主题增删改查\" class=\"headerlink\" title=\"主题增删改查\"></a><strong>主题增删改查</strong></h2><h3 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a>创建</h3><pre><code class=\"shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1</code></pre>\n<p>从 Kafka 2.2 版本开始，社区推荐用 –bootstrap-server 参数替换 –zookeeper 参数</p>\n<h3 id=\"查询\"><a href=\"#查询\" class=\"headerlink\" title=\"查询\"></a>查询</h3><pre><code class=\"shell\"># 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic &lt;topic_name&gt;</code></pre>\n<h3 id=\"修改\"><a href=\"#修改\" class=\"headerlink\" title=\"修改\"></a>修改</h3><pre><code class=\"shell\"># 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt;新分区数&gt;\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name &lt;topic_name&gt; --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{&quot;version&quot;:1, &quot;partitions&quot;:[\n {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]}, \n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,2,1]},\n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0,2]},\n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,2,0]},\n  ...\n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:49,&quot;replicas&quot;:[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#39;leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600&#39; --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#39;leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*&#39; --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions</code></pre>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><pre><code class=\"shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic &lt;topic_name&gt;</code></pre>\n<h2 id=\"特殊主体管理\"><a href=\"#特殊主体管理\" class=\"headerlink\" title=\"特殊主体管理\"></a>特殊主体管理</h2><h3 id=\"查看消费者组提交的位移数\"><a href=\"#查看消费者组提交的位移数\" class=\"headerlink\" title=\"查看消费者组提交的位移数\"></a>查看消费者组提交的位移数</h3><pre><code class=\"shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; --from-beginning</code></pre>\n<h3 id=\"查看消费者组的状态信息\"><a href=\"#查看消费者组的状态信息\" class=\"headerlink\" title=\"查看消费者组的状态信息\"></a>查看消费者组的状态信息</h3><pre><code class=\"shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter&quot; --from-beginning</code></pre>\n<h2 id=\"常见主题错误处理\"><a href=\"#常见主题错误处理\" class=\"headerlink\" title=\"常见主题错误处理\"></a>常见主题错误处理</h2><h3 id=\"主题删除失败\"><a href=\"#主题删除失败\" class=\"headerlink\" title=\"主题删除失败\"></a>主题删除失败</h3><ul>\n<li>副本所在的 Broker 宕机了；–重启即可</li>\n<li>待删除主题的部分分区依然在执行迁移过程</li>\n</ul>\n<p><strong>解决</strong></p>\n<p>第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。</p>\n<p>第 2 步，手动删除该主题在磁盘上的分区目录。</p>\n<p>第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。–非必须，可能造成大面积的分区 Leader 重选举</p>\n<h3 id=\"consumer-offsets-占用太多的磁盘\"><a href=\"#consumer-offsets-占用太多的磁盘\" class=\"headerlink\" title=\"__consumer_offsets 占用太多的磁盘\"></a>__consumer_offsets 占用太多的磁盘</h3><p> jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。</p>\n"},{"title":"kafka思维导图","top":true,"cover":false,"toc":true,"mathjax":false,"date":"2021-04-02T13:19:32.000Z","password":null,"summary":"博客中kafka相关的思维导图。","_content":"\n![](kafka.png)","source":"_posts/kafka思维导图.md","raw":"---\ntitle: kafka思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: false\ndate: 2021-04-02 21:19:32\npassword:\nsummary: 博客中kafka相关的思维导图。\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n![](kafka.png)","slug":"kafka思维导图","published":1,"updated":"2021-04-02T13:21:29.499Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6m1000iq4uf7etfdn6x","content":"<p><img src=\"kafka.png\" alt></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p><img src=\"kafka.png\" alt></p>\n"},{"title":"Kafka控制器","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T11:48:00.000Z","password":null,"summary":null,"_content":"\n控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。\n\n![](zookeeper.jpg)\n\n## **控制器选举**\n\nBroker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n\n## **控制器作用**\n\n- 主题管理（创建、删除、增加分区）\n- 分区重分配\n- Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案\n- 集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。\n- 数据服务：保存了最全的集群元数据信息\n\n![](data.jpg)\n\n## **控制器故障转移**\n\n故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。\n\n![](Failover.jpg)\n\n","source":"_posts/Kafka控制器.md","raw":"---\ntitle: Kafka控制器\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 19:48:00\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。\n\n![](zookeeper.jpg)\n\n## **控制器选举**\n\nBroker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n\n## **控制器作用**\n\n- 主题管理（创建、删除、增加分区）\n- 分区重分配\n- Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案\n- 集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。\n- 数据服务：保存了最全的集群元数据信息\n\n![](data.jpg)\n\n## **控制器故障转移**\n\n故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。\n\n![](Failover.jpg)\n\n","slug":"Kafka控制器","published":1,"updated":"2021-04-02T14:01:48.263Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6mi000lq4ufecnel9ts","content":"<p>控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。</p>\n<p><img src=\"zookeeper.jpg\" alt></p>\n<h2 id=\"控制器选举\"><a href=\"#控制器选举\" class=\"headerlink\" title=\"控制器选举\"></a><strong>控制器选举</strong></h2><p>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。</p>\n<h2 id=\"控制器作用\"><a href=\"#控制器作用\" class=\"headerlink\" title=\"控制器作用\"></a><strong>控制器作用</strong></h2><ul>\n<li>主题管理（创建、删除、增加分区）</li>\n<li>分区重分配</li>\n<li>Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案</li>\n<li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。</li>\n<li>数据服务：保存了最全的集群元数据信息</li>\n</ul>\n<p><img src=\"data.jpg\" alt></p>\n<h2 id=\"控制器故障转移\"><a href=\"#控制器故障转移\" class=\"headerlink\" title=\"控制器故障转移\"></a><strong>控制器故障转移</strong></h2><p>故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。</p>\n<p><img src=\"Failover.jpg\" alt></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。</p>\n<p><img src=\"zookeeper.jpg\" alt></p>\n<h2 id=\"控制器选举\"><a href=\"#控制器选举\" class=\"headerlink\" title=\"控制器选举\"></a><strong>控制器选举</strong></h2><p>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。</p>\n<h2 id=\"控制器作用\"><a href=\"#控制器作用\" class=\"headerlink\" title=\"控制器作用\"></a><strong>控制器作用</strong></h2><ul>\n<li>主题管理（创建、删除、增加分区）</li>\n<li>分区重分配</li>\n<li>Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案</li>\n<li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。</li>\n<li>数据服务：保存了最全的集群元数据信息</li>\n</ul>\n<p><img src=\"data.jpg\" alt></p>\n<h2 id=\"控制器故障转移\"><a href=\"#控制器故障转移\" class=\"headerlink\" title=\"控制器故障转移\"></a><strong>控制器故障转移</strong></h2><p>故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。</p>\n<p><img src=\"Failover.jpg\" alt></p>\n"},{"title":"kafka副本","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T09:45:20.000Z","password":null,"summary":null,"_content":"\n主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能**追加写消息的提交日志**。\n\n## 副本分类\n\n副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n\n- 所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。\n\n- 追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。\n- 领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。\n\n**优势**\n\n1.方便实现“Read-your-writes”：\n\n2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。\n\n## In-sync Replicas（ISR）\n\n与 Leader 同步的副本，包括 Leader 副本。\n\n标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。\n\n## Unclean 领导者选举\n\n非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。\n\nBroker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。","source":"_posts/kafka副本.md","raw":"---\ntitle: kafka副本\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 17:45:20\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能**追加写消息的提交日志**。\n\n## 副本分类\n\n副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n\n- 所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。\n\n- 追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。\n- 领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。\n\n**优势**\n\n1.方便实现“Read-your-writes”：\n\n2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。\n\n## In-sync Replicas（ISR）\n\n与 Leader 同步的副本，包括 Leader 副本。\n\n标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。\n\n## Unclean 领导者选举\n\n非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。\n\nBroker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。","slug":"kafka副本","published":1,"updated":"2021-04-01T23:01:49.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6mu000oq4ufhwj95egj","content":"<p>主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能<strong>追加写消息的提交日志</strong>。</p>\n<h2 id=\"副本分类\"><a href=\"#副本分类\" class=\"headerlink\" title=\"副本分类\"></a>副本分类</h2><p>副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p>\n<ul>\n<li><p>所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。</p>\n</li>\n<li><p>追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p>\n</li>\n<li><p>领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</p>\n</li>\n</ul>\n<p><strong>优势</strong></p>\n<p>1.方便实现“Read-your-writes”：</p>\n<p>2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。</p>\n<h2 id=\"In-sync-Replicas（ISR）\"><a href=\"#In-sync-Replicas（ISR）\" class=\"headerlink\" title=\"In-sync Replicas（ISR）\"></a>In-sync Replicas（ISR）</h2><p>与 Leader 同步的副本，包括 Leader 副本。</p>\n<p>标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。</p>\n<h2 id=\"Unclean-领导者选举\"><a href=\"#Unclean-领导者选举\" class=\"headerlink\" title=\"Unclean 领导者选举\"></a>Unclean 领导者选举</h2><p>非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。</p>\n<p>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能<strong>追加写消息的提交日志</strong>。</p>\n<h2 id=\"副本分类\"><a href=\"#副本分类\" class=\"headerlink\" title=\"副本分类\"></a>副本分类</h2><p>副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p>\n<ul>\n<li><p>所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。</p>\n</li>\n<li><p>追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p>\n</li>\n<li><p>领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</p>\n</li>\n</ul>\n<p><strong>优势</strong></p>\n<p>1.方便实现“Read-your-writes”：</p>\n<p>2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。</p>\n<h2 id=\"In-sync-Replicas（ISR）\"><a href=\"#In-sync-Replicas（ISR）\" class=\"headerlink\" title=\"In-sync Replicas（ISR）\"></a>In-sync Replicas（ISR）</h2><p>与 Leader 同步的副本，包括 Leader 副本。</p>\n<p>标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。</p>\n<h2 id=\"Unclean-领导者选举\"><a href=\"#Unclean-领导者选举\" class=\"headerlink\" title=\"Unclean 领导者选举\"></a>Unclean 领导者选举</h2><p>非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。</p>\n<p>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</p>\n"},{"title":"kafka拦截器","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T11:18:48.000Z","password":null,"summary":null,"_content":"\nKafka 拦截器分为生产者拦截器和消费者拦截器。\n\n生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；\n\n而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。\n\n**使用**\n\n当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫` interceptor.classes`，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。\n\n```java\nProperties props = new Properties();\nList<String> interceptors = new ArrayList<>();\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"); // 拦截器1\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n```\n\n`AddTimeStampInterceptor` 和 `UpdateCounterInterceptor `这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 `org.apache.kafka.clients.producer.ProducerInterceptor `接口。该接口是 Kafka 提供的，里面有两个核心的方法。\n\n- `onSend`：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。\n- `onAcknowledgement`：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。\n\n\n\n消费者拦截器具体的实现类要实现 `org.apache.kafka.clients.consumer.ConsumerInterceptor` 接口，这里面也有两个核心方法。\n\n- `onConsume`：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。\n- `onCommit`：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。\n\n**场景**\n\nKafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。\n\n如：业务消息从被生产出来到最后被消费的平均总时长统计\n\n```java\n// 生产者\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor<String, String> {\n\n\n    private Jedis jedis; // 省略Jedis初始化\n\n\n    @Override\n    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n        jedis.incr(\"totalSentMessage\");\n        return record;\n    }\n\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<java.lang.String, ?> configs) {\n    }\n //消费者\n    \n\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {\n\n\n    private Jedis jedis; //省略Jedis初始化\n\n\n    @Override\n    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {\n        long lantency = 0L;\n        for (ConsumerRecord<String, String> record : records) {\n            lantency += (System.currentTimeMillis() - record.timestamp());\n        }\n        jedis.incrBy(\"totalLatency\", lantency);\n        long totalLatency = Long.parseLong(jedis.get(\"totalLatency\"));\n        long totalSentMsgs = Long.parseLong(jedis.get(\"totalSentMessage\"));\n        jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMsgs));\n        return records;\n    }\n\n\n    @Override\n    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n    }\n}\n```\n\n","source":"_posts/kafka拦截器.md","raw":"---\ntitle: kafka拦截器\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 19:18:48\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\nKafka 拦截器分为生产者拦截器和消费者拦截器。\n\n生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；\n\n而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。\n\n**使用**\n\n当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫` interceptor.classes`，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。\n\n```java\nProperties props = new Properties();\nList<String> interceptors = new ArrayList<>();\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"); // 拦截器1\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n```\n\n`AddTimeStampInterceptor` 和 `UpdateCounterInterceptor `这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 `org.apache.kafka.clients.producer.ProducerInterceptor `接口。该接口是 Kafka 提供的，里面有两个核心的方法。\n\n- `onSend`：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。\n- `onAcknowledgement`：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。\n\n\n\n消费者拦截器具体的实现类要实现 `org.apache.kafka.clients.consumer.ConsumerInterceptor` 接口，这里面也有两个核心方法。\n\n- `onConsume`：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。\n- `onCommit`：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。\n\n**场景**\n\nKafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。\n\n如：业务消息从被生产出来到最后被消费的平均总时长统计\n\n```java\n// 生产者\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor<String, String> {\n\n\n    private Jedis jedis; // 省略Jedis初始化\n\n\n    @Override\n    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n        jedis.incr(\"totalSentMessage\");\n        return record;\n    }\n\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<java.lang.String, ?> configs) {\n    }\n //消费者\n    \n\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {\n\n\n    private Jedis jedis; //省略Jedis初始化\n\n\n    @Override\n    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {\n        long lantency = 0L;\n        for (ConsumerRecord<String, String> record : records) {\n            lantency += (System.currentTimeMillis() - record.timestamp());\n        }\n        jedis.incrBy(\"totalLatency\", lantency);\n        long totalLatency = Long.parseLong(jedis.get(\"totalLatency\"));\n        long totalSentMsgs = Long.parseLong(jedis.get(\"totalSentMessage\"));\n        jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMsgs));\n        return records;\n    }\n\n\n    @Override\n    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n    }\n}\n```\n\n","slug":"kafka拦截器","published":1,"updated":"2021-04-01T23:01:49.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6n5000rq4ufbe04kcd9","content":"<p>Kafka 拦截器分为生产者拦截器和消费者拦截器。</p>\n<p>生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；</p>\n<p>而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</p>\n<p><strong>使用</strong></p>\n<p>当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫<code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nList<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> interceptors <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayList</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ninterceptors<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 拦截器1</span>\ninterceptors<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 拦截器2</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ProducerConfig<span class=\"token punctuation\">.</span>INTERCEPTOR_CLASSES_CONFIG<span class=\"token punctuation\">,</span> interceptors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>AddTimeStampInterceptor</code> 和 <code>UpdateCounterInterceptor</code>这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code>接口。该接口是 Kafka 提供的，里面有两个核心的方法。</p>\n<ul>\n<li><code>onSend</code>：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。</li>\n<li><code>onAcknowledgement</code>：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。</li>\n</ul>\n<p>消费者拦截器具体的实现类要实现 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里面也有两个核心方法。</p>\n<ul>\n<li><code>onConsume</code>：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。</li>\n<li><code>onCommit</code>：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。</li>\n</ul>\n<p><strong>场景</strong></p>\n<p>Kafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。</p>\n<p>如：业务消息从被生产出来到最后被消费的平均总时长统计</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 生产者</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">AvgLatencyProducerInterceptor</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ProducerInterceptor</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n\n\n    <span class=\"token keyword\">private</span> Jedis jedis<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 省略Jedis初始化</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> ProducerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token function\">onSend</span><span class=\"token punctuation\">(</span>ProducerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">incr</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalSentMessage\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> record<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onAcknowledgement</span><span class=\"token punctuation\">(</span>RecordMetadata metadata<span class=\"token punctuation\">,</span> Exception exception<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">configure</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>String<span class=\"token punctuation\">,</span> <span class=\"token operator\">?</span><span class=\"token operator\">></span> configs<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n <span class=\"token comment\" spellcheck=\"true\">//消费者</span>\n\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">AvgLatencyConsumerInterceptor</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ConsumerInterceptor</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n\n\n    <span class=\"token keyword\">private</span> Jedis jedis<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//省略Jedis初始化</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token function\">onConsume</span><span class=\"token punctuation\">(</span>ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">long</span> lantency <span class=\"token operator\">=</span> 0L<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            lantency <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span>System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">timestamp</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">incrBy</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalLatency\"</span><span class=\"token punctuation\">,</span> lantency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">long</span> totalLatency <span class=\"token operator\">=</span> Long<span class=\"token punctuation\">.</span><span class=\"token function\">parseLong</span><span class=\"token punctuation\">(</span>jedis<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalLatency\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">long</span> totalSentMsgs <span class=\"token operator\">=</span> Long<span class=\"token punctuation\">.</span><span class=\"token function\">parseLong</span><span class=\"token punctuation\">(</span>jedis<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalSentMessage\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"avgLatency\"</span><span class=\"token punctuation\">,</span> String<span class=\"token punctuation\">.</span><span class=\"token function\">valueOf</span><span class=\"token punctuation\">(</span>totalLatency <span class=\"token operator\">/</span> totalSentMsgs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> records<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onCommit</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">configure</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> <span class=\"token operator\">?</span><span class=\"token operator\">></span> configs<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>Kafka 拦截器分为生产者拦截器和消费者拦截器。</p>\n<p>生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；</p>\n<p>而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</p>\n<p><strong>使用</strong></p>\n<p>当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫<code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p>\n<pre><code class=\"java\">Properties props = new Properties();\nList&lt;String&gt; interceptors = new ArrayList&lt;&gt;();\ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1\ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</code></pre>\n<p><code>AddTimeStampInterceptor</code> 和 <code>UpdateCounterInterceptor</code>这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code>接口。该接口是 Kafka 提供的，里面有两个核心的方法。</p>\n<ul>\n<li><code>onSend</code>：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。</li>\n<li><code>onAcknowledgement</code>：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。</li>\n</ul>\n<p>消费者拦截器具体的实现类要实现 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里面也有两个核心方法。</p>\n<ul>\n<li><code>onConsume</code>：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。</li>\n<li><code>onCommit</code>：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。</li>\n</ul>\n<p><strong>场景</strong></p>\n<p>Kafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。</p>\n<p>如：业务消息从被生产出来到最后被消费的平均总时长统计</p>\n<pre><code class=\"java\">// 生产者\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor&lt;String, String&gt; {\n\n\n    private Jedis jedis; // 省略Jedis初始化\n\n\n    @Override\n    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) {\n        jedis.incr(&quot;totalSentMessage&quot;);\n        return record;\n    }\n\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map&lt;java.lang.String, ?&gt; configs) {\n    }\n //消费者\n\n\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; {\n\n\n    private Jedis jedis; //省略Jedis初始化\n\n\n    @Override\n    public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) {\n        long lantency = 0L;\n        for (ConsumerRecord&lt;String, String&gt; record : records) {\n            lantency += (System.currentTimeMillis() - record.timestamp());\n        }\n        jedis.incrBy(&quot;totalLatency&quot;, lantency);\n        long totalLatency = Long.parseLong(jedis.get(&quot;totalLatency&quot;));\n        long totalSentMsgs = Long.parseLong(jedis.get(&quot;totalSentMessage&quot;));\n        jedis.set(&quot;avgLatency&quot;, String.valueOf(totalLatency / totalSentMsgs));\n        return records;\n    }\n\n\n    @Override\n    public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map&lt;String, ?&gt; configs) {\n    }\n}</code></pre>\n"},{"title":"kafka授权","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T13:47:25.000Z","password":null,"summary":null,"_content":"\n授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。\n\nKafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。\n\n## kafka-acls 脚本\n\n```shell\n# Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic\n```\n\n","source":"_posts/kafka授权.md","raw":"---\ntitle: kafka授权\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 21:47:25\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。\n\nKafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。\n\n## kafka-acls 脚本\n\n```shell\n# Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic\n```\n\n","slug":"kafka授权","published":1,"updated":"2021-04-01T23:01:49.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6nf000uq4ufl288qzu0","content":"<p>授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。</p>\n<p>Kafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。</p>\n<h2 id=\"kafka-acls-脚本\"><a href=\"#kafka-acls-脚本\" class=\"headerlink\" title=\"kafka-acls 脚本\"></a>kafka-acls 脚本</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。</p>\n<p>Kafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。</p>\n<h2 id=\"kafka-acls-脚本\"><a href=\"#kafka-acls-脚本\" class=\"headerlink\" title=\"kafka-acls 脚本\"></a>kafka-acls 脚本</h2><pre><code class=\"shell\"># Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic &#39;*&#39; --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:&#39;*&#39; --allow-host &#39;*&#39; --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic</code></pre>\n"},{"title":"MVCC","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-14T12:14:27.000Z","password":null,"summary":null,"_content":"\n## MVCC\n\n多版本并发控制。\n\n> MVCC 只在 RC 和 RR 两个隔离级别下工作。\n>\n> 不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。\n\n## Undo log\n\nundo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。\n\nundo log 的另一个作用是 MVCC， MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。\n\n## MVCC 的实现原理\n\n通过保存数据在某个时间点的快照来实现的：\n\nInnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。\n\n## MVCC 的优势\n\nMVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。\n通过 MVCC，保证了事务 ACID 中的隔离性特性。","source":"_posts/MVCC.md","raw":"---\ntitle: MVCC\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-14 20:14:27\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## MVCC\n\n多版本并发控制。\n\n> MVCC 只在 RC 和 RR 两个隔离级别下工作。\n>\n> 不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。\n\n## Undo log\n\nundo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。\n\nundo log 的另一个作用是 MVCC， MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。\n\n## MVCC 的实现原理\n\n通过保存数据在某个时间点的快照来实现的：\n\nInnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。\n\n## MVCC 的优势\n\nMVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。\n通过 MVCC，保证了事务 ACID 中的隔离性特性。","slug":"MVCC","published":1,"updated":"2021-04-28T23:48:38.597Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6nn000xq4ufraqzm32h","content":"<h2 id=\"MVCC\"><a href=\"#MVCC\" class=\"headerlink\" title=\"MVCC\"></a>MVCC</h2><p>多版本并发控制。</p>\n<blockquote>\n<p>MVCC 只在 RC 和 RR 两个隔离级别下工作。</p>\n<p>不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p>\n</blockquote>\n<h2 id=\"Undo-log\"><a href=\"#Undo-log\" class=\"headerlink\" title=\"Undo log\"></a>Undo log</h2><p>undo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。</p>\n<p>undo log 的另一个作用是 MVCC， MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。</p>\n<h2 id=\"MVCC-的实现原理\"><a href=\"#MVCC-的实现原理\" class=\"headerlink\" title=\"MVCC 的实现原理\"></a>MVCC 的实现原理</h2><p>通过保存数据在某个时间点的快照来实现的：</p>\n<p>InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。</p>\n<h2 id=\"MVCC-的优势\"><a href=\"#MVCC-的优势\" class=\"headerlink\" title=\"MVCC 的优势\"></a>MVCC 的优势</h2><p>MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。<br>通过 MVCC，保证了事务 ACID 中的隔离性特性。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"MVCC\"><a href=\"#MVCC\" class=\"headerlink\" title=\"MVCC\"></a>MVCC</h2><p>多版本并发控制。</p>\n<blockquote>\n<p>MVCC 只在 RC 和 RR 两个隔离级别下工作。</p>\n<p>不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p>\n</blockquote>\n<h2 id=\"Undo-log\"><a href=\"#Undo-log\" class=\"headerlink\" title=\"Undo log\"></a>Undo log</h2><p>undo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。</p>\n<p>undo log 的另一个作用是 MVCC， MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。</p>\n<h2 id=\"MVCC-的实现原理\"><a href=\"#MVCC-的实现原理\" class=\"headerlink\" title=\"MVCC 的实现原理\"></a>MVCC 的实现原理</h2><p>通过保存数据在某个时间点的快照来实现的：</p>\n<p>InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。</p>\n<h2 id=\"MVCC-的优势\"><a href=\"#MVCC-的优势\" class=\"headerlink\" title=\"MVCC 的优势\"></a>MVCC 的优势</h2><p>MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。<br>通过 MVCC，保证了事务 ACID 中的隔离性特性。</p>\n"},{"title":"kafka消息丢失","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T11:13:33.000Z","password":null,"summary":null,"_content":"\nkafka 只对“已提交”的消息做有限度的持久化保证。\n\n## 避免消息丢失\n\n**生产者**\n\n- 不要使用 `producer.send(msg)`，而要使用` producer.send(msg, callback)`。一定要使用带有回调通知的 send 方法。\n- 设置 `acks = all`。`acks `是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。\n- 设置 `retries` 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 `retries > 0` 的 Producer 能够自动重试消息发送，避免消息丢失。\n\n**broker**\n\n- 设置 `unclean.leader.election.enable = false`。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。\n- 设置 `replication.factor >= 3`。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。\n- 设置 `min.insync.replicas > 1`。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。\n- 确保 `replication.factor > min.insync.replicas`。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 `replication.factor = min.insync.replicas + 1`。\n\n**消费者**\n\n- 确保消息消费完成再提交。Consumer 端有个参数 `enable.auto.commit`，最好把它设置成 `false`，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的\n\n","source":"_posts/kafka消息丢失.md","raw":"---\ntitle: kafka消息丢失\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 19:13:33\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\nkafka 只对“已提交”的消息做有限度的持久化保证。\n\n## 避免消息丢失\n\n**生产者**\n\n- 不要使用 `producer.send(msg)`，而要使用` producer.send(msg, callback)`。一定要使用带有回调通知的 send 方法。\n- 设置 `acks = all`。`acks `是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。\n- 设置 `retries` 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 `retries > 0` 的 Producer 能够自动重试消息发送，避免消息丢失。\n\n**broker**\n\n- 设置 `unclean.leader.election.enable = false`。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。\n- 设置 `replication.factor >= 3`。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。\n- 设置 `min.insync.replicas > 1`。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。\n- 确保 `replication.factor > min.insync.replicas`。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 `replication.factor = min.insync.replicas + 1`。\n\n**消费者**\n\n- 确保消息消费完成再提交。Consumer 端有个参数 `enable.auto.commit`，最好把它设置成 `false`，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的\n\n","slug":"kafka消息丢失","published":1,"updated":"2021-05-11T11:33:29.544Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6nt0010q4uffy4kz589","content":"<p>kafka 只对“已提交”的消息做有限度的持久化保证。</p>\n<h2 id=\"避免消息丢失\"><a href=\"#避免消息丢失\" class=\"headerlink\" title=\"避免消息丢失\"></a>避免消息丢失</h2><p><strong>生产者</strong></p>\n<ul>\n<li>不要使用 <code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>。一定要使用带有回调通知的 send 方法。</li>\n<li>设置 <code>acks = all</code>。<code>acks</code>是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>\n<li>设置 <code>retries</code> 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</li>\n</ul>\n<p><strong>broker</strong></p>\n<ul>\n<li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li>\n<li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li>\n<li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>\n<li>确保 <code>replication.factor &gt; min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li>\n</ul>\n<p><strong>消费者</strong></p>\n<ul>\n<li>确保消息消费完成再提交。Consumer 端有个参数 <code>enable.auto.commit</code>，最好把它设置成 <code>false</code>，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>kafka 只对“已提交”的消息做有限度的持久化保证。</p>\n<h2 id=\"避免消息丢失\"><a href=\"#避免消息丢失\" class=\"headerlink\" title=\"避免消息丢失\"></a>避免消息丢失</h2><p><strong>生产者</strong></p>\n<ul>\n<li>不要使用 <code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>。一定要使用带有回调通知的 send 方法。</li>\n<li>设置 <code>acks = all</code>。<code>acks</code>是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>\n<li>设置 <code>retries</code> 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</li>\n</ul>\n<p><strong>broker</strong></p>\n<ul>\n<li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li>\n<li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li>\n<li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>\n<li>确保 <code>replication.factor &gt; min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li>\n</ul>\n<p><strong>消费者</strong></p>\n<ul>\n<li>确保消息消费完成再提交。Consumer 端有个参数 <code>enable.auto.commit</code>，最好把它设置成 <code>false</code>，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的</li>\n</ul>\n"},{"title":"kafka消费者","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T13:07:18.000Z","password":null,"summary":null,"_content":"\n## 消费者组\n\nConsumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\n\n- Consumer Group 下可以有一个或多个 Consumer 实例。\n- Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。\n- 单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。\n- 理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数\n\n### 重平衡\n\nRebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。\n\n协调者（Coordinator），负责为 Group 执行 **Rebalance 以及提供位移管理和组成员管理**等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。\n\n**Consumer Group 确定 Coordinator 所在的 Broker** \n\n第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：`partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)`。\n\n第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。\n\n注： Java Consumer API，能够自动发现并连接正确的 Coordinator。\n\n**Rebalance 触发条件**\n\n- 组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。\n- 订阅主题数发生变更。\n- 订阅主题的分区数发生变更。\n\n**重平衡的通知**\n\n通过心跳线程来完成。\n\n- 0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 `KafkaConsumer.poll `方法的线程。\n- 0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。\n\n**Rebalance影响**\n\n1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成\n\n2、Rebalance 效率不高，需要重新分配所有分区\n\n3、Rebalance很慢\n\n**消费者组状态机**\n\n\n![](state.jpeg)\n\n![](transport.jpg)\n\n**消费者端重平衡流程**\n\n- 加入组\n\n向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。\n\n协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。\n\n- 等待领导者消费者（Leader Consumer）分配方案\n\n领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。\n\n其他成员也会向协调者发送 SyncGroup 请求.\n\n协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。\n\n**Broker端重平衡流程**\n\n场景一：新成员入组\n\n![](newadd.jpg)\n\n场景二：组成员主动离组。\n\n![](leavegroup.jpg)\n\n场景三：组成员崩溃离组\n\n![](comsumedown.jpg)\n\n**避免 Rebalance**\n\n主要方法：**避免组成员数发生减少的情况**。\n\nConsumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。`session.timeout.ms `+ `heartbeat.interval.ms`\n\nConsumer 端应用程序两次调用` poll` 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。`max.poll.interval.ms`\n\n## 位移主题\n\n当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是`offsets.topic.num.partitions` 50，副本数是`offsets.topic.replication.factor` 3。\n\n1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 `__consumer_offsets `中。\n\n位移主题消息的 Key 中格式：<Group ID，主题名，分区号 >，消息体保存了**位移值**和位移提交的元数据，诸如时间戳和用户自定义的数据等。\n\n2、保存 Consumer Group 相关信息的消息\n\n3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息\n\n**消费位移**\n\n记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。\n\n提交位移的配置：`enable.auto.commit` + `auto.commit.interval.ms `控制。\n\n### **自动提交位移**\n\n- Kafka 会保证在开始调用 `poll` 方法时，提交上次 `poll` 返回的所有消息。\n\n- 从顺序上来说，`poll `方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。\n\n- 问题：重平衡出现时可能会出现重复消费\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\nprops.put(\"enable.auto.commit\", \"true\");\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", \n                          record.offset(), record.key(), record.value());\n}\n```\n\n### 手动提交位移\n\n**手动提交，需要将 `commitSync` 和 `commitAsync` 组合使用。**\n\n`commitSync()`会提交 `poll() `返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。\n\n缺陷：调用 `commitSync() `时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。\n\n```java\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}\n```\n\n`commitAsync()`，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数`callback`，供你实现提交之后的逻辑，比如记录日志或处理异常等。\n缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。\n\n```java\ntry {\n    while(true) {\n        ConsumerRecords<String, String> records =\n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n`commitSync(Map<TopicPartition, OffsetAndMetadata>) `和 `commitAsync(Map<TopicPartition, OffsetAndMetadata>)`。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 `OffsetAndMetadata` 对象，保存位移数据。\n\n```java\nprivate Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1)；\n        if（count % 100 == 0）\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n         count++;\n    }\n}\n```\n\n### CommitFailedException\n\n提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例\n**解决**\n\n- 缩短单条消息处理的时间\n- 增加 Consumer 端允许下游系统消费一批消息的最大时长`max.poll.interval.ms` \n- 减少下游系统一次性消费的消息总数`max.poll.records `\n- 下游系统使用多线程来加速消费\n\n### **过期消息删除**\n\nkafka 使用 Compact 策略来删除位移主题中的过期消息。\n\nKafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。\n\n对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。\n\n### 重设消费者组位移\n\n由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。\n\n#### 重设位移策略\n\n![](stragey.jpg)\n\n#### 重设方式\n\n通过消费者 API 来实现。\n\n```java\nProperties consumerProperties = new Properties();\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); //禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\nString topic = \"test\";  // 要重设位移的Kafka主题 \ntry (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    consumer.poll(0);\n    consumer.seekToBeginning(\n        consumer.partitionsFor(topic).stream().map(\n            partitionInfo -> new TopicPartition(topic, partitionInfo.partition())\n   \t\t).collect(Collectors.toList()));// 需要一次性构造主题的所有分区对象\n} \n// Current\nconsumer.partitionsFor(topic).stream().map(\n    info -> new TopicPartition(topic, info.partition())\n  ).forEach(tp -> {\n  long committedOffset = consumer.committed(tp).offset();\n  consumer.seek(tp, committedOffset);\n});\n//Specified-Offset\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n  TopicPartition tp = new TopicPartition(topic, info.partition());\n  consumer.seek(tp, targetOffset);\n}\n//Shift-By-N \nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n         TopicPartition tp = new TopicPartition(topic, info.partition());\n  // 假设向前跳123条消息\n         long targetOffset = consumer.committed(tp).offset() + 123L; \n         consumer.seek(tp, targetOffset);\n}\n//DateTime \nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0).toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\nMap<TopicPartition, Long> timeToSearch = \n         consumer.partitionsFor(topic).stream().map(info -> \n  new TopicPartition(topic, info.partition()))\n  .collect(Collectors.toMap(Function.identity(), tp -> ts));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n  consumer.offsetsForTimes(timeToSearch).entrySet()) {\nconsumer.seek(entry.getKey(), entry.getValue().offset());\n}\n//Duration\n\nMap<TopicPartition, Long> timeToSearch = consumer.partitionsFor(topic).stream()\n         .map(info -> new TopicPartition(topic, info.partition()))\n         .collect(Collectors.toMap(Function.identity(), tp -> System.currentTimeMillis() - 30 * 1000  * 60));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n     consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}\n```\n\n通过 kafka-consumer-groups 命令行脚本来实现\n\n```shell\n# to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute\n```\n\n##  独立消费者\n\n每个消费者实例都是独立工作的，彼此之间毫无联系。\n\n## KafkaConsumer \n\n用户主线程，启动 Consumer 应用程序 main 方法的那个线程。\n\n心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）\n\n### 多线程方案\n\nKafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 `ConcurrentModificationException `异常\n\n1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程\n\n![](plan1.jpg)\n\n```java\n\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n\n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(\"topic\"));\n             while (!closed.get()) {\n      ConsumerRecords records = \n        consumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n\n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}\n```\n\n2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。\n\n![](plan2.jpg)\n\n```java\n\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n\n\nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n  workerNum,\n  workerNum,\n  0L, \n  TimeUnit.MILLISECONDS,\n  new ArrayBlockingQueue<>(1000), \n  new ThreadPoolExecutor.CallerRunsPolicy()\n);\n\n\n...\nwhile (true)  {\n  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n  for (final ConsumerRecord record : records) {\n    executors.submit(new Worker(record));\n  }\n}\n..\n```\n\n**方案比较**\n\n![](compare.jpg)\n\n### TCP 连接\n\n**TCP 连接是在调用 `KafkaConsumer.poll `方法时被创建的。**\n\n1.发起 `FindCoordinator` 请求时。\n\n当消费者程序首次启动调用 `poll `方法时，它需要向 Kafka 集群发送一个名为 `FindCoordinator` 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。\n\n2.连接协调者时。\n\n消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。\n\n3.消费数据时。\n\n消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP\n\n**消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。**\n\n1、手动调用` KafkaConsumer.close() `方法，或者是执行 Kill 命令\n\n2、Kafka 自动关闭是由消费者端参数 `connection.max.idle.ms` 控制的，默认值是 9 分钟\n\n注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。\n\n## 消费进度\n\n消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。\n\n**监控方法**\n\n1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。\n\n```shell\n# Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称>\n```\n\n![](groups_shell.png)\n\n2、使用 Kafka Java Consumer API 编程。\n\n```java\n\npublic static Map<TopicPartition, Long> lagOf(String groupID, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n        try {\n            //获取订阅分区的最新消息位移\n            Map<TopicPartition, OffsetAndMetadata> consumedOffsets = \n                result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n                //最新消费消息的位移\n                Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedOffsets.keySet()); \n                return endOffsets.entrySet().stream().collect(Collectors.toMap(\n                    entry -> entry.getKey(),\n                    entry -> entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            // 处理中断异常\n            // ...\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            // 处理ExecutionException\n            // ...\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(\"Timed out when getting lag for consumer group \" + groupID);\n        }\n    }\n}\n```\n\n3、使用 Kafka 自带的 JMX 监控指标。\n\nKafka 消费者的JMX 指标 `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”`，其中：`records-lag-max` 和 `records-lead-min`，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。\n\n **Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。**\n\n一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。\n\nKafka 消费者还在分区级别提供了 JMX 指标，用于监控**分区级别的 Lag 和 Lead 值**。JMX 名称为：`kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”`","source":"_posts/kafka消费者.md","raw":"---\ntitle: kafka消费者\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 21:07:18\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 消费者组\n\nConsumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\n\n- Consumer Group 下可以有一个或多个 Consumer 实例。\n- Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。\n- 单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。\n- 理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数\n\n### 重平衡\n\nRebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。\n\n协调者（Coordinator），负责为 Group 执行 **Rebalance 以及提供位移管理和组成员管理**等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。\n\n**Consumer Group 确定 Coordinator 所在的 Broker** \n\n第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：`partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)`。\n\n第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。\n\n注： Java Consumer API，能够自动发现并连接正确的 Coordinator。\n\n**Rebalance 触发条件**\n\n- 组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。\n- 订阅主题数发生变更。\n- 订阅主题的分区数发生变更。\n\n**重平衡的通知**\n\n通过心跳线程来完成。\n\n- 0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 `KafkaConsumer.poll `方法的线程。\n- 0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。\n\n**Rebalance影响**\n\n1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成\n\n2、Rebalance 效率不高，需要重新分配所有分区\n\n3、Rebalance很慢\n\n**消费者组状态机**\n\n\n![](state.jpeg)\n\n![](transport.jpg)\n\n**消费者端重平衡流程**\n\n- 加入组\n\n向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。\n\n协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。\n\n- 等待领导者消费者（Leader Consumer）分配方案\n\n领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。\n\n其他成员也会向协调者发送 SyncGroup 请求.\n\n协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。\n\n**Broker端重平衡流程**\n\n场景一：新成员入组\n\n![](newadd.jpg)\n\n场景二：组成员主动离组。\n\n![](leavegroup.jpg)\n\n场景三：组成员崩溃离组\n\n![](comsumedown.jpg)\n\n**避免 Rebalance**\n\n主要方法：**避免组成员数发生减少的情况**。\n\nConsumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。`session.timeout.ms `+ `heartbeat.interval.ms`\n\nConsumer 端应用程序两次调用` poll` 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。`max.poll.interval.ms`\n\n## 位移主题\n\n当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是`offsets.topic.num.partitions` 50，副本数是`offsets.topic.replication.factor` 3。\n\n1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 `__consumer_offsets `中。\n\n位移主题消息的 Key 中格式：<Group ID，主题名，分区号 >，消息体保存了**位移值**和位移提交的元数据，诸如时间戳和用户自定义的数据等。\n\n2、保存 Consumer Group 相关信息的消息\n\n3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息\n\n**消费位移**\n\n记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。\n\n提交位移的配置：`enable.auto.commit` + `auto.commit.interval.ms `控制。\n\n### **自动提交位移**\n\n- Kafka 会保证在开始调用 `poll` 方法时，提交上次 `poll` 返回的所有消息。\n\n- 从顺序上来说，`poll `方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。\n\n- 问题：重平衡出现时可能会出现重复消费\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\nprops.put(\"enable.auto.commit\", \"true\");\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", \n                          record.offset(), record.key(), record.value());\n}\n```\n\n### 手动提交位移\n\n**手动提交，需要将 `commitSync` 和 `commitAsync` 组合使用。**\n\n`commitSync()`会提交 `poll() `返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。\n\n缺陷：调用 `commitSync() `时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。\n\n```java\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}\n```\n\n`commitAsync()`，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数`callback`，供你实现提交之后的逻辑，比如记录日志或处理异常等。\n缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。\n\n```java\ntry {\n    while(true) {\n        ConsumerRecords<String, String> records =\n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n`commitSync(Map<TopicPartition, OffsetAndMetadata>) `和 `commitAsync(Map<TopicPartition, OffsetAndMetadata>)`。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 `OffsetAndMetadata` 对象，保存位移数据。\n\n```java\nprivate Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1)；\n        if（count % 100 == 0）\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n         count++;\n    }\n}\n```\n\n### CommitFailedException\n\n提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例\n**解决**\n\n- 缩短单条消息处理的时间\n- 增加 Consumer 端允许下游系统消费一批消息的最大时长`max.poll.interval.ms` \n- 减少下游系统一次性消费的消息总数`max.poll.records `\n- 下游系统使用多线程来加速消费\n\n### **过期消息删除**\n\nkafka 使用 Compact 策略来删除位移主题中的过期消息。\n\nKafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。\n\n对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。\n\n### 重设消费者组位移\n\n由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。\n\n#### 重设位移策略\n\n![](stragey.jpg)\n\n#### 重设方式\n\n通过消费者 API 来实现。\n\n```java\nProperties consumerProperties = new Properties();\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); //禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\nString topic = \"test\";  // 要重设位移的Kafka主题 \ntry (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    consumer.poll(0);\n    consumer.seekToBeginning(\n        consumer.partitionsFor(topic).stream().map(\n            partitionInfo -> new TopicPartition(topic, partitionInfo.partition())\n   \t\t).collect(Collectors.toList()));// 需要一次性构造主题的所有分区对象\n} \n// Current\nconsumer.partitionsFor(topic).stream().map(\n    info -> new TopicPartition(topic, info.partition())\n  ).forEach(tp -> {\n  long committedOffset = consumer.committed(tp).offset();\n  consumer.seek(tp, committedOffset);\n});\n//Specified-Offset\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n  TopicPartition tp = new TopicPartition(topic, info.partition());\n  consumer.seek(tp, targetOffset);\n}\n//Shift-By-N \nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n         TopicPartition tp = new TopicPartition(topic, info.partition());\n  // 假设向前跳123条消息\n         long targetOffset = consumer.committed(tp).offset() + 123L; \n         consumer.seek(tp, targetOffset);\n}\n//DateTime \nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0).toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\nMap<TopicPartition, Long> timeToSearch = \n         consumer.partitionsFor(topic).stream().map(info -> \n  new TopicPartition(topic, info.partition()))\n  .collect(Collectors.toMap(Function.identity(), tp -> ts));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n  consumer.offsetsForTimes(timeToSearch).entrySet()) {\nconsumer.seek(entry.getKey(), entry.getValue().offset());\n}\n//Duration\n\nMap<TopicPartition, Long> timeToSearch = consumer.partitionsFor(topic).stream()\n         .map(info -> new TopicPartition(topic, info.partition()))\n         .collect(Collectors.toMap(Function.identity(), tp -> System.currentTimeMillis() - 30 * 1000  * 60));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n     consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}\n```\n\n通过 kafka-consumer-groups 命令行脚本来实现\n\n```shell\n# to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute\n```\n\n##  独立消费者\n\n每个消费者实例都是独立工作的，彼此之间毫无联系。\n\n## KafkaConsumer \n\n用户主线程，启动 Consumer 应用程序 main 方法的那个线程。\n\n心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）\n\n### 多线程方案\n\nKafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 `ConcurrentModificationException `异常\n\n1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程\n\n![](plan1.jpg)\n\n```java\n\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n\n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(\"topic\"));\n             while (!closed.get()) {\n      ConsumerRecords records = \n        consumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n\n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}\n```\n\n2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。\n\n![](plan2.jpg)\n\n```java\n\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n\n\nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n  workerNum,\n  workerNum,\n  0L, \n  TimeUnit.MILLISECONDS,\n  new ArrayBlockingQueue<>(1000), \n  new ThreadPoolExecutor.CallerRunsPolicy()\n);\n\n\n...\nwhile (true)  {\n  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n  for (final ConsumerRecord record : records) {\n    executors.submit(new Worker(record));\n  }\n}\n..\n```\n\n**方案比较**\n\n![](compare.jpg)\n\n### TCP 连接\n\n**TCP 连接是在调用 `KafkaConsumer.poll `方法时被创建的。**\n\n1.发起 `FindCoordinator` 请求时。\n\n当消费者程序首次启动调用 `poll `方法时，它需要向 Kafka 集群发送一个名为 `FindCoordinator` 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。\n\n2.连接协调者时。\n\n消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。\n\n3.消费数据时。\n\n消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP\n\n**消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。**\n\n1、手动调用` KafkaConsumer.close() `方法，或者是执行 Kill 命令\n\n2、Kafka 自动关闭是由消费者端参数 `connection.max.idle.ms` 控制的，默认值是 9 分钟\n\n注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。\n\n## 消费进度\n\n消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。\n\n**监控方法**\n\n1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。\n\n```shell\n# Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称>\n```\n\n![](groups_shell.png)\n\n2、使用 Kafka Java Consumer API 编程。\n\n```java\n\npublic static Map<TopicPartition, Long> lagOf(String groupID, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n        try {\n            //获取订阅分区的最新消息位移\n            Map<TopicPartition, OffsetAndMetadata> consumedOffsets = \n                result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n                //最新消费消息的位移\n                Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedOffsets.keySet()); \n                return endOffsets.entrySet().stream().collect(Collectors.toMap(\n                    entry -> entry.getKey(),\n                    entry -> entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            // 处理中断异常\n            // ...\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            // 处理ExecutionException\n            // ...\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(\"Timed out when getting lag for consumer group \" + groupID);\n        }\n    }\n}\n```\n\n3、使用 Kafka 自带的 JMX 监控指标。\n\nKafka 消费者的JMX 指标 `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”`，其中：`records-lag-max` 和 `records-lead-min`，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。\n\n **Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。**\n\n一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。\n\nKafka 消费者还在分区级别提供了 JMX 指标，用于监控**分区级别的 Lag 和 Lead 值**。JMX 名称为：`kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”`","slug":"kafka消费者","published":1,"updated":"2021-04-27T11:50:20.338Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ny0013q4uf2y8staid","content":"<h2 id=\"消费者组\"><a href=\"#消费者组\" class=\"headerlink\" title=\"消费者组\"></a>消费者组</h2><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。</p>\n<ul>\n<li>Consumer Group 下可以有一个或多个 Consumer 实例。</li>\n<li>Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li>\n<li>单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。</li>\n<li>理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数</li>\n</ul>\n<h3 id=\"重平衡\"><a href=\"#重平衡\" class=\"headerlink\" title=\"重平衡\"></a>重平衡</h3><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p>\n<p>协调者（Coordinator），负责为 Group 执行 <strong>Rebalance 以及提供位移管理和组成员管理</strong>等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。</p>\n<p><strong>Consumer Group 确定 Coordinator 所在的 Broker</strong> </p>\n<p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p>\n<p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p>\n<p>注： Java Consumer API，能够自动发现并连接正确的 Coordinator。</p>\n<p><strong>Rebalance 触发条件</strong></p>\n<ul>\n<li>组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。</li>\n<li>订阅主题数发生变更。</li>\n<li>订阅主题的分区数发生变更。</li>\n</ul>\n<p><strong>重平衡的通知</strong></p>\n<p>通过心跳线程来完成。</p>\n<ul>\n<li>0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 <code>KafkaConsumer.poll</code>方法的线程。</li>\n<li>0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。</li>\n</ul>\n<p><strong>Rebalance影响</strong></p>\n<p>1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成</p>\n<p>2、Rebalance 效率不高，需要重新分配所有分区</p>\n<p>3、Rebalance很慢</p>\n<p><strong>消费者组状态机</strong></p>\n<p><img src=\"state.jpeg\" alt></p>\n<p><img src=\"transport.jpg\" alt></p>\n<p><strong>消费者端重平衡流程</strong></p>\n<ul>\n<li>加入组</li>\n</ul>\n<p>向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。</p>\n<p>协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。</p>\n<ul>\n<li>等待领导者消费者（Leader Consumer）分配方案</li>\n</ul>\n<p>领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。</p>\n<p>其他成员也会向协调者发送 SyncGroup 请求.</p>\n<p>协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。</p>\n<p><strong>Broker端重平衡流程</strong></p>\n<p>场景一：新成员入组</p>\n<p><img src=\"newadd.jpg\" alt></p>\n<p>场景二：组成员主动离组。</p>\n<p><img src=\"leavegroup.jpg\" alt></p>\n<p>场景三：组成员崩溃离组</p>\n<p><img src=\"comsumedown.jpg\" alt></p>\n<p><strong>避免 Rebalance</strong></p>\n<p>主要方法：<strong>避免组成员数发生减少的情况</strong>。</p>\n<p>Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。<code>session.timeout.ms</code>+ <code>heartbeat.interval.ms</code></p>\n<p>Consumer 端应用程序两次调用<code>poll</code> 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。<code>max.poll.interval.ms</code></p>\n<h2 id=\"位移主题\"><a href=\"#位移主题\" class=\"headerlink\" title=\"位移主题\"></a>位移主题</h2><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是<code>offsets.topic.num.partitions</code> 50，副本数是<code>offsets.topic.replication.factor</code> 3。</p>\n<p>1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 <code>__consumer_offsets</code>中。</p>\n<p>位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等。</p>\n<p>2、保存 Consumer Group 相关信息的消息</p>\n<p>3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息</p>\n<p><strong>消费位移</strong></p>\n<p>记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。</p>\n<p>提交位移的配置：<code>enable.auto.commit</code> + <code>auto.commit.interval.ms</code>控制。</p>\n<h3 id=\"自动提交位移\"><a href=\"#自动提交位移\" class=\"headerlink\" title=\"自动提交位移\"></a><strong>自动提交位移</strong></h3><ul>\n<li><p>Kafka 会保证在开始调用 <code>poll</code> 方法时，提交上次 <code>poll</code> 返回的所有消息。</p>\n</li>\n<li><p>从顺序上来说，<code>poll</code>方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。</p>\n</li>\n<li><p>问题：重平衡出现时可能会出现重复消费</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"bootstrap.servers\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"localhost:9092\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"group.id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"test\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"enable.auto.commit\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"auto.commit.interval.ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2000\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"key.deserializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringDeserializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"value.deserializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringDeserializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nKafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"foo\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"bar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"offset = %d, key = %s, value = %s%n\"</span><span class=\"token punctuation\">,</span> \n                          record<span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">key</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">value</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"手动提交位移\"><a href=\"#手动提交位移\" class=\"headerlink\" title=\"手动提交位移\"></a>手动提交位移</h3><p><strong>手动提交，需要将 <code>commitSync</code> 和 <code>commitAsync</code> 组合使用。</strong></p>\n<p><code>commitSync()</code>会提交 <code>poll()</code>返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。</p>\n<p>缺陷：调用 <code>commitSync()</code>时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">process</span><span class=\"token punctuation\">(</span>records<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理消息</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitSync</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">CommitFailedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token function\">handle</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理提交失败异常</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>commitAsync()</code>，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数<code>callback</code>，供你实现提交之后的逻辑，比如记录日志或处理异常等。<br>缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span>\n            consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">process</span><span class=\"token punctuation\">(</span>records<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理消息</span>\n        <span class=\"token function\">commitAysnc</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 使用异步提交规避阻塞</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span><span class=\"token punctuation\">(</span>Exception e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token function\">handle</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理异常</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitSync</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 最后一次提交使用同步阻塞式提交</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>和 <code>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 <code>OffsetAndMetadata</code> 对象，保存位移数据。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">private</span> Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">int</span> count <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n……\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record<span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token function\">process</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">// 处理消息</span>\n        offsets<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">.</span><span class=\"token function\">topic</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token keyword\">new</span> <span class=\"token class-name\">OffsetAndMetadata</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>；\n        <span class=\"token keyword\">if</span>（count <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span>）\n            consumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitAsync</span><span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">,</span> null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 回调处理逻辑是null</span>\n         count<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"CommitFailedException\"><a href=\"#CommitFailedException\" class=\"headerlink\" title=\"CommitFailedException\"></a>CommitFailedException</h3><p>提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例<br><strong>解决</strong></p>\n<ul>\n<li>缩短单条消息处理的时间</li>\n<li>增加 Consumer 端允许下游系统消费一批消息的最大时长<code>max.poll.interval.ms</code> </li>\n<li>减少下游系统一次性消费的消息总数<code>max.poll.records</code></li>\n<li>下游系统使用多线程来加速消费</li>\n</ul>\n<h3 id=\"过期消息删除\"><a href=\"#过期消息删除\" class=\"headerlink\" title=\"过期消息删除\"></a><strong>过期消息删除</strong></h3><p>kafka 使用 Compact 策略来删除位移主题中的过期消息。</p>\n<p>Kafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。</p>\n<p>对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p>\n<h3 id=\"重设消费者组位移\"><a href=\"#重设消费者组位移\" class=\"headerlink\" title=\"重设消费者组位移\"></a>重设消费者组位移</h3><p>由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。</p>\n<h4 id=\"重设位移策略\"><a href=\"#重设位移策略\" class=\"headerlink\" title=\"重设位移策略\"></a>重设位移策略</h4><p><img src=\"stragey.jpg\" alt></p>\n<h4 id=\"重设方式\"><a href=\"#重设方式\" class=\"headerlink\" title=\"重设方式\"></a>重设方式</h4><p>通过消费者 API 来实现。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties consumerProperties <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//禁止自动提交位移</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>GROUP_ID_CONFIG<span class=\"token punctuation\">,</span> groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>AUTO_OFFSET_RESET_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token string\">\"earliest\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> brokerList<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\nString topic <span class=\"token operator\">=</span> <span class=\"token string\">\"test\"</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">// 要重设位移的Kafka主题 </span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>consumerProperties<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Collections<span class=\"token punctuation\">.</span><span class=\"token function\">singleton</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seekToBeginning</span><span class=\"token punctuation\">(</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>\n            partitionInfo <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> partitionInfo<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n           <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toList</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\" spellcheck=\"true\">// 需要一次性构造主题的所有分区对象</span>\n<span class=\"token punctuation\">}</span> \n<span class=\"token comment\" spellcheck=\"true\">// Current</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>\n    info <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">forEach</span><span class=\"token punctuation\">(</span>tp <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">long</span> committedOffset <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">committed</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> committedOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">//Specified-Offset</span>\n<span class=\"token keyword\">long</span> targetOffset <span class=\"token operator\">=</span> 1234L<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>PartitionInfo info <span class=\"token operator\">:</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  TopicPartition tp <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> targetOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//Shift-By-N </span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>PartitionInfo info <span class=\"token operator\">:</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         TopicPartition tp <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\" spellcheck=\"true\">// 假设向前跳123条消息</span>\n         <span class=\"token keyword\">long</span> targetOffset <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">committed</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> 123L<span class=\"token punctuation\">;</span> \n         consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> targetOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//DateTime </span>\n<span class=\"token keyword\">long</span> ts <span class=\"token operator\">=</span> LocalDateTime<span class=\"token punctuation\">.</span><span class=\"token function\">of</span><span class=\"token punctuation\">(</span><span class=\"token number\">2019</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">toInstant</span><span class=\"token punctuation\">(</span>ZoneOffset<span class=\"token punctuation\">.</span><span class=\"token function\">ofHours</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">toEpochMilli</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nMap<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> timeToSearch <span class=\"token operator\">=</span> \n         consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>info <span class=\"token operator\">-</span><span class=\"token operator\">></span> \n  <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toMap</span><span class=\"token punctuation\">(</span>Function<span class=\"token punctuation\">.</span><span class=\"token function\">identity</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tp <span class=\"token operator\">-</span><span class=\"token operator\">></span> ts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Map<span class=\"token punctuation\">.</span>Entry<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndTimestamp<span class=\"token operator\">></span> entry <span class=\"token operator\">:</span> \n  consumer<span class=\"token punctuation\">.</span><span class=\"token function\">offsetsForTimes</span><span class=\"token punctuation\">(</span>timeToSearch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">entrySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//Duration</span>\n\nMap<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> timeToSearch <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n         <span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>info <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n         <span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toMap</span><span class=\"token punctuation\">(</span>Function<span class=\"token punctuation\">.</span><span class=\"token function\">identity</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tp <span class=\"token operator\">-</span><span class=\"token operator\">></span> System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">30</span> <span class=\"token operator\">*</span> <span class=\"token number\">1000</span>  <span class=\"token operator\">*</span> <span class=\"token number\">60</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Map<span class=\"token punctuation\">.</span>Entry<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndTimestamp<span class=\"token operator\">></span> entry <span class=\"token operator\">:</span> \n     consumer<span class=\"token punctuation\">.</span><span class=\"token function\">offsetsForTimes</span><span class=\"token punctuation\">(</span>timeToSearch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">entrySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>通过 kafka-consumer-groups 命令行脚本来实现</p>\n<pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"独立消费者\"><a href=\"#独立消费者\" class=\"headerlink\" title=\"独立消费者\"></a>独立消费者</h2><p>每个消费者实例都是独立工作的，彼此之间毫无联系。</p>\n<h2 id=\"KafkaConsumer\"><a href=\"#KafkaConsumer\" class=\"headerlink\" title=\"KafkaConsumer\"></a>KafkaConsumer</h2><p>用户主线程，启动 Consumer 应用程序 main 方法的那个线程。</p>\n<p>心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）</p>\n<h3 id=\"多线程方案\"><a href=\"#多线程方案\" class=\"headerlink\" title=\"多线程方案\"></a>多线程方案</h3><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p>\n<p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p>\n<p><img src=\"plan1.jpg\" alt></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">KafkaConsumerRunner</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Runnable</span> <span class=\"token punctuation\">{</span>\n     <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> AtomicBoolean closed <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AtomicBoolean</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> KafkaConsumer consumer<span class=\"token punctuation\">;</span>\n\n     <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n             consumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"topic\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n             <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>closed<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      ConsumerRecords records <span class=\"token operator\">=</span> \n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofMillis</span><span class=\"token punctuation\">(</span><span class=\"token number\">10000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                 <span class=\"token comment\" spellcheck=\"true\">//  执行消息处理逻辑</span>\n             <span class=\"token punctuation\">}</span>\n         <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">WakeupException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n             <span class=\"token comment\" spellcheck=\"true\">// Ignore exception if closing</span>\n             <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>closed<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throw</span> e<span class=\"token punctuation\">;</span>\n         <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n             consumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         <span class=\"token punctuation\">}</span>\n     <span class=\"token punctuation\">}</span>\n\n     <span class=\"token comment\" spellcheck=\"true\">// Shutdown hook which can be called from a separate thread</span>\n     <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">shutdown</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         closed<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         consumer<span class=\"token punctuation\">.</span><span class=\"token function\">wakeup</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p>\n<p><img src=\"plan2.jpg\" alt></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">private</span> ExecutorService executors<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n\n<span class=\"token keyword\">private</span> <span class=\"token keyword\">int</span> workerNum <span class=\"token operator\">=</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">;</span>\nexecutors <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ThreadPoolExecutor</span><span class=\"token punctuation\">(</span>\n  workerNum<span class=\"token punctuation\">,</span>\n  workerNum<span class=\"token punctuation\">,</span>\n  0L<span class=\"token punctuation\">,</span> \n  TimeUnit<span class=\"token punctuation\">.</span>MILLISECONDS<span class=\"token punctuation\">,</span>\n  <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayBlockingQueue</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> \n  <span class=\"token keyword\">new</span> <span class=\"token class-name\">ThreadPoolExecutor<span class=\"token punctuation\">.</span>CallerRunsPolicy</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span>  <span class=\"token punctuation\">{</span>\n  ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> ConsumerRecord record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    executors<span class=\"token punctuation\">.</span><span class=\"token function\">submit</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">Worker</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>方案比较</strong></p>\n<p><img src=\"compare.jpg\" alt></p>\n<h3 id=\"TCP-连接\"><a href=\"#TCP-连接\" class=\"headerlink\" title=\"TCP 连接\"></a>TCP 连接</h3><p><strong>TCP 连接是在调用 <code>KafkaConsumer.poll</code>方法时被创建的。</strong></p>\n<p>1.发起 <code>FindCoordinator</code> 请求时。</p>\n<p>当消费者程序首次启动调用 <code>poll</code>方法时，它需要向 Kafka 集群发送一个名为 <code>FindCoordinator</code> 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。</p>\n<p>2.连接协调者时。</p>\n<p>消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。</p>\n<p>3.消费数据时。</p>\n<p>消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP</p>\n<p><strong>消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。</strong></p>\n<p>1、手动调用<code>KafkaConsumer.close()</code>方法，或者是执行 Kill 命令</p>\n<p>2、Kafka 自动关闭是由消费者端参数 <code>connection.max.idle.ms</code> 控制的，默认值是 9 分钟</p>\n<p>注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。</p>\n<h2 id=\"消费进度\"><a href=\"#消费进度\" class=\"headerlink\" title=\"消费进度\"></a>消费进度</h2><p>消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。</p>\n<p><strong>监控方法</strong></p>\n<p>1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。</p>\n<pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><img src=\"groups_shell.png\" alt></p>\n<p>2、使用 Kafka Java Consumer API 编程。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> <span class=\"token function\">lagOf</span><span class=\"token punctuation\">(</span>String groupID<span class=\"token punctuation\">,</span> String bootstrapServers<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> TimeoutException <span class=\"token punctuation\">{</span>\n    Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>CommonClientConfigs<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> bootstrapServers<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        ListConsumerGroupOffsetsResult result <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">listConsumerGroupOffsets</span><span class=\"token punctuation\">(</span>groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token comment\" spellcheck=\"true\">//获取订阅分区的最新消息位移</span>\n            Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> consumedOffsets <span class=\"token operator\">=</span> \n                result<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsToOffsetAndMetadata</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>SECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 禁止自动提交位移</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>GROUP_ID_CONFIG<span class=\"token punctuation\">,</span> groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token comment\" spellcheck=\"true\">//最新消费消息的位移</span>\n                Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> endOffsets <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">endOffsets</span><span class=\"token punctuation\">(</span>consumedOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">keySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n                <span class=\"token keyword\">return</span> endOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">entrySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toMap</span><span class=\"token punctuation\">(</span>\n                    entry <span class=\"token operator\">-</span><span class=\"token operator\">></span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    entry <span class=\"token operator\">-</span><span class=\"token operator\">></span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> consumedOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">InterruptedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            Thread<span class=\"token punctuation\">.</span><span class=\"token function\">currentThread</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">interrupt</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token comment\" spellcheck=\"true\">// 处理中断异常</span>\n            <span class=\"token comment\" spellcheck=\"true\">// ...</span>\n            <span class=\"token keyword\">return</span> Collections<span class=\"token punctuation\">.</span><span class=\"token function\">emptyMap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">ExecutionException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token comment\" spellcheck=\"true\">// 处理ExecutionException</span>\n            <span class=\"token comment\" spellcheck=\"true\">// ...</span>\n            <span class=\"token keyword\">return</span> Collections<span class=\"token punctuation\">.</span><span class=\"token function\">emptyMap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">TimeoutException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TimeoutException</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Timed out when getting lag for consumer group \"</span> <span class=\"token operator\">+</span> groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>3、使用 Kafka 自带的 JMX 监控指标。</p>\n<p>Kafka 消费者的JMX 指标 <code>kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”</code>，其中：<code>records-lag-max</code> 和 <code>records-lead-min</code>，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。</p>\n<p> <strong>Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。</strong></p>\n<p>一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。</p>\n<p>Kafka 消费者还在分区级别提供了 JMX 指标，用于监控<strong>分区级别的 Lag 和 Lead 值</strong>。JMX 名称为：<code>kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”</code></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"消费者组\"><a href=\"#消费者组\" class=\"headerlink\" title=\"消费者组\"></a>消费者组</h2><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。</p>\n<ul>\n<li>Consumer Group 下可以有一个或多个 Consumer 实例。</li>\n<li>Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li>\n<li>单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。</li>\n<li>理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数</li>\n</ul>\n<h3 id=\"重平衡\"><a href=\"#重平衡\" class=\"headerlink\" title=\"重平衡\"></a>重平衡</h3><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p>\n<p>协调者（Coordinator），负责为 Group 执行 <strong>Rebalance 以及提供位移管理和组成员管理</strong>等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。</p>\n<p><strong>Consumer Group 确定 Coordinator 所在的 Broker</strong> </p>\n<p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p>\n<p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p>\n<p>注： Java Consumer API，能够自动发现并连接正确的 Coordinator。</p>\n<p><strong>Rebalance 触发条件</strong></p>\n<ul>\n<li>组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。</li>\n<li>订阅主题数发生变更。</li>\n<li>订阅主题的分区数发生变更。</li>\n</ul>\n<p><strong>重平衡的通知</strong></p>\n<p>通过心跳线程来完成。</p>\n<ul>\n<li>0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 <code>KafkaConsumer.poll</code>方法的线程。</li>\n<li>0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。</li>\n</ul>\n<p><strong>Rebalance影响</strong></p>\n<p>1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成</p>\n<p>2、Rebalance 效率不高，需要重新分配所有分区</p>\n<p>3、Rebalance很慢</p>\n<p><strong>消费者组状态机</strong></p>\n<p><img src=\"state.jpeg\" alt></p>\n<p><img src=\"transport.jpg\" alt></p>\n<p><strong>消费者端重平衡流程</strong></p>\n<ul>\n<li>加入组</li>\n</ul>\n<p>向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。</p>\n<p>协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。</p>\n<ul>\n<li>等待领导者消费者（Leader Consumer）分配方案</li>\n</ul>\n<p>领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。</p>\n<p>其他成员也会向协调者发送 SyncGroup 请求.</p>\n<p>协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。</p>\n<p><strong>Broker端重平衡流程</strong></p>\n<p>场景一：新成员入组</p>\n<p><img src=\"newadd.jpg\" alt></p>\n<p>场景二：组成员主动离组。</p>\n<p><img src=\"leavegroup.jpg\" alt></p>\n<p>场景三：组成员崩溃离组</p>\n<p><img src=\"comsumedown.jpg\" alt></p>\n<p><strong>避免 Rebalance</strong></p>\n<p>主要方法：<strong>避免组成员数发生减少的情况</strong>。</p>\n<p>Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。<code>session.timeout.ms</code>+ <code>heartbeat.interval.ms</code></p>\n<p>Consumer 端应用程序两次调用<code>poll</code> 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。<code>max.poll.interval.ms</code></p>\n<h2 id=\"位移主题\"><a href=\"#位移主题\" class=\"headerlink\" title=\"位移主题\"></a>位移主题</h2><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是<code>offsets.topic.num.partitions</code> 50，副本数是<code>offsets.topic.replication.factor</code> 3。</p>\n<p>1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 <code>__consumer_offsets</code>中。</p>\n<p>位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等。</p>\n<p>2、保存 Consumer Group 相关信息的消息</p>\n<p>3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息</p>\n<p><strong>消费位移</strong></p>\n<p>记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。</p>\n<p>提交位移的配置：<code>enable.auto.commit</code> + <code>auto.commit.interval.ms</code>控制。</p>\n<h3 id=\"自动提交位移\"><a href=\"#自动提交位移\" class=\"headerlink\" title=\"自动提交位移\"></a><strong>自动提交位移</strong></h3><ul>\n<li><p>Kafka 会保证在开始调用 <code>poll</code> 方法时，提交上次 <code>poll</code> 返回的所有消息。</p>\n</li>\n<li><p>从顺序上来说，<code>poll</code>方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。</p>\n</li>\n<li><p>问题：重平衡出现时可能会出现重复消费</p>\n</li>\n</ul>\n<pre><code class=\"java\">Properties props = new Properties();\nprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\nprops.put(&quot;group.id&quot;, &quot;test&quot;);\nprops.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);\nprops.put(&quot;auto.commit.interval.ms&quot;, &quot;2000&quot;);\nprops.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nprops.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nKafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);\nconsumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));\nwhile (true) {\n    ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);\n    for (ConsumerRecord&lt;String, String&gt; record : records)\n        System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, \n                          record.offset(), record.key(), record.value());\n}</code></pre>\n<h3 id=\"手动提交位移\"><a href=\"#手动提交位移\" class=\"headerlink\" title=\"手动提交位移\"></a>手动提交位移</h3><p><strong>手动提交，需要将 <code>commitSync</code> 和 <code>commitAsync</code> 组合使用。</strong></p>\n<p><code>commitSync()</code>会提交 <code>poll()</code>返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。</p>\n<p>缺陷：调用 <code>commitSync()</code>时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。</p>\n<pre><code class=\"java\">while (true) {\n    ConsumerRecords&lt;String, String&gt; records =\n        consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}</code></pre>\n<p><code>commitAsync()</code>，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数<code>callback</code>，供你实现提交之后的逻辑，比如记录日志或处理异常等。<br>缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。</p>\n<pre><code class=\"java\">try {\n    while(true) {\n        ConsumerRecords&lt;String, String&gt; records =\n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}</code></pre>\n<p><code>commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>和 <code>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 <code>OffsetAndMetadata</code> 对象，保存位移数据。</p>\n<pre><code class=\"java\">private Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords&lt;String, String&gt; records =\n        consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord&lt;String, String&gt; record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1)；\n        if（count % 100 == 0）\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n         count++;\n    }\n}</code></pre>\n<h3 id=\"CommitFailedException\"><a href=\"#CommitFailedException\" class=\"headerlink\" title=\"CommitFailedException\"></a>CommitFailedException</h3><p>提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例<br><strong>解决</strong></p>\n<ul>\n<li>缩短单条消息处理的时间</li>\n<li>增加 Consumer 端允许下游系统消费一批消息的最大时长<code>max.poll.interval.ms</code> </li>\n<li>减少下游系统一次性消费的消息总数<code>max.poll.records</code></li>\n<li>下游系统使用多线程来加速消费</li>\n</ul>\n<h3 id=\"过期消息删除\"><a href=\"#过期消息删除\" class=\"headerlink\" title=\"过期消息删除\"></a><strong>过期消息删除</strong></h3><p>kafka 使用 Compact 策略来删除位移主题中的过期消息。</p>\n<p>Kafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。</p>\n<p>对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p>\n<h3 id=\"重设消费者组位移\"><a href=\"#重设消费者组位移\" class=\"headerlink\" title=\"重设消费者组位移\"></a>重设消费者组位移</h3><p>由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。</p>\n<h4 id=\"重设位移策略\"><a href=\"#重设位移策略\" class=\"headerlink\" title=\"重设位移策略\"></a>重设位移策略</h4><p><img src=\"stragey.jpg\" alt></p>\n<h4 id=\"重设方式\"><a href=\"#重设方式\" class=\"headerlink\" title=\"重设方式\"></a>重设方式</h4><p>通过消费者 API 来实现。</p>\n<pre><code class=\"java\">Properties consumerProperties = new Properties();\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); //禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\nString topic = &quot;test&quot;;  // 要重设位移的Kafka主题 \ntry (final KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    consumer.poll(0);\n    consumer.seekToBeginning(\n        consumer.partitionsFor(topic).stream().map(\n            partitionInfo -&gt; new TopicPartition(topic, partitionInfo.partition())\n           ).collect(Collectors.toList()));// 需要一次性构造主题的所有分区对象\n} \n// Current\nconsumer.partitionsFor(topic).stream().map(\n    info -&gt; new TopicPartition(topic, info.partition())\n  ).forEach(tp -&gt; {\n  long committedOffset = consumer.committed(tp).offset();\n  consumer.seek(tp, committedOffset);\n});\n//Specified-Offset\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n  TopicPartition tp = new TopicPartition(topic, info.partition());\n  consumer.seek(tp, targetOffset);\n}\n//Shift-By-N \nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n         TopicPartition tp = new TopicPartition(topic, info.partition());\n  // 假设向前跳123条消息\n         long targetOffset = consumer.committed(tp).offset() + 123L; \n         consumer.seek(tp, targetOffset);\n}\n//DateTime \nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0).toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\nMap&lt;TopicPartition, Long&gt; timeToSearch = \n         consumer.partitionsFor(topic).stream().map(info -&gt; \n  new TopicPartition(topic, info.partition()))\n  .collect(Collectors.toMap(Function.identity(), tp -&gt; ts));\n\nfor (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : \n  consumer.offsetsForTimes(timeToSearch).entrySet()) {\nconsumer.seek(entry.getKey(), entry.getValue().offset());\n}\n//Duration\n\nMap&lt;TopicPartition, Long&gt; timeToSearch = consumer.partitionsFor(topic).stream()\n         .map(info -&gt; new TopicPartition(topic, info.partition()))\n         .collect(Collectors.toMap(Function.identity(), tp -&gt; System.currentTimeMillis() - 30 * 1000  * 60));\n\nfor (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : \n     consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}</code></pre>\n<p>通过 kafka-consumer-groups 命令行脚本来实现</p>\n<pre><code class=\"shell\"># to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset &lt;offset&gt; --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by &lt;offset_N&gt; --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute</code></pre>\n<h2 id=\"独立消费者\"><a href=\"#独立消费者\" class=\"headerlink\" title=\"独立消费者\"></a>独立消费者</h2><p>每个消费者实例都是独立工作的，彼此之间毫无联系。</p>\n<h2 id=\"KafkaConsumer\"><a href=\"#KafkaConsumer\" class=\"headerlink\" title=\"KafkaConsumer\"></a>KafkaConsumer</h2><p>用户主线程，启动 Consumer 应用程序 main 方法的那个线程。</p>\n<p>心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）</p>\n<h3 id=\"多线程方案\"><a href=\"#多线程方案\" class=\"headerlink\" title=\"多线程方案\"></a>多线程方案</h3><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p>\n<p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p>\n<p><img src=\"plan1.jpg\" alt></p>\n<pre><code class=\"java\">\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n\n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(&quot;topic&quot;));\n             while (!closed.get()) {\n      ConsumerRecords records = \n        consumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n\n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}</code></pre>\n<p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p>\n<p><img src=\"plan2.jpg\" alt></p>\n<pre><code class=\"java\">\nprivate final KafkaConsumer&lt;String, String&gt; consumer;\nprivate ExecutorService executors;\n...\n\n\nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n  workerNum,\n  workerNum,\n  0L, \n  TimeUnit.MILLISECONDS,\n  new ArrayBlockingQueue&lt;&gt;(1000), \n  new ThreadPoolExecutor.CallerRunsPolicy()\n);\n\n\n...\nwhile (true)  {\n  ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));\n  for (final ConsumerRecord record : records) {\n    executors.submit(new Worker(record));\n  }\n}\n..</code></pre>\n<p><strong>方案比较</strong></p>\n<p><img src=\"compare.jpg\" alt></p>\n<h3 id=\"TCP-连接\"><a href=\"#TCP-连接\" class=\"headerlink\" title=\"TCP 连接\"></a>TCP 连接</h3><p><strong>TCP 连接是在调用 <code>KafkaConsumer.poll</code>方法时被创建的。</strong></p>\n<p>1.发起 <code>FindCoordinator</code> 请求时。</p>\n<p>当消费者程序首次启动调用 <code>poll</code>方法时，它需要向 Kafka 集群发送一个名为 <code>FindCoordinator</code> 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。</p>\n<p>2.连接协调者时。</p>\n<p>消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。</p>\n<p>3.消费数据时。</p>\n<p>消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP</p>\n<p><strong>消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。</strong></p>\n<p>1、手动调用<code>KafkaConsumer.close()</code>方法，或者是执行 Kill 命令</p>\n<p>2、Kafka 自动关闭是由消费者端参数 <code>connection.max.idle.ms</code> 控制的，默认值是 9 分钟</p>\n<p>注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。</p>\n<h2 id=\"消费进度\"><a href=\"#消费进度\" class=\"headerlink\" title=\"消费进度\"></a>消费进度</h2><p>消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。</p>\n<p><strong>监控方法</strong></p>\n<p>1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。</p>\n<pre><code class=\"shell\"># Kafka 连接信息就是 &lt; 主机名：端口 &gt; 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server &lt;Kafka broker连接信息&gt; --describe --group &lt;group名称&gt;</code></pre>\n<p><img src=\"groups_shell.png\" alt></p>\n<p>2、使用 Kafka Java Consumer API 编程。</p>\n<pre><code class=\"java\">\npublic static Map&lt;TopicPartition, Long&gt; lagOf(String groupID, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n        try {\n            //获取订阅分区的最新消息位移\n            Map&lt;TopicPartition, OffsetAndMetadata&gt; consumedOffsets = \n                result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props)) {\n                //最新消费消息的位移\n                Map&lt;TopicPartition, Long&gt; endOffsets = consumer.endOffsets(consumedOffsets.keySet()); \n                return endOffsets.entrySet().stream().collect(Collectors.toMap(\n                    entry -&gt; entry.getKey(),\n                    entry -&gt; entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            // 处理中断异常\n            // ...\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            // 处理ExecutionException\n            // ...\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(&quot;Timed out when getting lag for consumer group &quot; + groupID);\n        }\n    }\n}</code></pre>\n<p>3、使用 Kafka 自带的 JMX 监控指标。</p>\n<p>Kafka 消费者的JMX 指标 <code>kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”</code>，其中：<code>records-lag-max</code> 和 <code>records-lead-min</code>，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。</p>\n<p> <strong>Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。</strong></p>\n<p>一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。</p>\n<p>Kafka 消费者还在分区级别提供了 JMX 指标，用于监控<strong>分区级别的 Lag 和 Lead 值</strong>。JMX 名称为：<code>kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”</code></p>\n"},{"title":"kafka生产者","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T10:45:20.000Z","password":null,"summary":null,"_content":"\n## 消息分区机制\n\n### 为什么分区\n\n**提供负载均衡的能力，实现系统的高伸缩性。**\n\n不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。\n\n### 分区策略\n\n**自定义分区策略**\n\n编写一个具体的类实现`org.apache.kafka.clients.producer.Partitioner`接口。其中包含`partition()`和`close()`，一般只需要实现 `partition `方法。\n\n**轮询策略**\n\n` Round-robin` 策略，即顺序分配。\n\n轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，最合理也最常用的分区策略，。\n\n**随机策略**\n\n`Randomness `策略。将消息放置到任意一个分区上。\n\n**按消息键保序策略**\n\nKafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。\n\n```java\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n\n//可以根据 Broker 所在的 IP 地址实现定制化的分区策略\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(\n    p -> isSouth(p.leader().host())\n).map(PartitionInfo::partition).findAny().get();\n```\n\n## 压缩\n\nKafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。\n\n### V1 版本和 V2 版本区别\n\n1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。\n\n2、消息的 CRC 校验工作就被移到了消息集合这一层。\n\n3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩\n\n### 何时压缩\n\n1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。\n\n```java\n Properties props = new Properties();\n props.put(\"bootstrap.servers\", \"localhost:9092\");\n props.put(\"acks\", \"all\");\n props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n // 开启GZIP压缩\n props.put(\"compression.type\", \"gzip\");\n \n Producer<String, String> producer = new KafkaProducer<>(props);\n```\n\n2、Broker 重新压缩消息\n\n- Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。\n\n- Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性\n\n### 解压缩\n\n通常来说解压缩发生在消费者程序中。\n\n Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。\n\n### 压缩算法\n\n吞吐量：LZ4 > Snappy > zstd 和 GZIP；\n\n压缩比：zstd > LZ4 > GZIP > Snappy\n\n## Kafka 生产者程序\n\n第 1 步：构造生产者对象所需的参数对象。\n\n第 2 步：利用参数对象，创建 KafkaProducer 对象实例。\n\n第 3 步：使用 KafkaProducer 的 send 方法发送消息。\n\n第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。\n\n```java\nProperties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer<String, String> producer = new KafkaProducer<>(props)) {\n    producer.send(new ProducerRecord<String, String>(……), callback);\n  ……\n}\n```\n\n## 生产者的TCP\n\n在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会**创建与 Broker 的TCP连接**。它会连接 `bootstrap.servers` 参数指定的所有 Broker。\n\n`KafkaProducer `实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 `RecordAccumulator `类，维护了 `RecordAccumulator` 类的线程安全，也就实现了 KafkaProducer 类的线程安全。\n\n**其他TCP连接创建**\n\n- 当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。\n\n- 当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。\n\n**更新元数据场景**\n\n1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。\n\n2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。\n\n**关闭TCP连接**\n\n- 用户主动关闭\n\n- Kafka 自动关闭\n\nconnections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。\n\n可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或 `props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要**事务**或者依赖**事务型 Producer**\n\n","source":"_posts/kafka生产者.md","raw":"---\ntitle: kafka生产者\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 18:45:20\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 消息分区机制\n\n### 为什么分区\n\n**提供负载均衡的能力，实现系统的高伸缩性。**\n\n不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。\n\n### 分区策略\n\n**自定义分区策略**\n\n编写一个具体的类实现`org.apache.kafka.clients.producer.Partitioner`接口。其中包含`partition()`和`close()`，一般只需要实现 `partition `方法。\n\n**轮询策略**\n\n` Round-robin` 策略，即顺序分配。\n\n轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，最合理也最常用的分区策略，。\n\n**随机策略**\n\n`Randomness `策略。将消息放置到任意一个分区上。\n\n**按消息键保序策略**\n\nKafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。\n\n```java\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n\n//可以根据 Broker 所在的 IP 地址实现定制化的分区策略\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(\n    p -> isSouth(p.leader().host())\n).map(PartitionInfo::partition).findAny().get();\n```\n\n## 压缩\n\nKafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。\n\n### V1 版本和 V2 版本区别\n\n1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。\n\n2、消息的 CRC 校验工作就被移到了消息集合这一层。\n\n3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩\n\n### 何时压缩\n\n1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。\n\n```java\n Properties props = new Properties();\n props.put(\"bootstrap.servers\", \"localhost:9092\");\n props.put(\"acks\", \"all\");\n props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n // 开启GZIP压缩\n props.put(\"compression.type\", \"gzip\");\n \n Producer<String, String> producer = new KafkaProducer<>(props);\n```\n\n2、Broker 重新压缩消息\n\n- Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。\n\n- Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性\n\n### 解压缩\n\n通常来说解压缩发生在消费者程序中。\n\n Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。\n\n### 压缩算法\n\n吞吐量：LZ4 > Snappy > zstd 和 GZIP；\n\n压缩比：zstd > LZ4 > GZIP > Snappy\n\n## Kafka 生产者程序\n\n第 1 步：构造生产者对象所需的参数对象。\n\n第 2 步：利用参数对象，创建 KafkaProducer 对象实例。\n\n第 3 步：使用 KafkaProducer 的 send 方法发送消息。\n\n第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。\n\n```java\nProperties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer<String, String> producer = new KafkaProducer<>(props)) {\n    producer.send(new ProducerRecord<String, String>(……), callback);\n  ……\n}\n```\n\n## 生产者的TCP\n\n在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会**创建与 Broker 的TCP连接**。它会连接 `bootstrap.servers` 参数指定的所有 Broker。\n\n`KafkaProducer `实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 `RecordAccumulator `类，维护了 `RecordAccumulator` 类的线程安全，也就实现了 KafkaProducer 类的线程安全。\n\n**其他TCP连接创建**\n\n- 当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。\n\n- 当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。\n\n**更新元数据场景**\n\n1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。\n\n2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。\n\n**关闭TCP连接**\n\n- 用户主动关闭\n\n- Kafka 自动关闭\n\nconnections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。\n\n可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或 `props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要**事务**或者依赖**事务型 Producer**\n\n","slug":"kafka生产者","published":1,"updated":"2021-04-27T11:49:49.131Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6o70016q4uf4w4bnhqv","content":"<h2 id=\"消息分区机制\"><a href=\"#消息分区机制\" class=\"headerlink\" title=\"消息分区机制\"></a>消息分区机制</h2><h3 id=\"为什么分区\"><a href=\"#为什么分区\" class=\"headerlink\" title=\"为什么分区\"></a>为什么分区</h3><p><strong>提供负载均衡的能力，实现系统的高伸缩性。</strong></p>\n<p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。</p>\n<h3 id=\"分区策略\"><a href=\"#分区策略\" class=\"headerlink\" title=\"分区策略\"></a>分区策略</h3><p><strong>自定义分区策略</strong></p>\n<p>编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口。其中包含<code>partition()</code>和<code>close()</code>，一般只需要实现 <code>partition</code>方法。</p>\n<p><strong>轮询策略</strong></p>\n<p><code>Round-robin</code> 策略，即顺序分配。</p>\n<p>轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，最合理也最常用的分区策略，。</p>\n<p><strong>随机策略</strong></p>\n<p><code>Randomness</code>策略。将消息放置到任意一个分区上。</p>\n<p><strong>按消息键保序策略</strong></p>\n<p>Kafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">List<span class=\"token operator\">&lt;</span>PartitionInfo<span class=\"token operator\">></span> partitions <span class=\"token operator\">=</span> cluster<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsForTopic</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">return</span> Math<span class=\"token punctuation\">.</span><span class=\"token function\">abs</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">.</span><span class=\"token function\">hashCode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> partitions<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">//可以根据 Broker 所在的 IP 地址实现定制化的分区策略</span>\nList<span class=\"token operator\">&lt;</span>PartitionInfo<span class=\"token operator\">></span> partitions <span class=\"token operator\">=</span> cluster<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsForTopic</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">return</span> partitions<span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">filter</span><span class=\"token punctuation\">(</span>\n    p <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token function\">isSouth</span><span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">.</span><span class=\"token function\">leader</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">host</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>PartitionInfo<span class=\"token operator\">:</span><span class=\"token operator\">:</span>partition<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">findAny</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"压缩\"><a href=\"#压缩\" class=\"headerlink\" title=\"压缩\"></a>压缩</h2><p>Kafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。</p>\n<h3 id=\"V1-版本和-V2-版本区别\"><a href=\"#V1-版本和-V2-版本区别\" class=\"headerlink\" title=\"V1 版本和 V2 版本区别\"></a>V1 版本和 V2 版本区别</h3><p>1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。</p>\n<p>2、消息的 CRC 校验工作就被移到了消息集合这一层。</p>\n<p>3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩</p>\n<h3 id=\"何时压缩\"><a href=\"#何时压缩\" class=\"headerlink\" title=\"何时压缩\"></a>何时压缩</h3><p>1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"> Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"bootstrap.servers\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"localhost:9092\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"acks\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"all\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"key.serializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringSerializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"value.serializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringSerializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n <span class=\"token comment\" spellcheck=\"true\">// 开启GZIP压缩</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"compression.type\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"gzip\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n Producer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaProducer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>2、Broker 重新压缩消息</p>\n<ul>\n<li><p>Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。</p>\n</li>\n<li><p>Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性</p>\n</li>\n</ul>\n<h3 id=\"解压缩\"><a href=\"#解压缩\" class=\"headerlink\" title=\"解压缩\"></a>解压缩</h3><p>通常来说解压缩发生在消费者程序中。</p>\n<p> Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。</p>\n<h3 id=\"压缩算法\"><a href=\"#压缩算法\" class=\"headerlink\" title=\"压缩算法\"></a>压缩算法</h3><p>吞吐量：LZ4 &gt; Snappy &gt; zstd 和 GZIP；</p>\n<p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy</p>\n<h2 id=\"Kafka-生产者程序\"><a href=\"#Kafka-生产者程序\" class=\"headerlink\" title=\"Kafka 生产者程序\"></a>Kafka 生产者程序</h2><p>第 1 步：构造生产者对象所需的参数对象。</p>\n<p>第 2 步：利用参数对象，创建 KafkaProducer 对象实例。</p>\n<p>第 3 步：使用 KafkaProducer 的 send 方法发送消息。</p>\n<p>第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>“参数<span class=\"token number\">1</span>”<span class=\"token punctuation\">,</span> “参数<span class=\"token number\">1</span>的值”<span class=\"token punctuation\">)</span>；\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>“参数<span class=\"token number\">2</span>”<span class=\"token punctuation\">,</span> “参数<span class=\"token number\">2</span>的值”<span class=\"token punctuation\">)</span>；\n……\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>Producer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaProducer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">ProducerRecord</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span><span class=\"token punctuation\">(</span>……<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> callback<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  ……\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"生产者的TCP\"><a href=\"#生产者的TCP\" class=\"headerlink\" title=\"生产者的TCP\"></a>生产者的TCP</h2><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会<strong>创建与 Broker 的TCP连接</strong>。它会连接 <code>bootstrap.servers</code> 参数指定的所有 Broker。</p>\n<p><code>KafkaProducer</code>实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 <code>RecordAccumulator</code>类，维护了 <code>RecordAccumulator</code> 类的线程安全，也就实现了 KafkaProducer 类的线程安全。</p>\n<p><strong>其他TCP连接创建</strong></p>\n<ul>\n<li><p>当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。</p>\n</li>\n<li><p>当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。</p>\n</li>\n</ul>\n<p><strong>更新元数据场景</strong></p>\n<p>1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。</p>\n<p>2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。</p>\n<p><strong>关闭TCP连接</strong></p>\n<ul>\n<li><p>用户主动关闭</p>\n</li>\n<li><p>Kafka 自动关闭</p>\n</li>\n</ul>\n<p>connections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。</p>\n<p>可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或 <code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要<strong>事务</strong>或者依赖<strong>事务型 Producer</strong></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"消息分区机制\"><a href=\"#消息分区机制\" class=\"headerlink\" title=\"消息分区机制\"></a>消息分区机制</h2><h3 id=\"为什么分区\"><a href=\"#为什么分区\" class=\"headerlink\" title=\"为什么分区\"></a>为什么分区</h3><p><strong>提供负载均衡的能力，实现系统的高伸缩性。</strong></p>\n<p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。</p>\n<h3 id=\"分区策略\"><a href=\"#分区策略\" class=\"headerlink\" title=\"分区策略\"></a>分区策略</h3><p><strong>自定义分区策略</strong></p>\n<p>编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口。其中包含<code>partition()</code>和<code>close()</code>，一般只需要实现 <code>partition</code>方法。</p>\n<p><strong>轮询策略</strong></p>\n<p><code>Round-robin</code> 策略，即顺序分配。</p>\n<p>轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，最合理也最常用的分区策略，。</p>\n<p><strong>随机策略</strong></p>\n<p><code>Randomness</code>策略。将消息放置到任意一个分区上。</p>\n<p><strong>按消息键保序策略</strong></p>\n<p>Kafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。</p>\n<pre><code class=\"java\">List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n\n//可以根据 Broker 所在的 IP 地址实现定制化的分区策略\nList&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(\n    p -&gt; isSouth(p.leader().host())\n).map(PartitionInfo::partition).findAny().get();</code></pre>\n<h2 id=\"压缩\"><a href=\"#压缩\" class=\"headerlink\" title=\"压缩\"></a>压缩</h2><p>Kafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。</p>\n<h3 id=\"V1-版本和-V2-版本区别\"><a href=\"#V1-版本和-V2-版本区别\" class=\"headerlink\" title=\"V1 版本和 V2 版本区别\"></a>V1 版本和 V2 版本区别</h3><p>1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。</p>\n<p>2、消息的 CRC 校验工作就被移到了消息集合这一层。</p>\n<p>3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩</p>\n<h3 id=\"何时压缩\"><a href=\"#何时压缩\" class=\"headerlink\" title=\"何时压缩\"></a>何时压缩</h3><p>1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。</p>\n<pre><code class=\"java\"> Properties props = new Properties();\n props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\n props.put(&quot;acks&quot;, &quot;all&quot;);\n props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n // 开启GZIP压缩\n props.put(&quot;compression.type&quot;, &quot;gzip&quot;);\n\n Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre>\n<p>2、Broker 重新压缩消息</p>\n<ul>\n<li><p>Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。</p>\n</li>\n<li><p>Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性</p>\n</li>\n</ul>\n<h3 id=\"解压缩\"><a href=\"#解压缩\" class=\"headerlink\" title=\"解压缩\"></a>解压缩</h3><p>通常来说解压缩发生在消费者程序中。</p>\n<p> Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。</p>\n<h3 id=\"压缩算法\"><a href=\"#压缩算法\" class=\"headerlink\" title=\"压缩算法\"></a>压缩算法</h3><p>吞吐量：LZ4 &gt; Snappy &gt; zstd 和 GZIP；</p>\n<p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy</p>\n<h2 id=\"Kafka-生产者程序\"><a href=\"#Kafka-生产者程序\" class=\"headerlink\" title=\"Kafka 生产者程序\"></a>Kafka 生产者程序</h2><p>第 1 步：构造生产者对象所需的参数对象。</p>\n<p>第 2 步：利用参数对象，创建 KafkaProducer 对象实例。</p>\n<p>第 3 步：使用 KafkaProducer 的 send 方法发送消息。</p>\n<p>第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。</p>\n<pre><code class=\"java\">Properties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props)) {\n    producer.send(new ProducerRecord&lt;String, String&gt;(……), callback);\n  ……\n}</code></pre>\n<h2 id=\"生产者的TCP\"><a href=\"#生产者的TCP\" class=\"headerlink\" title=\"生产者的TCP\"></a>生产者的TCP</h2><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会<strong>创建与 Broker 的TCP连接</strong>。它会连接 <code>bootstrap.servers</code> 参数指定的所有 Broker。</p>\n<p><code>KafkaProducer</code>实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 <code>RecordAccumulator</code>类，维护了 <code>RecordAccumulator</code> 类的线程安全，也就实现了 KafkaProducer 类的线程安全。</p>\n<p><strong>其他TCP连接创建</strong></p>\n<ul>\n<li><p>当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。</p>\n</li>\n<li><p>当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。</p>\n</li>\n</ul>\n<p><strong>更新元数据场景</strong></p>\n<p>1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。</p>\n<p>2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。</p>\n<p><strong>关闭TCP连接</strong></p>\n<ul>\n<li><p>用户主动关闭</p>\n</li>\n<li><p>Kafka 自动关闭</p>\n</li>\n</ul>\n<p>connections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。</p>\n<p>可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或 <code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要<strong>事务</strong>或者依赖<strong>事务型 Producer</strong></p>\n"},{"title":"kafka认证","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T13:37:09.000Z","password":null,"summary":null,"_content":"\n认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。\n\n## Kafka 认证机制\n\n**基于 SSL 的认证**主要是指 Broker 和客户端的双路认证。\n\n客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。\n\n**基于 SASL 的安全认证机制**\n\nSASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：\n\nGSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。\n\nPLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。\n\nSCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。\n\nOAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。\n\nDelegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。\n\n## 认证机制的比较\n\n可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。\n\n![](compare.jpg)\n\n","source":"_posts/kafka认证.md","raw":"---\ntitle: kafka认证\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 21:37:09\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。\n\n## Kafka 认证机制\n\n**基于 SSL 的认证**主要是指 Broker 和客户端的双路认证。\n\n客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。\n\n**基于 SASL 的安全认证机制**\n\nSASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：\n\nGSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。\n\nPLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。\n\nSCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。\n\nOAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。\n\nDelegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。\n\n## 认证机制的比较\n\n可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。\n\n![](compare.jpg)\n\n","slug":"kafka认证","published":1,"updated":"2021-04-02T13:46:25.827Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ob0019q4uf7x7kf8wm","content":"<p>认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。</p>\n<h2 id=\"Kafka-认证机制\"><a href=\"#Kafka-认证机制\" class=\"headerlink\" title=\"Kafka 认证机制\"></a>Kafka 认证机制</h2><p><strong>基于 SSL 的认证</strong>主要是指 Broker 和客户端的双路认证。</p>\n<p>客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。</p>\n<p><strong>基于 SASL 的安全认证机制</strong></p>\n<p>SASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：</p>\n<p>GSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。</p>\n<p>PLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。</p>\n<p>SCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。</p>\n<p>OAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。</p>\n<p>Delegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。</p>\n<h2 id=\"认证机制的比较\"><a href=\"#认证机制的比较\" class=\"headerlink\" title=\"认证机制的比较\"></a>认证机制的比较</h2><p>可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。</p>\n<p><img src=\"compare.jpg\" alt></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。</p>\n<h2 id=\"Kafka-认证机制\"><a href=\"#Kafka-认证机制\" class=\"headerlink\" title=\"Kafka 认证机制\"></a>Kafka 认证机制</h2><p><strong>基于 SSL 的认证</strong>主要是指 Broker 和客户端的双路认证。</p>\n<p>客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。</p>\n<p><strong>基于 SASL 的安全认证机制</strong></p>\n<p>SASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：</p>\n<p>GSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。</p>\n<p>PLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。</p>\n<p>SCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。</p>\n<p>OAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。</p>\n<p>Delegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。</p>\n<h2 id=\"认证机制的比较\"><a href=\"#认证机制的比较\" class=\"headerlink\" title=\"认证机制的比较\"></a>认证机制的比较</h2><p>可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。</p>\n<p><img src=\"compare.jpg\" alt></p>\n"},{"title":"kafka精确一次","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T12:59:45.000Z","password":null,"summary":null,"_content":"\nkafka通过**幂等性（Idempotence）**和**事务（Transaction）**实现消息精确一次（exactly once）的可靠性保障。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或` props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要依赖**事务型 Producer**.\n\n## **事务型 Producer**\n\n事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。\n\n设置事务型 Producer 的方法：\n\n- 开启`enable.idempotence = true`。\n\n- 设置 Producer 端参数` transactional.id`。最好为其设置一个有意义的名字。\n\n```java\nproducer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(record1);\n    producer.send(record2);\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}\n```\n\n`isolation.level`支持`read_uncommitted`和`read_committed`","source":"_posts/kafka精确一次.md","raw":"---\ntitle: kafka精确一次\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 20:59:45\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\nkafka通过**幂等性（Idempotence）**和**事务（Transaction）**实现消息精确一次（exactly once）的可靠性保障。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或` props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要依赖**事务型 Producer**.\n\n## **事务型 Producer**\n\n事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。\n\n设置事务型 Producer 的方法：\n\n- 开启`enable.idempotence = true`。\n\n- 设置 Producer 端参数` transactional.id`。最好为其设置一个有意义的名字。\n\n```java\nproducer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(record1);\n    producer.send(record2);\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}\n```\n\n`isolation.level`支持`read_uncommitted`和`read_committed`","slug":"kafka精确一次","published":1,"updated":"2021-04-01T23:01:49.856Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ol001cq4uf03z6bdkh","content":"<p>kafka通过<strong>幂等性（Idempotence）</strong>和<strong>事务（Transaction）</strong>实现消息精确一次（exactly once）的可靠性保障。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或<code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要依赖<strong>事务型 Producer</strong>.</p>\n<h2 id=\"事务型-Producer\"><a href=\"#事务型-Producer\" class=\"headerlink\" title=\"事务型 Producer\"></a><strong>事务型 Producer</strong></h2><p>事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。</p>\n<p>设置事务型 Producer 的方法：</p>\n<ul>\n<li><p>开启<code>enable.idempotence = true</code>。</p>\n</li>\n<li><p>设置 Producer 端参数<code>transactional.id</code>。最好为其设置一个有意义的名字。</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">producer<span class=\"token punctuation\">.</span><span class=\"token function\">initTransactions</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">beginTransaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span>record1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span>record2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">commitTransaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">KafkaException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">abortTransaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>isolation.level</code>支持<code>read_uncommitted</code>和<code>read_committed</code></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>kafka通过<strong>幂等性（Idempotence）</strong>和<strong>事务（Transaction）</strong>实现消息精确一次（exactly once）的可靠性保障。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或<code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要依赖<strong>事务型 Producer</strong>.</p>\n<h2 id=\"事务型-Producer\"><a href=\"#事务型-Producer\" class=\"headerlink\" title=\"事务型 Producer\"></a><strong>事务型 Producer</strong></h2><p>事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。</p>\n<p>设置事务型 Producer 的方法：</p>\n<ul>\n<li><p>开启<code>enable.idempotence = true</code>。</p>\n</li>\n<li><p>设置 Producer 端参数<code>transactional.id</code>。最好为其设置一个有意义的名字。</p>\n</li>\n</ul>\n<pre><code class=\"java\">producer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(record1);\n    producer.send(record2);\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}</code></pre>\n<p><code>isolation.level</code>支持<code>read_uncommitted</code>和<code>read_committed</code></p>\n"},{"title":"kafka调优","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-30T13:30:58.000Z","password":null,"summary":null,"_content":"\n## 调优目标\n\n吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。\n\n延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。\n\n## 优化\n\n### 操作系统调优\n\n1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。\n\n2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程\n\n3、ulimit -n 不宜太小\n\n4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。\n\n### JVM 层调优\n\n1. 设置堆大小。6～8GB\n2. GC 收集器使用 G1 收集器。\n\n### Broker 端调优\n\n保持客户端版本和 Broker 端版本一致。\n\n### 应用层调优\n\n1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。\n\n2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。\n\n## 性能指标调优\n\n### 调优吞吐量\n\n1、broker 端参数 `num.replica.fetchers `表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。\n\n2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 `batch.size` 和 `linger.ms`。\n\n3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd\n\n4、Consumer端使用多线程方案\n\n### 调优延时\n\n1、在 Broker 端，我们依然要增加 `num.replica.fetchers` 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时\n\n2、设置 `linger.ms=0`，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。\n\n3、Consumer 端，我们保持` fetch.min.bytes=1` 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。","source":"_posts/kafka调优.md","raw":"---\ntitle: kafka调优\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-30 21:30:58\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 调优目标\n\n吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。\n\n延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。\n\n## 优化\n\n### 操作系统调优\n\n1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。\n\n2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程\n\n3、ulimit -n 不宜太小\n\n4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。\n\n### JVM 层调优\n\n1. 设置堆大小。6～8GB\n2. GC 收集器使用 G1 收集器。\n\n### Broker 端调优\n\n保持客户端版本和 Broker 端版本一致。\n\n### 应用层调优\n\n1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。\n\n2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。\n\n## 性能指标调优\n\n### 调优吞吐量\n\n1、broker 端参数 `num.replica.fetchers `表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。\n\n2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 `batch.size` 和 `linger.ms`。\n\n3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd\n\n4、Consumer端使用多线程方案\n\n### 调优延时\n\n1、在 Broker 端，我们依然要增加 `num.replica.fetchers` 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时\n\n2、设置 `linger.ms=0`，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。\n\n3、Consumer 端，我们保持` fetch.min.bytes=1` 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。","slug":"kafka调优","published":1,"updated":"2021-04-02T13:16:17.846Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6or001fq4ufh5g5is60","content":"<h2 id=\"调优目标\"><a href=\"#调优目标\" class=\"headerlink\" title=\"调优目标\"></a>调优目标</h2><p>吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。</p>\n<p>延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><h3 id=\"操作系统调优\"><a href=\"#操作系统调优\" class=\"headerlink\" title=\"操作系统调优\"></a>操作系统调优</h3><p>1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。</p>\n<p>2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程</p>\n<p>3、ulimit -n 不宜太小</p>\n<p>4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。</p>\n<h3 id=\"JVM-层调优\"><a href=\"#JVM-层调优\" class=\"headerlink\" title=\"JVM 层调优\"></a>JVM 层调优</h3><ol>\n<li>设置堆大小。6～8GB</li>\n<li>GC 收集器使用 G1 收集器。</li>\n</ol>\n<h3 id=\"Broker-端调优\"><a href=\"#Broker-端调优\" class=\"headerlink\" title=\"Broker 端调优\"></a>Broker 端调优</h3><p>保持客户端版本和 Broker 端版本一致。</p>\n<h3 id=\"应用层调优\"><a href=\"#应用层调优\" class=\"headerlink\" title=\"应用层调优\"></a>应用层调优</h3><p>1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。</p>\n<p>2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。</p>\n<h2 id=\"性能指标调优\"><a href=\"#性能指标调优\" class=\"headerlink\" title=\"性能指标调优\"></a>性能指标调优</h2><h3 id=\"调优吞吐量\"><a href=\"#调优吞吐量\" class=\"headerlink\" title=\"调优吞吐量\"></a>调优吞吐量</h3><p>1、broker 端参数 <code>num.replica.fetchers</code>表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。</p>\n<p>2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 <code>batch.size</code> 和 <code>linger.ms</code>。</p>\n<p>3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd</p>\n<p>4、Consumer端使用多线程方案</p>\n<h3 id=\"调优延时\"><a href=\"#调优延时\" class=\"headerlink\" title=\"调优延时\"></a>调优延时</h3><p>1、在 Broker 端，我们依然要增加 <code>num.replica.fetchers</code> 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时</p>\n<p>2、设置 <code>linger.ms=0</code>，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。</p>\n<p>3、Consumer 端，我们保持<code>fetch.min.bytes=1</code> 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"调优目标\"><a href=\"#调优目标\" class=\"headerlink\" title=\"调优目标\"></a>调优目标</h2><p>吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。</p>\n<p>延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><h3 id=\"操作系统调优\"><a href=\"#操作系统调优\" class=\"headerlink\" title=\"操作系统调优\"></a>操作系统调优</h3><p>1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。</p>\n<p>2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程</p>\n<p>3、ulimit -n 不宜太小</p>\n<p>4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。</p>\n<h3 id=\"JVM-层调优\"><a href=\"#JVM-层调优\" class=\"headerlink\" title=\"JVM 层调优\"></a>JVM 层调优</h3><ol>\n<li>设置堆大小。6～8GB</li>\n<li>GC 收集器使用 G1 收集器。</li>\n</ol>\n<h3 id=\"Broker-端调优\"><a href=\"#Broker-端调优\" class=\"headerlink\" title=\"Broker 端调优\"></a>Broker 端调优</h3><p>保持客户端版本和 Broker 端版本一致。</p>\n<h3 id=\"应用层调优\"><a href=\"#应用层调优\" class=\"headerlink\" title=\"应用层调优\"></a>应用层调优</h3><p>1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。</p>\n<p>2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。</p>\n<h2 id=\"性能指标调优\"><a href=\"#性能指标调优\" class=\"headerlink\" title=\"性能指标调优\"></a>性能指标调优</h2><h3 id=\"调优吞吐量\"><a href=\"#调优吞吐量\" class=\"headerlink\" title=\"调优吞吐量\"></a>调优吞吐量</h3><p>1、broker 端参数 <code>num.replica.fetchers</code>表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。</p>\n<p>2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 <code>batch.size</code> 和 <code>linger.ms</code>。</p>\n<p>3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd</p>\n<p>4、Consumer端使用多线程方案</p>\n<h3 id=\"调优延时\"><a href=\"#调优延时\" class=\"headerlink\" title=\"调优延时\"></a>调优延时</h3><p>1、在 Broker 端，我们依然要增加 <code>num.replica.fetchers</code> 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时</p>\n<p>2、设置 <code>linger.ms=0</code>，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。</p>\n<p>3、Consumer 端，我们保持<code>fetch.min.bytes=1</code> 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。</p>\n"},{"title":"kafka集群配置","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-12-10T13:12:03.000Z","password":null,"summary":null,"_content":"\n## Broker 端参数\n\n- log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移\n- log.dir：单个路径\n\n- zookeeper.connect：zookeeper端口\n- listeners：访问kafka的监听器\n- advertised.listeners：Broker 用于对外发布的监听器\n- auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false\n- unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false\n- auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false\n- log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低\n- log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1\n- message.max.bytes：控制 Broker 能够接收的最大消息大小。\n\n## Topic 级别参数\n\n- retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。\n\n- retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。\n- max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小\n\n创建topic时设置:\n\n```\n\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880\n```\n\n修改topic(推荐)：\n\n```\n\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760\n```\n\n## JVM参数\n\n JVM 堆大小设置成 6GB ，用默认的 G1 收集器\n\n- KAFKA_HEAP_OPTS：指定堆大小。\n- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。\n\n启动broker前设置：\n\n```\n$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$> bin/kafka-server-start.sh config/server.properties\n```\n\n## 操作系统参数\n\n文件描述符限制：`ulimit -n 1000000`，通常将它设置成一个超大的值\n\n文件系统类型：最好选择xfs\n\nSwap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。\n\n提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作\n\n## 动态 Broker 参数配置\n\n**配置的类别**\n\nread-only。只有重启 Broker，才能修改生效。\n\nper-broker。修改后，只会在对应的 Broker 上生效。\n\ncluster-wide。修改后，会在整个集群范围内生效。\n\n**使用场景**\n\n- 动态调整 Broker 端各种线程池大小，实时应对突发流量。\n- 动态调整 Broker 端连接信息或安全配置信息。\n- 动态更新 SSL Keystore 有效期。\n- 动态调整 Broker 端 Compact 操作性能。\n- 实时变更 JMX 指标收集器 。\n\n**实现**\n\nKafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。\n\n![](atoconfig.png)\n\nchanges 是用来实时监测动态参数变更的；\n\ntopics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。\n\nusers 和 clients 则是用于动态调整客户端配额的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。\n\n/config/brokers znode 才是保存动态 Broker 参数。第一类子节点< default >，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。\n\n**设置**\n\n```shell\n# 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable\n```\n\n**常用动态参数**\n\n- log.retention.ms：日志留存时间\n- num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。\n- num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。\n\n","source":"_posts/kafka集群配置.md","raw":"---\ntitle: kafka集群配置\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-12-10 21:12:03\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## Broker 端参数\n\n- log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移\n- log.dir：单个路径\n\n- zookeeper.connect：zookeeper端口\n- listeners：访问kafka的监听器\n- advertised.listeners：Broker 用于对外发布的监听器\n- auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false\n- unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false\n- auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false\n- log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低\n- log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1\n- message.max.bytes：控制 Broker 能够接收的最大消息大小。\n\n## Topic 级别参数\n\n- retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。\n\n- retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。\n- max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小\n\n创建topic时设置:\n\n```\n\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880\n```\n\n修改topic(推荐)：\n\n```\n\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760\n```\n\n## JVM参数\n\n JVM 堆大小设置成 6GB ，用默认的 G1 收集器\n\n- KAFKA_HEAP_OPTS：指定堆大小。\n- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。\n\n启动broker前设置：\n\n```\n$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$> bin/kafka-server-start.sh config/server.properties\n```\n\n## 操作系统参数\n\n文件描述符限制：`ulimit -n 1000000`，通常将它设置成一个超大的值\n\n文件系统类型：最好选择xfs\n\nSwap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。\n\n提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作\n\n## 动态 Broker 参数配置\n\n**配置的类别**\n\nread-only。只有重启 Broker，才能修改生效。\n\nper-broker。修改后，只会在对应的 Broker 上生效。\n\ncluster-wide。修改后，会在整个集群范围内生效。\n\n**使用场景**\n\n- 动态调整 Broker 端各种线程池大小，实时应对突发流量。\n- 动态调整 Broker 端连接信息或安全配置信息。\n- 动态更新 SSL Keystore 有效期。\n- 动态调整 Broker 端 Compact 操作性能。\n- 实时变更 JMX 指标收集器 。\n\n**实现**\n\nKafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。\n\n![](atoconfig.png)\n\nchanges 是用来实时监测动态参数变更的；\n\ntopics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。\n\nusers 和 clients 则是用于动态调整客户端配额的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。\n\n/config/brokers znode 才是保存动态 Broker 参数。第一类子节点< default >，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。\n\n**设置**\n\n```shell\n# 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable\n```\n\n**常用动态参数**\n\n- log.retention.ms：日志留存时间\n- num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。\n- num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。\n\n","slug":"kafka集群配置","published":1,"updated":"2021-04-28T12:38:22.204Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6ud001sq4uf22cr7xrv","content":"<h2 id=\"Broker-端参数\"><a href=\"#Broker-端参数\" class=\"headerlink\" title=\"Broker 端参数\"></a>Broker 端参数</h2><ul>\n<li><p>log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移</p>\n</li>\n<li><p>log.dir：单个路径</p>\n</li>\n<li><p>zookeeper.connect：zookeeper端口</p>\n</li>\n<li><p>listeners：访问kafka的监听器</p>\n</li>\n<li><p>advertised.listeners：Broker 用于对外发布的监听器</p>\n</li>\n<li><p>auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false</p>\n</li>\n<li><p>unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false</p>\n</li>\n<li><p>auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false</p>\n</li>\n<li><p>log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低</p>\n</li>\n<li><p>log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1</p>\n</li>\n<li><p>message.max.bytes：控制 Broker 能够接收的最大消息大小。</p>\n</li>\n</ul>\n<h2 id=\"Topic-级别参数\"><a href=\"#Topic-级别参数\" class=\"headerlink\" title=\"Topic 级别参数\"></a>Topic 级别参数</h2><ul>\n<li><p>retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。</p>\n</li>\n<li><p>retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。</p>\n</li>\n<li><p>max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小</p>\n</li>\n</ul>\n<p>创建topic时设置:</p>\n<pre><code>\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880</code></pre><p>修改topic(推荐)：</p>\n<pre><code>\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760</code></pre><h2 id=\"JVM参数\"><a href=\"#JVM参数\" class=\"headerlink\" title=\"JVM参数\"></a>JVM参数</h2><p> JVM 堆大小设置成 6GB ，用默认的 G1 收集器</p>\n<ul>\n<li>KAFKA_HEAP_OPTS：指定堆大小。</li>\n<li>KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。</li>\n</ul>\n<p>启动broker前设置：</p>\n<pre><code>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$&gt; bin/kafka-server-start.sh config/server.properties</code></pre><h2 id=\"操作系统参数\"><a href=\"#操作系统参数\" class=\"headerlink\" title=\"操作系统参数\"></a>操作系统参数</h2><p>文件描述符限制：<code>ulimit -n 1000000</code>，通常将它设置成一个超大的值</p>\n<p>文件系统类型：最好选择xfs</p>\n<p>Swap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。</p>\n<p>提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作</p>\n<h2 id=\"动态-Broker-参数配置\"><a href=\"#动态-Broker-参数配置\" class=\"headerlink\" title=\"动态 Broker 参数配置\"></a>动态 Broker 参数配置</h2><p><strong>配置的类别</strong></p>\n<p>read-only。只有重启 Broker，才能修改生效。</p>\n<p>per-broker。修改后，只会在对应的 Broker 上生效。</p>\n<p>cluster-wide。修改后，会在整个集群范围内生效。</p>\n<p><strong>使用场景</strong></p>\n<ul>\n<li>动态调整 Broker 端各种线程池大小，实时应对突发流量。</li>\n<li>动态调整 Broker 端连接信息或安全配置信息。</li>\n<li>动态更新 SSL Keystore 有效期。</li>\n<li>动态调整 Broker 端 Compact 操作性能。</li>\n<li>实时变更 JMX 指标收集器 。</li>\n</ul>\n<p><strong>实现</strong></p>\n<p>Kafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。</p>\n<p><img src=\"atoconfig.png\" alt></p>\n<p>changes 是用来实时监测动态参数变更的；</p>\n<p>topics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。</p>\n<p>users 和 clients 则是用于动态调整客户端配额的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。</p>\n<p>/config/brokers znode 才是保存动态 Broker 参数。第一类子节点&lt; default &gt;，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。</p>\n<p><strong>设置</strong></p>\n<pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>常用动态参数</strong></p>\n<ul>\n<li>log.retention.ms：日志留存时间</li>\n<li>num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。</li>\n<li>num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"Broker-端参数\"><a href=\"#Broker-端参数\" class=\"headerlink\" title=\"Broker 端参数\"></a>Broker 端参数</h2><ul>\n<li><p>log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移</p>\n</li>\n<li><p>log.dir：单个路径</p>\n</li>\n<li><p>zookeeper.connect：zookeeper端口</p>\n</li>\n<li><p>listeners：访问kafka的监听器</p>\n</li>\n<li><p>advertised.listeners：Broker 用于对外发布的监听器</p>\n</li>\n<li><p>auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false</p>\n</li>\n<li><p>unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false</p>\n</li>\n<li><p>auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false</p>\n</li>\n<li><p>log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低</p>\n</li>\n<li><p>log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1</p>\n</li>\n<li><p>message.max.bytes：控制 Broker 能够接收的最大消息大小。</p>\n</li>\n</ul>\n<h2 id=\"Topic-级别参数\"><a href=\"#Topic-级别参数\" class=\"headerlink\" title=\"Topic 级别参数\"></a>Topic 级别参数</h2><ul>\n<li><p>retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。</p>\n</li>\n<li><p>retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。</p>\n</li>\n<li><p>max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小</p>\n</li>\n</ul>\n<p>创建topic时设置:</p>\n<pre><code>\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880</code></pre><p>修改topic(推荐)：</p>\n<pre><code>\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760</code></pre><h2 id=\"JVM参数\"><a href=\"#JVM参数\" class=\"headerlink\" title=\"JVM参数\"></a>JVM参数</h2><p> JVM 堆大小设置成 6GB ，用默认的 G1 收集器</p>\n<ul>\n<li>KAFKA_HEAP_OPTS：指定堆大小。</li>\n<li>KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。</li>\n</ul>\n<p>启动broker前设置：</p>\n<pre><code>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$&gt; bin/kafka-server-start.sh config/server.properties</code></pre><h2 id=\"操作系统参数\"><a href=\"#操作系统参数\" class=\"headerlink\" title=\"操作系统参数\"></a>操作系统参数</h2><p>文件描述符限制：<code>ulimit -n 1000000</code>，通常将它设置成一个超大的值</p>\n<p>文件系统类型：最好选择xfs</p>\n<p>Swap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。</p>\n<p>提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作</p>\n<h2 id=\"动态-Broker-参数配置\"><a href=\"#动态-Broker-参数配置\" class=\"headerlink\" title=\"动态 Broker 参数配置\"></a>动态 Broker 参数配置</h2><p><strong>配置的类别</strong></p>\n<p>read-only。只有重启 Broker，才能修改生效。</p>\n<p>per-broker。修改后，只会在对应的 Broker 上生效。</p>\n<p>cluster-wide。修改后，会在整个集群范围内生效。</p>\n<p><strong>使用场景</strong></p>\n<ul>\n<li>动态调整 Broker 端各种线程池大小，实时应对突发流量。</li>\n<li>动态调整 Broker 端连接信息或安全配置信息。</li>\n<li>动态更新 SSL Keystore 有效期。</li>\n<li>动态调整 Broker 端 Compact 操作性能。</li>\n<li>实时变更 JMX 指标收集器 。</li>\n</ul>\n<p><strong>实现</strong></p>\n<p>Kafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。</p>\n<p><img src=\"atoconfig.png\" alt></p>\n<p>changes 是用来实时监测动态参数变更的；</p>\n<p>topics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。</p>\n<p>users 和 clients 则是用于动态调整客户端配额的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。</p>\n<p>/config/brokers znode 才是保存动态 Broker 参数。第一类子节点&lt; default &gt;，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。</p>\n<p><strong>设置</strong></p>\n<pre><code class=\"shell\"># 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable</code></pre>\n<p><strong>常用动态参数</strong></p>\n<ul>\n<li>log.retention.ms：日志留存时间</li>\n<li>num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。</li>\n<li>num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。</li>\n</ul>\n"},{"title":"kafka脚本","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T11:52:44.000Z","password":null,"summary":null,"_content":"\n## 生产消息\n\n```shell\n# 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n>\n```\n\n## 消费消息\n\n```shell\n# 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false \n```\n\n## 测试生产者性能\n\n```shell\n# 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.\n```\n\n## 测试消费者性能\n\n```shell\n$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012\n```\n\n## 查看主题消息总数\n\n```shell\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w\n```\n\n## 查看消息文件数据\n\n```shell\n\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n```\n\n## 查看消费者组位移\n\n```shell\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group\n```\n\n","source":"_posts/kafka脚本.md","raw":"---\ntitle: kafka脚本\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 19:52:44\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 生产消息\n\n```shell\n# 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n>\n```\n\n## 消费消息\n\n```shell\n# 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false \n```\n\n## 测试生产者性能\n\n```shell\n# 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.\n```\n\n## 测试消费者性能\n\n```shell\n$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012\n```\n\n## 查看主题消息总数\n\n```shell\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w\n```\n\n## 查看消息文件数据\n\n```shell\n\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n```\n\n## 查看消费者组位移\n\n```shell\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group\n```\n\n","slug":"kafka脚本","published":1,"updated":"2021-04-28T12:44:09.831Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6uj001uq4uf2kip4udp","content":"<h2 id=\"生产消息\"><a href=\"#生产消息\" class=\"headerlink\" title=\"生产消息\"></a>生产消息</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h2 id=\"测试生产者性能\"><a href=\"#测试生产者性能\" class=\"headerlink\" title=\"测试生产者性能\"></a>测试生产者性能</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"测试消费者性能\"><a href=\"#测试消费者性能\" class=\"headerlink\" title=\"测试消费者性能\"></a>测试消费者性能</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看主题消息总数\"><a href=\"#查看主题消息总数\" class=\"headerlink\" title=\"查看主题消息总数\"></a>查看主题消息总数</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看消息文件数据\"><a href=\"#查看消息文件数据\" class=\"headerlink\" title=\"查看消息文件数据\"></a>查看消息文件数据</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看消费者组位移\"><a href=\"#查看消费者组位移\" class=\"headerlink\" title=\"查看消费者组位移\"></a>查看消费者组位移</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"生产消息\"><a href=\"#生产消息\" class=\"headerlink\" title=\"生产消息\"></a>生产消息</h2><pre><code class=\"shell\"># 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n&gt;</code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><pre><code class=\"shell\"># 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false </code></pre>\n<h2 id=\"测试生产者性能\"><a href=\"#测试生产者性能\" class=\"headerlink\" title=\"测试生产者性能\"></a>测试生产者性能</h2><pre><code class=\"shell\"># 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.</code></pre>\n<h2 id=\"测试消费者性能\"><a href=\"#测试消费者性能\" class=\"headerlink\" title=\"测试消费者性能\"></a>测试消费者性能</h2><pre><code class=\"shell\">$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012</code></pre>\n<h2 id=\"查看主题消息总数\"><a href=\"#查看主题消息总数\" class=\"headerlink\" title=\"查看主题消息总数\"></a>查看主题消息总数</h2><pre><code class=\"shell\">$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w</code></pre>\n<h2 id=\"查看消息文件数据\"><a href=\"#查看消息文件数据\" class=\"headerlink\" title=\"查看消息文件数据\"></a>查看消息文件数据</h2><pre><code class=\"shell\">\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......</code></pre>\n<h2 id=\"查看消费者组位移\"><a href=\"#查看消费者组位移\" class=\"headerlink\" title=\"查看消费者组位移\"></a>查看消费者组位移</h2><pre><code class=\"shell\">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group</code></pre>\n"},{"title":"mysql思维导图","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-02T13:28:18.000Z","password":null,"summary":"博客中mysql相关思维导图","_content":"\n![](mysql.png)","source":"_posts/mysql思维导图.md","raw":"---\ntitle: mysql思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-02 21:28:18\npassword:\nsummary: 博客中mysql相关思维导图\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n![](mysql.png)","slug":"mysql思维导图","published":1,"updated":"2021-04-02T13:29:59.029Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6v0001xq4ufvjotaaxd","content":"<p><img src=\"mysql.png\" alt></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p><img src=\"mysql.png\" alt></p>\n"},{"title":"kafka高水位和Leader Epoch","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T12:07:34.000Z","password":null,"summary":null,"_content":"\n## 高水位\n\n在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。\n\n**作用**\n\n- 定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。\n- 帮助 Kafka 完成副本同步。\n\n**LEO（Log End Offset）**表示副本写入下一条消息的位移值。\n\n## 高水位更新机制\n\n![](water.jpg)\n\n![](watertime.jpg)\n\n### **Leader 副本高水位**\n\n**处理生产者请求**的逻辑如下：\n\n1、写入消息到本地磁盘。\n\n2、更新分区高水位值。\n\ni. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。\n\nii. 获取 Leader 副本高水位值：currentHW。\n\niii. 更新 `currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}`。\n\n**处理 Follower 副本拉取消息**的逻辑如下：\n\n1、读取磁盘（或页缓存）中的消息数据。\n\n2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。\n\n3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。\n\n### **Follower 副本高水位**\n\n**从 Leader 拉取消息的处理逻辑**如下：\n\n1、写入消息到本地磁盘。\n\n2、更新 LEO 值。\n\n3、更新高水位值。\n\ni. 获取 Leader 发送的高水位值：currentHW。\n\nii. 获取步骤 2 中更新过的 LEO 值：currentLEO。\n\niii. 更新高水位为 `min(currentHW, currentLEO)`。\n\n### 高水位更新说明\n\n新消息写入时，先更新leader副本LEO，\n\nfollower副本新消息写入后第一次拉消息，更新了follower副本的LEO，\n\nfollower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位\n\n**问题**：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。\n\n**背景**：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。\n\n![](bad.jpg)\n\n1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 **LEO 值由2调整为之前的高水位值**，也就是 1。\n\n2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。\n\n**影响：**位移值为 1 的消息丢失。\n\n## Leader Epoch\n\n它由两部分数据组成。\n\n- Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。\n- 起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。\n\nKafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。\n\n**解决：**\n\n![](good.jpg)\n\nFollower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 **Leader 的 LEO 值**。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 > 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。\n\n副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。\n\n后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。","source":"_posts/kafka高水位和Leader-Epoch.md","raw":"---\ntitle: kafka高水位和Leader Epoch\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 20:07:34\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 高水位\n\n在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。\n\n**作用**\n\n- 定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。\n- 帮助 Kafka 完成副本同步。\n\n**LEO（Log End Offset）**表示副本写入下一条消息的位移值。\n\n## 高水位更新机制\n\n![](water.jpg)\n\n![](watertime.jpg)\n\n### **Leader 副本高水位**\n\n**处理生产者请求**的逻辑如下：\n\n1、写入消息到本地磁盘。\n\n2、更新分区高水位值。\n\ni. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。\n\nii. 获取 Leader 副本高水位值：currentHW。\n\niii. 更新 `currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}`。\n\n**处理 Follower 副本拉取消息**的逻辑如下：\n\n1、读取磁盘（或页缓存）中的消息数据。\n\n2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。\n\n3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。\n\n### **Follower 副本高水位**\n\n**从 Leader 拉取消息的处理逻辑**如下：\n\n1、写入消息到本地磁盘。\n\n2、更新 LEO 值。\n\n3、更新高水位值。\n\ni. 获取 Leader 发送的高水位值：currentHW。\n\nii. 获取步骤 2 中更新过的 LEO 值：currentLEO。\n\niii. 更新高水位为 `min(currentHW, currentLEO)`。\n\n### 高水位更新说明\n\n新消息写入时，先更新leader副本LEO，\n\nfollower副本新消息写入后第一次拉消息，更新了follower副本的LEO，\n\nfollower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位\n\n**问题**：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。\n\n**背景**：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。\n\n![](bad.jpg)\n\n1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 **LEO 值由2调整为之前的高水位值**，也就是 1。\n\n2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。\n\n**影响：**位移值为 1 的消息丢失。\n\n## Leader Epoch\n\n它由两部分数据组成。\n\n- Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。\n- 起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。\n\nKafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。\n\n**解决：**\n\n![](good.jpg)\n\nFollower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 **Leader 的 LEO 值**。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 > 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。\n\n副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。\n\n后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。","slug":"kafka高水位和Leader-Epoch","published":1,"updated":"2021-04-01T23:38:36.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6va0020q4ufb8mssjuj","content":"<h2 id=\"高水位\"><a href=\"#高水位\" class=\"headerlink\" title=\"高水位\"></a>高水位</h2><p>在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。</p>\n<p><strong>作用</strong></p>\n<ul>\n<li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。</li>\n<li>帮助 Kafka 完成副本同步。</li>\n</ul>\n<p><strong>LEO（Log End Offset）</strong>表示副本写入下一条消息的位移值。</p>\n<h2 id=\"高水位更新机制\"><a href=\"#高水位更新机制\" class=\"headerlink\" title=\"高水位更新机制\"></a>高水位更新机制</h2><p><img src=\"water.jpg\" alt></p>\n<p><img src=\"watertime.jpg\" alt></p>\n<h3 id=\"Leader-副本高水位\"><a href=\"#Leader-副本高水位\" class=\"headerlink\" title=\"Leader 副本高水位\"></a><strong>Leader 副本高水位</strong></h3><p><strong>处理生产者请求</strong>的逻辑如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新分区高水位值。</p>\n<p>i. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。</p>\n<p>ii. 获取 Leader 副本高水位值：currentHW。</p>\n<p>iii. 更新 <code>currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}</code>。</p>\n<p><strong>处理 Follower 副本拉取消息</strong>的逻辑如下：</p>\n<p>1、读取磁盘（或页缓存）中的消息数据。</p>\n<p>2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。</p>\n<p>3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。</p>\n<h3 id=\"Follower-副本高水位\"><a href=\"#Follower-副本高水位\" class=\"headerlink\" title=\"Follower 副本高水位\"></a><strong>Follower 副本高水位</strong></h3><p><strong>从 Leader 拉取消息的处理逻辑</strong>如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新 LEO 值。</p>\n<p>3、更新高水位值。</p>\n<p>i. 获取 Leader 发送的高水位值：currentHW。</p>\n<p>ii. 获取步骤 2 中更新过的 LEO 值：currentLEO。</p>\n<p>iii. 更新高水位为 <code>min(currentHW, currentLEO)</code>。</p>\n<h3 id=\"高水位更新说明\"><a href=\"#高水位更新说明\" class=\"headerlink\" title=\"高水位更新说明\"></a>高水位更新说明</h3><p>新消息写入时，先更新leader副本LEO，</p>\n<p>follower副本新消息写入后第一次拉消息，更新了follower副本的LEO，</p>\n<p>follower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位</p>\n<p><strong>问题</strong>：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。</p>\n<p><strong>背景</strong>：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。</p>\n<p><img src=\"bad.jpg\" alt></p>\n<p>1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 <strong>LEO 值由2调整为之前的高水位值</strong>，也就是 1。</p>\n<p>2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。</p>\n<p><strong>影响：</strong>位移值为 1 的消息丢失。</p>\n<h2 id=\"Leader-Epoch\"><a href=\"#Leader-Epoch\" class=\"headerlink\" title=\"Leader Epoch\"></a>Leader Epoch</h2><p>它由两部分数据组成。</p>\n<ul>\n<li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>\n<li>起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。</li>\n</ul>\n<p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。</p>\n<p><strong>解决：</strong></p>\n<p><img src=\"good.jpg\" alt></p>\n<p>Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 <strong>Leader 的 LEO 值</strong>。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。</p>\n<p>副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。</p>\n<p>后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"高水位\"><a href=\"#高水位\" class=\"headerlink\" title=\"高水位\"></a>高水位</h2><p>在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。</p>\n<p><strong>作用</strong></p>\n<ul>\n<li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。</li>\n<li>帮助 Kafka 完成副本同步。</li>\n</ul>\n<p><strong>LEO（Log End Offset）</strong>表示副本写入下一条消息的位移值。</p>\n<h2 id=\"高水位更新机制\"><a href=\"#高水位更新机制\" class=\"headerlink\" title=\"高水位更新机制\"></a>高水位更新机制</h2><p><img src=\"water.jpg\" alt></p>\n<p><img src=\"watertime.jpg\" alt></p>\n<h3 id=\"Leader-副本高水位\"><a href=\"#Leader-副本高水位\" class=\"headerlink\" title=\"Leader 副本高水位\"></a><strong>Leader 副本高水位</strong></h3><p><strong>处理生产者请求</strong>的逻辑如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新分区高水位值。</p>\n<p>i. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。</p>\n<p>ii. 获取 Leader 副本高水位值：currentHW。</p>\n<p>iii. 更新 <code>currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}</code>。</p>\n<p><strong>处理 Follower 副本拉取消息</strong>的逻辑如下：</p>\n<p>1、读取磁盘（或页缓存）中的消息数据。</p>\n<p>2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。</p>\n<p>3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。</p>\n<h3 id=\"Follower-副本高水位\"><a href=\"#Follower-副本高水位\" class=\"headerlink\" title=\"Follower 副本高水位\"></a><strong>Follower 副本高水位</strong></h3><p><strong>从 Leader 拉取消息的处理逻辑</strong>如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新 LEO 值。</p>\n<p>3、更新高水位值。</p>\n<p>i. 获取 Leader 发送的高水位值：currentHW。</p>\n<p>ii. 获取步骤 2 中更新过的 LEO 值：currentLEO。</p>\n<p>iii. 更新高水位为 <code>min(currentHW, currentLEO)</code>。</p>\n<h3 id=\"高水位更新说明\"><a href=\"#高水位更新说明\" class=\"headerlink\" title=\"高水位更新说明\"></a>高水位更新说明</h3><p>新消息写入时，先更新leader副本LEO，</p>\n<p>follower副本新消息写入后第一次拉消息，更新了follower副本的LEO，</p>\n<p>follower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位</p>\n<p><strong>问题</strong>：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。</p>\n<p><strong>背景</strong>：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。</p>\n<p><img src=\"bad.jpg\" alt></p>\n<p>1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 <strong>LEO 值由2调整为之前的高水位值</strong>，也就是 1。</p>\n<p>2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。</p>\n<p><strong>影响：</strong>位移值为 1 的消息丢失。</p>\n<h2 id=\"Leader-Epoch\"><a href=\"#Leader-Epoch\" class=\"headerlink\" title=\"Leader Epoch\"></a>Leader Epoch</h2><p>它由两部分数据组成。</p>\n<ul>\n<li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>\n<li>起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。</li>\n</ul>\n<p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。</p>\n<p><strong>解决：</strong></p>\n<p><img src=\"good.jpg\" alt></p>\n<p>Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 <strong>Leader 的 LEO 值</strong>。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。</p>\n<p>副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。</p>\n<p>后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。</p>\n"},{"title":"kafka面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-08T11:55:21.000Z","password":null,"summary":null,"_content":"\n## Kafka 是什么？主要应用场景有哪些？\n\nKafka 是一个分布式流式处理平台，可以作为企业级的消息引擎。\n\nKafka 主要有两大应用场景：\n\n1. **消息队列** ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。\n2. **数据处理：** 构建实时的流数据处理程序来转换或处理数据流。\n\n## Kafka的优势在哪里？\n\n1. **极致的性能** ：最高可以每秒处理千万级别的消息。\n2. **生态系统兼容性无可匹敌** ：尤其在大数据和流计算领域。\n\n## 队列模型？Kafka 的消息模型？\n\n### 队列模型\n\n使用队列作为消息通信载体，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。 \n\n**问题**\n\n将生产者产生的消息分发给多个消费者难以处理。\n\n### 发布-订阅模型（Kafka 消息模型）\n\n 使用主题作为消息通信载体，类似于广播模式；生产者发布一条消息，该消息通过主题传递给所有的订阅者。\n\n如果只有一个订阅者，那就退化到队列模型。\n\n## Producer、Consumer、Broker、Topic、Partition、Record？\n\n1. **Producer（生产者）** ： 产生消息的一方。\n2. **Consumer（消费者）**：消费消息的一方。\n3. **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。\n\n- **Topic（主题）** : kafka 通过不同的主题区分不同的业务类型的消息记录。Producer 将消息发送到特定的主题，Consumer 通过订阅特定的主题来消费消息。\n- **Partition（分区）**： Partition属于Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上。\n- **记录（Record）：**实际写入到kafka集群并且可以被消费者读取的数据。每条记录包含一个键、值和时间戳。\n\n## 什么是消费者组？\n\n可扩展且具有容错性的消费者机制。\n\n- Kafka允许你将同一份消息广播到多个消费者组里。\n- 一个消费者组中可以包含多个消费者，他们共同消费该主题的数据。\n- 同一个消费者组下的消费者有相同的组ID，他们被分配不同的订阅分区。\n- 当某个消费者挂掉的时候，其他消费者会自动地承担起它负责消费的分区。 \n\n## LEO、LSO、AR、ISR、HW？\n\n- LEO（Log End Offset）：日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。\n- LSO（Log Stable Offset）：该值控制了事务型消费者能够看到的消息范围。\n- AR（Assigned Replicas）：主题被创建后，创建的副本集合，副本个数由副本因子决定。\n- ISR（In-Sync Replicas）：AR中与Leader保持同步的副本集合。Leader副本天然在ISR中。\n- HW（High watermark）：高水位值，这是控制消费者可读取消息范围。一个普通消费者只能看到Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。\n\n## 位移的作用\n\n用于标识消息在分区中的位置。\n\n一旦消息被写入到分区日志，它的位移值将不能被修改。\n\n## 磁盘容量规划考虑因素？\n\n  - 新增消息数\n  - 消息留存时间\n  - 平均消息大小\n  - 备份数\n  - 是否启用压缩\n\n## __consumer_offsets 作用？\n\n- 内部主题，存储消费者的位移数据\n- 保存消费者组相关的消息\n- 用于删除消费者组过期位移、删除消费者组的消息。tombstone 消息，即墓碑消息\n\n## 多副本机制？好处？\n\n- Kafka副本当前分为领导者副本和追随者副本。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n- 只有Leader副本才能对外提供读写服务。\n- Follower副本只是采用拉的方式，同步Leader副本中的数据\n- 在Leader副本所在的Broker宕机后，Kafka 依托于 ZooKeeper 提供的监控，实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。\n\n**多分区多副本好处？**\n\n1. Kafka 通过给特定 Topic 指定多个 Partition， 而各个 Partition 可以分布在不同的 Broker 上， 这样便能提供比较好的并发能力（负载均衡）。\n2. 多副本提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。\n3. 方便实现“Read-your-writes”\n4. 方便实现单调读：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在\n\n## Zookeeper 的作用？\n\n- 存放元数据：主题分区的相关数据都保存在 ZooKeeper 中，且以它保存的数据为权威。\n- 成员管理：Broker 节点的注册、注销以及属性变更。\n- Controller 选举：选举集群 Controller节点\n- 其他管理类任务：包括但不限于主题删除、参数配置等。\n\n##  如何保证消息的消费顺序？\n\n分区是真正保存消息的地方。Topic 可以指定多个 Partition。\n\nKafka 只能为我们保证分区中的消息有序，而不能保证 主题中的消息有序。\n\n1. 1 个 Topic 只对应一个 Partition。\n2. （推荐）发送消息的时候指定 key/Partition。\n\n## 如何保证消息不丢失\n\n### 生产者丢失消息\n\n- 生产者调用`send`方法发送消息之后，消息可能因为网络问题并没有发送过去。 为了确定消息是发送成功，我们要判断消息发送的结果。可以采用回调函数的形式，如果消息发送失败的话，我们检查失败的原因之后重新发送即可。\n\n- 为 生产者的`retries `（重试次数）设置一个比较合理的值，一般是 3 。\n- **设置 acks = all**，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交\n\n### 消费者丢失消息\n\n- 关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。\n\n### Kafka 弄丢消息\n\n- 设置 `replication.factor >= 3`。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。\n- 设置 `min.insync.replicas > 1`。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。\n- 设置 `unclean.leader.election.enable = false`。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。\n\n## 如何保证消息不重复消费\n\n去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过。\n\n## 为什么性能好\n\n### 顺序写\n\n> 操作系统读写磁盘时，需要先寻址，再进行数据读写。如果是机械硬盘，寻址就需要较长的时间。\n\n Kafka 用的是顺序写，追加数据是追加到末尾，磁盘顺序写的性能极高。\n\n### 零拷贝\n\nKafka 利用了 Linux 的 sendFile 技术实现零拷贝，直接从磁盘文件复制到网卡设备中,减少了内核和用户模式之间的上下文切换。\n\n### 网络线程模型\n\n加强版的 Reactor 网络线程模型\n\n### 消息批量量处理\n\n合并小的请求，然后以流的方式进行交互，直顶网络上限。\n\n## 为什么不支持读写分离？\n\nCAP理论下，我们只能保证可用性和一致性取其一。\n\n如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣。\n\n如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。\n\n## Controller发生网络分区时，Kafka会怎么样？\n\n判断：Broker端的ActiveControllerCount。\n\n由于Controller会给Broker发送3类请求，LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，因此，一旦出现网络分区，这些请求将不能顺利到达Broker端。\n\n将影响主题的创建、修改、删除操作的信息同步。\n\n## Java Consumer 为什么采用单线程来获取消息？\n\nJava Consumer是双线程的设计。用户主线程，负责获取消息；心跳线程，负责向Kafka汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的“假死”情况。\n\n- 单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。\n- 可以简化代码的开发。多线程交互的代码是非常容易出错的。\n\n## Follower副本消息同步的流程？\n\n- Follower发送FETCH请求给Leader。\n- Leader会读取底层日志文件中的消息数据，使用FETCH请求中的fetchOffset，更新Follower远程副本的LEO值。leader副本尝试更新分区高水位值。\n- Follower接收到FETCH响应之后，会把消息写入到底层日志，接着更新LEO和HW值。\n\nLeader和Follower的HW值更新时机是不同的，Follower的HW更新永远落后于Leader的HW。这种时间上的错配是造成各种不一致的原因。\n\n## Leader总是-1，怎么破？\n\n通常情况下就是Controller不工作了，导致无法分配leader。\n\n方法\n\n1、删除ZooKeeper中的/controller节点，触发Controller重选举。Controller重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题。\n\n2、重启Controller节点上的Kafka进程，让其他节点重新注册Controller角色。\n\n## 如何设置Kafka能接收的最大消息的大小？\n\n- Broker端参数：`message.max.bytes`，`max.message.bytes`（topic级别），`replica.fetch.max.bytes`\n- Consumer端参数：`fetch.message.max.bytes`\n\n## Kafka能手动删除消息吗？\n\n一般不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。同时支持手动删除消息的。\n\n- 对于设置了Key且参数cleanup.policy=compact的主题而言，我们可以构造一条消息发送给Broker，依靠日志清理组件提供的功能删除掉该 Key 的消息。\n- 对于普通主题，可以使用`kafka-delete-records`，或编写程序调用`Admin.deleteRecords`方法来删除消息。\n\n## 如何确定合适的Kafka主题的分区数量？\n\n需要根据每个分区的生产者和消费者的期望吞吐量进行估计,以便达到并行读写、负载均衡和高吞吐。\n\n> 假设期望读取数据的速率1GB/Sec，而一个消费者的读取速率为50MB/Sec，此时至少需要20个分区以及20个消费者。\n>\n> 如果期望生产数据的速率为**1GB/Sec**，而每个生产者的生产速率为**100MB/Sec**，此时就需要有10个分区。\n>\n> 设置20个分区，既可以保障生产速率，也可以保障的吞吐量\n\n## kafka如何实现延迟队列？\n\n**基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）**。基于时间轮可以将插入和删除操作的时间复杂度都降为`O（1）`。\n\n**底层使用数组实现，**数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask。\n\n**推进时间？**Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的`TimingWheel`专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O（1）的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，**这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”**。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。\n\n##  判断一个节点还活着的两个条件？\n\n（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接\n\n（2）如果节点是 follower，他必须能及时的同步 leader 的写操作，延时不能太久\n\n## 消息是采用 Pull 模式，还是 Push 模式？\n\n生产者将消息推送到 broker，消费者从 broker 拉取消息。\n\n##  存储在硬盘上的消息格式是什么？\n\n消息由一个固定长度的头部和可变长度的字节数组组成。\n\n- 消息长度: 4 bytes\n- 版本号: 1 byte\n- CRC 校验码: 4 bytes\n- 具体的消息: n bytes\n\n## ack 机制\n\n- 0：生产者不会等待 broker 的 ack，延迟最低，可能丢数据\n- 1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack，leader切换可能丢数据\n- -1：等所有的 follower 的副本收到数据后，leader 发出的 ack，数据不会丢失\n\n## 消费者如何消费数据\n\nKafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 `ConcurrentModificationException`异常\n\n1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程\n\n2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。","source":"_posts/kafka面试.md","raw":"---\ntitle: kafka面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-08 19:55:21\npassword:\nsummary:\ntags:\n- interview\ncategories:\n- interview\n---\n\n## Kafka 是什么？主要应用场景有哪些？\n\nKafka 是一个分布式流式处理平台，可以作为企业级的消息引擎。\n\nKafka 主要有两大应用场景：\n\n1. **消息队列** ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。\n2. **数据处理：** 构建实时的流数据处理程序来转换或处理数据流。\n\n## Kafka的优势在哪里？\n\n1. **极致的性能** ：最高可以每秒处理千万级别的消息。\n2. **生态系统兼容性无可匹敌** ：尤其在大数据和流计算领域。\n\n## 队列模型？Kafka 的消息模型？\n\n### 队列模型\n\n使用队列作为消息通信载体，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。 \n\n**问题**\n\n将生产者产生的消息分发给多个消费者难以处理。\n\n### 发布-订阅模型（Kafka 消息模型）\n\n 使用主题作为消息通信载体，类似于广播模式；生产者发布一条消息，该消息通过主题传递给所有的订阅者。\n\n如果只有一个订阅者，那就退化到队列模型。\n\n## Producer、Consumer、Broker、Topic、Partition、Record？\n\n1. **Producer（生产者）** ： 产生消息的一方。\n2. **Consumer（消费者）**：消费消息的一方。\n3. **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。\n\n- **Topic（主题）** : kafka 通过不同的主题区分不同的业务类型的消息记录。Producer 将消息发送到特定的主题，Consumer 通过订阅特定的主题来消费消息。\n- **Partition（分区）**： Partition属于Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上。\n- **记录（Record）：**实际写入到kafka集群并且可以被消费者读取的数据。每条记录包含一个键、值和时间戳。\n\n## 什么是消费者组？\n\n可扩展且具有容错性的消费者机制。\n\n- Kafka允许你将同一份消息广播到多个消费者组里。\n- 一个消费者组中可以包含多个消费者，他们共同消费该主题的数据。\n- 同一个消费者组下的消费者有相同的组ID，他们被分配不同的订阅分区。\n- 当某个消费者挂掉的时候，其他消费者会自动地承担起它负责消费的分区。 \n\n## LEO、LSO、AR、ISR、HW？\n\n- LEO（Log End Offset）：日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。\n- LSO（Log Stable Offset）：该值控制了事务型消费者能够看到的消息范围。\n- AR（Assigned Replicas）：主题被创建后，创建的副本集合，副本个数由副本因子决定。\n- ISR（In-Sync Replicas）：AR中与Leader保持同步的副本集合。Leader副本天然在ISR中。\n- HW（High watermark）：高水位值，这是控制消费者可读取消息范围。一个普通消费者只能看到Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。\n\n## 位移的作用\n\n用于标识消息在分区中的位置。\n\n一旦消息被写入到分区日志，它的位移值将不能被修改。\n\n## 磁盘容量规划考虑因素？\n\n  - 新增消息数\n  - 消息留存时间\n  - 平均消息大小\n  - 备份数\n  - 是否启用压缩\n\n## __consumer_offsets 作用？\n\n- 内部主题，存储消费者的位移数据\n- 保存消费者组相关的消息\n- 用于删除消费者组过期位移、删除消费者组的消息。tombstone 消息，即墓碑消息\n\n## 多副本机制？好处？\n\n- Kafka副本当前分为领导者副本和追随者副本。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n- 只有Leader副本才能对外提供读写服务。\n- Follower副本只是采用拉的方式，同步Leader副本中的数据\n- 在Leader副本所在的Broker宕机后，Kafka 依托于 ZooKeeper 提供的监控，实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。\n\n**多分区多副本好处？**\n\n1. Kafka 通过给特定 Topic 指定多个 Partition， 而各个 Partition 可以分布在不同的 Broker 上， 这样便能提供比较好的并发能力（负载均衡）。\n2. 多副本提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。\n3. 方便实现“Read-your-writes”\n4. 方便实现单调读：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在\n\n## Zookeeper 的作用？\n\n- 存放元数据：主题分区的相关数据都保存在 ZooKeeper 中，且以它保存的数据为权威。\n- 成员管理：Broker 节点的注册、注销以及属性变更。\n- Controller 选举：选举集群 Controller节点\n- 其他管理类任务：包括但不限于主题删除、参数配置等。\n\n##  如何保证消息的消费顺序？\n\n分区是真正保存消息的地方。Topic 可以指定多个 Partition。\n\nKafka 只能为我们保证分区中的消息有序，而不能保证 主题中的消息有序。\n\n1. 1 个 Topic 只对应一个 Partition。\n2. （推荐）发送消息的时候指定 key/Partition。\n\n## 如何保证消息不丢失\n\n### 生产者丢失消息\n\n- 生产者调用`send`方法发送消息之后，消息可能因为网络问题并没有发送过去。 为了确定消息是发送成功，我们要判断消息发送的结果。可以采用回调函数的形式，如果消息发送失败的话，我们检查失败的原因之后重新发送即可。\n\n- 为 生产者的`retries `（重试次数）设置一个比较合理的值，一般是 3 。\n- **设置 acks = all**，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交\n\n### 消费者丢失消息\n\n- 关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。\n\n### Kafka 弄丢消息\n\n- 设置 `replication.factor >= 3`。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。\n- 设置 `min.insync.replicas > 1`。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。\n- 设置 `unclean.leader.election.enable = false`。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。\n\n## 如何保证消息不重复消费\n\n去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过。\n\n## 为什么性能好\n\n### 顺序写\n\n> 操作系统读写磁盘时，需要先寻址，再进行数据读写。如果是机械硬盘，寻址就需要较长的时间。\n\n Kafka 用的是顺序写，追加数据是追加到末尾，磁盘顺序写的性能极高。\n\n### 零拷贝\n\nKafka 利用了 Linux 的 sendFile 技术实现零拷贝，直接从磁盘文件复制到网卡设备中,减少了内核和用户模式之间的上下文切换。\n\n### 网络线程模型\n\n加强版的 Reactor 网络线程模型\n\n### 消息批量量处理\n\n合并小的请求，然后以流的方式进行交互，直顶网络上限。\n\n## 为什么不支持读写分离？\n\nCAP理论下，我们只能保证可用性和一致性取其一。\n\n如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣。\n\n如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。\n\n## Controller发生网络分区时，Kafka会怎么样？\n\n判断：Broker端的ActiveControllerCount。\n\n由于Controller会给Broker发送3类请求，LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，因此，一旦出现网络分区，这些请求将不能顺利到达Broker端。\n\n将影响主题的创建、修改、删除操作的信息同步。\n\n## Java Consumer 为什么采用单线程来获取消息？\n\nJava Consumer是双线程的设计。用户主线程，负责获取消息；心跳线程，负责向Kafka汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的“假死”情况。\n\n- 单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。\n- 可以简化代码的开发。多线程交互的代码是非常容易出错的。\n\n## Follower副本消息同步的流程？\n\n- Follower发送FETCH请求给Leader。\n- Leader会读取底层日志文件中的消息数据，使用FETCH请求中的fetchOffset，更新Follower远程副本的LEO值。leader副本尝试更新分区高水位值。\n- Follower接收到FETCH响应之后，会把消息写入到底层日志，接着更新LEO和HW值。\n\nLeader和Follower的HW值更新时机是不同的，Follower的HW更新永远落后于Leader的HW。这种时间上的错配是造成各种不一致的原因。\n\n## Leader总是-1，怎么破？\n\n通常情况下就是Controller不工作了，导致无法分配leader。\n\n方法\n\n1、删除ZooKeeper中的/controller节点，触发Controller重选举。Controller重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题。\n\n2、重启Controller节点上的Kafka进程，让其他节点重新注册Controller角色。\n\n## 如何设置Kafka能接收的最大消息的大小？\n\n- Broker端参数：`message.max.bytes`，`max.message.bytes`（topic级别），`replica.fetch.max.bytes`\n- Consumer端参数：`fetch.message.max.bytes`\n\n## Kafka能手动删除消息吗？\n\n一般不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。同时支持手动删除消息的。\n\n- 对于设置了Key且参数cleanup.policy=compact的主题而言，我们可以构造一条消息发送给Broker，依靠日志清理组件提供的功能删除掉该 Key 的消息。\n- 对于普通主题，可以使用`kafka-delete-records`，或编写程序调用`Admin.deleteRecords`方法来删除消息。\n\n## 如何确定合适的Kafka主题的分区数量？\n\n需要根据每个分区的生产者和消费者的期望吞吐量进行估计,以便达到并行读写、负载均衡和高吞吐。\n\n> 假设期望读取数据的速率1GB/Sec，而一个消费者的读取速率为50MB/Sec，此时至少需要20个分区以及20个消费者。\n>\n> 如果期望生产数据的速率为**1GB/Sec**，而每个生产者的生产速率为**100MB/Sec**，此时就需要有10个分区。\n>\n> 设置20个分区，既可以保障生产速率，也可以保障的吞吐量\n\n## kafka如何实现延迟队列？\n\n**基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）**。基于时间轮可以将插入和删除操作的时间复杂度都降为`O（1）`。\n\n**底层使用数组实现，**数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask。\n\n**推进时间？**Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的`TimingWheel`专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O（1）的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，**这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”**。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。\n\n##  判断一个节点还活着的两个条件？\n\n（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接\n\n（2）如果节点是 follower，他必须能及时的同步 leader 的写操作，延时不能太久\n\n## 消息是采用 Pull 模式，还是 Push 模式？\n\n生产者将消息推送到 broker，消费者从 broker 拉取消息。\n\n##  存储在硬盘上的消息格式是什么？\n\n消息由一个固定长度的头部和可变长度的字节数组组成。\n\n- 消息长度: 4 bytes\n- 版本号: 1 byte\n- CRC 校验码: 4 bytes\n- 具体的消息: n bytes\n\n## ack 机制\n\n- 0：生产者不会等待 broker 的 ack，延迟最低，可能丢数据\n- 1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack，leader切换可能丢数据\n- -1：等所有的 follower 的副本收到数据后，leader 发出的 ack，数据不会丢失\n\n## 消费者如何消费数据\n\nKafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 `ConcurrentModificationException`异常\n\n1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程\n\n2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。","slug":"kafka面试","published":1,"updated":"2021-05-18T21:52:44.088Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6vk0024q4ufxgaq4uay","content":"<h2 id=\"Kafka-是什么？主要应用场景有哪些？\"><a href=\"#Kafka-是什么？主要应用场景有哪些？\" class=\"headerlink\" title=\"Kafka 是什么？主要应用场景有哪些？\"></a>Kafka 是什么？主要应用场景有哪些？</h2><p>Kafka 是一个分布式流式处理平台，可以作为企业级的消息引擎。</p>\n<p>Kafka 主要有两大应用场景：</p>\n<ol>\n<li><strong>消息队列</strong> ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>\n<li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流。</li>\n</ol>\n<h2 id=\"Kafka的优势在哪里？\"><a href=\"#Kafka的优势在哪里？\" class=\"headerlink\" title=\"Kafka的优势在哪里？\"></a>Kafka的优势在哪里？</h2><ol>\n<li><strong>极致的性能</strong> ：最高可以每秒处理千万级别的消息。</li>\n<li><strong>生态系统兼容性无可匹敌</strong> ：尤其在大数据和流计算领域。</li>\n</ol>\n<h2 id=\"队列模型？Kafka-的消息模型？\"><a href=\"#队列模型？Kafka-的消息模型？\" class=\"headerlink\" title=\"队列模型？Kafka 的消息模型？\"></a>队列模型？Kafka 的消息模型？</h2><h3 id=\"队列模型\"><a href=\"#队列模型\" class=\"headerlink\" title=\"队列模型\"></a>队列模型</h3><p>使用队列作为消息通信载体，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。 </p>\n<p><strong>问题</strong></p>\n<p>将生产者产生的消息分发给多个消费者难以处理。</p>\n<h3 id=\"发布-订阅模型（Kafka-消息模型）\"><a href=\"#发布-订阅模型（Kafka-消息模型）\" class=\"headerlink\" title=\"发布-订阅模型（Kafka 消息模型）\"></a>发布-订阅模型（Kafka 消息模型）</h3><p> 使用主题作为消息通信载体，类似于广播模式；生产者发布一条消息，该消息通过主题传递给所有的订阅者。</p>\n<p>如果只有一个订阅者，那就退化到队列模型。</p>\n<h2 id=\"Producer、Consumer、Broker、Topic、Partition、Record？\"><a href=\"#Producer、Consumer、Broker、Topic、Partition、Record？\" class=\"headerlink\" title=\"Producer、Consumer、Broker、Topic、Partition、Record？\"></a>Producer、Consumer、Broker、Topic、Partition、Record？</h2><ol>\n<li><strong>Producer（生产者）</strong> ： 产生消息的一方。</li>\n<li><strong>Consumer（消费者）</strong>：消费消息的一方。</li>\n<li><strong>Broker（代理）</strong> : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。</li>\n</ol>\n<ul>\n<li><strong>Topic（主题）</strong> : kafka 通过不同的主题区分不同的业务类型的消息记录。Producer 将消息发送到特定的主题，Consumer 通过订阅特定的主题来消费消息。</li>\n<li><strong>Partition（分区）</strong>： Partition属于Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上。</li>\n<li><strong>记录（Record）：</strong>实际写入到kafka集群并且可以被消费者读取的数据。每条记录包含一个键、值和时间戳。</li>\n</ul>\n<h2 id=\"什么是消费者组？\"><a href=\"#什么是消费者组？\" class=\"headerlink\" title=\"什么是消费者组？\"></a>什么是消费者组？</h2><p>可扩展且具有容错性的消费者机制。</p>\n<ul>\n<li>Kafka允许你将同一份消息广播到多个消费者组里。</li>\n<li>一个消费者组中可以包含多个消费者，他们共同消费该主题的数据。</li>\n<li>同一个消费者组下的消费者有相同的组ID，他们被分配不同的订阅分区。</li>\n<li>当某个消费者挂掉的时候，其他消费者会自动地承担起它负责消费的分区。 </li>\n</ul>\n<h2 id=\"LEO、LSO、AR、ISR、HW？\"><a href=\"#LEO、LSO、AR、ISR、HW？\" class=\"headerlink\" title=\"LEO、LSO、AR、ISR、HW？\"></a>LEO、LSO、AR、ISR、HW？</h2><ul>\n<li>LEO（Log End Offset）：日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。</li>\n<li>LSO（Log Stable Offset）：该值控制了事务型消费者能够看到的消息范围。</li>\n<li>AR（Assigned Replicas）：主题被创建后，创建的副本集合，副本个数由副本因子决定。</li>\n<li>ISR（In-Sync Replicas）：AR中与Leader保持同步的副本集合。Leader副本天然在ISR中。</li>\n<li>HW（High watermark）：高水位值，这是控制消费者可读取消息范围。一个普通消费者只能看到Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。</li>\n</ul>\n<h2 id=\"位移的作用\"><a href=\"#位移的作用\" class=\"headerlink\" title=\"位移的作用\"></a>位移的作用</h2><p>用于标识消息在分区中的位置。</p>\n<p>一旦消息被写入到分区日志，它的位移值将不能被修改。</p>\n<h2 id=\"磁盘容量规划考虑因素？\"><a href=\"#磁盘容量规划考虑因素？\" class=\"headerlink\" title=\"磁盘容量规划考虑因素？\"></a>磁盘容量规划考虑因素？</h2><ul>\n<li>新增消息数</li>\n<li>消息留存时间</li>\n<li>平均消息大小</li>\n<li>备份数</li>\n<li>是否启用压缩</li>\n</ul>\n<h2 id=\"consumer-offsets-作用？\"><a href=\"#consumer-offsets-作用？\" class=\"headerlink\" title=\"__consumer_offsets 作用？\"></a>__consumer_offsets 作用？</h2><ul>\n<li>内部主题，存储消费者的位移数据</li>\n<li>保存消费者组相关的消息</li>\n<li>用于删除消费者组过期位移、删除消费者组的消息。tombstone 消息，即墓碑消息</li>\n</ul>\n<h2 id=\"多副本机制？好处？\"><a href=\"#多副本机制？好处？\" class=\"headerlink\" title=\"多副本机制？好处？\"></a>多副本机制？好处？</h2><ul>\n<li>Kafka副本当前分为领导者副本和追随者副本。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</li>\n<li>只有Leader副本才能对外提供读写服务。</li>\n<li>Follower副本只是采用拉的方式，同步Leader副本中的数据</li>\n<li>在Leader副本所在的Broker宕机后，Kafka 依托于 ZooKeeper 提供的监控，实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</li>\n</ul>\n<p><strong>多分区多副本好处？</strong></p>\n<ol>\n<li>Kafka 通过给特定 Topic 指定多个 Partition， 而各个 Partition 可以分布在不同的 Broker 上， 这样便能提供比较好的并发能力（负载均衡）。</li>\n<li>多副本提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。</li>\n<li>方便实现“Read-your-writes”</li>\n<li>方便实现单调读：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在</li>\n</ol>\n<h2 id=\"Zookeeper-的作用？\"><a href=\"#Zookeeper-的作用？\" class=\"headerlink\" title=\"Zookeeper 的作用？\"></a>Zookeeper 的作用？</h2><ul>\n<li>存放元数据：主题分区的相关数据都保存在 ZooKeeper 中，且以它保存的数据为权威。</li>\n<li>成员管理：Broker 节点的注册、注销以及属性变更。</li>\n<li>Controller 选举：选举集群 Controller节点</li>\n<li>其他管理类任务：包括但不限于主题删除、参数配置等。</li>\n</ul>\n<h2 id=\"如何保证消息的消费顺序？\"><a href=\"#如何保证消息的消费顺序？\" class=\"headerlink\" title=\"如何保证消息的消费顺序？\"></a>如何保证消息的消费顺序？</h2><p>分区是真正保存消息的地方。Topic 可以指定多个 Partition。</p>\n<p>Kafka 只能为我们保证分区中的消息有序，而不能保证 主题中的消息有序。</p>\n<ol>\n<li>1 个 Topic 只对应一个 Partition。</li>\n<li>（推荐）发送消息的时候指定 key/Partition。</li>\n</ol>\n<h2 id=\"如何保证消息不丢失\"><a href=\"#如何保证消息不丢失\" class=\"headerlink\" title=\"如何保证消息不丢失\"></a>如何保证消息不丢失</h2><h3 id=\"生产者丢失消息\"><a href=\"#生产者丢失消息\" class=\"headerlink\" title=\"生产者丢失消息\"></a>生产者丢失消息</h3><ul>\n<li><p>生产者调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。 为了确定消息是发送成功，我们要判断消息发送的结果。可以采用回调函数的形式，如果消息发送失败的话，我们检查失败的原因之后重新发送即可。</p>\n</li>\n<li><p>为 生产者的<code>retries</code>（重试次数）设置一个比较合理的值，一般是 3 。</p>\n</li>\n<li><p><strong>设置 acks = all</strong>，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交</p>\n</li>\n</ul>\n<h3 id=\"消费者丢失消息\"><a href=\"#消费者丢失消息\" class=\"headerlink\" title=\"消费者丢失消息\"></a>消费者丢失消息</h3><ul>\n<li>关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。</li>\n</ul>\n<h3 id=\"Kafka-弄丢消息\"><a href=\"#Kafka-弄丢消息\" class=\"headerlink\" title=\"Kafka 弄丢消息\"></a>Kafka 弄丢消息</h3><ul>\n<li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li>\n<li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</li>\n<li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li>\n</ul>\n<h2 id=\"如何保证消息不重复消费\"><a href=\"#如何保证消息不重复消费\" class=\"headerlink\" title=\"如何保证消息不重复消费\"></a>如何保证消息不重复消费</h2><p>去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过。</p>\n<h2 id=\"为什么性能好\"><a href=\"#为什么性能好\" class=\"headerlink\" title=\"为什么性能好\"></a>为什么性能好</h2><h3 id=\"顺序写\"><a href=\"#顺序写\" class=\"headerlink\" title=\"顺序写\"></a>顺序写</h3><blockquote>\n<p>操作系统读写磁盘时，需要先寻址，再进行数据读写。如果是机械硬盘，寻址就需要较长的时间。</p>\n</blockquote>\n<p> Kafka 用的是顺序写，追加数据是追加到末尾，磁盘顺序写的性能极高。</p>\n<h3 id=\"零拷贝\"><a href=\"#零拷贝\" class=\"headerlink\" title=\"零拷贝\"></a>零拷贝</h3><p>Kafka 利用了 Linux 的 sendFile 技术实现零拷贝，直接从磁盘文件复制到网卡设备中,减少了内核和用户模式之间的上下文切换。</p>\n<h3 id=\"网络线程模型\"><a href=\"#网络线程模型\" class=\"headerlink\" title=\"网络线程模型\"></a>网络线程模型</h3><p>加强版的 Reactor 网络线程模型</p>\n<h3 id=\"消息批量量处理\"><a href=\"#消息批量量处理\" class=\"headerlink\" title=\"消息批量量处理\"></a>消息批量量处理</h3><p>合并小的请求，然后以流的方式进行交互，直顶网络上限。</p>\n<h2 id=\"为什么不支持读写分离？\"><a href=\"#为什么不支持读写分离？\" class=\"headerlink\" title=\"为什么不支持读写分离？\"></a>为什么不支持读写分离？</h2><p>CAP理论下，我们只能保证可用性和一致性取其一。</p>\n<p>如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣。</p>\n<p>如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。</p>\n<h2 id=\"Controller发生网络分区时，Kafka会怎么样？\"><a href=\"#Controller发生网络分区时，Kafka会怎么样？\" class=\"headerlink\" title=\"Controller发生网络分区时，Kafka会怎么样？\"></a>Controller发生网络分区时，Kafka会怎么样？</h2><p>判断：Broker端的ActiveControllerCount。</p>\n<p>由于Controller会给Broker发送3类请求，LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，因此，一旦出现网络分区，这些请求将不能顺利到达Broker端。</p>\n<p>将影响主题的创建、修改、删除操作的信息同步。</p>\n<h2 id=\"Java-Consumer-为什么采用单线程来获取消息？\"><a href=\"#Java-Consumer-为什么采用单线程来获取消息？\" class=\"headerlink\" title=\"Java Consumer 为什么采用单线程来获取消息？\"></a>Java Consumer 为什么采用单线程来获取消息？</h2><p>Java Consumer是双线程的设计。用户主线程，负责获取消息；心跳线程，负责向Kafka汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的“假死”情况。</p>\n<ul>\n<li>单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。</li>\n<li>可以简化代码的开发。多线程交互的代码是非常容易出错的。</li>\n</ul>\n<h2 id=\"Follower副本消息同步的流程？\"><a href=\"#Follower副本消息同步的流程？\" class=\"headerlink\" title=\"Follower副本消息同步的流程？\"></a>Follower副本消息同步的流程？</h2><ul>\n<li>Follower发送FETCH请求给Leader。</li>\n<li>Leader会读取底层日志文件中的消息数据，使用FETCH请求中的fetchOffset，更新Follower远程副本的LEO值。leader副本尝试更新分区高水位值。</li>\n<li>Follower接收到FETCH响应之后，会把消息写入到底层日志，接着更新LEO和HW值。</li>\n</ul>\n<p>Leader和Follower的HW值更新时机是不同的，Follower的HW更新永远落后于Leader的HW。这种时间上的错配是造成各种不一致的原因。</p>\n<h2 id=\"Leader总是-1，怎么破？\"><a href=\"#Leader总是-1，怎么破？\" class=\"headerlink\" title=\"Leader总是-1，怎么破？\"></a>Leader总是-1，怎么破？</h2><p>通常情况下就是Controller不工作了，导致无法分配leader。</p>\n<p>方法</p>\n<p>1、删除ZooKeeper中的/controller节点，触发Controller重选举。Controller重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题。</p>\n<p>2、重启Controller节点上的Kafka进程，让其他节点重新注册Controller角色。</p>\n<h2 id=\"如何设置Kafka能接收的最大消息的大小？\"><a href=\"#如何设置Kafka能接收的最大消息的大小？\" class=\"headerlink\" title=\"如何设置Kafka能接收的最大消息的大小？\"></a>如何设置Kafka能接收的最大消息的大小？</h2><ul>\n<li>Broker端参数：<code>message.max.bytes</code>，<code>max.message.bytes</code>（topic级别），<code>replica.fetch.max.bytes</code></li>\n<li>Consumer端参数：<code>fetch.message.max.bytes</code></li>\n</ul>\n<h2 id=\"Kafka能手动删除消息吗？\"><a href=\"#Kafka能手动删除消息吗？\" class=\"headerlink\" title=\"Kafka能手动删除消息吗？\"></a>Kafka能手动删除消息吗？</h2><p>一般不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。同时支持手动删除消息的。</p>\n<ul>\n<li>对于设置了Key且参数cleanup.policy=compact的主题而言，我们可以构造一条消息发送给Broker，依靠日志清理组件提供的功能删除掉该 Key 的消息。</li>\n<li>对于普通主题，可以使用<code>kafka-delete-records</code>，或编写程序调用<code>Admin.deleteRecords</code>方法来删除消息。</li>\n</ul>\n<h2 id=\"如何确定合适的Kafka主题的分区数量？\"><a href=\"#如何确定合适的Kafka主题的分区数量？\" class=\"headerlink\" title=\"如何确定合适的Kafka主题的分区数量？\"></a>如何确定合适的Kafka主题的分区数量？</h2><p>需要根据每个分区的生产者和消费者的期望吞吐量进行估计,以便达到并行读写、负载均衡和高吞吐。</p>\n<blockquote>\n<p>假设期望读取数据的速率1GB/Sec，而一个消费者的读取速率为50MB/Sec，此时至少需要20个分区以及20个消费者。</p>\n<p>如果期望生产数据的速率为<strong>1GB/Sec</strong>，而每个生产者的生产速率为<strong>100MB/Sec</strong>，此时就需要有10个分区。</p>\n<p>设置20个分区，既可以保障生产速率，也可以保障的吞吐量</p>\n</blockquote>\n<h2 id=\"kafka如何实现延迟队列？\"><a href=\"#kafka如何实现延迟队列？\" class=\"headerlink\" title=\"kafka如何实现延迟队列？\"></a>kafka如何实现延迟队列？</h2><p><strong>基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）</strong>。基于时间轮可以将插入和删除操作的时间复杂度都降为<code>O（1）</code>。</p>\n<p><strong>底层使用数组实现，</strong>数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask。</p>\n<p><strong>推进时间？</strong>Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的<code>TimingWheel</code>专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O（1）的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，<strong>这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”</strong>。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。</p>\n<h2 id=\"判断一个节点还活着的两个条件？\"><a href=\"#判断一个节点还活着的两个条件？\" class=\"headerlink\" title=\"判断一个节点还活着的两个条件？\"></a>判断一个节点还活着的两个条件？</h2><p>（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接</p>\n<p>（2）如果节点是 follower，他必须能及时的同步 leader 的写操作，延时不能太久</p>\n<h2 id=\"消息是采用-Pull-模式，还是-Push-模式？\"><a href=\"#消息是采用-Pull-模式，还是-Push-模式？\" class=\"headerlink\" title=\"消息是采用 Pull 模式，还是 Push 模式？\"></a>消息是采用 Pull 模式，还是 Push 模式？</h2><p>生产者将消息推送到 broker，消费者从 broker 拉取消息。</p>\n<h2 id=\"存储在硬盘上的消息格式是什么？\"><a href=\"#存储在硬盘上的消息格式是什么？\" class=\"headerlink\" title=\"存储在硬盘上的消息格式是什么？\"></a>存储在硬盘上的消息格式是什么？</h2><p>消息由一个固定长度的头部和可变长度的字节数组组成。</p>\n<ul>\n<li>消息长度: 4 bytes</li>\n<li>版本号: 1 byte</li>\n<li>CRC 校验码: 4 bytes</li>\n<li>具体的消息: n bytes</li>\n</ul>\n<h2 id=\"ack-机制\"><a href=\"#ack-机制\" class=\"headerlink\" title=\"ack 机制\"></a>ack 机制</h2><ul>\n<li>0：生产者不会等待 broker 的 ack，延迟最低，可能丢数据</li>\n<li>1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack，leader切换可能丢数据</li>\n<li>-1：等所有的 follower 的副本收到数据后，leader 发出的 ack，数据不会丢失</li>\n</ul>\n<h2 id=\"消费者如何消费数据\"><a href=\"#消费者如何消费数据\" class=\"headerlink\" title=\"消费者如何消费数据\"></a>消费者如何消费数据</h2><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p>\n<p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p>\n<p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"Kafka-是什么？主要应用场景有哪些？\"><a href=\"#Kafka-是什么？主要应用场景有哪些？\" class=\"headerlink\" title=\"Kafka 是什么？主要应用场景有哪些？\"></a>Kafka 是什么？主要应用场景有哪些？</h2><p>Kafka 是一个分布式流式处理平台，可以作为企业级的消息引擎。</p>\n<p>Kafka 主要有两大应用场景：</p>\n<ol>\n<li><strong>消息队列</strong> ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>\n<li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流。</li>\n</ol>\n<h2 id=\"Kafka的优势在哪里？\"><a href=\"#Kafka的优势在哪里？\" class=\"headerlink\" title=\"Kafka的优势在哪里？\"></a>Kafka的优势在哪里？</h2><ol>\n<li><strong>极致的性能</strong> ：最高可以每秒处理千万级别的消息。</li>\n<li><strong>生态系统兼容性无可匹敌</strong> ：尤其在大数据和流计算领域。</li>\n</ol>\n<h2 id=\"队列模型？Kafka-的消息模型？\"><a href=\"#队列模型？Kafka-的消息模型？\" class=\"headerlink\" title=\"队列模型？Kafka 的消息模型？\"></a>队列模型？Kafka 的消息模型？</h2><h3 id=\"队列模型\"><a href=\"#队列模型\" class=\"headerlink\" title=\"队列模型\"></a>队列模型</h3><p>使用队列作为消息通信载体，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。 </p>\n<p><strong>问题</strong></p>\n<p>将生产者产生的消息分发给多个消费者难以处理。</p>\n<h3 id=\"发布-订阅模型（Kafka-消息模型）\"><a href=\"#发布-订阅模型（Kafka-消息模型）\" class=\"headerlink\" title=\"发布-订阅模型（Kafka 消息模型）\"></a>发布-订阅模型（Kafka 消息模型）</h3><p> 使用主题作为消息通信载体，类似于广播模式；生产者发布一条消息，该消息通过主题传递给所有的订阅者。</p>\n<p>如果只有一个订阅者，那就退化到队列模型。</p>\n<h2 id=\"Producer、Consumer、Broker、Topic、Partition、Record？\"><a href=\"#Producer、Consumer、Broker、Topic、Partition、Record？\" class=\"headerlink\" title=\"Producer、Consumer、Broker、Topic、Partition、Record？\"></a>Producer、Consumer、Broker、Topic、Partition、Record？</h2><ol>\n<li><strong>Producer（生产者）</strong> ： 产生消息的一方。</li>\n<li><strong>Consumer（消费者）</strong>：消费消息的一方。</li>\n<li><strong>Broker（代理）</strong> : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。</li>\n</ol>\n<ul>\n<li><strong>Topic（主题）</strong> : kafka 通过不同的主题区分不同的业务类型的消息记录。Producer 将消息发送到特定的主题，Consumer 通过订阅特定的主题来消费消息。</li>\n<li><strong>Partition（分区）</strong>： Partition属于Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上。</li>\n<li><strong>记录（Record）：</strong>实际写入到kafka集群并且可以被消费者读取的数据。每条记录包含一个键、值和时间戳。</li>\n</ul>\n<h2 id=\"什么是消费者组？\"><a href=\"#什么是消费者组？\" class=\"headerlink\" title=\"什么是消费者组？\"></a>什么是消费者组？</h2><p>可扩展且具有容错性的消费者机制。</p>\n<ul>\n<li>Kafka允许你将同一份消息广播到多个消费者组里。</li>\n<li>一个消费者组中可以包含多个消费者，他们共同消费该主题的数据。</li>\n<li>同一个消费者组下的消费者有相同的组ID，他们被分配不同的订阅分区。</li>\n<li>当某个消费者挂掉的时候，其他消费者会自动地承担起它负责消费的分区。 </li>\n</ul>\n<h2 id=\"LEO、LSO、AR、ISR、HW？\"><a href=\"#LEO、LSO、AR、ISR、HW？\" class=\"headerlink\" title=\"LEO、LSO、AR、ISR、HW？\"></a>LEO、LSO、AR、ISR、HW？</h2><ul>\n<li>LEO（Log End Offset）：日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。</li>\n<li>LSO（Log Stable Offset）：该值控制了事务型消费者能够看到的消息范围。</li>\n<li>AR（Assigned Replicas）：主题被创建后，创建的副本集合，副本个数由副本因子决定。</li>\n<li>ISR（In-Sync Replicas）：AR中与Leader保持同步的副本集合。Leader副本天然在ISR中。</li>\n<li>HW（High watermark）：高水位值，这是控制消费者可读取消息范围。一个普通消费者只能看到Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。</li>\n</ul>\n<h2 id=\"位移的作用\"><a href=\"#位移的作用\" class=\"headerlink\" title=\"位移的作用\"></a>位移的作用</h2><p>用于标识消息在分区中的位置。</p>\n<p>一旦消息被写入到分区日志，它的位移值将不能被修改。</p>\n<h2 id=\"磁盘容量规划考虑因素？\"><a href=\"#磁盘容量规划考虑因素？\" class=\"headerlink\" title=\"磁盘容量规划考虑因素？\"></a>磁盘容量规划考虑因素？</h2><ul>\n<li>新增消息数</li>\n<li>消息留存时间</li>\n<li>平均消息大小</li>\n<li>备份数</li>\n<li>是否启用压缩</li>\n</ul>\n<h2 id=\"consumer-offsets-作用？\"><a href=\"#consumer-offsets-作用？\" class=\"headerlink\" title=\"__consumer_offsets 作用？\"></a>__consumer_offsets 作用？</h2><ul>\n<li>内部主题，存储消费者的位移数据</li>\n<li>保存消费者组相关的消息</li>\n<li>用于删除消费者组过期位移、删除消费者组的消息。tombstone 消息，即墓碑消息</li>\n</ul>\n<h2 id=\"多副本机制？好处？\"><a href=\"#多副本机制？好处？\" class=\"headerlink\" title=\"多副本机制？好处？\"></a>多副本机制？好处？</h2><ul>\n<li>Kafka副本当前分为领导者副本和追随者副本。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</li>\n<li>只有Leader副本才能对外提供读写服务。</li>\n<li>Follower副本只是采用拉的方式，同步Leader副本中的数据</li>\n<li>在Leader副本所在的Broker宕机后，Kafka 依托于 ZooKeeper 提供的监控，实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</li>\n</ul>\n<p><strong>多分区多副本好处？</strong></p>\n<ol>\n<li>Kafka 通过给特定 Topic 指定多个 Partition， 而各个 Partition 可以分布在不同的 Broker 上， 这样便能提供比较好的并发能力（负载均衡）。</li>\n<li>多副本提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。</li>\n<li>方便实现“Read-your-writes”</li>\n<li>方便实现单调读：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在</li>\n</ol>\n<h2 id=\"Zookeeper-的作用？\"><a href=\"#Zookeeper-的作用？\" class=\"headerlink\" title=\"Zookeeper 的作用？\"></a>Zookeeper 的作用？</h2><ul>\n<li>存放元数据：主题分区的相关数据都保存在 ZooKeeper 中，且以它保存的数据为权威。</li>\n<li>成员管理：Broker 节点的注册、注销以及属性变更。</li>\n<li>Controller 选举：选举集群 Controller节点</li>\n<li>其他管理类任务：包括但不限于主题删除、参数配置等。</li>\n</ul>\n<h2 id=\"如何保证消息的消费顺序？\"><a href=\"#如何保证消息的消费顺序？\" class=\"headerlink\" title=\"如何保证消息的消费顺序？\"></a>如何保证消息的消费顺序？</h2><p>分区是真正保存消息的地方。Topic 可以指定多个 Partition。</p>\n<p>Kafka 只能为我们保证分区中的消息有序，而不能保证 主题中的消息有序。</p>\n<ol>\n<li>1 个 Topic 只对应一个 Partition。</li>\n<li>（推荐）发送消息的时候指定 key/Partition。</li>\n</ol>\n<h2 id=\"如何保证消息不丢失\"><a href=\"#如何保证消息不丢失\" class=\"headerlink\" title=\"如何保证消息不丢失\"></a>如何保证消息不丢失</h2><h3 id=\"生产者丢失消息\"><a href=\"#生产者丢失消息\" class=\"headerlink\" title=\"生产者丢失消息\"></a>生产者丢失消息</h3><ul>\n<li><p>生产者调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。 为了确定消息是发送成功，我们要判断消息发送的结果。可以采用回调函数的形式，如果消息发送失败的话，我们检查失败的原因之后重新发送即可。</p>\n</li>\n<li><p>为 生产者的<code>retries</code>（重试次数）设置一个比较合理的值，一般是 3 。</p>\n</li>\n<li><p><strong>设置 acks = all</strong>，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交</p>\n</li>\n</ul>\n<h3 id=\"消费者丢失消息\"><a href=\"#消费者丢失消息\" class=\"headerlink\" title=\"消费者丢失消息\"></a>消费者丢失消息</h3><ul>\n<li>关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。</li>\n</ul>\n<h3 id=\"Kafka-弄丢消息\"><a href=\"#Kafka-弄丢消息\" class=\"headerlink\" title=\"Kafka 弄丢消息\"></a>Kafka 弄丢消息</h3><ul>\n<li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li>\n<li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</li>\n<li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li>\n</ul>\n<h2 id=\"如何保证消息不重复消费\"><a href=\"#如何保证消息不重复消费\" class=\"headerlink\" title=\"如何保证消息不重复消费\"></a>如何保证消息不重复消费</h2><p>去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过。</p>\n<h2 id=\"为什么性能好\"><a href=\"#为什么性能好\" class=\"headerlink\" title=\"为什么性能好\"></a>为什么性能好</h2><h3 id=\"顺序写\"><a href=\"#顺序写\" class=\"headerlink\" title=\"顺序写\"></a>顺序写</h3><blockquote>\n<p>操作系统读写磁盘时，需要先寻址，再进行数据读写。如果是机械硬盘，寻址就需要较长的时间。</p>\n</blockquote>\n<p> Kafka 用的是顺序写，追加数据是追加到末尾，磁盘顺序写的性能极高。</p>\n<h3 id=\"零拷贝\"><a href=\"#零拷贝\" class=\"headerlink\" title=\"零拷贝\"></a>零拷贝</h3><p>Kafka 利用了 Linux 的 sendFile 技术实现零拷贝，直接从磁盘文件复制到网卡设备中,减少了内核和用户模式之间的上下文切换。</p>\n<h3 id=\"网络线程模型\"><a href=\"#网络线程模型\" class=\"headerlink\" title=\"网络线程模型\"></a>网络线程模型</h3><p>加强版的 Reactor 网络线程模型</p>\n<h3 id=\"消息批量量处理\"><a href=\"#消息批量量处理\" class=\"headerlink\" title=\"消息批量量处理\"></a>消息批量量处理</h3><p>合并小的请求，然后以流的方式进行交互，直顶网络上限。</p>\n<h2 id=\"为什么不支持读写分离？\"><a href=\"#为什么不支持读写分离？\" class=\"headerlink\" title=\"为什么不支持读写分离？\"></a>为什么不支持读写分离？</h2><p>CAP理论下，我们只能保证可用性和一致性取其一。</p>\n<p>如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣。</p>\n<p>如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。</p>\n<h2 id=\"Controller发生网络分区时，Kafka会怎么样？\"><a href=\"#Controller发生网络分区时，Kafka会怎么样？\" class=\"headerlink\" title=\"Controller发生网络分区时，Kafka会怎么样？\"></a>Controller发生网络分区时，Kafka会怎么样？</h2><p>判断：Broker端的ActiveControllerCount。</p>\n<p>由于Controller会给Broker发送3类请求，LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，因此，一旦出现网络分区，这些请求将不能顺利到达Broker端。</p>\n<p>将影响主题的创建、修改、删除操作的信息同步。</p>\n<h2 id=\"Java-Consumer-为什么采用单线程来获取消息？\"><a href=\"#Java-Consumer-为什么采用单线程来获取消息？\" class=\"headerlink\" title=\"Java Consumer 为什么采用单线程来获取消息？\"></a>Java Consumer 为什么采用单线程来获取消息？</h2><p>Java Consumer是双线程的设计。用户主线程，负责获取消息；心跳线程，负责向Kafka汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的“假死”情况。</p>\n<ul>\n<li>单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。</li>\n<li>可以简化代码的开发。多线程交互的代码是非常容易出错的。</li>\n</ul>\n<h2 id=\"Follower副本消息同步的流程？\"><a href=\"#Follower副本消息同步的流程？\" class=\"headerlink\" title=\"Follower副本消息同步的流程？\"></a>Follower副本消息同步的流程？</h2><ul>\n<li>Follower发送FETCH请求给Leader。</li>\n<li>Leader会读取底层日志文件中的消息数据，使用FETCH请求中的fetchOffset，更新Follower远程副本的LEO值。leader副本尝试更新分区高水位值。</li>\n<li>Follower接收到FETCH响应之后，会把消息写入到底层日志，接着更新LEO和HW值。</li>\n</ul>\n<p>Leader和Follower的HW值更新时机是不同的，Follower的HW更新永远落后于Leader的HW。这种时间上的错配是造成各种不一致的原因。</p>\n<h2 id=\"Leader总是-1，怎么破？\"><a href=\"#Leader总是-1，怎么破？\" class=\"headerlink\" title=\"Leader总是-1，怎么破？\"></a>Leader总是-1，怎么破？</h2><p>通常情况下就是Controller不工作了，导致无法分配leader。</p>\n<p>方法</p>\n<p>1、删除ZooKeeper中的/controller节点，触发Controller重选举。Controller重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题。</p>\n<p>2、重启Controller节点上的Kafka进程，让其他节点重新注册Controller角色。</p>\n<h2 id=\"如何设置Kafka能接收的最大消息的大小？\"><a href=\"#如何设置Kafka能接收的最大消息的大小？\" class=\"headerlink\" title=\"如何设置Kafka能接收的最大消息的大小？\"></a>如何设置Kafka能接收的最大消息的大小？</h2><ul>\n<li>Broker端参数：<code>message.max.bytes</code>，<code>max.message.bytes</code>（topic级别），<code>replica.fetch.max.bytes</code></li>\n<li>Consumer端参数：<code>fetch.message.max.bytes</code></li>\n</ul>\n<h2 id=\"Kafka能手动删除消息吗？\"><a href=\"#Kafka能手动删除消息吗？\" class=\"headerlink\" title=\"Kafka能手动删除消息吗？\"></a>Kafka能手动删除消息吗？</h2><p>一般不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。同时支持手动删除消息的。</p>\n<ul>\n<li>对于设置了Key且参数cleanup.policy=compact的主题而言，我们可以构造一条消息发送给Broker，依靠日志清理组件提供的功能删除掉该 Key 的消息。</li>\n<li>对于普通主题，可以使用<code>kafka-delete-records</code>，或编写程序调用<code>Admin.deleteRecords</code>方法来删除消息。</li>\n</ul>\n<h2 id=\"如何确定合适的Kafka主题的分区数量？\"><a href=\"#如何确定合适的Kafka主题的分区数量？\" class=\"headerlink\" title=\"如何确定合适的Kafka主题的分区数量？\"></a>如何确定合适的Kafka主题的分区数量？</h2><p>需要根据每个分区的生产者和消费者的期望吞吐量进行估计,以便达到并行读写、负载均衡和高吞吐。</p>\n<blockquote>\n<p>假设期望读取数据的速率1GB/Sec，而一个消费者的读取速率为50MB/Sec，此时至少需要20个分区以及20个消费者。</p>\n<p>如果期望生产数据的速率为<strong>1GB/Sec</strong>，而每个生产者的生产速率为<strong>100MB/Sec</strong>，此时就需要有10个分区。</p>\n<p>设置20个分区，既可以保障生产速率，也可以保障的吞吐量</p>\n</blockquote>\n<h2 id=\"kafka如何实现延迟队列？\"><a href=\"#kafka如何实现延迟队列？\" class=\"headerlink\" title=\"kafka如何实现延迟队列？\"></a>kafka如何实现延迟队列？</h2><p><strong>基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）</strong>。基于时间轮可以将插入和删除操作的时间复杂度都降为<code>O（1）</code>。</p>\n<p><strong>底层使用数组实现，</strong>数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask。</p>\n<p><strong>推进时间？</strong>Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的<code>TimingWheel</code>专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O（1）的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，<strong>这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”</strong>。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。</p>\n<h2 id=\"判断一个节点还活着的两个条件？\"><a href=\"#判断一个节点还活着的两个条件？\" class=\"headerlink\" title=\"判断一个节点还活着的两个条件？\"></a>判断一个节点还活着的两个条件？</h2><p>（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接</p>\n<p>（2）如果节点是 follower，他必须能及时的同步 leader 的写操作，延时不能太久</p>\n<h2 id=\"消息是采用-Pull-模式，还是-Push-模式？\"><a href=\"#消息是采用-Pull-模式，还是-Push-模式？\" class=\"headerlink\" title=\"消息是采用 Pull 模式，还是 Push 模式？\"></a>消息是采用 Pull 模式，还是 Push 模式？</h2><p>生产者将消息推送到 broker，消费者从 broker 拉取消息。</p>\n<h2 id=\"存储在硬盘上的消息格式是什么？\"><a href=\"#存储在硬盘上的消息格式是什么？\" class=\"headerlink\" title=\"存储在硬盘上的消息格式是什么？\"></a>存储在硬盘上的消息格式是什么？</h2><p>消息由一个固定长度的头部和可变长度的字节数组组成。</p>\n<ul>\n<li>消息长度: 4 bytes</li>\n<li>版本号: 1 byte</li>\n<li>CRC 校验码: 4 bytes</li>\n<li>具体的消息: n bytes</li>\n</ul>\n<h2 id=\"ack-机制\"><a href=\"#ack-机制\" class=\"headerlink\" title=\"ack 机制\"></a>ack 机制</h2><ul>\n<li>0：生产者不会等待 broker 的 ack，延迟最低，可能丢数据</li>\n<li>1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack，leader切换可能丢数据</li>\n<li>-1：等所有的 follower 的副本收到数据后，leader 发出的 ack，数据不会丢失</li>\n</ul>\n<h2 id=\"消费者如何消费数据\"><a href=\"#消费者如何消费数据\" class=\"headerlink\" title=\"消费者如何消费数据\"></a>消费者如何消费数据</h2><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p>\n<p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p>\n<p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p>\n"},{"title":"mysql数据类型","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-11T02:17:16.000Z","password":null,"summary":null,"_content":"\n## 数据类型\n\n1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。\n\n长度：整数类型可以被指定长度，例如：`INT(11)`表示长度为11的INT类型。长度不会限制值的合法范围，只会影响显示字符的个数。\n\n2、实数类型，包括FLOAT、DOUBLE、DECIMAL。\n\nDECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。\n\nFLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节\n\n计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。\n\n3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB\n\nVARCHAR用于存储可变长字符串，它比定长类型更节省空间。\n\nVARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。\n\nVARCHAR存储的内容超出设置的长度时，内容会被截断。\n\nCHAR是定长的，根据定义的字符串长度分配足够的空间。\n\nCHAR会根据需要使用空格进行填充方便比较。\n\nCHAR适合存储很短的字符串，或者所有值都接近同一个长度。\n\nCHAR存储的内容超出设置的长度时，内容同样会被截断。\n\n**使用策略：**\n\n对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。\n\n对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。\n\n使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。\n\n尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。\n\n4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。\n\n有时可以使用ENUM代替常用的字符串类型。\n\nENUM存储非常紧凑，会把列表值压缩到一个或两个字节。\n\nENUM在内部存储时，其实存的是整数。\n\n尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。\n\n排序是按照内部存储的整数\n\n5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，\n\n用整数保存时间戳通常不方便处理。\n\n如果需要存储微秒，可以使用bigint存储。","source":"_posts/mysql数据类型.md","raw":"---\ntitle: mysql数据类型\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-11 10:17:16\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 数据类型\n\n1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。\n\n长度：整数类型可以被指定长度，例如：`INT(11)`表示长度为11的INT类型。长度不会限制值的合法范围，只会影响显示字符的个数。\n\n2、实数类型，包括FLOAT、DOUBLE、DECIMAL。\n\nDECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。\n\nFLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节\n\n计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。\n\n3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB\n\nVARCHAR用于存储可变长字符串，它比定长类型更节省空间。\n\nVARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。\n\nVARCHAR存储的内容超出设置的长度时，内容会被截断。\n\nCHAR是定长的，根据定义的字符串长度分配足够的空间。\n\nCHAR会根据需要使用空格进行填充方便比较。\n\nCHAR适合存储很短的字符串，或者所有值都接近同一个长度。\n\nCHAR存储的内容超出设置的长度时，内容同样会被截断。\n\n**使用策略：**\n\n对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。\n\n对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。\n\n使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。\n\n尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。\n\n4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。\n\n有时可以使用ENUM代替常用的字符串类型。\n\nENUM存储非常紧凑，会把列表值压缩到一个或两个字节。\n\nENUM在内部存储时，其实存的是整数。\n\n尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。\n\n排序是按照内部存储的整数\n\n5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，\n\n用整数保存时间戳通常不方便处理。\n\n如果需要存储微秒，可以使用bigint存储。","slug":"mysql数据类型","published":1,"updated":"2021-05-11T13:09:54.160Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6vs0028q4ufkxdopd6s","content":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p>1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。</p>\n<p>长度：整数类型可以被指定长度，例如：<code>INT(11)</code>表示长度为11的INT类型。长度不会限制值的合法范围，只会影响显示字符的个数。</p>\n<p>2、实数类型，包括FLOAT、DOUBLE、DECIMAL。</p>\n<p>DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。</p>\n<p>FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节</p>\n<p>计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。</p>\n<p>3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB</p>\n<p>VARCHAR用于存储可变长字符串，它比定长类型更节省空间。</p>\n<p>VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。</p>\n<p>VARCHAR存储的内容超出设置的长度时，内容会被截断。</p>\n<p>CHAR是定长的，根据定义的字符串长度分配足够的空间。</p>\n<p>CHAR会根据需要使用空格进行填充方便比较。</p>\n<p>CHAR适合存储很短的字符串，或者所有值都接近同一个长度。</p>\n<p>CHAR存储的内容超出设置的长度时，内容同样会被截断。</p>\n<p><strong>使用策略：</strong></p>\n<p>对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。</p>\n<p>对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。</p>\n<p>使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。</p>\n<p>尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。</p>\n<p>4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。</p>\n<p>有时可以使用ENUM代替常用的字符串类型。</p>\n<p>ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。</p>\n<p>ENUM在内部存储时，其实存的是整数。</p>\n<p>尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。</p>\n<p>排序是按照内部存储的整数</p>\n<p>5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，</p>\n<p>用整数保存时间戳通常不方便处理。</p>\n<p>如果需要存储微秒，可以使用bigint存储。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p>1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。</p>\n<p>长度：整数类型可以被指定长度，例如：<code>INT(11)</code>表示长度为11的INT类型。长度不会限制值的合法范围，只会影响显示字符的个数。</p>\n<p>2、实数类型，包括FLOAT、DOUBLE、DECIMAL。</p>\n<p>DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。</p>\n<p>FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节</p>\n<p>计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。</p>\n<p>3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB</p>\n<p>VARCHAR用于存储可变长字符串，它比定长类型更节省空间。</p>\n<p>VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。</p>\n<p>VARCHAR存储的内容超出设置的长度时，内容会被截断。</p>\n<p>CHAR是定长的，根据定义的字符串长度分配足够的空间。</p>\n<p>CHAR会根据需要使用空格进行填充方便比较。</p>\n<p>CHAR适合存储很短的字符串，或者所有值都接近同一个长度。</p>\n<p>CHAR存储的内容超出设置的长度时，内容同样会被截断。</p>\n<p><strong>使用策略：</strong></p>\n<p>对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。</p>\n<p>对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。</p>\n<p>使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。</p>\n<p>尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。</p>\n<p>4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。</p>\n<p>有时可以使用ENUM代替常用的字符串类型。</p>\n<p>ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。</p>\n<p>ENUM在内部存储时，其实存的是整数。</p>\n<p>尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。</p>\n<p>排序是按照内部存储的整数</p>\n<p>5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，</p>\n<p>用整数保存时间戳通常不方便处理。</p>\n<p>如果需要存储微秒，可以使用bigint存储。</p>\n"},{"title":"mysql存储引擎","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-11T01:30:57.000Z","password":null,"summary":null,"_content":"\n## innodb和myisiam区别\n\n**Innodb引擎：**支持数据库ACID事务。并且还提供了行级锁和外键。它的设计的目标就是处理大数据容量的数据库系统，InnoDB 适合频繁修改以及涉及到安全性较高的应用；。\n\n**MyIASM引擎**：不提供事务的支持，也不支持行级锁和外键。MyISAM 适合查询以及插入为主的应用\n\n|                 | **MyISAM**                                                   | **Innodb**                                                   |\n| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 存储结构        | **每张表被存放在三个文件：frm表格定义、MYD数据文件、MYI索引文件** | **所有的表都保存在同一个数据文件中**（也可能是多个文件，或者是独立的表空间文件） |\n| 存储空间        | MyISAM索引是有压缩的，存储空间较小                           | InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 |\n| 文件格式        | **数据和索引是分别存储的，数据.MYD，索引.MYI**               | **数据和索引是集中存储的，.ibd**                             |\n| 记录存储顺序    | 按记录插入顺序保存                                           | 按主键大小有序插入                                           |\n| 外键            | 不支持                                                       | 支持                                                         |\n| 事务            | 不支持                                                       | 支持                                                         |\n| 锁支持          | 表级锁定                                                     | 行级锁定、表级锁定，锁定力度小并发能力高                     |\n| select count(*) | myisam更快，myisam内部维护了计数器。                         |                                                              |\n| 索引的实现方式  | B+树索引                                                     | B+树索引                                                     |\n\n### MyISAM索引与InnoDB索引的区别\n\nInnoDB索引是**聚簇索引**，MyISAM索引是**非聚簇索引**。\n\nInnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。\n\nInnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效\n\n**其他**\n\n- 清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表\n\n### InnoDB引擎的4大特性\n\n- 插入缓冲\n- 二次写\n- 自适应哈希索引\n- 预读\n\n### 存储引擎选择\n\n如果没有特别的需求，使用默认的Innodb即可。\n\nMyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。\n\nInnodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。","source":"_posts/mysql存储引擎.md","raw":"---\ntitle: mysql存储引擎\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-11 09:30:57\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## innodb和myisiam区别\n\n**Innodb引擎：**支持数据库ACID事务。并且还提供了行级锁和外键。它的设计的目标就是处理大数据容量的数据库系统，InnoDB 适合频繁修改以及涉及到安全性较高的应用；。\n\n**MyIASM引擎**：不提供事务的支持，也不支持行级锁和外键。MyISAM 适合查询以及插入为主的应用\n\n|                 | **MyISAM**                                                   | **Innodb**                                                   |\n| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 存储结构        | **每张表被存放在三个文件：frm表格定义、MYD数据文件、MYI索引文件** | **所有的表都保存在同一个数据文件中**（也可能是多个文件，或者是独立的表空间文件） |\n| 存储空间        | MyISAM索引是有压缩的，存储空间较小                           | InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 |\n| 文件格式        | **数据和索引是分别存储的，数据.MYD，索引.MYI**               | **数据和索引是集中存储的，.ibd**                             |\n| 记录存储顺序    | 按记录插入顺序保存                                           | 按主键大小有序插入                                           |\n| 外键            | 不支持                                                       | 支持                                                         |\n| 事务            | 不支持                                                       | 支持                                                         |\n| 锁支持          | 表级锁定                                                     | 行级锁定、表级锁定，锁定力度小并发能力高                     |\n| select count(*) | myisam更快，myisam内部维护了计数器。                         |                                                              |\n| 索引的实现方式  | B+树索引                                                     | B+树索引                                                     |\n\n### MyISAM索引与InnoDB索引的区别\n\nInnoDB索引是**聚簇索引**，MyISAM索引是**非聚簇索引**。\n\nInnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。\n\nInnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效\n\n**其他**\n\n- 清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表\n\n### InnoDB引擎的4大特性\n\n- 插入缓冲\n- 二次写\n- 自适应哈希索引\n- 预读\n\n### 存储引擎选择\n\n如果没有特别的需求，使用默认的Innodb即可。\n\nMyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。\n\nInnodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。","slug":"mysql存储引擎","published":1,"updated":"2021-05-11T11:33:29.561Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6w5002cq4uff8ni5v6c","content":"<h2 id=\"innodb和myisiam区别\"><a href=\"#innodb和myisiam区别\" class=\"headerlink\" title=\"innodb和myisiam区别\"></a>innodb和myisiam区别</h2><p><strong>Innodb引擎：</strong>支持数据库ACID事务。并且还提供了行级锁和外键。它的设计的目标就是处理大数据容量的数据库系统，InnoDB 适合频繁修改以及涉及到安全性较高的应用；。</p>\n<p><strong>MyIASM引擎</strong>：不提供事务的支持，也不支持行级锁和外键。MyISAM 适合查询以及插入为主的应用</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>MyISAM</strong></th>\n<th><strong>Innodb</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>存储结构</td>\n<td><strong>每张表被存放在三个文件：frm表格定义、MYD数据文件、MYI索引文件</strong></td>\n<td><strong>所有的表都保存在同一个数据文件中</strong>（也可能是多个文件，或者是独立的表空间文件）</td>\n</tr>\n<tr>\n<td>存储空间</td>\n<td>MyISAM索引是有压缩的，存储空间较小</td>\n<td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td>\n</tr>\n<tr>\n<td>文件格式</td>\n<td><strong>数据和索引是分别存储的，数据.MYD，索引.MYI</strong></td>\n<td><strong>数据和索引是集中存储的，.ibd</strong></td>\n</tr>\n<tr>\n<td>记录存储顺序</td>\n<td>按记录插入顺序保存</td>\n<td>按主键大小有序插入</td>\n</tr>\n<tr>\n<td>外键</td>\n<td>不支持</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>事务</td>\n<td>不支持</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>锁支持</td>\n<td>表级锁定</td>\n<td>行级锁定、表级锁定，锁定力度小并发能力高</td>\n</tr>\n<tr>\n<td>select count(*)</td>\n<td>myisam更快，myisam内部维护了计数器。</td>\n<td></td>\n</tr>\n<tr>\n<td>索引的实现方式</td>\n<td>B+树索引</td>\n<td>B+树索引</td>\n</tr>\n</tbody></table>\n<h3 id=\"MyISAM索引与InnoDB索引的区别\"><a href=\"#MyISAM索引与InnoDB索引的区别\" class=\"headerlink\" title=\"MyISAM索引与InnoDB索引的区别\"></a>MyISAM索引与InnoDB索引的区别</h3><p>InnoDB索引是<strong>聚簇索引</strong>，MyISAM索引是<strong>非聚簇索引</strong>。</p>\n<p>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p>\n<p>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效</p>\n<p><strong>其他</strong></p>\n<ul>\n<li>清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表</li>\n</ul>\n<h3 id=\"InnoDB引擎的4大特性\"><a href=\"#InnoDB引擎的4大特性\" class=\"headerlink\" title=\"InnoDB引擎的4大特性\"></a>InnoDB引擎的4大特性</h3><ul>\n<li>插入缓冲</li>\n<li>二次写</li>\n<li>自适应哈希索引</li>\n<li>预读</li>\n</ul>\n<h3 id=\"存储引擎选择\"><a href=\"#存储引擎选择\" class=\"headerlink\" title=\"存储引擎选择\"></a>存储引擎选择</h3><p>如果没有特别的需求，使用默认的Innodb即可。</p>\n<p>MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。</p>\n<p>Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"innodb和myisiam区别\"><a href=\"#innodb和myisiam区别\" class=\"headerlink\" title=\"innodb和myisiam区别\"></a>innodb和myisiam区别</h2><p><strong>Innodb引擎：</strong>支持数据库ACID事务。并且还提供了行级锁和外键。它的设计的目标就是处理大数据容量的数据库系统，InnoDB 适合频繁修改以及涉及到安全性较高的应用；。</p>\n<p><strong>MyIASM引擎</strong>：不提供事务的支持，也不支持行级锁和外键。MyISAM 适合查询以及插入为主的应用</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>MyISAM</strong></th>\n<th><strong>Innodb</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>存储结构</td>\n<td><strong>每张表被存放在三个文件：frm表格定义、MYD数据文件、MYI索引文件</strong></td>\n<td><strong>所有的表都保存在同一个数据文件中</strong>（也可能是多个文件，或者是独立的表空间文件）</td>\n</tr>\n<tr>\n<td>存储空间</td>\n<td>MyISAM索引是有压缩的，存储空间较小</td>\n<td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td>\n</tr>\n<tr>\n<td>文件格式</td>\n<td><strong>数据和索引是分别存储的，数据.MYD，索引.MYI</strong></td>\n<td><strong>数据和索引是集中存储的，.ibd</strong></td>\n</tr>\n<tr>\n<td>记录存储顺序</td>\n<td>按记录插入顺序保存</td>\n<td>按主键大小有序插入</td>\n</tr>\n<tr>\n<td>外键</td>\n<td>不支持</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>事务</td>\n<td>不支持</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>锁支持</td>\n<td>表级锁定</td>\n<td>行级锁定、表级锁定，锁定力度小并发能力高</td>\n</tr>\n<tr>\n<td>select count(*)</td>\n<td>myisam更快，myisam内部维护了计数器。</td>\n<td></td>\n</tr>\n<tr>\n<td>索引的实现方式</td>\n<td>B+树索引</td>\n<td>B+树索引</td>\n</tr>\n</tbody></table>\n<h3 id=\"MyISAM索引与InnoDB索引的区别\"><a href=\"#MyISAM索引与InnoDB索引的区别\" class=\"headerlink\" title=\"MyISAM索引与InnoDB索引的区别\"></a>MyISAM索引与InnoDB索引的区别</h3><p>InnoDB索引是<strong>聚簇索引</strong>，MyISAM索引是<strong>非聚簇索引</strong>。</p>\n<p>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p>\n<p>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效</p>\n<p><strong>其他</strong></p>\n<ul>\n<li>清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表</li>\n</ul>\n<h3 id=\"InnoDB引擎的4大特性\"><a href=\"#InnoDB引擎的4大特性\" class=\"headerlink\" title=\"InnoDB引擎的4大特性\"></a>InnoDB引擎的4大特性</h3><ul>\n<li>插入缓冲</li>\n<li>二次写</li>\n<li>自适应哈希索引</li>\n<li>预读</li>\n</ul>\n<h3 id=\"存储引擎选择\"><a href=\"#存储引擎选择\" class=\"headerlink\" title=\"存储引擎选择\"></a>存储引擎选择</h3><p>如果没有特别的需求，使用默认的Innodb即可。</p>\n<p>MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。</p>\n<p>Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。</p>\n"},{"title":"order/group by优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T07:45:38.000Z","password":null,"summary":null,"_content":"\n## order by 原理\n\n按照排序原理分[manual](https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html)，MySQL 排序方式分两种：\n\n- 通过有序索引直接返回有序数据：Using index\n- 通过 Filesort 进行的排序：Using filesort\n\nFilesort是内存排序还是磁盘排序取决于：\n\n-  “排序的数据大小” < sort_buffer_size: 内存排序\n-  “排序的数据大小” > sort_buffer_size: 磁盘排序\n\n通过trace中的`number_of_tmp_files`，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。\n\n**Filesort 下的排序模式**\n\n- < sort_key, rowid >双路排序（回表排序模式）：取出排序字段和行 ID，在 sort buffer 中排序，排序完后再次取回其它需要的字段；\n- < sort_key, additional_fields >单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；\n- < sort_key, packed_additional_fields >打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。\n\n**单路和双路的选择**\n\n-  max_length_for_sort_data 比查询字段的总长度大，使用单路排序模式；\n-  max_length_for_sort_data 比查询字段的总长度小，使用回表排序模式。\n\n\n\n如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。\n\n## order by 优化\n\n###  添加合适索引\n\n1、 排序字段添加索引\n\n2、多个字段排序添加联合索引\n\n3、先等值查询再排序，在条件字段和排序字段添加联合索引\n\n### 去掉不必要的返回字段\n\n过多返回字段可能需要扫描索引再回表，成本全表扫描更高。\n\n```mysql\nselect id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */\n```\n\n### 修改参数\n\nmax_length_for_sort_data：可以适当加大 max_length_for_sort_data 的值\n\nsort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。\n\n### 无法使用索引\n\n1、 使用范围查询再排序：\n\n```mysql\nselect id,a,b from t1 where a>9000 order by b;\n```\n\n2、ASC 和 DESC 混合使用\n\n```mysql\nselect id,a,b from t1 order by a asc,b desc;\n```\n\n## group by优化\n\n默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致。\n\n如果目的只是分组而不用排序，可以指定`order by null`禁止排序。\n\n","source":"_posts/order-group-by优化.md","raw":"---\ntitle: order/group by优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 15:45:38\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## order by 原理\n\n按照排序原理分[manual](https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html)，MySQL 排序方式分两种：\n\n- 通过有序索引直接返回有序数据：Using index\n- 通过 Filesort 进行的排序：Using filesort\n\nFilesort是内存排序还是磁盘排序取决于：\n\n-  “排序的数据大小” < sort_buffer_size: 内存排序\n-  “排序的数据大小” > sort_buffer_size: 磁盘排序\n\n通过trace中的`number_of_tmp_files`，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。\n\n**Filesort 下的排序模式**\n\n- < sort_key, rowid >双路排序（回表排序模式）：取出排序字段和行 ID，在 sort buffer 中排序，排序完后再次取回其它需要的字段；\n- < sort_key, additional_fields >单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；\n- < sort_key, packed_additional_fields >打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。\n\n**单路和双路的选择**\n\n-  max_length_for_sort_data 比查询字段的总长度大，使用单路排序模式；\n-  max_length_for_sort_data 比查询字段的总长度小，使用回表排序模式。\n\n\n\n如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。\n\n## order by 优化\n\n###  添加合适索引\n\n1、 排序字段添加索引\n\n2、多个字段排序添加联合索引\n\n3、先等值查询再排序，在条件字段和排序字段添加联合索引\n\n### 去掉不必要的返回字段\n\n过多返回字段可能需要扫描索引再回表，成本全表扫描更高。\n\n```mysql\nselect id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */\n```\n\n### 修改参数\n\nmax_length_for_sort_data：可以适当加大 max_length_for_sort_data 的值\n\nsort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。\n\n### 无法使用索引\n\n1、 使用范围查询再排序：\n\n```mysql\nselect id,a,b from t1 where a>9000 order by b;\n```\n\n2、ASC 和 DESC 混合使用\n\n```mysql\nselect id,a,b from t1 order by a asc,b desc;\n```\n\n## group by优化\n\n默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致。\n\n如果目的只是分组而不用排序，可以指定`order by null`禁止排序。\n\n","slug":"order-group-by优化","published":1,"updated":"2021-05-11T12:06:53.619Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6wb002fq4uf6l4fgh18","content":"<h2 id=\"order-by-原理\"><a href=\"#order-by-原理\" class=\"headerlink\" title=\"order by 原理\"></a>order by 原理</h2><p>按照排序原理分<a href=\"https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html\" target=\"_blank\" rel=\"noopener\">manual</a>，MySQL 排序方式分两种：</p>\n<ul>\n<li>通过有序索引直接返回有序数据：Using index</li>\n<li>通过 Filesort 进行的排序：Using filesort</li>\n</ul>\n<p>Filesort是内存排序还是磁盘排序取决于：</p>\n<ul>\n<li>“排序的数据大小” &lt; sort_buffer_size: 内存排序</li>\n<li>“排序的数据大小” &gt; sort_buffer_size: 磁盘排序</li>\n</ul>\n<p>通过trace中的<code>number_of_tmp_files</code>，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。</p>\n<p><strong>Filesort 下的排序模式</strong></p>\n<ul>\n<li>&lt; sort_key, rowid &gt;双路排序（回表排序模式）：取出排序字段和行 ID，在 sort buffer 中排序，排序完后再次取回其它需要的字段；</li>\n<li>&lt; sort_key, additional_fields &gt;单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；</li>\n<li>&lt; sort_key, packed_additional_fields &gt;打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。</li>\n</ul>\n<p><strong>单路和双路的选择</strong></p>\n<ul>\n<li>max_length_for_sort_data 比查询字段的总长度大，使用单路排序模式；</li>\n<li>max_length_for_sort_data 比查询字段的总长度小，使用回表排序模式。</li>\n</ul>\n<p>如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。</p>\n<h2 id=\"order-by-优化\"><a href=\"#order-by-优化\" class=\"headerlink\" title=\"order by 优化\"></a>order by 优化</h2><h3 id=\"添加合适索引\"><a href=\"#添加合适索引\" class=\"headerlink\" title=\"添加合适索引\"></a>添加合适索引</h3><p>1、 排序字段添加索引</p>\n<p>2、多个字段排序添加联合索引</p>\n<p>3、先等值查询再排序，在条件字段和排序字段添加联合索引</p>\n<h3 id=\"去掉不必要的返回字段\"><a href=\"#去掉不必要的返回字段\" class=\"headerlink\" title=\"去掉不必要的返回字段\"></a>去掉不必要的返回字段</h3><p>过多返回字段可能需要扫描索引再回表，成本全表扫描更高。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"修改参数\"><a href=\"#修改参数\" class=\"headerlink\" title=\"修改参数\"></a>修改参数</h3><p>max_length_for_sort_data：可以适当加大 max_length_for_sort_data 的值</p>\n<p>sort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。</p>\n<h3 id=\"无法使用索引\"><a href=\"#无法使用索引\" class=\"headerlink\" title=\"无法使用索引\"></a>无法使用索引</h3><p>1、 使用范围查询再排序：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select id,a,b from t1 where a>9000 order by b;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>2、ASC 和 DESC 混合使用</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select id,a,b from t1 order by a asc,b desc;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"group-by优化\"><a href=\"#group-by优化\" class=\"headerlink\" title=\"group by优化\"></a>group by优化</h2><p>默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致。</p>\n<p>如果目的只是分组而不用排序，可以指定<code>order by null</code>禁止排序。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"order-by-原理\"><a href=\"#order-by-原理\" class=\"headerlink\" title=\"order by 原理\"></a>order by 原理</h2><p>按照排序原理分<a href=\"https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html\" target=\"_blank\" rel=\"noopener\">manual</a>，MySQL 排序方式分两种：</p>\n<ul>\n<li>通过有序索引直接返回有序数据：Using index</li>\n<li>通过 Filesort 进行的排序：Using filesort</li>\n</ul>\n<p>Filesort是内存排序还是磁盘排序取决于：</p>\n<ul>\n<li>“排序的数据大小” &lt; sort_buffer_size: 内存排序</li>\n<li>“排序的数据大小” &gt; sort_buffer_size: 磁盘排序</li>\n</ul>\n<p>通过trace中的<code>number_of_tmp_files</code>，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。</p>\n<p><strong>Filesort 下的排序模式</strong></p>\n<ul>\n<li>&lt; sort_key, rowid &gt;双路排序（回表排序模式）：取出排序字段和行 ID，在 sort buffer 中排序，排序完后再次取回其它需要的字段；</li>\n<li>&lt; sort_key, additional_fields &gt;单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；</li>\n<li>&lt; sort_key, packed_additional_fields &gt;打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。</li>\n</ul>\n<p><strong>单路和双路的选择</strong></p>\n<ul>\n<li>max_length_for_sort_data 比查询字段的总长度大，使用单路排序模式；</li>\n<li>max_length_for_sort_data 比查询字段的总长度小，使用回表排序模式。</li>\n</ul>\n<p>如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。</p>\n<h2 id=\"order-by-优化\"><a href=\"#order-by-优化\" class=\"headerlink\" title=\"order by 优化\"></a>order by 优化</h2><h3 id=\"添加合适索引\"><a href=\"#添加合适索引\" class=\"headerlink\" title=\"添加合适索引\"></a>添加合适索引</h3><p>1、 排序字段添加索引</p>\n<p>2、多个字段排序添加联合索引</p>\n<p>3、先等值查询再排序，在条件字段和排序字段添加联合索引</p>\n<h3 id=\"去掉不必要的返回字段\"><a href=\"#去掉不必要的返回字段\" class=\"headerlink\" title=\"去掉不必要的返回字段\"></a>去掉不必要的返回字段</h3><p>过多返回字段可能需要扫描索引再回表，成本全表扫描更高。</p>\n<pre><code class=\"mysql\">select id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */</code></pre>\n<h3 id=\"修改参数\"><a href=\"#修改参数\" class=\"headerlink\" title=\"修改参数\"></a>修改参数</h3><p>max_length_for_sort_data：可以适当加大 max_length_for_sort_data 的值</p>\n<p>sort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。</p>\n<h3 id=\"无法使用索引\"><a href=\"#无法使用索引\" class=\"headerlink\" title=\"无法使用索引\"></a>无法使用索引</h3><p>1、 使用范围查询再排序：</p>\n<pre><code class=\"mysql\">select id,a,b from t1 where a&gt;9000 order by b;</code></pre>\n<p>2、ASC 和 DESC 混合使用</p>\n<pre><code class=\"mysql\">select id,a,b from t1 order by a asc,b desc;</code></pre>\n<h2 id=\"group-by优化\"><a href=\"#group-by优化\" class=\"headerlink\" title=\"group by优化\"></a>group by优化</h2><p>默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致。</p>\n<p>如果目的只是分组而不用排序，可以指定<code>order by null</code>禁止排序。</p>\n"},{"title":"mysql面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-10T10:45:14.000Z","password":null,"summary":null,"_content":"\n## 架构\n\n**server层**\n\n1. 连接器：管理连接，权限验证  \n\n2. 查询缓存  \n\n3. 分析器：词法、语法解析\n\n4. 优化器：生成执行计划，索引选择\n\n5. 执行器：操作引擎，返回结果\n\n**存储引擎层**\n\n1. 负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎\n\n##  日志系统\n\n### redo log（重做日志）\n\n1. InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）\n\n2. 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）\n\n3. redo log 是物理日志，记录的是在某个数据页上做了什么修改\n\n4. redo log是循环写，空间固定会用完\n\n### binlog（归档日志）\n\n1. server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力\n\n2. binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER、TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志\n\n3. binlog采用追加写的模式\n\n4. **用途：**  \n\n- 恢复：binlog日志恢复数据库数据  \n- 复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  \n- 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击\n\n**binlog常见格式**\n\n| format    | 定义                       | 优点                           | 缺点                                                         |\n| --------- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |\n| statement | 记录的是修改SQL语句        | 日志文件小，节约IO，提高性能   | 准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况） |\n| row       | 记录的是每行实际数据的变更 | 准确性强，能准确复制数据的变更 | 日志文件大，较大的网络IO和磁盘IO                             |\n| mixed     | statement和row模式的混合   | 准确性强，文件大小适中         | 有可能发生主从不一致问题                                     |\n\n### 两段提交  \n\n1. 两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致\n\n2. 两段提交： 写入redo log处于prepare阶段 --写入bin log --提交事务处于commit状态 \n\n- 时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  \n- 时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务\n\n3. bin log完整性判断:  \n\n- statement格式最后有commit  \n- row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）\n\n### undo log\n\n1. undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录\n\n2. undo log 作用  \n\n- 提供回滚  \n- 多版本并发控制（MVCC）\n\n### Mysql抖动\n\n当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。\n\n**flush场景**\n\n1. InnoDB 的 redo log 写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘\n2. 系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是\"脏页\"，就要先将脏页写到磁盘\n3. MySQL 认为系统\"空闲\"的时候，会flush脏页\n4. MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上\n\nInnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度\n\n## MyISAM索引与InnoDB索引的区别\n\nInnoDB索引是**聚簇索引**，MyISAM索引是**非聚簇索引**。\n\nInnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。\n\nInnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效\n\n**其他**\n\n- **InnoDB支持事务，MyISAM不支持**\n- MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用\n- **InnoDB支持外键，MyISAM不支持**\n- InnoDB中不保存表的行数，如`select count(*) from table`时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当`count(*)`语句包含where条件时MyISAM也需要扫描整个表\n- 对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引\n- 清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表\n- **InnoDB支持行锁**（某些情况下还是锁整表，如 `update table set a=1 where user like '%lee%'`\n\n## 索引\n\n### 定义\n\n数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。\n\n通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。\n\n索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。\n\n### 优缺点\n\n**索引的优点**\n\n- 加快数据的检索速度。\n\n**索引的缺点**\n\n- 创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；\n- 索引需要占物理空间。\n\n### 使用场景\n\n**where**\n\n**order by**\n\n使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据**使用磁盘临时文件完成外部排序或者在内存中完成排序**。具体取决于排序所需的内存和参数sort_buffer_size。\n\n如果我们对该字段建立索引，由于索引本身是有序的，因此直接**按照索引的顺序和映射关系逐条取出数据即可**。\n\n**join**\n\n对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）\n\n**覆盖索引**\n\n辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。\n\n如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。\n\n> 尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。\n\n### 索引类型\n\n**主键索引**： 不允许重复，不允许为NULL，一个表只能有一个主键。\n\n**唯一索引**：不允许重复，允许为NULL，一个表允许多唯一索引。\n\n**普通索引**：基本的索引类型，没有唯一性的限制，允许为NULL值。\n\n**全文索引**： 是目前搜索引擎使用的一种关键技术。\n\n### 索引的数据结构\n\n和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。\n\nInnoDB存储引擎的默认索引实现为：B+树索引。\n\n哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。\n\n### 索引设计的原则\n\n**适合索引的列**是出现在where子句中的列，或者连接子句中指定的列\n\n**使用短索引**，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间\n\n**不要过度索引**。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。\n\n### 创建索引的原则\n\n1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立`(a,b,c,d)`顺序的索引，d是用不到索引的，如果建立`(a,b,d,c)`的索引则都可以用到，a,b,d的顺序可以任意调整。\n\n2）较频繁作为查询条件的字段才去创建索引\n\n3）更新频繁字段不适合创建索引\n\n4）若是不能有效区分数据的列不适合做索引列（如性别，男女未知，最多也就三种，区分度实在太低），选择基数较大的列做索引\n\n5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。\n\n6）定义有外键的数据列一定要建立索引。\n\n### 创建索引注意点\n\n**非空字段：**应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；\n\n**取值离散大的字段：**（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值\n\n**索引字段越小越好**：数据库的数据存储以页为单位，一页存储的数据越多一次IO操作获取的数据越大，效率越高。\n\n### 使用索引查询一定能提高查询的性能吗\n\n**通常，通过索引查询数据比全表扫描要快。**但是我们也必须注意到它的代价。\n\n**索引需要空间来存储，也需要定期维护，** 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况:\n\n- 基于一个范围的检索，一般查询返回结果集小于表中记录数的30%\n- **基于非唯一性索引的检索（？？？）**\n\n### 百万级别或以上的数据如何删除\n\n> 索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的。\n\n所以删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）\n\n然后删除其中无用数据（此过程需要不到两分钟）\n\n删除完成后重新创建索引（此时数据较少了，创建索引也非常快，约十分钟左右。）\n\n### 前缀索引\n\n语法：``index(field(10))``，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。\n\n前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。\n\n实操的难度：**在于前缀截取的长度。**\n\n我们可以利用`select count(*)/count(distinct left(password,prefixLen));`，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）\n\n### B-/+Tree索引的性能分析\n\n B-Tree：根据B-Tree的定义，可知检索一次最多需要访问h个节点，利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，保证一个节点存储在一个页里。\n\nB+Tree：B+Tree更适合外存索引，由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能\n\n### B-Tree和B+Tree的区别\n\n在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。\n\nB+树的叶子节点有一条链相连，而B树的叶子节点各自独立。\n\n### 使用B树的好处\n\nB树可以在**内部节点同时存储键和值**，因此，**把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。**这种特性使得B树在特定数据重复多次查询的场景中更加高效。\n\n### 使用B+树的好处\n\n由于**B+树的内部节点只存放键**，不存放值，因此，**一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围**。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，**B+树只需要使用`O(logN)`时间找到最小的一个节点，然后通过链进行`O(N)`的顺序遍历即可。**而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间\n\n### Hash索引和B+树优劣\n\n首先要知道Hash索引和B+树索引的底层实现原理：\n\n**hash索引底层就是hash表**，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是**多路平衡查找树**。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。\n\n那么可以看出他们有以下的不同：\n\n- hash索引进行**等值查询更快（一般情况下），但是却无法进行范围查询**。\n\n因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。\n\n- hash索引**不支持使用索引进行排序**，原理同上。\n\n- hash索引不**支持模糊查询以及多列索引的最左前缀匹配。**原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。\n\n- hash索引任何时候都**避免不了回表查询数据**，而B+树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。\n- hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。\n\n因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。\n\n### 使用B+树而不是B树\n\n- **B树只适合随机检索，而B+树同时支持随机检索和顺序检索**；\n\n-  **B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。**一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；\n\n- **B+树的查询效率更加稳定。**B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。\n\n- **B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。**B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。\n\n- **增删文件（节点）时，效率更高。**因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。\n\n### 聚簇索引\n\n**聚簇索引**：将数据存储与索引放到了一块，找到索引也就找到了数据\n\n**非聚簇索引**：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，因此索引不在key buffer命中时，速度慢。\n\n**澄清一个概念：**innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值\n\n### 非聚簇索引一定会回表查询吗？\n\n不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。\n\n> 举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age < 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。\n\n### **联合索引**\n\nMySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。\n\n### **为什么需要注意联合索引中的顺序？**\n\nMySQL使用索引时需要索引有序.\n\n一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。\n\n## 数据库范式\n\n**第一范式：**强调的是列的原子性，即列不能够再分成其他几列。\n\n **第二范式**：首先是 1NF，另外包含两部分内容，**一是表必须有一个主键**；二是没有包含在主键中的**列必须完全依赖于主键，而不能只依赖于主键的一部分**。否则可拆表。\n\n **第三范式**：在1NF基础上，**任何非主属性不依赖于其它非主属性**[在2NF基础上消除传递依赖]。\n\n## mysql有关权限的表\n\nMySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别**user，db，table_priv，columns_priv和host**。下面分别介绍一下这些表的结构和内容：\n\nuser权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。\n\ndb权限表：记录各个帐号在各个数据库上的操作权限。\n\ntable_priv权限表：记录数据表级的操作权限。\n\ncolumns_priv权限表：记录数据列级的操作权限。\n\nhost权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。\n\n## 视图\n\n视图是虚拟的表，视图只包含使用时动态检索数据的查询;不包含任何列或数据。\n\n使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;\n\n视图创建后，可以使用与表相同的方式利用它们。\n\n> 视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。\n\n### 视图有哪些特点？\n\n- 视图是由基本表（实表）产生的表（虚表）。\n- 视图的建立和删除不影响基本表。\n- 对视图内容的更新（添加，删除和修改）直接影响基本表。\n- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。\n- 当视图来自多个基本表时，不允许添加和删除数据。\n\n### 视图的使用场景有哪些？\n\n视图根本用途：简化sql查询，提高开发效率。\n\n**常见使用场景：**\n\n重用SQL语句；\n\n**简化复杂的SQL操作**。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；\n\n**保护数据**。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；\n\n**更改数据格式和表示**。视图可返回与底层表的表示和格式不同的数据。\n\n### 视图的优点\n\n**查询简单化**。视图能简化用户的操作\n\n**数据安全性**。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护\n\n### 视图的缺点\n\n**性能**。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由复杂的多表查询所定义，那么，视图的查询，需要花费一定的时间。\n\n**修改限制**。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。\n\n### 游标\n\n游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。用户可以通过游标，逐一获取记录，进一步处理。\n\n## 事务\n\n### 什么是数据库事务？\n\n一个不可分割的数据库操作序列，是数据库并发控制的基本单位。\n\n事务是逻辑上的一组操作，要么都执行，要么都不执行。\n\n> 假如小明要给小红转账1000元：将小明的余额减少1000元，将小红的余额增加1000元。万一操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么成功，要么都失败。\n\n### 事务的特性\n\n- atomicity（原子性） ：要么全执行，要么全都不执行；\n- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；\n- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；\n- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。\n\n### 什么是脏读？幻读？不可重复读？\n\n脏读：读取未提交的事务。\n\n不可重复读：多次读取同一数据，读取的数据不一致。\n\n幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n### 事务的隔离级别\n\n| **隔离级别**     | **脏读** | **不可重复读** | **幻读** |\n| ---------------- | -------- | -------------- | -------- |\n| READ-UNCOMMITTED | √        | √              | √        |\n| READ-COMMITTED   | ×        | √              | √        |\n| REPEATABLE-READ  | ×        | ×              | √        |\n| SERIALIZABLE     | ×        | ×              | ×        |\n\n事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。\n\n## 锁\n\n当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。\n\n### 锁分类\n\n按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。\n\n**行级锁** 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。\n\n特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。\n\n**表级锁** 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。\n\n特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。\n\n**页级锁** 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。\n\n特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般\n\n从锁的类别上来讲，有共享锁和排他锁。\n\n**共享锁:** 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。\n\n**排他锁:** 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。\n\n### InnoDB存储引擎的锁的算法\n\nRecord lock：单个行记录上的锁\n\nGap lock：间隙锁，锁定一个范围，不包括记录本身\n\nNext-key lock：record+gap 锁定一个范围，包含记录本身\n\n### 死锁\n\n1. **Mysql死锁策略**  \n\n- 直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置  \n- 发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑\n\n2. **避免死锁的常用方法**  \n\n- 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会  \n- 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能  \n\n### 什么是死锁？怎么解决？\n\n死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。\n\n**常见的避免死锁的方法**\n\n1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。\n\n2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；\n\n3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；\n\n4、在RR隔离级别下，如果两个线程同时对相同条件记录用 SELECT...FOR UPDATE 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，**将隔离级别改成RC不会产生间隙锁**，就可避免问题  \n\n5、在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯，如果出现死锁，可以用 **show innodb status** 命令来确定最后一个死锁产生的原因，返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等\n\n如果业务处理不好可以用**分布式事务锁或者使用乐观锁**\n\n### 乐观锁和悲观锁是什么？怎么实现的？\n\n**悲观锁：**假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制\n\n **乐观锁：**假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。\n\n **两种锁的使用场景**\n\n 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。\n\n 多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。\n\n## 存储过程\n\n存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。\n\n**优点**\n\n1）存储过程是预编译过的，执行效率高。\n\n2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。\n\n3）安全性高，执行存储过程需要有一定权限的用户。\n\n4）存储过程可以重复使用，减少数据库开发人员的工作量。\n\n**缺点**\n\n1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。\n\n2）移植问题，数据库端代码当然是与数据库相关的。\n\n3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。\n\n4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。\n\n## 触发器\n\n### 什么是触发器 \n\n触发器是用户定义在关系表上的一类**由事件驱动的特殊的存储过程**。触发器是指一段代码，当触发某个事件时，自动执行这些代码。\n\n**使用场景**\n\n**可以通过数据库中的相关表实现级联更改。**\n\n实时监控某张表中的某个字段的更改而需要做出相应的处理。\n\n### MySQL中都有哪些触发器？\n\n**在MySQL数据库中有如下六种触发器：**\n\nBefore Insert、After Insert、Before Update、After Update、Before Delete、After Delete\n\n## 常用SQL语句\n\n### SQL语句主要分为哪几类\n\n数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER\n\n数据查询语言DQL（Data Query Language）SELECT\n\n数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE\n\n数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK\n\n### 主键 超键 候选键 外键\n\n- 主键：数据库表中对**存储数据对象予以唯一和完整标识**的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值\n\n- 外键：在一个表中存在**的另一个表的主键称此表的外键**。\n\n- 超键：**在关系中能唯一标识元组的属性集称为超键。**一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。候选键和主键一定是超键。\n\n- 候选键：是最小超键，即没有冗余元素的超键。\n\n### SQL 约束有哪几种？\n\n**NOT NULL**: 用于控制字段的内容一定不能为空。\n\n**UNIQUE**: 控件字段内容不能重复，一个表允许有多个 Unique 约束。\n\n**PRIMARY KEY**: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。\n\n**FOREIGN KEY:** 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。\n\n**CHECK**: 用于控制字段的值范围。\n\n### 关联查询\n\n**内连接**（INNER JOIN）\n\n**外连接**（LEFT JOIN/RIGHT JOIN）\n\n**联合查询**（UNION与UNION ALL）\n\n**交叉连接**（CROSS JOIN）\n\n**内连接分为三类**\n\n等值连接：ON A.id=B.id\n\n不等值连接：ON A.id > B.id\n\n自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid\n\n**外连接（LEFT JOIN/RIGHT JOIN）**\n\n左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN\n\n右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN\n\n**联合查询（UNION与UNION ALL**）\n\n就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并\n\n如果使用UNION ALL，不会合并重复的记录行\n\n效率 UNION ALL 高于 UNION\n\n### 什么是子查询\n\n一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。\n\n### 子查询的三种情况\n\n- 子查询是单行单列的情况：结果集是一个值，父查询使用：=、 <、 > 等运算符\n\n- 子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符\n\n- 子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表\n\n### in 和 exists 区别\n\nmysql中的in语句是**把外表和内表作hash 连接**，而**exists语句是对外表作loop循环，每次loop循环再对内表进行查询**。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。\n\n1、如果查询的两个表大小相当，那么用in和exists差别不大。\n\n2、如果两个表中一个表大，另一个是表小，那么IN适合于外表大而子查询表小的情况。\n\n3、如果两个表中一个表大，另一个是表小，EXISTS适合于外表小而子查询表大的情况。\n\nnot in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；\n\n而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。\n\n### drop,delete与truncate\n\ndrop直接删掉表，truncate、delete删除表中数据。\n\n1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。\n\n2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。\n\n3.应用范围。truncate只能对table，delete可以是table和view\n\n**使用场景:** \n\n不再需要一张表的时候，用drop \n\n想删除部分数据行时候，用delete，并且带上where子句 \n\n保留表而删除所有数据的时候用truncate \n\n|          | **Delete**                               | **Truncate**                   | **Drop**                                             |\n| -------- | ---------------------------------------- | ------------------------------ | ---------------------------------------------------- |\n| 类型     | 属于DML                                  | 属于DDL                        | 属于DDL                                              |\n| 回滚     | 可回滚                                   | 不可回滚                       | 不可回滚                                             |\n| 删除内容 | 表结构还在，删除表的全部或者一部分数据行 | 表结构还在，删除表中的所有数据 | 从数据库中删除表，所有的数据行，索引和权限也会被删除 |\n| 删除速度 | 删除速度慢，需要逐行删除                 | 删除速度快                     | 删除速度最快                                         |\n\n## SQL优化\n\n### 如何定位及优化SQL语句的性能问题？\n\nMySQL提供了**explain命令来查看语句的执行计划** 。执行计划，显示数据库引擎对于SQL语句的执行的详细情况，其中包含了**是否使用索引，使用什么索引，使用的索引的相关信息**等。\n\n**select_type** 每个子查询的查询类型，一些常见的查询类型。\n\n| **select_type** | **description**                           |\n| --------------- | ----------------------------------------- |\n| SIMPLE          | 不包含任何子查询或union等查询             |\n| PRIMARY         | 包含子查询最外层查询就显示为 PRIMARY      |\n| SUBQUERY        | 在select或 where字句中包含的查询          |\n| DERIVED         | from字句中包含的查询                      |\n| UNION           | 出现在union后的查询语句中                 |\n| UNION RESULT    | 从UNION中获取结果集，例如上文的第三个例子 |\n\n**type**(非常重要，可以看到有没有走索引) 访问类型\n\nALL 扫描全表数据\n\nindex 遍历索引\n\nrange 索引范围查找\n\nindex_subquery 在子查询中使用 ref\n\nunique_subquery 在子查询中使用 eq_ref\n\nref_or_null 对Null进行索引的优化的 ref\n\nfulltext 使用全文索引\n\nref 使用非唯一索引查找数据\n\neq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。\n\n**key** 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。\n\n**ref** 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n\n**rows** 返回估算的结果集数目，并不是一个准确的值。\n\n**extra** 的信息非常丰富，常见的有：\n\n- Using index 使用覆盖索引\n\n-  Using where 使用了用where子句来过滤结果集\n\n- Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。\n\n- Using temporary 使用了临时表\n\n### 大表数据查询，怎么优化\n\n优化shema、sql语句+索引；\n\n 第二加缓存，memcached, redis；\n\n主从复制，读写分离；\n\n垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；\n\n水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；\n\n### 超大分页怎么处理？\n\n- 数据库层面,类似于**select \\* from table where age > 20 limit 1000000,10**这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为`select * from table where id in (select id from table where age > 20 limit 1000000,10)`.**这样虽然也load了一百万的数据,但是由于**索引覆盖**,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以**`select * from table where id > 1000000 limit 10`效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.\n\n- 从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.\n\n### mysql 分页\n\nLIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0\n\n>  mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15\n\n### 慢查询日志\n\n用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。\n\n**开启慢查询日志**\n\n配置项：slow_query_log\n\n可以使用`show variables like ‘slow_query_log’`查看是否开启，如果状态值为OFF，可以使用`set GLOBAL slow_query_log = on`来开启，它会在datadir下产生一个xxx-slow.log的文件。\n\n**设置临界时间**\n\n配置项：long_query_time\n\n查看：show VARIABLES like 'long_query_time'，单位秒\n\n设置：set long_query_time=0.5\n\n实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉\n\n查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中\n\n### 为什么要尽量设定一个主键？\n\n主键是数据库确保**数据行在整张表唯一性**的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。\n\n### 主键使用自增ID还是UUID？\n\n自增ID，不要使用UUID。 \n\n因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，**会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。**\n\n### 字段为什么要求定义为not null？\n\nnull值会占用更多的字节，且会在程序中造成很多与预期不符的情况。\n\n### 如果要存储用户的密码散列，应该使用什么字段进行存储？\n\n密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。\n\n### SQL语句优化的一些方法\n\n- 尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。\n- 不使用SELECT \\*，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 \n- 能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 \n\n**避免索引失效**\n\n- 使用!= 或者 <> 或者或者or 来连接条件导致索引失效：需要判断索引成本\n- 筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效\n- 模糊搜索的前缀模糊导致的索引失效\n- NOT IN、NOT EXISTS导致索引失效：需要判断回表成本\n- 尽量避免在 where 子句中对字段进行 null 值判断\n\n## 数据库优化\n\n- 优化索引、SQL 语句、分析慢查询; \n- 设计表的时候严格根据数据库的设计范式来设计数据库; \n- 使用缓存，把经常访问到的数据而且不需要经常变化的 数据放在缓存中，能节约磁盘 IO; \n- 优化硬件;采用 SSD，使用磁盘队列技术 (RAID0,RAID1,RDID5)等; \n- 采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率; \n- 垂直分表;把一些不经常读的数据放在一张表里，节约 磁盘 I/O; \n- 主从分离读写;采用主从复制把数据库的读操作和写入操作分离开来;\n- 分库分表分机器，主要的原理就是数据路由; \n- 选择合适的表引擎，参数上的优化; \n- 进行架构级别的缓存，静态化和分布式; \n\n## galera复制原理\n\nGalera采用的是多主同步复制。\n\n事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。\n\n所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。\n\n## 分库分表后面临的问题\n\n **事务支持** 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。\n\n **跨库join** \n\n只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 \n\n **跨节点的count,order by,group by以及聚合函数问题** 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。\n\n **数据迁移，容量规划，扩容等问题** 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 \n\n **ID问题**\n\n一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略\n\n**UUID 使用UUID作主键是最简单的方案**，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 **Twitter的分布式自增ID算法Snowflake** 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。\n\n## sql语句中where与having的区别\n\nWhere 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。\n\nHaving是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。\n\n在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。","source":"_posts/mysql面试.md","raw":"---\ntitle: mysql面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-10 18:45:14\npassword:\nsummary:\ntags:\n- interview\ncategories:\n- interview\n---\n\n## 架构\n\n**server层**\n\n1. 连接器：管理连接，权限验证  \n\n2. 查询缓存  \n\n3. 分析器：词法、语法解析\n\n4. 优化器：生成执行计划，索引选择\n\n5. 执行器：操作引擎，返回结果\n\n**存储引擎层**\n\n1. 负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎\n\n##  日志系统\n\n### redo log（重做日志）\n\n1. InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）\n\n2. 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）\n\n3. redo log 是物理日志，记录的是在某个数据页上做了什么修改\n\n4. redo log是循环写，空间固定会用完\n\n### binlog（归档日志）\n\n1. server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力\n\n2. binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER、TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志\n\n3. binlog采用追加写的模式\n\n4. **用途：**  \n\n- 恢复：binlog日志恢复数据库数据  \n- 复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  \n- 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击\n\n**binlog常见格式**\n\n| format    | 定义                       | 优点                           | 缺点                                                         |\n| --------- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |\n| statement | 记录的是修改SQL语句        | 日志文件小，节约IO，提高性能   | 准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况） |\n| row       | 记录的是每行实际数据的变更 | 准确性强，能准确复制数据的变更 | 日志文件大，较大的网络IO和磁盘IO                             |\n| mixed     | statement和row模式的混合   | 准确性强，文件大小适中         | 有可能发生主从不一致问题                                     |\n\n### 两段提交  \n\n1. 两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致\n\n2. 两段提交： 写入redo log处于prepare阶段 --写入bin log --提交事务处于commit状态 \n\n- 时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  \n- 时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务\n\n3. bin log完整性判断:  \n\n- statement格式最后有commit  \n- row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）\n\n### undo log\n\n1. undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录\n\n2. undo log 作用  \n\n- 提供回滚  \n- 多版本并发控制（MVCC）\n\n### Mysql抖动\n\n当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。\n\n**flush场景**\n\n1. InnoDB 的 redo log 写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘\n2. 系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是\"脏页\"，就要先将脏页写到磁盘\n3. MySQL 认为系统\"空闲\"的时候，会flush脏页\n4. MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上\n\nInnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度\n\n## MyISAM索引与InnoDB索引的区别\n\nInnoDB索引是**聚簇索引**，MyISAM索引是**非聚簇索引**。\n\nInnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。\n\nInnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效\n\n**其他**\n\n- **InnoDB支持事务，MyISAM不支持**\n- MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用\n- **InnoDB支持外键，MyISAM不支持**\n- InnoDB中不保存表的行数，如`select count(*) from table`时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当`count(*)`语句包含where条件时MyISAM也需要扫描整个表\n- 对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引\n- 清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表\n- **InnoDB支持行锁**（某些情况下还是锁整表，如 `update table set a=1 where user like '%lee%'`\n\n## 索引\n\n### 定义\n\n数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。\n\n通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。\n\n索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。\n\n### 优缺点\n\n**索引的优点**\n\n- 加快数据的检索速度。\n\n**索引的缺点**\n\n- 创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；\n- 索引需要占物理空间。\n\n### 使用场景\n\n**where**\n\n**order by**\n\n使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据**使用磁盘临时文件完成外部排序或者在内存中完成排序**。具体取决于排序所需的内存和参数sort_buffer_size。\n\n如果我们对该字段建立索引，由于索引本身是有序的，因此直接**按照索引的顺序和映射关系逐条取出数据即可**。\n\n**join**\n\n对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）\n\n**覆盖索引**\n\n辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。\n\n如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。\n\n> 尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。\n\n### 索引类型\n\n**主键索引**： 不允许重复，不允许为NULL，一个表只能有一个主键。\n\n**唯一索引**：不允许重复，允许为NULL，一个表允许多唯一索引。\n\n**普通索引**：基本的索引类型，没有唯一性的限制，允许为NULL值。\n\n**全文索引**： 是目前搜索引擎使用的一种关键技术。\n\n### 索引的数据结构\n\n和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。\n\nInnoDB存储引擎的默认索引实现为：B+树索引。\n\n哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。\n\n### 索引设计的原则\n\n**适合索引的列**是出现在where子句中的列，或者连接子句中指定的列\n\n**使用短索引**，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间\n\n**不要过度索引**。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。\n\n### 创建索引的原则\n\n1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立`(a,b,c,d)`顺序的索引，d是用不到索引的，如果建立`(a,b,d,c)`的索引则都可以用到，a,b,d的顺序可以任意调整。\n\n2）较频繁作为查询条件的字段才去创建索引\n\n3）更新频繁字段不适合创建索引\n\n4）若是不能有效区分数据的列不适合做索引列（如性别，男女未知，最多也就三种，区分度实在太低），选择基数较大的列做索引\n\n5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。\n\n6）定义有外键的数据列一定要建立索引。\n\n### 创建索引注意点\n\n**非空字段：**应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；\n\n**取值离散大的字段：**（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值\n\n**索引字段越小越好**：数据库的数据存储以页为单位，一页存储的数据越多一次IO操作获取的数据越大，效率越高。\n\n### 使用索引查询一定能提高查询的性能吗\n\n**通常，通过索引查询数据比全表扫描要快。**但是我们也必须注意到它的代价。\n\n**索引需要空间来存储，也需要定期维护，** 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况:\n\n- 基于一个范围的检索，一般查询返回结果集小于表中记录数的30%\n- **基于非唯一性索引的检索（？？？）**\n\n### 百万级别或以上的数据如何删除\n\n> 索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的。\n\n所以删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）\n\n然后删除其中无用数据（此过程需要不到两分钟）\n\n删除完成后重新创建索引（此时数据较少了，创建索引也非常快，约十分钟左右。）\n\n### 前缀索引\n\n语法：``index(field(10))``，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。\n\n前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。\n\n实操的难度：**在于前缀截取的长度。**\n\n我们可以利用`select count(*)/count(distinct left(password,prefixLen));`，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）\n\n### B-/+Tree索引的性能分析\n\n B-Tree：根据B-Tree的定义，可知检索一次最多需要访问h个节点，利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，保证一个节点存储在一个页里。\n\nB+Tree：B+Tree更适合外存索引，由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能\n\n### B-Tree和B+Tree的区别\n\n在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。\n\nB+树的叶子节点有一条链相连，而B树的叶子节点各自独立。\n\n### 使用B树的好处\n\nB树可以在**内部节点同时存储键和值**，因此，**把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。**这种特性使得B树在特定数据重复多次查询的场景中更加高效。\n\n### 使用B+树的好处\n\n由于**B+树的内部节点只存放键**，不存放值，因此，**一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围**。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，**B+树只需要使用`O(logN)`时间找到最小的一个节点，然后通过链进行`O(N)`的顺序遍历即可。**而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间\n\n### Hash索引和B+树优劣\n\n首先要知道Hash索引和B+树索引的底层实现原理：\n\n**hash索引底层就是hash表**，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是**多路平衡查找树**。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。\n\n那么可以看出他们有以下的不同：\n\n- hash索引进行**等值查询更快（一般情况下），但是却无法进行范围查询**。\n\n因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。\n\n- hash索引**不支持使用索引进行排序**，原理同上。\n\n- hash索引不**支持模糊查询以及多列索引的最左前缀匹配。**原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。\n\n- hash索引任何时候都**避免不了回表查询数据**，而B+树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。\n- hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。\n\n因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。\n\n### 使用B+树而不是B树\n\n- **B树只适合随机检索，而B+树同时支持随机检索和顺序检索**；\n\n-  **B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。**一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；\n\n- **B+树的查询效率更加稳定。**B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。\n\n- **B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。**B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。\n\n- **增删文件（节点）时，效率更高。**因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。\n\n### 聚簇索引\n\n**聚簇索引**：将数据存储与索引放到了一块，找到索引也就找到了数据\n\n**非聚簇索引**：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，因此索引不在key buffer命中时，速度慢。\n\n**澄清一个概念：**innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值\n\n### 非聚簇索引一定会回表查询吗？\n\n不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。\n\n> 举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age < 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。\n\n### **联合索引**\n\nMySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。\n\n### **为什么需要注意联合索引中的顺序？**\n\nMySQL使用索引时需要索引有序.\n\n一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。\n\n## 数据库范式\n\n**第一范式：**强调的是列的原子性，即列不能够再分成其他几列。\n\n **第二范式**：首先是 1NF，另外包含两部分内容，**一是表必须有一个主键**；二是没有包含在主键中的**列必须完全依赖于主键，而不能只依赖于主键的一部分**。否则可拆表。\n\n **第三范式**：在1NF基础上，**任何非主属性不依赖于其它非主属性**[在2NF基础上消除传递依赖]。\n\n## mysql有关权限的表\n\nMySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别**user，db，table_priv，columns_priv和host**。下面分别介绍一下这些表的结构和内容：\n\nuser权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。\n\ndb权限表：记录各个帐号在各个数据库上的操作权限。\n\ntable_priv权限表：记录数据表级的操作权限。\n\ncolumns_priv权限表：记录数据列级的操作权限。\n\nhost权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。\n\n## 视图\n\n视图是虚拟的表，视图只包含使用时动态检索数据的查询;不包含任何列或数据。\n\n使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;\n\n视图创建后，可以使用与表相同的方式利用它们。\n\n> 视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。\n\n### 视图有哪些特点？\n\n- 视图是由基本表（实表）产生的表（虚表）。\n- 视图的建立和删除不影响基本表。\n- 对视图内容的更新（添加，删除和修改）直接影响基本表。\n- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。\n- 当视图来自多个基本表时，不允许添加和删除数据。\n\n### 视图的使用场景有哪些？\n\n视图根本用途：简化sql查询，提高开发效率。\n\n**常见使用场景：**\n\n重用SQL语句；\n\n**简化复杂的SQL操作**。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；\n\n**保护数据**。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；\n\n**更改数据格式和表示**。视图可返回与底层表的表示和格式不同的数据。\n\n### 视图的优点\n\n**查询简单化**。视图能简化用户的操作\n\n**数据安全性**。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护\n\n### 视图的缺点\n\n**性能**。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由复杂的多表查询所定义，那么，视图的查询，需要花费一定的时间。\n\n**修改限制**。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。\n\n### 游标\n\n游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。用户可以通过游标，逐一获取记录，进一步处理。\n\n## 事务\n\n### 什么是数据库事务？\n\n一个不可分割的数据库操作序列，是数据库并发控制的基本单位。\n\n事务是逻辑上的一组操作，要么都执行，要么都不执行。\n\n> 假如小明要给小红转账1000元：将小明的余额减少1000元，将小红的余额增加1000元。万一操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么成功，要么都失败。\n\n### 事务的特性\n\n- atomicity（原子性） ：要么全执行，要么全都不执行；\n- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；\n- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；\n- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。\n\n### 什么是脏读？幻读？不可重复读？\n\n脏读：读取未提交的事务。\n\n不可重复读：多次读取同一数据，读取的数据不一致。\n\n幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n### 事务的隔离级别\n\n| **隔离级别**     | **脏读** | **不可重复读** | **幻读** |\n| ---------------- | -------- | -------------- | -------- |\n| READ-UNCOMMITTED | √        | √              | √        |\n| READ-COMMITTED   | ×        | √              | √        |\n| REPEATABLE-READ  | ×        | ×              | √        |\n| SERIALIZABLE     | ×        | ×              | ×        |\n\n事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。\n\n## 锁\n\n当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。\n\n### 锁分类\n\n按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。\n\n**行级锁** 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。\n\n特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。\n\n**表级锁** 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。\n\n特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。\n\n**页级锁** 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。\n\n特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般\n\n从锁的类别上来讲，有共享锁和排他锁。\n\n**共享锁:** 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。\n\n**排他锁:** 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。\n\n### InnoDB存储引擎的锁的算法\n\nRecord lock：单个行记录上的锁\n\nGap lock：间隙锁，锁定一个范围，不包括记录本身\n\nNext-key lock：record+gap 锁定一个范围，包含记录本身\n\n### 死锁\n\n1. **Mysql死锁策略**  \n\n- 直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置  \n- 发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑\n\n2. **避免死锁的常用方法**  \n\n- 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会  \n- 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能  \n\n### 什么是死锁？怎么解决？\n\n死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。\n\n**常见的避免死锁的方法**\n\n1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。\n\n2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；\n\n3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；\n\n4、在RR隔离级别下，如果两个线程同时对相同条件记录用 SELECT...FOR UPDATE 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，**将隔离级别改成RC不会产生间隙锁**，就可避免问题  \n\n5、在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯，如果出现死锁，可以用 **show innodb status** 命令来确定最后一个死锁产生的原因，返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等\n\n如果业务处理不好可以用**分布式事务锁或者使用乐观锁**\n\n### 乐观锁和悲观锁是什么？怎么实现的？\n\n**悲观锁：**假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制\n\n **乐观锁：**假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。\n\n **两种锁的使用场景**\n\n 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。\n\n 多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。\n\n## 存储过程\n\n存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。\n\n**优点**\n\n1）存储过程是预编译过的，执行效率高。\n\n2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。\n\n3）安全性高，执行存储过程需要有一定权限的用户。\n\n4）存储过程可以重复使用，减少数据库开发人员的工作量。\n\n**缺点**\n\n1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。\n\n2）移植问题，数据库端代码当然是与数据库相关的。\n\n3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。\n\n4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。\n\n## 触发器\n\n### 什么是触发器 \n\n触发器是用户定义在关系表上的一类**由事件驱动的特殊的存储过程**。触发器是指一段代码，当触发某个事件时，自动执行这些代码。\n\n**使用场景**\n\n**可以通过数据库中的相关表实现级联更改。**\n\n实时监控某张表中的某个字段的更改而需要做出相应的处理。\n\n### MySQL中都有哪些触发器？\n\n**在MySQL数据库中有如下六种触发器：**\n\nBefore Insert、After Insert、Before Update、After Update、Before Delete、After Delete\n\n## 常用SQL语句\n\n### SQL语句主要分为哪几类\n\n数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER\n\n数据查询语言DQL（Data Query Language）SELECT\n\n数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE\n\n数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK\n\n### 主键 超键 候选键 外键\n\n- 主键：数据库表中对**存储数据对象予以唯一和完整标识**的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值\n\n- 外键：在一个表中存在**的另一个表的主键称此表的外键**。\n\n- 超键：**在关系中能唯一标识元组的属性集称为超键。**一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。候选键和主键一定是超键。\n\n- 候选键：是最小超键，即没有冗余元素的超键。\n\n### SQL 约束有哪几种？\n\n**NOT NULL**: 用于控制字段的内容一定不能为空。\n\n**UNIQUE**: 控件字段内容不能重复，一个表允许有多个 Unique 约束。\n\n**PRIMARY KEY**: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。\n\n**FOREIGN KEY:** 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。\n\n**CHECK**: 用于控制字段的值范围。\n\n### 关联查询\n\n**内连接**（INNER JOIN）\n\n**外连接**（LEFT JOIN/RIGHT JOIN）\n\n**联合查询**（UNION与UNION ALL）\n\n**交叉连接**（CROSS JOIN）\n\n**内连接分为三类**\n\n等值连接：ON A.id=B.id\n\n不等值连接：ON A.id > B.id\n\n自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid\n\n**外连接（LEFT JOIN/RIGHT JOIN）**\n\n左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN\n\n右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN\n\n**联合查询（UNION与UNION ALL**）\n\n就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并\n\n如果使用UNION ALL，不会合并重复的记录行\n\n效率 UNION ALL 高于 UNION\n\n### 什么是子查询\n\n一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。\n\n### 子查询的三种情况\n\n- 子查询是单行单列的情况：结果集是一个值，父查询使用：=、 <、 > 等运算符\n\n- 子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符\n\n- 子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表\n\n### in 和 exists 区别\n\nmysql中的in语句是**把外表和内表作hash 连接**，而**exists语句是对外表作loop循环，每次loop循环再对内表进行查询**。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。\n\n1、如果查询的两个表大小相当，那么用in和exists差别不大。\n\n2、如果两个表中一个表大，另一个是表小，那么IN适合于外表大而子查询表小的情况。\n\n3、如果两个表中一个表大，另一个是表小，EXISTS适合于外表小而子查询表大的情况。\n\nnot in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；\n\n而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。\n\n### drop,delete与truncate\n\ndrop直接删掉表，truncate、delete删除表中数据。\n\n1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。\n\n2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。\n\n3.应用范围。truncate只能对table，delete可以是table和view\n\n**使用场景:** \n\n不再需要一张表的时候，用drop \n\n想删除部分数据行时候，用delete，并且带上where子句 \n\n保留表而删除所有数据的时候用truncate \n\n|          | **Delete**                               | **Truncate**                   | **Drop**                                             |\n| -------- | ---------------------------------------- | ------------------------------ | ---------------------------------------------------- |\n| 类型     | 属于DML                                  | 属于DDL                        | 属于DDL                                              |\n| 回滚     | 可回滚                                   | 不可回滚                       | 不可回滚                                             |\n| 删除内容 | 表结构还在，删除表的全部或者一部分数据行 | 表结构还在，删除表中的所有数据 | 从数据库中删除表，所有的数据行，索引和权限也会被删除 |\n| 删除速度 | 删除速度慢，需要逐行删除                 | 删除速度快                     | 删除速度最快                                         |\n\n## SQL优化\n\n### 如何定位及优化SQL语句的性能问题？\n\nMySQL提供了**explain命令来查看语句的执行计划** 。执行计划，显示数据库引擎对于SQL语句的执行的详细情况，其中包含了**是否使用索引，使用什么索引，使用的索引的相关信息**等。\n\n**select_type** 每个子查询的查询类型，一些常见的查询类型。\n\n| **select_type** | **description**                           |\n| --------------- | ----------------------------------------- |\n| SIMPLE          | 不包含任何子查询或union等查询             |\n| PRIMARY         | 包含子查询最外层查询就显示为 PRIMARY      |\n| SUBQUERY        | 在select或 where字句中包含的查询          |\n| DERIVED         | from字句中包含的查询                      |\n| UNION           | 出现在union后的查询语句中                 |\n| UNION RESULT    | 从UNION中获取结果集，例如上文的第三个例子 |\n\n**type**(非常重要，可以看到有没有走索引) 访问类型\n\nALL 扫描全表数据\n\nindex 遍历索引\n\nrange 索引范围查找\n\nindex_subquery 在子查询中使用 ref\n\nunique_subquery 在子查询中使用 eq_ref\n\nref_or_null 对Null进行索引的优化的 ref\n\nfulltext 使用全文索引\n\nref 使用非唯一索引查找数据\n\neq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。\n\n**key** 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。\n\n**ref** 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n\n**rows** 返回估算的结果集数目，并不是一个准确的值。\n\n**extra** 的信息非常丰富，常见的有：\n\n- Using index 使用覆盖索引\n\n-  Using where 使用了用where子句来过滤结果集\n\n- Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。\n\n- Using temporary 使用了临时表\n\n### 大表数据查询，怎么优化\n\n优化shema、sql语句+索引；\n\n 第二加缓存，memcached, redis；\n\n主从复制，读写分离；\n\n垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；\n\n水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；\n\n### 超大分页怎么处理？\n\n- 数据库层面,类似于**select \\* from table where age > 20 limit 1000000,10**这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为`select * from table where id in (select id from table where age > 20 limit 1000000,10)`.**这样虽然也load了一百万的数据,但是由于**索引覆盖**,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以**`select * from table where id > 1000000 limit 10`效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.\n\n- 从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.\n\n### mysql 分页\n\nLIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0\n\n>  mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15\n\n### 慢查询日志\n\n用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。\n\n**开启慢查询日志**\n\n配置项：slow_query_log\n\n可以使用`show variables like ‘slow_query_log’`查看是否开启，如果状态值为OFF，可以使用`set GLOBAL slow_query_log = on`来开启，它会在datadir下产生一个xxx-slow.log的文件。\n\n**设置临界时间**\n\n配置项：long_query_time\n\n查看：show VARIABLES like 'long_query_time'，单位秒\n\n设置：set long_query_time=0.5\n\n实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉\n\n查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中\n\n### 为什么要尽量设定一个主键？\n\n主键是数据库确保**数据行在整张表唯一性**的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。\n\n### 主键使用自增ID还是UUID？\n\n自增ID，不要使用UUID。 \n\n因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，**会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。**\n\n### 字段为什么要求定义为not null？\n\nnull值会占用更多的字节，且会在程序中造成很多与预期不符的情况。\n\n### 如果要存储用户的密码散列，应该使用什么字段进行存储？\n\n密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。\n\n### SQL语句优化的一些方法\n\n- 尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。\n- 不使用SELECT \\*，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 \n- 能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 \n\n**避免索引失效**\n\n- 使用!= 或者 <> 或者或者or 来连接条件导致索引失效：需要判断索引成本\n- 筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效\n- 模糊搜索的前缀模糊导致的索引失效\n- NOT IN、NOT EXISTS导致索引失效：需要判断回表成本\n- 尽量避免在 where 子句中对字段进行 null 值判断\n\n## 数据库优化\n\n- 优化索引、SQL 语句、分析慢查询; \n- 设计表的时候严格根据数据库的设计范式来设计数据库; \n- 使用缓存，把经常访问到的数据而且不需要经常变化的 数据放在缓存中，能节约磁盘 IO; \n- 优化硬件;采用 SSD，使用磁盘队列技术 (RAID0,RAID1,RDID5)等; \n- 采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率; \n- 垂直分表;把一些不经常读的数据放在一张表里，节约 磁盘 I/O; \n- 主从分离读写;采用主从复制把数据库的读操作和写入操作分离开来;\n- 分库分表分机器，主要的原理就是数据路由; \n- 选择合适的表引擎，参数上的优化; \n- 进行架构级别的缓存，静态化和分布式; \n\n## galera复制原理\n\nGalera采用的是多主同步复制。\n\n事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。\n\n所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。\n\n## 分库分表后面临的问题\n\n **事务支持** 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。\n\n **跨库join** \n\n只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 \n\n **跨节点的count,order by,group by以及聚合函数问题** 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。\n\n **数据迁移，容量规划，扩容等问题** 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 \n\n **ID问题**\n\n一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略\n\n**UUID 使用UUID作主键是最简单的方案**，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 **Twitter的分布式自增ID算法Snowflake** 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。\n\n## sql语句中where与having的区别\n\nWhere 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。\n\nHaving是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。\n\n在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。","slug":"mysql面试","published":1,"updated":"2021-05-19T11:09:42.123Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6wm002iq4ufxuaapxqp","content":"<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p><strong>server层</strong></p>\n<ol>\n<li><p>连接器：管理连接，权限验证  </p>\n</li>\n<li><p>查询缓存  </p>\n</li>\n<li><p>分析器：词法、语法解析</p>\n</li>\n<li><p>优化器：生成执行计划，索引选择</p>\n</li>\n<li><p>执行器：操作引擎，返回结果</p>\n</li>\n</ol>\n<p><strong>存储引擎层</strong></p>\n<ol>\n<li>负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎</li>\n</ol>\n<h2 id=\"日志系统\"><a href=\"#日志系统\" class=\"headerlink\" title=\"日志系统\"></a>日志系统</h2><h3 id=\"redo-log（重做日志）\"><a href=\"#redo-log（重做日志）\" class=\"headerlink\" title=\"redo log（重做日志）\"></a>redo log（重做日志）</h3><ol>\n<li><p>InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）</p>\n</li>\n<li><p>在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）</p>\n</li>\n<li><p>redo log 是物理日志，记录的是在某个数据页上做了什么修改</p>\n</li>\n<li><p>redo log是循环写，空间固定会用完</p>\n</li>\n</ol>\n<h3 id=\"binlog（归档日志）\"><a href=\"#binlog（归档日志）\" class=\"headerlink\" title=\"binlog（归档日志）\"></a>binlog（归档日志）</h3><ol>\n<li><p>server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力</p>\n</li>\n<li><p>binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER、TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志</p>\n</li>\n<li><p>binlog采用追加写的模式</p>\n</li>\n<li><p><strong>用途：</strong>  </p>\n</li>\n</ol>\n<ul>\n<li>恢复：binlog日志恢复数据库数据  </li>\n<li>复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  </li>\n<li>审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击</li>\n</ul>\n<p><strong>binlog常见格式</strong></p>\n<table>\n<thead>\n<tr>\n<th>format</th>\n<th>定义</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>statement</td>\n<td>记录的是修改SQL语句</td>\n<td>日志文件小，节约IO，提高性能</td>\n<td>准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况）</td>\n</tr>\n<tr>\n<td>row</td>\n<td>记录的是每行实际数据的变更</td>\n<td>准确性强，能准确复制数据的变更</td>\n<td>日志文件大，较大的网络IO和磁盘IO</td>\n</tr>\n<tr>\n<td>mixed</td>\n<td>statement和row模式的混合</td>\n<td>准确性强，文件大小适中</td>\n<td>有可能发生主从不一致问题</td>\n</tr>\n</tbody></table>\n<h3 id=\"两段提交\"><a href=\"#两段提交\" class=\"headerlink\" title=\"两段提交\"></a>两段提交</h3><ol>\n<li><p>两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致</p>\n</li>\n<li><p>两段提交： 写入redo log处于prepare阶段 –写入bin log –提交事务处于commit状态 </p>\n</li>\n</ol>\n<ul>\n<li>时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  </li>\n<li>时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务</li>\n</ul>\n<ol start=\"3\">\n<li>bin log完整性判断:  </li>\n</ol>\n<ul>\n<li>statement格式最后有commit  </li>\n<li>row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）</li>\n</ul>\n<h3 id=\"undo-log\"><a href=\"#undo-log\" class=\"headerlink\" title=\"undo log\"></a>undo log</h3><ol>\n<li><p>undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</p>\n</li>\n<li><p>undo log 作用  </p>\n</li>\n</ol>\n<ul>\n<li>提供回滚  </li>\n<li>多版本并发控制（MVCC）</li>\n</ul>\n<h3 id=\"Mysql抖动\"><a href=\"#Mysql抖动\" class=\"headerlink\" title=\"Mysql抖动\"></a>Mysql抖动</h3><p>当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。</p>\n<p><strong>flush场景</strong></p>\n<ol>\n<li>InnoDB 的 redo log 写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘</li>\n<li>系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是”脏页”，就要先将脏页写到磁盘</li>\n<li>MySQL 认为系统”空闲”的时候，会flush脏页</li>\n<li>MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上</li>\n</ol>\n<p>InnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度</p>\n<h2 id=\"MyISAM索引与InnoDB索引的区别\"><a href=\"#MyISAM索引与InnoDB索引的区别\" class=\"headerlink\" title=\"MyISAM索引与InnoDB索引的区别\"></a>MyISAM索引与InnoDB索引的区别</h2><p>InnoDB索引是<strong>聚簇索引</strong>，MyISAM索引是<strong>非聚簇索引</strong>。</p>\n<p>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p>\n<p>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效</p>\n<p><strong>其他</strong></p>\n<ul>\n<li><strong>InnoDB支持事务，MyISAM不支持</strong></li>\n<li>MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用</li>\n<li><strong>InnoDB支持外键，MyISAM不支持</strong></li>\n<li>InnoDB中不保存表的行数，如<code>select count(*) from table</code>时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当<code>count(*)</code>语句包含where条件时MyISAM也需要扫描整个表</li>\n<li>对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引</li>\n<li>清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表</li>\n<li><strong>InnoDB支持行锁</strong>（某些情况下还是锁整表，如 <code>update table set a=1 where user like &#39;%lee%&#39;</code></li>\n</ul>\n<h2 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。</p>\n<p>通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。</p>\n<p>索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。</p>\n<h3 id=\"优缺点\"><a href=\"#优缺点\" class=\"headerlink\" title=\"优缺点\"></a>优缺点</h3><p><strong>索引的优点</strong></p>\n<ul>\n<li>加快数据的检索速度。</li>\n</ul>\n<p><strong>索引的缺点</strong></p>\n<ul>\n<li>创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；</li>\n<li>索引需要占物理空间。</li>\n</ul>\n<h3 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a>使用场景</h3><p><strong>where</strong></p>\n<p><strong>order by</strong></p>\n<p>使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据<strong>使用磁盘临时文件完成外部排序或者在内存中完成排序</strong>。具体取决于排序所需的内存和参数sort_buffer_size。</p>\n<p>如果我们对该字段建立索引，由于索引本身是有序的，因此直接<strong>按照索引的顺序和映射关系逐条取出数据即可</strong>。</p>\n<p><strong>join</strong></p>\n<p>对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）</p>\n<p><strong>覆盖索引</strong></p>\n<p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p>\n<p>如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。</p>\n<blockquote>\n<p>尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。</p>\n</blockquote>\n<h3 id=\"索引类型\"><a href=\"#索引类型\" class=\"headerlink\" title=\"索引类型\"></a>索引类型</h3><p><strong>主键索引</strong>： 不允许重复，不允许为NULL，一个表只能有一个主键。</p>\n<p><strong>唯一索引</strong>：不允许重复，允许为NULL，一个表允许多唯一索引。</p>\n<p><strong>普通索引</strong>：基本的索引类型，没有唯一性的限制，允许为NULL值。</p>\n<p><strong>全文索引</strong>： 是目前搜索引擎使用的一种关键技术。</p>\n<h3 id=\"索引的数据结构\"><a href=\"#索引的数据结构\" class=\"headerlink\" title=\"索引的数据结构\"></a>索引的数据结构</h3><p>和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。</p>\n<p>InnoDB存储引擎的默认索引实现为：B+树索引。</p>\n<p>哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。</p>\n<h3 id=\"索引设计的原则\"><a href=\"#索引设计的原则\" class=\"headerlink\" title=\"索引设计的原则\"></a>索引设计的原则</h3><p><strong>适合索引的列</strong>是出现在where子句中的列，或者连接子句中指定的列</p>\n<p><strong>使用短索引</strong>，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间</p>\n<p><strong>不要过度索引</strong>。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。</p>\n<h3 id=\"创建索引的原则\"><a href=\"#创建索引的原则\" class=\"headerlink\" title=\"创建索引的原则\"></a>创建索引的原则</h3><p>1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立<code>(a,b,c,d)</code>顺序的索引，d是用不到索引的，如果建立<code>(a,b,d,c)</code>的索引则都可以用到，a,b,d的顺序可以任意调整。</p>\n<p>2）较频繁作为查询条件的字段才去创建索引</p>\n<p>3）更新频繁字段不适合创建索引</p>\n<p>4）若是不能有效区分数据的列不适合做索引列（如性别，男女未知，最多也就三种，区分度实在太低），选择基数较大的列做索引</p>\n<p>5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。</p>\n<p>6）定义有外键的数据列一定要建立索引。</p>\n<h3 id=\"创建索引注意点\"><a href=\"#创建索引注意点\" class=\"headerlink\" title=\"创建索引注意点\"></a>创建索引注意点</h3><p><strong>非空字段：</strong>应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</p>\n<p><strong>取值离散大的字段：</strong>（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值</p>\n<p><strong>索引字段越小越好</strong>：数据库的数据存储以页为单位，一页存储的数据越多一次IO操作获取的数据越大，效率越高。</p>\n<h3 id=\"使用索引查询一定能提高查询的性能吗\"><a href=\"#使用索引查询一定能提高查询的性能吗\" class=\"headerlink\" title=\"使用索引查询一定能提高查询的性能吗\"></a>使用索引查询一定能提高查询的性能吗</h3><p><strong>通常，通过索引查询数据比全表扫描要快。</strong>但是我们也必须注意到它的代价。</p>\n<p><strong>索引需要空间来存储，也需要定期维护，</strong> 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况:</p>\n<ul>\n<li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%</li>\n<li><strong>基于非唯一性索引的检索（？？？）</strong></li>\n</ul>\n<h3 id=\"百万级别或以上的数据如何删除\"><a href=\"#百万级别或以上的数据如何删除\" class=\"headerlink\" title=\"百万级别或以上的数据如何删除\"></a>百万级别或以上的数据如何删除</h3><blockquote>\n<p>索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的。</p>\n</blockquote>\n<p>所以删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）</p>\n<p>然后删除其中无用数据（此过程需要不到两分钟）</p>\n<p>删除完成后重新创建索引（此时数据较少了，创建索引也非常快，约十分钟左右。）</p>\n<h3 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h3><p>语法：<code>index(field(10))</code>，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。</p>\n<p>前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。</p>\n<p>实操的难度：<strong>在于前缀截取的长度。</strong></p>\n<p>我们可以利用<code>select count(*)/count(distinct left(password,prefixLen));</code>，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）</p>\n<h3 id=\"B-Tree索引的性能分析\"><a href=\"#B-Tree索引的性能分析\" class=\"headerlink\" title=\"B-/+Tree索引的性能分析\"></a>B-/+Tree索引的性能分析</h3><p> B-Tree：根据B-Tree的定义，可知检索一次最多需要访问h个节点，利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，保证一个节点存储在一个页里。</p>\n<p>B+Tree：B+Tree更适合外存索引，由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能</p>\n<h3 id=\"B-Tree和B-Tree的区别\"><a href=\"#B-Tree和B-Tree的区别\" class=\"headerlink\" title=\"B-Tree和B+Tree的区别\"></a>B-Tree和B+Tree的区别</h3><p>在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。</p>\n<p>B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。</p>\n<h3 id=\"使用B树的好处\"><a href=\"#使用B树的好处\" class=\"headerlink\" title=\"使用B树的好处\"></a>使用B树的好处</h3><p>B树可以在<strong>内部节点同时存储键和值</strong>，因此，<strong>把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。</strong>这种特性使得B树在特定数据重复多次查询的场景中更加高效。</p>\n<h3 id=\"使用B-树的好处\"><a href=\"#使用B-树的好处\" class=\"headerlink\" title=\"使用B+树的好处\"></a>使用B+树的好处</h3><p>由于<strong>B+树的内部节点只存放键</strong>，不存放值，因此，<strong>一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围</strong>。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，<strong>B+树只需要使用<code>O(logN)</code>时间找到最小的一个节点，然后通过链进行<code>O(N)</code>的顺序遍历即可。</strong>而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间</p>\n<h3 id=\"Hash索引和B-树优劣\"><a href=\"#Hash索引和B-树优劣\" class=\"headerlink\" title=\"Hash索引和B+树优劣\"></a>Hash索引和B+树优劣</h3><p>首先要知道Hash索引和B+树索引的底层实现原理：</p>\n<p><strong>hash索引底层就是hash表</strong>，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是<strong>多路平衡查找树</strong>。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。</p>\n<p>那么可以看出他们有以下的不同：</p>\n<ul>\n<li>hash索引进行<strong>等值查询更快（一般情况下），但是却无法进行范围查询</strong>。</li>\n</ul>\n<p>因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。</p>\n<ul>\n<li><p>hash索引<strong>不支持使用索引进行排序</strong>，原理同上。</p>\n</li>\n<li><p>hash索引不<strong>支持模糊查询以及多列索引的最左前缀匹配。</strong>原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。</p>\n</li>\n<li><p>hash索引任何时候都<strong>避免不了回表查询数据</strong>，而B+树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。</p>\n</li>\n<li><p>hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。</p>\n</li>\n</ul>\n<p>因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。</p>\n<h3 id=\"使用B-树而不是B树\"><a href=\"#使用B-树而不是B树\" class=\"headerlink\" title=\"使用B+树而不是B树\"></a>使用B+树而不是B树</h3><ul>\n<li><p><strong>B树只适合随机检索，而B+树同时支持随机检索和顺序检索</strong>；</p>\n</li>\n<li><p><strong>B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。</strong>一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；</p>\n</li>\n<li><p><strong>B+树的查询效率更加稳定。</strong>B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。</p>\n</li>\n<li><p><strong>B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。</strong>B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。</p>\n</li>\n<li><p><strong>增删文件（节点）时，效率更高。</strong>因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。</p>\n</li>\n</ul>\n<h3 id=\"聚簇索引\"><a href=\"#聚簇索引\" class=\"headerlink\" title=\"聚簇索引\"></a>聚簇索引</h3><p><strong>聚簇索引</strong>：将数据存储与索引放到了一块，找到索引也就找到了数据</p>\n<p><strong>非聚簇索引</strong>：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，因此索引不在key buffer命中时，速度慢。</p>\n<p><strong>澄清一个概念：</strong>innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值</p>\n<h3 id=\"非聚簇索引一定会回表查询吗？\"><a href=\"#非聚簇索引一定会回表查询吗？\" class=\"headerlink\" title=\"非聚簇索引一定会回表查询吗？\"></a>非聚簇索引一定会回表查询吗？</h3><p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。</p>\n<blockquote>\n<p>举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age &lt; 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。</p>\n</blockquote>\n<h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a><strong>联合索引</strong></h3><p>MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。</p>\n<h3 id=\"为什么需要注意联合索引中的顺序？\"><a href=\"#为什么需要注意联合索引中的顺序？\" class=\"headerlink\" title=\"为什么需要注意联合索引中的顺序？\"></a><strong>为什么需要注意联合索引中的顺序？</strong></h3><p>MySQL使用索引时需要索引有序.</p>\n<p>一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p>\n<h2 id=\"数据库范式\"><a href=\"#数据库范式\" class=\"headerlink\" title=\"数据库范式\"></a>数据库范式</h2><p><strong>第一范式：</strong>强调的是列的原子性，即列不能够再分成其他几列。</p>\n<p> <strong>第二范式</strong>：首先是 1NF，另外包含两部分内容，<strong>一是表必须有一个主键</strong>；二是没有包含在主键中的<strong>列必须完全依赖于主键，而不能只依赖于主键的一部分</strong>。否则可拆表。</p>\n<p> <strong>第三范式</strong>：在1NF基础上，<strong>任何非主属性不依赖于其它非主属性</strong>[在2NF基础上消除传递依赖]。</p>\n<h2 id=\"mysql有关权限的表\"><a href=\"#mysql有关权限的表\" class=\"headerlink\" title=\"mysql有关权限的表\"></a>mysql有关权限的表</h2><p>MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别<strong>user，db，table_priv，columns_priv和host</strong>。下面分别介绍一下这些表的结构和内容：</p>\n<p>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</p>\n<p>db权限表：记录各个帐号在各个数据库上的操作权限。</p>\n<p>table_priv权限表：记录数据表级的操作权限。</p>\n<p>columns_priv权限表：记录数据列级的操作权限。</p>\n<p>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。</p>\n<h2 id=\"视图\"><a href=\"#视图\" class=\"headerlink\" title=\"视图\"></a>视图</h2><p>视图是虚拟的表，视图只包含使用时动态检索数据的查询;不包含任何列或数据。</p>\n<p>使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;</p>\n<p>视图创建后，可以使用与表相同的方式利用它们。</p>\n<blockquote>\n<p>视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。</p>\n</blockquote>\n<h3 id=\"视图有哪些特点？\"><a href=\"#视图有哪些特点？\" class=\"headerlink\" title=\"视图有哪些特点？\"></a>视图有哪些特点？</h3><ul>\n<li>视图是由基本表（实表）产生的表（虚表）。</li>\n<li>视图的建立和删除不影响基本表。</li>\n<li>对视图内容的更新（添加，删除和修改）直接影响基本表。</li>\n<li>视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。</li>\n<li>当视图来自多个基本表时，不允许添加和删除数据。</li>\n</ul>\n<h3 id=\"视图的使用场景有哪些？\"><a href=\"#视图的使用场景有哪些？\" class=\"headerlink\" title=\"视图的使用场景有哪些？\"></a>视图的使用场景有哪些？</h3><p>视图根本用途：简化sql查询，提高开发效率。</p>\n<p><strong>常见使用场景：</strong></p>\n<p>重用SQL语句；</p>\n<p><strong>简化复杂的SQL操作</strong>。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</p>\n<p><strong>保护数据</strong>。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</p>\n<p><strong>更改数据格式和表示</strong>。视图可返回与底层表的表示和格式不同的数据。</p>\n<h3 id=\"视图的优点\"><a href=\"#视图的优点\" class=\"headerlink\" title=\"视图的优点\"></a>视图的优点</h3><p><strong>查询简单化</strong>。视图能简化用户的操作</p>\n<p><strong>数据安全性</strong>。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护</p>\n<h3 id=\"视图的缺点\"><a href=\"#视图的缺点\" class=\"headerlink\" title=\"视图的缺点\"></a>视图的缺点</h3><p><strong>性能</strong>。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由复杂的多表查询所定义，那么，视图的查询，需要花费一定的时间。</p>\n<p><strong>修改限制</strong>。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。</p>\n<h3 id=\"游标\"><a href=\"#游标\" class=\"headerlink\" title=\"游标\"></a>游标</h3><p>游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。用户可以通过游标，逐一获取记录，进一步处理。</p>\n<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><h3 id=\"什么是数据库事务？\"><a href=\"#什么是数据库事务？\" class=\"headerlink\" title=\"什么是数据库事务？\"></a>什么是数据库事务？</h3><p>一个不可分割的数据库操作序列，是数据库并发控制的基本单位。</p>\n<p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>\n<blockquote>\n<p>假如小明要给小红转账1000元：将小明的余额减少1000元，将小红的余额增加1000元。万一操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么成功，要么都失败。</p>\n</blockquote>\n<h3 id=\"事务的特性\"><a href=\"#事务的特性\" class=\"headerlink\" title=\"事务的特性\"></a>事务的特性</h3><ul>\n<li>atomicity（原子性） ：要么全执行，要么全都不执行；</li>\n<li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li>\n<li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li>\n<li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li>\n</ul>\n<h3 id=\"什么是脏读？幻读？不可重复读？\"><a href=\"#什么是脏读？幻读？不可重复读？\" class=\"headerlink\" title=\"什么是脏读？幻读？不可重复读？\"></a>什么是脏读？幻读？不可重复读？</h3><p>脏读：读取未提交的事务。</p>\n<p>不可重复读：多次读取同一数据，读取的数据不一致。</p>\n<p>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p>\n<h3 id=\"事务的隔离级别\"><a href=\"#事务的隔离级别\" class=\"headerlink\" title=\"事务的隔离级别\"></a>事务的隔离级别</h3><table>\n<thead>\n<tr>\n<th><strong>隔离级别</strong></th>\n<th><strong>脏读</strong></th>\n<th><strong>不可重复读</strong></th>\n<th><strong>幻读</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>READ-UNCOMMITTED</td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n</tr>\n<tr>\n<td>READ-COMMITTED</td>\n<td>×</td>\n<td>√</td>\n<td>√</td>\n</tr>\n<tr>\n<td>REPEATABLE-READ</td>\n<td>×</td>\n<td>×</td>\n<td>√</td>\n</tr>\n<tr>\n<td>SERIALIZABLE</td>\n<td>×</td>\n<td>×</td>\n<td>×</td>\n</tr>\n</tbody></table>\n<p>事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p>\n<h2 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h2><p>当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。</p>\n<h3 id=\"锁分类\"><a href=\"#锁分类\" class=\"headerlink\" title=\"锁分类\"></a>锁分类</h3><p>按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。</p>\n<p><strong>行级锁</strong> 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。</p>\n<p>特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p>\n<p><strong>表级锁</strong> 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。</p>\n<p>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。</p>\n<p><strong>页级锁</strong> 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。</p>\n<p>特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p>\n<p>从锁的类别上来讲，有共享锁和排他锁。</p>\n<p><strong>共享锁:</strong> 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p>\n<p><strong>排他锁:</strong> 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p>\n<h3 id=\"InnoDB存储引擎的锁的算法\"><a href=\"#InnoDB存储引擎的锁的算法\" class=\"headerlink\" title=\"InnoDB存储引擎的锁的算法\"></a>InnoDB存储引擎的锁的算法</h3><p>Record lock：单个行记录上的锁</p>\n<p>Gap lock：间隙锁，锁定一个范围，不包括记录本身</p>\n<p>Next-key lock：record+gap 锁定一个范围，包含记录本身</p>\n<h3 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h3><ol>\n<li><strong>Mysql死锁策略</strong>  </li>\n</ol>\n<ul>\n<li>直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置  </li>\n<li>发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑</li>\n</ul>\n<ol start=\"2\">\n<li><strong>避免死锁的常用方法</strong>  </li>\n</ol>\n<ul>\n<li>在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会  </li>\n<li>在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能  </li>\n</ul>\n<h3 id=\"什么是死锁？怎么解决？\"><a href=\"#什么是死锁？怎么解决？\" class=\"headerlink\" title=\"什么是死锁？怎么解决？\"></a>什么是死锁？怎么解决？</h3><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p>\n<p><strong>常见的避免死锁的方法</strong></p>\n<p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p>\n<p>2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p>\n<p>3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；</p>\n<p>4、在RR隔离级别下，如果两个线程同时对相同条件记录用 SELECT…FOR UPDATE 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，<strong>将隔离级别改成RC不会产生间隙锁</strong>，就可避免问题  </p>\n<p>5、在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯，如果出现死锁，可以用 <strong>show innodb status</strong> 命令来确定最后一个死锁产生的原因，返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等</p>\n<p>如果业务处理不好可以用<strong>分布式事务锁或者使用乐观锁</strong></p>\n<h3 id=\"乐观锁和悲观锁是什么？怎么实现的？\"><a href=\"#乐观锁和悲观锁是什么？怎么实现的？\" class=\"headerlink\" title=\"乐观锁和悲观锁是什么？怎么实现的？\"></a>乐观锁和悲观锁是什么？怎么实现的？</h3><p><strong>悲观锁：</strong>假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制</p>\n<p> <strong>乐观锁：</strong>假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。</p>\n<p> <strong>两种锁的使用场景</strong></p>\n<p> 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p>\n<p> 多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。</p>\n<h2 id=\"存储过程\"><a href=\"#存储过程\" class=\"headerlink\" title=\"存储过程\"></a>存储过程</h2><p>存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。</p>\n<p><strong>优点</strong></p>\n<p>1）存储过程是预编译过的，执行效率高。</p>\n<p>2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。</p>\n<p>3）安全性高，执行存储过程需要有一定权限的用户。</p>\n<p>4）存储过程可以重复使用，减少数据库开发人员的工作量。</p>\n<p><strong>缺点</strong></p>\n<p>1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。</p>\n<p>2）移植问题，数据库端代码当然是与数据库相关的。</p>\n<p>3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。</p>\n<p>4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。</p>\n<h2 id=\"触发器\"><a href=\"#触发器\" class=\"headerlink\" title=\"触发器\"></a>触发器</h2><h3 id=\"什么是触发器\"><a href=\"#什么是触发器\" class=\"headerlink\" title=\"什么是触发器\"></a>什么是触发器</h3><p>触发器是用户定义在关系表上的一类<strong>由事件驱动的特殊的存储过程</strong>。触发器是指一段代码，当触发某个事件时，自动执行这些代码。</p>\n<p><strong>使用场景</strong></p>\n<p><strong>可以通过数据库中的相关表实现级联更改。</strong></p>\n<p>实时监控某张表中的某个字段的更改而需要做出相应的处理。</p>\n<h3 id=\"MySQL中都有哪些触发器？\"><a href=\"#MySQL中都有哪些触发器？\" class=\"headerlink\" title=\"MySQL中都有哪些触发器？\"></a>MySQL中都有哪些触发器？</h3><p><strong>在MySQL数据库中有如下六种触发器：</strong></p>\n<p>Before Insert、After Insert、Before Update、After Update、Before Delete、After Delete</p>\n<h2 id=\"常用SQL语句\"><a href=\"#常用SQL语句\" class=\"headerlink\" title=\"常用SQL语句\"></a>常用SQL语句</h2><h3 id=\"SQL语句主要分为哪几类\"><a href=\"#SQL语句主要分为哪几类\" class=\"headerlink\" title=\"SQL语句主要分为哪几类\"></a>SQL语句主要分为哪几类</h3><p>数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER</p>\n<p>数据查询语言DQL（Data Query Language）SELECT</p>\n<p>数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE</p>\n<p>数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK</p>\n<h3 id=\"主键-超键-候选键-外键\"><a href=\"#主键-超键-候选键-外键\" class=\"headerlink\" title=\"主键 超键 候选键 外键\"></a>主键 超键 候选键 外键</h3><ul>\n<li><p>主键：数据库表中对<strong>存储数据对象予以唯一和完整标识</strong>的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值</p>\n</li>\n<li><p>外键：在一个表中存在<strong>的另一个表的主键称此表的外键</strong>。</p>\n</li>\n<li><p>超键：<strong>在关系中能唯一标识元组的属性集称为超键。</strong>一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。候选键和主键一定是超键。</p>\n</li>\n<li><p>候选键：是最小超键，即没有冗余元素的超键。</p>\n</li>\n</ul>\n<h3 id=\"SQL-约束有哪几种？\"><a href=\"#SQL-约束有哪几种？\" class=\"headerlink\" title=\"SQL 约束有哪几种？\"></a>SQL 约束有哪几种？</h3><p><strong>NOT NULL</strong>: 用于控制字段的内容一定不能为空。</p>\n<p><strong>UNIQUE</strong>: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</p>\n<p><strong>PRIMARY KEY</strong>: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</p>\n<p><strong>FOREIGN KEY:</strong> 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</p>\n<p><strong>CHECK</strong>: 用于控制字段的值范围。</p>\n<h3 id=\"关联查询\"><a href=\"#关联查询\" class=\"headerlink\" title=\"关联查询\"></a>关联查询</h3><p><strong>内连接</strong>（INNER JOIN）</p>\n<p><strong>外连接</strong>（LEFT JOIN/RIGHT JOIN）</p>\n<p><strong>联合查询</strong>（UNION与UNION ALL）</p>\n<p><strong>交叉连接</strong>（CROSS JOIN）</p>\n<p><strong>内连接分为三类</strong></p>\n<p>等值连接：ON A.id=B.id</p>\n<p>不等值连接：ON A.id &gt; B.id</p>\n<p>自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid</p>\n<p><strong>外连接（LEFT JOIN/RIGHT JOIN）</strong></p>\n<p>左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN</p>\n<p>右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN</p>\n<p><strong>联合查询（UNION与UNION ALL</strong>）</p>\n<p>就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并</p>\n<p>如果使用UNION ALL，不会合并重复的记录行</p>\n<p>效率 UNION ALL 高于 UNION</p>\n<h3 id=\"什么是子查询\"><a href=\"#什么是子查询\" class=\"headerlink\" title=\"什么是子查询\"></a>什么是子查询</h3><p>一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。</p>\n<h3 id=\"子查询的三种情况\"><a href=\"#子查询的三种情况\" class=\"headerlink\" title=\"子查询的三种情况\"></a>子查询的三种情况</h3><ul>\n<li><p>子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、 &gt; 等运算符</p>\n</li>\n<li><p>子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符</p>\n</li>\n<li><p>子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表</p>\n</li>\n</ul>\n<h3 id=\"in-和-exists-区别\"><a href=\"#in-和-exists-区别\" class=\"headerlink\" title=\"in 和 exists 区别\"></a>in 和 exists 区别</h3><p>mysql中的in语句是<strong>把外表和内表作hash 连接</strong>，而<strong>exists语句是对外表作loop循环，每次loop循环再对内表进行查询</strong>。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>\n<p>1、如果查询的两个表大小相当，那么用in和exists差别不大。</p>\n<p>2、如果两个表中一个表大，另一个是表小，那么IN适合于外表大而子查询表小的情况。</p>\n<p>3、如果两个表中一个表大，另一个是表小，EXISTS适合于外表小而子查询表大的情况。</p>\n<p>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；</p>\n<p>而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</p>\n<h3 id=\"drop-delete与truncate\"><a href=\"#drop-delete与truncate\" class=\"headerlink\" title=\"drop,delete与truncate\"></a>drop,delete与truncate</h3><p>drop直接删掉表，truncate、delete删除表中数据。</p>\n<p>1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。</p>\n<p>2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。</p>\n<p>3.应用范围。truncate只能对table，delete可以是table和view</p>\n<p><strong>使用场景:</strong> </p>\n<p>不再需要一张表的时候，用drop </p>\n<p>想删除部分数据行时候，用delete，并且带上where子句 </p>\n<p>保留表而删除所有数据的时候用truncate </p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>Delete</strong></th>\n<th><strong>Truncate</strong></th>\n<th><strong>Drop</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>类型</td>\n<td>属于DML</td>\n<td>属于DDL</td>\n<td>属于DDL</td>\n</tr>\n<tr>\n<td>回滚</td>\n<td>可回滚</td>\n<td>不可回滚</td>\n<td>不可回滚</td>\n</tr>\n<tr>\n<td>删除内容</td>\n<td>表结构还在，删除表的全部或者一部分数据行</td>\n<td>表结构还在，删除表中的所有数据</td>\n<td>从数据库中删除表，所有的数据行，索引和权限也会被删除</td>\n</tr>\n<tr>\n<td>删除速度</td>\n<td>删除速度慢，需要逐行删除</td>\n<td>删除速度快</td>\n<td>删除速度最快</td>\n</tr>\n</tbody></table>\n<h2 id=\"SQL优化\"><a href=\"#SQL优化\" class=\"headerlink\" title=\"SQL优化\"></a>SQL优化</h2><h3 id=\"如何定位及优化SQL语句的性能问题？\"><a href=\"#如何定位及优化SQL语句的性能问题？\" class=\"headerlink\" title=\"如何定位及优化SQL语句的性能问题？\"></a>如何定位及优化SQL语句的性能问题？</h3><p>MySQL提供了<strong>explain命令来查看语句的执行计划</strong> 。执行计划，显示数据库引擎对于SQL语句的执行的详细情况，其中包含了<strong>是否使用索引，使用什么索引，使用的索引的相关信息</strong>等。</p>\n<p><strong>select_type</strong> 每个子查询的查询类型，一些常见的查询类型。</p>\n<table>\n<thead>\n<tr>\n<th><strong>select_type</strong></th>\n<th><strong>description</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SIMPLE</td>\n<td>不包含任何子查询或union等查询</td>\n</tr>\n<tr>\n<td>PRIMARY</td>\n<td>包含子查询最外层查询就显示为 PRIMARY</td>\n</tr>\n<tr>\n<td>SUBQUERY</td>\n<td>在select或 where字句中包含的查询</td>\n</tr>\n<tr>\n<td>DERIVED</td>\n<td>from字句中包含的查询</td>\n</tr>\n<tr>\n<td>UNION</td>\n<td>出现在union后的查询语句中</td>\n</tr>\n<tr>\n<td>UNION RESULT</td>\n<td>从UNION中获取结果集，例如上文的第三个例子</td>\n</tr>\n</tbody></table>\n<p><strong>type</strong>(非常重要，可以看到有没有走索引) 访问类型</p>\n<p>ALL 扫描全表数据</p>\n<p>index 遍历索引</p>\n<p>range 索引范围查找</p>\n<p>index_subquery 在子查询中使用 ref</p>\n<p>unique_subquery 在子查询中使用 eq_ref</p>\n<p>ref_or_null 对Null进行索引的优化的 ref</p>\n<p>fulltext 使用全文索引</p>\n<p>ref 使用非唯一索引查找数据</p>\n<p>eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。</p>\n<p><strong>key</strong> 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。</p>\n<p><strong>ref</strong> 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</p>\n<p><strong>rows</strong> 返回估算的结果集数目，并不是一个准确的值。</p>\n<p><strong>extra</strong> 的信息非常丰富，常见的有：</p>\n<ul>\n<li><p>Using index 使用覆盖索引</p>\n</li>\n<li><p>Using where 使用了用where子句来过滤结果集</p>\n</li>\n<li><p>Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。</p>\n</li>\n<li><p>Using temporary 使用了临时表</p>\n</li>\n</ul>\n<h3 id=\"大表数据查询，怎么优化\"><a href=\"#大表数据查询，怎么优化\" class=\"headerlink\" title=\"大表数据查询，怎么优化\"></a>大表数据查询，怎么优化</h3><p>优化shema、sql语句+索引；</p>\n<p> 第二加缓存，memcached, redis；</p>\n<p>主从复制，读写分离；</p>\n<p>垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；</p>\n<p>水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；</p>\n<h3 id=\"超大分页怎么处理？\"><a href=\"#超大分页怎么处理？\" class=\"headerlink\" title=\"超大分页怎么处理？\"></a>超大分页怎么处理？</h3><ul>\n<li><p>数据库层面,类似于<strong>select * from table where age &gt; 20 limit 1000000,10</strong>这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为<code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</code>.<strong>这样虽然也load了一百万的数据,但是由于</strong>索引覆盖<strong>,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以</strong><code>select * from table where id &gt; 1000000 limit 10</code>效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.</p>\n</li>\n<li><p>从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.</p>\n</li>\n</ul>\n<h3 id=\"mysql-分页\"><a href=\"#mysql-分页\" class=\"headerlink\" title=\"mysql 分页\"></a>mysql 分页</h3><p>LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0</p>\n<blockquote>\n<p> mysql&gt; SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15</p>\n</blockquote>\n<h3 id=\"慢查询日志\"><a href=\"#慢查询日志\" class=\"headerlink\" title=\"慢查询日志\"></a>慢查询日志</h3><p>用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。</p>\n<p><strong>开启慢查询日志</strong></p>\n<p>配置项：slow_query_log</p>\n<p>可以使用<code>show variables like ‘slow_query_log’</code>查看是否开启，如果状态值为OFF，可以使用<code>set GLOBAL slow_query_log = on</code>来开启，它会在datadir下产生一个xxx-slow.log的文件。</p>\n<p><strong>设置临界时间</strong></p>\n<p>配置项：long_query_time</p>\n<p>查看：show VARIABLES like ‘long_query_time’，单位秒</p>\n<p>设置：set long_query_time=0.5</p>\n<p>实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉</p>\n<p>查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中</p>\n<h3 id=\"为什么要尽量设定一个主键？\"><a href=\"#为什么要尽量设定一个主键？\" class=\"headerlink\" title=\"为什么要尽量设定一个主键？\"></a>为什么要尽量设定一个主键？</h3><p>主键是数据库确保<strong>数据行在整张表唯一性</strong>的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。</p>\n<h3 id=\"主键使用自增ID还是UUID？\"><a href=\"#主键使用自增ID还是UUID？\" class=\"headerlink\" title=\"主键使用自增ID还是UUID？\"></a>主键使用自增ID还是UUID？</h3><p>自增ID，不要使用UUID。 </p>\n<p>因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，<strong>会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。</strong></p>\n<h3 id=\"字段为什么要求定义为not-null？\"><a href=\"#字段为什么要求定义为not-null？\" class=\"headerlink\" title=\"字段为什么要求定义为not null？\"></a>字段为什么要求定义为not null？</h3><p>null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。</p>\n<h3 id=\"如果要存储用户的密码散列，应该使用什么字段进行存储？\"><a href=\"#如果要存储用户的密码散列，应该使用什么字段进行存储？\" class=\"headerlink\" title=\"如果要存储用户的密码散列，应该使用什么字段进行存储？\"></a>如果要存储用户的密码散列，应该使用什么字段进行存储？</h3><p>密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。</p>\n<h3 id=\"SQL语句优化的一些方法\"><a href=\"#SQL语句优化的一些方法\" class=\"headerlink\" title=\"SQL语句优化的一些方法\"></a>SQL语句优化的一些方法</h3><ul>\n<li>尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。</li>\n<li>不使用SELECT *，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 </li>\n<li>能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 </li>\n</ul>\n<p><strong>避免索引失效</strong></p>\n<ul>\n<li>使用!= 或者 &lt;&gt; 或者或者or 来连接条件导致索引失效：需要判断索引成本</li>\n<li>筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效</li>\n<li>模糊搜索的前缀模糊导致的索引失效</li>\n<li>NOT IN、NOT EXISTS导致索引失效：需要判断回表成本</li>\n<li>尽量避免在 where 子句中对字段进行 null 值判断</li>\n</ul>\n<h2 id=\"数据库优化\"><a href=\"#数据库优化\" class=\"headerlink\" title=\"数据库优化\"></a>数据库优化</h2><ul>\n<li>优化索引、SQL 语句、分析慢查询; </li>\n<li>设计表的时候严格根据数据库的设计范式来设计数据库; </li>\n<li>使用缓存，把经常访问到的数据而且不需要经常变化的 数据放在缓存中，能节约磁盘 IO; </li>\n<li>优化硬件;采用 SSD，使用磁盘队列技术 (RAID0,RAID1,RDID5)等; </li>\n<li>采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率; </li>\n<li>垂直分表;把一些不经常读的数据放在一张表里，节约 磁盘 I/O; </li>\n<li>主从分离读写;采用主从复制把数据库的读操作和写入操作分离开来;</li>\n<li>分库分表分机器，主要的原理就是数据路由; </li>\n<li>选择合适的表引擎，参数上的优化; </li>\n<li>进行架构级别的缓存，静态化和分布式; </li>\n</ul>\n<h2 id=\"galera复制原理\"><a href=\"#galera复制原理\" class=\"headerlink\" title=\"galera复制原理\"></a>galera复制原理</h2><p>Galera采用的是多主同步复制。</p>\n<p>事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。</p>\n<p>所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。</p>\n<h2 id=\"分库分表后面临的问题\"><a href=\"#分库分表后面临的问题\" class=\"headerlink\" title=\"分库分表后面临的问题\"></a>分库分表后面临的问题</h2><p> <strong>事务支持</strong> 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。</p>\n<p> <strong>跨库join</strong> </p>\n<p>只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 </p>\n<p> <strong>跨节点的count,order by,group by以及聚合函数问题</strong> 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。</p>\n<p> <strong>数据迁移，容量规划，扩容等问题</strong> 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 </p>\n<p> <strong>ID问题</strong></p>\n<p>一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略</p>\n<p><strong>UUID 使用UUID作主键是最简单的方案</strong>，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 <strong>Twitter的分布式自增ID算法Snowflake</strong> 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。</p>\n<h2 id=\"sql语句中where与having的区别\"><a href=\"#sql语句中where与having的区别\" class=\"headerlink\" title=\"sql语句中where与having的区别\"></a>sql语句中where与having的区别</h2><p>Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。</p>\n<p>Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。</p>\n<p>在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p><strong>server层</strong></p>\n<ol>\n<li><p>连接器：管理连接，权限验证  </p>\n</li>\n<li><p>查询缓存  </p>\n</li>\n<li><p>分析器：词法、语法解析</p>\n</li>\n<li><p>优化器：生成执行计划，索引选择</p>\n</li>\n<li><p>执行器：操作引擎，返回结果</p>\n</li>\n</ol>\n<p><strong>存储引擎层</strong></p>\n<ol>\n<li>负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎</li>\n</ol>\n<h2 id=\"日志系统\"><a href=\"#日志系统\" class=\"headerlink\" title=\"日志系统\"></a>日志系统</h2><h3 id=\"redo-log（重做日志）\"><a href=\"#redo-log（重做日志）\" class=\"headerlink\" title=\"redo log（重做日志）\"></a>redo log（重做日志）</h3><ol>\n<li><p>InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）</p>\n</li>\n<li><p>在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）</p>\n</li>\n<li><p>redo log 是物理日志，记录的是在某个数据页上做了什么修改</p>\n</li>\n<li><p>redo log是循环写，空间固定会用完</p>\n</li>\n</ol>\n<h3 id=\"binlog（归档日志）\"><a href=\"#binlog（归档日志）\" class=\"headerlink\" title=\"binlog（归档日志）\"></a>binlog（归档日志）</h3><ol>\n<li><p>server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力</p>\n</li>\n<li><p>binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER、TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志</p>\n</li>\n<li><p>binlog采用追加写的模式</p>\n</li>\n<li><p><strong>用途：</strong>  </p>\n</li>\n</ol>\n<ul>\n<li>恢复：binlog日志恢复数据库数据  </li>\n<li>复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  </li>\n<li>审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击</li>\n</ul>\n<p><strong>binlog常见格式</strong></p>\n<table>\n<thead>\n<tr>\n<th>format</th>\n<th>定义</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>statement</td>\n<td>记录的是修改SQL语句</td>\n<td>日志文件小，节约IO，提高性能</td>\n<td>准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况）</td>\n</tr>\n<tr>\n<td>row</td>\n<td>记录的是每行实际数据的变更</td>\n<td>准确性强，能准确复制数据的变更</td>\n<td>日志文件大，较大的网络IO和磁盘IO</td>\n</tr>\n<tr>\n<td>mixed</td>\n<td>statement和row模式的混合</td>\n<td>准确性强，文件大小适中</td>\n<td>有可能发生主从不一致问题</td>\n</tr>\n</tbody></table>\n<h3 id=\"两段提交\"><a href=\"#两段提交\" class=\"headerlink\" title=\"两段提交\"></a>两段提交</h3><ol>\n<li><p>两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致</p>\n</li>\n<li><p>两段提交： 写入redo log处于prepare阶段 –写入bin log –提交事务处于commit状态 </p>\n</li>\n</ol>\n<ul>\n<li>时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  </li>\n<li>时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务</li>\n</ul>\n<ol start=\"3\">\n<li>bin log完整性判断:  </li>\n</ol>\n<ul>\n<li>statement格式最后有commit  </li>\n<li>row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）</li>\n</ul>\n<h3 id=\"undo-log\"><a href=\"#undo-log\" class=\"headerlink\" title=\"undo log\"></a>undo log</h3><ol>\n<li><p>undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</p>\n</li>\n<li><p>undo log 作用  </p>\n</li>\n</ol>\n<ul>\n<li>提供回滚  </li>\n<li>多版本并发控制（MVCC）</li>\n</ul>\n<h3 id=\"Mysql抖动\"><a href=\"#Mysql抖动\" class=\"headerlink\" title=\"Mysql抖动\"></a>Mysql抖动</h3><p>当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。</p>\n<p><strong>flush场景</strong></p>\n<ol>\n<li>InnoDB 的 redo log 写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘</li>\n<li>系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是”脏页”，就要先将脏页写到磁盘</li>\n<li>MySQL 认为系统”空闲”的时候，会flush脏页</li>\n<li>MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上</li>\n</ol>\n<p>InnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度</p>\n<h2 id=\"MyISAM索引与InnoDB索引的区别\"><a href=\"#MyISAM索引与InnoDB索引的区别\" class=\"headerlink\" title=\"MyISAM索引与InnoDB索引的区别\"></a>MyISAM索引与InnoDB索引的区别</h2><p>InnoDB索引是<strong>聚簇索引</strong>，MyISAM索引是<strong>非聚簇索引</strong>。</p>\n<p>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p>\n<p>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效</p>\n<p><strong>其他</strong></p>\n<ul>\n<li><strong>InnoDB支持事务，MyISAM不支持</strong></li>\n<li>MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用</li>\n<li><strong>InnoDB支持外键，MyISAM不支持</strong></li>\n<li>InnoDB中不保存表的行数，如<code>select count(*) from table</code>时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当<code>count(*)</code>语句包含where条件时MyISAM也需要扫描整个表</li>\n<li>对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引</li>\n<li>清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表</li>\n<li><strong>InnoDB支持行锁</strong>（某些情况下还是锁整表，如 <code>update table set a=1 where user like &#39;%lee%&#39;</code></li>\n</ul>\n<h2 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。</p>\n<p>通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。</p>\n<p>索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。</p>\n<h3 id=\"优缺点\"><a href=\"#优缺点\" class=\"headerlink\" title=\"优缺点\"></a>优缺点</h3><p><strong>索引的优点</strong></p>\n<ul>\n<li>加快数据的检索速度。</li>\n</ul>\n<p><strong>索引的缺点</strong></p>\n<ul>\n<li>创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；</li>\n<li>索引需要占物理空间。</li>\n</ul>\n<h3 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a>使用场景</h3><p><strong>where</strong></p>\n<p><strong>order by</strong></p>\n<p>使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据<strong>使用磁盘临时文件完成外部排序或者在内存中完成排序</strong>。具体取决于排序所需的内存和参数sort_buffer_size。</p>\n<p>如果我们对该字段建立索引，由于索引本身是有序的，因此直接<strong>按照索引的顺序和映射关系逐条取出数据即可</strong>。</p>\n<p><strong>join</strong></p>\n<p>对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）</p>\n<p><strong>覆盖索引</strong></p>\n<p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p>\n<p>如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。</p>\n<blockquote>\n<p>尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。</p>\n</blockquote>\n<h3 id=\"索引类型\"><a href=\"#索引类型\" class=\"headerlink\" title=\"索引类型\"></a>索引类型</h3><p><strong>主键索引</strong>： 不允许重复，不允许为NULL，一个表只能有一个主键。</p>\n<p><strong>唯一索引</strong>：不允许重复，允许为NULL，一个表允许多唯一索引。</p>\n<p><strong>普通索引</strong>：基本的索引类型，没有唯一性的限制，允许为NULL值。</p>\n<p><strong>全文索引</strong>： 是目前搜索引擎使用的一种关键技术。</p>\n<h3 id=\"索引的数据结构\"><a href=\"#索引的数据结构\" class=\"headerlink\" title=\"索引的数据结构\"></a>索引的数据结构</h3><p>和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。</p>\n<p>InnoDB存储引擎的默认索引实现为：B+树索引。</p>\n<p>哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。</p>\n<h3 id=\"索引设计的原则\"><a href=\"#索引设计的原则\" class=\"headerlink\" title=\"索引设计的原则\"></a>索引设计的原则</h3><p><strong>适合索引的列</strong>是出现在where子句中的列，或者连接子句中指定的列</p>\n<p><strong>使用短索引</strong>，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间</p>\n<p><strong>不要过度索引</strong>。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。</p>\n<h3 id=\"创建索引的原则\"><a href=\"#创建索引的原则\" class=\"headerlink\" title=\"创建索引的原则\"></a>创建索引的原则</h3><p>1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立<code>(a,b,c,d)</code>顺序的索引，d是用不到索引的，如果建立<code>(a,b,d,c)</code>的索引则都可以用到，a,b,d的顺序可以任意调整。</p>\n<p>2）较频繁作为查询条件的字段才去创建索引</p>\n<p>3）更新频繁字段不适合创建索引</p>\n<p>4）若是不能有效区分数据的列不适合做索引列（如性别，男女未知，最多也就三种，区分度实在太低），选择基数较大的列做索引</p>\n<p>5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。</p>\n<p>6）定义有外键的数据列一定要建立索引。</p>\n<h3 id=\"创建索引注意点\"><a href=\"#创建索引注意点\" class=\"headerlink\" title=\"创建索引注意点\"></a>创建索引注意点</h3><p><strong>非空字段：</strong>应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</p>\n<p><strong>取值离散大的字段：</strong>（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值</p>\n<p><strong>索引字段越小越好</strong>：数据库的数据存储以页为单位，一页存储的数据越多一次IO操作获取的数据越大，效率越高。</p>\n<h3 id=\"使用索引查询一定能提高查询的性能吗\"><a href=\"#使用索引查询一定能提高查询的性能吗\" class=\"headerlink\" title=\"使用索引查询一定能提高查询的性能吗\"></a>使用索引查询一定能提高查询的性能吗</h3><p><strong>通常，通过索引查询数据比全表扫描要快。</strong>但是我们也必须注意到它的代价。</p>\n<p><strong>索引需要空间来存储，也需要定期维护，</strong> 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况:</p>\n<ul>\n<li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%</li>\n<li><strong>基于非唯一性索引的检索（？？？）</strong></li>\n</ul>\n<h3 id=\"百万级别或以上的数据如何删除\"><a href=\"#百万级别或以上的数据如何删除\" class=\"headerlink\" title=\"百万级别或以上的数据如何删除\"></a>百万级别或以上的数据如何删除</h3><blockquote>\n<p>索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的。</p>\n</blockquote>\n<p>所以删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）</p>\n<p>然后删除其中无用数据（此过程需要不到两分钟）</p>\n<p>删除完成后重新创建索引（此时数据较少了，创建索引也非常快，约十分钟左右。）</p>\n<h3 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h3><p>语法：<code>index(field(10))</code>，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。</p>\n<p>前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。</p>\n<p>实操的难度：<strong>在于前缀截取的长度。</strong></p>\n<p>我们可以利用<code>select count(*)/count(distinct left(password,prefixLen));</code>，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）</p>\n<h3 id=\"B-Tree索引的性能分析\"><a href=\"#B-Tree索引的性能分析\" class=\"headerlink\" title=\"B-/+Tree索引的性能分析\"></a>B-/+Tree索引的性能分析</h3><p> B-Tree：根据B-Tree的定义，可知检索一次最多需要访问h个节点，利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，保证一个节点存储在一个页里。</p>\n<p>B+Tree：B+Tree更适合外存索引，由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能</p>\n<h3 id=\"B-Tree和B-Tree的区别\"><a href=\"#B-Tree和B-Tree的区别\" class=\"headerlink\" title=\"B-Tree和B+Tree的区别\"></a>B-Tree和B+Tree的区别</h3><p>在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。</p>\n<p>B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。</p>\n<h3 id=\"使用B树的好处\"><a href=\"#使用B树的好处\" class=\"headerlink\" title=\"使用B树的好处\"></a>使用B树的好处</h3><p>B树可以在<strong>内部节点同时存储键和值</strong>，因此，<strong>把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。</strong>这种特性使得B树在特定数据重复多次查询的场景中更加高效。</p>\n<h3 id=\"使用B-树的好处\"><a href=\"#使用B-树的好处\" class=\"headerlink\" title=\"使用B+树的好处\"></a>使用B+树的好处</h3><p>由于<strong>B+树的内部节点只存放键</strong>，不存放值，因此，<strong>一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围</strong>。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，<strong>B+树只需要使用<code>O(logN)</code>时间找到最小的一个节点，然后通过链进行<code>O(N)</code>的顺序遍历即可。</strong>而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间</p>\n<h3 id=\"Hash索引和B-树优劣\"><a href=\"#Hash索引和B-树优劣\" class=\"headerlink\" title=\"Hash索引和B+树优劣\"></a>Hash索引和B+树优劣</h3><p>首先要知道Hash索引和B+树索引的底层实现原理：</p>\n<p><strong>hash索引底层就是hash表</strong>，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是<strong>多路平衡查找树</strong>。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。</p>\n<p>那么可以看出他们有以下的不同：</p>\n<ul>\n<li>hash索引进行<strong>等值查询更快（一般情况下），但是却无法进行范围查询</strong>。</li>\n</ul>\n<p>因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。</p>\n<ul>\n<li><p>hash索引<strong>不支持使用索引进行排序</strong>，原理同上。</p>\n</li>\n<li><p>hash索引不<strong>支持模糊查询以及多列索引的最左前缀匹配。</strong>原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。</p>\n</li>\n<li><p>hash索引任何时候都<strong>避免不了回表查询数据</strong>，而B+树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。</p>\n</li>\n<li><p>hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。</p>\n</li>\n</ul>\n<p>因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。</p>\n<h3 id=\"使用B-树而不是B树\"><a href=\"#使用B-树而不是B树\" class=\"headerlink\" title=\"使用B+树而不是B树\"></a>使用B+树而不是B树</h3><ul>\n<li><p><strong>B树只适合随机检索，而B+树同时支持随机检索和顺序检索</strong>；</p>\n</li>\n<li><p><strong>B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。</strong>一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；</p>\n</li>\n<li><p><strong>B+树的查询效率更加稳定。</strong>B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。</p>\n</li>\n<li><p><strong>B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。</strong>B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。</p>\n</li>\n<li><p><strong>增删文件（节点）时，效率更高。</strong>因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。</p>\n</li>\n</ul>\n<h3 id=\"聚簇索引\"><a href=\"#聚簇索引\" class=\"headerlink\" title=\"聚簇索引\"></a>聚簇索引</h3><p><strong>聚簇索引</strong>：将数据存储与索引放到了一块，找到索引也就找到了数据</p>\n<p><strong>非聚簇索引</strong>：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，因此索引不在key buffer命中时，速度慢。</p>\n<p><strong>澄清一个概念：</strong>innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值</p>\n<h3 id=\"非聚簇索引一定会回表查询吗？\"><a href=\"#非聚簇索引一定会回表查询吗？\" class=\"headerlink\" title=\"非聚簇索引一定会回表查询吗？\"></a>非聚簇索引一定会回表查询吗？</h3><p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。</p>\n<blockquote>\n<p>举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age &lt; 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。</p>\n</blockquote>\n<h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a><strong>联合索引</strong></h3><p>MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。</p>\n<h3 id=\"为什么需要注意联合索引中的顺序？\"><a href=\"#为什么需要注意联合索引中的顺序？\" class=\"headerlink\" title=\"为什么需要注意联合索引中的顺序？\"></a><strong>为什么需要注意联合索引中的顺序？</strong></h3><p>MySQL使用索引时需要索引有序.</p>\n<p>一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p>\n<h2 id=\"数据库范式\"><a href=\"#数据库范式\" class=\"headerlink\" title=\"数据库范式\"></a>数据库范式</h2><p><strong>第一范式：</strong>强调的是列的原子性，即列不能够再分成其他几列。</p>\n<p> <strong>第二范式</strong>：首先是 1NF，另外包含两部分内容，<strong>一是表必须有一个主键</strong>；二是没有包含在主键中的<strong>列必须完全依赖于主键，而不能只依赖于主键的一部分</strong>。否则可拆表。</p>\n<p> <strong>第三范式</strong>：在1NF基础上，<strong>任何非主属性不依赖于其它非主属性</strong>[在2NF基础上消除传递依赖]。</p>\n<h2 id=\"mysql有关权限的表\"><a href=\"#mysql有关权限的表\" class=\"headerlink\" title=\"mysql有关权限的表\"></a>mysql有关权限的表</h2><p>MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别<strong>user，db，table_priv，columns_priv和host</strong>。下面分别介绍一下这些表的结构和内容：</p>\n<p>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</p>\n<p>db权限表：记录各个帐号在各个数据库上的操作权限。</p>\n<p>table_priv权限表：记录数据表级的操作权限。</p>\n<p>columns_priv权限表：记录数据列级的操作权限。</p>\n<p>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。</p>\n<h2 id=\"视图\"><a href=\"#视图\" class=\"headerlink\" title=\"视图\"></a>视图</h2><p>视图是虚拟的表，视图只包含使用时动态检索数据的查询;不包含任何列或数据。</p>\n<p>使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;</p>\n<p>视图创建后，可以使用与表相同的方式利用它们。</p>\n<blockquote>\n<p>视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。</p>\n</blockquote>\n<h3 id=\"视图有哪些特点？\"><a href=\"#视图有哪些特点？\" class=\"headerlink\" title=\"视图有哪些特点？\"></a>视图有哪些特点？</h3><ul>\n<li>视图是由基本表（实表）产生的表（虚表）。</li>\n<li>视图的建立和删除不影响基本表。</li>\n<li>对视图内容的更新（添加，删除和修改）直接影响基本表。</li>\n<li>视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。</li>\n<li>当视图来自多个基本表时，不允许添加和删除数据。</li>\n</ul>\n<h3 id=\"视图的使用场景有哪些？\"><a href=\"#视图的使用场景有哪些？\" class=\"headerlink\" title=\"视图的使用场景有哪些？\"></a>视图的使用场景有哪些？</h3><p>视图根本用途：简化sql查询，提高开发效率。</p>\n<p><strong>常见使用场景：</strong></p>\n<p>重用SQL语句；</p>\n<p><strong>简化复杂的SQL操作</strong>。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</p>\n<p><strong>保护数据</strong>。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</p>\n<p><strong>更改数据格式和表示</strong>。视图可返回与底层表的表示和格式不同的数据。</p>\n<h3 id=\"视图的优点\"><a href=\"#视图的优点\" class=\"headerlink\" title=\"视图的优点\"></a>视图的优点</h3><p><strong>查询简单化</strong>。视图能简化用户的操作</p>\n<p><strong>数据安全性</strong>。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护</p>\n<h3 id=\"视图的缺点\"><a href=\"#视图的缺点\" class=\"headerlink\" title=\"视图的缺点\"></a>视图的缺点</h3><p><strong>性能</strong>。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由复杂的多表查询所定义，那么，视图的查询，需要花费一定的时间。</p>\n<p><strong>修改限制</strong>。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。</p>\n<h3 id=\"游标\"><a href=\"#游标\" class=\"headerlink\" title=\"游标\"></a>游标</h3><p>游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。用户可以通过游标，逐一获取记录，进一步处理。</p>\n<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><h3 id=\"什么是数据库事务？\"><a href=\"#什么是数据库事务？\" class=\"headerlink\" title=\"什么是数据库事务？\"></a>什么是数据库事务？</h3><p>一个不可分割的数据库操作序列，是数据库并发控制的基本单位。</p>\n<p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>\n<blockquote>\n<p>假如小明要给小红转账1000元：将小明的余额减少1000元，将小红的余额增加1000元。万一操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么成功，要么都失败。</p>\n</blockquote>\n<h3 id=\"事务的特性\"><a href=\"#事务的特性\" class=\"headerlink\" title=\"事务的特性\"></a>事务的特性</h3><ul>\n<li>atomicity（原子性） ：要么全执行，要么全都不执行；</li>\n<li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li>\n<li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li>\n<li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li>\n</ul>\n<h3 id=\"什么是脏读？幻读？不可重复读？\"><a href=\"#什么是脏读？幻读？不可重复读？\" class=\"headerlink\" title=\"什么是脏读？幻读？不可重复读？\"></a>什么是脏读？幻读？不可重复读？</h3><p>脏读：读取未提交的事务。</p>\n<p>不可重复读：多次读取同一数据，读取的数据不一致。</p>\n<p>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p>\n<h3 id=\"事务的隔离级别\"><a href=\"#事务的隔离级别\" class=\"headerlink\" title=\"事务的隔离级别\"></a>事务的隔离级别</h3><table>\n<thead>\n<tr>\n<th><strong>隔离级别</strong></th>\n<th><strong>脏读</strong></th>\n<th><strong>不可重复读</strong></th>\n<th><strong>幻读</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>READ-UNCOMMITTED</td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n</tr>\n<tr>\n<td>READ-COMMITTED</td>\n<td>×</td>\n<td>√</td>\n<td>√</td>\n</tr>\n<tr>\n<td>REPEATABLE-READ</td>\n<td>×</td>\n<td>×</td>\n<td>√</td>\n</tr>\n<tr>\n<td>SERIALIZABLE</td>\n<td>×</td>\n<td>×</td>\n<td>×</td>\n</tr>\n</tbody></table>\n<p>事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p>\n<h2 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h2><p>当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。</p>\n<h3 id=\"锁分类\"><a href=\"#锁分类\" class=\"headerlink\" title=\"锁分类\"></a>锁分类</h3><p>按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。</p>\n<p><strong>行级锁</strong> 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。</p>\n<p>特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p>\n<p><strong>表级锁</strong> 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。</p>\n<p>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。</p>\n<p><strong>页级锁</strong> 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。</p>\n<p>特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p>\n<p>从锁的类别上来讲，有共享锁和排他锁。</p>\n<p><strong>共享锁:</strong> 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p>\n<p><strong>排他锁:</strong> 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p>\n<h3 id=\"InnoDB存储引擎的锁的算法\"><a href=\"#InnoDB存储引擎的锁的算法\" class=\"headerlink\" title=\"InnoDB存储引擎的锁的算法\"></a>InnoDB存储引擎的锁的算法</h3><p>Record lock：单个行记录上的锁</p>\n<p>Gap lock：间隙锁，锁定一个范围，不包括记录本身</p>\n<p>Next-key lock：record+gap 锁定一个范围，包含记录本身</p>\n<h3 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h3><ol>\n<li><strong>Mysql死锁策略</strong>  </li>\n</ol>\n<ul>\n<li>直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置  </li>\n<li>发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑</li>\n</ul>\n<ol start=\"2\">\n<li><strong>避免死锁的常用方法</strong>  </li>\n</ol>\n<ul>\n<li>在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会  </li>\n<li>在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能  </li>\n</ul>\n<h3 id=\"什么是死锁？怎么解决？\"><a href=\"#什么是死锁？怎么解决？\" class=\"headerlink\" title=\"什么是死锁？怎么解决？\"></a>什么是死锁？怎么解决？</h3><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p>\n<p><strong>常见的避免死锁的方法</strong></p>\n<p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p>\n<p>2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p>\n<p>3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；</p>\n<p>4、在RR隔离级别下，如果两个线程同时对相同条件记录用 SELECT…FOR UPDATE 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，<strong>将隔离级别改成RC不会产生间隙锁</strong>，就可避免问题  </p>\n<p>5、在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯，如果出现死锁，可以用 <strong>show innodb status</strong> 命令来确定最后一个死锁产生的原因，返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等</p>\n<p>如果业务处理不好可以用<strong>分布式事务锁或者使用乐观锁</strong></p>\n<h3 id=\"乐观锁和悲观锁是什么？怎么实现的？\"><a href=\"#乐观锁和悲观锁是什么？怎么实现的？\" class=\"headerlink\" title=\"乐观锁和悲观锁是什么？怎么实现的？\"></a>乐观锁和悲观锁是什么？怎么实现的？</h3><p><strong>悲观锁：</strong>假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制</p>\n<p> <strong>乐观锁：</strong>假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。</p>\n<p> <strong>两种锁的使用场景</strong></p>\n<p> 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p>\n<p> 多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。</p>\n<h2 id=\"存储过程\"><a href=\"#存储过程\" class=\"headerlink\" title=\"存储过程\"></a>存储过程</h2><p>存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。</p>\n<p><strong>优点</strong></p>\n<p>1）存储过程是预编译过的，执行效率高。</p>\n<p>2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。</p>\n<p>3）安全性高，执行存储过程需要有一定权限的用户。</p>\n<p>4）存储过程可以重复使用，减少数据库开发人员的工作量。</p>\n<p><strong>缺点</strong></p>\n<p>1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。</p>\n<p>2）移植问题，数据库端代码当然是与数据库相关的。</p>\n<p>3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。</p>\n<p>4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。</p>\n<h2 id=\"触发器\"><a href=\"#触发器\" class=\"headerlink\" title=\"触发器\"></a>触发器</h2><h3 id=\"什么是触发器\"><a href=\"#什么是触发器\" class=\"headerlink\" title=\"什么是触发器\"></a>什么是触发器</h3><p>触发器是用户定义在关系表上的一类<strong>由事件驱动的特殊的存储过程</strong>。触发器是指一段代码，当触发某个事件时，自动执行这些代码。</p>\n<p><strong>使用场景</strong></p>\n<p><strong>可以通过数据库中的相关表实现级联更改。</strong></p>\n<p>实时监控某张表中的某个字段的更改而需要做出相应的处理。</p>\n<h3 id=\"MySQL中都有哪些触发器？\"><a href=\"#MySQL中都有哪些触发器？\" class=\"headerlink\" title=\"MySQL中都有哪些触发器？\"></a>MySQL中都有哪些触发器？</h3><p><strong>在MySQL数据库中有如下六种触发器：</strong></p>\n<p>Before Insert、After Insert、Before Update、After Update、Before Delete、After Delete</p>\n<h2 id=\"常用SQL语句\"><a href=\"#常用SQL语句\" class=\"headerlink\" title=\"常用SQL语句\"></a>常用SQL语句</h2><h3 id=\"SQL语句主要分为哪几类\"><a href=\"#SQL语句主要分为哪几类\" class=\"headerlink\" title=\"SQL语句主要分为哪几类\"></a>SQL语句主要分为哪几类</h3><p>数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER</p>\n<p>数据查询语言DQL（Data Query Language）SELECT</p>\n<p>数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE</p>\n<p>数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK</p>\n<h3 id=\"主键-超键-候选键-外键\"><a href=\"#主键-超键-候选键-外键\" class=\"headerlink\" title=\"主键 超键 候选键 外键\"></a>主键 超键 候选键 外键</h3><ul>\n<li><p>主键：数据库表中对<strong>存储数据对象予以唯一和完整标识</strong>的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值</p>\n</li>\n<li><p>外键：在一个表中存在<strong>的另一个表的主键称此表的外键</strong>。</p>\n</li>\n<li><p>超键：<strong>在关系中能唯一标识元组的属性集称为超键。</strong>一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。候选键和主键一定是超键。</p>\n</li>\n<li><p>候选键：是最小超键，即没有冗余元素的超键。</p>\n</li>\n</ul>\n<h3 id=\"SQL-约束有哪几种？\"><a href=\"#SQL-约束有哪几种？\" class=\"headerlink\" title=\"SQL 约束有哪几种？\"></a>SQL 约束有哪几种？</h3><p><strong>NOT NULL</strong>: 用于控制字段的内容一定不能为空。</p>\n<p><strong>UNIQUE</strong>: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</p>\n<p><strong>PRIMARY KEY</strong>: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</p>\n<p><strong>FOREIGN KEY:</strong> 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</p>\n<p><strong>CHECK</strong>: 用于控制字段的值范围。</p>\n<h3 id=\"关联查询\"><a href=\"#关联查询\" class=\"headerlink\" title=\"关联查询\"></a>关联查询</h3><p><strong>内连接</strong>（INNER JOIN）</p>\n<p><strong>外连接</strong>（LEFT JOIN/RIGHT JOIN）</p>\n<p><strong>联合查询</strong>（UNION与UNION ALL）</p>\n<p><strong>交叉连接</strong>（CROSS JOIN）</p>\n<p><strong>内连接分为三类</strong></p>\n<p>等值连接：ON A.id=B.id</p>\n<p>不等值连接：ON A.id &gt; B.id</p>\n<p>自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid</p>\n<p><strong>外连接（LEFT JOIN/RIGHT JOIN）</strong></p>\n<p>左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN</p>\n<p>右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN</p>\n<p><strong>联合查询（UNION与UNION ALL</strong>）</p>\n<p>就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并</p>\n<p>如果使用UNION ALL，不会合并重复的记录行</p>\n<p>效率 UNION ALL 高于 UNION</p>\n<h3 id=\"什么是子查询\"><a href=\"#什么是子查询\" class=\"headerlink\" title=\"什么是子查询\"></a>什么是子查询</h3><p>一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。</p>\n<h3 id=\"子查询的三种情况\"><a href=\"#子查询的三种情况\" class=\"headerlink\" title=\"子查询的三种情况\"></a>子查询的三种情况</h3><ul>\n<li><p>子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、 &gt; 等运算符</p>\n</li>\n<li><p>子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符</p>\n</li>\n<li><p>子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表</p>\n</li>\n</ul>\n<h3 id=\"in-和-exists-区别\"><a href=\"#in-和-exists-区别\" class=\"headerlink\" title=\"in 和 exists 区别\"></a>in 和 exists 区别</h3><p>mysql中的in语句是<strong>把外表和内表作hash 连接</strong>，而<strong>exists语句是对外表作loop循环，每次loop循环再对内表进行查询</strong>。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>\n<p>1、如果查询的两个表大小相当，那么用in和exists差别不大。</p>\n<p>2、如果两个表中一个表大，另一个是表小，那么IN适合于外表大而子查询表小的情况。</p>\n<p>3、如果两个表中一个表大，另一个是表小，EXISTS适合于外表小而子查询表大的情况。</p>\n<p>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；</p>\n<p>而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</p>\n<h3 id=\"drop-delete与truncate\"><a href=\"#drop-delete与truncate\" class=\"headerlink\" title=\"drop,delete与truncate\"></a>drop,delete与truncate</h3><p>drop直接删掉表，truncate、delete删除表中数据。</p>\n<p>1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。</p>\n<p>2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。</p>\n<p>3.应用范围。truncate只能对table，delete可以是table和view</p>\n<p><strong>使用场景:</strong> </p>\n<p>不再需要一张表的时候，用drop </p>\n<p>想删除部分数据行时候，用delete，并且带上where子句 </p>\n<p>保留表而删除所有数据的时候用truncate </p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th><strong>Delete</strong></th>\n<th><strong>Truncate</strong></th>\n<th><strong>Drop</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>类型</td>\n<td>属于DML</td>\n<td>属于DDL</td>\n<td>属于DDL</td>\n</tr>\n<tr>\n<td>回滚</td>\n<td>可回滚</td>\n<td>不可回滚</td>\n<td>不可回滚</td>\n</tr>\n<tr>\n<td>删除内容</td>\n<td>表结构还在，删除表的全部或者一部分数据行</td>\n<td>表结构还在，删除表中的所有数据</td>\n<td>从数据库中删除表，所有的数据行，索引和权限也会被删除</td>\n</tr>\n<tr>\n<td>删除速度</td>\n<td>删除速度慢，需要逐行删除</td>\n<td>删除速度快</td>\n<td>删除速度最快</td>\n</tr>\n</tbody></table>\n<h2 id=\"SQL优化\"><a href=\"#SQL优化\" class=\"headerlink\" title=\"SQL优化\"></a>SQL优化</h2><h3 id=\"如何定位及优化SQL语句的性能问题？\"><a href=\"#如何定位及优化SQL语句的性能问题？\" class=\"headerlink\" title=\"如何定位及优化SQL语句的性能问题？\"></a>如何定位及优化SQL语句的性能问题？</h3><p>MySQL提供了<strong>explain命令来查看语句的执行计划</strong> 。执行计划，显示数据库引擎对于SQL语句的执行的详细情况，其中包含了<strong>是否使用索引，使用什么索引，使用的索引的相关信息</strong>等。</p>\n<p><strong>select_type</strong> 每个子查询的查询类型，一些常见的查询类型。</p>\n<table>\n<thead>\n<tr>\n<th><strong>select_type</strong></th>\n<th><strong>description</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SIMPLE</td>\n<td>不包含任何子查询或union等查询</td>\n</tr>\n<tr>\n<td>PRIMARY</td>\n<td>包含子查询最外层查询就显示为 PRIMARY</td>\n</tr>\n<tr>\n<td>SUBQUERY</td>\n<td>在select或 where字句中包含的查询</td>\n</tr>\n<tr>\n<td>DERIVED</td>\n<td>from字句中包含的查询</td>\n</tr>\n<tr>\n<td>UNION</td>\n<td>出现在union后的查询语句中</td>\n</tr>\n<tr>\n<td>UNION RESULT</td>\n<td>从UNION中获取结果集，例如上文的第三个例子</td>\n</tr>\n</tbody></table>\n<p><strong>type</strong>(非常重要，可以看到有没有走索引) 访问类型</p>\n<p>ALL 扫描全表数据</p>\n<p>index 遍历索引</p>\n<p>range 索引范围查找</p>\n<p>index_subquery 在子查询中使用 ref</p>\n<p>unique_subquery 在子查询中使用 eq_ref</p>\n<p>ref_or_null 对Null进行索引的优化的 ref</p>\n<p>fulltext 使用全文索引</p>\n<p>ref 使用非唯一索引查找数据</p>\n<p>eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。</p>\n<p><strong>key</strong> 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。</p>\n<p><strong>ref</strong> 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</p>\n<p><strong>rows</strong> 返回估算的结果集数目，并不是一个准确的值。</p>\n<p><strong>extra</strong> 的信息非常丰富，常见的有：</p>\n<ul>\n<li><p>Using index 使用覆盖索引</p>\n</li>\n<li><p>Using where 使用了用where子句来过滤结果集</p>\n</li>\n<li><p>Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。</p>\n</li>\n<li><p>Using temporary 使用了临时表</p>\n</li>\n</ul>\n<h3 id=\"大表数据查询，怎么优化\"><a href=\"#大表数据查询，怎么优化\" class=\"headerlink\" title=\"大表数据查询，怎么优化\"></a>大表数据查询，怎么优化</h3><p>优化shema、sql语句+索引；</p>\n<p> 第二加缓存，memcached, redis；</p>\n<p>主从复制，读写分离；</p>\n<p>垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；</p>\n<p>水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；</p>\n<h3 id=\"超大分页怎么处理？\"><a href=\"#超大分页怎么处理？\" class=\"headerlink\" title=\"超大分页怎么处理？\"></a>超大分页怎么处理？</h3><ul>\n<li><p>数据库层面,类似于<strong>select * from table where age &gt; 20 limit 1000000,10</strong>这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为<code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</code>.<strong>这样虽然也load了一百万的数据,但是由于</strong>索引覆盖<strong>,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以</strong><code>select * from table where id &gt; 1000000 limit 10</code>效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.</p>\n</li>\n<li><p>从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.</p>\n</li>\n</ul>\n<h3 id=\"mysql-分页\"><a href=\"#mysql-分页\" class=\"headerlink\" title=\"mysql 分页\"></a>mysql 分页</h3><p>LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0</p>\n<blockquote>\n<p> mysql&gt; SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15</p>\n</blockquote>\n<h3 id=\"慢查询日志\"><a href=\"#慢查询日志\" class=\"headerlink\" title=\"慢查询日志\"></a>慢查询日志</h3><p>用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。</p>\n<p><strong>开启慢查询日志</strong></p>\n<p>配置项：slow_query_log</p>\n<p>可以使用<code>show variables like ‘slow_query_log’</code>查看是否开启，如果状态值为OFF，可以使用<code>set GLOBAL slow_query_log = on</code>来开启，它会在datadir下产生一个xxx-slow.log的文件。</p>\n<p><strong>设置临界时间</strong></p>\n<p>配置项：long_query_time</p>\n<p>查看：show VARIABLES like ‘long_query_time’，单位秒</p>\n<p>设置：set long_query_time=0.5</p>\n<p>实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉</p>\n<p>查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中</p>\n<h3 id=\"为什么要尽量设定一个主键？\"><a href=\"#为什么要尽量设定一个主键？\" class=\"headerlink\" title=\"为什么要尽量设定一个主键？\"></a>为什么要尽量设定一个主键？</h3><p>主键是数据库确保<strong>数据行在整张表唯一性</strong>的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。</p>\n<h3 id=\"主键使用自增ID还是UUID？\"><a href=\"#主键使用自增ID还是UUID？\" class=\"headerlink\" title=\"主键使用自增ID还是UUID？\"></a>主键使用自增ID还是UUID？</h3><p>自增ID，不要使用UUID。 </p>\n<p>因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，<strong>会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。</strong></p>\n<h3 id=\"字段为什么要求定义为not-null？\"><a href=\"#字段为什么要求定义为not-null？\" class=\"headerlink\" title=\"字段为什么要求定义为not null？\"></a>字段为什么要求定义为not null？</h3><p>null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。</p>\n<h3 id=\"如果要存储用户的密码散列，应该使用什么字段进行存储？\"><a href=\"#如果要存储用户的密码散列，应该使用什么字段进行存储？\" class=\"headerlink\" title=\"如果要存储用户的密码散列，应该使用什么字段进行存储？\"></a>如果要存储用户的密码散列，应该使用什么字段进行存储？</h3><p>密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。</p>\n<h3 id=\"SQL语句优化的一些方法\"><a href=\"#SQL语句优化的一些方法\" class=\"headerlink\" title=\"SQL语句优化的一些方法\"></a>SQL语句优化的一些方法</h3><ul>\n<li>尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。</li>\n<li>不使用SELECT *，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 </li>\n<li>能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 </li>\n</ul>\n<p><strong>避免索引失效</strong></p>\n<ul>\n<li>使用!= 或者 &lt;&gt; 或者或者or 来连接条件导致索引失效：需要判断索引成本</li>\n<li>筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效</li>\n<li>模糊搜索的前缀模糊导致的索引失效</li>\n<li>NOT IN、NOT EXISTS导致索引失效：需要判断回表成本</li>\n<li>尽量避免在 where 子句中对字段进行 null 值判断</li>\n</ul>\n<h2 id=\"数据库优化\"><a href=\"#数据库优化\" class=\"headerlink\" title=\"数据库优化\"></a>数据库优化</h2><ul>\n<li>优化索引、SQL 语句、分析慢查询; </li>\n<li>设计表的时候严格根据数据库的设计范式来设计数据库; </li>\n<li>使用缓存，把经常访问到的数据而且不需要经常变化的 数据放在缓存中，能节约磁盘 IO; </li>\n<li>优化硬件;采用 SSD，使用磁盘队列技术 (RAID0,RAID1,RDID5)等; </li>\n<li>采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率; </li>\n<li>垂直分表;把一些不经常读的数据放在一张表里，节约 磁盘 I/O; </li>\n<li>主从分离读写;采用主从复制把数据库的读操作和写入操作分离开来;</li>\n<li>分库分表分机器，主要的原理就是数据路由; </li>\n<li>选择合适的表引擎，参数上的优化; </li>\n<li>进行架构级别的缓存，静态化和分布式; </li>\n</ul>\n<h2 id=\"galera复制原理\"><a href=\"#galera复制原理\" class=\"headerlink\" title=\"galera复制原理\"></a>galera复制原理</h2><p>Galera采用的是多主同步复制。</p>\n<p>事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。</p>\n<p>所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。</p>\n<h2 id=\"分库分表后面临的问题\"><a href=\"#分库分表后面临的问题\" class=\"headerlink\" title=\"分库分表后面临的问题\"></a>分库分表后面临的问题</h2><p> <strong>事务支持</strong> 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。</p>\n<p> <strong>跨库join</strong> </p>\n<p>只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 </p>\n<p> <strong>跨节点的count,order by,group by以及聚合函数问题</strong> 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。</p>\n<p> <strong>数据迁移，容量规划，扩容等问题</strong> 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 </p>\n<p> <strong>ID问题</strong></p>\n<p>一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略</p>\n<p><strong>UUID 使用UUID作主键是最简单的方案</strong>，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 <strong>Twitter的分布式自增ID算法Snowflake</strong> 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。</p>\n<h2 id=\"sql语句中where与having的区别\"><a href=\"#sql语句中where与having的区别\" class=\"headerlink\" title=\"sql语句中where与having的区别\"></a>sql语句中where与having的区别</h2><p>Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。</p>\n<p>Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。</p>\n<p>在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。</p>\n"},{"title":"rabbitmq思维导图","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-04T06:58:19.000Z","password":null,"summary":"博客中涉及到的rabbitmq相关概念。","_content":"\n![](rabbitmq.png)","source":"_posts/rabbitmq思维导图.md","raw":"---\ntitle: rabbitmq思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-04 14:58:19\npassword:\nsummary: 博客中涉及到的rabbitmq相关概念。\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n![](rabbitmq.png)","slug":"rabbitmq思维导图","published":1,"updated":"2021-04-04T06:59:45.233Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6wq002lq4ufhxybvkwe","content":"<p><img src=\"rabbitmq.png\" alt></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p><img src=\"rabbitmq.png\" alt></p>\n"},{"title":"mysql日志系统","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-11T01:04:56.000Z","password":null,"summary":null,"_content":"\n##  日志系统\n\n### redo log（重做日志）\n\n1. InnoDB引擎日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）\n\n2. 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）\n\n3. redo log 是物理日志，记录的是在某个数据页上做了什么修改\n\n4. redo log是循环写，空间固定会用完\n\n### binlog（归档日志）\n\n1. server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力\n\n2. binlog是逻辑日志，记录的是记录所有数据库表结构变更（CREATE、ALTER）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志\n\n3. binlog采用追加写的模式\n\n4. **用途：**  \n\n- 恢复：binlog日志恢复数据库数据  \n\n- 复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  \n\n- 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击\n\n**binlog常见格式**\n\n| format    | 定义                       | 优点                           | 缺点                                                         |\n| --------- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |\n| statement | 记录的是修改SQL语句        | 日志文件小，节约IO，提高性能   | 准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况） |\n| row       | 记录的是每行实际数据的变更 | 准确性强，能准确复制数据的变更 | 日志文件大，较大的网络IO和磁盘IO                             |\n| mixed     | statement和row模式的混合   | 准确性强，文件大小适中         | 有可能发生主从不一致问题                                     |\n\n### 两段提交  \n\n1. 保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致\n\n2. 两段提交: 写入redo log处于prepare阶段 --（A）- 写入bin log -（B）-- 提交事务处于commit状态 \n\n   - 时刻A崩溃恢复: redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  \n\n   - 时刻B崩溃恢复: 如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，“是”提交事务，”否“回滚事务\n\n3. bin log完整性判断:  \n\n   - statement格式最后有commit  \n\n   - row格式最有有一个XID event（redo log 和 bin log关联：有一个共同字段XID）\n\n### undo log\n\n1. undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录\n\n2. undo log 作用  \n\n   - 提供回滚  \n\n   - 多个行版本控制（MVCC）","source":"_posts/mysql日志系统.md","raw":"---\ntitle: mysql日志系统\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-11 09:04:56\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n##  日志系统\n\n### redo log（重做日志）\n\n1. InnoDB引擎日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）\n\n2. 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）\n\n3. redo log 是物理日志，记录的是在某个数据页上做了什么修改\n\n4. redo log是循环写，空间固定会用完\n\n### binlog（归档日志）\n\n1. server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力\n\n2. binlog是逻辑日志，记录的是记录所有数据库表结构变更（CREATE、ALTER）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志\n\n3. binlog采用追加写的模式\n\n4. **用途：**  \n\n- 恢复：binlog日志恢复数据库数据  \n\n- 复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  \n\n- 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击\n\n**binlog常见格式**\n\n| format    | 定义                       | 优点                           | 缺点                                                         |\n| --------- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |\n| statement | 记录的是修改SQL语句        | 日志文件小，节约IO，提高性能   | 准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况） |\n| row       | 记录的是每行实际数据的变更 | 准确性强，能准确复制数据的变更 | 日志文件大，较大的网络IO和磁盘IO                             |\n| mixed     | statement和row模式的混合   | 准确性强，文件大小适中         | 有可能发生主从不一致问题                                     |\n\n### 两段提交  \n\n1. 保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致\n\n2. 两段提交: 写入redo log处于prepare阶段 --（A）- 写入bin log -（B）-- 提交事务处于commit状态 \n\n   - 时刻A崩溃恢复: redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  \n\n   - 时刻B崩溃恢复: 如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，“是”提交事务，”否“回滚事务\n\n3. bin log完整性判断:  \n\n   - statement格式最后有commit  \n\n   - row格式最有有一个XID event（redo log 和 bin log关联：有一个共同字段XID）\n\n### undo log\n\n1. undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录\n\n2. undo log 作用  \n\n   - 提供回滚  \n\n   - 多个行版本控制（MVCC）","slug":"mysql日志系统","published":1,"updated":"2021-04-29T00:08:42.008Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6x3002oq4ufmivveoap","content":"<h2 id=\"日志系统\"><a href=\"#日志系统\" class=\"headerlink\" title=\"日志系统\"></a>日志系统</h2><h3 id=\"redo-log（重做日志）\"><a href=\"#redo-log（重做日志）\" class=\"headerlink\" title=\"redo log（重做日志）\"></a>redo log（重做日志）</h3><ol>\n<li><p>InnoDB引擎日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）</p>\n</li>\n<li><p>在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）</p>\n</li>\n<li><p>redo log 是物理日志，记录的是在某个数据页上做了什么修改</p>\n</li>\n<li><p>redo log是循环写，空间固定会用完</p>\n</li>\n</ol>\n<h3 id=\"binlog（归档日志）\"><a href=\"#binlog（归档日志）\" class=\"headerlink\" title=\"binlog（归档日志）\"></a>binlog（归档日志）</h3><ol>\n<li><p>server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力</p>\n</li>\n<li><p>binlog是逻辑日志，记录的是记录所有数据库表结构变更（CREATE、ALTER）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志</p>\n</li>\n<li><p>binlog采用追加写的模式</p>\n</li>\n<li><p><strong>用途：</strong>  </p>\n</li>\n</ol>\n<ul>\n<li><p>恢复：binlog日志恢复数据库数据  </p>\n</li>\n<li><p>复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  </p>\n</li>\n<li><p>审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击</p>\n</li>\n</ul>\n<p><strong>binlog常见格式</strong></p>\n<table>\n<thead>\n<tr>\n<th>format</th>\n<th>定义</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>statement</td>\n<td>记录的是修改SQL语句</td>\n<td>日志文件小，节约IO，提高性能</td>\n<td>准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况）</td>\n</tr>\n<tr>\n<td>row</td>\n<td>记录的是每行实际数据的变更</td>\n<td>准确性强，能准确复制数据的变更</td>\n<td>日志文件大，较大的网络IO和磁盘IO</td>\n</tr>\n<tr>\n<td>mixed</td>\n<td>statement和row模式的混合</td>\n<td>准确性强，文件大小适中</td>\n<td>有可能发生主从不一致问题</td>\n</tr>\n</tbody></table>\n<h3 id=\"两段提交\"><a href=\"#两段提交\" class=\"headerlink\" title=\"两段提交\"></a>两段提交</h3><ol>\n<li><p>保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致</p>\n</li>\n<li><p>两段提交: 写入redo log处于prepare阶段 –（A）- 写入bin log -（B）– 提交事务处于commit状态 </p>\n<ul>\n<li><p>时刻A崩溃恢复: redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  </p>\n</li>\n<li><p>时刻B崩溃恢复: 如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，“是”提交事务，”否“回滚事务</p>\n</li>\n</ul>\n</li>\n<li><p>bin log完整性判断:  </p>\n<ul>\n<li><p>statement格式最后有commit  </p>\n</li>\n<li><p>row格式最有有一个XID event（redo log 和 bin log关联：有一个共同字段XID）</p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"undo-log\"><a href=\"#undo-log\" class=\"headerlink\" title=\"undo log\"></a>undo log</h3><ol>\n<li><p>undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</p>\n</li>\n<li><p>undo log 作用  </p>\n<ul>\n<li><p>提供回滚  </p>\n</li>\n<li><p>多个行版本控制（MVCC）</p>\n</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"日志系统\"><a href=\"#日志系统\" class=\"headerlink\" title=\"日志系统\"></a>日志系统</h2><h3 id=\"redo-log（重做日志）\"><a href=\"#redo-log（重做日志）\" class=\"headerlink\" title=\"redo log（重做日志）\"></a>redo log（重做日志）</h3><ol>\n<li><p>InnoDB引擎日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）</p>\n</li>\n<li><p>在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）</p>\n</li>\n<li><p>redo log 是物理日志，记录的是在某个数据页上做了什么修改</p>\n</li>\n<li><p>redo log是循环写，空间固定会用完</p>\n</li>\n</ol>\n<h3 id=\"binlog（归档日志）\"><a href=\"#binlog（归档日志）\" class=\"headerlink\" title=\"binlog（归档日志）\"></a>binlog（归档日志）</h3><ol>\n<li><p>server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力</p>\n</li>\n<li><p>binlog是逻辑日志，记录的是记录所有数据库表结构变更（CREATE、ALTER）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志</p>\n</li>\n<li><p>binlog采用追加写的模式</p>\n</li>\n<li><p><strong>用途：</strong>  </p>\n</li>\n</ol>\n<ul>\n<li><p>恢复：binlog日志恢复数据库数据  </p>\n</li>\n<li><p>复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  </p>\n</li>\n<li><p>审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击</p>\n</li>\n</ul>\n<p><strong>binlog常见格式</strong></p>\n<table>\n<thead>\n<tr>\n<th>format</th>\n<th>定义</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>statement</td>\n<td>记录的是修改SQL语句</td>\n<td>日志文件小，节约IO，提高性能</td>\n<td>准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况）</td>\n</tr>\n<tr>\n<td>row</td>\n<td>记录的是每行实际数据的变更</td>\n<td>准确性强，能准确复制数据的变更</td>\n<td>日志文件大，较大的网络IO和磁盘IO</td>\n</tr>\n<tr>\n<td>mixed</td>\n<td>statement和row模式的混合</td>\n<td>准确性强，文件大小适中</td>\n<td>有可能发生主从不一致问题</td>\n</tr>\n</tbody></table>\n<h3 id=\"两段提交\"><a href=\"#两段提交\" class=\"headerlink\" title=\"两段提交\"></a>两段提交</h3><ol>\n<li><p>保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致</p>\n</li>\n<li><p>两段提交: 写入redo log处于prepare阶段 –（A）- 写入bin log -（B）– 提交事务处于commit状态 </p>\n<ul>\n<li><p>时刻A崩溃恢复: redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  </p>\n</li>\n<li><p>时刻B崩溃恢复: 如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，“是”提交事务，”否“回滚事务</p>\n</li>\n</ul>\n</li>\n<li><p>bin log完整性判断:  </p>\n<ul>\n<li><p>statement格式最后有commit  </p>\n</li>\n<li><p>row格式最有有一个XID event（redo log 和 bin log关联：有一个共同字段XID）</p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"undo-log\"><a href=\"#undo-log\" class=\"headerlink\" title=\"undo log\"></a>undo log</h3><ol>\n<li><p>undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</p>\n</li>\n<li><p>undo log 作用  </p>\n<ul>\n<li><p>提供回滚  </p>\n</li>\n<li><p>多个行版本控制（MVCC）</p>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"rabbitmq客户端开发","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-03T12:58:05.000Z","password":null,"summary":"rabbitmq客户端开发的说明。","_content":"\n## 连接 RabbitMQ\n\n```java\nConnectionFactory factory = new ConnectionFactory();\nfactory.setUsername(USERNAME);\nfactory.setPassword(PASSWORD);\nfactory.setVirtualHost(virtualHost);\nfacotry.setHost(IP_ADRESS);\nfactory.setPort(PORT);\n// 通过URI方式\n// factory.setUri(\"amqp://userName;password@ipAddress:portNumber/virtualHost\");\nConnection conn = factory.newConnection();\nChannel channel = conn.createChannel();\n```\n\nConnection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel\n\n## 使用交换器和队列\n\n```java\n// 持久化的、非自动删除的、绑定类型为direct的交换器\nchannel.exchangeDeclare(exchangeName,\"direct\",true);\n// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名\nString queueName = channel.queueDeclare().getQueue();\n// 持久化的、非排他的、非自动删除的、确定的已知名称\n// channel.queueDeclare(queueName,true,false,false,null);\nchannel.queueBind(queueName,exchangeName,routingKey);\n```\n\nexchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置\n\nqueueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。\n\nqueueBind定义：队列名称、交换器名称、路由键\n\n## 发送消息\n\n```java\nbyte[] messageBodyBytes = \"Hello,world\".getBytes();\n// 普通发送\nchannel.basicPublish(exchangeName,routingKey,null,messageBodyBytes);\n// 控制发送,使用mandatory\nchannel.basicPublish(exchangeName,routingKey,mandatory,MessageProperties.PERSiSTENT_TEXT_PLAIN,messageBodyBytes);\n```\n\n## 消费消息\n\n消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get\n\n**推模式**\n\n```java\nboolean autoAck = false;\nchannel.basicQos(64);\nchannel.basicConsume(queueName,autoAck,\"myConsumerTag\",\n    new DefaultConsumer(channel){\n        @Override\n        public void handleDelivery(String consumerTag,Envelope envelope,AMQP.BasicProperties properties,byte[] body) throws IOException{\n            String routingKey = envelope.getRoutingKey();\n            String contentType = properties.getContentType();\n            long deliveryTag = envelope.getDeliveryTag();\n            channel.basicAck(deliveryTag, false);\n        }\n    }\n);\n```\n\n显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失\n\n每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者\n\n如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁\n\n**拉模式**\n\n```java\nGetResponse response = channel.basicGet(QUEUE_NAME,false);\nSystem.out.pringln(new String(response.getBody()));\nchannel.basicAck(response.getEnvelope().getDeliveryTag(),false);\n```\n\n如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收\n\n如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。\n\n## 消费端的确认与拒绝\n\n**消息确认机制**\n\nRabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数\nautoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息\nautoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除\n**拒绝消息**\n\n消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack\n如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者\n如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除\n如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题\n**注意要点**\n\nRabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息\n如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者\nRabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。\n\n## 关闭连接\n\n```java\nchannel.close();\nconn.close();\n```\n\n显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭","source":"_posts/rabbitmq客户端开发.md","raw":"---\ntitle: rabbitmq客户端开发\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-03 20:58:05\npassword:\nsummary: rabbitmq客户端开发的说明。\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 连接 RabbitMQ\n\n```java\nConnectionFactory factory = new ConnectionFactory();\nfactory.setUsername(USERNAME);\nfactory.setPassword(PASSWORD);\nfactory.setVirtualHost(virtualHost);\nfacotry.setHost(IP_ADRESS);\nfactory.setPort(PORT);\n// 通过URI方式\n// factory.setUri(\"amqp://userName;password@ipAddress:portNumber/virtualHost\");\nConnection conn = factory.newConnection();\nChannel channel = conn.createChannel();\n```\n\nConnection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel\n\n## 使用交换器和队列\n\n```java\n// 持久化的、非自动删除的、绑定类型为direct的交换器\nchannel.exchangeDeclare(exchangeName,\"direct\",true);\n// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名\nString queueName = channel.queueDeclare().getQueue();\n// 持久化的、非排他的、非自动删除的、确定的已知名称\n// channel.queueDeclare(queueName,true,false,false,null);\nchannel.queueBind(queueName,exchangeName,routingKey);\n```\n\nexchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置\n\nqueueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。\n\nqueueBind定义：队列名称、交换器名称、路由键\n\n## 发送消息\n\n```java\nbyte[] messageBodyBytes = \"Hello,world\".getBytes();\n// 普通发送\nchannel.basicPublish(exchangeName,routingKey,null,messageBodyBytes);\n// 控制发送,使用mandatory\nchannel.basicPublish(exchangeName,routingKey,mandatory,MessageProperties.PERSiSTENT_TEXT_PLAIN,messageBodyBytes);\n```\n\n## 消费消息\n\n消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get\n\n**推模式**\n\n```java\nboolean autoAck = false;\nchannel.basicQos(64);\nchannel.basicConsume(queueName,autoAck,\"myConsumerTag\",\n    new DefaultConsumer(channel){\n        @Override\n        public void handleDelivery(String consumerTag,Envelope envelope,AMQP.BasicProperties properties,byte[] body) throws IOException{\n            String routingKey = envelope.getRoutingKey();\n            String contentType = properties.getContentType();\n            long deliveryTag = envelope.getDeliveryTag();\n            channel.basicAck(deliveryTag, false);\n        }\n    }\n);\n```\n\n显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失\n\n每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者\n\n如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁\n\n**拉模式**\n\n```java\nGetResponse response = channel.basicGet(QUEUE_NAME,false);\nSystem.out.pringln(new String(response.getBody()));\nchannel.basicAck(response.getEnvelope().getDeliveryTag(),false);\n```\n\n如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收\n\n如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。\n\n## 消费端的确认与拒绝\n\n**消息确认机制**\n\nRabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数\nautoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息\nautoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除\n**拒绝消息**\n\n消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack\n如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者\n如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除\n如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题\n**注意要点**\n\nRabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息\n如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者\nRabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。\n\n## 关闭连接\n\n```java\nchannel.close();\nconn.close();\n```\n\n显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭","slug":"rabbitmq客户端开发","published":1,"updated":"2021-04-03T13:30:23.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6xd002sq4ufkxy6hiyo","content":"<h2 id=\"连接-RabbitMQ\"><a href=\"#连接-RabbitMQ\" class=\"headerlink\" title=\"连接 RabbitMQ\"></a>连接 RabbitMQ</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\">ConnectionFactory factory <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ConnectionFactory</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setUsername</span><span class=\"token punctuation\">(</span>USERNAME<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setPassword</span><span class=\"token punctuation\">(</span>PASSWORD<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setVirtualHost</span><span class=\"token punctuation\">(</span>virtualHost<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfacotry<span class=\"token punctuation\">.</span><span class=\"token function\">setHost</span><span class=\"token punctuation\">(</span>IP_ADRESS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setPort</span><span class=\"token punctuation\">(</span>PORT<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 通过URI方式</span>\n<span class=\"token comment\" spellcheck=\"true\">// factory.setUri(\"amqp://userName;password@ipAddress:portNumber/virtualHost\");</span>\nConnection conn <span class=\"token operator\">=</span> factory<span class=\"token punctuation\">.</span><span class=\"token function\">newConnection</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nChannel channel <span class=\"token operator\">=</span> conn<span class=\"token punctuation\">.</span><span class=\"token function\">createChannel</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Connection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel</p>\n<h2 id=\"使用交换器和队列\"><a href=\"#使用交换器和队列\" class=\"headerlink\" title=\"使用交换器和队列\"></a>使用交换器和队列</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 持久化的、非自动删除的、绑定类型为direct的交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">exchangeDeclare</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span><span class=\"token string\">\"direct\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名</span>\nString queueName <span class=\"token operator\">=</span> channel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getQueue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 持久化的、非排他的、非自动删除的、确定的已知名称</span>\n<span class=\"token comment\" spellcheck=\"true\">// channel.queueDeclare(queueName,true,false,false,null);</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueBind</span><span class=\"token punctuation\">(</span>queueName<span class=\"token punctuation\">,</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>exchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置</p>\n<p>queueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。</p>\n<p>queueBind定义：队列名称、交换器名称、路由键</p>\n<h2 id=\"发送消息\"><a href=\"#发送消息\" class=\"headerlink\" title=\"发送消息\"></a>发送消息</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> messageBodyBytes <span class=\"token operator\">=</span> <span class=\"token string\">\"Hello,world\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 普通发送</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">,</span>null<span class=\"token punctuation\">,</span>messageBodyBytes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 控制发送,使用mandatory</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">,</span>mandatory<span class=\"token punctuation\">,</span>MessageProperties<span class=\"token punctuation\">.</span>PERSiSTENT_TEXT_PLAIN<span class=\"token punctuation\">,</span>messageBodyBytes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><p>消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get</p>\n<p><strong>推模式</strong></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">boolean</span> autoAck <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicQos</span><span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicConsume</span><span class=\"token punctuation\">(</span>queueName<span class=\"token punctuation\">,</span>autoAck<span class=\"token punctuation\">,</span><span class=\"token string\">\"myConsumerTag\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token keyword\">new</span> <span class=\"token class-name\">DefaultConsumer</span><span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">handleDelivery</span><span class=\"token punctuation\">(</span>String consumerTag<span class=\"token punctuation\">,</span>Envelope envelope<span class=\"token punctuation\">,</span>AMQP<span class=\"token punctuation\">.</span>BasicProperties properties<span class=\"token punctuation\">,</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> body<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> IOException<span class=\"token punctuation\">{</span>\n            String routingKey <span class=\"token operator\">=</span> envelope<span class=\"token punctuation\">.</span><span class=\"token function\">getRoutingKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            String contentType <span class=\"token operator\">=</span> properties<span class=\"token punctuation\">.</span><span class=\"token function\">getContentType</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">long</span> deliveryTag <span class=\"token operator\">=</span> envelope<span class=\"token punctuation\">.</span><span class=\"token function\">getDeliveryTag</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            channel<span class=\"token punctuation\">.</span><span class=\"token function\">basicAck</span><span class=\"token punctuation\">(</span>deliveryTag<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失</p>\n<p>每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者</p>\n<p>如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁</p>\n<p><strong>拉模式</strong></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">GetResponse response <span class=\"token operator\">=</span> channel<span class=\"token punctuation\">.</span><span class=\"token function\">basicGet</span><span class=\"token punctuation\">(</span>QUEUE_NAME<span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nSystem<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">pringln</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">String</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span><span class=\"token function\">getBody</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicAck</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span><span class=\"token function\">getEnvelope</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getDeliveryTag</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收</p>\n<p>如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。</p>\n<h2 id=\"消费端的确认与拒绝\"><a href=\"#消费端的确认与拒绝\" class=\"headerlink\" title=\"消费端的确认与拒绝\"></a>消费端的确认与拒绝</h2><p><strong>消息确认机制</strong></p>\n<p>RabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数<br>autoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息<br>autoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除<br><strong>拒绝消息</strong></p>\n<p>消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack<br>如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者<br>如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除<br>如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题<br><strong>注意要点</strong></p>\n<p>RabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息<br>如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者<br>RabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。</p>\n<h2 id=\"关闭连接\"><a href=\"#关闭连接\" class=\"headerlink\" title=\"关闭连接\"></a>关闭连接</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\">channel<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconn<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"连接-RabbitMQ\"><a href=\"#连接-RabbitMQ\" class=\"headerlink\" title=\"连接 RabbitMQ\"></a>连接 RabbitMQ</h2><pre><code class=\"java\">ConnectionFactory factory = new ConnectionFactory();\nfactory.setUsername(USERNAME);\nfactory.setPassword(PASSWORD);\nfactory.setVirtualHost(virtualHost);\nfacotry.setHost(IP_ADRESS);\nfactory.setPort(PORT);\n// 通过URI方式\n// factory.setUri(&quot;amqp://userName;password@ipAddress:portNumber/virtualHost&quot;);\nConnection conn = factory.newConnection();\nChannel channel = conn.createChannel();</code></pre>\n<p>Connection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel</p>\n<h2 id=\"使用交换器和队列\"><a href=\"#使用交换器和队列\" class=\"headerlink\" title=\"使用交换器和队列\"></a>使用交换器和队列</h2><pre><code class=\"java\">// 持久化的、非自动删除的、绑定类型为direct的交换器\nchannel.exchangeDeclare(exchangeName,&quot;direct&quot;,true);\n// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名\nString queueName = channel.queueDeclare().getQueue();\n// 持久化的、非排他的、非自动删除的、确定的已知名称\n// channel.queueDeclare(queueName,true,false,false,null);\nchannel.queueBind(queueName,exchangeName,routingKey);</code></pre>\n<p>exchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置</p>\n<p>queueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。</p>\n<p>queueBind定义：队列名称、交换器名称、路由键</p>\n<h2 id=\"发送消息\"><a href=\"#发送消息\" class=\"headerlink\" title=\"发送消息\"></a>发送消息</h2><pre><code class=\"java\">byte[] messageBodyBytes = &quot;Hello,world&quot;.getBytes();\n// 普通发送\nchannel.basicPublish(exchangeName,routingKey,null,messageBodyBytes);\n// 控制发送,使用mandatory\nchannel.basicPublish(exchangeName,routingKey,mandatory,MessageProperties.PERSiSTENT_TEXT_PLAIN,messageBodyBytes);</code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><p>消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get</p>\n<p><strong>推模式</strong></p>\n<pre><code class=\"java\">boolean autoAck = false;\nchannel.basicQos(64);\nchannel.basicConsume(queueName,autoAck,&quot;myConsumerTag&quot;,\n    new DefaultConsumer(channel){\n        @Override\n        public void handleDelivery(String consumerTag,Envelope envelope,AMQP.BasicProperties properties,byte[] body) throws IOException{\n            String routingKey = envelope.getRoutingKey();\n            String contentType = properties.getContentType();\n            long deliveryTag = envelope.getDeliveryTag();\n            channel.basicAck(deliveryTag, false);\n        }\n    }\n);</code></pre>\n<p>显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失</p>\n<p>每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者</p>\n<p>如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁</p>\n<p><strong>拉模式</strong></p>\n<pre><code class=\"java\">GetResponse response = channel.basicGet(QUEUE_NAME,false);\nSystem.out.pringln(new String(response.getBody()));\nchannel.basicAck(response.getEnvelope().getDeliveryTag(),false);</code></pre>\n<p>如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收</p>\n<p>如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。</p>\n<h2 id=\"消费端的确认与拒绝\"><a href=\"#消费端的确认与拒绝\" class=\"headerlink\" title=\"消费端的确认与拒绝\"></a>消费端的确认与拒绝</h2><p><strong>消息确认机制</strong></p>\n<p>RabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数<br>autoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息<br>autoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除<br><strong>拒绝消息</strong></p>\n<p>消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack<br>如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者<br>如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除<br>如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题<br><strong>注意要点</strong></p>\n<p>RabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息<br>如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者<br>RabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。</p>\n<h2 id=\"关闭连接\"><a href=\"#关闭连接\" class=\"headerlink\" title=\"关闭连接\"></a>关闭连接</h2><pre><code class=\"java\">channel.close();\nconn.close();</code></pre>\n<p>显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭</p>\n"},{"title":"python面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-13T11:58:48.000Z","password":null,"summary":null,"_content":"\n## 语言特性\n\n解释型语言。Python不需要在运行之前进行编译。\n\n动态语言，不需要声明变量的类型。\n\n适合面向对象的编程，允许类的定义和继承。\n\n## python2和python3区别\n\n- Python2 的默认编码是 ascii，Python 3 默认编码 UTF-8，不需要在文件顶部写 `# coding=utf-8 `。\n- 在Python2 中，字符串有两个类型， unicode和 str，前者表示文本字符串，后者表示字节序列，不过两者并没有明显的界限； Python3  str 表示字符串，byte 表示字节序列。\n- True 和 False 在 Python2 中是全局变量，分别对应 1 和 0，可以指向其它对象。 Python3  True 和 False 变为关键字，不允许再被重新赋值。\n- Python 2中print是特殊语句，Python 3中print是函数，需要加上括号。\n- 在Python 2中，3/2是整数，在Python 3中，浮点数。\n- python2 range返回列表，python3 range中返回可迭代对象，节约内存。\n- Python 2 map函数返回list，Python 3 map函数返回迭代器。\n- python2中的raw_input函数，python3中改名为input函数\n- 在Pyhon3，新增了关键字 nonlcoal，支持嵌套函数中，变量声明为非局部变量。\n\n## Python基础\n\n### 可变数据类型和不可变数据类型\n\n可变数据类型（引用类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址不发生改变。\n\n不可变数据类型（值类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址发生了改变。\n\n可变数据类型：list和dict；\n\n不可变数据类型：int、型float、string和tuple。\n\n### python2中xrange和range的区别\n\n`range()`返回的是一个list对象，而xrange返回的是一个可迭代对象。\n\n`xrange()`则不会直接生成一个list，而是每次调用返回其中的一个值，内存空间使用极少。因而性能非常好。\n\n### 变量的作用域/查找顺序\n\n函数作用域的LEGB顺序\n\nL： local ，局部作用域；\n\nE： enclosing，嵌套的父级函数的局部作用域；\n\nG：global ，全局变量；\n\nB： build-in， 系统固定模块里面的变量。\n\nPython除了def/class/lambda 外，其他如: if/elif/else/ try/except for/while并不能改变其作用域。\n\n### 内置函数\n\n`reduce()` 函数会对参数序列中元素进行累积。\n\n先对数据集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据做函数运算。\n\n```python\ndef add(x, y) :      # 两数相加\n   return x + y\nreduce(add, [1,2,3,4,5])  # 计算列表和：1+2+3+4+5\nreduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数\n```\n\n`filter()` 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。\n\n序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。\n\n```python\ndef is_odd(n):\n  return n % 2 == 1\n\nnewlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprint(newlist)\n```\n\n`map()` 会根据提供的函数对指定序列做映射。\n\n序列中的每一个元素调用 函数，返回包含每次函数返回值的新列表（python2），python3是会返回可迭代对象的。\n\n```python\ndef square(x) :      # 计算平方数\n   return x ** 2\nmap(square, [1,2,3,4,5])  # 计算列表各个元素的平方\n```\n\n`repr() `函数将对象转化为供解释器读取的形式\n\n```python\ndict1 = {'runoob': 'runoob.com', 'google': 'google.com'};\nrepr(dict1)\nstr(dict1)\n\n\"{'google': 'google.com', 'runoob': 'runoob.com'}\"\n```\n\n`vars() `函数返回对象object的属性和属性值的字典对象。\n\n```\nclass Runoob:\n   a = 1\nprint(vars(Runoob))\n{'a': 1, '__module__': '__main__', '__doc__': None}\n```\n\n**ord**\n\n一个长度为1的字符串作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。\n\n#### dir\n\n不带参数时，返回当前范围内的变量、方法和定义的类型列表；\n\n带参数时，返回参数的属性、方法列表。\n\n如果参数包含方法`__dir__()`，该方法将被调用。\n\n#### **isinstance** \n\n`isinstance() `判断一个对象是否是一个已知的类型，`type()`查看一个类型或变量的类型。\n\n`type() `不会认为子类是一种父类类型。`isinstance() `会认为子类是一种父类类型。\n\n#### raw_input、input\n\n1、在 Python2.x 中` raw_input() `和` input()`，两个函数都存在，其中区别为:\n\n- `raw_input()`将所有输入作为字符串看待，返回字符串类型。\n-  `input()` 只能接收“数字”的输入，它返回所输入的数字的类型。\n\n2、在 Python3.x 中 仅保留了`input()` 函数，将所有输入作为字符串处理，并返回字符串类型。\n\n#### sort sorted\n\n**区别**\n\n对于一个无序的列表a，调用`a.sort()`，对a进行排序后返回None，`sort()`函数修改待排序的列表内容。\n\n而对于同样一个无序的列表a，调用`sorted(a)`，对a进行排序后返回一个新的列表，而对a不产生影响。\n\n**sort**\n\ntimsort是结合了合并排序和插入排序而得出的排序算法。该算法找到数据中已经排好序的块-分区，每一个分区叫一个run，然后按规则合并这些run。\n\n为了减少对升序部分的回溯和对降序部分的性能倒退，将输入按其升序和降序特点进行了分区。排序的输入的单位不是一个个单独的数字，而是一个个的块-分区。其中每一个分区叫一个run。针对这些 run 序列，每次拿一个 run 出来按规则进行合并。每次合并会将两个 run合并成一个 run。合并的结果保存到栈中。合并直到消耗掉所有的 run，这时将栈上剩余的 run合并到只剩一个 run 为止。这时这个仅剩的 run 便是排好序的结果。\n\n（0）数组长度小于某个值，直接用二分插入排序算法\n\n（1）找到各个run，并入栈\n\n（2）按规则合并run\n\n0：有序部分的长度一般不会太长，当小于 minRun 时，会将此部分后面的元素插入其中，直至长度满足 minRun。通过二分法查找元素\n\n2：会将该run在数组中的起始位置和run的长度放入栈中，然后根据先前放入栈中的run决定是否该合并run。Timsort不会合并在栈中不连续的run\n\n先用二分查找算法/折半查找算法（binary search）找到插入的位置，然后在插入。\n\n   例如，我们要将A和B这2个run 合并，且A是较小的run。因为A和B已经分别是排好序的，二分查找会找到B的第一个元素在A中何处插入。同样，A的最后一个元素找到在B的何处插入，找到以后，B在这个元素之后的元素就不需要比较了。这种查找可能在随机数中效率不会很高，但是在其他情况下有很高的效率。\n\n### 魔法方法\n\n在特殊的情况下被Python所调用的方法。\n\n`__init__`构造器，当一个实例被创建的时候用于初始化的方法。\n\n`__new__`实例化对象调用的第一个方法，用来创造一个类的实例的，取下cls参数，把其他参数传给`__init__`.\n\n`__call__`让一个类的实例像函数一样被调用\n\n`__getitem__`定义获取容器中指定元素的行为，相当于`self[key]`\n\n`__getattr__`定义当用户试图访问一个不存在属性的时候的行为\n\n`__setattr__`定义当一个属性被设置的时候的行为\n\n`__getattribute___`定义当一个属性被访问的时候的行为\n\n`__del__`删除对象执行的方法\n\n`__str__`强调可读性，面向用户；而`__repr__`强调标准性，面向机器\n\n%s调用`__str__`方法，而%r调用`__repr__`方法\n\n`__repr__`在表示类时，是一级的，如果只定义它，那么`__str__` = `__repr__`。\n\n```python\nclass Callable:\n  def __call__(self, a, b):\n     return a + b\n\n\nfunc = Callable() \nresult = func(2, 3) # 像函数一样调用\nprint(result)\n```\n\n### new & init区别\n\n1、`__new__`有参数cls，代表当前类，从而产生一个实例；`__new__`必须要有返回值，返回实例化出来的实例，可以return父类（`super(当前类名, cls)`）`__new__`出来的实例，或object的`__new__`出来的实例\n\n2、`__init__`有参数self，完成一些初始化的动作，`__init__`不需要返回值\n\n3、如果`__new__`创建的是当前类的实例，会自动调用`__init__`（return语句里面调用的`__new__`函数的第一个参数是cls，保证是当前类实例）；如果`__new__`返回一个已经存在的实例，`__init__`不会被调用。\n\n4、如果我们在`__new__`函数中不返回任何对象，则`__init__`函数也不会被调用。\n\n> Python的旧类中实际上并没有`__new__`方法。因为旧类中的`__init__`实际上起构造器的作用\n\n### 字符串\n\n避免转义，给字符串加r表示原始字符串。\n\n### is 和 ==区别\n\nis：比较俩对象是否为同一个实例对象，是否指向同一个内存地址。\n\n== ： 比较的两个对象的内容/值是否相等，默认会调用对象的`eq()`方法\n\n### set去重\n\nset的去重是通过两个函数`__hash__`和`__eq__`结合实现的。\n\n1、当两个变量的哈希值不相同时，就认为这两个变量是不同的\n\n2、当两个变量哈希值一样时，调用`__eq__`方法，当返回值为True时认为这两个变量是同一个。返回FALSE时，不去重。\n\n### list切片\n\n索引操作本身基于`__getitem__`和`__setitem__`\n\npython向`__getitem__`传入了一个`slice`的对象，这个类有start, stop, step三个属性，缺省值都是None。\n\n```python\na = [1,2,3,4,5,6]\nx = a [1: 5]        # x = a.__getitem__(slice( 1, 5, None))\na [1: 3] = [10, 11, 12]  # a.__setitem__(slice(1, 3, None), [ 10, 11, 12 ])\ndel a [1: 4]        # a.__delitem__(slice(1, 4, None))\n```\n\n### 三元算子\n\n`[on true] if [expression] else [on false]`\n\n### pass\n\n1、一般作为占位符或者创建占位程序，pass语句不会执行任何操作\n\n2、保证格式、语义完整 \n\n### lambda\n\n创建匿名函数的一个特殊语法,即用即仍，\n\n1.一般用来给filter，map这样的函数式编程服务\n\n2.作为回调函数\n\n### 迭代器和生成器\n\n#### 迭代器\n\n**迭代器协议**： `__iter__()` 返回一个特殊的迭代器对象， 这个迭代器对象实现了 `__next__()` 并通过 `StopIteration` 异常，标识迭代的完成。\n\n**迭代器对象**：实现了迭代器协议的对象/被`next()`函数调用并不断返回下一个值的对象称为迭代器。\n\n**例子**\n\nPython的内置工具（如for循环，sum，min，max函数等）使用迭代器协议访问对象\n\n#### 生成器\n\n**使用了 yield 的函数被称为生成器**。**只要把一个列表生成式的`[]`改成`()`，就创建了一个生成器**\n\n生成器是一种特殊的迭代器，生成器自动实现了“迭代器协议”。\n\n生成器在迭代的过程中可以改变当前迭代值，而修改普通迭代器的当前迭代值往往会发生异常，影响程序的执行。\n\n#### 可迭代对象\n\n实现`__iter__`方法的对象。可迭代对象包含文件对象、序列（字符串、列表、元组、集合）、字典。\n\n#### 判断方法\n\n```python\nfrom collections import Iterable, Iterator\nfrom inspect import isgenerator\n\nisinstance(a, Iterable)\nisinstance(a, Iterator)\nisgenerator(a)\n```\n\n### 装饰器\n\n装饰器本质上是一个**Python函数或者类**，让其他函数在不做任何代码变动，从而增加额外功能，装饰器的返回值也是一个函数对象。\n\n场景：**插入日志**、性能测试、**事务处理**、缓存、**权限校验、异常处理**。\n\n```python\nimport functools\n\ndef add(a, b):\n  print(a + b)\n \nadd  = functools.partial(add, 1)\n# 输出：3\nadd(2)\n```\n\n经过partial包装之后，a参数的值被固定为了1，新的add对象（注意此处add已经是一个可调用对象）只需要接收一个参数即可。\n\n**把原函数的部分参数固定了初始值，新的调用只需要传递其它参数。**\n\n`@functools.wraps(func)`底层逻辑，就是把wrapped函数的属性拷贝到wrapper函数中。\n\n```python\ndef outer(func):\n  @functools.wraps(func)\n  def inner(*args, **kwargs):\n     print(f\"before...\")\n     func(*args, **kwargs)\n     print(\"after...\")\n  return inner\n\n@outer\ndef add(a, b):\n  \"\"\"\n  求和运算\n  \"\"\"\n  print(a + b)\n```\n\n1、原函数为add。\n\n2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。\n\n3、执行outer函数时，加载inner函数，此时会直接执行`functools.wraps(func)`返回一个可调用对象，即partial对象。\n\n4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。\n\n5、把add指向inner函数。\n\n6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。\n\n **总结**\n\n1）functools.wraps 旨在消除装饰器对原函数造成的影响，即对原函数的相关属性进行拷贝。\n\n2）wraps内部通过partial对象和update_wrapper函数实现。\n\n3）partial是一个类，通过实现`__new__`，**自定义实例化对象过程，使得对象内部保留原函数和固定参数**，通过实现`__call__`，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。\n\n#### **类装饰器**\n\n类装饰器具有**灵活度大、高内聚、封装性**等优点。\n\n依靠`__call__`方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。\n\n```python\nclass Foo(object):\n  def __init__(self, func):\n     self._func = func\n\ndef __call__(self):\n   print ('class decorator runing')\n   self._func()\n   print ('class decorator ending')\n\n@Foo\ndef bar():\n  print ('bar')\n\nbar()\n```\n\n### property\n\n让方法像属性一样使用\n\n```python\nproperty([fget[, fset[, fdel[, doc]]]])\nfdel = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\nfget = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\nfset = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\n\nclass C(object):\n  def __init__(self):\n     self._x = None\n \n  def getx(self):\n    return self._x\n\n  def setx(self, value):\n    self._x = value\n\n  def delx(self):\n    del self._x\n\n  x = property(getx, setx, delx, \"I'm the 'x' property.\")\n```\n\nproperty 的 getter,setter 和 deleter 方法同样可以用作装饰器：\n\n```python\nclass C(object):\n\n  def __init__(self):\n     self._x = None\n\n  @property\n  def x(self):\n     \"\"\"I'm the 'x' property.\"\"\"\n     return self._x\n\n  @x.setter\n  def x(self, value):\n     self._x = value\n\n  @x.deleter\n  def x(self):\n     del self._x\n```\n\n使用property装饰后，x不再是一个函数，而是property类的一个实例。所以第二个函数可以使用 x.setter 来装饰，本质是调用property.setter 来产生一个新的 property实例赋值给第二个x。\n\n第一个 x和第二个 x 是两个不同 property实例。但他们都属于同一个描述符类（property），当赋值时，就会进入 `property.__set__`，取值时，就会进入 `property.__get__`。\n\n### 参数类型\n\n**位置参数：**传参数时，按照顺序，依次传值。\n\n**默认参数：**参数提供默认值。默认参数一定要指向不变对象。\n\n**可变参数：**可变参数就是传入的参数个数是可变的。特征：*args\n\n**关键字参数：**允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。特征：**kw\n\n**命名关键字参数：**如果要限制关键字参数的名字，就可以用命名关键字参数。特征：命名关键字参数需要一个特殊分隔符`*`，而后面的参数被视为命名关键字参数。如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要特殊分隔符了\n\n参数定义的**顺序**必须是：位置参数–>默认参数–>可变参数–>命名关键字参数–>关键字参数\n\n### zip\n\n拉链函数， 将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表迭代器。\n\n如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同。\n\n```python\nprint(list(zip([0,1,3],[5,6,7],['a','b'])))\n[(0, 5, 'a'), (1, 6, 'b')]\n```\n\n### and 和or\n\n 在不加括号时候, and优先级大于or \n\nx or y：x为真是x, x为假是y \n\nx and y ： x为真就是y, x为假就是x\n\n```python\nv = 1 and 2 or 3 and 4 \nprint(v) # 2\n```\n\n### for 循环\n\n**通过调用`iter()`方法执行（字符串，元组，字典，集合，文件）对象内部的`__iter__`方法，获取一个迭代器，然后使用迭代器协议去实现循环访问，**当元素循环完时，会触发StopIteration异常，for循环会捕捉到这种异常，终止迭代\n\n### 深拷贝和浅拷贝\n\n浅拷贝：在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素地址的拷贝。也就是说新的容器中指向了旧的元素（ 新瓶装旧酒 ）。\n\n深拷贝：在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。（ 新瓶装新酒 ）。\n\n1、复制不可变数据类型， copy /deepcopy，都指向原地址对象\n\n2、复制的值是可变对象\n\n**浅拷贝copy有两种情况：**\n\n复制对象中包含的非可变数据类型：改变值，会开辟新的内存，有新的引用。原来值的改变并不会影响浅复制的值。\n\n复制对象中包含的可变数据类型：改变原来的值，会影响浅复制的值。\n\n**深拷贝deepcopy**\n\n完全复制独立，包括内层列表和字典\n\n### 参数传递\n\n**值传递：**实参把值传递给形参，形参的改变不影响实参值。\n\n**引用传递（地址传递）：**把实参地址传递形参，形参值的改变会影响实参的值。\n\n- 函数中修改字典某一个键值对是有效的\n- 函数中交换两个字典并无法生效\n\n因此不是严格意义上的引用传递，而是**基于引用地址的值传递**，传递的是对象地址的拷贝。\n\n### 闭包\n\n**高阶函数**：函数为入参，或者函数作为返回结果。\n\n**闭包**：在外函数中定义了内函数，内函数里使用了外函数的临时变量，并且外函数的返回值是内函数的引用。\n\n```python\ndef timer(func):\n  def wrapper(*args, **kwargs):\n     start = time.time()\n     func(*args, **kwargs) #此处拿到了被装饰的函数func\n     time.sleep(2)#模拟耗时操作\n     long = time.time() - start\n      print(f'共耗时{long}秒。')\n  return wrapper #返回内层函数的引用\n\n@timer\ndef add(a, b):\n  print(a+b)\n \nadd(1, 2) #正常调用add\n```\n\n**模块加载**\n\n-  遇到@，执行timer函数，传入add函数 \n-  生成`timer.<locals>.wrapper`函数并命名为add，其实是覆盖了原同名函数 \n-  调用`add(1, 2) `\n-  去执行`timer.<locals>.wrapper(1, 2) `\n-  wrapper内部持有原add函数引用`(func)`，调用`func(1, 2) `\n-  继续执行完wrapper函数\n\n**带参数的装饰器**\n\n```python\ndef auth(permission):\n  def _auth(func):\n     def wrapper(*args, **kwargs):\n       print(f\"验证权限[{permission}]...\")\n       func(*args, **kwargs)\n       print(\"执行完毕...\")\n     return wrapper\n  return _auth\n\n@auth(\"add\")\ndef add(a, b):\n  \"\"\"\n  求和运算\n  \"\"\"\n  print(a + b)\n```\n\n真正调用的是装饰后生成的新函数。\n\n为了消除装饰器对原函数的影响，需要伪装成原函数，拥有原函数的属性。可以利用functools：\n\n```python\ndef auth(permission):\n  def _auth(func):\n     @functools.wraps(func) # 注意此处\n     def wrapper(*args, **kwargs):\n       print(f\"验证权限[{permission}]...\")\n       func(*args, **kwargs)\n       print(\"执行完毕...\")\n     return wrapper\n  return _auth\n\n@auth(\"add\")\ndef add(a, b):\n  \"\"\"\n  求和运算\n  \"\"\"\n  print(a + b)\n```\n\n#### 特殊例子\n\n```python\ndef multi():\n  return [lambda x : i*x for i in range(4)]\n\nprint([m(3) for m in multi()]) # [9,9,9,9]\n```\n\n闭包的延迟绑定导致的，在**闭包中的变量是在内部函数被调用的时候被查找的**，最后函数被调用的时候，for循环已经完成， i 的值最后是3，因此每一个返回值的i都是3，所以最后的结果是[9,9,9,9]\n\n```python\n# [0, 3, 6, 9]\ndef multipliers():\n  for i in range(4):\n     yield lambda x: i *x\n```\n\n### 上下文管理\n\n在一个类里，实现了`__enter__`和`__exit__`的方法，这个类的实例就是一个上下文管理器。\n\n**基本使用语法**\n\n```pyt\nwith EXPR as VAR:\n    BLOCK\n```\n\n**为什么要使用上下文管理器？**\n\n一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接；处理异常；\n\n**使用contextlib**\n\n```python\nimport contextlib\n\n@contextlib.contextmanager\ndef open_func(file_name):\n    # __enter__方法\n    print('open file:', file_name, 'in __enter__')\n    file_handler = open(file_name, 'r')\n\n    try:\n        yield file_handler\n    except Exception as exc:\n        # deal with exception\n        print('the exception was thrown')\n    finally:\n        print('close file:', file_name, 'in __exit__')\n        file_handler.close()\n\n        return\n\nwith open_func('/Users/MING/mytest.txt') as file_in:\n    for line in file_in:\n        1/0\n        print(line)\n```\n\n### 编码和解码\n\n#### 编码类型\n\n- ascii ：一个字节表示一个字符，最多只能表示 256 个符号。\n- unicode： 所有字符需要2个字节表示\n- gbk：英文字符1个字节，中文字符两个字节\n- utf-8：英文字符1个字节、 欧洲字符2个字节， 亚洲字符3个字节\n\npython2 的默认编码方式为ASCII码，python3默认的文件编码是UTF-8\n\nPython的字符串类型是`str`，在内存中以Unicode表示。\n\n> 如果我们从网络或磁盘上读取了字节流，那么读到的数据就是`bytes`。要把`bytes`变为`str`，就需要用`decode()`方法；\n>\n> 如果要在网络上传输，或者保存到磁盘上，就需要把`str`变为以字节为单位的`bytes`\n\n### pickling和unpickling？\n\n模块 pickle 实现了对一个 Python 对象结构的二进制序列化和反序列化。\n\n \"pickling\" 是将 Python 对象及转化为一个字节流的过程\n\n\"unpickling\" 将字节流转化回一个对象层次结构。\n\nPickle 协议和 JSON 间有着本质的**不同**：\n\n- JSON 是一个文本序列化格式，而 pickle 是一个二进制序列化格式；\n- JSON 是我们可以直观阅读的，而 pickle 不是；\n- JSON在Python之外广泛使用，而pickle则是Python专用的；\n- JSON 只能表示 Python 内置类型的子集，不能表示自定义的类；但 pickle 可以表示大量的 Python 数据类型。\n\n### 说一下`namedtuple`的用法和作用\n\n只有属性没有方法的类，用于组织数据，称为数据类。\n\n在Python中可以用`namedtuple`（命名元组）来替代这种类。\n\n```python\nfrom collections import namedtuple\n\nCard = namedtuple('Card', ('suite', 'face'))\ncard1 = Card('红桃', 13)\ncard2 = Card('草花', 5)\nprint(f'{card1.suite}{card1.face}')\nprint(f'{card2.suite}{card2.face}')\n```\n\n命名元组与普通元组一样是不可变容器，一旦将数据存储在`namedtuple`的顶层属性中，数据就不能再修改了，\n\n对象上的所有属性都遵循“一次写入，多次读取”的原则。\n\n和普通元组不同的是，命名元组中的数据有访问名称，可以通过名称而不是索引来获取保存的数据\n\n命名元组的本质就是一个类，所以它还可以作为父类创建子类。\n\n除此之外，命名元组内置了一系列的方法，例如，可以通过`_asdict`方法将命名元组处理成字典，也可以通过`_replace`方法创建命名元组对象的浅拷贝。\n\n```python\nclass MyCard(Card):\n    \n    def show(self):\n        faces = ['', 'A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']\n        return f'{self.suite}{faces[self.face]}'\n\n\nprint(Card)    # <class '__main__.Card'>\ncard3 = MyCard('方块', 12)\nprint(card3.show())    # 方块Q\nprint(dict(card1._asdict()))    # {'suite': '红桃', 'face': 13}\nprint(card2._replace(suite='方块'))    # Card(suite='方块', face=5)\n```\n\n## 面向对象\n\n继承：将多个类的共同属性和方法封装到一个父类下面，然后在用这些类来继承这个类的属性和方法\n\n封装：将有共同的属性和方法封装到同一个类下面\n\n多态：Python天生是支持多态的。指的是基类的同一个方法在不同的派生类中有着不同的功能\n\n### 新式类和经典类\n\nPython3里只有新式类；Python2里面继承object的是新式类，没有写父类的是经典类\n\n**区别**\n\n- 新式类 保持class与type的统一，对新式类的实例执行`a.__class__`与`type(a)`的结果是一致的\n- 旧式类的`type(a)`返回instance。\n- 多重继承的属性搜索顺序不一样，新式类是采用广度优先搜索，旧式类采用深度优先搜索。\n\n```python\nclass A():\n  def foo1(self):\n     print \"A\"\n\nclass B(A):\n  def foo2(self):\n     pass\n\nclass C(A):\n  def foo1(self):\n     print \"C\"\n\nclass D(B, C):\n  pass\n\n\nd = D()\nd.foo1()\n```\n\n**缺点：**经典类的查找顺序是深度优先的规则，在访问`d.foo1()`的时候,D->B->A,找到了`foo1()`,调用A的`foo1()`，导致C重写的`foo1()`被绕过\n\n### 类方法、类实例方法、静态方法\n\n- 类方法: 是类对象的方法，使用 @classmethod 进行装饰，形参有cls，表示类对象\n- 类实例方法: 是类实例化对象的方法，形参为self，指代对象本身;\n- 静态方法: 是一个任意函数，使用 @staticmethod 进行装饰\n\n  > 实例方法只能通过实例对象调用；\n  >\n  > 类方法和静态方法可以通过类对象或者实例对象调用，\n  >\n  > 使用实例对象调用的类方法或静态方法，最终通过类对象调用。\n\n### 如何判断是函数还是方法？\n\n如果是以函数的形式定义或者是静态方法，一定是函数\n\n如果是类方法，一定是方法。\n\n实例方法是方法，如果类直接调用实例方法，则是函数（直接调用运行是有问题的）。\n\n```python\nfrom types import MethodType,FunctionType\nprint(isinstance(obj.func, FunctionType)) \nprint(isinstance(obj.func, MethodType))  \n```\n\n### 接口类与抽象类\n\n```python\nclass Operate_database():    # 接口类1\n    def query(self, sql):\n        raise NotImplementedError\n\n    def update(self, sql):\n        raise NotImplementedError\n\nfrom abc import ABCMeta,abstractmethod\nclass Operate_database(metaclass=ABCMeta):    # 接口类2\n    @abstractmethod\n    def query(self, sql):\n        pass\n\n    @abstractmethod\n    def update(self, sql):\n        pass\n```\n\n Python 原生仅支持抽象类，不支持接口类，abc模块就是用来实现抽象类的。\n\n若是类中所有的方法都没有实现，则认为这是一个接口，\n\n若是有部分方法实现，则认为这是一个抽象类。\n\n抽象类和接口类都仅用于被继承，不能被实例化.\n\n### 描述符\n\n**一个实现了描述符协议的类就是一个描述符。**\n\n**描述符协议：实现了` __get__()`、`__set__()`、`__delete__() `其中至少一个方法的类，就是一个描述符。**\n\n`__get__`： 用于访问属性。它返回属性的值，若属性不存在、不合法等都可以抛出对应的异常。\n\n`__set__`：将在属性分配操作中调用。\n\n`__delete__`：控制删除操作。\n\n描述符的作用和优势，以弥补Python动态类型的缺点。\n\n```python\nclass Score:\n  def __init__(self, default=0):\n     self._score = default\n\n  def __set__(self, instance, value):\n     if not isinstance(value, int):\n       raise TypeError('Score must be integer')\n\n     if not 0 <= value <= 100:\n       raise ValueError('Valid value must be in [0, 100]')\n\n     self._score = value\n\n  def __get__(self, instance, owner):\n     return self._score\n\n  def __delete__(self):\n     del self._score    \n\nclass Student:\n  math = Score(0)\n  chinese = Score(0)\n  english = Score(0)\n\n  def __init__(self, name, math, chinese, english):\n     self.name = name\n     self.math = math\n     self.chinese = chinese\n     self.english = english\n```\n\n**staticmethod**\n\n```python\nclass Test:\n  @staticmethod\n  def myfunc():\n     print(\"hello\")\n\n# 上下两种写法等价\nclass Test:\n  def myfunc():\n     print(\"hello\")\n  # 重点：这就是描述符的体现\n  # 每调用一次，它都会经过描述符类的 __get__\n  myfunc = staticmethod(myfunc)\n```\n\n**classmethod**\n\n```python\nclass classmethod(object):\n  def __init__(self, f):\n     self.f = f\n  def __get__(self, instance, owner=None):\n     print(\"in classmethod __get__\")\n     def newfunc(*args):\n       return self.f(owner, *args)\n     return newfunc\n\nclass Test:\n  def myfunc(cls):\n     print(\"hello\")\n  # 重点：这就是描述符的体现\n  myfunc = classmethod(myfunc)\n```\n\n### 元类\n\n**元类是用来创建类的类。**\n\n如果类属性中定义了`__metaclass__`，则在创建类的时候用元类来创建；\n\n如果没有则向其父类查找`__metaclass__`。\n\n如果都没有，则用`type()`创建类。\n\n```python\n# metaclass是类的模板，所以必须从`type`类型派生：\nclass ListMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs['add'] = lambda self, value: self.append(value)\n        return type.__new__(cls, name, bases, attrs)\n    \nclass MyList(list, metaclass=ListMetaclass):\n    pass\n```\n\n传入关键字参数`metaclass`时，指示Python解释器在创建`MyList`时，要通过`ListMetaclass.__new__()`来创建\n\n在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。\n\n`__new__()`方法接收到的参数依次是：\n\n1. 当前准备创建的类的对象；\n2. 类的名字；\n3. 类继承的父类集合；\n4. 类的方法集合。\n\n**元类作用**\n\n- 拦截类的创建\n- 修改类\n- 返回修改后的类\n\n**应用场景**\n\nORM：所有的类都只能动态定义，因为只有使用者才能根据表的结构定义出对应的类来。\n\n## 字典\n\n字典的查询、添加、删除的平均时间复杂度都是`O(1)`。因为字典是通过哈希表来实现的.\n\n- 计算key的hash值`hash(key)`，再和mask做与操作【mask=字典最小长度（DictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的enteies哈希表中的下标位置\n\n- 若index下标位置已经被占用，则会判断enteies的key是否与要插入的key是否相等\n\n  - 如果key相等就表示key已存在，则更新value值\n\n  - 如果key不相等，就表示hash冲突，则会继续向下寻找空位置，一直到找到剩余空位为止。\n\n### **开放寻址法**\n\n开放寻址法中，所有的元素都存放在散列表里，当产生哈希冲突时，通过一个探测函数计算出下一个候选位置，如果下一个获选位置还是有冲突，不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。\n\n> 开放寻址法中解决冲突的方法有：线行探查法、平方探查法、双散列函数探查法\n\n采用哈希表，dict的哈希表里每个slot都是一个自定义的entry结构：\n\n```c\ntypedef struct {\n   Py_ssize_t me_hash;\n   PyObject *me_key;\n   PyObject *me_value;\n} PyDictEntry;\n```\n\n每个entry有三种状态Active, Unused, Dummy。\n\n- Unused:me_key == me_value == NULL，即未使用的空闲状态。\n\n- Active:me_key != NULL, me_value != NULL，即该entry已被占用\n\n- Dummy:me_key == dummy, me_value == NULL。\n\n**为什么entry有Dummy状态呢？**\n\n用开放寻址法中，**遇到哈希冲突时会找到下一个合适的位置，**例如ABC构成了探测链，查找元素时如果hash值相同，那么也是**顺着这条探测链不断往后找**，当删除探测链中的某个元素时，如果直接把B从哈希表中移除，即变成Unused状态，那么C就不可能再找到了，因此需要Dummy保证探测链的连续性。\n\ndict对象的定义为：\n\n```c\nstruct _dictobject {\n  PyObject _HEAD\n  Py_ssize_t ma_fill; /* # Active + # Dummy */\n  Py_ssize_t ma_used; /* # Active */\n  Py_ssize_t ma_mask; //slot -1\n  PyDictEntry *ma_table;\n  PyDictEntry *(*ma_lookup)(PyDictObject *mp, PyObject *key, long hash); // 搜索函数指针\n  PyDictEntry ma_smalltable[PyDict_MINSIZE]; //默认的slot\n};\n```\n\n### **dict对象的创建**\n\ndict对象的创建很简单，先看看缓冲的对象池里有没有可用对象，如果有就直接用，没有就从堆上申请。\n\n### **dict对象的插入**\n\n如果不存在key-value则插入，存在则覆盖。\n\n- 生成Hash\n- 如果可用的entry<0，字典扩容\n- 基于key、hash，查找可用哈希位置，以便于存储\n  - 字典中是否有空余的值，或者如果找到了满足 hash 值与 key 相同的,就将 value 设置为找到的值\n- 保存key、Hash、value值\n\n### **dict对象的删除**\n\n算出哈希值，找到entry，将其从Active转换成Dummy，并调整table的容量。\n\n**注意**\n\n（1） dict的key 或者 set的值都必须是可hash的不可变对象，都是可hash的\n\n（2）当发现内存空间中的“空”只有1/3时，便会触发扩容操作。\n\n## 整数\n\nPython使用**小整数对象池**small_ints缓存了[-5，257）之间的整数，该范围内的整数在Python系统中是共享的，值相同就属于同一个对象。\n\n对于同一个代码块中值不在`small_ints`缓存范围内的整数，如果同一个代码块中已经存在一个值与其相同的整数对象，那么就直接引用该对象，否则创建新的`int`对象。\n\n## 字符串\n\nPython解释器中使用了 intern（字符串驻留）的技术来提高字符串效率，值同样的字符串对象仅仅会保存一份，放在一个字符串储蓄池中，是共用的。\n\n**简单原理**\n\n维护一个字符串存储池，这个池子是一个字典结构\n\n如果字符串已经存在于池子中，直接返回之前创建好的字符串对象，\n\n如果不存在，则构造一个字符串对象并加入到池子中去。\n\n> 在shell中，并非全部的字符串都会采用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。不能超过20个字符。因为如果超过xx个字符的话，解释器认为这个字符串不常用，不用放入字符串池中。\n>\n> 字符串拼接时，运行时拼接，不会intern；例如\"hell\" + \"o\"在编译时完成拼接的才会intern\n\n## 堆 栈\n\n在Python中，变量也称为：对象的引用。变量存储的就是对象的地址。\n\n**变量位于：栈内存。**\n\n**对象位于：堆内存。**\n\n内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。\n\n**代码区：**程序中的代码数据、二进制数据、方法数据等等程序运行需要的预加载数据。\n\n**静态数据区：**存储**全局变量、静态变量**。\n\n**栈区：**存储变量。存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。\n\n**堆区**：对象真实数据。\n\n## 内存回收机制\n\npython采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略。\n\n###  **引用计数法**\n\n**原理：**每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数加1，每当该对象的引用失效时，计数减1，一旦对象的引用计数为0，该对象立即被回收，占用的内存空间将被释放。\n\n**缺点：**不能解决对象的循环引用\n\n### 标记清除\n\n解决容器对象可能产生的循环引用问题。（只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等）\n\n**A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达**；\n\nB）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。\n\n### 分代回收\n\n标记清除时，应用程序会被暂停，为了减少应用程序暂停的时间。\n\n**对象存在时间越长，越可能不是垃圾，应该越少去收集**。\n\n给对象定义了三种世代，每一个新生对象在0代中，如果它在一轮gc扫描中活了下来，那么它将被移至1代，在那里他将较少的被扫描，如果它又活过了一轮gc，它又将被移至2代，在那里它被扫描的次数将会更少。\n\n### **gc的扫描在什么时候会被触发呢**?\n\n年轻代链表的总数达到上限时。\n\n当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。\n\n### **调优手段**\n\n1.手动垃圾回收\n\n2.调高垃圾回收阈值\n\n3.避免循环引用\n\n## 退出Python时，是否释放全部内存？\n\n进程退出的时候，资源最终都会释放掉，这是操作系统负责的。\n\n如果是一段程序运行结束之后：\n\n1. CPython会通过引用计数立即释放引用数量为0的对象（其它版本解释器并不保证）；循环引用的对象会在下一次GC时释放，除非有两个对象都带有`__del__`析构函数，且直接或间接循环引用。这种情况下，所有循环引用的对象都无法被释放。原因在于无法确定`__del__`的执行顺序。\n2. 全局引用的对象无法被回收，但也不只是模块中直接或间接保存的对象，还包括未退出的线程使用的对象，解释器缓存的小整数和字符串，还有C模块里间接引用的对象等等。\n3. C扩展直接通过malloc分配的内存自然无法通过gc来回收，但一般如果存在没有被回收的内存说明是有内存泄漏的，这属于实现的bug\n\n## 协程，线程和进程\n\n### 进程\n\n进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。在Python中，进程适合计算密集型任务。\n\n#### 进程间的通信（IPC）\n\n**1）管道（Pipe**）：通过`send()`和`recv()`来发送和接受信息，适合父子进程关系或者两个子进程之间。 \n\n2）**有名管道（FIFO）**：有名管道也是半双工的通信方式。 将自己注册到文件系统里一个文件，通过读写这个文件进行通信。允许在没有亲缘关系的进程之间使用。要求读写双方必须同时打开才可以继续进行读写操作，否则打开操作会堵塞直到对方也打开。\n\n3）**信号量（Semaphore）**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 创建子进程时将信号量my_semaphore作为参数传入子进程任务函数，子进程中使用semaphore.acquire() 尝试获取信号量，semaphore.release()尝试 释放信号量。\n\n**4）队列（Queue）**。 使用get/put在父子进程关系或者两个子进程之间通信。\n\n5）**信号 （signal）**：用于通知接收进程某个事件已经发生，可以设置信号处理函数。 \n\n6）共享内存（shared memory）：操作系统负责将同一份物理地址的内存映射到多个进程的不同的虚拟地址空间中。进而每个进程都可以操作这份内存。需要在进程访问时做好并发控制，比如使用信号量。 python标准库mmap，apache开源的pyarrow都是。\n\n7）套接字（socket）：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。 \n\n**8）文件** \n\n（1）仅进程同步不涉及数据传输，可以使用信号、信号量；\n（2）若进程间需要传递少量数据，可以使用管道、有名管道、队列；\n（3）若进程间需要传递大量数据，最佳方式是使用共享内存，推荐使用pyarrow，这样减少数据拷贝、传输的时间内存代价；\n（4）跨主机的进程间通信（RPC）可以使用socket通信。\n\n**共享变量**\n\n使用 Process 定义的多进程之间（父子或者兄弟）共享变量可以直接使用 multiprocessing 下的 Value，Array，Queue 等，如果要共享 list，dict，可以使用强大的 Manager 模块。\n\n###  线程\n\n线程是cpu调度执行的最小单位，依赖进程存在，一个进程至少有一个线程。在python中，线程适合IO密集型任务。\n\n同一个进程下的线程共享程序的内存空间**（如代码段，全局变量，堆栈等）**\n\n#### 使用\n\n继承Thread，重写run方法，通过start方法开线程\n\n将要执行的方法作为参数传给Thread的构造方法\n\n#### 状态\n\n线程有五种状态:创建、就绪、运行、阻塞、死亡。 \n\n- 调用start方法时，线程就会进入就绪状态。 \n\n- 在线程得到cpu时间片时进入运行状态。 \n\n- **线程调用yield方法可以让出cpu时间回到就绪状态**。 \n\n- 线程运行时可能**由于IO、调用sleep、wait、join方法或者无法获得同步锁等原因进入阻塞**状态。 \n\n- 当线程获得到等待的资源资源或者引起阻塞的条件得到满足时，会从阻塞状态进入就绪状态。 \n\n- 当线程的run方法执行结束时，线程就进入死亡状态。\n\n#### 锁\n\n多个线程同时对一个公共资源（如全局变量）进行操作的情况，为了避免发生混乱。`threading.lock`，`acquire()`方法上锁，`release()`方法解锁\n\n可重入锁：为了支持在同一线程中多次请求同一资源，python提供了threading.RLock。重入锁必须由获取它的同一个线程释放，同时要求解锁次数应与加锁次数相同，才能用于另一个线程。\n\n#### 同步\n\n阻塞线程直到子线程全部结束。\n\n#### 守护线程\n\n不重要线程。主线程会等所有‘重要’线程结束后才结束。\n\n#### 线程池的工作原理\n\n减少线程本身创建和销毁造成的开销，属于典型的空间换时间操作。\n\n创建和释放线程涉及到大量的系统底层操作，开销较大，如果变成预创建和借还操作，将大大减少底层开销。\n\n- 在应用程序启动后，线程池创建一定数量的线程，放入空闲队列中。这些线程最开始都处于阻塞状态，不会消耗CPU，占用少量的内存。\n- 当任务到来后，从队列中取出一个空闲线程，把任务派发到这个线程中运行，并将标记为已占用。\n- 当线程池中所有的线程都被占用后，可以选择自动创建一定数量的新线程，用于处理更多的任务，也可以选择让任务排队等待直到有空闲的线程可用。\n- 在任务执行完毕后，线程并不退出结束，而是继续保持在池中等待下一次的任务。\n- 当系统比较空闲时，大部分线程长时间处于闲置状态时，线程池可以自动销毁一部分线程，回收系统资源。\n\n线程池组成部分：\n\n1. 线程池管理器：用于创建并管理线程池。\n2. 工作线程和线程队列：线程池中实际执行的线程以及保存这些线程的容器。\n3. 任务接口：将线程执行的任务抽象出来，形成任务接口，确保线程池与具体的任务无关。\n4. 任务队列：线程池中保存等待被执行的任务的容器。\n\n###  协程\n\n协程是一种用户态的轻量级线程，调度完全由用户控制。\n\n协程拥有自己的寄存器上下文和栈。协程的切换都在用户空间内进行，不需要进行系统调用。\n\n协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，基本没有内核切换的开销，可以不加锁的访问全局变量，上下文的切换非常快。\n\n\n\n**如何利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能**。\n\n**常用模块**\n\ngreenlet：提供了切换任务的快捷方式，但是遇到io无法自动切换任务，需要手动切换\n\ngevent：开启协程任务并切换的模块，遇到io自动切换任务。\n\nasyncio：`@asyncio.coroutine`装饰器的函数称为协程函数。\n\n`yield from`语法用于将一个生成器部分操作委托给另一个生成器。\n\n`async`/`await`：`@asyncio.coroutine`和`yield from`的语法糖\n\n**缺点**\n\n- 无法利用多核资源：协程的本质是个单线程\n\n- 进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序\n\n**协程主要使用场景**\n\n网络请求，比如爬虫，大量使用 aiohttp\n\n文件读取， aiofile\n\nweb 框架， aiohttp， fastapi\n\n数据库查询， asyncpg, databases\n\n**协程优于线程**\n\n- python 线程调度方式是，每执行 100 个字节码或者遇到阻塞就停止当前线程，然后进行一个系统调用，让 os 内核选出下一个线程。但是协程 只会在 阻塞的时候，切换到下一个协程。100个字节码，说多不多，说少不少，你调用两个库函数说不定就没了，因此线程的切换存在很多是无效的切换，当线程数量越大，这种因为调度策略的先天不足带来的性能损耗就越大。\n- 线程需要进行系统调用，协程不需要。系统调用需要进入内核态，无效的调度会让这部分开销显得更大\n- 协程可以自主调度，而线程只能决定合适退出，但是下一个线程是谁则依赖于操作系统。\n\n### 僵尸进程和孤儿进程 \n\n孤儿进程： **父进程退出，子进程还在运行的这些子进程都是孤儿进程，**孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。\n\n僵尸进程： 进程使用fork 创建子进程**，如果子进程退出，而父进程并没有调用wait 获取子进程的状态信息**，那么子进程的进程描述符仍然保存在系统中，这些进程是僵尸进程。\n\n避免僵尸进程的方法：\n\n1.用`wait()`函数使父进程阻塞\n\n2.使用信号量，在signal handler 中调用waitpid，这样父进程不用阻塞\n\n**3.fork 两次用孙子进程去完成子进程的任务（？？？）**\n\n##  Global Interpreter Lock(全局解释器锁)\n\nPython 默认的解释器是 CPython，**GIL 是存在于 CPython 解释器中的**。\n\n执行 Python 字节码时，为了保护访问 Python 对象而阻止多个线程执行的一把互斥锁。主要是因为 CPython 解释器的内存管理不是线程安全的。\n\n常见的 Python 解释器：IPython（基于Cython）、IPython、Jython（可以把 Python 代码编译成 Java 字节码，依赖 Java 平台，不存在 GIL）、IronPython（运行在微软的 .Net 平台下的 Python 解释器，可以把 Python 代码编译成 .Net 字节码，不存在 GIL）\n\n### GIL原理\n\npython 的线程就是 C 语言的 pthread，它是通过操作系统调度算法调度执行的。\n\nPython 2.x 的代码执行是基于 opcode 数量的调度方式，简单来说就是每执行一定数量的字节码，或遇到系统 IO 时，会强制释放 GIL，然后触发一次操作系统的线程调度。\n\n Python 3.x 基于固定时间的调度方式，就是每执行固定时间的字节码，或遇到系统 IO 时，强制释放 GIL，触发系统的线程调度。\n\n### 为什么会有GIL\n\nPython 设计者在设计解释器时，可能没有想到 CPU 的性能提升会这么快转为多核心方向发展，所以在当时的场景下，设计一个全局锁是那个时代保护多线程资源一致性最简单经济的设计方案。\n\n多核心时代来临，当大家试图去拆分和去除 GIL 的时候，发现大量库的代码和开发者已经重度依赖 GIL（默认认为 Pythonn内部对象是线程安全的，无需在开发时额外加锁），所以这个去除 GIL 的任务变得复杂且难以实现。\n\n## 性能分析\n\npython 内置了丰富的性能分析工具，**如 profile,cProfile 与 hotshot 等**。其中 Profiler 是 python 自带的一组程序，能够描述程序运行时候的性能，并提供各种统计帮助用户定位程序的性能瓶颈。\n\nPython 标准库提供了同一分析接口的两种不同实现：\n\n1. 建议使用 [`cProfile`](https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile) ；这是一个 C 扩展插件，因为其合理的运行开销，所以适合于分析长时间运行的程序。\n2. [`profile`](https://docs.python.org/zh-cn/3/library/profile.html#module-profile) 是一个纯 Python 模块（[`cProfile`](https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile) 就是模拟其接口的 C 语言实现），但它会显著增加配置程序的开销。如果你正在尝试以某种方式扩展分析器，则使用此模块可能会更容易完成任务\n\n支持输出：调用次数、在指定函数中消耗的总时间（不包括调用子函数的时间）、指定的函数及其所有子函数（从调用到退出）消耗的累积时间、函数运行一次的平均时间\n\n\n\n## 单例模式\n\n### **使用装饰器**\n\n```python\ndef singleton(cls):\n  instances = {}\n  def wrapper(*args, **kwargs):\n     if cls not in instances:\n       instances[cls] = cls(*args, **kwargs)\n     return instances[cls]\n\n  return wrapper\n\n@singleton\nclass Foo(object):\n  pass\n\nfoo1 = Foo()\nfoo2 = Foo()\n\nprint(foo1 is foo2) # True\n```\n\n### 使用new\n\nNew 是真正创建实例对象的方法，所以重写基类的new 方法，以此保证创建对象的时候只生成一个实例。\n\n但是以上的方法在多线程中会有线程安全问题，当有多个线程同时去初始化对象时，就很可能同时判断__instance is None，从而进入初始化instance的代码中。所以需要用**互斥锁**来解决这个问题。\n\n```python\nclass Singleton(object):\n  def __new__(cls, *args, **kwargs):\n     if not hasattr(cls, '_instance'):\n       cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n     return cls._instance\n\n\nclass Singleton(object):\n  __instance = None\n  def __new__(cls, *args, **kwargs):\n     if cls.__instance is None:\n       cls.__instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n     return cls.__instance\n\nclass Foo(Singleton):\n  pass\n\nfoo1 = Foo()\nfoo2 = Foo()\n\nprint(foo1 is foo2) # True\n```\n\n### classmethod\n\n```python\nimport time\nimport threading\nclass Singleton(object):\n     _instance_lock = threading.Lock() \n    def __init__(self):\n        time.sleep(1)        \n    @classmethod\n    def instance(cls, *args, **kwargs):\n        with Singleton._instance_lock: # 加锁\n            if not hasattr(Singleton, '_instance'):\n                Singleton._instance = Singleton(*args, **kwargs)\n            return Singleton._instance\n```\n\n\n\n### 元类\n\n元类是用于创建类对象的类，类对象创建实例对象时一定要调用call方法，因此在调用call时候保证始终只创建一个实例即可，type是python的元类\n\n```python\nclass Singleton(type):\n    def __call__(cls, *args, **kwargs):\n        if not hasattr(cls, '_instance'):\n            cls._instance = super(Singleton, cls).__call__(*args, **kwargs)\n        return cls._instance\n\n\n# Python2\nclass Foo(object):\n\t__metaclass__ = Singleton\n```\n\n### **线程安全装饰器**\n\n ```python\ndef make_synchronized(func):\n    import threading\n    func.__lock__ = threading.Lock()\n\n    # 用装饰器实现同步锁\n    def synced_func(*args, **kwargs):\n        with func.__lock__:\n            return func(*args, **kwargs)\n\n    return synced_func\n\nclass Singleton(object):\n    __instance = None\n\n    @make_synchronized\n    def __new__(cls, *args, **kwargs):\n        if not cls.__instance:\n            cls.__instance = object.__new__(cls)\n        return cls.__instance\n\n    def __init__(self):\n        self.blog = \"blog\"\n ```\n\n### **线程安全--元类**\n\n```python\nimport threading\n\nclass MetaSingleton(type):\n    _instance_lock = threading.Lock()\n    def __call__(cls, *args, **kwargs):\n        if not hasattr(cls, '_instance'):\n            with MetaSingleton._instance_lock:\n                if not hasattr(cls, '_instance'):\n                    cls._instance = super(MetaSingleton, cls).__call__(*args, **kwargs)\n\n        return cls._instance\n    \n  \nclass Singleton(metaclass=MetaSingleton):\n    def __init__(self, name):\n        self.name = name\n```\n\n## select,poll和epoll \n\n select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 \n\n\n\n","source":"_posts/python面试.md","raw":"---\ntitle: python面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-13 19:58:48\npassword:\nsummary:\ntags:\n- interview\ncategories:\n- interview\n---\n\n## 语言特性\n\n解释型语言。Python不需要在运行之前进行编译。\n\n动态语言，不需要声明变量的类型。\n\n适合面向对象的编程，允许类的定义和继承。\n\n## python2和python3区别\n\n- Python2 的默认编码是 ascii，Python 3 默认编码 UTF-8，不需要在文件顶部写 `# coding=utf-8 `。\n- 在Python2 中，字符串有两个类型， unicode和 str，前者表示文本字符串，后者表示字节序列，不过两者并没有明显的界限； Python3  str 表示字符串，byte 表示字节序列。\n- True 和 False 在 Python2 中是全局变量，分别对应 1 和 0，可以指向其它对象。 Python3  True 和 False 变为关键字，不允许再被重新赋值。\n- Python 2中print是特殊语句，Python 3中print是函数，需要加上括号。\n- 在Python 2中，3/2是整数，在Python 3中，浮点数。\n- python2 range返回列表，python3 range中返回可迭代对象，节约内存。\n- Python 2 map函数返回list，Python 3 map函数返回迭代器。\n- python2中的raw_input函数，python3中改名为input函数\n- 在Pyhon3，新增了关键字 nonlcoal，支持嵌套函数中，变量声明为非局部变量。\n\n## Python基础\n\n### 可变数据类型和不可变数据类型\n\n可变数据类型（引用类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址不发生改变。\n\n不可变数据类型（值类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址发生了改变。\n\n可变数据类型：list和dict；\n\n不可变数据类型：int、型float、string和tuple。\n\n### python2中xrange和range的区别\n\n`range()`返回的是一个list对象，而xrange返回的是一个可迭代对象。\n\n`xrange()`则不会直接生成一个list，而是每次调用返回其中的一个值，内存空间使用极少。因而性能非常好。\n\n### 变量的作用域/查找顺序\n\n函数作用域的LEGB顺序\n\nL： local ，局部作用域；\n\nE： enclosing，嵌套的父级函数的局部作用域；\n\nG：global ，全局变量；\n\nB： build-in， 系统固定模块里面的变量。\n\nPython除了def/class/lambda 外，其他如: if/elif/else/ try/except for/while并不能改变其作用域。\n\n### 内置函数\n\n`reduce()` 函数会对参数序列中元素进行累积。\n\n先对数据集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据做函数运算。\n\n```python\ndef add(x, y) :      # 两数相加\n   return x + y\nreduce(add, [1,2,3,4,5])  # 计算列表和：1+2+3+4+5\nreduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数\n```\n\n`filter()` 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。\n\n序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。\n\n```python\ndef is_odd(n):\n  return n % 2 == 1\n\nnewlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprint(newlist)\n```\n\n`map()` 会根据提供的函数对指定序列做映射。\n\n序列中的每一个元素调用 函数，返回包含每次函数返回值的新列表（python2），python3是会返回可迭代对象的。\n\n```python\ndef square(x) :      # 计算平方数\n   return x ** 2\nmap(square, [1,2,3,4,5])  # 计算列表各个元素的平方\n```\n\n`repr() `函数将对象转化为供解释器读取的形式\n\n```python\ndict1 = {'runoob': 'runoob.com', 'google': 'google.com'};\nrepr(dict1)\nstr(dict1)\n\n\"{'google': 'google.com', 'runoob': 'runoob.com'}\"\n```\n\n`vars() `函数返回对象object的属性和属性值的字典对象。\n\n```\nclass Runoob:\n   a = 1\nprint(vars(Runoob))\n{'a': 1, '__module__': '__main__', '__doc__': None}\n```\n\n**ord**\n\n一个长度为1的字符串作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。\n\n#### dir\n\n不带参数时，返回当前范围内的变量、方法和定义的类型列表；\n\n带参数时，返回参数的属性、方法列表。\n\n如果参数包含方法`__dir__()`，该方法将被调用。\n\n#### **isinstance** \n\n`isinstance() `判断一个对象是否是一个已知的类型，`type()`查看一个类型或变量的类型。\n\n`type() `不会认为子类是一种父类类型。`isinstance() `会认为子类是一种父类类型。\n\n#### raw_input、input\n\n1、在 Python2.x 中` raw_input() `和` input()`，两个函数都存在，其中区别为:\n\n- `raw_input()`将所有输入作为字符串看待，返回字符串类型。\n-  `input()` 只能接收“数字”的输入，它返回所输入的数字的类型。\n\n2、在 Python3.x 中 仅保留了`input()` 函数，将所有输入作为字符串处理，并返回字符串类型。\n\n#### sort sorted\n\n**区别**\n\n对于一个无序的列表a，调用`a.sort()`，对a进行排序后返回None，`sort()`函数修改待排序的列表内容。\n\n而对于同样一个无序的列表a，调用`sorted(a)`，对a进行排序后返回一个新的列表，而对a不产生影响。\n\n**sort**\n\ntimsort是结合了合并排序和插入排序而得出的排序算法。该算法找到数据中已经排好序的块-分区，每一个分区叫一个run，然后按规则合并这些run。\n\n为了减少对升序部分的回溯和对降序部分的性能倒退，将输入按其升序和降序特点进行了分区。排序的输入的单位不是一个个单独的数字，而是一个个的块-分区。其中每一个分区叫一个run。针对这些 run 序列，每次拿一个 run 出来按规则进行合并。每次合并会将两个 run合并成一个 run。合并的结果保存到栈中。合并直到消耗掉所有的 run，这时将栈上剩余的 run合并到只剩一个 run 为止。这时这个仅剩的 run 便是排好序的结果。\n\n（0）数组长度小于某个值，直接用二分插入排序算法\n\n（1）找到各个run，并入栈\n\n（2）按规则合并run\n\n0：有序部分的长度一般不会太长，当小于 minRun 时，会将此部分后面的元素插入其中，直至长度满足 minRun。通过二分法查找元素\n\n2：会将该run在数组中的起始位置和run的长度放入栈中，然后根据先前放入栈中的run决定是否该合并run。Timsort不会合并在栈中不连续的run\n\n先用二分查找算法/折半查找算法（binary search）找到插入的位置，然后在插入。\n\n   例如，我们要将A和B这2个run 合并，且A是较小的run。因为A和B已经分别是排好序的，二分查找会找到B的第一个元素在A中何处插入。同样，A的最后一个元素找到在B的何处插入，找到以后，B在这个元素之后的元素就不需要比较了。这种查找可能在随机数中效率不会很高，但是在其他情况下有很高的效率。\n\n### 魔法方法\n\n在特殊的情况下被Python所调用的方法。\n\n`__init__`构造器，当一个实例被创建的时候用于初始化的方法。\n\n`__new__`实例化对象调用的第一个方法，用来创造一个类的实例的，取下cls参数，把其他参数传给`__init__`.\n\n`__call__`让一个类的实例像函数一样被调用\n\n`__getitem__`定义获取容器中指定元素的行为，相当于`self[key]`\n\n`__getattr__`定义当用户试图访问一个不存在属性的时候的行为\n\n`__setattr__`定义当一个属性被设置的时候的行为\n\n`__getattribute___`定义当一个属性被访问的时候的行为\n\n`__del__`删除对象执行的方法\n\n`__str__`强调可读性，面向用户；而`__repr__`强调标准性，面向机器\n\n%s调用`__str__`方法，而%r调用`__repr__`方法\n\n`__repr__`在表示类时，是一级的，如果只定义它，那么`__str__` = `__repr__`。\n\n```python\nclass Callable:\n  def __call__(self, a, b):\n     return a + b\n\n\nfunc = Callable() \nresult = func(2, 3) # 像函数一样调用\nprint(result)\n```\n\n### new & init区别\n\n1、`__new__`有参数cls，代表当前类，从而产生一个实例；`__new__`必须要有返回值，返回实例化出来的实例，可以return父类（`super(当前类名, cls)`）`__new__`出来的实例，或object的`__new__`出来的实例\n\n2、`__init__`有参数self，完成一些初始化的动作，`__init__`不需要返回值\n\n3、如果`__new__`创建的是当前类的实例，会自动调用`__init__`（return语句里面调用的`__new__`函数的第一个参数是cls，保证是当前类实例）；如果`__new__`返回一个已经存在的实例，`__init__`不会被调用。\n\n4、如果我们在`__new__`函数中不返回任何对象，则`__init__`函数也不会被调用。\n\n> Python的旧类中实际上并没有`__new__`方法。因为旧类中的`__init__`实际上起构造器的作用\n\n### 字符串\n\n避免转义，给字符串加r表示原始字符串。\n\n### is 和 ==区别\n\nis：比较俩对象是否为同一个实例对象，是否指向同一个内存地址。\n\n== ： 比较的两个对象的内容/值是否相等，默认会调用对象的`eq()`方法\n\n### set去重\n\nset的去重是通过两个函数`__hash__`和`__eq__`结合实现的。\n\n1、当两个变量的哈希值不相同时，就认为这两个变量是不同的\n\n2、当两个变量哈希值一样时，调用`__eq__`方法，当返回值为True时认为这两个变量是同一个。返回FALSE时，不去重。\n\n### list切片\n\n索引操作本身基于`__getitem__`和`__setitem__`\n\npython向`__getitem__`传入了一个`slice`的对象，这个类有start, stop, step三个属性，缺省值都是None。\n\n```python\na = [1,2,3,4,5,6]\nx = a [1: 5]        # x = a.__getitem__(slice( 1, 5, None))\na [1: 3] = [10, 11, 12]  # a.__setitem__(slice(1, 3, None), [ 10, 11, 12 ])\ndel a [1: 4]        # a.__delitem__(slice(1, 4, None))\n```\n\n### 三元算子\n\n`[on true] if [expression] else [on false]`\n\n### pass\n\n1、一般作为占位符或者创建占位程序，pass语句不会执行任何操作\n\n2、保证格式、语义完整 \n\n### lambda\n\n创建匿名函数的一个特殊语法,即用即仍，\n\n1.一般用来给filter，map这样的函数式编程服务\n\n2.作为回调函数\n\n### 迭代器和生成器\n\n#### 迭代器\n\n**迭代器协议**： `__iter__()` 返回一个特殊的迭代器对象， 这个迭代器对象实现了 `__next__()` 并通过 `StopIteration` 异常，标识迭代的完成。\n\n**迭代器对象**：实现了迭代器协议的对象/被`next()`函数调用并不断返回下一个值的对象称为迭代器。\n\n**例子**\n\nPython的内置工具（如for循环，sum，min，max函数等）使用迭代器协议访问对象\n\n#### 生成器\n\n**使用了 yield 的函数被称为生成器**。**只要把一个列表生成式的`[]`改成`()`，就创建了一个生成器**\n\n生成器是一种特殊的迭代器，生成器自动实现了“迭代器协议”。\n\n生成器在迭代的过程中可以改变当前迭代值，而修改普通迭代器的当前迭代值往往会发生异常，影响程序的执行。\n\n#### 可迭代对象\n\n实现`__iter__`方法的对象。可迭代对象包含文件对象、序列（字符串、列表、元组、集合）、字典。\n\n#### 判断方法\n\n```python\nfrom collections import Iterable, Iterator\nfrom inspect import isgenerator\n\nisinstance(a, Iterable)\nisinstance(a, Iterator)\nisgenerator(a)\n```\n\n### 装饰器\n\n装饰器本质上是一个**Python函数或者类**，让其他函数在不做任何代码变动，从而增加额外功能，装饰器的返回值也是一个函数对象。\n\n场景：**插入日志**、性能测试、**事务处理**、缓存、**权限校验、异常处理**。\n\n```python\nimport functools\n\ndef add(a, b):\n  print(a + b)\n \nadd  = functools.partial(add, 1)\n# 输出：3\nadd(2)\n```\n\n经过partial包装之后，a参数的值被固定为了1，新的add对象（注意此处add已经是一个可调用对象）只需要接收一个参数即可。\n\n**把原函数的部分参数固定了初始值，新的调用只需要传递其它参数。**\n\n`@functools.wraps(func)`底层逻辑，就是把wrapped函数的属性拷贝到wrapper函数中。\n\n```python\ndef outer(func):\n  @functools.wraps(func)\n  def inner(*args, **kwargs):\n     print(f\"before...\")\n     func(*args, **kwargs)\n     print(\"after...\")\n  return inner\n\n@outer\ndef add(a, b):\n  \"\"\"\n  求和运算\n  \"\"\"\n  print(a + b)\n```\n\n1、原函数为add。\n\n2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。\n\n3、执行outer函数时，加载inner函数，此时会直接执行`functools.wraps(func)`返回一个可调用对象，即partial对象。\n\n4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。\n\n5、把add指向inner函数。\n\n6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。\n\n **总结**\n\n1）functools.wraps 旨在消除装饰器对原函数造成的影响，即对原函数的相关属性进行拷贝。\n\n2）wraps内部通过partial对象和update_wrapper函数实现。\n\n3）partial是一个类，通过实现`__new__`，**自定义实例化对象过程，使得对象内部保留原函数和固定参数**，通过实现`__call__`，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。\n\n#### **类装饰器**\n\n类装饰器具有**灵活度大、高内聚、封装性**等优点。\n\n依靠`__call__`方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。\n\n```python\nclass Foo(object):\n  def __init__(self, func):\n     self._func = func\n\ndef __call__(self):\n   print ('class decorator runing')\n   self._func()\n   print ('class decorator ending')\n\n@Foo\ndef bar():\n  print ('bar')\n\nbar()\n```\n\n### property\n\n让方法像属性一样使用\n\n```python\nproperty([fget[, fset[, fdel[, doc]]]])\nfdel = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\nfget = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\nfset = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\n\nclass C(object):\n  def __init__(self):\n     self._x = None\n \n  def getx(self):\n    return self._x\n\n  def setx(self, value):\n    self._x = value\n\n  def delx(self):\n    del self._x\n\n  x = property(getx, setx, delx, \"I'm the 'x' property.\")\n```\n\nproperty 的 getter,setter 和 deleter 方法同样可以用作装饰器：\n\n```python\nclass C(object):\n\n  def __init__(self):\n     self._x = None\n\n  @property\n  def x(self):\n     \"\"\"I'm the 'x' property.\"\"\"\n     return self._x\n\n  @x.setter\n  def x(self, value):\n     self._x = value\n\n  @x.deleter\n  def x(self):\n     del self._x\n```\n\n使用property装饰后，x不再是一个函数，而是property类的一个实例。所以第二个函数可以使用 x.setter 来装饰，本质是调用property.setter 来产生一个新的 property实例赋值给第二个x。\n\n第一个 x和第二个 x 是两个不同 property实例。但他们都属于同一个描述符类（property），当赋值时，就会进入 `property.__set__`，取值时，就会进入 `property.__get__`。\n\n### 参数类型\n\n**位置参数：**传参数时，按照顺序，依次传值。\n\n**默认参数：**参数提供默认值。默认参数一定要指向不变对象。\n\n**可变参数：**可变参数就是传入的参数个数是可变的。特征：*args\n\n**关键字参数：**允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。特征：**kw\n\n**命名关键字参数：**如果要限制关键字参数的名字，就可以用命名关键字参数。特征：命名关键字参数需要一个特殊分隔符`*`，而后面的参数被视为命名关键字参数。如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要特殊分隔符了\n\n参数定义的**顺序**必须是：位置参数–>默认参数–>可变参数–>命名关键字参数–>关键字参数\n\n### zip\n\n拉链函数， 将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表迭代器。\n\n如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同。\n\n```python\nprint(list(zip([0,1,3],[5,6,7],['a','b'])))\n[(0, 5, 'a'), (1, 6, 'b')]\n```\n\n### and 和or\n\n 在不加括号时候, and优先级大于or \n\nx or y：x为真是x, x为假是y \n\nx and y ： x为真就是y, x为假就是x\n\n```python\nv = 1 and 2 or 3 and 4 \nprint(v) # 2\n```\n\n### for 循环\n\n**通过调用`iter()`方法执行（字符串，元组，字典，集合，文件）对象内部的`__iter__`方法，获取一个迭代器，然后使用迭代器协议去实现循环访问，**当元素循环完时，会触发StopIteration异常，for循环会捕捉到这种异常，终止迭代\n\n### 深拷贝和浅拷贝\n\n浅拷贝：在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素地址的拷贝。也就是说新的容器中指向了旧的元素（ 新瓶装旧酒 ）。\n\n深拷贝：在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。（ 新瓶装新酒 ）。\n\n1、复制不可变数据类型， copy /deepcopy，都指向原地址对象\n\n2、复制的值是可变对象\n\n**浅拷贝copy有两种情况：**\n\n复制对象中包含的非可变数据类型：改变值，会开辟新的内存，有新的引用。原来值的改变并不会影响浅复制的值。\n\n复制对象中包含的可变数据类型：改变原来的值，会影响浅复制的值。\n\n**深拷贝deepcopy**\n\n完全复制独立，包括内层列表和字典\n\n### 参数传递\n\n**值传递：**实参把值传递给形参，形参的改变不影响实参值。\n\n**引用传递（地址传递）：**把实参地址传递形参，形参值的改变会影响实参的值。\n\n- 函数中修改字典某一个键值对是有效的\n- 函数中交换两个字典并无法生效\n\n因此不是严格意义上的引用传递，而是**基于引用地址的值传递**，传递的是对象地址的拷贝。\n\n### 闭包\n\n**高阶函数**：函数为入参，或者函数作为返回结果。\n\n**闭包**：在外函数中定义了内函数，内函数里使用了外函数的临时变量，并且外函数的返回值是内函数的引用。\n\n```python\ndef timer(func):\n  def wrapper(*args, **kwargs):\n     start = time.time()\n     func(*args, **kwargs) #此处拿到了被装饰的函数func\n     time.sleep(2)#模拟耗时操作\n     long = time.time() - start\n      print(f'共耗时{long}秒。')\n  return wrapper #返回内层函数的引用\n\n@timer\ndef add(a, b):\n  print(a+b)\n \nadd(1, 2) #正常调用add\n```\n\n**模块加载**\n\n-  遇到@，执行timer函数，传入add函数 \n-  生成`timer.<locals>.wrapper`函数并命名为add，其实是覆盖了原同名函数 \n-  调用`add(1, 2) `\n-  去执行`timer.<locals>.wrapper(1, 2) `\n-  wrapper内部持有原add函数引用`(func)`，调用`func(1, 2) `\n-  继续执行完wrapper函数\n\n**带参数的装饰器**\n\n```python\ndef auth(permission):\n  def _auth(func):\n     def wrapper(*args, **kwargs):\n       print(f\"验证权限[{permission}]...\")\n       func(*args, **kwargs)\n       print(\"执行完毕...\")\n     return wrapper\n  return _auth\n\n@auth(\"add\")\ndef add(a, b):\n  \"\"\"\n  求和运算\n  \"\"\"\n  print(a + b)\n```\n\n真正调用的是装饰后生成的新函数。\n\n为了消除装饰器对原函数的影响，需要伪装成原函数，拥有原函数的属性。可以利用functools：\n\n```python\ndef auth(permission):\n  def _auth(func):\n     @functools.wraps(func) # 注意此处\n     def wrapper(*args, **kwargs):\n       print(f\"验证权限[{permission}]...\")\n       func(*args, **kwargs)\n       print(\"执行完毕...\")\n     return wrapper\n  return _auth\n\n@auth(\"add\")\ndef add(a, b):\n  \"\"\"\n  求和运算\n  \"\"\"\n  print(a + b)\n```\n\n#### 特殊例子\n\n```python\ndef multi():\n  return [lambda x : i*x for i in range(4)]\n\nprint([m(3) for m in multi()]) # [9,9,9,9]\n```\n\n闭包的延迟绑定导致的，在**闭包中的变量是在内部函数被调用的时候被查找的**，最后函数被调用的时候，for循环已经完成， i 的值最后是3，因此每一个返回值的i都是3，所以最后的结果是[9,9,9,9]\n\n```python\n# [0, 3, 6, 9]\ndef multipliers():\n  for i in range(4):\n     yield lambda x: i *x\n```\n\n### 上下文管理\n\n在一个类里，实现了`__enter__`和`__exit__`的方法，这个类的实例就是一个上下文管理器。\n\n**基本使用语法**\n\n```pyt\nwith EXPR as VAR:\n    BLOCK\n```\n\n**为什么要使用上下文管理器？**\n\n一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接；处理异常；\n\n**使用contextlib**\n\n```python\nimport contextlib\n\n@contextlib.contextmanager\ndef open_func(file_name):\n    # __enter__方法\n    print('open file:', file_name, 'in __enter__')\n    file_handler = open(file_name, 'r')\n\n    try:\n        yield file_handler\n    except Exception as exc:\n        # deal with exception\n        print('the exception was thrown')\n    finally:\n        print('close file:', file_name, 'in __exit__')\n        file_handler.close()\n\n        return\n\nwith open_func('/Users/MING/mytest.txt') as file_in:\n    for line in file_in:\n        1/0\n        print(line)\n```\n\n### 编码和解码\n\n#### 编码类型\n\n- ascii ：一个字节表示一个字符，最多只能表示 256 个符号。\n- unicode： 所有字符需要2个字节表示\n- gbk：英文字符1个字节，中文字符两个字节\n- utf-8：英文字符1个字节、 欧洲字符2个字节， 亚洲字符3个字节\n\npython2 的默认编码方式为ASCII码，python3默认的文件编码是UTF-8\n\nPython的字符串类型是`str`，在内存中以Unicode表示。\n\n> 如果我们从网络或磁盘上读取了字节流，那么读到的数据就是`bytes`。要把`bytes`变为`str`，就需要用`decode()`方法；\n>\n> 如果要在网络上传输，或者保存到磁盘上，就需要把`str`变为以字节为单位的`bytes`\n\n### pickling和unpickling？\n\n模块 pickle 实现了对一个 Python 对象结构的二进制序列化和反序列化。\n\n \"pickling\" 是将 Python 对象及转化为一个字节流的过程\n\n\"unpickling\" 将字节流转化回一个对象层次结构。\n\nPickle 协议和 JSON 间有着本质的**不同**：\n\n- JSON 是一个文本序列化格式，而 pickle 是一个二进制序列化格式；\n- JSON 是我们可以直观阅读的，而 pickle 不是；\n- JSON在Python之外广泛使用，而pickle则是Python专用的；\n- JSON 只能表示 Python 内置类型的子集，不能表示自定义的类；但 pickle 可以表示大量的 Python 数据类型。\n\n### 说一下`namedtuple`的用法和作用\n\n只有属性没有方法的类，用于组织数据，称为数据类。\n\n在Python中可以用`namedtuple`（命名元组）来替代这种类。\n\n```python\nfrom collections import namedtuple\n\nCard = namedtuple('Card', ('suite', 'face'))\ncard1 = Card('红桃', 13)\ncard2 = Card('草花', 5)\nprint(f'{card1.suite}{card1.face}')\nprint(f'{card2.suite}{card2.face}')\n```\n\n命名元组与普通元组一样是不可变容器，一旦将数据存储在`namedtuple`的顶层属性中，数据就不能再修改了，\n\n对象上的所有属性都遵循“一次写入，多次读取”的原则。\n\n和普通元组不同的是，命名元组中的数据有访问名称，可以通过名称而不是索引来获取保存的数据\n\n命名元组的本质就是一个类，所以它还可以作为父类创建子类。\n\n除此之外，命名元组内置了一系列的方法，例如，可以通过`_asdict`方法将命名元组处理成字典，也可以通过`_replace`方法创建命名元组对象的浅拷贝。\n\n```python\nclass MyCard(Card):\n    \n    def show(self):\n        faces = ['', 'A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']\n        return f'{self.suite}{faces[self.face]}'\n\n\nprint(Card)    # <class '__main__.Card'>\ncard3 = MyCard('方块', 12)\nprint(card3.show())    # 方块Q\nprint(dict(card1._asdict()))    # {'suite': '红桃', 'face': 13}\nprint(card2._replace(suite='方块'))    # Card(suite='方块', face=5)\n```\n\n## 面向对象\n\n继承：将多个类的共同属性和方法封装到一个父类下面，然后在用这些类来继承这个类的属性和方法\n\n封装：将有共同的属性和方法封装到同一个类下面\n\n多态：Python天生是支持多态的。指的是基类的同一个方法在不同的派生类中有着不同的功能\n\n### 新式类和经典类\n\nPython3里只有新式类；Python2里面继承object的是新式类，没有写父类的是经典类\n\n**区别**\n\n- 新式类 保持class与type的统一，对新式类的实例执行`a.__class__`与`type(a)`的结果是一致的\n- 旧式类的`type(a)`返回instance。\n- 多重继承的属性搜索顺序不一样，新式类是采用广度优先搜索，旧式类采用深度优先搜索。\n\n```python\nclass A():\n  def foo1(self):\n     print \"A\"\n\nclass B(A):\n  def foo2(self):\n     pass\n\nclass C(A):\n  def foo1(self):\n     print \"C\"\n\nclass D(B, C):\n  pass\n\n\nd = D()\nd.foo1()\n```\n\n**缺点：**经典类的查找顺序是深度优先的规则，在访问`d.foo1()`的时候,D->B->A,找到了`foo1()`,调用A的`foo1()`，导致C重写的`foo1()`被绕过\n\n### 类方法、类实例方法、静态方法\n\n- 类方法: 是类对象的方法，使用 @classmethod 进行装饰，形参有cls，表示类对象\n- 类实例方法: 是类实例化对象的方法，形参为self，指代对象本身;\n- 静态方法: 是一个任意函数，使用 @staticmethod 进行装饰\n\n  > 实例方法只能通过实例对象调用；\n  >\n  > 类方法和静态方法可以通过类对象或者实例对象调用，\n  >\n  > 使用实例对象调用的类方法或静态方法，最终通过类对象调用。\n\n### 如何判断是函数还是方法？\n\n如果是以函数的形式定义或者是静态方法，一定是函数\n\n如果是类方法，一定是方法。\n\n实例方法是方法，如果类直接调用实例方法，则是函数（直接调用运行是有问题的）。\n\n```python\nfrom types import MethodType,FunctionType\nprint(isinstance(obj.func, FunctionType)) \nprint(isinstance(obj.func, MethodType))  \n```\n\n### 接口类与抽象类\n\n```python\nclass Operate_database():    # 接口类1\n    def query(self, sql):\n        raise NotImplementedError\n\n    def update(self, sql):\n        raise NotImplementedError\n\nfrom abc import ABCMeta,abstractmethod\nclass Operate_database(metaclass=ABCMeta):    # 接口类2\n    @abstractmethod\n    def query(self, sql):\n        pass\n\n    @abstractmethod\n    def update(self, sql):\n        pass\n```\n\n Python 原生仅支持抽象类，不支持接口类，abc模块就是用来实现抽象类的。\n\n若是类中所有的方法都没有实现，则认为这是一个接口，\n\n若是有部分方法实现，则认为这是一个抽象类。\n\n抽象类和接口类都仅用于被继承，不能被实例化.\n\n### 描述符\n\n**一个实现了描述符协议的类就是一个描述符。**\n\n**描述符协议：实现了` __get__()`、`__set__()`、`__delete__() `其中至少一个方法的类，就是一个描述符。**\n\n`__get__`： 用于访问属性。它返回属性的值，若属性不存在、不合法等都可以抛出对应的异常。\n\n`__set__`：将在属性分配操作中调用。\n\n`__delete__`：控制删除操作。\n\n描述符的作用和优势，以弥补Python动态类型的缺点。\n\n```python\nclass Score:\n  def __init__(self, default=0):\n     self._score = default\n\n  def __set__(self, instance, value):\n     if not isinstance(value, int):\n       raise TypeError('Score must be integer')\n\n     if not 0 <= value <= 100:\n       raise ValueError('Valid value must be in [0, 100]')\n\n     self._score = value\n\n  def __get__(self, instance, owner):\n     return self._score\n\n  def __delete__(self):\n     del self._score    \n\nclass Student:\n  math = Score(0)\n  chinese = Score(0)\n  english = Score(0)\n\n  def __init__(self, name, math, chinese, english):\n     self.name = name\n     self.math = math\n     self.chinese = chinese\n     self.english = english\n```\n\n**staticmethod**\n\n```python\nclass Test:\n  @staticmethod\n  def myfunc():\n     print(\"hello\")\n\n# 上下两种写法等价\nclass Test:\n  def myfunc():\n     print(\"hello\")\n  # 重点：这就是描述符的体现\n  # 每调用一次，它都会经过描述符类的 __get__\n  myfunc = staticmethod(myfunc)\n```\n\n**classmethod**\n\n```python\nclass classmethod(object):\n  def __init__(self, f):\n     self.f = f\n  def __get__(self, instance, owner=None):\n     print(\"in classmethod __get__\")\n     def newfunc(*args):\n       return self.f(owner, *args)\n     return newfunc\n\nclass Test:\n  def myfunc(cls):\n     print(\"hello\")\n  # 重点：这就是描述符的体现\n  myfunc = classmethod(myfunc)\n```\n\n### 元类\n\n**元类是用来创建类的类。**\n\n如果类属性中定义了`__metaclass__`，则在创建类的时候用元类来创建；\n\n如果没有则向其父类查找`__metaclass__`。\n\n如果都没有，则用`type()`创建类。\n\n```python\n# metaclass是类的模板，所以必须从`type`类型派生：\nclass ListMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs['add'] = lambda self, value: self.append(value)\n        return type.__new__(cls, name, bases, attrs)\n    \nclass MyList(list, metaclass=ListMetaclass):\n    pass\n```\n\n传入关键字参数`metaclass`时，指示Python解释器在创建`MyList`时，要通过`ListMetaclass.__new__()`来创建\n\n在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。\n\n`__new__()`方法接收到的参数依次是：\n\n1. 当前准备创建的类的对象；\n2. 类的名字；\n3. 类继承的父类集合；\n4. 类的方法集合。\n\n**元类作用**\n\n- 拦截类的创建\n- 修改类\n- 返回修改后的类\n\n**应用场景**\n\nORM：所有的类都只能动态定义，因为只有使用者才能根据表的结构定义出对应的类来。\n\n## 字典\n\n字典的查询、添加、删除的平均时间复杂度都是`O(1)`。因为字典是通过哈希表来实现的.\n\n- 计算key的hash值`hash(key)`，再和mask做与操作【mask=字典最小长度（DictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的enteies哈希表中的下标位置\n\n- 若index下标位置已经被占用，则会判断enteies的key是否与要插入的key是否相等\n\n  - 如果key相等就表示key已存在，则更新value值\n\n  - 如果key不相等，就表示hash冲突，则会继续向下寻找空位置，一直到找到剩余空位为止。\n\n### **开放寻址法**\n\n开放寻址法中，所有的元素都存放在散列表里，当产生哈希冲突时，通过一个探测函数计算出下一个候选位置，如果下一个获选位置还是有冲突，不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。\n\n> 开放寻址法中解决冲突的方法有：线行探查法、平方探查法、双散列函数探查法\n\n采用哈希表，dict的哈希表里每个slot都是一个自定义的entry结构：\n\n```c\ntypedef struct {\n   Py_ssize_t me_hash;\n   PyObject *me_key;\n   PyObject *me_value;\n} PyDictEntry;\n```\n\n每个entry有三种状态Active, Unused, Dummy。\n\n- Unused:me_key == me_value == NULL，即未使用的空闲状态。\n\n- Active:me_key != NULL, me_value != NULL，即该entry已被占用\n\n- Dummy:me_key == dummy, me_value == NULL。\n\n**为什么entry有Dummy状态呢？**\n\n用开放寻址法中，**遇到哈希冲突时会找到下一个合适的位置，**例如ABC构成了探测链，查找元素时如果hash值相同，那么也是**顺着这条探测链不断往后找**，当删除探测链中的某个元素时，如果直接把B从哈希表中移除，即变成Unused状态，那么C就不可能再找到了，因此需要Dummy保证探测链的连续性。\n\ndict对象的定义为：\n\n```c\nstruct _dictobject {\n  PyObject _HEAD\n  Py_ssize_t ma_fill; /* # Active + # Dummy */\n  Py_ssize_t ma_used; /* # Active */\n  Py_ssize_t ma_mask; //slot -1\n  PyDictEntry *ma_table;\n  PyDictEntry *(*ma_lookup)(PyDictObject *mp, PyObject *key, long hash); // 搜索函数指针\n  PyDictEntry ma_smalltable[PyDict_MINSIZE]; //默认的slot\n};\n```\n\n### **dict对象的创建**\n\ndict对象的创建很简单，先看看缓冲的对象池里有没有可用对象，如果有就直接用，没有就从堆上申请。\n\n### **dict对象的插入**\n\n如果不存在key-value则插入，存在则覆盖。\n\n- 生成Hash\n- 如果可用的entry<0，字典扩容\n- 基于key、hash，查找可用哈希位置，以便于存储\n  - 字典中是否有空余的值，或者如果找到了满足 hash 值与 key 相同的,就将 value 设置为找到的值\n- 保存key、Hash、value值\n\n### **dict对象的删除**\n\n算出哈希值，找到entry，将其从Active转换成Dummy，并调整table的容量。\n\n**注意**\n\n（1） dict的key 或者 set的值都必须是可hash的不可变对象，都是可hash的\n\n（2）当发现内存空间中的“空”只有1/3时，便会触发扩容操作。\n\n## 整数\n\nPython使用**小整数对象池**small_ints缓存了[-5，257）之间的整数，该范围内的整数在Python系统中是共享的，值相同就属于同一个对象。\n\n对于同一个代码块中值不在`small_ints`缓存范围内的整数，如果同一个代码块中已经存在一个值与其相同的整数对象，那么就直接引用该对象，否则创建新的`int`对象。\n\n## 字符串\n\nPython解释器中使用了 intern（字符串驻留）的技术来提高字符串效率，值同样的字符串对象仅仅会保存一份，放在一个字符串储蓄池中，是共用的。\n\n**简单原理**\n\n维护一个字符串存储池，这个池子是一个字典结构\n\n如果字符串已经存在于池子中，直接返回之前创建好的字符串对象，\n\n如果不存在，则构造一个字符串对象并加入到池子中去。\n\n> 在shell中，并非全部的字符串都会采用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。不能超过20个字符。因为如果超过xx个字符的话，解释器认为这个字符串不常用，不用放入字符串池中。\n>\n> 字符串拼接时，运行时拼接，不会intern；例如\"hell\" + \"o\"在编译时完成拼接的才会intern\n\n## 堆 栈\n\n在Python中，变量也称为：对象的引用。变量存储的就是对象的地址。\n\n**变量位于：栈内存。**\n\n**对象位于：堆内存。**\n\n内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。\n\n**代码区：**程序中的代码数据、二进制数据、方法数据等等程序运行需要的预加载数据。\n\n**静态数据区：**存储**全局变量、静态变量**。\n\n**栈区：**存储变量。存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。\n\n**堆区**：对象真实数据。\n\n## 内存回收机制\n\npython采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略。\n\n###  **引用计数法**\n\n**原理：**每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数加1，每当该对象的引用失效时，计数减1，一旦对象的引用计数为0，该对象立即被回收，占用的内存空间将被释放。\n\n**缺点：**不能解决对象的循环引用\n\n### 标记清除\n\n解决容器对象可能产生的循环引用问题。（只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等）\n\n**A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达**；\n\nB）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。\n\n### 分代回收\n\n标记清除时，应用程序会被暂停，为了减少应用程序暂停的时间。\n\n**对象存在时间越长，越可能不是垃圾，应该越少去收集**。\n\n给对象定义了三种世代，每一个新生对象在0代中，如果它在一轮gc扫描中活了下来，那么它将被移至1代，在那里他将较少的被扫描，如果它又活过了一轮gc，它又将被移至2代，在那里它被扫描的次数将会更少。\n\n### **gc的扫描在什么时候会被触发呢**?\n\n年轻代链表的总数达到上限时。\n\n当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。\n\n### **调优手段**\n\n1.手动垃圾回收\n\n2.调高垃圾回收阈值\n\n3.避免循环引用\n\n## 退出Python时，是否释放全部内存？\n\n进程退出的时候，资源最终都会释放掉，这是操作系统负责的。\n\n如果是一段程序运行结束之后：\n\n1. CPython会通过引用计数立即释放引用数量为0的对象（其它版本解释器并不保证）；循环引用的对象会在下一次GC时释放，除非有两个对象都带有`__del__`析构函数，且直接或间接循环引用。这种情况下，所有循环引用的对象都无法被释放。原因在于无法确定`__del__`的执行顺序。\n2. 全局引用的对象无法被回收，但也不只是模块中直接或间接保存的对象，还包括未退出的线程使用的对象，解释器缓存的小整数和字符串，还有C模块里间接引用的对象等等。\n3. C扩展直接通过malloc分配的内存自然无法通过gc来回收，但一般如果存在没有被回收的内存说明是有内存泄漏的，这属于实现的bug\n\n## 协程，线程和进程\n\n### 进程\n\n进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。在Python中，进程适合计算密集型任务。\n\n#### 进程间的通信（IPC）\n\n**1）管道（Pipe**）：通过`send()`和`recv()`来发送和接受信息，适合父子进程关系或者两个子进程之间。 \n\n2）**有名管道（FIFO）**：有名管道也是半双工的通信方式。 将自己注册到文件系统里一个文件，通过读写这个文件进行通信。允许在没有亲缘关系的进程之间使用。要求读写双方必须同时打开才可以继续进行读写操作，否则打开操作会堵塞直到对方也打开。\n\n3）**信号量（Semaphore）**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 创建子进程时将信号量my_semaphore作为参数传入子进程任务函数，子进程中使用semaphore.acquire() 尝试获取信号量，semaphore.release()尝试 释放信号量。\n\n**4）队列（Queue）**。 使用get/put在父子进程关系或者两个子进程之间通信。\n\n5）**信号 （signal）**：用于通知接收进程某个事件已经发生，可以设置信号处理函数。 \n\n6）共享内存（shared memory）：操作系统负责将同一份物理地址的内存映射到多个进程的不同的虚拟地址空间中。进而每个进程都可以操作这份内存。需要在进程访问时做好并发控制，比如使用信号量。 python标准库mmap，apache开源的pyarrow都是。\n\n7）套接字（socket）：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。 \n\n**8）文件** \n\n（1）仅进程同步不涉及数据传输，可以使用信号、信号量；\n（2）若进程间需要传递少量数据，可以使用管道、有名管道、队列；\n（3）若进程间需要传递大量数据，最佳方式是使用共享内存，推荐使用pyarrow，这样减少数据拷贝、传输的时间内存代价；\n（4）跨主机的进程间通信（RPC）可以使用socket通信。\n\n**共享变量**\n\n使用 Process 定义的多进程之间（父子或者兄弟）共享变量可以直接使用 multiprocessing 下的 Value，Array，Queue 等，如果要共享 list，dict，可以使用强大的 Manager 模块。\n\n###  线程\n\n线程是cpu调度执行的最小单位，依赖进程存在，一个进程至少有一个线程。在python中，线程适合IO密集型任务。\n\n同一个进程下的线程共享程序的内存空间**（如代码段，全局变量，堆栈等）**\n\n#### 使用\n\n继承Thread，重写run方法，通过start方法开线程\n\n将要执行的方法作为参数传给Thread的构造方法\n\n#### 状态\n\n线程有五种状态:创建、就绪、运行、阻塞、死亡。 \n\n- 调用start方法时，线程就会进入就绪状态。 \n\n- 在线程得到cpu时间片时进入运行状态。 \n\n- **线程调用yield方法可以让出cpu时间回到就绪状态**。 \n\n- 线程运行时可能**由于IO、调用sleep、wait、join方法或者无法获得同步锁等原因进入阻塞**状态。 \n\n- 当线程获得到等待的资源资源或者引起阻塞的条件得到满足时，会从阻塞状态进入就绪状态。 \n\n- 当线程的run方法执行结束时，线程就进入死亡状态。\n\n#### 锁\n\n多个线程同时对一个公共资源（如全局变量）进行操作的情况，为了避免发生混乱。`threading.lock`，`acquire()`方法上锁，`release()`方法解锁\n\n可重入锁：为了支持在同一线程中多次请求同一资源，python提供了threading.RLock。重入锁必须由获取它的同一个线程释放，同时要求解锁次数应与加锁次数相同，才能用于另一个线程。\n\n#### 同步\n\n阻塞线程直到子线程全部结束。\n\n#### 守护线程\n\n不重要线程。主线程会等所有‘重要’线程结束后才结束。\n\n#### 线程池的工作原理\n\n减少线程本身创建和销毁造成的开销，属于典型的空间换时间操作。\n\n创建和释放线程涉及到大量的系统底层操作，开销较大，如果变成预创建和借还操作，将大大减少底层开销。\n\n- 在应用程序启动后，线程池创建一定数量的线程，放入空闲队列中。这些线程最开始都处于阻塞状态，不会消耗CPU，占用少量的内存。\n- 当任务到来后，从队列中取出一个空闲线程，把任务派发到这个线程中运行，并将标记为已占用。\n- 当线程池中所有的线程都被占用后，可以选择自动创建一定数量的新线程，用于处理更多的任务，也可以选择让任务排队等待直到有空闲的线程可用。\n- 在任务执行完毕后，线程并不退出结束，而是继续保持在池中等待下一次的任务。\n- 当系统比较空闲时，大部分线程长时间处于闲置状态时，线程池可以自动销毁一部分线程，回收系统资源。\n\n线程池组成部分：\n\n1. 线程池管理器：用于创建并管理线程池。\n2. 工作线程和线程队列：线程池中实际执行的线程以及保存这些线程的容器。\n3. 任务接口：将线程执行的任务抽象出来，形成任务接口，确保线程池与具体的任务无关。\n4. 任务队列：线程池中保存等待被执行的任务的容器。\n\n###  协程\n\n协程是一种用户态的轻量级线程，调度完全由用户控制。\n\n协程拥有自己的寄存器上下文和栈。协程的切换都在用户空间内进行，不需要进行系统调用。\n\n协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，基本没有内核切换的开销，可以不加锁的访问全局变量，上下文的切换非常快。\n\n\n\n**如何利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能**。\n\n**常用模块**\n\ngreenlet：提供了切换任务的快捷方式，但是遇到io无法自动切换任务，需要手动切换\n\ngevent：开启协程任务并切换的模块，遇到io自动切换任务。\n\nasyncio：`@asyncio.coroutine`装饰器的函数称为协程函数。\n\n`yield from`语法用于将一个生成器部分操作委托给另一个生成器。\n\n`async`/`await`：`@asyncio.coroutine`和`yield from`的语法糖\n\n**缺点**\n\n- 无法利用多核资源：协程的本质是个单线程\n\n- 进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序\n\n**协程主要使用场景**\n\n网络请求，比如爬虫，大量使用 aiohttp\n\n文件读取， aiofile\n\nweb 框架， aiohttp， fastapi\n\n数据库查询， asyncpg, databases\n\n**协程优于线程**\n\n- python 线程调度方式是，每执行 100 个字节码或者遇到阻塞就停止当前线程，然后进行一个系统调用，让 os 内核选出下一个线程。但是协程 只会在 阻塞的时候，切换到下一个协程。100个字节码，说多不多，说少不少，你调用两个库函数说不定就没了，因此线程的切换存在很多是无效的切换，当线程数量越大，这种因为调度策略的先天不足带来的性能损耗就越大。\n- 线程需要进行系统调用，协程不需要。系统调用需要进入内核态，无效的调度会让这部分开销显得更大\n- 协程可以自主调度，而线程只能决定合适退出，但是下一个线程是谁则依赖于操作系统。\n\n### 僵尸进程和孤儿进程 \n\n孤儿进程： **父进程退出，子进程还在运行的这些子进程都是孤儿进程，**孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。\n\n僵尸进程： 进程使用fork 创建子进程**，如果子进程退出，而父进程并没有调用wait 获取子进程的状态信息**，那么子进程的进程描述符仍然保存在系统中，这些进程是僵尸进程。\n\n避免僵尸进程的方法：\n\n1.用`wait()`函数使父进程阻塞\n\n2.使用信号量，在signal handler 中调用waitpid，这样父进程不用阻塞\n\n**3.fork 两次用孙子进程去完成子进程的任务（？？？）**\n\n##  Global Interpreter Lock(全局解释器锁)\n\nPython 默认的解释器是 CPython，**GIL 是存在于 CPython 解释器中的**。\n\n执行 Python 字节码时，为了保护访问 Python 对象而阻止多个线程执行的一把互斥锁。主要是因为 CPython 解释器的内存管理不是线程安全的。\n\n常见的 Python 解释器：IPython（基于Cython）、IPython、Jython（可以把 Python 代码编译成 Java 字节码，依赖 Java 平台，不存在 GIL）、IronPython（运行在微软的 .Net 平台下的 Python 解释器，可以把 Python 代码编译成 .Net 字节码，不存在 GIL）\n\n### GIL原理\n\npython 的线程就是 C 语言的 pthread，它是通过操作系统调度算法调度执行的。\n\nPython 2.x 的代码执行是基于 opcode 数量的调度方式，简单来说就是每执行一定数量的字节码，或遇到系统 IO 时，会强制释放 GIL，然后触发一次操作系统的线程调度。\n\n Python 3.x 基于固定时间的调度方式，就是每执行固定时间的字节码，或遇到系统 IO 时，强制释放 GIL，触发系统的线程调度。\n\n### 为什么会有GIL\n\nPython 设计者在设计解释器时，可能没有想到 CPU 的性能提升会这么快转为多核心方向发展，所以在当时的场景下，设计一个全局锁是那个时代保护多线程资源一致性最简单经济的设计方案。\n\n多核心时代来临，当大家试图去拆分和去除 GIL 的时候，发现大量库的代码和开发者已经重度依赖 GIL（默认认为 Pythonn内部对象是线程安全的，无需在开发时额外加锁），所以这个去除 GIL 的任务变得复杂且难以实现。\n\n## 性能分析\n\npython 内置了丰富的性能分析工具，**如 profile,cProfile 与 hotshot 等**。其中 Profiler 是 python 自带的一组程序，能够描述程序运行时候的性能，并提供各种统计帮助用户定位程序的性能瓶颈。\n\nPython 标准库提供了同一分析接口的两种不同实现：\n\n1. 建议使用 [`cProfile`](https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile) ；这是一个 C 扩展插件，因为其合理的运行开销，所以适合于分析长时间运行的程序。\n2. [`profile`](https://docs.python.org/zh-cn/3/library/profile.html#module-profile) 是一个纯 Python 模块（[`cProfile`](https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile) 就是模拟其接口的 C 语言实现），但它会显著增加配置程序的开销。如果你正在尝试以某种方式扩展分析器，则使用此模块可能会更容易完成任务\n\n支持输出：调用次数、在指定函数中消耗的总时间（不包括调用子函数的时间）、指定的函数及其所有子函数（从调用到退出）消耗的累积时间、函数运行一次的平均时间\n\n\n\n## 单例模式\n\n### **使用装饰器**\n\n```python\ndef singleton(cls):\n  instances = {}\n  def wrapper(*args, **kwargs):\n     if cls not in instances:\n       instances[cls] = cls(*args, **kwargs)\n     return instances[cls]\n\n  return wrapper\n\n@singleton\nclass Foo(object):\n  pass\n\nfoo1 = Foo()\nfoo2 = Foo()\n\nprint(foo1 is foo2) # True\n```\n\n### 使用new\n\nNew 是真正创建实例对象的方法，所以重写基类的new 方法，以此保证创建对象的时候只生成一个实例。\n\n但是以上的方法在多线程中会有线程安全问题，当有多个线程同时去初始化对象时，就很可能同时判断__instance is None，从而进入初始化instance的代码中。所以需要用**互斥锁**来解决这个问题。\n\n```python\nclass Singleton(object):\n  def __new__(cls, *args, **kwargs):\n     if not hasattr(cls, '_instance'):\n       cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n     return cls._instance\n\n\nclass Singleton(object):\n  __instance = None\n  def __new__(cls, *args, **kwargs):\n     if cls.__instance is None:\n       cls.__instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n     return cls.__instance\n\nclass Foo(Singleton):\n  pass\n\nfoo1 = Foo()\nfoo2 = Foo()\n\nprint(foo1 is foo2) # True\n```\n\n### classmethod\n\n```python\nimport time\nimport threading\nclass Singleton(object):\n     _instance_lock = threading.Lock() \n    def __init__(self):\n        time.sleep(1)        \n    @classmethod\n    def instance(cls, *args, **kwargs):\n        with Singleton._instance_lock: # 加锁\n            if not hasattr(Singleton, '_instance'):\n                Singleton._instance = Singleton(*args, **kwargs)\n            return Singleton._instance\n```\n\n\n\n### 元类\n\n元类是用于创建类对象的类，类对象创建实例对象时一定要调用call方法，因此在调用call时候保证始终只创建一个实例即可，type是python的元类\n\n```python\nclass Singleton(type):\n    def __call__(cls, *args, **kwargs):\n        if not hasattr(cls, '_instance'):\n            cls._instance = super(Singleton, cls).__call__(*args, **kwargs)\n        return cls._instance\n\n\n# Python2\nclass Foo(object):\n\t__metaclass__ = Singleton\n```\n\n### **线程安全装饰器**\n\n ```python\ndef make_synchronized(func):\n    import threading\n    func.__lock__ = threading.Lock()\n\n    # 用装饰器实现同步锁\n    def synced_func(*args, **kwargs):\n        with func.__lock__:\n            return func(*args, **kwargs)\n\n    return synced_func\n\nclass Singleton(object):\n    __instance = None\n\n    @make_synchronized\n    def __new__(cls, *args, **kwargs):\n        if not cls.__instance:\n            cls.__instance = object.__new__(cls)\n        return cls.__instance\n\n    def __init__(self):\n        self.blog = \"blog\"\n ```\n\n### **线程安全--元类**\n\n```python\nimport threading\n\nclass MetaSingleton(type):\n    _instance_lock = threading.Lock()\n    def __call__(cls, *args, **kwargs):\n        if not hasattr(cls, '_instance'):\n            with MetaSingleton._instance_lock:\n                if not hasattr(cls, '_instance'):\n                    cls._instance = super(MetaSingleton, cls).__call__(*args, **kwargs)\n\n        return cls._instance\n    \n  \nclass Singleton(metaclass=MetaSingleton):\n    def __init__(self, name):\n        self.name = name\n```\n\n## select,poll和epoll \n\n select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 \n\n\n\n","slug":"python面试","published":1,"updated":"2021-05-19T00:00:40.520Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6xw002vq4ufqj6x75zf","content":"<h2 id=\"语言特性\"><a href=\"#语言特性\" class=\"headerlink\" title=\"语言特性\"></a>语言特性</h2><p>解释型语言。Python不需要在运行之前进行编译。</p>\n<p>动态语言，不需要声明变量的类型。</p>\n<p>适合面向对象的编程，允许类的定义和继承。</p>\n<h2 id=\"python2和python3区别\"><a href=\"#python2和python3区别\" class=\"headerlink\" title=\"python2和python3区别\"></a>python2和python3区别</h2><ul>\n<li>Python2 的默认编码是 ascii，Python 3 默认编码 UTF-8，不需要在文件顶部写 <code># coding=utf-8</code>。</li>\n<li>在Python2 中，字符串有两个类型， unicode和 str，前者表示文本字符串，后者表示字节序列，不过两者并没有明显的界限； Python3  str 表示字符串，byte 表示字节序列。</li>\n<li>True 和 False 在 Python2 中是全局变量，分别对应 1 和 0，可以指向其它对象。 Python3  True 和 False 变为关键字，不允许再被重新赋值。</li>\n<li>Python 2中print是特殊语句，Python 3中print是函数，需要加上括号。</li>\n<li>在Python 2中，3/2是整数，在Python 3中，浮点数。</li>\n<li>python2 range返回列表，python3 range中返回可迭代对象，节约内存。</li>\n<li>Python 2 map函数返回list，Python 3 map函数返回迭代器。</li>\n<li>python2中的raw_input函数，python3中改名为input函数</li>\n<li>在Pyhon3，新增了关键字 nonlcoal，支持嵌套函数中，变量声明为非局部变量。</li>\n</ul>\n<h2 id=\"Python基础\"><a href=\"#Python基础\" class=\"headerlink\" title=\"Python基础\"></a>Python基础</h2><h3 id=\"可变数据类型和不可变数据类型\"><a href=\"#可变数据类型和不可变数据类型\" class=\"headerlink\" title=\"可变数据类型和不可变数据类型\"></a>可变数据类型和不可变数据类型</h3><p>可变数据类型（引用类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址不发生改变。</p>\n<p>不可变数据类型（值类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址发生了改变。</p>\n<p>可变数据类型：list和dict；</p>\n<p>不可变数据类型：int、型float、string和tuple。</p>\n<h3 id=\"python2中xrange和range的区别\"><a href=\"#python2中xrange和range的区别\" class=\"headerlink\" title=\"python2中xrange和range的区别\"></a>python2中xrange和range的区别</h3><p><code>range()</code>返回的是一个list对象，而xrange返回的是一个可迭代对象。</p>\n<p><code>xrange()</code>则不会直接生成一个list，而是每次调用返回其中的一个值，内存空间使用极少。因而性能非常好。</p>\n<h3 id=\"变量的作用域-查找顺序\"><a href=\"#变量的作用域-查找顺序\" class=\"headerlink\" title=\"变量的作用域/查找顺序\"></a>变量的作用域/查找顺序</h3><p>函数作用域的LEGB顺序</p>\n<p>L： local ，局部作用域；</p>\n<p>E： enclosing，嵌套的父级函数的局部作用域；</p>\n<p>G：global ，全局变量；</p>\n<p>B： build-in， 系统固定模块里面的变量。</p>\n<p>Python除了def/class/lambda 外，其他如: if/elif/else/ try/except for/while并不能改变其作用域。</p>\n<h3 id=\"内置函数\"><a href=\"#内置函数\" class=\"headerlink\" title=\"内置函数\"></a>内置函数</h3><p><code>reduce()</code> 函数会对参数序列中元素进行累积。</p>\n<p>先对数据集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据做函数运算。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">add</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">:</span>      <span class=\"token comment\" spellcheck=\"true\"># 两数相加</span>\n   <span class=\"token keyword\">return</span> x <span class=\"token operator\">+</span> y\nreduce<span class=\"token punctuation\">(</span>add<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\" spellcheck=\"true\"># 计算列表和：1+2+3+4+5</span>\nreduce<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">:</span> x<span class=\"token operator\">+</span>y<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># 使用 lambda 匿名函数</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>filter()</code> 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。</p>\n<p>序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">is_odd</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">return</span> n <span class=\"token operator\">%</span> <span class=\"token number\">2</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span>\n\nnewlist <span class=\"token operator\">=</span> filter<span class=\"token punctuation\">(</span>is_odd<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>newlist<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>map()</code> 会根据提供的函数对指定序列做映射。</p>\n<p>序列中的每一个元素调用 函数，返回包含每次函数返回值的新列表（python2），python3是会返回可迭代对象的。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">square</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">:</span>      <span class=\"token comment\" spellcheck=\"true\"># 计算平方数</span>\n   <span class=\"token keyword\">return</span> x <span class=\"token operator\">**</span> <span class=\"token number\">2</span>\nmap<span class=\"token punctuation\">(</span>square<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\" spellcheck=\"true\"># 计算列表各个元素的平方</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p><code>repr()</code>函数将对象转化为供解释器读取的形式</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\">dict1 <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'runoob'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'runoob.com'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'google'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'google.com'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\nrepr<span class=\"token punctuation\">(</span>dict1<span class=\"token punctuation\">)</span>\nstr<span class=\"token punctuation\">(</span>dict1<span class=\"token punctuation\">)</span>\n\n<span class=\"token string\">\"{'google': 'google.com', 'runoob': 'runoob.com'}\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>vars()</code>函数返回对象object的属性和属性值的字典对象。</p>\n<pre><code>class Runoob:\n   a = 1\nprint(vars(Runoob))\n{&#39;a&#39;: 1, &#39;__module__&#39;: &#39;__main__&#39;, &#39;__doc__&#39;: None}</code></pre><p><strong>ord</strong></p>\n<p>一个长度为1的字符串作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。</p>\n<h4 id=\"dir\"><a href=\"#dir\" class=\"headerlink\" title=\"dir\"></a>dir</h4><p>不带参数时，返回当前范围内的变量、方法和定义的类型列表；</p>\n<p>带参数时，返回参数的属性、方法列表。</p>\n<p>如果参数包含方法<code>__dir__()</code>，该方法将被调用。</p>\n<h4 id=\"isinstance\"><a href=\"#isinstance\" class=\"headerlink\" title=\"isinstance\"></a><strong>isinstance</strong></h4><p><code>isinstance()</code>判断一个对象是否是一个已知的类型，<code>type()</code>查看一个类型或变量的类型。</p>\n<p><code>type()</code>不会认为子类是一种父类类型。<code>isinstance()</code>会认为子类是一种父类类型。</p>\n<h4 id=\"raw-input、input\"><a href=\"#raw-input、input\" class=\"headerlink\" title=\"raw_input、input\"></a>raw_input、input</h4><p>1、在 Python2.x 中<code>raw_input()</code>和<code>input()</code>，两个函数都存在，其中区别为:</p>\n<ul>\n<li><code>raw_input()</code>将所有输入作为字符串看待，返回字符串类型。</li>\n<li><code>input()</code> 只能接收“数字”的输入，它返回所输入的数字的类型。</li>\n</ul>\n<p>2、在 Python3.x 中 仅保留了<code>input()</code> 函数，将所有输入作为字符串处理，并返回字符串类型。</p>\n<h4 id=\"sort-sorted\"><a href=\"#sort-sorted\" class=\"headerlink\" title=\"sort sorted\"></a>sort sorted</h4><p><strong>区别</strong></p>\n<p>对于一个无序的列表a，调用<code>a.sort()</code>，对a进行排序后返回None，<code>sort()</code>函数修改待排序的列表内容。</p>\n<p>而对于同样一个无序的列表a，调用<code>sorted(a)</code>，对a进行排序后返回一个新的列表，而对a不产生影响。</p>\n<p><strong>sort</strong></p>\n<p>timsort是结合了合并排序和插入排序而得出的排序算法。该算法找到数据中已经排好序的块-分区，每一个分区叫一个run，然后按规则合并这些run。</p>\n<p>为了减少对升序部分的回溯和对降序部分的性能倒退，将输入按其升序和降序特点进行了分区。排序的输入的单位不是一个个单独的数字，而是一个个的块-分区。其中每一个分区叫一个run。针对这些 run 序列，每次拿一个 run 出来按规则进行合并。每次合并会将两个 run合并成一个 run。合并的结果保存到栈中。合并直到消耗掉所有的 run，这时将栈上剩余的 run合并到只剩一个 run 为止。这时这个仅剩的 run 便是排好序的结果。</p>\n<p>（0）数组长度小于某个值，直接用二分插入排序算法</p>\n<p>（1）找到各个run，并入栈</p>\n<p>（2）按规则合并run</p>\n<p>0：有序部分的长度一般不会太长，当小于 minRun 时，会将此部分后面的元素插入其中，直至长度满足 minRun。通过二分法查找元素</p>\n<p>2：会将该run在数组中的起始位置和run的长度放入栈中，然后根据先前放入栈中的run决定是否该合并run。Timsort不会合并在栈中不连续的run</p>\n<p>先用二分查找算法/折半查找算法（binary search）找到插入的位置，然后在插入。</p>\n<p>   例如，我们要将A和B这2个run 合并，且A是较小的run。因为A和B已经分别是排好序的，二分查找会找到B的第一个元素在A中何处插入。同样，A的最后一个元素找到在B的何处插入，找到以后，B在这个元素之后的元素就不需要比较了。这种查找可能在随机数中效率不会很高，但是在其他情况下有很高的效率。</p>\n<h3 id=\"魔法方法\"><a href=\"#魔法方法\" class=\"headerlink\" title=\"魔法方法\"></a>魔法方法</h3><p>在特殊的情况下被Python所调用的方法。</p>\n<p><code>__init__</code>构造器，当一个实例被创建的时候用于初始化的方法。</p>\n<p><code>__new__</code>实例化对象调用的第一个方法，用来创造一个类的实例的，取下cls参数，把其他参数传给<code>__init__</code>.</p>\n<p><code>__call__</code>让一个类的实例像函数一样被调用</p>\n<p><code>__getitem__</code>定义获取容器中指定元素的行为，相当于<code>self[key]</code></p>\n<p><code>__getattr__</code>定义当用户试图访问一个不存在属性的时候的行为</p>\n<p><code>__setattr__</code>定义当一个属性被设置的时候的行为</p>\n<p><code>__getattribute___</code>定义当一个属性被访问的时候的行为</p>\n<p><code>__del__</code>删除对象执行的方法</p>\n<p><code>__str__</code>强调可读性，面向用户；而<code>__repr__</code>强调标准性，面向机器</p>\n<p>%s调用<code>__str__</code>方法，而%r调用<code>__repr__</code>方法</p>\n<p><code>__repr__</code>在表示类时，是一级的，如果只定义它，那么<code>__str__</code> = <code>__repr__</code>。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Callable</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__call__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">return</span> a <span class=\"token operator\">+</span> b\n\n\nfunc <span class=\"token operator\">=</span> Callable<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \nresult <span class=\"token operator\">=</span> func<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># 像函数一样调用</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"new-amp-init区别\"><a href=\"#new-amp-init区别\" class=\"headerlink\" title=\"new &amp; init区别\"></a>new &amp; init区别</h3><p>1、<code>__new__</code>有参数cls，代表当前类，从而产生一个实例；<code>__new__</code>必须要有返回值，返回实例化出来的实例，可以return父类（<code>super(当前类名, cls)</code>）<code>__new__</code>出来的实例，或object的<code>__new__</code>出来的实例</p>\n<p>2、<code>__init__</code>有参数self，完成一些初始化的动作，<code>__init__</code>不需要返回值</p>\n<p>3、如果<code>__new__</code>创建的是当前类的实例，会自动调用<code>__init__</code>（return语句里面调用的<code>__new__</code>函数的第一个参数是cls，保证是当前类实例）；如果<code>__new__</code>返回一个已经存在的实例，<code>__init__</code>不会被调用。</p>\n<p>4、如果我们在<code>__new__</code>函数中不返回任何对象，则<code>__init__</code>函数也不会被调用。</p>\n<blockquote>\n<p>Python的旧类中实际上并没有<code>__new__</code>方法。因为旧类中的<code>__init__</code>实际上起构造器的作用</p>\n</blockquote>\n<h3 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h3><p>避免转义，给字符串加r表示原始字符串。</p>\n<h3 id=\"is-和-区别\"><a href=\"#is-和-区别\" class=\"headerlink\" title=\"is 和 ==区别\"></a>is 和 ==区别</h3><p>is：比较俩对象是否为同一个实例对象，是否指向同一个内存地址。</p>\n<p>== ： 比较的两个对象的内容/值是否相等，默认会调用对象的<code>eq()</code>方法</p>\n<h3 id=\"set去重\"><a href=\"#set去重\" class=\"headerlink\" title=\"set去重\"></a>set去重</h3><p>set的去重是通过两个函数<code>__hash__</code>和<code>__eq__</code>结合实现的。</p>\n<p>1、当两个变量的哈希值不相同时，就认为这两个变量是不同的</p>\n<p>2、当两个变量哈希值一样时，调用<code>__eq__</code>方法，当返回值为True时认为这两个变量是同一个。返回FALSE时，不去重。</p>\n<h3 id=\"list切片\"><a href=\"#list切片\" class=\"headerlink\" title=\"list切片\"></a>list切片</h3><p>索引操作本身基于<code>__getitem__</code>和<code>__setitem__</code></p>\n<p>python向<code>__getitem__</code>传入了一个<code>slice</code>的对象，这个类有start, stop, step三个属性，缺省值都是None。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\">a <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span>\nx <span class=\"token operator\">=</span> a <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span>        <span class=\"token comment\" spellcheck=\"true\"># x = a.__getitem__(slice( 1, 5, None))</span>\na <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">11</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\" spellcheck=\"true\"># a.__setitem__(slice(1, 3, None), [ 10, 11, 12 ])</span>\n<span class=\"token keyword\">del</span> a <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span>        <span class=\"token comment\" spellcheck=\"true\"># a.__delitem__(slice(1, 4, None))</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"三元算子\"><a href=\"#三元算子\" class=\"headerlink\" title=\"三元算子\"></a>三元算子</h3><p><code>[on true] if [expression] else [on false]</code></p>\n<h3 id=\"pass\"><a href=\"#pass\" class=\"headerlink\" title=\"pass\"></a>pass</h3><p>1、一般作为占位符或者创建占位程序，pass语句不会执行任何操作</p>\n<p>2、保证格式、语义完整 </p>\n<h3 id=\"lambda\"><a href=\"#lambda\" class=\"headerlink\" title=\"lambda\"></a>lambda</h3><p>创建匿名函数的一个特殊语法,即用即仍，</p>\n<p>1.一般用来给filter，map这样的函数式编程服务</p>\n<p>2.作为回调函数</p>\n<h3 id=\"迭代器和生成器\"><a href=\"#迭代器和生成器\" class=\"headerlink\" title=\"迭代器和生成器\"></a>迭代器和生成器</h3><h4 id=\"迭代器\"><a href=\"#迭代器\" class=\"headerlink\" title=\"迭代器\"></a>迭代器</h4><p><strong>迭代器协议</strong>： <code>__iter__()</code> 返回一个特殊的迭代器对象， 这个迭代器对象实现了 <code>__next__()</code> 并通过 <code>StopIteration</code> 异常，标识迭代的完成。</p>\n<p><strong>迭代器对象</strong>：实现了迭代器协议的对象/被<code>next()</code>函数调用并不断返回下一个值的对象称为迭代器。</p>\n<p><strong>例子</strong></p>\n<p>Python的内置工具（如for循环，sum，min，max函数等）使用迭代器协议访问对象</p>\n<h4 id=\"生成器\"><a href=\"#生成器\" class=\"headerlink\" title=\"生成器\"></a>生成器</h4><p><strong>使用了 yield 的函数被称为生成器</strong>。<strong>只要把一个列表生成式的<code>[]</code>改成<code>()</code>，就创建了一个生成器</strong></p>\n<p>生成器是一种特殊的迭代器，生成器自动实现了“迭代器协议”。</p>\n<p>生成器在迭代的过程中可以改变当前迭代值，而修改普通迭代器的当前迭代值往往会发生异常，影响程序的执行。</p>\n<h4 id=\"可迭代对象\"><a href=\"#可迭代对象\" class=\"headerlink\" title=\"可迭代对象\"></a>可迭代对象</h4><p>实现<code>__iter__</code>方法的对象。可迭代对象包含文件对象、序列（字符串、列表、元组、集合）、字典。</p>\n<h4 id=\"判断方法\"><a href=\"#判断方法\" class=\"headerlink\" title=\"判断方法\"></a>判断方法</h4><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> collections <span class=\"token keyword\">import</span> Iterable<span class=\"token punctuation\">,</span> Iterator\n<span class=\"token keyword\">from</span> inspect <span class=\"token keyword\">import</span> isgenerator\n\nisinstance<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> Iterable<span class=\"token punctuation\">)</span>\nisinstance<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> Iterator<span class=\"token punctuation\">)</span>\nisgenerator<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"装饰器\"><a href=\"#装饰器\" class=\"headerlink\" title=\"装饰器\"></a>装饰器</h3><p>装饰器本质上是一个<strong>Python函数或者类</strong>，让其他函数在不做任何代码变动，从而增加额外功能，装饰器的返回值也是一个函数对象。</p>\n<p>场景：<strong>插入日志</strong>、性能测试、<strong>事务处理</strong>、缓存、<strong>权限校验、异常处理</strong>。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> functools\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">add</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>\n\nadd  <span class=\"token operator\">=</span> functools<span class=\"token punctuation\">.</span>partial<span class=\"token punctuation\">(</span>add<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># 输出：3</span>\nadd<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>经过partial包装之后，a参数的值被固定为了1，新的add对象（注意此处add已经是一个可调用对象）只需要接收一个参数即可。</p>\n<p><strong>把原函数的部分参数固定了初始值，新的调用只需要传递其它参数。</strong></p>\n<p><code>@functools.wraps(func)</code>底层逻辑，就是把wrapped函数的属性拷贝到wrapper函数中。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">outer</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  @functools<span class=\"token punctuation\">.</span>wraps<span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">inner</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>f<span class=\"token string\">\"before...\"</span><span class=\"token punctuation\">)</span>\n     func<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"after...\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> inner\n\n@outer\n<span class=\"token keyword\">def</span> <span class=\"token function\">add</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"\n  求和运算\n  \"\"\"</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>1、原函数为add。</p>\n<p>2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。</p>\n<p>3、执行outer函数时，加载inner函数，此时会直接执行<code>functools.wraps(func)</code>返回一个可调用对象，即partial对象。</p>\n<p>4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。</p>\n<p>5、把add指向inner函数。</p>\n<p>6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。</p>\n<p> <strong>总结</strong></p>\n<p>1）functools.wraps 旨在消除装饰器对原函数造成的影响，即对原函数的相关属性进行拷贝。</p>\n<p>2）wraps内部通过partial对象和update_wrapper函数实现。</p>\n<p>3）partial是一个类，通过实现<code>__new__</code>，<strong>自定义实例化对象过程，使得对象内部保留原函数和固定参数</strong>，通过实现<code>__call__</code>，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。</p>\n<h4 id=\"类装饰器\"><a href=\"#类装饰器\" class=\"headerlink\" title=\"类装饰器\"></a><strong>类装饰器</strong></h4><p>类装饰器具有<strong>灵活度大、高内聚、封装性</strong>等优点。</p>\n<p>依靠<code>__call__</code>方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Foo</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>_func <span class=\"token operator\">=</span> func\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">__call__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n   <span class=\"token keyword\">print</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'class decorator runing'</span><span class=\"token punctuation\">)</span>\n   self<span class=\"token punctuation\">.</span>_func<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n   <span class=\"token keyword\">print</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'class decorator ending'</span><span class=\"token punctuation\">)</span>\n\n@Foo\n<span class=\"token keyword\">def</span> <span class=\"token function\">bar</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">print</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'bar'</span><span class=\"token punctuation\">)</span>\n\nbar<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"property\"><a href=\"#property\" class=\"headerlink\" title=\"property\"></a>property</h3><p>让方法像属性一样使用</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\">property<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>fget<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> fset<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> fdel<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> doc<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nfdel <span class=\"token operator\">=</span> property<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">:</span> object<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">:</span> None<span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">:</span> None<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># default</span>\nfget <span class=\"token operator\">=</span> property<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">:</span> object<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">:</span> None<span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">:</span> None<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># default</span>\nfset <span class=\"token operator\">=</span> property<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">:</span> object<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">:</span> None<span class=\"token punctuation\">,</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">:</span> None<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># default</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">C</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>_x <span class=\"token operator\">=</span> None\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">getx</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_x\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">setx</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    self<span class=\"token punctuation\">.</span>_x <span class=\"token operator\">=</span> value\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">delx</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">del</span> self<span class=\"token punctuation\">.</span>_x\n\n  x <span class=\"token operator\">=</span> property<span class=\"token punctuation\">(</span>getx<span class=\"token punctuation\">,</span> setx<span class=\"token punctuation\">,</span> delx<span class=\"token punctuation\">,</span> <span class=\"token string\">\"I'm the 'x' property.\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>property 的 getter,setter 和 deleter 方法同样可以用作装饰器：</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">C</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>_x <span class=\"token operator\">=</span> None\n\n  @property\n  <span class=\"token keyword\">def</span> <span class=\"token function\">x</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token triple-quoted-string string\">\"\"\"I'm the 'x' property.\"\"\"</span>\n     <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_x\n\n  @x<span class=\"token punctuation\">.</span>setter\n  <span class=\"token keyword\">def</span> <span class=\"token function\">x</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>_x <span class=\"token operator\">=</span> value\n\n  @x<span class=\"token punctuation\">.</span>deleter\n  <span class=\"token keyword\">def</span> <span class=\"token function\">x</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">del</span> self<span class=\"token punctuation\">.</span>_x<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>使用property装饰后，x不再是一个函数，而是property类的一个实例。所以第二个函数可以使用 x.setter 来装饰，本质是调用property.setter 来产生一个新的 property实例赋值给第二个x。</p>\n<p>第一个 x和第二个 x 是两个不同 property实例。但他们都属于同一个描述符类（property），当赋值时，就会进入 <code>property.__set__</code>，取值时，就会进入 <code>property.__get__</code>。</p>\n<h3 id=\"参数类型\"><a href=\"#参数类型\" class=\"headerlink\" title=\"参数类型\"></a>参数类型</h3><p><strong>位置参数：</strong>传参数时，按照顺序，依次传值。</p>\n<p><strong>默认参数：</strong>参数提供默认值。默认参数一定要指向不变对象。</p>\n<p><strong>可变参数：</strong>可变参数就是传入的参数个数是可变的。特征：*args</p>\n<p><strong>关键字参数：</strong>允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。特征：**kw</p>\n<p><strong>命名关键字参数：</strong>如果要限制关键字参数的名字，就可以用命名关键字参数。特征：命名关键字参数需要一个特殊分隔符<code>*</code>，而后面的参数被视为命名关键字参数。如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要特殊分隔符了</p>\n<p>参数定义的<strong>顺序</strong>必须是：位置参数–&gt;默认参数–&gt;可变参数–&gt;命名关键字参数–&gt;关键字参数</p>\n<h3 id=\"zip\"><a href=\"#zip\" class=\"headerlink\" title=\"zip\"></a>zip</h3><p>拉链函数， 将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表迭代器。</p>\n<p>如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>list<span class=\"token punctuation\">(</span>zip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">7</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">[</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'b'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h3 id=\"and-和or\"><a href=\"#and-和or\" class=\"headerlink\" title=\"and 和or\"></a>and 和or</h3><p> 在不加括号时候, and优先级大于or </p>\n<p>x or y：x为真是x, x为假是y </p>\n<p>x and y ： x为真就是y, x为假就是x</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\">v <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token operator\">and</span> <span class=\"token number\">2</span> <span class=\"token operator\">or</span> <span class=\"token number\">3</span> <span class=\"token operator\">and</span> <span class=\"token number\">4</span> \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># 2</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h3 id=\"for-循环\"><a href=\"#for-循环\" class=\"headerlink\" title=\"for 循环\"></a>for 循环</h3><p><strong>通过调用<code>iter()</code>方法执行（字符串，元组，字典，集合，文件）对象内部的<code>__iter__</code>方法，获取一个迭代器，然后使用迭代器协议去实现循环访问，</strong>当元素循环完时，会触发StopIteration异常，for循环会捕捉到这种异常，终止迭代</p>\n<h3 id=\"深拷贝和浅拷贝\"><a href=\"#深拷贝和浅拷贝\" class=\"headerlink\" title=\"深拷贝和浅拷贝\"></a>深拷贝和浅拷贝</h3><p>浅拷贝：在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素地址的拷贝。也就是说新的容器中指向了旧的元素（ 新瓶装旧酒 ）。</p>\n<p>深拷贝：在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。（ 新瓶装新酒 ）。</p>\n<p>1、复制不可变数据类型， copy /deepcopy，都指向原地址对象</p>\n<p>2、复制的值是可变对象</p>\n<p><strong>浅拷贝copy有两种情况：</strong></p>\n<p>复制对象中包含的非可变数据类型：改变值，会开辟新的内存，有新的引用。原来值的改变并不会影响浅复制的值。</p>\n<p>复制对象中包含的可变数据类型：改变原来的值，会影响浅复制的值。</p>\n<p><strong>深拷贝deepcopy</strong></p>\n<p>完全复制独立，包括内层列表和字典</p>\n<h3 id=\"参数传递\"><a href=\"#参数传递\" class=\"headerlink\" title=\"参数传递\"></a>参数传递</h3><p><strong>值传递：</strong>实参把值传递给形参，形参的改变不影响实参值。</p>\n<p><strong>引用传递（地址传递）：</strong>把实参地址传递形参，形参值的改变会影响实参的值。</p>\n<ul>\n<li>函数中修改字典某一个键值对是有效的</li>\n<li>函数中交换两个字典并无法生效</li>\n</ul>\n<p>因此不是严格意义上的引用传递，而是<strong>基于引用地址的值传递</strong>，传递的是对象地址的拷贝。</p>\n<h3 id=\"闭包\"><a href=\"#闭包\" class=\"headerlink\" title=\"闭包\"></a>闭包</h3><p><strong>高阶函数</strong>：函数为入参，或者函数作为返回结果。</p>\n<p><strong>闭包</strong>：在外函数中定义了内函数，内函数里使用了外函数的临时变量，并且外函数的返回值是内函数的引用。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">timer</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">wrapper</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n     func<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\">#此处拿到了被装饰的函数func</span>\n     time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token comment\" spellcheck=\"true\">#模拟耗时操作</span>\n     long <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start\n      <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>f<span class=\"token string\">'共耗时{long}秒。'</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> wrapper <span class=\"token comment\" spellcheck=\"true\">#返回内层函数的引用</span>\n\n@timer\n<span class=\"token keyword\">def</span> <span class=\"token function\">add</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a<span class=\"token operator\">+</span>b<span class=\"token punctuation\">)</span>\n\nadd<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\">#正常调用add</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>模块加载</strong></p>\n<ul>\n<li>遇到@，执行timer函数，传入add函数 </li>\n<li>生成<code>timer.&lt;locals&gt;.wrapper</code>函数并命名为add，其实是覆盖了原同名函数 </li>\n<li>调用<code>add(1, 2)</code></li>\n<li>去执行<code>timer.&lt;locals&gt;.wrapper(1, 2)</code></li>\n<li>wrapper内部持有原add函数引用<code>(func)</code>，调用<code>func(1, 2)</code></li>\n<li>继续执行完wrapper函数</li>\n</ul>\n<p><strong>带参数的装饰器</strong></p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">auth</span><span class=\"token punctuation\">(</span>permission<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">_auth</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">def</span> <span class=\"token function\">wrapper</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>f<span class=\"token string\">\"验证权限[{permission}]...\"</span><span class=\"token punctuation\">)</span>\n       func<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n       <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"执行完毕...\"</span><span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">return</span> wrapper\n  <span class=\"token keyword\">return</span> _auth\n\n@auth<span class=\"token punctuation\">(</span><span class=\"token string\">\"add\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">add</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"\n  求和运算\n  \"\"\"</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>真正调用的是装饰后生成的新函数。</p>\n<p>为了消除装饰器对原函数的影响，需要伪装成原函数，拥有原函数的属性。可以利用functools：</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">auth</span><span class=\"token punctuation\">(</span>permission<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">_auth</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     @functools<span class=\"token punctuation\">.</span>wraps<span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># 注意此处</span>\n     <span class=\"token keyword\">def</span> <span class=\"token function\">wrapper</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>f<span class=\"token string\">\"验证权限[{permission}]...\"</span><span class=\"token punctuation\">)</span>\n       func<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n       <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"执行完毕...\"</span><span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">return</span> wrapper\n  <span class=\"token keyword\">return</span> _auth\n\n@auth<span class=\"token punctuation\">(</span><span class=\"token string\">\"add\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">add</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"\n  求和运算\n  \"\"\"</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"特殊例子\"><a href=\"#特殊例子\" class=\"headerlink\" title=\"特殊例子\"></a>特殊例子</h4><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">multi</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span> i<span class=\"token operator\">*</span>x <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> m <span class=\"token keyword\">in</span> multi<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># [9,9,9,9]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>闭包的延迟绑定导致的，在<strong>闭包中的变量是在内部函数被调用的时候被查找的</strong>，最后函数被调用的时候，for循环已经完成， i 的值最后是3，因此每一个返回值的i都是3，所以最后的结果是[9,9,9,9]</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># [0, 3, 6, 9]</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">multipliers</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">yield</span> <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> i <span class=\"token operator\">*</span>x<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"上下文管理\"><a href=\"#上下文管理\" class=\"headerlink\" title=\"上下文管理\"></a>上下文管理</h3><p>在一个类里，实现了<code>__enter__</code>和<code>__exit__</code>的方法，这个类的实例就是一个上下文管理器。</p>\n<p><strong>基本使用语法</strong></p>\n<pre class=\"line-numbers language-pyt\"><code class=\"language-pyt\">with EXPR as VAR:\n    BLOCK<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><strong>为什么要使用上下文管理器？</strong></p>\n<p>一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接；处理异常；</p>\n<p><strong>使用contextlib</strong></p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> contextlib\n\n@contextlib<span class=\"token punctuation\">.</span>contextmanager\n<span class=\"token keyword\">def</span> <span class=\"token function\">open_func</span><span class=\"token punctuation\">(</span>file_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># __enter__方法</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'open file:'</span><span class=\"token punctuation\">,</span> file_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'in __enter__'</span><span class=\"token punctuation\">)</span>\n    file_handler <span class=\"token operator\">=</span> open<span class=\"token punctuation\">(</span>file_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">yield</span> file_handler\n    <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> exc<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\"># deal with exception</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'the exception was thrown'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">finally</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'close file:'</span><span class=\"token punctuation\">,</span> file_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'in __exit__'</span><span class=\"token punctuation\">)</span>\n        file_handler<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span>\n\n<span class=\"token keyword\">with</span> open_func<span class=\"token punctuation\">(</span><span class=\"token string\">'/Users/MING/mytest.txt'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> file_in<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> file_in<span class=\"token punctuation\">:</span>\n        <span class=\"token number\">1</span><span class=\"token operator\">/</span><span class=\"token number\">0</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"编码和解码\"><a href=\"#编码和解码\" class=\"headerlink\" title=\"编码和解码\"></a>编码和解码</h3><h4 id=\"编码类型\"><a href=\"#编码类型\" class=\"headerlink\" title=\"编码类型\"></a>编码类型</h4><ul>\n<li>ascii ：一个字节表示一个字符，最多只能表示 256 个符号。</li>\n<li>unicode： 所有字符需要2个字节表示</li>\n<li>gbk：英文字符1个字节，中文字符两个字节</li>\n<li>utf-8：英文字符1个字节、 欧洲字符2个字节， 亚洲字符3个字节</li>\n</ul>\n<p>python2 的默认编码方式为ASCII码，python3默认的文件编码是UTF-8</p>\n<p>Python的字符串类型是<code>str</code>，在内存中以Unicode表示。</p>\n<blockquote>\n<p>如果我们从网络或磁盘上读取了字节流，那么读到的数据就是<code>bytes</code>。要把<code>bytes</code>变为<code>str</code>，就需要用<code>decode()</code>方法；</p>\n<p>如果要在网络上传输，或者保存到磁盘上，就需要把<code>str</code>变为以字节为单位的<code>bytes</code></p>\n</blockquote>\n<h3 id=\"pickling和unpickling？\"><a href=\"#pickling和unpickling？\" class=\"headerlink\" title=\"pickling和unpickling？\"></a>pickling和unpickling？</h3><p>模块 pickle 实现了对一个 Python 对象结构的二进制序列化和反序列化。</p>\n<p> “pickling” 是将 Python 对象及转化为一个字节流的过程</p>\n<p>“unpickling” 将字节流转化回一个对象层次结构。</p>\n<p>Pickle 协议和 JSON 间有着本质的<strong>不同</strong>：</p>\n<ul>\n<li>JSON 是一个文本序列化格式，而 pickle 是一个二进制序列化格式；</li>\n<li>JSON 是我们可以直观阅读的，而 pickle 不是；</li>\n<li>JSON在Python之外广泛使用，而pickle则是Python专用的；</li>\n<li>JSON 只能表示 Python 内置类型的子集，不能表示自定义的类；但 pickle 可以表示大量的 Python 数据类型。</li>\n</ul>\n<h3 id=\"说一下namedtuple的用法和作用\"><a href=\"#说一下namedtuple的用法和作用\" class=\"headerlink\" title=\"说一下namedtuple的用法和作用\"></a>说一下<code>namedtuple</code>的用法和作用</h3><p>只有属性没有方法的类，用于组织数据，称为数据类。</p>\n<p>在Python中可以用<code>namedtuple</code>（命名元组）来替代这种类。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> collections <span class=\"token keyword\">import</span> namedtuple\n\nCard <span class=\"token operator\">=</span> namedtuple<span class=\"token punctuation\">(</span><span class=\"token string\">'Card'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'suite'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'face'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ncard1 <span class=\"token operator\">=</span> Card<span class=\"token punctuation\">(</span><span class=\"token string\">'红桃'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">13</span><span class=\"token punctuation\">)</span>\ncard2 <span class=\"token operator\">=</span> Card<span class=\"token punctuation\">(</span><span class=\"token string\">'草花'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>f<span class=\"token string\">'{card1.suite}{card1.face}'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>f<span class=\"token string\">'{card2.suite}{card2.face}'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>命名元组与普通元组一样是不可变容器，一旦将数据存储在<code>namedtuple</code>的顶层属性中，数据就不能再修改了，</p>\n<p>对象上的所有属性都遵循“一次写入，多次读取”的原则。</p>\n<p>和普通元组不同的是，命名元组中的数据有访问名称，可以通过名称而不是索引来获取保存的数据</p>\n<p>命名元组的本质就是一个类，所以它还可以作为父类创建子类。</p>\n<p>除此之外，命名元组内置了一系列的方法，例如，可以通过<code>_asdict</code>方法将命名元组处理成字典，也可以通过<code>_replace</code>方法创建命名元组对象的浅拷贝。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">MyCard</span><span class=\"token punctuation\">(</span>Card<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">show</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        faces <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">''</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'3'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'5'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'6'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'7'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'8'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'9'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'10'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'J'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Q'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'K'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">return</span> f<span class=\"token string\">'{self.suite}{faces[self.face]}'</span>\n\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>Card<span class=\"token punctuation\">)</span>    <span class=\"token comment\" spellcheck=\"true\"># &lt;class '__main__.Card'></span>\ncard3 <span class=\"token operator\">=</span> MyCard<span class=\"token punctuation\">(</span><span class=\"token string\">'方块'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>card3<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\" spellcheck=\"true\"># 方块Q</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>dict<span class=\"token punctuation\">(</span>card1<span class=\"token punctuation\">.</span>_asdict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\" spellcheck=\"true\"># {'suite': '红桃', 'face': 13}</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>card2<span class=\"token punctuation\">.</span>_replace<span class=\"token punctuation\">(</span>suite<span class=\"token operator\">=</span><span class=\"token string\">'方块'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\" spellcheck=\"true\"># Card(suite='方块', face=5)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"面向对象\"><a href=\"#面向对象\" class=\"headerlink\" title=\"面向对象\"></a>面向对象</h2><p>继承：将多个类的共同属性和方法封装到一个父类下面，然后在用这些类来继承这个类的属性和方法</p>\n<p>封装：将有共同的属性和方法封装到同一个类下面</p>\n<p>多态：Python天生是支持多态的。指的是基类的同一个方法在不同的派生类中有着不同的功能</p>\n<h3 id=\"新式类和经典类\"><a href=\"#新式类和经典类\" class=\"headerlink\" title=\"新式类和经典类\"></a>新式类和经典类</h3><p>Python3里只有新式类；Python2里面继承object的是新式类，没有写父类的是经典类</p>\n<p><strong>区别</strong></p>\n<ul>\n<li>新式类 保持class与type的统一，对新式类的实例执行<code>a.__class__</code>与<code>type(a)</code>的结果是一致的</li>\n<li>旧式类的<code>type(a)</code>返回instance。</li>\n<li>多重继承的属性搜索顺序不一样，新式类是采用广度优先搜索，旧式类采用深度优先搜索。</li>\n</ul>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">A</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">foo1</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span> <span class=\"token string\">\"A\"</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">B</span><span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">foo2</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">pass</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">C</span><span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">foo1</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span> <span class=\"token string\">\"C\"</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">D</span><span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">pass</span>\n\n\nd <span class=\"token operator\">=</span> D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nd<span class=\"token punctuation\">.</span>foo1<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>缺点：</strong>经典类的查找顺序是深度优先的规则，在访问<code>d.foo1()</code>的时候,D-&gt;B-&gt;A,找到了<code>foo1()</code>,调用A的<code>foo1()</code>，导致C重写的<code>foo1()</code>被绕过</p>\n<h3 id=\"类方法、类实例方法、静态方法\"><a href=\"#类方法、类实例方法、静态方法\" class=\"headerlink\" title=\"类方法、类实例方法、静态方法\"></a>类方法、类实例方法、静态方法</h3><ul>\n<li><p>类方法: 是类对象的方法，使用 @classmethod 进行装饰，形参有cls，表示类对象</p>\n</li>\n<li><p>类实例方法: 是类实例化对象的方法，形参为self，指代对象本身;</p>\n</li>\n<li><p>静态方法: 是一个任意函数，使用 @staticmethod 进行装饰</p>\n<blockquote>\n<p>实例方法只能通过实例对象调用；</p>\n<p>类方法和静态方法可以通过类对象或者实例对象调用，</p>\n<p>使用实例对象调用的类方法或静态方法，最终通过类对象调用。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"如何判断是函数还是方法？\"><a href=\"#如何判断是函数还是方法？\" class=\"headerlink\" title=\"如何判断是函数还是方法？\"></a>如何判断是函数还是方法？</h3><p>如果是以函数的形式定义或者是静态方法，一定是函数</p>\n<p>如果是类方法，一定是方法。</p>\n<p>实例方法是方法，如果类直接调用实例方法，则是函数（直接调用运行是有问题的）。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> types <span class=\"token keyword\">import</span> MethodType<span class=\"token punctuation\">,</span>FunctionType\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>isinstance<span class=\"token punctuation\">(</span>obj<span class=\"token punctuation\">.</span>func<span class=\"token punctuation\">,</span> FunctionType<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>isinstance<span class=\"token punctuation\">(</span>obj<span class=\"token punctuation\">.</span>func<span class=\"token punctuation\">,</span> MethodType<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"接口类与抽象类\"><a href=\"#接口类与抽象类\" class=\"headerlink\" title=\"接口类与抽象类\"></a>接口类与抽象类</h3><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Operate_database</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>    <span class=\"token comment\" spellcheck=\"true\"># 接口类1</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">query</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> NotImplementedError\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">update</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> NotImplementedError\n\n<span class=\"token keyword\">from</span> abc <span class=\"token keyword\">import</span> ABCMeta<span class=\"token punctuation\">,</span>abstractmethod\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Operate_database</span><span class=\"token punctuation\">(</span>metaclass<span class=\"token operator\">=</span>ABCMeta<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>    <span class=\"token comment\" spellcheck=\"true\"># 接口类2</span>\n    @abstractmethod\n    <span class=\"token keyword\">def</span> <span class=\"token function\">query</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">pass</span>\n\n    @abstractmethod\n    <span class=\"token keyword\">def</span> <span class=\"token function\">update</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">pass</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p> Python 原生仅支持抽象类，不支持接口类，abc模块就是用来实现抽象类的。</p>\n<p>若是类中所有的方法都没有实现，则认为这是一个接口，</p>\n<p>若是有部分方法实现，则认为这是一个抽象类。</p>\n<p>抽象类和接口类都仅用于被继承，不能被实例化.</p>\n<h3 id=\"描述符\"><a href=\"#描述符\" class=\"headerlink\" title=\"描述符\"></a>描述符</h3><p><strong>一个实现了描述符协议的类就是一个描述符。</strong></p>\n<p><strong>描述符协议：实现了<code>__get__()</code>、<code>__set__()</code>、<code>__delete__()</code>其中至少一个方法的类，就是一个描述符。</strong></p>\n<p><code>__get__</code>： 用于访问属性。它返回属性的值，若属性不存在、不合法等都可以抛出对应的异常。</p>\n<p><code>__set__</code>：将在属性分配操作中调用。</p>\n<p><code>__delete__</code>：控制删除操作。</p>\n<p>描述符的作用和优势，以弥补Python动态类型的缺点。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Score</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>_score <span class=\"token operator\">=</span> default\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__set__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> instance<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> isinstance<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">,</span> int<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       <span class=\"token keyword\">raise</span> TypeError<span class=\"token punctuation\">(</span><span class=\"token string\">'Score must be integer'</span><span class=\"token punctuation\">)</span>\n\n     <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> <span class=\"token number\">0</span> <span class=\"token operator\">&lt;=</span> value <span class=\"token operator\">&lt;=</span> <span class=\"token number\">100</span><span class=\"token punctuation\">:</span>\n       <span class=\"token keyword\">raise</span> ValueError<span class=\"token punctuation\">(</span><span class=\"token string\">'Valid value must be in [0, 100]'</span><span class=\"token punctuation\">)</span>\n\n     self<span class=\"token punctuation\">.</span>_score <span class=\"token operator\">=</span> value\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__get__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> instance<span class=\"token punctuation\">,</span> owner<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_score\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__delete__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">del</span> self<span class=\"token punctuation\">.</span>_score    \n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Student</span><span class=\"token punctuation\">:</span>\n  math <span class=\"token operator\">=</span> Score<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n  chinese <span class=\"token operator\">=</span> Score<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n  english <span class=\"token operator\">=</span> Score<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">,</span> math<span class=\"token punctuation\">,</span> chinese<span class=\"token punctuation\">,</span> english<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> name\n     self<span class=\"token punctuation\">.</span>math <span class=\"token operator\">=</span> math\n     self<span class=\"token punctuation\">.</span>chinese <span class=\"token operator\">=</span> chinese\n     self<span class=\"token punctuation\">.</span>english <span class=\"token operator\">=</span> english<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>staticmethod</strong></p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Test</span><span class=\"token punctuation\">:</span>\n  @staticmethod\n  <span class=\"token keyword\">def</span> <span class=\"token function\">myfunc</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># 上下两种写法等价</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Test</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">myfunc</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token comment\" spellcheck=\"true\"># 重点：这就是描述符的体现</span>\n  <span class=\"token comment\" spellcheck=\"true\"># 每调用一次，它都会经过描述符类的 __get__</span>\n  myfunc <span class=\"token operator\">=</span> staticmethod<span class=\"token punctuation\">(</span>myfunc<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>classmethod</strong></p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">classmethod</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     self<span class=\"token punctuation\">.</span>f <span class=\"token operator\">=</span> f\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__get__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> instance<span class=\"token punctuation\">,</span> owner<span class=\"token operator\">=</span>None<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"in classmethod __get__\"</span><span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">def</span> <span class=\"token function\">newfunc</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>f<span class=\"token punctuation\">(</span>owner<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">return</span> newfunc\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Test</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">myfunc</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token comment\" spellcheck=\"true\"># 重点：这就是描述符的体现</span>\n  myfunc <span class=\"token operator\">=</span> classmethod<span class=\"token punctuation\">(</span>myfunc<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"元类\"><a href=\"#元类\" class=\"headerlink\" title=\"元类\"></a>元类</h3><p><strong>元类是用来创建类的类。</strong></p>\n<p>如果类属性中定义了<code>__metaclass__</code>，则在创建类的时候用元类来创建；</p>\n<p>如果没有则向其父类查找<code>__metaclass__</code>。</p>\n<p>如果都没有，则用<code>type()</code>创建类。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># metaclass是类的模板，所以必须从`type`类型派生：</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ListMetaclass</span><span class=\"token punctuation\">(</span>type<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__new__</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">,</span> bases<span class=\"token punctuation\">,</span> attrs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        attrs<span class=\"token punctuation\">[</span><span class=\"token string\">'add'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> self<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> type<span class=\"token punctuation\">.</span>__new__<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">,</span> bases<span class=\"token punctuation\">,</span> attrs<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">MyList</span><span class=\"token punctuation\">(</span>list<span class=\"token punctuation\">,</span> metaclass<span class=\"token operator\">=</span>ListMetaclass<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>传入关键字参数<code>metaclass</code>时，指示Python解释器在创建<code>MyList</code>时，要通过<code>ListMetaclass.__new__()</code>来创建</p>\n<p>在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。</p>\n<p><code>__new__()</code>方法接收到的参数依次是：</p>\n<ol>\n<li>当前准备创建的类的对象；</li>\n<li>类的名字；</li>\n<li>类继承的父类集合；</li>\n<li>类的方法集合。</li>\n</ol>\n<p><strong>元类作用</strong></p>\n<ul>\n<li>拦截类的创建</li>\n<li>修改类</li>\n<li>返回修改后的类</li>\n</ul>\n<p><strong>应用场景</strong></p>\n<p>ORM：所有的类都只能动态定义，因为只有使用者才能根据表的结构定义出对应的类来。</p>\n<h2 id=\"字典\"><a href=\"#字典\" class=\"headerlink\" title=\"字典\"></a>字典</h2><p>字典的查询、添加、删除的平均时间复杂度都是<code>O(1)</code>。因为字典是通过哈希表来实现的.</p>\n<ul>\n<li><p>计算key的hash值<code>hash(key)</code>，再和mask做与操作【mask=字典最小长度（DictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的enteies哈希表中的下标位置</p>\n</li>\n<li><p>若index下标位置已经被占用，则会判断enteies的key是否与要插入的key是否相等</p>\n<ul>\n<li><p>如果key相等就表示key已存在，则更新value值</p>\n</li>\n<li><p>如果key不相等，就表示hash冲突，则会继续向下寻找空位置，一直到找到剩余空位为止。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"开放寻址法\"><a href=\"#开放寻址法\" class=\"headerlink\" title=\"开放寻址法\"></a><strong>开放寻址法</strong></h3><p>开放寻址法中，所有的元素都存放在散列表里，当产生哈希冲突时，通过一个探测函数计算出下一个候选位置，如果下一个获选位置还是有冲突，不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。</p>\n<blockquote>\n<p>开放寻址法中解决冲突的方法有：线行探查法、平方探查法、双散列函数探查法</p>\n</blockquote>\n<p>采用哈希表，dict的哈希表里每个slot都是一个自定义的entry结构：</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">typedef</span> <span class=\"token keyword\">struct</span> <span class=\"token punctuation\">{</span>\n   Py_ssize_t me_hash<span class=\"token punctuation\">;</span>\n   PyObject <span class=\"token operator\">*</span>me_key<span class=\"token punctuation\">;</span>\n   PyObject <span class=\"token operator\">*</span>me_value<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> PyDictEntry<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>每个entry有三种状态Active, Unused, Dummy。</p>\n<ul>\n<li><p>Unused:me_key == me_value == NULL，即未使用的空闲状态。</p>\n</li>\n<li><p>Active:me_key != NULL, me_value != NULL，即该entry已被占用</p>\n</li>\n<li><p>Dummy:me_key == dummy, me_value == NULL。</p>\n</li>\n</ul>\n<p><strong>为什么entry有Dummy状态呢？</strong></p>\n<p>用开放寻址法中，<strong>遇到哈希冲突时会找到下一个合适的位置，</strong>例如ABC构成了探测链，查找元素时如果hash值相同，那么也是<strong>顺着这条探测链不断往后找</strong>，当删除探测链中的某个元素时，如果直接把B从哈希表中移除，即变成Unused状态，那么C就不可能再找到了，因此需要Dummy保证探测链的连续性。</p>\n<p>dict对象的定义为：</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> _dictobject <span class=\"token punctuation\">{</span>\n  PyObject _HEAD\n  Py_ssize_t ma_fill<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">/* # Active + # Dummy */</span>\n  Py_ssize_t ma_used<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">/* # Active */</span>\n  Py_ssize_t ma_mask<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//slot -1</span>\n  PyDictEntry <span class=\"token operator\">*</span>ma_table<span class=\"token punctuation\">;</span>\n  PyDictEntry <span class=\"token operator\">*</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>ma_lookup<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>PyDictObject <span class=\"token operator\">*</span>mp<span class=\"token punctuation\">,</span> PyObject <span class=\"token operator\">*</span>key<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> hash<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 搜索函数指针</span>\n  PyDictEntry ma_smalltable<span class=\"token punctuation\">[</span>PyDict_MINSIZE<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//默认的slot</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"dict对象的创建\"><a href=\"#dict对象的创建\" class=\"headerlink\" title=\"dict对象的创建\"></a><strong>dict对象的创建</strong></h3><p>dict对象的创建很简单，先看看缓冲的对象池里有没有可用对象，如果有就直接用，没有就从堆上申请。</p>\n<h3 id=\"dict对象的插入\"><a href=\"#dict对象的插入\" class=\"headerlink\" title=\"dict对象的插入\"></a><strong>dict对象的插入</strong></h3><p>如果不存在key-value则插入，存在则覆盖。</p>\n<ul>\n<li>生成Hash</li>\n<li>如果可用的entry&lt;0，字典扩容</li>\n<li>基于key、hash，查找可用哈希位置，以便于存储<ul>\n<li>字典中是否有空余的值，或者如果找到了满足 hash 值与 key 相同的,就将 value 设置为找到的值</li>\n</ul>\n</li>\n<li>保存key、Hash、value值</li>\n</ul>\n<h3 id=\"dict对象的删除\"><a href=\"#dict对象的删除\" class=\"headerlink\" title=\"dict对象的删除\"></a><strong>dict对象的删除</strong></h3><p>算出哈希值，找到entry，将其从Active转换成Dummy，并调整table的容量。</p>\n<p><strong>注意</strong></p>\n<p>（1） dict的key 或者 set的值都必须是可hash的不可变对象，都是可hash的</p>\n<p>（2）当发现内存空间中的“空”只有1/3时，便会触发扩容操作。</p>\n<h2 id=\"整数\"><a href=\"#整数\" class=\"headerlink\" title=\"整数\"></a>整数</h2><p>Python使用<strong>小整数对象池</strong>small_ints缓存了[-5，257）之间的整数，该范围内的整数在Python系统中是共享的，值相同就属于同一个对象。</p>\n<p>对于同一个代码块中值不在<code>small_ints</code>缓存范围内的整数，如果同一个代码块中已经存在一个值与其相同的整数对象，那么就直接引用该对象，否则创建新的<code>int</code>对象。</p>\n<h2 id=\"字符串-1\"><a href=\"#字符串-1\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>Python解释器中使用了 intern（字符串驻留）的技术来提高字符串效率，值同样的字符串对象仅仅会保存一份，放在一个字符串储蓄池中，是共用的。</p>\n<p><strong>简单原理</strong></p>\n<p>维护一个字符串存储池，这个池子是一个字典结构</p>\n<p>如果字符串已经存在于池子中，直接返回之前创建好的字符串对象，</p>\n<p>如果不存在，则构造一个字符串对象并加入到池子中去。</p>\n<blockquote>\n<p>在shell中，并非全部的字符串都会采用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。不能超过20个字符。因为如果超过xx个字符的话，解释器认为这个字符串不常用，不用放入字符串池中。</p>\n<p>字符串拼接时，运行时拼接，不会intern；例如”hell” + “o”在编译时完成拼接的才会intern</p>\n</blockquote>\n<h2 id=\"堆-栈\"><a href=\"#堆-栈\" class=\"headerlink\" title=\"堆 栈\"></a>堆 栈</h2><p>在Python中，变量也称为：对象的引用。变量存储的就是对象的地址。</p>\n<p><strong>变量位于：栈内存。</strong></p>\n<p><strong>对象位于：堆内存。</strong></p>\n<p>内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。</p>\n<p><strong>代码区：</strong>程序中的代码数据、二进制数据、方法数据等等程序运行需要的预加载数据。</p>\n<p><strong>静态数据区：</strong>存储<strong>全局变量、静态变量</strong>。</p>\n<p><strong>栈区：</strong>存储变量。存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。</p>\n<p><strong>堆区</strong>：对象真实数据。</p>\n<h2 id=\"内存回收机制\"><a href=\"#内存回收机制\" class=\"headerlink\" title=\"内存回收机制\"></a>内存回收机制</h2><p>python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略。</p>\n<h3 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a><strong>引用计数法</strong></h3><p><strong>原理：</strong>每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数加1，每当该对象的引用失效时，计数减1，一旦对象的引用计数为0，该对象立即被回收，占用的内存空间将被释放。</p>\n<p><strong>缺点：</strong>不能解决对象的循环引用</p>\n<h3 id=\"标记清除\"><a href=\"#标记清除\" class=\"headerlink\" title=\"标记清除\"></a>标记清除</h3><p>解决容器对象可能产生的循环引用问题。（只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等）</p>\n<p><strong>A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达</strong>；</p>\n<p>B）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。</p>\n<h3 id=\"分代回收\"><a href=\"#分代回收\" class=\"headerlink\" title=\"分代回收\"></a>分代回收</h3><p>标记清除时，应用程序会被暂停，为了减少应用程序暂停的时间。</p>\n<p><strong>对象存在时间越长，越可能不是垃圾，应该越少去收集</strong>。</p>\n<p>给对象定义了三种世代，每一个新生对象在0代中，如果它在一轮gc扫描中活了下来，那么它将被移至1代，在那里他将较少的被扫描，如果它又活过了一轮gc，它又将被移至2代，在那里它被扫描的次数将会更少。</p>\n<h3 id=\"gc的扫描在什么时候会被触发呢\"><a href=\"#gc的扫描在什么时候会被触发呢\" class=\"headerlink\" title=\"gc的扫描在什么时候会被触发呢?\"></a><strong>gc的扫描在什么时候会被触发呢</strong>?</h3><p>年轻代链表的总数达到上限时。</p>\n<p>当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。</p>\n<h3 id=\"调优手段\"><a href=\"#调优手段\" class=\"headerlink\" title=\"调优手段\"></a><strong>调优手段</strong></h3><p>1.手动垃圾回收</p>\n<p>2.调高垃圾回收阈值</p>\n<p>3.避免循环引用</p>\n<h2 id=\"退出Python时，是否释放全部内存？\"><a href=\"#退出Python时，是否释放全部内存？\" class=\"headerlink\" title=\"退出Python时，是否释放全部内存？\"></a>退出Python时，是否释放全部内存？</h2><p>进程退出的时候，资源最终都会释放掉，这是操作系统负责的。</p>\n<p>如果是一段程序运行结束之后：</p>\n<ol>\n<li>CPython会通过引用计数立即释放引用数量为0的对象（其它版本解释器并不保证）；循环引用的对象会在下一次GC时释放，除非有两个对象都带有<code>__del__</code>析构函数，且直接或间接循环引用。这种情况下，所有循环引用的对象都无法被释放。原因在于无法确定<code>__del__</code>的执行顺序。</li>\n<li>全局引用的对象无法被回收，但也不只是模块中直接或间接保存的对象，还包括未退出的线程使用的对象，解释器缓存的小整数和字符串，还有C模块里间接引用的对象等等。</li>\n<li>C扩展直接通过malloc分配的内存自然无法通过gc来回收，但一般如果存在没有被回收的内存说明是有内存泄漏的，这属于实现的bug</li>\n</ol>\n<h2 id=\"协程，线程和进程\"><a href=\"#协程，线程和进程\" class=\"headerlink\" title=\"协程，线程和进程\"></a>协程，线程和进程</h2><h3 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h3><p>进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。在Python中，进程适合计算密集型任务。</p>\n<h4 id=\"进程间的通信（IPC）\"><a href=\"#进程间的通信（IPC）\" class=\"headerlink\" title=\"进程间的通信（IPC）\"></a>进程间的通信（IPC）</h4><p><strong>1）管道（Pipe</strong>）：通过<code>send()</code>和<code>recv()</code>来发送和接受信息，适合父子进程关系或者两个子进程之间。 </p>\n<p>2）<strong>有名管道（FIFO）</strong>：有名管道也是半双工的通信方式。 将自己注册到文件系统里一个文件，通过读写这个文件进行通信。允许在没有亲缘关系的进程之间使用。要求读写双方必须同时打开才可以继续进行读写操作，否则打开操作会堵塞直到对方也打开。</p>\n<p>3）<strong>信号量（Semaphore）</strong>：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 创建子进程时将信号量my_semaphore作为参数传入子进程任务函数，子进程中使用semaphore.acquire() 尝试获取信号量，semaphore.release()尝试 释放信号量。</p>\n<p><strong>4）队列（Queue）</strong>。 使用get/put在父子进程关系或者两个子进程之间通信。</p>\n<p>5）<strong>信号 （signal）</strong>：用于通知接收进程某个事件已经发生，可以设置信号处理函数。 </p>\n<p>6）共享内存（shared memory）：操作系统负责将同一份物理地址的内存映射到多个进程的不同的虚拟地址空间中。进而每个进程都可以操作这份内存。需要在进程访问时做好并发控制，比如使用信号量。 python标准库mmap，apache开源的pyarrow都是。</p>\n<p>7）套接字（socket）：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。 </p>\n<p><strong>8）文件</strong> </p>\n<p>（1）仅进程同步不涉及数据传输，可以使用信号、信号量；<br>（2）若进程间需要传递少量数据，可以使用管道、有名管道、队列；<br>（3）若进程间需要传递大量数据，最佳方式是使用共享内存，推荐使用pyarrow，这样减少数据拷贝、传输的时间内存代价；<br>（4）跨主机的进程间通信（RPC）可以使用socket通信。</p>\n<p><strong>共享变量</strong></p>\n<p>使用 Process 定义的多进程之间（父子或者兄弟）共享变量可以直接使用 multiprocessing 下的 Value，Array，Queue 等，如果要共享 list，dict，可以使用强大的 Manager 模块。</p>\n<h3 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h3><p>线程是cpu调度执行的最小单位，依赖进程存在，一个进程至少有一个线程。在python中，线程适合IO密集型任务。</p>\n<p>同一个进程下的线程共享程序的内存空间<strong>（如代码段，全局变量，堆栈等）</strong></p>\n<h4 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h4><p>继承Thread，重写run方法，通过start方法开线程</p>\n<p>将要执行的方法作为参数传给Thread的构造方法</p>\n<h4 id=\"状态\"><a href=\"#状态\" class=\"headerlink\" title=\"状态\"></a>状态</h4><p>线程有五种状态:创建、就绪、运行、阻塞、死亡。 </p>\n<ul>\n<li><p>调用start方法时，线程就会进入就绪状态。 </p>\n</li>\n<li><p>在线程得到cpu时间片时进入运行状态。 </p>\n</li>\n<li><p><strong>线程调用yield方法可以让出cpu时间回到就绪状态</strong>。 </p>\n</li>\n<li><p>线程运行时可能<strong>由于IO、调用sleep、wait、join方法或者无法获得同步锁等原因进入阻塞</strong>状态。 </p>\n</li>\n<li><p>当线程获得到等待的资源资源或者引起阻塞的条件得到满足时，会从阻塞状态进入就绪状态。 </p>\n</li>\n<li><p>当线程的run方法执行结束时，线程就进入死亡状态。</p>\n</li>\n</ul>\n<h4 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h4><p>多个线程同时对一个公共资源（如全局变量）进行操作的情况，为了避免发生混乱。<code>threading.lock</code>，<code>acquire()</code>方法上锁，<code>release()</code>方法解锁</p>\n<p>可重入锁：为了支持在同一线程中多次请求同一资源，python提供了threading.RLock。重入锁必须由获取它的同一个线程释放，同时要求解锁次数应与加锁次数相同，才能用于另一个线程。</p>\n<h4 id=\"同步\"><a href=\"#同步\" class=\"headerlink\" title=\"同步\"></a>同步</h4><p>阻塞线程直到子线程全部结束。</p>\n<h4 id=\"守护线程\"><a href=\"#守护线程\" class=\"headerlink\" title=\"守护线程\"></a>守护线程</h4><p>不重要线程。主线程会等所有‘重要’线程结束后才结束。</p>\n<h4 id=\"线程池的工作原理\"><a href=\"#线程池的工作原理\" class=\"headerlink\" title=\"线程池的工作原理\"></a>线程池的工作原理</h4><p>减少线程本身创建和销毁造成的开销，属于典型的空间换时间操作。</p>\n<p>创建和释放线程涉及到大量的系统底层操作，开销较大，如果变成预创建和借还操作，将大大减少底层开销。</p>\n<ul>\n<li>在应用程序启动后，线程池创建一定数量的线程，放入空闲队列中。这些线程最开始都处于阻塞状态，不会消耗CPU，占用少量的内存。</li>\n<li>当任务到来后，从队列中取出一个空闲线程，把任务派发到这个线程中运行，并将标记为已占用。</li>\n<li>当线程池中所有的线程都被占用后，可以选择自动创建一定数量的新线程，用于处理更多的任务，也可以选择让任务排队等待直到有空闲的线程可用。</li>\n<li>在任务执行完毕后，线程并不退出结束，而是继续保持在池中等待下一次的任务。</li>\n<li>当系统比较空闲时，大部分线程长时间处于闲置状态时，线程池可以自动销毁一部分线程，回收系统资源。</li>\n</ul>\n<p>线程池组成部分：</p>\n<ol>\n<li>线程池管理器：用于创建并管理线程池。</li>\n<li>工作线程和线程队列：线程池中实际执行的线程以及保存这些线程的容器。</li>\n<li>任务接口：将线程执行的任务抽象出来，形成任务接口，确保线程池与具体的任务无关。</li>\n<li>任务队列：线程池中保存等待被执行的任务的容器。</li>\n</ol>\n<h3 id=\"协程\"><a href=\"#协程\" class=\"headerlink\" title=\"协程\"></a>协程</h3><p>协程是一种用户态的轻量级线程，调度完全由用户控制。</p>\n<p>协程拥有自己的寄存器上下文和栈。协程的切换都在用户空间内进行，不需要进行系统调用。</p>\n<p>协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，基本没有内核切换的开销，可以不加锁的访问全局变量，上下文的切换非常快。</p>\n<p><strong>如何利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能</strong>。</p>\n<p><strong>常用模块</strong></p>\n<p>greenlet：提供了切换任务的快捷方式，但是遇到io无法自动切换任务，需要手动切换</p>\n<p>gevent：开启协程任务并切换的模块，遇到io自动切换任务。</p>\n<p>asyncio：<code>@asyncio.coroutine</code>装饰器的函数称为协程函数。</p>\n<p><code>yield from</code>语法用于将一个生成器部分操作委托给另一个生成器。</p>\n<p><code>async</code>/<code>await</code>：<code>@asyncio.coroutine</code>和<code>yield from</code>的语法糖</p>\n<p><strong>缺点</strong></p>\n<ul>\n<li><p>无法利用多核资源：协程的本质是个单线程</p>\n</li>\n<li><p>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序</p>\n</li>\n</ul>\n<p><strong>协程主要使用场景</strong></p>\n<p>网络请求，比如爬虫，大量使用 aiohttp</p>\n<p>文件读取， aiofile</p>\n<p>web 框架， aiohttp， fastapi</p>\n<p>数据库查询， asyncpg, databases</p>\n<p><strong>协程优于线程</strong></p>\n<ul>\n<li>python 线程调度方式是，每执行 100 个字节码或者遇到阻塞就停止当前线程，然后进行一个系统调用，让 os 内核选出下一个线程。但是协程 只会在 阻塞的时候，切换到下一个协程。100个字节码，说多不多，说少不少，你调用两个库函数说不定就没了，因此线程的切换存在很多是无效的切换，当线程数量越大，这种因为调度策略的先天不足带来的性能损耗就越大。</li>\n<li>线程需要进行系统调用，协程不需要。系统调用需要进入内核态，无效的调度会让这部分开销显得更大</li>\n<li>协程可以自主调度，而线程只能决定合适退出，但是下一个线程是谁则依赖于操作系统。</li>\n</ul>\n<h3 id=\"僵尸进程和孤儿进程\"><a href=\"#僵尸进程和孤儿进程\" class=\"headerlink\" title=\"僵尸进程和孤儿进程\"></a>僵尸进程和孤儿进程</h3><p>孤儿进程： <strong>父进程退出，子进程还在运行的这些子进程都是孤儿进程，</strong>孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。</p>\n<p>僵尸进程： 进程使用fork 创建子进程<strong>，如果子进程退出，而父进程并没有调用wait 获取子进程的状态信息</strong>，那么子进程的进程描述符仍然保存在系统中，这些进程是僵尸进程。</p>\n<p>避免僵尸进程的方法：</p>\n<p>1.用<code>wait()</code>函数使父进程阻塞</p>\n<p>2.使用信号量，在signal handler 中调用waitpid，这样父进程不用阻塞</p>\n<p><strong>3.fork 两次用孙子进程去完成子进程的任务（？？？）</strong></p>\n<h2 id=\"Global-Interpreter-Lock-全局解释器锁\"><a href=\"#Global-Interpreter-Lock-全局解释器锁\" class=\"headerlink\" title=\"Global Interpreter Lock(全局解释器锁)\"></a>Global Interpreter Lock(全局解释器锁)</h2><p>Python 默认的解释器是 CPython，<strong>GIL 是存在于 CPython 解释器中的</strong>。</p>\n<p>执行 Python 字节码时，为了保护访问 Python 对象而阻止多个线程执行的一把互斥锁。主要是因为 CPython 解释器的内存管理不是线程安全的。</p>\n<p>常见的 Python 解释器：IPython（基于Cython）、IPython、Jython（可以把 Python 代码编译成 Java 字节码，依赖 Java 平台，不存在 GIL）、IronPython（运行在微软的 .Net 平台下的 Python 解释器，可以把 Python 代码编译成 .Net 字节码，不存在 GIL）</p>\n<h3 id=\"GIL原理\"><a href=\"#GIL原理\" class=\"headerlink\" title=\"GIL原理\"></a>GIL原理</h3><p>python 的线程就是 C 语言的 pthread，它是通过操作系统调度算法调度执行的。</p>\n<p>Python 2.x 的代码执行是基于 opcode 数量的调度方式，简单来说就是每执行一定数量的字节码，或遇到系统 IO 时，会强制释放 GIL，然后触发一次操作系统的线程调度。</p>\n<p> Python 3.x 基于固定时间的调度方式，就是每执行固定时间的字节码，或遇到系统 IO 时，强制释放 GIL，触发系统的线程调度。</p>\n<h3 id=\"为什么会有GIL\"><a href=\"#为什么会有GIL\" class=\"headerlink\" title=\"为什么会有GIL\"></a>为什么会有GIL</h3><p>Python 设计者在设计解释器时，可能没有想到 CPU 的性能提升会这么快转为多核心方向发展，所以在当时的场景下，设计一个全局锁是那个时代保护多线程资源一致性最简单经济的设计方案。</p>\n<p>多核心时代来临，当大家试图去拆分和去除 GIL 的时候，发现大量库的代码和开发者已经重度依赖 GIL（默认认为 Pythonn内部对象是线程安全的，无需在开发时额外加锁），所以这个去除 GIL 的任务变得复杂且难以实现。</p>\n<h2 id=\"性能分析\"><a href=\"#性能分析\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>python 内置了丰富的性能分析工具，<strong>如 profile,cProfile 与 hotshot 等</strong>。其中 Profiler 是 python 自带的一组程序，能够描述程序运行时候的性能，并提供各种统计帮助用户定位程序的性能瓶颈。</p>\n<p>Python 标准库提供了同一分析接口的两种不同实现：</p>\n<ol>\n<li>建议使用 <a href=\"https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile\" target=\"_blank\" rel=\"noopener\"><code>cProfile</code></a> ；这是一个 C 扩展插件，因为其合理的运行开销，所以适合于分析长时间运行的程序。</li>\n<li><a href=\"https://docs.python.org/zh-cn/3/library/profile.html#module-profile\" target=\"_blank\" rel=\"noopener\"><code>profile</code></a> 是一个纯 Python 模块（<a href=\"https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile\" target=\"_blank\" rel=\"noopener\"><code>cProfile</code></a> 就是模拟其接口的 C 语言实现），但它会显著增加配置程序的开销。如果你正在尝试以某种方式扩展分析器，则使用此模块可能会更容易完成任务</li>\n</ol>\n<p>支持输出：调用次数、在指定函数中消耗的总时间（不包括调用子函数的时间）、指定的函数及其所有子函数（从调用到退出）消耗的累积时间、函数运行一次的平均时间</p>\n<h2 id=\"单例模式\"><a href=\"#单例模式\" class=\"headerlink\" title=\"单例模式\"></a>单例模式</h2><h3 id=\"使用装饰器\"><a href=\"#使用装饰器\" class=\"headerlink\" title=\"使用装饰器\"></a><strong>使用装饰器</strong></h3><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">singleton</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  instances <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">wrapper</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">if</span> cls <span class=\"token operator\">not</span> <span class=\"token keyword\">in</span> instances<span class=\"token punctuation\">:</span>\n       instances<span class=\"token punctuation\">[</span>cls<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> cls<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">return</span> instances<span class=\"token punctuation\">[</span>cls<span class=\"token punctuation\">]</span>\n\n  <span class=\"token keyword\">return</span> wrapper\n\n@singleton\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Foo</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">pass</span>\n\nfoo1 <span class=\"token operator\">=</span> Foo<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfoo2 <span class=\"token operator\">=</span> Foo<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>foo1 <span class=\"token keyword\">is</span> foo2<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># True</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"使用new\"><a href=\"#使用new\" class=\"headerlink\" title=\"使用new\"></a>使用new</h3><p>New 是真正创建实例对象的方法，所以重写基类的new 方法，以此保证创建对象的时候只生成一个实例。</p>\n<p>但是以上的方法在多线程中会有线程安全问题，当有多个线程同时去初始化对象时，就很可能同时判断__instance is None，从而进入初始化instance的代码中。所以需要用<strong>互斥锁</strong>来解决这个问题。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__new__</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> hasattr<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token string\">'_instance'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n       cls<span class=\"token punctuation\">.</span>_instance <span class=\"token operator\">=</span> super<span class=\"token punctuation\">(</span>Singleton<span class=\"token punctuation\">,</span> cls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__new__<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>_instance\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  __instance <span class=\"token operator\">=</span> None\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__new__</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     <span class=\"token keyword\">if</span> cls<span class=\"token punctuation\">.</span>__instance <span class=\"token keyword\">is</span> None<span class=\"token punctuation\">:</span>\n       cls<span class=\"token punctuation\">.</span>__instance <span class=\"token operator\">=</span> super<span class=\"token punctuation\">(</span>Singleton<span class=\"token punctuation\">,</span> cls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__new__<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n     <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>__instance\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Foo</span><span class=\"token punctuation\">(</span>Singleton<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">pass</span>\n\nfoo1 <span class=\"token operator\">=</span> Foo<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfoo2 <span class=\"token operator\">=</span> Foo<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>foo1 <span class=\"token keyword\">is</span> foo2<span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\"># True</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"classmethod\"><a href=\"#classmethod\" class=\"headerlink\" title=\"classmethod\"></a>classmethod</h3><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> threading\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     _instance_lock <span class=\"token operator\">=</span> threading<span class=\"token punctuation\">.</span>Lock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>        \n    @classmethod\n    <span class=\"token keyword\">def</span> <span class=\"token function\">instance</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">with</span> Singleton<span class=\"token punctuation\">.</span>_instance_lock<span class=\"token punctuation\">:</span> <span class=\"token comment\" spellcheck=\"true\"># 加锁</span>\n            <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> hasattr<span class=\"token punctuation\">(</span>Singleton<span class=\"token punctuation\">,</span> <span class=\"token string\">'_instance'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                Singleton<span class=\"token punctuation\">.</span>_instance <span class=\"token operator\">=</span> Singleton<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> Singleton<span class=\"token punctuation\">.</span>_instance<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"元类-1\"><a href=\"#元类-1\" class=\"headerlink\" title=\"元类\"></a>元类</h3><p>元类是用于创建类对象的类，类对象创建实例对象时一定要调用call方法，因此在调用call时候保证始终只创建一个实例即可，type是python的元类</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span>type<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__call__</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> hasattr<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token string\">'_instance'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            cls<span class=\"token punctuation\">.</span>_instance <span class=\"token operator\">=</span> super<span class=\"token punctuation\">(</span>Singleton<span class=\"token punctuation\">,</span> cls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__call__<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>_instance\n\n\n<span class=\"token comment\" spellcheck=\"true\"># Python2</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Foo</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    __metaclass__ <span class=\"token operator\">=</span> Singleton<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"线程安全装饰器\"><a href=\"#线程安全装饰器\" class=\"headerlink\" title=\"线程安全装饰器\"></a><strong>线程安全装饰器</strong></h3><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">make_synchronized</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">import</span> threading\n    func<span class=\"token punctuation\">.</span>__lock__ <span class=\"token operator\">=</span> threading<span class=\"token punctuation\">.</span>Lock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># 用装饰器实现同步锁</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">synced_func</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">with</span> func<span class=\"token punctuation\">.</span>__lock__<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> func<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> synced_func\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span>object<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    __instance <span class=\"token operator\">=</span> None\n\n    @make_synchronized\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__new__</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> cls<span class=\"token punctuation\">.</span>__instance<span class=\"token punctuation\">:</span>\n            cls<span class=\"token punctuation\">.</span>__instance <span class=\"token operator\">=</span> object<span class=\"token punctuation\">.</span>__new__<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>__instance\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>blog <span class=\"token operator\">=</span> <span class=\"token string\">\"blog\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"线程安全–元类\"><a href=\"#线程安全–元类\" class=\"headerlink\" title=\"线程安全–元类\"></a><strong>线程安全–元类</strong></h3><pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> threading\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">MetaSingleton</span><span class=\"token punctuation\">(</span>type<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    _instance_lock <span class=\"token operator\">=</span> threading<span class=\"token punctuation\">.</span>Lock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__call__</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> hasattr<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token string\">'_instance'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">with</span> MetaSingleton<span class=\"token punctuation\">.</span>_instance_lock<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> hasattr<span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> <span class=\"token string\">'_instance'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    cls<span class=\"token punctuation\">.</span>_instance <span class=\"token operator\">=</span> super<span class=\"token punctuation\">(</span>MetaSingleton<span class=\"token punctuation\">,</span> cls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__call__<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> cls<span class=\"token punctuation\">.</span>_instance\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span>metaclass<span class=\"token operator\">=</span>MetaSingleton<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> name<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"select-poll和epoll\"><a href=\"#select-poll和epoll\" class=\"headerlink\" title=\"select,poll和epoll\"></a>select,poll和epoll</h2><p> select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 </p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"语言特性\"><a href=\"#语言特性\" class=\"headerlink\" title=\"语言特性\"></a>语言特性</h2><p>解释型语言。Python不需要在运行之前进行编译。</p>\n<p>动态语言，不需要声明变量的类型。</p>\n<p>适合面向对象的编程，允许类的定义和继承。</p>\n<h2 id=\"python2和python3区别\"><a href=\"#python2和python3区别\" class=\"headerlink\" title=\"python2和python3区别\"></a>python2和python3区别</h2><ul>\n<li>Python2 的默认编码是 ascii，Python 3 默认编码 UTF-8，不需要在文件顶部写 <code># coding=utf-8</code>。</li>\n<li>在Python2 中，字符串有两个类型， unicode和 str，前者表示文本字符串，后者表示字节序列，不过两者并没有明显的界限； Python3  str 表示字符串，byte 表示字节序列。</li>\n<li>True 和 False 在 Python2 中是全局变量，分别对应 1 和 0，可以指向其它对象。 Python3  True 和 False 变为关键字，不允许再被重新赋值。</li>\n<li>Python 2中print是特殊语句，Python 3中print是函数，需要加上括号。</li>\n<li>在Python 2中，3/2是整数，在Python 3中，浮点数。</li>\n<li>python2 range返回列表，python3 range中返回可迭代对象，节约内存。</li>\n<li>Python 2 map函数返回list，Python 3 map函数返回迭代器。</li>\n<li>python2中的raw_input函数，python3中改名为input函数</li>\n<li>在Pyhon3，新增了关键字 nonlcoal，支持嵌套函数中，变量声明为非局部变量。</li>\n</ul>\n<h2 id=\"Python基础\"><a href=\"#Python基础\" class=\"headerlink\" title=\"Python基础\"></a>Python基础</h2><h3 id=\"可变数据类型和不可变数据类型\"><a href=\"#可变数据类型和不可变数据类型\" class=\"headerlink\" title=\"可变数据类型和不可变数据类型\"></a>可变数据类型和不可变数据类型</h3><p>可变数据类型（引用类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址不发生改变。</p>\n<p>不可变数据类型（值类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址发生了改变。</p>\n<p>可变数据类型：list和dict；</p>\n<p>不可变数据类型：int、型float、string和tuple。</p>\n<h3 id=\"python2中xrange和range的区别\"><a href=\"#python2中xrange和range的区别\" class=\"headerlink\" title=\"python2中xrange和range的区别\"></a>python2中xrange和range的区别</h3><p><code>range()</code>返回的是一个list对象，而xrange返回的是一个可迭代对象。</p>\n<p><code>xrange()</code>则不会直接生成一个list，而是每次调用返回其中的一个值，内存空间使用极少。因而性能非常好。</p>\n<h3 id=\"变量的作用域-查找顺序\"><a href=\"#变量的作用域-查找顺序\" class=\"headerlink\" title=\"变量的作用域/查找顺序\"></a>变量的作用域/查找顺序</h3><p>函数作用域的LEGB顺序</p>\n<p>L： local ，局部作用域；</p>\n<p>E： enclosing，嵌套的父级函数的局部作用域；</p>\n<p>G：global ，全局变量；</p>\n<p>B： build-in， 系统固定模块里面的变量。</p>\n<p>Python除了def/class/lambda 外，其他如: if/elif/else/ try/except for/while并不能改变其作用域。</p>\n<h3 id=\"内置函数\"><a href=\"#内置函数\" class=\"headerlink\" title=\"内置函数\"></a>内置函数</h3><p><code>reduce()</code> 函数会对参数序列中元素进行累积。</p>\n<p>先对数据集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据做函数运算。</p>\n<pre><code class=\"python\">def add(x, y) :      # 两数相加\n   return x + y\nreduce(add, [1,2,3,4,5])  # 计算列表和：1+2+3+4+5\nreduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数</code></pre>\n<p><code>filter()</code> 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。</p>\n<p>序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。</p>\n<pre><code class=\"python\">def is_odd(n):\n  return n % 2 == 1\n\nnewlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprint(newlist)</code></pre>\n<p><code>map()</code> 会根据提供的函数对指定序列做映射。</p>\n<p>序列中的每一个元素调用 函数，返回包含每次函数返回值的新列表（python2），python3是会返回可迭代对象的。</p>\n<pre><code class=\"python\">def square(x) :      # 计算平方数\n   return x ** 2\nmap(square, [1,2,3,4,5])  # 计算列表各个元素的平方</code></pre>\n<p><code>repr()</code>函数将对象转化为供解释器读取的形式</p>\n<pre><code class=\"python\">dict1 = {&#39;runoob&#39;: &#39;runoob.com&#39;, &#39;google&#39;: &#39;google.com&#39;};\nrepr(dict1)\nstr(dict1)\n\n&quot;{&#39;google&#39;: &#39;google.com&#39;, &#39;runoob&#39;: &#39;runoob.com&#39;}&quot;</code></pre>\n<p><code>vars()</code>函数返回对象object的属性和属性值的字典对象。</p>\n<pre><code>class Runoob:\n   a = 1\nprint(vars(Runoob))\n{&#39;a&#39;: 1, &#39;__module__&#39;: &#39;__main__&#39;, &#39;__doc__&#39;: None}</code></pre><p><strong>ord</strong></p>\n<p>一个长度为1的字符串作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。</p>\n<h4 id=\"dir\"><a href=\"#dir\" class=\"headerlink\" title=\"dir\"></a>dir</h4><p>不带参数时，返回当前范围内的变量、方法和定义的类型列表；</p>\n<p>带参数时，返回参数的属性、方法列表。</p>\n<p>如果参数包含方法<code>__dir__()</code>，该方法将被调用。</p>\n<h4 id=\"isinstance\"><a href=\"#isinstance\" class=\"headerlink\" title=\"isinstance\"></a><strong>isinstance</strong></h4><p><code>isinstance()</code>判断一个对象是否是一个已知的类型，<code>type()</code>查看一个类型或变量的类型。</p>\n<p><code>type()</code>不会认为子类是一种父类类型。<code>isinstance()</code>会认为子类是一种父类类型。</p>\n<h4 id=\"raw-input、input\"><a href=\"#raw-input、input\" class=\"headerlink\" title=\"raw_input、input\"></a>raw_input、input</h4><p>1、在 Python2.x 中<code>raw_input()</code>和<code>input()</code>，两个函数都存在，其中区别为:</p>\n<ul>\n<li><code>raw_input()</code>将所有输入作为字符串看待，返回字符串类型。</li>\n<li><code>input()</code> 只能接收“数字”的输入，它返回所输入的数字的类型。</li>\n</ul>\n<p>2、在 Python3.x 中 仅保留了<code>input()</code> 函数，将所有输入作为字符串处理，并返回字符串类型。</p>\n<h4 id=\"sort-sorted\"><a href=\"#sort-sorted\" class=\"headerlink\" title=\"sort sorted\"></a>sort sorted</h4><p><strong>区别</strong></p>\n<p>对于一个无序的列表a，调用<code>a.sort()</code>，对a进行排序后返回None，<code>sort()</code>函数修改待排序的列表内容。</p>\n<p>而对于同样一个无序的列表a，调用<code>sorted(a)</code>，对a进行排序后返回一个新的列表，而对a不产生影响。</p>\n<p><strong>sort</strong></p>\n<p>timsort是结合了合并排序和插入排序而得出的排序算法。该算法找到数据中已经排好序的块-分区，每一个分区叫一个run，然后按规则合并这些run。</p>\n<p>为了减少对升序部分的回溯和对降序部分的性能倒退，将输入按其升序和降序特点进行了分区。排序的输入的单位不是一个个单独的数字，而是一个个的块-分区。其中每一个分区叫一个run。针对这些 run 序列，每次拿一个 run 出来按规则进行合并。每次合并会将两个 run合并成一个 run。合并的结果保存到栈中。合并直到消耗掉所有的 run，这时将栈上剩余的 run合并到只剩一个 run 为止。这时这个仅剩的 run 便是排好序的结果。</p>\n<p>（0）数组长度小于某个值，直接用二分插入排序算法</p>\n<p>（1）找到各个run，并入栈</p>\n<p>（2）按规则合并run</p>\n<p>0：有序部分的长度一般不会太长，当小于 minRun 时，会将此部分后面的元素插入其中，直至长度满足 minRun。通过二分法查找元素</p>\n<p>2：会将该run在数组中的起始位置和run的长度放入栈中，然后根据先前放入栈中的run决定是否该合并run。Timsort不会合并在栈中不连续的run</p>\n<p>先用二分查找算法/折半查找算法（binary search）找到插入的位置，然后在插入。</p>\n<p>   例如，我们要将A和B这2个run 合并，且A是较小的run。因为A和B已经分别是排好序的，二分查找会找到B的第一个元素在A中何处插入。同样，A的最后一个元素找到在B的何处插入，找到以后，B在这个元素之后的元素就不需要比较了。这种查找可能在随机数中效率不会很高，但是在其他情况下有很高的效率。</p>\n<h3 id=\"魔法方法\"><a href=\"#魔法方法\" class=\"headerlink\" title=\"魔法方法\"></a>魔法方法</h3><p>在特殊的情况下被Python所调用的方法。</p>\n<p><code>__init__</code>构造器，当一个实例被创建的时候用于初始化的方法。</p>\n<p><code>__new__</code>实例化对象调用的第一个方法，用来创造一个类的实例的，取下cls参数，把其他参数传给<code>__init__</code>.</p>\n<p><code>__call__</code>让一个类的实例像函数一样被调用</p>\n<p><code>__getitem__</code>定义获取容器中指定元素的行为，相当于<code>self[key]</code></p>\n<p><code>__getattr__</code>定义当用户试图访问一个不存在属性的时候的行为</p>\n<p><code>__setattr__</code>定义当一个属性被设置的时候的行为</p>\n<p><code>__getattribute___</code>定义当一个属性被访问的时候的行为</p>\n<p><code>__del__</code>删除对象执行的方法</p>\n<p><code>__str__</code>强调可读性，面向用户；而<code>__repr__</code>强调标准性，面向机器</p>\n<p>%s调用<code>__str__</code>方法，而%r调用<code>__repr__</code>方法</p>\n<p><code>__repr__</code>在表示类时，是一级的，如果只定义它，那么<code>__str__</code> = <code>__repr__</code>。</p>\n<pre><code class=\"python\">class Callable:\n  def __call__(self, a, b):\n     return a + b\n\n\nfunc = Callable() \nresult = func(2, 3) # 像函数一样调用\nprint(result)</code></pre>\n<h3 id=\"new-amp-init区别\"><a href=\"#new-amp-init区别\" class=\"headerlink\" title=\"new &amp; init区别\"></a>new &amp; init区别</h3><p>1、<code>__new__</code>有参数cls，代表当前类，从而产生一个实例；<code>__new__</code>必须要有返回值，返回实例化出来的实例，可以return父类（<code>super(当前类名, cls)</code>）<code>__new__</code>出来的实例，或object的<code>__new__</code>出来的实例</p>\n<p>2、<code>__init__</code>有参数self，完成一些初始化的动作，<code>__init__</code>不需要返回值</p>\n<p>3、如果<code>__new__</code>创建的是当前类的实例，会自动调用<code>__init__</code>（return语句里面调用的<code>__new__</code>函数的第一个参数是cls，保证是当前类实例）；如果<code>__new__</code>返回一个已经存在的实例，<code>__init__</code>不会被调用。</p>\n<p>4、如果我们在<code>__new__</code>函数中不返回任何对象，则<code>__init__</code>函数也不会被调用。</p>\n<blockquote>\n<p>Python的旧类中实际上并没有<code>__new__</code>方法。因为旧类中的<code>__init__</code>实际上起构造器的作用</p>\n</blockquote>\n<h3 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h3><p>避免转义，给字符串加r表示原始字符串。</p>\n<h3 id=\"is-和-区别\"><a href=\"#is-和-区别\" class=\"headerlink\" title=\"is 和 ==区别\"></a>is 和 ==区别</h3><p>is：比较俩对象是否为同一个实例对象，是否指向同一个内存地址。</p>\n<p>== ： 比较的两个对象的内容/值是否相等，默认会调用对象的<code>eq()</code>方法</p>\n<h3 id=\"set去重\"><a href=\"#set去重\" class=\"headerlink\" title=\"set去重\"></a>set去重</h3><p>set的去重是通过两个函数<code>__hash__</code>和<code>__eq__</code>结合实现的。</p>\n<p>1、当两个变量的哈希值不相同时，就认为这两个变量是不同的</p>\n<p>2、当两个变量哈希值一样时，调用<code>__eq__</code>方法，当返回值为True时认为这两个变量是同一个。返回FALSE时，不去重。</p>\n<h3 id=\"list切片\"><a href=\"#list切片\" class=\"headerlink\" title=\"list切片\"></a>list切片</h3><p>索引操作本身基于<code>__getitem__</code>和<code>__setitem__</code></p>\n<p>python向<code>__getitem__</code>传入了一个<code>slice</code>的对象，这个类有start, stop, step三个属性，缺省值都是None。</p>\n<pre><code class=\"python\">a = [1,2,3,4,5,6]\nx = a [1: 5]        # x = a.__getitem__(slice( 1, 5, None))\na [1: 3] = [10, 11, 12]  # a.__setitem__(slice(1, 3, None), [ 10, 11, 12 ])\ndel a [1: 4]        # a.__delitem__(slice(1, 4, None))</code></pre>\n<h3 id=\"三元算子\"><a href=\"#三元算子\" class=\"headerlink\" title=\"三元算子\"></a>三元算子</h3><p><code>[on true] if [expression] else [on false]</code></p>\n<h3 id=\"pass\"><a href=\"#pass\" class=\"headerlink\" title=\"pass\"></a>pass</h3><p>1、一般作为占位符或者创建占位程序，pass语句不会执行任何操作</p>\n<p>2、保证格式、语义完整 </p>\n<h3 id=\"lambda\"><a href=\"#lambda\" class=\"headerlink\" title=\"lambda\"></a>lambda</h3><p>创建匿名函数的一个特殊语法,即用即仍，</p>\n<p>1.一般用来给filter，map这样的函数式编程服务</p>\n<p>2.作为回调函数</p>\n<h3 id=\"迭代器和生成器\"><a href=\"#迭代器和生成器\" class=\"headerlink\" title=\"迭代器和生成器\"></a>迭代器和生成器</h3><h4 id=\"迭代器\"><a href=\"#迭代器\" class=\"headerlink\" title=\"迭代器\"></a>迭代器</h4><p><strong>迭代器协议</strong>： <code>__iter__()</code> 返回一个特殊的迭代器对象， 这个迭代器对象实现了 <code>__next__()</code> 并通过 <code>StopIteration</code> 异常，标识迭代的完成。</p>\n<p><strong>迭代器对象</strong>：实现了迭代器协议的对象/被<code>next()</code>函数调用并不断返回下一个值的对象称为迭代器。</p>\n<p><strong>例子</strong></p>\n<p>Python的内置工具（如for循环，sum，min，max函数等）使用迭代器协议访问对象</p>\n<h4 id=\"生成器\"><a href=\"#生成器\" class=\"headerlink\" title=\"生成器\"></a>生成器</h4><p><strong>使用了 yield 的函数被称为生成器</strong>。<strong>只要把一个列表生成式的<code>[]</code>改成<code>()</code>，就创建了一个生成器</strong></p>\n<p>生成器是一种特殊的迭代器，生成器自动实现了“迭代器协议”。</p>\n<p>生成器在迭代的过程中可以改变当前迭代值，而修改普通迭代器的当前迭代值往往会发生异常，影响程序的执行。</p>\n<h4 id=\"可迭代对象\"><a href=\"#可迭代对象\" class=\"headerlink\" title=\"可迭代对象\"></a>可迭代对象</h4><p>实现<code>__iter__</code>方法的对象。可迭代对象包含文件对象、序列（字符串、列表、元组、集合）、字典。</p>\n<h4 id=\"判断方法\"><a href=\"#判断方法\" class=\"headerlink\" title=\"判断方法\"></a>判断方法</h4><pre><code class=\"python\">from collections import Iterable, Iterator\nfrom inspect import isgenerator\n\nisinstance(a, Iterable)\nisinstance(a, Iterator)\nisgenerator(a)</code></pre>\n<h3 id=\"装饰器\"><a href=\"#装饰器\" class=\"headerlink\" title=\"装饰器\"></a>装饰器</h3><p>装饰器本质上是一个<strong>Python函数或者类</strong>，让其他函数在不做任何代码变动，从而增加额外功能，装饰器的返回值也是一个函数对象。</p>\n<p>场景：<strong>插入日志</strong>、性能测试、<strong>事务处理</strong>、缓存、<strong>权限校验、异常处理</strong>。</p>\n<pre><code class=\"python\">import functools\n\ndef add(a, b):\n  print(a + b)\n\nadd  = functools.partial(add, 1)\n# 输出：3\nadd(2)</code></pre>\n<p>经过partial包装之后，a参数的值被固定为了1，新的add对象（注意此处add已经是一个可调用对象）只需要接收一个参数即可。</p>\n<p><strong>把原函数的部分参数固定了初始值，新的调用只需要传递其它参数。</strong></p>\n<p><code>@functools.wraps(func)</code>底层逻辑，就是把wrapped函数的属性拷贝到wrapper函数中。</p>\n<pre><code class=\"python\">def outer(func):\n  @functools.wraps(func)\n  def inner(*args, **kwargs):\n     print(f&quot;before...&quot;)\n     func(*args, **kwargs)\n     print(&quot;after...&quot;)\n  return inner\n\n@outer\ndef add(a, b):\n  &quot;&quot;&quot;\n  求和运算\n  &quot;&quot;&quot;\n  print(a + b)</code></pre>\n<p>1、原函数为add。</p>\n<p>2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。</p>\n<p>3、执行outer函数时，加载inner函数，此时会直接执行<code>functools.wraps(func)</code>返回一个可调用对象，即partial对象。</p>\n<p>4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。</p>\n<p>5、把add指向inner函数。</p>\n<p>6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。</p>\n<p> <strong>总结</strong></p>\n<p>1）functools.wraps 旨在消除装饰器对原函数造成的影响，即对原函数的相关属性进行拷贝。</p>\n<p>2）wraps内部通过partial对象和update_wrapper函数实现。</p>\n<p>3）partial是一个类，通过实现<code>__new__</code>，<strong>自定义实例化对象过程，使得对象内部保留原函数和固定参数</strong>，通过实现<code>__call__</code>，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。</p>\n<h4 id=\"类装饰器\"><a href=\"#类装饰器\" class=\"headerlink\" title=\"类装饰器\"></a><strong>类装饰器</strong></h4><p>类装饰器具有<strong>灵活度大、高内聚、封装性</strong>等优点。</p>\n<p>依靠<code>__call__</code>方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。</p>\n<pre><code class=\"python\">class Foo(object):\n  def __init__(self, func):\n     self._func = func\n\ndef __call__(self):\n   print (&#39;class decorator runing&#39;)\n   self._func()\n   print (&#39;class decorator ending&#39;)\n\n@Foo\ndef bar():\n  print (&#39;bar&#39;)\n\nbar()</code></pre>\n<h3 id=\"property\"><a href=\"#property\" class=\"headerlink\" title=\"property\"></a>property</h3><p>让方法像属性一样使用</p>\n<pre><code class=\"python\">property([fget[, fset[, fdel[, doc]]]])\nfdel = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\nfget = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\nfset = property(lambda self: object(), lambda self, v: None, lambda self: None) # default\n\nclass C(object):\n  def __init__(self):\n     self._x = None\n\n  def getx(self):\n    return self._x\n\n  def setx(self, value):\n    self._x = value\n\n  def delx(self):\n    del self._x\n\n  x = property(getx, setx, delx, &quot;I&#39;m the &#39;x&#39; property.&quot;)</code></pre>\n<p>property 的 getter,setter 和 deleter 方法同样可以用作装饰器：</p>\n<pre><code class=\"python\">class C(object):\n\n  def __init__(self):\n     self._x = None\n\n  @property\n  def x(self):\n     &quot;&quot;&quot;I&#39;m the &#39;x&#39; property.&quot;&quot;&quot;\n     return self._x\n\n  @x.setter\n  def x(self, value):\n     self._x = value\n\n  @x.deleter\n  def x(self):\n     del self._x</code></pre>\n<p>使用property装饰后，x不再是一个函数，而是property类的一个实例。所以第二个函数可以使用 x.setter 来装饰，本质是调用property.setter 来产生一个新的 property实例赋值给第二个x。</p>\n<p>第一个 x和第二个 x 是两个不同 property实例。但他们都属于同一个描述符类（property），当赋值时，就会进入 <code>property.__set__</code>，取值时，就会进入 <code>property.__get__</code>。</p>\n<h3 id=\"参数类型\"><a href=\"#参数类型\" class=\"headerlink\" title=\"参数类型\"></a>参数类型</h3><p><strong>位置参数：</strong>传参数时，按照顺序，依次传值。</p>\n<p><strong>默认参数：</strong>参数提供默认值。默认参数一定要指向不变对象。</p>\n<p><strong>可变参数：</strong>可变参数就是传入的参数个数是可变的。特征：*args</p>\n<p><strong>关键字参数：</strong>允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。特征：**kw</p>\n<p><strong>命名关键字参数：</strong>如果要限制关键字参数的名字，就可以用命名关键字参数。特征：命名关键字参数需要一个特殊分隔符<code>*</code>，而后面的参数被视为命名关键字参数。如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要特殊分隔符了</p>\n<p>参数定义的<strong>顺序</strong>必须是：位置参数–&gt;默认参数–&gt;可变参数–&gt;命名关键字参数–&gt;关键字参数</p>\n<h3 id=\"zip\"><a href=\"#zip\" class=\"headerlink\" title=\"zip\"></a>zip</h3><p>拉链函数， 将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表迭代器。</p>\n<p>如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同。</p>\n<pre><code class=\"python\">print(list(zip([0,1,3],[5,6,7],[&#39;a&#39;,&#39;b&#39;])))\n[(0, 5, &#39;a&#39;), (1, 6, &#39;b&#39;)]</code></pre>\n<h3 id=\"and-和or\"><a href=\"#and-和or\" class=\"headerlink\" title=\"and 和or\"></a>and 和or</h3><p> 在不加括号时候, and优先级大于or </p>\n<p>x or y：x为真是x, x为假是y </p>\n<p>x and y ： x为真就是y, x为假就是x</p>\n<pre><code class=\"python\">v = 1 and 2 or 3 and 4 \nprint(v) # 2</code></pre>\n<h3 id=\"for-循环\"><a href=\"#for-循环\" class=\"headerlink\" title=\"for 循环\"></a>for 循环</h3><p><strong>通过调用<code>iter()</code>方法执行（字符串，元组，字典，集合，文件）对象内部的<code>__iter__</code>方法，获取一个迭代器，然后使用迭代器协议去实现循环访问，</strong>当元素循环完时，会触发StopIteration异常，for循环会捕捉到这种异常，终止迭代</p>\n<h3 id=\"深拷贝和浅拷贝\"><a href=\"#深拷贝和浅拷贝\" class=\"headerlink\" title=\"深拷贝和浅拷贝\"></a>深拷贝和浅拷贝</h3><p>浅拷贝：在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素地址的拷贝。也就是说新的容器中指向了旧的元素（ 新瓶装旧酒 ）。</p>\n<p>深拷贝：在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。（ 新瓶装新酒 ）。</p>\n<p>1、复制不可变数据类型， copy /deepcopy，都指向原地址对象</p>\n<p>2、复制的值是可变对象</p>\n<p><strong>浅拷贝copy有两种情况：</strong></p>\n<p>复制对象中包含的非可变数据类型：改变值，会开辟新的内存，有新的引用。原来值的改变并不会影响浅复制的值。</p>\n<p>复制对象中包含的可变数据类型：改变原来的值，会影响浅复制的值。</p>\n<p><strong>深拷贝deepcopy</strong></p>\n<p>完全复制独立，包括内层列表和字典</p>\n<h3 id=\"参数传递\"><a href=\"#参数传递\" class=\"headerlink\" title=\"参数传递\"></a>参数传递</h3><p><strong>值传递：</strong>实参把值传递给形参，形参的改变不影响实参值。</p>\n<p><strong>引用传递（地址传递）：</strong>把实参地址传递形参，形参值的改变会影响实参的值。</p>\n<ul>\n<li>函数中修改字典某一个键值对是有效的</li>\n<li>函数中交换两个字典并无法生效</li>\n</ul>\n<p>因此不是严格意义上的引用传递，而是<strong>基于引用地址的值传递</strong>，传递的是对象地址的拷贝。</p>\n<h3 id=\"闭包\"><a href=\"#闭包\" class=\"headerlink\" title=\"闭包\"></a>闭包</h3><p><strong>高阶函数</strong>：函数为入参，或者函数作为返回结果。</p>\n<p><strong>闭包</strong>：在外函数中定义了内函数，内函数里使用了外函数的临时变量，并且外函数的返回值是内函数的引用。</p>\n<pre><code class=\"python\">def timer(func):\n  def wrapper(*args, **kwargs):\n     start = time.time()\n     func(*args, **kwargs) #此处拿到了被装饰的函数func\n     time.sleep(2)#模拟耗时操作\n     long = time.time() - start\n      print(f&#39;共耗时{long}秒。&#39;)\n  return wrapper #返回内层函数的引用\n\n@timer\ndef add(a, b):\n  print(a+b)\n\nadd(1, 2) #正常调用add</code></pre>\n<p><strong>模块加载</strong></p>\n<ul>\n<li>遇到@，执行timer函数，传入add函数 </li>\n<li>生成<code>timer.&lt;locals&gt;.wrapper</code>函数并命名为add，其实是覆盖了原同名函数 </li>\n<li>调用<code>add(1, 2)</code></li>\n<li>去执行<code>timer.&lt;locals&gt;.wrapper(1, 2)</code></li>\n<li>wrapper内部持有原add函数引用<code>(func)</code>，调用<code>func(1, 2)</code></li>\n<li>继续执行完wrapper函数</li>\n</ul>\n<p><strong>带参数的装饰器</strong></p>\n<pre><code class=\"python\">def auth(permission):\n  def _auth(func):\n     def wrapper(*args, **kwargs):\n       print(f&quot;验证权限[{permission}]...&quot;)\n       func(*args, **kwargs)\n       print(&quot;执行完毕...&quot;)\n     return wrapper\n  return _auth\n\n@auth(&quot;add&quot;)\ndef add(a, b):\n  &quot;&quot;&quot;\n  求和运算\n  &quot;&quot;&quot;\n  print(a + b)</code></pre>\n<p>真正调用的是装饰后生成的新函数。</p>\n<p>为了消除装饰器对原函数的影响，需要伪装成原函数，拥有原函数的属性。可以利用functools：</p>\n<pre><code class=\"python\">def auth(permission):\n  def _auth(func):\n     @functools.wraps(func) # 注意此处\n     def wrapper(*args, **kwargs):\n       print(f&quot;验证权限[{permission}]...&quot;)\n       func(*args, **kwargs)\n       print(&quot;执行完毕...&quot;)\n     return wrapper\n  return _auth\n\n@auth(&quot;add&quot;)\ndef add(a, b):\n  &quot;&quot;&quot;\n  求和运算\n  &quot;&quot;&quot;\n  print(a + b)</code></pre>\n<h4 id=\"特殊例子\"><a href=\"#特殊例子\" class=\"headerlink\" title=\"特殊例子\"></a>特殊例子</h4><pre><code class=\"python\">def multi():\n  return [lambda x : i*x for i in range(4)]\n\nprint([m(3) for m in multi()]) # [9,9,9,9]</code></pre>\n<p>闭包的延迟绑定导致的，在<strong>闭包中的变量是在内部函数被调用的时候被查找的</strong>，最后函数被调用的时候，for循环已经完成， i 的值最后是3，因此每一个返回值的i都是3，所以最后的结果是[9,9,9,9]</p>\n<pre><code class=\"python\"># [0, 3, 6, 9]\ndef multipliers():\n  for i in range(4):\n     yield lambda x: i *x</code></pre>\n<h3 id=\"上下文管理\"><a href=\"#上下文管理\" class=\"headerlink\" title=\"上下文管理\"></a>上下文管理</h3><p>在一个类里，实现了<code>__enter__</code>和<code>__exit__</code>的方法，这个类的实例就是一个上下文管理器。</p>\n<p><strong>基本使用语法</strong></p>\n<pre><code class=\"pyt\">with EXPR as VAR:\n    BLOCK</code></pre>\n<p><strong>为什么要使用上下文管理器？</strong></p>\n<p>一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接；处理异常；</p>\n<p><strong>使用contextlib</strong></p>\n<pre><code class=\"python\">import contextlib\n\n@contextlib.contextmanager\ndef open_func(file_name):\n    # __enter__方法\n    print(&#39;open file:&#39;, file_name, &#39;in __enter__&#39;)\n    file_handler = open(file_name, &#39;r&#39;)\n\n    try:\n        yield file_handler\n    except Exception as exc:\n        # deal with exception\n        print(&#39;the exception was thrown&#39;)\n    finally:\n        print(&#39;close file:&#39;, file_name, &#39;in __exit__&#39;)\n        file_handler.close()\n\n        return\n\nwith open_func(&#39;/Users/MING/mytest.txt&#39;) as file_in:\n    for line in file_in:\n        1/0\n        print(line)</code></pre>\n<h3 id=\"编码和解码\"><a href=\"#编码和解码\" class=\"headerlink\" title=\"编码和解码\"></a>编码和解码</h3><h4 id=\"编码类型\"><a href=\"#编码类型\" class=\"headerlink\" title=\"编码类型\"></a>编码类型</h4><ul>\n<li>ascii ：一个字节表示一个字符，最多只能表示 256 个符号。</li>\n<li>unicode： 所有字符需要2个字节表示</li>\n<li>gbk：英文字符1个字节，中文字符两个字节</li>\n<li>utf-8：英文字符1个字节、 欧洲字符2个字节， 亚洲字符3个字节</li>\n</ul>\n<p>python2 的默认编码方式为ASCII码，python3默认的文件编码是UTF-8</p>\n<p>Python的字符串类型是<code>str</code>，在内存中以Unicode表示。</p>\n<blockquote>\n<p>如果我们从网络或磁盘上读取了字节流，那么读到的数据就是<code>bytes</code>。要把<code>bytes</code>变为<code>str</code>，就需要用<code>decode()</code>方法；</p>\n<p>如果要在网络上传输，或者保存到磁盘上，就需要把<code>str</code>变为以字节为单位的<code>bytes</code></p>\n</blockquote>\n<h3 id=\"pickling和unpickling？\"><a href=\"#pickling和unpickling？\" class=\"headerlink\" title=\"pickling和unpickling？\"></a>pickling和unpickling？</h3><p>模块 pickle 实现了对一个 Python 对象结构的二进制序列化和反序列化。</p>\n<p> “pickling” 是将 Python 对象及转化为一个字节流的过程</p>\n<p>“unpickling” 将字节流转化回一个对象层次结构。</p>\n<p>Pickle 协议和 JSON 间有着本质的<strong>不同</strong>：</p>\n<ul>\n<li>JSON 是一个文本序列化格式，而 pickle 是一个二进制序列化格式；</li>\n<li>JSON 是我们可以直观阅读的，而 pickle 不是；</li>\n<li>JSON在Python之外广泛使用，而pickle则是Python专用的；</li>\n<li>JSON 只能表示 Python 内置类型的子集，不能表示自定义的类；但 pickle 可以表示大量的 Python 数据类型。</li>\n</ul>\n<h3 id=\"说一下namedtuple的用法和作用\"><a href=\"#说一下namedtuple的用法和作用\" class=\"headerlink\" title=\"说一下namedtuple的用法和作用\"></a>说一下<code>namedtuple</code>的用法和作用</h3><p>只有属性没有方法的类，用于组织数据，称为数据类。</p>\n<p>在Python中可以用<code>namedtuple</code>（命名元组）来替代这种类。</p>\n<pre><code class=\"python\">from collections import namedtuple\n\nCard = namedtuple(&#39;Card&#39;, (&#39;suite&#39;, &#39;face&#39;))\ncard1 = Card(&#39;红桃&#39;, 13)\ncard2 = Card(&#39;草花&#39;, 5)\nprint(f&#39;{card1.suite}{card1.face}&#39;)\nprint(f&#39;{card2.suite}{card2.face}&#39;)</code></pre>\n<p>命名元组与普通元组一样是不可变容器，一旦将数据存储在<code>namedtuple</code>的顶层属性中，数据就不能再修改了，</p>\n<p>对象上的所有属性都遵循“一次写入，多次读取”的原则。</p>\n<p>和普通元组不同的是，命名元组中的数据有访问名称，可以通过名称而不是索引来获取保存的数据</p>\n<p>命名元组的本质就是一个类，所以它还可以作为父类创建子类。</p>\n<p>除此之外，命名元组内置了一系列的方法，例如，可以通过<code>_asdict</code>方法将命名元组处理成字典，也可以通过<code>_replace</code>方法创建命名元组对象的浅拷贝。</p>\n<pre><code class=\"python\">class MyCard(Card):\n\n    def show(self):\n        faces = [&#39;&#39;, &#39;A&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;10&#39;, &#39;J&#39;, &#39;Q&#39;, &#39;K&#39;]\n        return f&#39;{self.suite}{faces[self.face]}&#39;\n\n\nprint(Card)    # &lt;class &#39;__main__.Card&#39;&gt;\ncard3 = MyCard(&#39;方块&#39;, 12)\nprint(card3.show())    # 方块Q\nprint(dict(card1._asdict()))    # {&#39;suite&#39;: &#39;红桃&#39;, &#39;face&#39;: 13}\nprint(card2._replace(suite=&#39;方块&#39;))    # Card(suite=&#39;方块&#39;, face=5)</code></pre>\n<h2 id=\"面向对象\"><a href=\"#面向对象\" class=\"headerlink\" title=\"面向对象\"></a>面向对象</h2><p>继承：将多个类的共同属性和方法封装到一个父类下面，然后在用这些类来继承这个类的属性和方法</p>\n<p>封装：将有共同的属性和方法封装到同一个类下面</p>\n<p>多态：Python天生是支持多态的。指的是基类的同一个方法在不同的派生类中有着不同的功能</p>\n<h3 id=\"新式类和经典类\"><a href=\"#新式类和经典类\" class=\"headerlink\" title=\"新式类和经典类\"></a>新式类和经典类</h3><p>Python3里只有新式类；Python2里面继承object的是新式类，没有写父类的是经典类</p>\n<p><strong>区别</strong></p>\n<ul>\n<li>新式类 保持class与type的统一，对新式类的实例执行<code>a.__class__</code>与<code>type(a)</code>的结果是一致的</li>\n<li>旧式类的<code>type(a)</code>返回instance。</li>\n<li>多重继承的属性搜索顺序不一样，新式类是采用广度优先搜索，旧式类采用深度优先搜索。</li>\n</ul>\n<pre><code class=\"python\">class A():\n  def foo1(self):\n     print &quot;A&quot;\n\nclass B(A):\n  def foo2(self):\n     pass\n\nclass C(A):\n  def foo1(self):\n     print &quot;C&quot;\n\nclass D(B, C):\n  pass\n\n\nd = D()\nd.foo1()</code></pre>\n<p><strong>缺点：</strong>经典类的查找顺序是深度优先的规则，在访问<code>d.foo1()</code>的时候,D-&gt;B-&gt;A,找到了<code>foo1()</code>,调用A的<code>foo1()</code>，导致C重写的<code>foo1()</code>被绕过</p>\n<h3 id=\"类方法、类实例方法、静态方法\"><a href=\"#类方法、类实例方法、静态方法\" class=\"headerlink\" title=\"类方法、类实例方法、静态方法\"></a>类方法、类实例方法、静态方法</h3><ul>\n<li><p>类方法: 是类对象的方法，使用 @classmethod 进行装饰，形参有cls，表示类对象</p>\n</li>\n<li><p>类实例方法: 是类实例化对象的方法，形参为self，指代对象本身;</p>\n</li>\n<li><p>静态方法: 是一个任意函数，使用 @staticmethod 进行装饰</p>\n<blockquote>\n<p>实例方法只能通过实例对象调用；</p>\n<p>类方法和静态方法可以通过类对象或者实例对象调用，</p>\n<p>使用实例对象调用的类方法或静态方法，最终通过类对象调用。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"如何判断是函数还是方法？\"><a href=\"#如何判断是函数还是方法？\" class=\"headerlink\" title=\"如何判断是函数还是方法？\"></a>如何判断是函数还是方法？</h3><p>如果是以函数的形式定义或者是静态方法，一定是函数</p>\n<p>如果是类方法，一定是方法。</p>\n<p>实例方法是方法，如果类直接调用实例方法，则是函数（直接调用运行是有问题的）。</p>\n<pre><code class=\"python\">from types import MethodType,FunctionType\nprint(isinstance(obj.func, FunctionType)) \nprint(isinstance(obj.func, MethodType))  </code></pre>\n<h3 id=\"接口类与抽象类\"><a href=\"#接口类与抽象类\" class=\"headerlink\" title=\"接口类与抽象类\"></a>接口类与抽象类</h3><pre><code class=\"python\">class Operate_database():    # 接口类1\n    def query(self, sql):\n        raise NotImplementedError\n\n    def update(self, sql):\n        raise NotImplementedError\n\nfrom abc import ABCMeta,abstractmethod\nclass Operate_database(metaclass=ABCMeta):    # 接口类2\n    @abstractmethod\n    def query(self, sql):\n        pass\n\n    @abstractmethod\n    def update(self, sql):\n        pass</code></pre>\n<p> Python 原生仅支持抽象类，不支持接口类，abc模块就是用来实现抽象类的。</p>\n<p>若是类中所有的方法都没有实现，则认为这是一个接口，</p>\n<p>若是有部分方法实现，则认为这是一个抽象类。</p>\n<p>抽象类和接口类都仅用于被继承，不能被实例化.</p>\n<h3 id=\"描述符\"><a href=\"#描述符\" class=\"headerlink\" title=\"描述符\"></a>描述符</h3><p><strong>一个实现了描述符协议的类就是一个描述符。</strong></p>\n<p><strong>描述符协议：实现了<code>__get__()</code>、<code>__set__()</code>、<code>__delete__()</code>其中至少一个方法的类，就是一个描述符。</strong></p>\n<p><code>__get__</code>： 用于访问属性。它返回属性的值，若属性不存在、不合法等都可以抛出对应的异常。</p>\n<p><code>__set__</code>：将在属性分配操作中调用。</p>\n<p><code>__delete__</code>：控制删除操作。</p>\n<p>描述符的作用和优势，以弥补Python动态类型的缺点。</p>\n<pre><code class=\"python\">class Score:\n  def __init__(self, default=0):\n     self._score = default\n\n  def __set__(self, instance, value):\n     if not isinstance(value, int):\n       raise TypeError(&#39;Score must be integer&#39;)\n\n     if not 0 &lt;= value &lt;= 100:\n       raise ValueError(&#39;Valid value must be in [0, 100]&#39;)\n\n     self._score = value\n\n  def __get__(self, instance, owner):\n     return self._score\n\n  def __delete__(self):\n     del self._score    \n\nclass Student:\n  math = Score(0)\n  chinese = Score(0)\n  english = Score(0)\n\n  def __init__(self, name, math, chinese, english):\n     self.name = name\n     self.math = math\n     self.chinese = chinese\n     self.english = english</code></pre>\n<p><strong>staticmethod</strong></p>\n<pre><code class=\"python\">class Test:\n  @staticmethod\n  def myfunc():\n     print(&quot;hello&quot;)\n\n# 上下两种写法等价\nclass Test:\n  def myfunc():\n     print(&quot;hello&quot;)\n  # 重点：这就是描述符的体现\n  # 每调用一次，它都会经过描述符类的 __get__\n  myfunc = staticmethod(myfunc)</code></pre>\n<p><strong>classmethod</strong></p>\n<pre><code class=\"python\">class classmethod(object):\n  def __init__(self, f):\n     self.f = f\n  def __get__(self, instance, owner=None):\n     print(&quot;in classmethod __get__&quot;)\n     def newfunc(*args):\n       return self.f(owner, *args)\n     return newfunc\n\nclass Test:\n  def myfunc(cls):\n     print(&quot;hello&quot;)\n  # 重点：这就是描述符的体现\n  myfunc = classmethod(myfunc)</code></pre>\n<h3 id=\"元类\"><a href=\"#元类\" class=\"headerlink\" title=\"元类\"></a>元类</h3><p><strong>元类是用来创建类的类。</strong></p>\n<p>如果类属性中定义了<code>__metaclass__</code>，则在创建类的时候用元类来创建；</p>\n<p>如果没有则向其父类查找<code>__metaclass__</code>。</p>\n<p>如果都没有，则用<code>type()</code>创建类。</p>\n<pre><code class=\"python\"># metaclass是类的模板，所以必须从`type`类型派生：\nclass ListMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs[&#39;add&#39;] = lambda self, value: self.append(value)\n        return type.__new__(cls, name, bases, attrs)\n\nclass MyList(list, metaclass=ListMetaclass):\n    pass</code></pre>\n<p>传入关键字参数<code>metaclass</code>时，指示Python解释器在创建<code>MyList</code>时，要通过<code>ListMetaclass.__new__()</code>来创建</p>\n<p>在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。</p>\n<p><code>__new__()</code>方法接收到的参数依次是：</p>\n<ol>\n<li>当前准备创建的类的对象；</li>\n<li>类的名字；</li>\n<li>类继承的父类集合；</li>\n<li>类的方法集合。</li>\n</ol>\n<p><strong>元类作用</strong></p>\n<ul>\n<li>拦截类的创建</li>\n<li>修改类</li>\n<li>返回修改后的类</li>\n</ul>\n<p><strong>应用场景</strong></p>\n<p>ORM：所有的类都只能动态定义，因为只有使用者才能根据表的结构定义出对应的类来。</p>\n<h2 id=\"字典\"><a href=\"#字典\" class=\"headerlink\" title=\"字典\"></a>字典</h2><p>字典的查询、添加、删除的平均时间复杂度都是<code>O(1)</code>。因为字典是通过哈希表来实现的.</p>\n<ul>\n<li><p>计算key的hash值<code>hash(key)</code>，再和mask做与操作【mask=字典最小长度（DictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的enteies哈希表中的下标位置</p>\n</li>\n<li><p>若index下标位置已经被占用，则会判断enteies的key是否与要插入的key是否相等</p>\n<ul>\n<li><p>如果key相等就表示key已存在，则更新value值</p>\n</li>\n<li><p>如果key不相等，就表示hash冲突，则会继续向下寻找空位置，一直到找到剩余空位为止。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"开放寻址法\"><a href=\"#开放寻址法\" class=\"headerlink\" title=\"开放寻址法\"></a><strong>开放寻址法</strong></h3><p>开放寻址法中，所有的元素都存放在散列表里，当产生哈希冲突时，通过一个探测函数计算出下一个候选位置，如果下一个获选位置还是有冲突，不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。</p>\n<blockquote>\n<p>开放寻址法中解决冲突的方法有：线行探查法、平方探查法、双散列函数探查法</p>\n</blockquote>\n<p>采用哈希表，dict的哈希表里每个slot都是一个自定义的entry结构：</p>\n<pre><code class=\"c\">typedef struct {\n   Py_ssize_t me_hash;\n   PyObject *me_key;\n   PyObject *me_value;\n} PyDictEntry;</code></pre>\n<p>每个entry有三种状态Active, Unused, Dummy。</p>\n<ul>\n<li><p>Unused:me_key == me_value == NULL，即未使用的空闲状态。</p>\n</li>\n<li><p>Active:me_key != NULL, me_value != NULL，即该entry已被占用</p>\n</li>\n<li><p>Dummy:me_key == dummy, me_value == NULL。</p>\n</li>\n</ul>\n<p><strong>为什么entry有Dummy状态呢？</strong></p>\n<p>用开放寻址法中，<strong>遇到哈希冲突时会找到下一个合适的位置，</strong>例如ABC构成了探测链，查找元素时如果hash值相同，那么也是<strong>顺着这条探测链不断往后找</strong>，当删除探测链中的某个元素时，如果直接把B从哈希表中移除，即变成Unused状态，那么C就不可能再找到了，因此需要Dummy保证探测链的连续性。</p>\n<p>dict对象的定义为：</p>\n<pre><code class=\"c\">struct _dictobject {\n  PyObject _HEAD\n  Py_ssize_t ma_fill; /* # Active + # Dummy */\n  Py_ssize_t ma_used; /* # Active */\n  Py_ssize_t ma_mask; //slot -1\n  PyDictEntry *ma_table;\n  PyDictEntry *(*ma_lookup)(PyDictObject *mp, PyObject *key, long hash); // 搜索函数指针\n  PyDictEntry ma_smalltable[PyDict_MINSIZE]; //默认的slot\n};</code></pre>\n<h3 id=\"dict对象的创建\"><a href=\"#dict对象的创建\" class=\"headerlink\" title=\"dict对象的创建\"></a><strong>dict对象的创建</strong></h3><p>dict对象的创建很简单，先看看缓冲的对象池里有没有可用对象，如果有就直接用，没有就从堆上申请。</p>\n<h3 id=\"dict对象的插入\"><a href=\"#dict对象的插入\" class=\"headerlink\" title=\"dict对象的插入\"></a><strong>dict对象的插入</strong></h3><p>如果不存在key-value则插入，存在则覆盖。</p>\n<ul>\n<li>生成Hash</li>\n<li>如果可用的entry&lt;0，字典扩容</li>\n<li>基于key、hash，查找可用哈希位置，以便于存储<ul>\n<li>字典中是否有空余的值，或者如果找到了满足 hash 值与 key 相同的,就将 value 设置为找到的值</li>\n</ul>\n</li>\n<li>保存key、Hash、value值</li>\n</ul>\n<h3 id=\"dict对象的删除\"><a href=\"#dict对象的删除\" class=\"headerlink\" title=\"dict对象的删除\"></a><strong>dict对象的删除</strong></h3><p>算出哈希值，找到entry，将其从Active转换成Dummy，并调整table的容量。</p>\n<p><strong>注意</strong></p>\n<p>（1） dict的key 或者 set的值都必须是可hash的不可变对象，都是可hash的</p>\n<p>（2）当发现内存空间中的“空”只有1/3时，便会触发扩容操作。</p>\n<h2 id=\"整数\"><a href=\"#整数\" class=\"headerlink\" title=\"整数\"></a>整数</h2><p>Python使用<strong>小整数对象池</strong>small_ints缓存了[-5，257）之间的整数，该范围内的整数在Python系统中是共享的，值相同就属于同一个对象。</p>\n<p>对于同一个代码块中值不在<code>small_ints</code>缓存范围内的整数，如果同一个代码块中已经存在一个值与其相同的整数对象，那么就直接引用该对象，否则创建新的<code>int</code>对象。</p>\n<h2 id=\"字符串-1\"><a href=\"#字符串-1\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>Python解释器中使用了 intern（字符串驻留）的技术来提高字符串效率，值同样的字符串对象仅仅会保存一份，放在一个字符串储蓄池中，是共用的。</p>\n<p><strong>简单原理</strong></p>\n<p>维护一个字符串存储池，这个池子是一个字典结构</p>\n<p>如果字符串已经存在于池子中，直接返回之前创建好的字符串对象，</p>\n<p>如果不存在，则构造一个字符串对象并加入到池子中去。</p>\n<blockquote>\n<p>在shell中，并非全部的字符串都会采用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。不能超过20个字符。因为如果超过xx个字符的话，解释器认为这个字符串不常用，不用放入字符串池中。</p>\n<p>字符串拼接时，运行时拼接，不会intern；例如”hell” + “o”在编译时完成拼接的才会intern</p>\n</blockquote>\n<h2 id=\"堆-栈\"><a href=\"#堆-栈\" class=\"headerlink\" title=\"堆 栈\"></a>堆 栈</h2><p>在Python中，变量也称为：对象的引用。变量存储的就是对象的地址。</p>\n<p><strong>变量位于：栈内存。</strong></p>\n<p><strong>对象位于：堆内存。</strong></p>\n<p>内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。</p>\n<p><strong>代码区：</strong>程序中的代码数据、二进制数据、方法数据等等程序运行需要的预加载数据。</p>\n<p><strong>静态数据区：</strong>存储<strong>全局变量、静态变量</strong>。</p>\n<p><strong>栈区：</strong>存储变量。存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。</p>\n<p><strong>堆区</strong>：对象真实数据。</p>\n<h2 id=\"内存回收机制\"><a href=\"#内存回收机制\" class=\"headerlink\" title=\"内存回收机制\"></a>内存回收机制</h2><p>python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略。</p>\n<h3 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a><strong>引用计数法</strong></h3><p><strong>原理：</strong>每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数加1，每当该对象的引用失效时，计数减1，一旦对象的引用计数为0，该对象立即被回收，占用的内存空间将被释放。</p>\n<p><strong>缺点：</strong>不能解决对象的循环引用</p>\n<h3 id=\"标记清除\"><a href=\"#标记清除\" class=\"headerlink\" title=\"标记清除\"></a>标记清除</h3><p>解决容器对象可能产生的循环引用问题。（只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等）</p>\n<p><strong>A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达</strong>；</p>\n<p>B）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。</p>\n<h3 id=\"分代回收\"><a href=\"#分代回收\" class=\"headerlink\" title=\"分代回收\"></a>分代回收</h3><p>标记清除时，应用程序会被暂停，为了减少应用程序暂停的时间。</p>\n<p><strong>对象存在时间越长，越可能不是垃圾，应该越少去收集</strong>。</p>\n<p>给对象定义了三种世代，每一个新生对象在0代中，如果它在一轮gc扫描中活了下来，那么它将被移至1代，在那里他将较少的被扫描，如果它又活过了一轮gc，它又将被移至2代，在那里它被扫描的次数将会更少。</p>\n<h3 id=\"gc的扫描在什么时候会被触发呢\"><a href=\"#gc的扫描在什么时候会被触发呢\" class=\"headerlink\" title=\"gc的扫描在什么时候会被触发呢?\"></a><strong>gc的扫描在什么时候会被触发呢</strong>?</h3><p>年轻代链表的总数达到上限时。</p>\n<p>当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。</p>\n<h3 id=\"调优手段\"><a href=\"#调优手段\" class=\"headerlink\" title=\"调优手段\"></a><strong>调优手段</strong></h3><p>1.手动垃圾回收</p>\n<p>2.调高垃圾回收阈值</p>\n<p>3.避免循环引用</p>\n<h2 id=\"退出Python时，是否释放全部内存？\"><a href=\"#退出Python时，是否释放全部内存？\" class=\"headerlink\" title=\"退出Python时，是否释放全部内存？\"></a>退出Python时，是否释放全部内存？</h2><p>进程退出的时候，资源最终都会释放掉，这是操作系统负责的。</p>\n<p>如果是一段程序运行结束之后：</p>\n<ol>\n<li>CPython会通过引用计数立即释放引用数量为0的对象（其它版本解释器并不保证）；循环引用的对象会在下一次GC时释放，除非有两个对象都带有<code>__del__</code>析构函数，且直接或间接循环引用。这种情况下，所有循环引用的对象都无法被释放。原因在于无法确定<code>__del__</code>的执行顺序。</li>\n<li>全局引用的对象无法被回收，但也不只是模块中直接或间接保存的对象，还包括未退出的线程使用的对象，解释器缓存的小整数和字符串，还有C模块里间接引用的对象等等。</li>\n<li>C扩展直接通过malloc分配的内存自然无法通过gc来回收，但一般如果存在没有被回收的内存说明是有内存泄漏的，这属于实现的bug</li>\n</ol>\n<h2 id=\"协程，线程和进程\"><a href=\"#协程，线程和进程\" class=\"headerlink\" title=\"协程，线程和进程\"></a>协程，线程和进程</h2><h3 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h3><p>进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。在Python中，进程适合计算密集型任务。</p>\n<h4 id=\"进程间的通信（IPC）\"><a href=\"#进程间的通信（IPC）\" class=\"headerlink\" title=\"进程间的通信（IPC）\"></a>进程间的通信（IPC）</h4><p><strong>1）管道（Pipe</strong>）：通过<code>send()</code>和<code>recv()</code>来发送和接受信息，适合父子进程关系或者两个子进程之间。 </p>\n<p>2）<strong>有名管道（FIFO）</strong>：有名管道也是半双工的通信方式。 将自己注册到文件系统里一个文件，通过读写这个文件进行通信。允许在没有亲缘关系的进程之间使用。要求读写双方必须同时打开才可以继续进行读写操作，否则打开操作会堵塞直到对方也打开。</p>\n<p>3）<strong>信号量（Semaphore）</strong>：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 创建子进程时将信号量my_semaphore作为参数传入子进程任务函数，子进程中使用semaphore.acquire() 尝试获取信号量，semaphore.release()尝试 释放信号量。</p>\n<p><strong>4）队列（Queue）</strong>。 使用get/put在父子进程关系或者两个子进程之间通信。</p>\n<p>5）<strong>信号 （signal）</strong>：用于通知接收进程某个事件已经发生，可以设置信号处理函数。 </p>\n<p>6）共享内存（shared memory）：操作系统负责将同一份物理地址的内存映射到多个进程的不同的虚拟地址空间中。进而每个进程都可以操作这份内存。需要在进程访问时做好并发控制，比如使用信号量。 python标准库mmap，apache开源的pyarrow都是。</p>\n<p>7）套接字（socket）：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。 </p>\n<p><strong>8）文件</strong> </p>\n<p>（1）仅进程同步不涉及数据传输，可以使用信号、信号量；<br>（2）若进程间需要传递少量数据，可以使用管道、有名管道、队列；<br>（3）若进程间需要传递大量数据，最佳方式是使用共享内存，推荐使用pyarrow，这样减少数据拷贝、传输的时间内存代价；<br>（4）跨主机的进程间通信（RPC）可以使用socket通信。</p>\n<p><strong>共享变量</strong></p>\n<p>使用 Process 定义的多进程之间（父子或者兄弟）共享变量可以直接使用 multiprocessing 下的 Value，Array，Queue 等，如果要共享 list，dict，可以使用强大的 Manager 模块。</p>\n<h3 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h3><p>线程是cpu调度执行的最小单位，依赖进程存在，一个进程至少有一个线程。在python中，线程适合IO密集型任务。</p>\n<p>同一个进程下的线程共享程序的内存空间<strong>（如代码段，全局变量，堆栈等）</strong></p>\n<h4 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h4><p>继承Thread，重写run方法，通过start方法开线程</p>\n<p>将要执行的方法作为参数传给Thread的构造方法</p>\n<h4 id=\"状态\"><a href=\"#状态\" class=\"headerlink\" title=\"状态\"></a>状态</h4><p>线程有五种状态:创建、就绪、运行、阻塞、死亡。 </p>\n<ul>\n<li><p>调用start方法时，线程就会进入就绪状态。 </p>\n</li>\n<li><p>在线程得到cpu时间片时进入运行状态。 </p>\n</li>\n<li><p><strong>线程调用yield方法可以让出cpu时间回到就绪状态</strong>。 </p>\n</li>\n<li><p>线程运行时可能<strong>由于IO、调用sleep、wait、join方法或者无法获得同步锁等原因进入阻塞</strong>状态。 </p>\n</li>\n<li><p>当线程获得到等待的资源资源或者引起阻塞的条件得到满足时，会从阻塞状态进入就绪状态。 </p>\n</li>\n<li><p>当线程的run方法执行结束时，线程就进入死亡状态。</p>\n</li>\n</ul>\n<h4 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h4><p>多个线程同时对一个公共资源（如全局变量）进行操作的情况，为了避免发生混乱。<code>threading.lock</code>，<code>acquire()</code>方法上锁，<code>release()</code>方法解锁</p>\n<p>可重入锁：为了支持在同一线程中多次请求同一资源，python提供了threading.RLock。重入锁必须由获取它的同一个线程释放，同时要求解锁次数应与加锁次数相同，才能用于另一个线程。</p>\n<h4 id=\"同步\"><a href=\"#同步\" class=\"headerlink\" title=\"同步\"></a>同步</h4><p>阻塞线程直到子线程全部结束。</p>\n<h4 id=\"守护线程\"><a href=\"#守护线程\" class=\"headerlink\" title=\"守护线程\"></a>守护线程</h4><p>不重要线程。主线程会等所有‘重要’线程结束后才结束。</p>\n<h4 id=\"线程池的工作原理\"><a href=\"#线程池的工作原理\" class=\"headerlink\" title=\"线程池的工作原理\"></a>线程池的工作原理</h4><p>减少线程本身创建和销毁造成的开销，属于典型的空间换时间操作。</p>\n<p>创建和释放线程涉及到大量的系统底层操作，开销较大，如果变成预创建和借还操作，将大大减少底层开销。</p>\n<ul>\n<li>在应用程序启动后，线程池创建一定数量的线程，放入空闲队列中。这些线程最开始都处于阻塞状态，不会消耗CPU，占用少量的内存。</li>\n<li>当任务到来后，从队列中取出一个空闲线程，把任务派发到这个线程中运行，并将标记为已占用。</li>\n<li>当线程池中所有的线程都被占用后，可以选择自动创建一定数量的新线程，用于处理更多的任务，也可以选择让任务排队等待直到有空闲的线程可用。</li>\n<li>在任务执行完毕后，线程并不退出结束，而是继续保持在池中等待下一次的任务。</li>\n<li>当系统比较空闲时，大部分线程长时间处于闲置状态时，线程池可以自动销毁一部分线程，回收系统资源。</li>\n</ul>\n<p>线程池组成部分：</p>\n<ol>\n<li>线程池管理器：用于创建并管理线程池。</li>\n<li>工作线程和线程队列：线程池中实际执行的线程以及保存这些线程的容器。</li>\n<li>任务接口：将线程执行的任务抽象出来，形成任务接口，确保线程池与具体的任务无关。</li>\n<li>任务队列：线程池中保存等待被执行的任务的容器。</li>\n</ol>\n<h3 id=\"协程\"><a href=\"#协程\" class=\"headerlink\" title=\"协程\"></a>协程</h3><p>协程是一种用户态的轻量级线程，调度完全由用户控制。</p>\n<p>协程拥有自己的寄存器上下文和栈。协程的切换都在用户空间内进行，不需要进行系统调用。</p>\n<p>协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，基本没有内核切换的开销，可以不加锁的访问全局变量，上下文的切换非常快。</p>\n<p><strong>如何利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能</strong>。</p>\n<p><strong>常用模块</strong></p>\n<p>greenlet：提供了切换任务的快捷方式，但是遇到io无法自动切换任务，需要手动切换</p>\n<p>gevent：开启协程任务并切换的模块，遇到io自动切换任务。</p>\n<p>asyncio：<code>@asyncio.coroutine</code>装饰器的函数称为协程函数。</p>\n<p><code>yield from</code>语法用于将一个生成器部分操作委托给另一个生成器。</p>\n<p><code>async</code>/<code>await</code>：<code>@asyncio.coroutine</code>和<code>yield from</code>的语法糖</p>\n<p><strong>缺点</strong></p>\n<ul>\n<li><p>无法利用多核资源：协程的本质是个单线程</p>\n</li>\n<li><p>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序</p>\n</li>\n</ul>\n<p><strong>协程主要使用场景</strong></p>\n<p>网络请求，比如爬虫，大量使用 aiohttp</p>\n<p>文件读取， aiofile</p>\n<p>web 框架， aiohttp， fastapi</p>\n<p>数据库查询， asyncpg, databases</p>\n<p><strong>协程优于线程</strong></p>\n<ul>\n<li>python 线程调度方式是，每执行 100 个字节码或者遇到阻塞就停止当前线程，然后进行一个系统调用，让 os 内核选出下一个线程。但是协程 只会在 阻塞的时候，切换到下一个协程。100个字节码，说多不多，说少不少，你调用两个库函数说不定就没了，因此线程的切换存在很多是无效的切换，当线程数量越大，这种因为调度策略的先天不足带来的性能损耗就越大。</li>\n<li>线程需要进行系统调用，协程不需要。系统调用需要进入内核态，无效的调度会让这部分开销显得更大</li>\n<li>协程可以自主调度，而线程只能决定合适退出，但是下一个线程是谁则依赖于操作系统。</li>\n</ul>\n<h3 id=\"僵尸进程和孤儿进程\"><a href=\"#僵尸进程和孤儿进程\" class=\"headerlink\" title=\"僵尸进程和孤儿进程\"></a>僵尸进程和孤儿进程</h3><p>孤儿进程： <strong>父进程退出，子进程还在运行的这些子进程都是孤儿进程，</strong>孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。</p>\n<p>僵尸进程： 进程使用fork 创建子进程<strong>，如果子进程退出，而父进程并没有调用wait 获取子进程的状态信息</strong>，那么子进程的进程描述符仍然保存在系统中，这些进程是僵尸进程。</p>\n<p>避免僵尸进程的方法：</p>\n<p>1.用<code>wait()</code>函数使父进程阻塞</p>\n<p>2.使用信号量，在signal handler 中调用waitpid，这样父进程不用阻塞</p>\n<p><strong>3.fork 两次用孙子进程去完成子进程的任务（？？？）</strong></p>\n<h2 id=\"Global-Interpreter-Lock-全局解释器锁\"><a href=\"#Global-Interpreter-Lock-全局解释器锁\" class=\"headerlink\" title=\"Global Interpreter Lock(全局解释器锁)\"></a>Global Interpreter Lock(全局解释器锁)</h2><p>Python 默认的解释器是 CPython，<strong>GIL 是存在于 CPython 解释器中的</strong>。</p>\n<p>执行 Python 字节码时，为了保护访问 Python 对象而阻止多个线程执行的一把互斥锁。主要是因为 CPython 解释器的内存管理不是线程安全的。</p>\n<p>常见的 Python 解释器：IPython（基于Cython）、IPython、Jython（可以把 Python 代码编译成 Java 字节码，依赖 Java 平台，不存在 GIL）、IronPython（运行在微软的 .Net 平台下的 Python 解释器，可以把 Python 代码编译成 .Net 字节码，不存在 GIL）</p>\n<h3 id=\"GIL原理\"><a href=\"#GIL原理\" class=\"headerlink\" title=\"GIL原理\"></a>GIL原理</h3><p>python 的线程就是 C 语言的 pthread，它是通过操作系统调度算法调度执行的。</p>\n<p>Python 2.x 的代码执行是基于 opcode 数量的调度方式，简单来说就是每执行一定数量的字节码，或遇到系统 IO 时，会强制释放 GIL，然后触发一次操作系统的线程调度。</p>\n<p> Python 3.x 基于固定时间的调度方式，就是每执行固定时间的字节码，或遇到系统 IO 时，强制释放 GIL，触发系统的线程调度。</p>\n<h3 id=\"为什么会有GIL\"><a href=\"#为什么会有GIL\" class=\"headerlink\" title=\"为什么会有GIL\"></a>为什么会有GIL</h3><p>Python 设计者在设计解释器时，可能没有想到 CPU 的性能提升会这么快转为多核心方向发展，所以在当时的场景下，设计一个全局锁是那个时代保护多线程资源一致性最简单经济的设计方案。</p>\n<p>多核心时代来临，当大家试图去拆分和去除 GIL 的时候，发现大量库的代码和开发者已经重度依赖 GIL（默认认为 Pythonn内部对象是线程安全的，无需在开发时额外加锁），所以这个去除 GIL 的任务变得复杂且难以实现。</p>\n<h2 id=\"性能分析\"><a href=\"#性能分析\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>python 内置了丰富的性能分析工具，<strong>如 profile,cProfile 与 hotshot 等</strong>。其中 Profiler 是 python 自带的一组程序，能够描述程序运行时候的性能，并提供各种统计帮助用户定位程序的性能瓶颈。</p>\n<p>Python 标准库提供了同一分析接口的两种不同实现：</p>\n<ol>\n<li>建议使用 <a href=\"https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile\" target=\"_blank\" rel=\"noopener\"><code>cProfile</code></a> ；这是一个 C 扩展插件，因为其合理的运行开销，所以适合于分析长时间运行的程序。</li>\n<li><a href=\"https://docs.python.org/zh-cn/3/library/profile.html#module-profile\" target=\"_blank\" rel=\"noopener\"><code>profile</code></a> 是一个纯 Python 模块（<a href=\"https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile\" target=\"_blank\" rel=\"noopener\"><code>cProfile</code></a> 就是模拟其接口的 C 语言实现），但它会显著增加配置程序的开销。如果你正在尝试以某种方式扩展分析器，则使用此模块可能会更容易完成任务</li>\n</ol>\n<p>支持输出：调用次数、在指定函数中消耗的总时间（不包括调用子函数的时间）、指定的函数及其所有子函数（从调用到退出）消耗的累积时间、函数运行一次的平均时间</p>\n<h2 id=\"单例模式\"><a href=\"#单例模式\" class=\"headerlink\" title=\"单例模式\"></a>单例模式</h2><h3 id=\"使用装饰器\"><a href=\"#使用装饰器\" class=\"headerlink\" title=\"使用装饰器\"></a><strong>使用装饰器</strong></h3><pre><code class=\"python\">def singleton(cls):\n  instances = {}\n  def wrapper(*args, **kwargs):\n     if cls not in instances:\n       instances[cls] = cls(*args, **kwargs)\n     return instances[cls]\n\n  return wrapper\n\n@singleton\nclass Foo(object):\n  pass\n\nfoo1 = Foo()\nfoo2 = Foo()\n\nprint(foo1 is foo2) # True</code></pre>\n<h3 id=\"使用new\"><a href=\"#使用new\" class=\"headerlink\" title=\"使用new\"></a>使用new</h3><p>New 是真正创建实例对象的方法，所以重写基类的new 方法，以此保证创建对象的时候只生成一个实例。</p>\n<p>但是以上的方法在多线程中会有线程安全问题，当有多个线程同时去初始化对象时，就很可能同时判断__instance is None，从而进入初始化instance的代码中。所以需要用<strong>互斥锁</strong>来解决这个问题。</p>\n<pre><code class=\"python\">class Singleton(object):\n  def __new__(cls, *args, **kwargs):\n     if not hasattr(cls, &#39;_instance&#39;):\n       cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n     return cls._instance\n\n\nclass Singleton(object):\n  __instance = None\n  def __new__(cls, *args, **kwargs):\n     if cls.__instance is None:\n       cls.__instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n     return cls.__instance\n\nclass Foo(Singleton):\n  pass\n\nfoo1 = Foo()\nfoo2 = Foo()\n\nprint(foo1 is foo2) # True</code></pre>\n<h3 id=\"classmethod\"><a href=\"#classmethod\" class=\"headerlink\" title=\"classmethod\"></a>classmethod</h3><pre><code class=\"python\">import time\nimport threading\nclass Singleton(object):\n     _instance_lock = threading.Lock() \n    def __init__(self):\n        time.sleep(1)        \n    @classmethod\n    def instance(cls, *args, **kwargs):\n        with Singleton._instance_lock: # 加锁\n            if not hasattr(Singleton, &#39;_instance&#39;):\n                Singleton._instance = Singleton(*args, **kwargs)\n            return Singleton._instance</code></pre>\n<h3 id=\"元类-1\"><a href=\"#元类-1\" class=\"headerlink\" title=\"元类\"></a>元类</h3><p>元类是用于创建类对象的类，类对象创建实例对象时一定要调用call方法，因此在调用call时候保证始终只创建一个实例即可，type是python的元类</p>\n<pre><code class=\"python\">class Singleton(type):\n    def __call__(cls, *args, **kwargs):\n        if not hasattr(cls, &#39;_instance&#39;):\n            cls._instance = super(Singleton, cls).__call__(*args, **kwargs)\n        return cls._instance\n\n\n# Python2\nclass Foo(object):\n    __metaclass__ = Singleton</code></pre>\n<h3 id=\"线程安全装饰器\"><a href=\"#线程安全装饰器\" class=\"headerlink\" title=\"线程安全装饰器\"></a><strong>线程安全装饰器</strong></h3><pre><code class=\"python\">def make_synchronized(func):\n    import threading\n    func.__lock__ = threading.Lock()\n\n    # 用装饰器实现同步锁\n    def synced_func(*args, **kwargs):\n        with func.__lock__:\n            return func(*args, **kwargs)\n\n    return synced_func\n\nclass Singleton(object):\n    __instance = None\n\n    @make_synchronized\n    def __new__(cls, *args, **kwargs):\n        if not cls.__instance:\n            cls.__instance = object.__new__(cls)\n        return cls.__instance\n\n    def __init__(self):\n        self.blog = &quot;blog&quot;</code></pre>\n<h3 id=\"线程安全–元类\"><a href=\"#线程安全–元类\" class=\"headerlink\" title=\"线程安全–元类\"></a><strong>线程安全–元类</strong></h3><pre><code class=\"python\">import threading\n\nclass MetaSingleton(type):\n    _instance_lock = threading.Lock()\n    def __call__(cls, *args, **kwargs):\n        if not hasattr(cls, &#39;_instance&#39;):\n            with MetaSingleton._instance_lock:\n                if not hasattr(cls, &#39;_instance&#39;):\n                    cls._instance = super(MetaSingleton, cls).__call__(*args, **kwargs)\n\n        return cls._instance\n\n\nclass Singleton(metaclass=MetaSingleton):\n    def __init__(self, name):\n        self.name = name</code></pre>\n<h2 id=\"select-poll和epoll\"><a href=\"#select-poll和epoll\" class=\"headerlink\" title=\"select,poll和epoll\"></a>select,poll和epoll</h2><p> select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 </p>\n"},{"title":"rabbitmq消息路由","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:15:04.000Z","password":null,"summary":null,"_content":"\n---\n## direct交换器\n\n------------\n\n### 特点\n- 投递的消息有一个或者多个确定的目标。\n- 检查字符串是否相等，不允许使用模式匹配。\n- 绑定相同路由键的队列都能收到该路由键对应的消息。\n- 适用于RPC消息通信模式下的路由应答消息\n\n示例代码：Direct交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'direct-example',\n                                     exchange_type='direct')\n        exchange.declare()\n```\n\n### 示例场景\nRPC worker消费图片实现面部识别，将结果发回给消息发布方。\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg)\n\n\n\n- 客户端应用程序上传图像\n- 应用程序处理请求，用唯一ID标识远程请求并创建一条消息\n- 图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID\n- 消息路由到队列，\n- 消费者消费队列中的消息\n- 结果以RPC请求形式返回前端。\n\n注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。\n\n示例代码：RPC Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\nexchange = rabbitpy.DirectExchange(channel, 'rpc-replies')\nexchange.declare()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('direct-rpc-requests', 'detect-faces')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例代码：RPC worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('direct-rpc-requests', 'detect-faces'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## fanout交换器\n\n### 特点\n\n- 所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。\n- 消息投递不需要检测路由键，性能更好\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                    'fanout-rpc-requests',\n                                     exchange_type='fanout')\n        exchange.declare()\n```\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg)\n\n\n\n\n示例程序：Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print 'Sending request for image #%s: %s' % (img_id, filename)\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('fanout-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint 'RPC requests processed'\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例程序：detect worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n示例程序：Hash Consumer\n```python\nimport os\nimport hashlib\nimport rabbitpy\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'hashing-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Create the hashing object\n    hash_obj = hashlib.md5(message.body)\n\n    # Print out the info, this might go into a database or log file\n    print('Image with correlation-id of %s has a hash of %s' %\n          (message.properties['correlation_id'],\n           hash_obj.hexdigest()))\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n\n## topic交换器\n\n### 特点\n\n- 消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。\n\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg)\n\n\n\n## headers交换器\n\n### 特点\n\n- 使用消息属性中的headers属性匹配。\n- queue.bind，x-match指定匹配策略，其他参数表示绑定值\n- 绑定策略可能会使得性能降低\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                     'headers-rpc-requests',\n                                     exchange_type='headers')\n        exchange.declare()\n\n```\n\n示例程序：publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'headers': {'source': 'profile',\n                                            'object': 'image',\n                                            'action': 'new'},\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('headers-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n\n示例程序：worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('headers-rpc-requests',\n              arguments={'x-match': 'all',\n                         'source': 'profile',\n                         'object': 'image',\n                         'action': 'new'}):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## 交换器路由\n\n交换器间绑定，使用RPC方法Exchange.Bind。\n\n### 示例场景\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg)\n\n\n示例代码：\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tpc = rabbitpy.Exchange(channel, 'events',\n                                exchange_type='topic')\n        tpc.declare()\n        xch = rabbitpy.Exchange(channel, 'distributed-events',\n                                exchange_type='x-consistent-hash')\n        xch.declare()\n        xch.bind(foo, '#')\n```\n\n\n## 一致性哈希交换器\n\n用于消息队列的负载均衡，可以提升吞吐量\n\n### 示例场景\n\n\n示例代码：采用路由键的哈希值来分发消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash')\n        exchange.declare()\n```\n\n示例代码：header中的属性值作为哈希值\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash',\n                                     arguments={'hash-header': 'image-hash'})\n        exchange.declare()\n\n```\n\n示例代码：队列的创建与绑定\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for queue_num in range(4):\n            queue = rabbitpy.Queue (channel, 'server%s' % queue_num)\n            queue.declare()\n            queue.bind('image-storage', '10')\n```","source":"_posts/rabbitmq消息路由.md","raw":"---\ntitle: rabbitmq消息路由\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:15:04\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n---\n## direct交换器\n\n------------\n\n### 特点\n- 投递的消息有一个或者多个确定的目标。\n- 检查字符串是否相等，不允许使用模式匹配。\n- 绑定相同路由键的队列都能收到该路由键对应的消息。\n- 适用于RPC消息通信模式下的路由应答消息\n\n示例代码：Direct交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'direct-example',\n                                     exchange_type='direct')\n        exchange.declare()\n```\n\n### 示例场景\nRPC worker消费图片实现面部识别，将结果发回给消息发布方。\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg)\n\n\n\n- 客户端应用程序上传图像\n- 应用程序处理请求，用唯一ID标识远程请求并创建一条消息\n- 图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID\n- 消息路由到队列，\n- 消费者消费队列中的消息\n- 结果以RPC请求形式返回前端。\n\n注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。\n\n示例代码：RPC Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\nexchange = rabbitpy.DirectExchange(channel, 'rpc-replies')\nexchange.declare()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('direct-rpc-requests', 'detect-faces')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例代码：RPC worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('direct-rpc-requests', 'detect-faces'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## fanout交换器\n\n### 特点\n\n- 所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。\n- 消息投递不需要检测路由键，性能更好\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                    'fanout-rpc-requests',\n                                     exchange_type='fanout')\n        exchange.declare()\n```\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg)\n\n\n\n\n示例程序：Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print 'Sending request for image #%s: %s' % (img_id, filename)\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('fanout-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint 'RPC requests processed'\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例程序：detect worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n示例程序：Hash Consumer\n```python\nimport os\nimport hashlib\nimport rabbitpy\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'hashing-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Create the hashing object\n    hash_obj = hashlib.md5(message.body)\n\n    # Print out the info, this might go into a database or log file\n    print('Image with correlation-id of %s has a hash of %s' %\n          (message.properties['correlation_id'],\n           hash_obj.hexdigest()))\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n\n## topic交换器\n\n### 特点\n\n- 消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。\n\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg)\n\n\n\n## headers交换器\n\n### 特点\n\n- 使用消息属性中的headers属性匹配。\n- queue.bind，x-match指定匹配策略，其他参数表示绑定值\n- 绑定策略可能会使得性能降低\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                     'headers-rpc-requests',\n                                     exchange_type='headers')\n        exchange.declare()\n\n```\n\n示例程序：publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'headers': {'source': 'profile',\n                                            'object': 'image',\n                                            'action': 'new'},\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('headers-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n\n示例程序：worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('headers-rpc-requests',\n              arguments={'x-match': 'all',\n                         'source': 'profile',\n                         'object': 'image',\n                         'action': 'new'}):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## 交换器路由\n\n交换器间绑定，使用RPC方法Exchange.Bind。\n\n### 示例场景\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg)\n\n\n示例代码：\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tpc = rabbitpy.Exchange(channel, 'events',\n                                exchange_type='topic')\n        tpc.declare()\n        xch = rabbitpy.Exchange(channel, 'distributed-events',\n                                exchange_type='x-consistent-hash')\n        xch.declare()\n        xch.bind(foo, '#')\n```\n\n\n## 一致性哈希交换器\n\n用于消息队列的负载均衡，可以提升吞吐量\n\n### 示例场景\n\n\n示例代码：采用路由键的哈希值来分发消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash')\n        exchange.declare()\n```\n\n示例代码：header中的属性值作为哈希值\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash',\n                                     arguments={'hash-header': 'image-hash'})\n        exchange.declare()\n\n```\n\n示例代码：队列的创建与绑定\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for queue_num in range(4):\n            queue = rabbitpy.Queue (channel, 'server%s' % queue_num)\n            queue.declare()\n            queue.bind('image-storage', '10')\n```","slug":"rabbitmq消息路由","published":1,"updated":"2021-05-11T11:33:29.590Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss6yc002wq4uf2anf2fbd","content":"<hr>\n<h2 id=\"direct交换器\"><a href=\"#direct交换器\" class=\"headerlink\" title=\"direct交换器\"></a>direct交换器</h2><hr>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>投递的消息有一个或者多个确定的目标。</li>\n<li>检查字符串是否相等，不允许使用模式匹配。</li>\n<li>绑定相同路由键的队列都能收到该路由键对应的消息。</li>\n<li>适用于RPC消息通信模式下的路由应答消息</li>\n</ul>\n<p>示例代码：Direct交换器</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'direct-example'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'direct'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"示例场景\"><a href=\"#示例场景\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>RPC worker消费图片实现面部识别，将结果发回给消息发布方。</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg\" alt></p>\n<ul>\n<li>客户端应用程序上传图像</li>\n<li>应用程序处理请求，用唯一ID标识远程请求并创建一条消息</li>\n<li>图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID</li>\n<li>消息路由到队列，</li>\n<li>消费者消费队列中的消息</li>\n<li>结果以RPC请求形式返回前端。</li>\n</ul>\n<p>注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。</p>\n<p>示例代码：RPC Publisher</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the channel and connection</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nexchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>DirectExchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">)</span>\nexchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the response queue that will automatically delete, is not durable and</span>\n<span class=\"token comment\" spellcheck=\"true\"># is exclusive to this publisher</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'response-queue-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresponse_queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                queue_name<span class=\"token punctuation\">,</span>\n                                auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                                exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># Declare the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Iterate through the images to send RPC requests for</span>\n<span class=\"token keyword\">for</span> img_id<span class=\"token punctuation\">,</span> filename <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>get_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Sending request for image #%s: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the message</span>\n    message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                               <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> utils<span class=\"token punctuation\">.</span>mime_type<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">:</span> queue_name<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                               opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Pubish the message</span>\n    message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'direct-rpc-requests'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'detect-faces'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Loop until there is a response message</span>\n    message <span class=\"token operator\">=</span> None\n    <span class=\"token keyword\">while</span> <span class=\"token operator\">not</span> message<span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> response_queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack the response message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Caculate how long it took from publish to response</span>\n    duration <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span>\n                time<span class=\"token punctuation\">.</span>mktime<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Facial detection RPC call for image %s total duration: %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> duration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display the image in the IPython notebook interface</span>\n    utils<span class=\"token punctuation\">.</span>display_image<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'RPC requests processed'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Close the channel and connection</span>\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：RPC worker</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> detect\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'rpc-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'direct-rpc-requests'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'detect-faces'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display how long it took for the message to get here</span>\n    duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> int<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%s'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Received RPC request published %.2f seconds ago'</span> <span class=\"token operator\">%</span> duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Write out the message body to a temp file for facial detection process</span>\n    temp_file <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>write_temp_file<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span>\n                                      message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Detect faces</span>\n    result_file <span class=\"token operator\">=</span> detect<span class=\"token punctuation\">.</span>faces<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Build response properties including the timestamp from the first publish</span>\n    properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'app_id'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Chapter 6 Listing 2 Consumer'</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                      <span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># The result file could just be the original image if nothing detected</span>\n    body <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the temp file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the result file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Publish the response response</span>\n    response <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">,</span> opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    response<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"fanout交换器\"><a href=\"#fanout交换器\" class=\"headerlink\" title=\"fanout交换器\"></a>fanout交换器</h2><h3 id=\"特点-1\"><a href=\"#特点-1\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。</li>\n<li>消息投递不需要检测路由键，性能更好</li>\n</ul>\n<p>示例代码</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'fanout'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"示例场景-1\"><a href=\"#示例场景-1\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg\" alt></p>\n<p>示例程序：Publisher</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the channel and connection</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the response queue that will automatically delete, is not durable and</span>\n<span class=\"token comment\" spellcheck=\"true\"># is exclusive to this publisher</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'response-queue-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresponse_queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                queue_name<span class=\"token punctuation\">,</span>\n                                auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                                exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># Declare the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Iterate through the images to send RPC requests for</span>\n<span class=\"token keyword\">for</span> img_id<span class=\"token punctuation\">,</span> filename <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>get_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span> <span class=\"token string\">'Sending request for image #%s: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the message</span>\n    message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                               <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> utils<span class=\"token punctuation\">.</span>mime_type<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">:</span> queue_name<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                               opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Pubish the message</span>\n    message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Loop until there is a response message</span>\n    message <span class=\"token operator\">=</span> None\n    <span class=\"token keyword\">while</span> <span class=\"token operator\">not</span> message<span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> response_queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack the response message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Caculate how long it took from publish to response</span>\n    duration <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span>\n                time<span class=\"token punctuation\">.</span>mktime<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Facial detection RPC call for image %s total duration: %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> duration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display the image in the IPython notebook interface</span>\n    utils<span class=\"token punctuation\">.</span>display_image<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span> <span class=\"token string\">'RPC requests processed'</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Close the channel and connection</span>\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：detect worker</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> detect\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'rpc-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display how long it took for the message to get here</span>\n    duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> int<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%s'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Received RPC request published %.2f seconds ago'</span> <span class=\"token operator\">%</span> duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Write out the message body to a temp file for facial detection process</span>\n    temp_file <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>write_temp_file<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span>\n                                      message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Detect faces</span>\n    result_file <span class=\"token operator\">=</span> detect<span class=\"token punctuation\">.</span>faces<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Build response properties including the timestamp from the first publish</span>\n    properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'app_id'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Chapter 6 Listing 2 Consumer'</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                      <span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># The result file could just be the original image if nothing detected</span>\n    body <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the temp file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the result file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Publish the response response</span>\n    response <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span>\n    response<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：Hash Consumer</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> hashlib\n<span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'hashing-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the hashing object</span>\n    hash_obj <span class=\"token operator\">=</span> hashlib<span class=\"token punctuation\">.</span>md5<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Print out the info, this might go into a database or log file</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Image with correlation-id of %s has a hash of %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n           hash_obj<span class=\"token punctuation\">.</span>hexdigest<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"topic交换器\"><a href=\"#topic交换器\" class=\"headerlink\" title=\"topic交换器\"></a>topic交换器</h2><h3 id=\"特点-2\"><a href=\"#特点-2\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。</li>\n</ul>\n<h3 id=\"示例场景-2\"><a href=\"#示例场景-2\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg\" alt></p>\n<h2 id=\"headers交换器\"><a href=\"#headers交换器\" class=\"headerlink\" title=\"headers交换器\"></a>headers交换器</h2><h3 id=\"特点-3\"><a href=\"#特点-3\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>使用消息属性中的headers属性匹配。</li>\n<li>queue.bind，x-match指定匹配策略，其他参数表示绑定值</li>\n<li>绑定策略可能会使得性能降低</li>\n</ul>\n<p>示例代码</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                     <span class=\"token string\">'headers-rpc-requests'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：publisher</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the channel and connection</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the response queue that will automatically delete, is not durable and</span>\n<span class=\"token comment\" spellcheck=\"true\"># is exclusive to this publisher</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'response-queue-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresponse_queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                queue_name<span class=\"token punctuation\">,</span>\n                                auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                                exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># Declare the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Iterate through the images to send RPC requests for</span>\n<span class=\"token keyword\">for</span> img_id<span class=\"token punctuation\">,</span> filename <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>get_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Sending request for image #%s: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the message</span>\n    message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                               <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> utils<span class=\"token punctuation\">.</span>mime_type<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'source'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'profile'</span><span class=\"token punctuation\">,</span>\n                                            <span class=\"token string\">'object'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'image'</span><span class=\"token punctuation\">,</span>\n                                            <span class=\"token string\">'action'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'new'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">:</span> queue_name<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                               opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Pubish the message</span>\n    message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'headers-rpc-requests'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Loop until there is a response message</span>\n    message <span class=\"token operator\">=</span> None\n    <span class=\"token keyword\">while</span> <span class=\"token operator\">not</span> message<span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> response_queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack the response message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Caculate how long it took from publish to response</span>\n    duration <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span>\n                time<span class=\"token punctuation\">.</span>mktime<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Facial detection RPC call for image %s total duration: %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> duration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display the image in the IPython notebook interface</span>\n    utils<span class=\"token punctuation\">.</span>display_image<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'RPC requests processed'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Close the channel and connection</span>\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：worker</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> detect\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'rpc-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'headers-rpc-requests'</span><span class=\"token punctuation\">,</span>\n              arguments<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'x-match'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'all'</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token string\">'source'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'profile'</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token string\">'object'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'image'</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token string\">'action'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'new'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display how long it took for the message to get here</span>\n    duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> int<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%s'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Received RPC request published %.2f seconds ago'</span> <span class=\"token operator\">%</span> duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Write out the message body to a temp file for facial detection process</span>\n    temp_file <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>write_temp_file<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span>\n                                      message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Detect faces</span>\n    result_file <span class=\"token operator\">=</span> detect<span class=\"token punctuation\">.</span>faces<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Build response properties including the timestamp from the first publish</span>\n    properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'app_id'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Chapter 6 Listing 2 Consumer'</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                      <span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># The result file could just be the original image if nothing detected</span>\n    body <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the temp file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the result file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Publish the response response</span>\n    response <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">,</span> opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    response<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"交换器路由\"><a href=\"#交换器路由\" class=\"headerlink\" title=\"交换器路由\"></a>交换器路由</h2><p>交换器间绑定，使用RPC方法Exchange.Bind。</p>\n<h3 id=\"示例场景-3\"><a href=\"#示例场景-3\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg\" alt></p>\n<p>示例代码：</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        tpc <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'events'</span><span class=\"token punctuation\">,</span>\n                                exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'topic'</span><span class=\"token punctuation\">)</span>\n        tpc<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        xch <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'distributed-events'</span><span class=\"token punctuation\">,</span>\n                                exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'x-consistent-hash'</span><span class=\"token punctuation\">)</span>\n        xch<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        xch<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span>foo<span class=\"token punctuation\">,</span> <span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"一致性哈希交换器\"><a href=\"#一致性哈希交换器\" class=\"headerlink\" title=\"一致性哈希交换器\"></a>一致性哈希交换器</h2><p>用于消息队列的负载均衡，可以提升吞吐量</p>\n<h3 id=\"示例场景-4\"><a href=\"#示例场景-4\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>示例代码：采用路由键的哈希值来分发消息</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'image-storage'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'x-consistent-hash'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：header中的属性值作为哈希值</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'image-storage'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'x-consistent-hash'</span><span class=\"token punctuation\">,</span>\n                                     arguments<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'hash-header'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'image-hash'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：队列的创建与绑定</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> queue_num <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue <span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'server%s'</span> <span class=\"token operator\">%</span> queue_num<span class=\"token punctuation\">)</span>\n            queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'image-storage'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'10'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<hr>\n<h2 id=\"direct交换器\"><a href=\"#direct交换器\" class=\"headerlink\" title=\"direct交换器\"></a>direct交换器</h2><hr>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>投递的消息有一个或者多个确定的目标。</li>\n<li>检查字符串是否相等，不允许使用模式匹配。</li>\n<li>绑定相同路由键的队列都能收到该路由键对应的消息。</li>\n<li>适用于RPC消息通信模式下的路由应答消息</li>\n</ul>\n<p>示例代码：Direct交换器</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;direct-example&#39;,\n                                     exchange_type=&#39;direct&#39;)\n        exchange.declare()</code></pre>\n<h3 id=\"示例场景\"><a href=\"#示例场景\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>RPC worker消费图片实现面部识别，将结果发回给消息发布方。</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg\" alt></p>\n<ul>\n<li>客户端应用程序上传图像</li>\n<li>应用程序处理请求，用唯一ID标识远程请求并创建一条消息</li>\n<li>图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID</li>\n<li>消息路由到队列，</li>\n<li>消费者消费队列中的消息</li>\n<li>结果以RPC请求形式返回前端。</li>\n</ul>\n<p>注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。</p>\n<p>示例代码：RPC Publisher</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\nexchange = rabbitpy.DirectExchange(channel, &#39;rpc-replies&#39;)\nexchange.declare()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = &#39;response-queue-%s&#39; % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print(&#39;Response queue declared&#39;)\n\n# Bind the response queue\nif response_queue.bind(&#39;rpc-replies&#39;, queue_name):\n    print(&#39;Response queue bound&#39;)\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print(&#39;Sending request for image #%s: %s&#39; % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {&#39;content_type&#39;: utils.mime_type(filename),\n                                &#39;correlation_id&#39;: str(img_id),\n                                &#39;reply_to&#39;: queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish(&#39;direct-rpc-requests&#39;, &#39;detect-faces&#39;)\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties[&#39;headers&#39;][&#39;first_publish&#39;]))\n\n    print(&#39;Facial detection RPC call for image %s total duration: %s&#39; %\n          (message.properties[&#39;correlation_id&#39;], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties[&#39;content_type&#39;])\n\nprint(&#39;RPC requests processed&#39;)\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n</code></pre>\n<p>示例代码：RPC worker</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;rpc-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;direct-rpc-requests&#39;, &#39;detect-faces&#39;):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties[&#39;timestamp&#39;].strftime(&#39;%s&#39;))\n    print(&#39;Received RPC request published %.2f seconds ago&#39; % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties[&#39;content_type&#39;])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {&#39;app_id&#39;: &#39;Chapter 6 Listing 2 Consumer&#39;,\n                  &#39;content_type&#39;: message.properties[&#39;content_type&#39;],\n                  &#39;correlation_id&#39;: message.properties[&#39;correlation_id&#39;],\n                  &#39;headers&#39;: {\n                      &#39;first_publish&#39;: message.properties[&#39;timestamp&#39;]}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish(&#39;rpc-replies&#39;, message.properties[&#39;reply_to&#39;])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<h2 id=\"fanout交换器\"><a href=\"#fanout交换器\" class=\"headerlink\" title=\"fanout交换器\"></a>fanout交换器</h2><h3 id=\"特点-1\"><a href=\"#特点-1\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。</li>\n<li>消息投递不需要检测路由键，性能更好</li>\n</ul>\n<p>示例代码</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                    &#39;fanout-rpc-requests&#39;,\n                                     exchange_type=&#39;fanout&#39;)\n        exchange.declare()</code></pre>\n<h3 id=\"示例场景-1\"><a href=\"#示例场景-1\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg\" alt></p>\n<p>示例程序：Publisher</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = &#39;response-queue-%s&#39; % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print(&#39;Response queue declared&#39;)\n\n# Bind the response queue\nif response_queue.bind(&#39;rpc-replies&#39;, queue_name):\n    print(&#39;Response queue bound&#39;)\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print &#39;Sending request for image #%s: %s&#39; % (img_id, filename)\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {&#39;content_type&#39;: utils.mime_type(filename),\n                                &#39;correlation_id&#39;: str(img_id),\n                                &#39;reply_to&#39;: queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish(&#39;fanout-rpc-requests&#39;)\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties[&#39;headers&#39;][&#39;first_publish&#39;]))\n\n    print(&#39;Facial detection RPC call for image %s total duration: %s&#39; %\n          (message.properties[&#39;correlation_id&#39;], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties[&#39;content_type&#39;])\n\nprint &#39;RPC requests processed&#39;\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n</code></pre>\n<p>示例程序：detect worker</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;rpc-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;fanout-rpc-requests&#39;):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties[&#39;timestamp&#39;].strftime(&#39;%s&#39;))\n    print(&#39;Received RPC request published %.2f seconds ago&#39; % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties[&#39;content_type&#39;])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {&#39;app_id&#39;: &#39;Chapter 6 Listing 2 Consumer&#39;,\n                  &#39;content_type&#39;: message.properties[&#39;content_type&#39;],\n                  &#39;correlation_id&#39;: message.properties[&#39;correlation_id&#39;],\n                  &#39;headers&#39;: {\n                      &#39;first_publish&#39;: message.properties[&#39;timestamp&#39;]}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties)\n    response.publish(&#39;rpc-replies&#39;, message.properties[&#39;reply_to&#39;])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<p>示例程序：Hash Consumer</p>\n<pre><code class=\"python\">import os\nimport hashlib\nimport rabbitpy\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;hashing-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;fanout-rpc-requests&#39;):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Create the hashing object\n    hash_obj = hashlib.md5(message.body)\n\n    # Print out the info, this might go into a database or log file\n    print(&#39;Image with correlation-id of %s has a hash of %s&#39; %\n          (message.properties[&#39;correlation_id&#39;],\n           hash_obj.hexdigest()))\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<h2 id=\"topic交换器\"><a href=\"#topic交换器\" class=\"headerlink\" title=\"topic交换器\"></a>topic交换器</h2><h3 id=\"特点-2\"><a href=\"#特点-2\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。</li>\n</ul>\n<h3 id=\"示例场景-2\"><a href=\"#示例场景-2\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg\" alt></p>\n<h2 id=\"headers交换器\"><a href=\"#headers交换器\" class=\"headerlink\" title=\"headers交换器\"></a>headers交换器</h2><h3 id=\"特点-3\"><a href=\"#特点-3\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>使用消息属性中的headers属性匹配。</li>\n<li>queue.bind，x-match指定匹配策略，其他参数表示绑定值</li>\n<li>绑定策略可能会使得性能降低</li>\n</ul>\n<p>示例代码</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                     &#39;headers-rpc-requests&#39;,\n                                     exchange_type=&#39;headers&#39;)\n        exchange.declare()\n</code></pre>\n<p>示例程序：publisher</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = &#39;response-queue-%s&#39; % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print(&#39;Response queue declared&#39;)\n\n# Bind the response queue\nif response_queue.bind(&#39;rpc-replies&#39;, queue_name):\n    print(&#39;Response queue bound&#39;)\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print(&#39;Sending request for image #%s: %s&#39; % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {&#39;content_type&#39;: utils.mime_type(filename),\n                                &#39;correlation_id&#39;: str(img_id),\n                                &#39;headers&#39;: {&#39;source&#39;: &#39;profile&#39;,\n                                            &#39;object&#39;: &#39;image&#39;,\n                                            &#39;action&#39;: &#39;new&#39;},\n                                &#39;reply_to&#39;: queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish(&#39;headers-rpc-requests&#39;)\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties[&#39;headers&#39;][&#39;first_publish&#39;]))\n\n    print(&#39;Facial detection RPC call for image %s total duration: %s&#39; %\n          (message.properties[&#39;correlation_id&#39;], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties[&#39;content_type&#39;])\n\nprint(&#39;RPC requests processed&#39;)\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n</code></pre>\n<p>示例程序：worker</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;rpc-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;headers-rpc-requests&#39;,\n              arguments={&#39;x-match&#39;: &#39;all&#39;,\n                         &#39;source&#39;: &#39;profile&#39;,\n                         &#39;object&#39;: &#39;image&#39;,\n                         &#39;action&#39;: &#39;new&#39;}):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties[&#39;timestamp&#39;].strftime(&#39;%s&#39;))\n    print(&#39;Received RPC request published %.2f seconds ago&#39; % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties[&#39;content_type&#39;])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {&#39;app_id&#39;: &#39;Chapter 6 Listing 2 Consumer&#39;,\n                  &#39;content_type&#39;: message.properties[&#39;content_type&#39;],\n                  &#39;correlation_id&#39;: message.properties[&#39;correlation_id&#39;],\n                  &#39;headers&#39;: {\n                      &#39;first_publish&#39;: message.properties[&#39;timestamp&#39;]}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish(&#39;rpc-replies&#39;, message.properties[&#39;reply_to&#39;])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<h2 id=\"交换器路由\"><a href=\"#交换器路由\" class=\"headerlink\" title=\"交换器路由\"></a>交换器路由</h2><p>交换器间绑定，使用RPC方法Exchange.Bind。</p>\n<h3 id=\"示例场景-3\"><a href=\"#示例场景-3\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg\" alt></p>\n<p>示例代码：</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tpc = rabbitpy.Exchange(channel, &#39;events&#39;,\n                                exchange_type=&#39;topic&#39;)\n        tpc.declare()\n        xch = rabbitpy.Exchange(channel, &#39;distributed-events&#39;,\n                                exchange_type=&#39;x-consistent-hash&#39;)\n        xch.declare()\n        xch.bind(foo, &#39;#&#39;)</code></pre>\n<h2 id=\"一致性哈希交换器\"><a href=\"#一致性哈希交换器\" class=\"headerlink\" title=\"一致性哈希交换器\"></a>一致性哈希交换器</h2><p>用于消息队列的负载均衡，可以提升吞吐量</p>\n<h3 id=\"示例场景-4\"><a href=\"#示例场景-4\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>示例代码：采用路由键的哈希值来分发消息</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;image-storage&#39;,\n                                     exchange_type=&#39;x-consistent-hash&#39;)\n        exchange.declare()</code></pre>\n<p>示例代码：header中的属性值作为哈希值</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;image-storage&#39;,\n                                     exchange_type=&#39;x-consistent-hash&#39;,\n                                     arguments={&#39;hash-header&#39;: &#39;image-hash&#39;})\n        exchange.declare()\n</code></pre>\n<p>示例代码：队列的创建与绑定</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for queue_num in range(4):\n            queue = rabbitpy.Queue (channel, &#39;server%s&#39; % queue_num)\n            queue.declare()\n            queue.bind(&#39;image-storage&#39;, &#39;10&#39;)</code></pre>\n"},{"title":"rabbitmq消息消费","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:16:01.000Z","password":null,"summary":null,"_content":"\n## 消费方法\n\n### **Basic.Get**\n\n - 每次接收消息必须发送一次请求 \n - 有消息可用，RabbitMQ返回Basic.GetOk以及消息\n - 无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。\n\n示例程序\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == 'stop':\n                    break\n```\n\n### **Basic.Consume**\n\n- 消费者可用时，异步方式发送消息\n- 应用程序自动接收消息，直到Basic.Cancel\n- 仍然需要确认消息\n\n示例程序\n```python\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint(）\n    # 消息确认\n    message.ack()\n```\n\n**消费者标签**\n应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。\n客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。\n\n示例代码：监听消息直到，收到停止消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n            if message.body == 'stop':\n                break\n```\n\n\n### **对比**\nConsume吞吐量更大。Get包含了每条消息的同步通信开销。\n\n## 消费性能优化\n\n### 1、no-ack\n\n应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。\n\n示例代码：消费不确认\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()\n```\n\n### 2、预取\n\nQoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。\n\n示例程序：指定QoS\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #预取数为10\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n```\n\n应用程序不需要确认每条消息，可确认所有以前未读消息。\n\n示例程序：多消息确认\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            unacknowledged += 1\n            if unacknowledged == 10:\n                # 确认所有未确认消息\n                message.ack(all_previous=True)\n                unacknowledged = 0\n\n```\n\n### 3、事务\n\n事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。\n\n## 拒绝消息\n\n### Basic.Reject\n\n通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。\n\n示例程序：消息拒绝\n```\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint()\n    print('Redelivered: %s' % message.redelivered)\n    message.reject(True)\n```\n\n### Basic.Nack\n\n同时拒绝多个消息\n\n### 死信交换器（DLX）\n\n创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。\n\n示例程序：指定死信交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #死信交换器\n        rabbitpy.Exchange(channel, 'rejected-messages').declare()\n        queue = rabbitpy.Queue(channel, 'dlx-example',\n                               dead_letter_exchange='rejected-messages')\n        queue.declare()\n\n```\n\n## 控制队列\n\n### 临时队列\n\n**自动删除队列**\n消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。\n\n示例程序：自动删除队列auto_delete=True\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'ad-example', auto_delete=True)\n        queue.declare()\n```\n\n**只允许单个消费者**\n只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。\n\n示例程序：独占队列exclusive\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'exclusive-example',\n                               exclusive=True)\n        queue.declare()\n```\n\n**自动过期队列**\n如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。\n\n示例程序：自动过期队列\n```\nimport rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-queue',\n                               arguments={'x-expires': 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print('The queue no longer exists')\n```\n\n### 永久队列\n\n**队列持久性**\n服务器重启后队列仍然存在。\n示例程序：持久队列\n\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'durable-queue',\n                               durable=True)\n        if queue.declare():\n            print('Queue declared')\n```\n\n**队列消息自动过期**\n同时指定死信交换器和消息TTL，过期消息将成为死信消息。\n\n示例程序：消息TTL\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-msg-queue',\n                               arguments={'x-message-ttl': 1000})\n         queue.declare()\n\n```\n\n**最大队列长度**\n一旦达到最大值，添加新消息时，删除队列前端的消息。\n\n声明队列时，如果指定死信交换器，前端移除的消息将成为死信。\n\n示例程序：最大长度队列\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'max-length-queue',\n                               arguments={'x-max-length': 1000})\n        queue.declare()\n\n```\n\n\n### 队列设置参数\n\n| 参数                      | 说明                                 |\n| ------------------------- | ------------------------------------ |\n| x-dead-letter-exchange    | 死信交换器，路由不重发且被拒绝的消息 |\n| x-dead-letter-routing-key | 死信消息的可选路由键                 |\n| x-expires                 | 队列在指定的毫秒数后删除             |\n| x-ha-proxy                | 创建HA队列                           |\n| x-ha-nodes                | HA队列分布的节点                     |\n| x-max-length              | 队列的最大消息数                     |\n| x-message-ttl             | 毫秒为单位的队列过期时间             |\n| x-max-priority            | 队列优先级排序                       |","source":"_posts/rabbitmq消息消费.md","raw":"---\ntitle: rabbitmq消息消费\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:16:01\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 消费方法\n\n### **Basic.Get**\n\n - 每次接收消息必须发送一次请求 \n - 有消息可用，RabbitMQ返回Basic.GetOk以及消息\n - 无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。\n\n示例程序\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == 'stop':\n                    break\n```\n\n### **Basic.Consume**\n\n- 消费者可用时，异步方式发送消息\n- 应用程序自动接收消息，直到Basic.Cancel\n- 仍然需要确认消息\n\n示例程序\n```python\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint(）\n    # 消息确认\n    message.ack()\n```\n\n**消费者标签**\n应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。\n客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。\n\n示例代码：监听消息直到，收到停止消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n            if message.body == 'stop':\n                break\n```\n\n\n### **对比**\nConsume吞吐量更大。Get包含了每条消息的同步通信开销。\n\n## 消费性能优化\n\n### 1、no-ack\n\n应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。\n\n示例代码：消费不确认\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()\n```\n\n### 2、预取\n\nQoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。\n\n示例程序：指定QoS\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #预取数为10\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n```\n\n应用程序不需要确认每条消息，可确认所有以前未读消息。\n\n示例程序：多消息确认\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            unacknowledged += 1\n            if unacknowledged == 10:\n                # 确认所有未确认消息\n                message.ack(all_previous=True)\n                unacknowledged = 0\n\n```\n\n### 3、事务\n\n事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。\n\n## 拒绝消息\n\n### Basic.Reject\n\n通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。\n\n示例程序：消息拒绝\n```\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint()\n    print('Redelivered: %s' % message.redelivered)\n    message.reject(True)\n```\n\n### Basic.Nack\n\n同时拒绝多个消息\n\n### 死信交换器（DLX）\n\n创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。\n\n示例程序：指定死信交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #死信交换器\n        rabbitpy.Exchange(channel, 'rejected-messages').declare()\n        queue = rabbitpy.Queue(channel, 'dlx-example',\n                               dead_letter_exchange='rejected-messages')\n        queue.declare()\n\n```\n\n## 控制队列\n\n### 临时队列\n\n**自动删除队列**\n消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。\n\n示例程序：自动删除队列auto_delete=True\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'ad-example', auto_delete=True)\n        queue.declare()\n```\n\n**只允许单个消费者**\n只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。\n\n示例程序：独占队列exclusive\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'exclusive-example',\n                               exclusive=True)\n        queue.declare()\n```\n\n**自动过期队列**\n如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。\n\n示例程序：自动过期队列\n```\nimport rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-queue',\n                               arguments={'x-expires': 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print('The queue no longer exists')\n```\n\n### 永久队列\n\n**队列持久性**\n服务器重启后队列仍然存在。\n示例程序：持久队列\n\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'durable-queue',\n                               durable=True)\n        if queue.declare():\n            print('Queue declared')\n```\n\n**队列消息自动过期**\n同时指定死信交换器和消息TTL，过期消息将成为死信消息。\n\n示例程序：消息TTL\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-msg-queue',\n                               arguments={'x-message-ttl': 1000})\n         queue.declare()\n\n```\n\n**最大队列长度**\n一旦达到最大值，添加新消息时，删除队列前端的消息。\n\n声明队列时，如果指定死信交换器，前端移除的消息将成为死信。\n\n示例程序：最大长度队列\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'max-length-queue',\n                               arguments={'x-max-length': 1000})\n        queue.declare()\n\n```\n\n\n### 队列设置参数\n\n| 参数                      | 说明                                 |\n| ------------------------- | ------------------------------------ |\n| x-dead-letter-exchange    | 死信交换器，路由不重发且被拒绝的消息 |\n| x-dead-letter-routing-key | 死信消息的可选路由键                 |\n| x-expires                 | 队列在指定的毫秒数后删除             |\n| x-ha-proxy                | 创建HA队列                           |\n| x-ha-nodes                | HA队列分布的节点                     |\n| x-max-length              | 队列的最大消息数                     |\n| x-message-ttl             | 毫秒为单位的队列过期时间             |\n| x-max-priority            | 队列优先级排序                       |","slug":"rabbitmq消息消费","published":1,"updated":"2021-05-11T11:33:29.589Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss70e0031q4uf682jz9xz","content":"<h2 id=\"消费方法\"><a href=\"#消费方法\" class=\"headerlink\" title=\"消费方法\"></a>消费方法</h2><h3 id=\"Basic-Get\"><a href=\"#Basic-Get\" class=\"headerlink\" title=\"Basic.Get\"></a><strong>Basic.Get</strong></h3><ul>\n<li>每次接收消息必须发送一次请求 </li>\n<li>有消息可用，RabbitMQ返回Basic.GetOk以及消息</li>\n<li>无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。</li>\n</ul>\n<p>示例程序</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == &#39;stop&#39;:\n                    break</code></pre><h3 id=\"Basic-Consume\"><a href=\"#Basic-Consume\" class=\"headerlink\" title=\"Basic.Consume\"></a><strong>Basic.Consume</strong></h3><ul>\n<li>消费者可用时，异步方式发送消息</li>\n<li>应用程序自动接收消息，直到Basic.Cancel</li>\n<li>仍然需要确认消息</li>\n</ul>\n<p>示例程序</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>consume<span class=\"token punctuation\">(</span><span class=\"token string\">'amqp://guest:guest@localhost:5672/%2f'</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span>）\n    <span class=\"token comment\" spellcheck=\"true\"># 消息确认</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>消费者标签</strong><br>应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。<br>客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。</p>\n<p>示例代码：监听消息直到，收到停止消息</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> message<span class=\"token punctuation\">.</span>body <span class=\"token operator\">==</span> <span class=\"token string\">'stop'</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">break</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a><strong>对比</strong></h3><p>Consume吞吐量更大。Get包含了每条消息的同步通信开销。</p>\n<h2 id=\"消费性能优化\"><a href=\"#消费性能优化\" class=\"headerlink\" title=\"消费性能优化\"></a>消费性能优化</h2><h3 id=\"1、no-ack\"><a href=\"#1、no-ack\" class=\"headerlink\" title=\"1、no-ack\"></a>1、no-ack</h3><p>应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。</p>\n<p>示例代码：消费不确认</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()</code></pre><h3 id=\"2、预取\"><a href=\"#2、预取\" class=\"headerlink\" title=\"2、预取\"></a>2、预取</h3><p>QoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。</p>\n<p>示例程序：指定QoS</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\">#预取数为10</span>\n        channel<span class=\"token punctuation\">.</span>prefetch_count<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>应用程序不需要确认每条消息，可确认所有以前未读消息。</p>\n<p>示例程序：多消息确认</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        channel<span class=\"token punctuation\">.</span>prefetch_count<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            unacknowledged <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">if</span> unacknowledged <span class=\"token operator\">==</span> <span class=\"token number\">10</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\" spellcheck=\"true\"># 确认所有未确认消息</span>\n                message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span>all_previous<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n                unacknowledged <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"3、事务\"><a href=\"#3、事务\" class=\"headerlink\" title=\"3、事务\"></a>3、事务</h3><p>事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。</p>\n<h2 id=\"拒绝消息\"><a href=\"#拒绝消息\" class=\"headerlink\" title=\"拒绝消息\"></a>拒绝消息</h2><h3 id=\"Basic-Reject\"><a href=\"#Basic-Reject\" class=\"headerlink\" title=\"Basic.Reject\"></a>Basic.Reject</h3><p>通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。</p>\n<p>示例程序：消息拒绝</p>\n<pre><code>import rabbitpy\n\nfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,\n                                &#39;test-messages&#39;):\n    message.pprint()\n    print(&#39;Redelivered: %s&#39; % message.redelivered)\n    message.reject(True)</code></pre><h3 id=\"Basic-Nack\"><a href=\"#Basic-Nack\" class=\"headerlink\" title=\"Basic.Nack\"></a>Basic.Nack</h3><p>同时拒绝多个消息</p>\n<h3 id=\"死信交换器（DLX）\"><a href=\"#死信交换器（DLX）\" class=\"headerlink\" title=\"死信交换器（DLX）\"></a>死信交换器（DLX）</h3><p>创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。</p>\n<p>示例程序：指定死信交换器</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\">#死信交换器</span>\n        rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'rejected-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'dlx-example'</span><span class=\"token punctuation\">,</span>\n                               dead_letter_exchange<span class=\"token operator\">=</span><span class=\"token string\">'rejected-messages'</span><span class=\"token punctuation\">)</span>\n        queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"控制队列\"><a href=\"#控制队列\" class=\"headerlink\" title=\"控制队列\"></a>控制队列</h2><h3 id=\"临时队列\"><a href=\"#临时队列\" class=\"headerlink\" title=\"临时队列\"></a>临时队列</h3><p><strong>自动删除队列</strong><br>消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。</p>\n<p>示例程序：自动删除队列auto_delete=True</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;ad-example&#39;, auto_delete=True)\n        queue.declare()</code></pre><p><strong>只允许单个消费者</strong><br>只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。</p>\n<p>示例程序：独占队列exclusive</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;exclusive-example&#39;,\n                               exclusive=True)\n        queue.declare()</code></pre><p><strong>自动过期队列</strong><br>如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。</p>\n<p>示例程序：自动过期队列</p>\n<pre><code>import rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-queue&#39;,\n                               arguments={&#39;x-expires&#39;: 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print(&#39;The queue no longer exists&#39;)</code></pre><h3 id=\"永久队列\"><a href=\"#永久队列\" class=\"headerlink\" title=\"永久队列\"></a>永久队列</h3><p><strong>队列持久性</strong><br>服务器重启后队列仍然存在。<br>示例程序：持久队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;durable-queue&#39;,\n                               durable=True)\n        if queue.declare():\n            print(&#39;Queue declared&#39;)</code></pre><p><strong>队列消息自动过期</strong><br>同时指定死信交换器和消息TTL，过期消息将成为死信消息。</p>\n<p>示例程序：消息TTL</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-msg-queue&#39;,\n                               arguments={&#39;x-message-ttl&#39;: 1000})\n         queue.declare()\n</code></pre><p><strong>最大队列长度</strong><br>一旦达到最大值，添加新消息时，删除队列前端的消息。</p>\n<p>声明队列时，如果指定死信交换器，前端移除的消息将成为死信。</p>\n<p>示例程序：最大长度队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;max-length-queue&#39;,\n                               arguments={&#39;x-max-length&#39;: 1000})\n        queue.declare()\n</code></pre><h3 id=\"队列设置参数\"><a href=\"#队列设置参数\" class=\"headerlink\" title=\"队列设置参数\"></a>队列设置参数</h3><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>x-dead-letter-exchange</td>\n<td>死信交换器，路由不重发且被拒绝的消息</td>\n</tr>\n<tr>\n<td>x-dead-letter-routing-key</td>\n<td>死信消息的可选路由键</td>\n</tr>\n<tr>\n<td>x-expires</td>\n<td>队列在指定的毫秒数后删除</td>\n</tr>\n<tr>\n<td>x-ha-proxy</td>\n<td>创建HA队列</td>\n</tr>\n<tr>\n<td>x-ha-nodes</td>\n<td>HA队列分布的节点</td>\n</tr>\n<tr>\n<td>x-max-length</td>\n<td>队列的最大消息数</td>\n</tr>\n<tr>\n<td>x-message-ttl</td>\n<td>毫秒为单位的队列过期时间</td>\n</tr>\n<tr>\n<td>x-max-priority</td>\n<td>队列优先级排序</td>\n</tr>\n</tbody></table>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"消费方法\"><a href=\"#消费方法\" class=\"headerlink\" title=\"消费方法\"></a>消费方法</h2><h3 id=\"Basic-Get\"><a href=\"#Basic-Get\" class=\"headerlink\" title=\"Basic.Get\"></a><strong>Basic.Get</strong></h3><ul>\n<li>每次接收消息必须发送一次请求 </li>\n<li>有消息可用，RabbitMQ返回Basic.GetOk以及消息</li>\n<li>无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。</li>\n</ul>\n<p>示例程序</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == &#39;stop&#39;:\n                    break</code></pre><h3 id=\"Basic-Consume\"><a href=\"#Basic-Consume\" class=\"headerlink\" title=\"Basic.Consume\"></a><strong>Basic.Consume</strong></h3><ul>\n<li>消费者可用时，异步方式发送消息</li>\n<li>应用程序自动接收消息，直到Basic.Cancel</li>\n<li>仍然需要确认消息</li>\n</ul>\n<p>示例程序</p>\n<pre><code class=\"python\">import rabbitpy\n\nfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,\n                                &#39;test-messages&#39;):\n    message.pprint(）\n    # 消息确认\n    message.ack()</code></pre>\n<p><strong>消费者标签</strong><br>应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。<br>客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。</p>\n<p>示例代码：监听消息直到，收到停止消息</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for message in rabbitpy.Queue(channel, &#39;test-messages&#39;):\n            message.pprint()\n            message.ack()\n            if message.body == &#39;stop&#39;:\n                break</code></pre>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a><strong>对比</strong></h3><p>Consume吞吐量更大。Get包含了每条消息的同步通信开销。</p>\n<h2 id=\"消费性能优化\"><a href=\"#消费性能优化\" class=\"headerlink\" title=\"消费性能优化\"></a>消费性能优化</h2><h3 id=\"1、no-ack\"><a href=\"#1、no-ack\" class=\"headerlink\" title=\"1、no-ack\"></a>1、no-ack</h3><p>应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。</p>\n<p>示例代码：消费不确认</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()</code></pre><h3 id=\"2、预取\"><a href=\"#2、预取\" class=\"headerlink\" title=\"2、预取\"></a>2、预取</h3><p>QoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。</p>\n<p>示例程序：指定QoS</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #预取数为10\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, &#39;test-messages&#39;):\n            message.pprint()\n            message.ack()</code></pre>\n<p>应用程序不需要确认每条消息，可确认所有以前未读消息。</p>\n<p>示例程序：多消息确认</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, &#39;test-messages&#39;):\n            message.pprint()\n            unacknowledged += 1\n            if unacknowledged == 10:\n                # 确认所有未确认消息\n                message.ack(all_previous=True)\n                unacknowledged = 0\n</code></pre>\n<h3 id=\"3、事务\"><a href=\"#3、事务\" class=\"headerlink\" title=\"3、事务\"></a>3、事务</h3><p>事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。</p>\n<h2 id=\"拒绝消息\"><a href=\"#拒绝消息\" class=\"headerlink\" title=\"拒绝消息\"></a>拒绝消息</h2><h3 id=\"Basic-Reject\"><a href=\"#Basic-Reject\" class=\"headerlink\" title=\"Basic.Reject\"></a>Basic.Reject</h3><p>通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。</p>\n<p>示例程序：消息拒绝</p>\n<pre><code>import rabbitpy\n\nfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,\n                                &#39;test-messages&#39;):\n    message.pprint()\n    print(&#39;Redelivered: %s&#39; % message.redelivered)\n    message.reject(True)</code></pre><h3 id=\"Basic-Nack\"><a href=\"#Basic-Nack\" class=\"headerlink\" title=\"Basic.Nack\"></a>Basic.Nack</h3><p>同时拒绝多个消息</p>\n<h3 id=\"死信交换器（DLX）\"><a href=\"#死信交换器（DLX）\" class=\"headerlink\" title=\"死信交换器（DLX）\"></a>死信交换器（DLX）</h3><p>创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。</p>\n<p>示例程序：指定死信交换器</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #死信交换器\n        rabbitpy.Exchange(channel, &#39;rejected-messages&#39;).declare()\n        queue = rabbitpy.Queue(channel, &#39;dlx-example&#39;,\n                               dead_letter_exchange=&#39;rejected-messages&#39;)\n        queue.declare()\n</code></pre>\n<h2 id=\"控制队列\"><a href=\"#控制队列\" class=\"headerlink\" title=\"控制队列\"></a>控制队列</h2><h3 id=\"临时队列\"><a href=\"#临时队列\" class=\"headerlink\" title=\"临时队列\"></a>临时队列</h3><p><strong>自动删除队列</strong><br>消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。</p>\n<p>示例程序：自动删除队列auto_delete=True</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;ad-example&#39;, auto_delete=True)\n        queue.declare()</code></pre><p><strong>只允许单个消费者</strong><br>只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。</p>\n<p>示例程序：独占队列exclusive</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;exclusive-example&#39;,\n                               exclusive=True)\n        queue.declare()</code></pre><p><strong>自动过期队列</strong><br>如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。</p>\n<p>示例程序：自动过期队列</p>\n<pre><code>import rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-queue&#39;,\n                               arguments={&#39;x-expires&#39;: 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print(&#39;The queue no longer exists&#39;)</code></pre><h3 id=\"永久队列\"><a href=\"#永久队列\" class=\"headerlink\" title=\"永久队列\"></a>永久队列</h3><p><strong>队列持久性</strong><br>服务器重启后队列仍然存在。<br>示例程序：持久队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;durable-queue&#39;,\n                               durable=True)\n        if queue.declare():\n            print(&#39;Queue declared&#39;)</code></pre><p><strong>队列消息自动过期</strong><br>同时指定死信交换器和消息TTL，过期消息将成为死信消息。</p>\n<p>示例程序：消息TTL</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-msg-queue&#39;,\n                               arguments={&#39;x-message-ttl&#39;: 1000})\n         queue.declare()\n</code></pre><p><strong>最大队列长度</strong><br>一旦达到最大值，添加新消息时，删除队列前端的消息。</p>\n<p>声明队列时，如果指定死信交换器，前端移除的消息将成为死信。</p>\n<p>示例程序：最大长度队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;max-length-queue&#39;,\n                               arguments={&#39;x-max-length&#39;: 1000})\n        queue.declare()\n</code></pre><h3 id=\"队列设置参数\"><a href=\"#队列设置参数\" class=\"headerlink\" title=\"队列设置参数\"></a>队列设置参数</h3><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>x-dead-letter-exchange</td>\n<td>死信交换器，路由不重发且被拒绝的消息</td>\n</tr>\n<tr>\n<td>x-dead-letter-routing-key</td>\n<td>死信消息的可选路由键</td>\n</tr>\n<tr>\n<td>x-expires</td>\n<td>队列在指定的毫秒数后删除</td>\n</tr>\n<tr>\n<td>x-ha-proxy</td>\n<td>创建HA队列</td>\n</tr>\n<tr>\n<td>x-ha-nodes</td>\n<td>HA队列分布的节点</td>\n</tr>\n<tr>\n<td>x-max-length</td>\n<td>队列的最大消息数</td>\n</tr>\n<tr>\n<td>x-message-ttl</td>\n<td>毫秒为单位的队列过期时间</td>\n</tr>\n<tr>\n<td>x-max-priority</td>\n<td>队列优先级排序</td>\n</tr>\n</tbody></table>\n"},{"title":"rabbitmq概念","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-03T10:50:50.000Z","password":null,"summary":"rabbit相关概念介绍","_content":"\nRabbitmq是生产者与消费者模型，负责接收、存储、转发消息。\n\n![](moxin.png)\n\n**Producer：生产者**\n\n**消息**包含2部分：\n\n- **消息体（payload）：**一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。\n\n- **标签（Label）：**用来描述这条消息，比如一个交换器的名称和一个路由键。\n\n**Consumer：消费者**\n\n当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。\n\n**Broker：服务节点**\n\n**Virtual host：**虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成\n\n**交换器类型**\n\nfanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中\n\ndirect：把消息路由到BindingKey和RoutingKey完全匹配的队列中\n\ntopic：把消息路由到BindingKey和RoutingKey相匹配的队列中\n\nheaders：根据发送消息内容中的headers进行匹配，性能比较差\n**运转流程**\n**生产者发送消息**\n\n- 生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）\n\n- 生产者声明一个交换器，并设置相关属性（交换机类型、持久化）\n\n- 生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）\n\n- 生产者通过路由键将交换器和队列绑定起来\n\n- 生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）\n\n- 相应的交换器根据接收到的路由键查找相匹配的队列\n\n- 若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者\n\n- 关闭信道\n\n- 关闭连接\n\n**消费者接收消息**\n\n- 消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）\n- 消费者向 RabbitMQ Broker 请求消费对应队列中的消息\n- 等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息\n- 消费者确认（ack）接收到的消息\n- RabbitMQ 从队列中删除相应已经被确认的消息\n- 关闭信道\n- 关闭连接\n\n","source":"_posts/rabbitmq概念.md","raw":"---\ntitle: rabbitmq概念\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-03 18:50:50\npassword:\nsummary: rabbit相关概念介绍\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\nRabbitmq是生产者与消费者模型，负责接收、存储、转发消息。\n\n![](moxin.png)\n\n**Producer：生产者**\n\n**消息**包含2部分：\n\n- **消息体（payload）：**一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。\n\n- **标签（Label）：**用来描述这条消息，比如一个交换器的名称和一个路由键。\n\n**Consumer：消费者**\n\n当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。\n\n**Broker：服务节点**\n\n**Virtual host：**虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成\n\n**交换器类型**\n\nfanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中\n\ndirect：把消息路由到BindingKey和RoutingKey完全匹配的队列中\n\ntopic：把消息路由到BindingKey和RoutingKey相匹配的队列中\n\nheaders：根据发送消息内容中的headers进行匹配，性能比较差\n**运转流程**\n**生产者发送消息**\n\n- 生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）\n\n- 生产者声明一个交换器，并设置相关属性（交换机类型、持久化）\n\n- 生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）\n\n- 生产者通过路由键将交换器和队列绑定起来\n\n- 生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）\n\n- 相应的交换器根据接收到的路由键查找相匹配的队列\n\n- 若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者\n\n- 关闭信道\n\n- 关闭连接\n\n**消费者接收消息**\n\n- 消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）\n- 消费者向 RabbitMQ Broker 请求消费对应队列中的消息\n- 等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息\n- 消费者确认（ack）接收到的消息\n- RabbitMQ 从队列中删除相应已经被确认的消息\n- 关闭信道\n- 关闭连接\n\n","slug":"rabbitmq概念","published":1,"updated":"2021-05-11T11:33:29.565Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss70j0033q4ufejdlwyys","content":"<p>Rabbitmq是生产者与消费者模型，负责接收、存储、转发消息。</p>\n<p><img src=\"moxin.png\" alt></p>\n<p><strong>Producer：生产者</strong></p>\n<p><strong>消息</strong>包含2部分：</p>\n<ul>\n<li><p><strong>消息体（payload）：</strong>一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。</p>\n</li>\n<li><p><strong>标签（Label）：</strong>用来描述这条消息，比如一个交换器的名称和一个路由键。</p>\n</li>\n</ul>\n<p><strong>Consumer：消费者</strong></p>\n<p>当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。</p>\n<p><strong>Broker：服务节点</strong></p>\n<p><strong>Virtual host：</strong>虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成</p>\n<p><strong>交换器类型</strong></p>\n<p>fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中</p>\n<p>direct：把消息路由到BindingKey和RoutingKey完全匹配的队列中</p>\n<p>topic：把消息路由到BindingKey和RoutingKey相匹配的队列中</p>\n<p>headers：根据发送消息内容中的headers进行匹配，性能比较差<br><strong>运转流程</strong><br><strong>生产者发送消息</strong></p>\n<ul>\n<li><p>生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）</p>\n</li>\n<li><p>生产者声明一个交换器，并设置相关属性（交换机类型、持久化）</p>\n</li>\n<li><p>生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）</p>\n</li>\n<li><p>生产者通过路由键将交换器和队列绑定起来</p>\n</li>\n<li><p>生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）</p>\n</li>\n<li><p>相应的交换器根据接收到的路由键查找相匹配的队列</p>\n</li>\n<li><p>若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者</p>\n</li>\n<li><p>关闭信道</p>\n</li>\n<li><p>关闭连接</p>\n</li>\n</ul>\n<p><strong>消费者接收消息</strong></p>\n<ul>\n<li>消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）</li>\n<li>消费者向 RabbitMQ Broker 请求消费对应队列中的消息</li>\n<li>等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息</li>\n<li>消费者确认（ack）接收到的消息</li>\n<li>RabbitMQ 从队列中删除相应已经被确认的消息</li>\n<li>关闭信道</li>\n<li>关闭连接</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>Rabbitmq是生产者与消费者模型，负责接收、存储、转发消息。</p>\n<p><img src=\"moxin.png\" alt></p>\n<p><strong>Producer：生产者</strong></p>\n<p><strong>消息</strong>包含2部分：</p>\n<ul>\n<li><p><strong>消息体（payload）：</strong>一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。</p>\n</li>\n<li><p><strong>标签（Label）：</strong>用来描述这条消息，比如一个交换器的名称和一个路由键。</p>\n</li>\n</ul>\n<p><strong>Consumer：消费者</strong></p>\n<p>当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。</p>\n<p><strong>Broker：服务节点</strong></p>\n<p><strong>Virtual host：</strong>虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成</p>\n<p><strong>交换器类型</strong></p>\n<p>fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中</p>\n<p>direct：把消息路由到BindingKey和RoutingKey完全匹配的队列中</p>\n<p>topic：把消息路由到BindingKey和RoutingKey相匹配的队列中</p>\n<p>headers：根据发送消息内容中的headers进行匹配，性能比较差<br><strong>运转流程</strong><br><strong>生产者发送消息</strong></p>\n<ul>\n<li><p>生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）</p>\n</li>\n<li><p>生产者声明一个交换器，并设置相关属性（交换机类型、持久化）</p>\n</li>\n<li><p>生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）</p>\n</li>\n<li><p>生产者通过路由键将交换器和队列绑定起来</p>\n</li>\n<li><p>生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）</p>\n</li>\n<li><p>相应的交换器根据接收到的路由键查找相匹配的队列</p>\n</li>\n<li><p>若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者</p>\n</li>\n<li><p>关闭信道</p>\n</li>\n<li><p>关闭连接</p>\n</li>\n</ul>\n<p><strong>消费者接收消息</strong></p>\n<ul>\n<li>消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）</li>\n<li>消费者向 RabbitMQ Broker 请求消费对应队列中的消息</li>\n<li>等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息</li>\n<li>消费者确认（ack）接收到的消息</li>\n<li>RabbitMQ 从队列中删除相应已经被确认的消息</li>\n<li>关闭信道</li>\n<li>关闭连接</li>\n</ul>\n"},{"title":"rabbitmq消息发布","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:13:06.000Z","password":null,"summary":null,"_content":"\n## 可靠投递\n\n------------\n\n### mandatory\n\n当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。\nBasic.Return是异步的，在消息发布后的任何时候都可能发生。\n在rabbitpy库中，客户端自动接收Basic.Return，并触发异常\n\n示例程序：发布失败\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        # Create the message to send\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel,\n                                   body,\n                                   {'content_type': 'text/plain',\n                                    'timestamp': datetime.datetime.now(),\n                                    'message_type': 'graphite metric'})\n\n        # Publish the message to the exchange with the routing key\n        # \"server-metrics\" and make sure it is routed to the exchange\n        message.publish('chapter2-example', 'server-metrics', mandatory=True)\n```\n\n示例程序：异常捕获\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        properties = {'content_type': 'text/plain',\n                      'timestamp': datetime.datetime.now(),\n                      'message_type': 'graphite metric'}\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel, body, properties)\n        message.publish('chapter2-example',\n                        'server-metrics',\n                        mandatory=True)\nexcept rabbitpy.exceptions.MessageReturnedException as error:\n    print('Publish failure: %s' % error)\n```\n\n### 发布者确认\n\n发布者发送给RabbitMQ的每条消息，服务器发送一个确认（Basic.Ack）或者否认响应（Basic.Nack）。\n\n示例程序：发布者确认\n```python\nimport rabbitpy\n\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'chapter4-example')\n        exchange.declare()\n        channel.enable_publisher_confirms()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'message_type': 'very important'})\n        if message.publish('chapter4-example', 'important.message'):\n            print('The message was confirmed')\n```\n\nrabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。\n\n### 备用交换器\n\n处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。\n\n\n示例程序：备用交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        my_ae = rabbitpy.Exchange(channel, 'my-ae',\n                                  exchange_type='fanout')\n        my_ae.declare()\n        args = {'alternate-exchange': my_ae.name}\n        exchange = rabbitpy.Exchange(channel,\n                                     'graphite',\n                                     exchange_type='topic',\n                                     arguments=args)\n        exchange.declare()\n        queue = rabbitpy.Queue(channel, 'unroutable-messages')\n        queue.declare()\n        if queue.bind(my_ae, '#'):\n            print('Queue bound to alternate-exchange')\n```\n\n### 基于事务的批量处理\n\n确保消息投递成功。\n\n\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tx = rabbitpy.Tx(channel)\n        tx.select()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'delivery_mode': 2,\n                                    'message_type': 'important'})\n        message.publish('chapter4-example', 'important.message')\n        try:\n            if tx.commit():\n                print('Transaction committed')\n        except rabbitpy.exceptions.NoActiveTransactionError:\n            print('Tried to commit without active transaction')\n```\n\n由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。\n\n### HA队列\n\n允许队列在多个服务器拥有冗余副本。\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n示例代码：HA队列声明\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel,\n                               'my-ha-queue',\n                               arguments={'x-ha-policy': 'all'})\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n\n示例代码：HA队列指定节点\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        arguments = {'x-ha-policy': 'nodes',\n                     'x-ha-nodes': ['rabbit@node1',\n                                    'rabbit@node2',\n                                    'rabbit@node3']}\n        queue = rabbitpy.Queue(channel,\n                               'my-2nd-ha-queue',\n                               arguments=arguments)\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n### 消息持久化\n\ndelivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。\n\n如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。\n\n\n## rabbitmq回推\n\n发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。\n\n示例代码：检测连接状态\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\nprint('Channel is Blocked? %s' % connection.blocked)\n\n```","source":"_posts/rabbitmq消息发布.md","raw":"---\ntitle: rabbitmq消息发布\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:13:06\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 可靠投递\n\n------------\n\n### mandatory\n\n当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。\nBasic.Return是异步的，在消息发布后的任何时候都可能发生。\n在rabbitpy库中，客户端自动接收Basic.Return，并触发异常\n\n示例程序：发布失败\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        # Create the message to send\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel,\n                                   body,\n                                   {'content_type': 'text/plain',\n                                    'timestamp': datetime.datetime.now(),\n                                    'message_type': 'graphite metric'})\n\n        # Publish the message to the exchange with the routing key\n        # \"server-metrics\" and make sure it is routed to the exchange\n        message.publish('chapter2-example', 'server-metrics', mandatory=True)\n```\n\n示例程序：异常捕获\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        properties = {'content_type': 'text/plain',\n                      'timestamp': datetime.datetime.now(),\n                      'message_type': 'graphite metric'}\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel, body, properties)\n        message.publish('chapter2-example',\n                        'server-metrics',\n                        mandatory=True)\nexcept rabbitpy.exceptions.MessageReturnedException as error:\n    print('Publish failure: %s' % error)\n```\n\n### 发布者确认\n\n发布者发送给RabbitMQ的每条消息，服务器发送一个确认（Basic.Ack）或者否认响应（Basic.Nack）。\n\n示例程序：发布者确认\n```python\nimport rabbitpy\n\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'chapter4-example')\n        exchange.declare()\n        channel.enable_publisher_confirms()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'message_type': 'very important'})\n        if message.publish('chapter4-example', 'important.message'):\n            print('The message was confirmed')\n```\n\nrabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。\n\n### 备用交换器\n\n处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。\n\n\n示例程序：备用交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        my_ae = rabbitpy.Exchange(channel, 'my-ae',\n                                  exchange_type='fanout')\n        my_ae.declare()\n        args = {'alternate-exchange': my_ae.name}\n        exchange = rabbitpy.Exchange(channel,\n                                     'graphite',\n                                     exchange_type='topic',\n                                     arguments=args)\n        exchange.declare()\n        queue = rabbitpy.Queue(channel, 'unroutable-messages')\n        queue.declare()\n        if queue.bind(my_ae, '#'):\n            print('Queue bound to alternate-exchange')\n```\n\n### 基于事务的批量处理\n\n确保消息投递成功。\n\n\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tx = rabbitpy.Tx(channel)\n        tx.select()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'delivery_mode': 2,\n                                    'message_type': 'important'})\n        message.publish('chapter4-example', 'important.message')\n        try:\n            if tx.commit():\n                print('Transaction committed')\n        except rabbitpy.exceptions.NoActiveTransactionError:\n            print('Tried to commit without active transaction')\n```\n\n由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。\n\n### HA队列\n\n允许队列在多个服务器拥有冗余副本。\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n示例代码：HA队列声明\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel,\n                               'my-ha-queue',\n                               arguments={'x-ha-policy': 'all'})\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n\n示例代码：HA队列指定节点\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        arguments = {'x-ha-policy': 'nodes',\n                     'x-ha-nodes': ['rabbit@node1',\n                                    'rabbit@node2',\n                                    'rabbit@node3']}\n        queue = rabbitpy.Queue(channel,\n                               'my-2nd-ha-queue',\n                               arguments=arguments)\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n### 消息持久化\n\ndelivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。\n\n如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。\n\n\n## rabbitmq回推\n\n发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。\n\n示例代码：检测连接状态\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\nprint('Channel is Blocked? %s' % connection.blocked)\n\n```","slug":"rabbitmq消息发布","published":1,"updated":"2021-05-11T11:33:29.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss70t0036q4ufpr3av5ob","content":"<h2 id=\"可靠投递\"><a href=\"#可靠投递\" class=\"headerlink\" title=\"可靠投递\"></a>可靠投递</h2><hr>\n<h3 id=\"mandatory\"><a href=\"#mandatory\" class=\"headerlink\" title=\"mandatory\"></a>mandatory</h3><p>当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。<br>Basic.Return是异步的，在消息发布后的任何时候都可能发生。<br>在rabbitpy库中，客户端自动接收Basic.Return，并触发异常</p>\n<p>示例程序：发布失败</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token comment\" spellcheck=\"true\"># Connect to the default URL of amqp://guest:guest@localhost:15672/%2F</span>\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\"># Create the message to send</span>\n        body <span class=\"token operator\">=</span> <span class=\"token string\">'server.cpu.utilization 25.5 1350884514'</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                   body<span class=\"token punctuation\">,</span>\n                                   <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'graphite metric'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\" spellcheck=\"true\"># Publish the message to the exchange with the routing key</span>\n        <span class=\"token comment\" spellcheck=\"true\"># \"server-metrics\" and make sure it is routed to the exchange</span>\n        message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter2-example'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'server-metrics'</span><span class=\"token punctuation\">,</span> mandatory<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：异常捕获</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token comment\" spellcheck=\"true\"># Connect to the default URL of amqp://guest:guest@localhost:15672/%2F</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                      <span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                      <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'graphite metric'</span><span class=\"token punctuation\">}</span>\n        body <span class=\"token operator\">=</span> <span class=\"token string\">'server.cpu.utilization 25.5 1350884514'</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span>\n        message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter2-example'</span><span class=\"token punctuation\">,</span>\n                        <span class=\"token string\">'server-metrics'</span><span class=\"token punctuation\">,</span>\n                        mandatory<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>MessageReturnedException <span class=\"token keyword\">as</span> error<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Publish failure: %s'</span> <span class=\"token operator\">%</span> error<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"发布者确认\"><a href=\"#发布者确认\" class=\"headerlink\" title=\"发布者确认\"></a>发布者确认</h3><p>发布者发送给RabbitMQ的每条消息，服务器发送一个确认（Basic.Ack）或者否认响应（Basic.Nack）。</p>\n<p>示例程序：发布者确认</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'chapter4-example'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        channel<span class=\"token punctuation\">.</span>enable_publisher_confirms<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                   <span class=\"token string\">'This is an important message'</span><span class=\"token punctuation\">,</span>\n                                   <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'very important'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter4-example'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'important.message'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'The message was confirmed'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>rabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。</p>\n<h3 id=\"备用交换器\"><a href=\"#备用交换器\" class=\"headerlink\" title=\"备用交换器\"></a>备用交换器</h3><p>处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。</p>\n<p>示例程序：备用交换器</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        my_ae <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'my-ae'</span><span class=\"token punctuation\">,</span>\n                                  exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'fanout'</span><span class=\"token punctuation\">)</span>\n        my_ae<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        args <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'alternate-exchange'</span><span class=\"token punctuation\">:</span> my_ae<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">}</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                     <span class=\"token string\">'graphite'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'topic'</span><span class=\"token punctuation\">,</span>\n                                     arguments<span class=\"token operator\">=</span>args<span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'unroutable-messages'</span><span class=\"token punctuation\">)</span>\n        queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span>my_ae<span class=\"token punctuation\">,</span> <span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue bound to alternate-exchange'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"基于事务的批量处理\"><a href=\"#基于事务的批量处理\" class=\"headerlink\" title=\"基于事务的批量处理\"></a>基于事务的批量处理</h3><p>确保消息投递成功。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        tx <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Tx<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">)</span>\n        tx<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                   <span class=\"token string\">'This is an important message'</span><span class=\"token punctuation\">,</span>\n                                   <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'delivery_mode'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'important'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter4-example'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'important.message'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> tx<span class=\"token punctuation\">.</span>commit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Transaction committed'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>NoActiveTransactionError<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Tried to commit without active transaction'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。</p>\n<h3 id=\"HA队列\"><a href=\"#HA队列\" class=\"headerlink\" title=\"HA队列\"></a>HA队列</h3><p>允许队列在多个服务器拥有冗余副本。<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>示例代码：HA队列声明</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               <span class=\"token string\">'my-ha-queue'</span><span class=\"token punctuation\">,</span>\n                               arguments<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'x-ha-policy'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'all'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declared'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>RemoteClosedChannelException <span class=\"token keyword\">as</span> error<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declare failed: %s'</span> <span class=\"token operator\">%</span> error<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：HA队列指定节点</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        arguments <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'x-ha-policy'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'nodes'</span><span class=\"token punctuation\">,</span>\n                     <span class=\"token string\">'x-ha-nodes'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'rabbit@node1'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'rabbit@node2'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'rabbit@node3'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               <span class=\"token string\">'my-2nd-ha-queue'</span><span class=\"token punctuation\">,</span>\n                               arguments<span class=\"token operator\">=</span>arguments<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declared'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>RemoteClosedChannelException <span class=\"token keyword\">as</span> error<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declare failed: %s'</span> <span class=\"token operator\">%</span> error<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"消息持久化\"><a href=\"#消息持久化\" class=\"headerlink\" title=\"消息持久化\"></a>消息持久化</h3><p>delivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。</p>\n<p>如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。</p>\n<h2 id=\"rabbitmq回推\"><a href=\"#rabbitmq回推\" class=\"headerlink\" title=\"rabbitmq回推\"></a>rabbitmq回推</h2><p>发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。</p>\n<p>示例代码：检测连接状态</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Channel is Blocked? %s'</span> <span class=\"token operator\">%</span> connection<span class=\"token punctuation\">.</span>blocked<span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"可靠投递\"><a href=\"#可靠投递\" class=\"headerlink\" title=\"可靠投递\"></a>可靠投递</h2><hr>\n<h3 id=\"mandatory\"><a href=\"#mandatory\" class=\"headerlink\" title=\"mandatory\"></a>mandatory</h3><p>当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。<br>Basic.Return是异步的，在消息发布后的任何时候都可能发生。<br>在rabbitpy库中，客户端自动接收Basic.Return，并触发异常</p>\n<p>示例程序：发布失败</p>\n<pre><code class=\"python\">import datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        # Create the message to send\n        body = &#39;server.cpu.utilization 25.5 1350884514&#39;\n        message = rabbitpy.Message(channel,\n                                   body,\n                                   {&#39;content_type&#39;: &#39;text/plain&#39;,\n                                    &#39;timestamp&#39;: datetime.datetime.now(),\n                                    &#39;message_type&#39;: &#39;graphite metric&#39;})\n\n        # Publish the message to the exchange with the routing key\n        # &quot;server-metrics&quot; and make sure it is routed to the exchange\n        message.publish(&#39;chapter2-example&#39;, &#39;server-metrics&#39;, mandatory=True)</code></pre>\n<p>示例程序：异常捕获</p>\n<pre><code class=\"python\">import datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        properties = {&#39;content_type&#39;: &#39;text/plain&#39;,\n                      &#39;timestamp&#39;: datetime.datetime.now(),\n                      &#39;message_type&#39;: &#39;graphite metric&#39;}\n        body = &#39;server.cpu.utilization 25.5 1350884514&#39;\n        message = rabbitpy.Message(channel, body, properties)\n        message.publish(&#39;chapter2-example&#39;,\n                        &#39;server-metrics&#39;,\n                        mandatory=True)\nexcept rabbitpy.exceptions.MessageReturnedException as error:\n    print(&#39;Publish failure: %s&#39; % error)</code></pre>\n<h3 id=\"发布者确认\"><a href=\"#发布者确认\" class=\"headerlink\" title=\"发布者确认\"></a>发布者确认</h3><p>发布者发送给RabbitMQ的每条消息，服务器发送一个确认（Basic.Ack）或者否认响应（Basic.Nack）。</p>\n<p>示例程序：发布者确认</p>\n<pre><code class=\"python\">import rabbitpy\n\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;chapter4-example&#39;)\n        exchange.declare()\n        channel.enable_publisher_confirms()\n        message = rabbitpy.Message(channel,\n                                   &#39;This is an important message&#39;,\n                                   {&#39;content_type&#39;: &#39;text/plain&#39;,\n                                    &#39;message_type&#39;: &#39;very important&#39;})\n        if message.publish(&#39;chapter4-example&#39;, &#39;important.message&#39;):\n            print(&#39;The message was confirmed&#39;)</code></pre>\n<p>rabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。</p>\n<h3 id=\"备用交换器\"><a href=\"#备用交换器\" class=\"headerlink\" title=\"备用交换器\"></a>备用交换器</h3><p>处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。</p>\n<p>示例程序：备用交换器</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        my_ae = rabbitpy.Exchange(channel, &#39;my-ae&#39;,\n                                  exchange_type=&#39;fanout&#39;)\n        my_ae.declare()\n        args = {&#39;alternate-exchange&#39;: my_ae.name}\n        exchange = rabbitpy.Exchange(channel,\n                                     &#39;graphite&#39;,\n                                     exchange_type=&#39;topic&#39;,\n                                     arguments=args)\n        exchange.declare()\n        queue = rabbitpy.Queue(channel, &#39;unroutable-messages&#39;)\n        queue.declare()\n        if queue.bind(my_ae, &#39;#&#39;):\n            print(&#39;Queue bound to alternate-exchange&#39;)</code></pre>\n<h3 id=\"基于事务的批量处理\"><a href=\"#基于事务的批量处理\" class=\"headerlink\" title=\"基于事务的批量处理\"></a>基于事务的批量处理</h3><p>确保消息投递成功。</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tx = rabbitpy.Tx(channel)\n        tx.select()\n        message = rabbitpy.Message(channel,\n                                   &#39;This is an important message&#39;,\n                                   {&#39;content_type&#39;: &#39;text/plain&#39;,\n                                    &#39;delivery_mode&#39;: 2,\n                                    &#39;message_type&#39;: &#39;important&#39;})\n        message.publish(&#39;chapter4-example&#39;, &#39;important.message&#39;)\n        try:\n            if tx.commit():\n                print(&#39;Transaction committed&#39;)\n        except rabbitpy.exceptions.NoActiveTransactionError:\n            print(&#39;Tried to commit without active transaction&#39;)</code></pre>\n<p>由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。</p>\n<h3 id=\"HA队列\"><a href=\"#HA队列\" class=\"headerlink\" title=\"HA队列\"></a>HA队列</h3><p>允许队列在多个服务器拥有冗余副本。<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>示例代码：HA队列声明</p>\n<pre><code class=\"python\">import rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel,\n                               &#39;my-ha-queue&#39;,\n                               arguments={&#39;x-ha-policy&#39;: &#39;all&#39;})\n        if queue.declare():\n            print(&#39;Queue declared&#39;)\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print(&#39;Queue declare failed: %s&#39; % error)</code></pre>\n<p>示例代码：HA队列指定节点</p>\n<pre><code class=\"python\">import rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        arguments = {&#39;x-ha-policy&#39;: &#39;nodes&#39;,\n                     &#39;x-ha-nodes&#39;: [&#39;rabbit@node1&#39;,\n                                    &#39;rabbit@node2&#39;,\n                                    &#39;rabbit@node3&#39;]}\n        queue = rabbitpy.Queue(channel,\n                               &#39;my-2nd-ha-queue&#39;,\n                               arguments=arguments)\n        if queue.declare():\n            print(&#39;Queue declared&#39;)\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print(&#39;Queue declare failed: %s&#39; % error)</code></pre>\n<h3 id=\"消息持久化\"><a href=\"#消息持久化\" class=\"headerlink\" title=\"消息持久化\"></a>消息持久化</h3><p>delivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。</p>\n<p>如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。</p>\n<h2 id=\"rabbitmq回推\"><a href=\"#rabbitmq回推\" class=\"headerlink\" title=\"rabbitmq回推\"></a>rabbitmq回推</h2><p>发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。</p>\n<p>示例代码：检测连接状态</p>\n<pre><code class=\"python\">import rabbitpy\n\nconnection = rabbitpy.Connection()\nprint(&#39;Channel is Blocked? %s&#39; % connection.blocked)\n</code></pre>\n"},{"title":"rabbitmq进阶","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-03T13:32:53.000Z","password":null,"summary":null,"_content":"\n## 消息传递\n\n**mandatory**\n\n`mandatory=true`，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 `Basic.Return `命令将消息返回给生产者，生产者通过调用 `channel.addReturnListener `添加监听器接收返回结果\n`mandatory=false`，上述情形下，RabbitMQ 将消息直接丢弃\n\n**immediate**\n\n`immediate=true`，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 `Basic.Return` 返回生产者\n**和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息**\n\n**备份交换器（Alternate Exchange）**\n\nAE可以将未被路由的消息存储到 RabbitMQ 中。简化了`mandatory`+`addReturnListener `的编程逻辑。\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"alternate-exchange\",\"myAe\");\n\n// 声明普通交换器（AE交换器作为备份交换器）\nchannel.exchangeDeclare(\"normalExchange\",\"direct\",true,false,args);\n// 声明AE交换器\nchannel.exchangeDeclare(\"myAe\",\"fanout\",true,false,null);\n\n// 普通队列 绑定 普通交换器\nchannel.queueBind(\"normalQueue\",\"normalExchange\",\"normalKey\");\n\n// 声明 未路由队列\nchannel.queueDeclare(\"unroutedQueue\",true,false,false,null);\n// 未路由队列 绑定 AE交换器\nchannel.queueBind(\"unroutedQueue\",\"myAe\",\"\");\n```\n\n特殊情况\n\n- 若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器和mandatory参数一起使用，该参数无效\n\n## 过期时间（TTL）\n\n**通过队列属性设置消息TTL**\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"x-message-ttl\",6000); // 单位毫秒\nchannel.queueDeclare(queueName,durable,exclusive,autoDelete,args);\n```\n\n- 不设置TTL：该消息不会过期\n- TTL为0：若直接可以投递到消费者，否则立刻被丢弃\n\n消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。\n\n**设置每条消息TTL**\n\n在 `channel.basicPublish` 方法中加入 expiration 参数，单位毫秒\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.deliveryMode(2);\nbuilder.expiration(\"60000\");\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(exchangeName,routingKey,mandatory,properties,\"ttlTestMessage\".getBytes());\n```\n\n消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。\n\n**设置队列的TTL**\n\n通过 `channel.queueDeclare` 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间\n\nRabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置\n\n## 死信队列\n\n当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列\n\n死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度\n\n绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX\n\n## 延迟队列\n\n消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费\n\n**场景：**\n\n订单超时支付，延时队列做异常处理；\n\n智能设备在指定时间进行工作，延时队列做指令推送；\n\n**用法：**\n\n- 每条消息设置为10秒过期时间\n- 通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中\n- 消费者订阅 queue.dlx 队列\n- 10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息\n\n## 优先级队列\n\n具有高优先级的队列有高的优先权，优先级高的消息优先被消费\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.priority(5);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(\"exchange_priority\",\"rk_priority\",properties,(\"message\").getBytes());\n```\n\n- 默认优先级为0，最高为队列设置的最大优先级\n- 如果Broker中有消息堆积，优先级高的消息可以被优先消费\n\n## RPC实现\n\n远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。\n\nRPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。\n\n```java\nString callbackQueueName = channel.queueDeclare().getQueue();\nBasicProperties props = new BasicProperties.Builder().replyTo(callbackQueueName).build();\nchannel.basicPublish(\"\",\"rpc_queue\",props,message.getBytes());\n```\n\nRPC 处理流程：\n\n- 客户端启动时，创建一个匿名的回调队列\n- 客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求\n- 请求被发送到 rpc_queue 队列中\n- RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列''; \n- 客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果\n\n## 持久化\n\n持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失\n\n持久化的各种情况\n\nRabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化\n\n- 若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。\n- 若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失\n- 若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡\n- 生产环境会设置镜像队列保证系统的高可用性\n  \n\n## 生产者确认\n\n默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。\n\n**事务机制**\n\n事务方法：\n\n- channel.txSelect： 用于将当前信道设置成事务模式\n- channel.txCommit：用于提交事务\n- channel.txRollback：用于事务回滚\n\n事务流程：\n\n- 客户端发送 Tx.Select，将信道置为事务模式\n- Broker回复 Tx.Select-Ok，确认已将信道置为事务模式\n- Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务\n- Broker 回复 Tx.Commit，确认事务提交\n\n事务问题：事务机制会耗尽 RabbitMQ 的性能\n\n**发送方确认机制**\n\n1. 生产者将信道设置成 confirm 模式\n2. 信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID\n3. 消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者\n\n发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。\n\n发送方确认机制的优势在于不一定需要同步确认：\n\n- 批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回\n- 异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。\n\n注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。\n\n## 消费端要点\n\n**消息分发**\n\n- 当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者\n- 但是这样会造成因为各机器性能不同而引起负载不均\n- 消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量\n- 一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果\n- Basic.Qos的使用对于拉模式消费方式无效\n\n**消息顺序性**\n\n顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的\n\n顺序性打破的情况：\n\n-  生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现\n- 启用 publiser confirm时，发生发生超时、中断，导致错序\n- 生产者设置了延迟队列，但是超时时间设置的不一样\n- 消息设置了优先级，消费端收到的消息必然不是顺序性的\n\n**弃用 QueueingConsumer**\n\n- 队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决\n- QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低\n- 同步调用 QueueingConsumer 会产生死锁\n\n## 消息传输保障\n\n**消息传输保障等级**\n\nAt most once：最多一次。消息可能丢失，但绝不会重复传输\nAt least once：最少一次。消息绝不会丢失，但可能重复传输\nExactly once：恰好一次。每条消息肯定会，有且传输一次\n最少一次：需要考虑 事务、mandatory、持久化处理、autoAck\n最多一次：无须考虑以上问题，随便发送与接收\n恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。\n\n去重一般是通过业务客户端引入GUID实现","source":"_posts/rabbitmq进阶.md","raw":"---\ntitle: rabbitmq进阶\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-03 21:32:53\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 消息传递\n\n**mandatory**\n\n`mandatory=true`，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 `Basic.Return `命令将消息返回给生产者，生产者通过调用 `channel.addReturnListener `添加监听器接收返回结果\n`mandatory=false`，上述情形下，RabbitMQ 将消息直接丢弃\n\n**immediate**\n\n`immediate=true`，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 `Basic.Return` 返回生产者\n**和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息**\n\n**备份交换器（Alternate Exchange）**\n\nAE可以将未被路由的消息存储到 RabbitMQ 中。简化了`mandatory`+`addReturnListener `的编程逻辑。\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"alternate-exchange\",\"myAe\");\n\n// 声明普通交换器（AE交换器作为备份交换器）\nchannel.exchangeDeclare(\"normalExchange\",\"direct\",true,false,args);\n// 声明AE交换器\nchannel.exchangeDeclare(\"myAe\",\"fanout\",true,false,null);\n\n// 普通队列 绑定 普通交换器\nchannel.queueBind(\"normalQueue\",\"normalExchange\",\"normalKey\");\n\n// 声明 未路由队列\nchannel.queueDeclare(\"unroutedQueue\",true,false,false,null);\n// 未路由队列 绑定 AE交换器\nchannel.queueBind(\"unroutedQueue\",\"myAe\",\"\");\n```\n\n特殊情况\n\n- 若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器和mandatory参数一起使用，该参数无效\n\n## 过期时间（TTL）\n\n**通过队列属性设置消息TTL**\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"x-message-ttl\",6000); // 单位毫秒\nchannel.queueDeclare(queueName,durable,exclusive,autoDelete,args);\n```\n\n- 不设置TTL：该消息不会过期\n- TTL为0：若直接可以投递到消费者，否则立刻被丢弃\n\n消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。\n\n**设置每条消息TTL**\n\n在 `channel.basicPublish` 方法中加入 expiration 参数，单位毫秒\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.deliveryMode(2);\nbuilder.expiration(\"60000\");\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(exchangeName,routingKey,mandatory,properties,\"ttlTestMessage\".getBytes());\n```\n\n消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。\n\n**设置队列的TTL**\n\n通过 `channel.queueDeclare` 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间\n\nRabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置\n\n## 死信队列\n\n当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列\n\n死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度\n\n绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX\n\n## 延迟队列\n\n消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费\n\n**场景：**\n\n订单超时支付，延时队列做异常处理；\n\n智能设备在指定时间进行工作，延时队列做指令推送；\n\n**用法：**\n\n- 每条消息设置为10秒过期时间\n- 通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中\n- 消费者订阅 queue.dlx 队列\n- 10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息\n\n## 优先级队列\n\n具有高优先级的队列有高的优先权，优先级高的消息优先被消费\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.priority(5);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(\"exchange_priority\",\"rk_priority\",properties,(\"message\").getBytes());\n```\n\n- 默认优先级为0，最高为队列设置的最大优先级\n- 如果Broker中有消息堆积，优先级高的消息可以被优先消费\n\n## RPC实现\n\n远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。\n\nRPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。\n\n```java\nString callbackQueueName = channel.queueDeclare().getQueue();\nBasicProperties props = new BasicProperties.Builder().replyTo(callbackQueueName).build();\nchannel.basicPublish(\"\",\"rpc_queue\",props,message.getBytes());\n```\n\nRPC 处理流程：\n\n- 客户端启动时，创建一个匿名的回调队列\n- 客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求\n- 请求被发送到 rpc_queue 队列中\n- RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列''; \n- 客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果\n\n## 持久化\n\n持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失\n\n持久化的各种情况\n\nRabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化\n\n- 若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。\n- 若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失\n- 若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡\n- 生产环境会设置镜像队列保证系统的高可用性\n  \n\n## 生产者确认\n\n默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。\n\n**事务机制**\n\n事务方法：\n\n- channel.txSelect： 用于将当前信道设置成事务模式\n- channel.txCommit：用于提交事务\n- channel.txRollback：用于事务回滚\n\n事务流程：\n\n- 客户端发送 Tx.Select，将信道置为事务模式\n- Broker回复 Tx.Select-Ok，确认已将信道置为事务模式\n- Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务\n- Broker 回复 Tx.Commit，确认事务提交\n\n事务问题：事务机制会耗尽 RabbitMQ 的性能\n\n**发送方确认机制**\n\n1. 生产者将信道设置成 confirm 模式\n2. 信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID\n3. 消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者\n\n发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。\n\n发送方确认机制的优势在于不一定需要同步确认：\n\n- 批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回\n- 异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。\n\n注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。\n\n## 消费端要点\n\n**消息分发**\n\n- 当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者\n- 但是这样会造成因为各机器性能不同而引起负载不均\n- 消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量\n- 一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果\n- Basic.Qos的使用对于拉模式消费方式无效\n\n**消息顺序性**\n\n顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的\n\n顺序性打破的情况：\n\n-  生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现\n- 启用 publiser confirm时，发生发生超时、中断，导致错序\n- 生产者设置了延迟队列，但是超时时间设置的不一样\n- 消息设置了优先级，消费端收到的消息必然不是顺序性的\n\n**弃用 QueueingConsumer**\n\n- 队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决\n- QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低\n- 同步调用 QueueingConsumer 会产生死锁\n\n## 消息传输保障\n\n**消息传输保障等级**\n\nAt most once：最多一次。消息可能丢失，但绝不会重复传输\nAt least once：最少一次。消息绝不会丢失，但可能重复传输\nExactly once：恰好一次。每条消息肯定会，有且传输一次\n最少一次：需要考虑 事务、mandatory、持久化处理、autoAck\n最多一次：无须考虑以上问题，随便发送与接收\n恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。\n\n去重一般是通过业务客户端引入GUID实现","slug":"rabbitmq进阶","published":1,"updated":"2021-04-04T05:02:06.522Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss70z0039q4uf7cza5zfy","content":"<h2 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h2><p><strong>mandatory</strong></p>\n<p><code>mandatory=true</code>，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 <code>Basic.Return</code>命令将消息返回给生产者，生产者通过调用 <code>channel.addReturnListener</code>添加监听器接收返回结果<br><code>mandatory=false</code>，上述情形下，RabbitMQ 将消息直接丢弃</p>\n<p><strong>immediate</strong></p>\n<p><code>immediate=true</code>，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 <code>Basic.Return</code> 返回生产者<br><strong>和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息</strong></p>\n<p><strong>备份交换器（Alternate Exchange）</strong></p>\n<p>AE可以将未被路由的消息存储到 RabbitMQ 中。简化了<code>mandatory</code>+<code>addReturnListener</code>的编程逻辑。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span> args <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nargs<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"alternate-exchange\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"myAe\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">// 声明普通交换器（AE交换器作为备份交换器）</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">exchangeDeclare</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"normalExchange\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"direct\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>args<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 声明AE交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">exchangeDeclare</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"myAe\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"fanout\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">// 普通队列 绑定 普通交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueBind</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"normalQueue\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"normalExchange\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"normalKey\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">// 声明 未路由队列</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"unroutedQueue\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 未路由队列 绑定 AE交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueBind</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"unroutedQueue\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"myAe\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>特殊情况</p>\n<ul>\n<li>若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器和mandatory参数一起使用，该参数无效</li>\n</ul>\n<h2 id=\"过期时间（TTL）\"><a href=\"#过期时间（TTL）\" class=\"headerlink\" title=\"过期时间（TTL）\"></a>过期时间（TTL）</h2><p><strong>通过队列属性设置消息TTL</strong></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span> args <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nargs<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"x-message-ttl\"</span><span class=\"token punctuation\">,</span><span class=\"token number\">6000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 单位毫秒</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span>queueName<span class=\"token punctuation\">,</span>durable<span class=\"token punctuation\">,</span>exclusive<span class=\"token punctuation\">,</span>autoDelete<span class=\"token punctuation\">,</span>args<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>不设置TTL：该消息不会过期</li>\n<li>TTL为0：若直接可以投递到消费者，否则立刻被丢弃</li>\n</ul>\n<p>消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。</p>\n<p><strong>设置每条消息TTL</strong></p>\n<p>在 <code>channel.basicPublish</code> 方法中加入 expiration 参数，单位毫秒</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder builder <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nbuilder<span class=\"token punctuation\">.</span><span class=\"token function\">deliveryMode</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nbuilder<span class=\"token punctuation\">.</span><span class=\"token function\">expiration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"60000\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nAMQP<span class=\"token punctuation\">.</span>BasicProperties properties <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">,</span>mandatory<span class=\"token punctuation\">,</span>properties<span class=\"token punctuation\">,</span><span class=\"token string\">\"ttlTestMessage\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。</p>\n<p><strong>设置队列的TTL</strong></p>\n<p>通过 <code>channel.queueDeclare</code> 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间</p>\n<p>RabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置</p>\n<h2 id=\"死信队列\"><a href=\"#死信队列\" class=\"headerlink\" title=\"死信队列\"></a>死信队列</h2><p>当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列</p>\n<p>死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度</p>\n<p>绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX</p>\n<h2 id=\"延迟队列\"><a href=\"#延迟队列\" class=\"headerlink\" title=\"延迟队列\"></a>延迟队列</h2><p>消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费</p>\n<p><strong>场景：</strong></p>\n<p>订单超时支付，延时队列做异常处理；</p>\n<p>智能设备在指定时间进行工作，延时队列做指令推送；</p>\n<p><strong>用法：</strong></p>\n<ul>\n<li>每条消息设置为10秒过期时间</li>\n<li>通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中</li>\n<li>消费者订阅 queue.dlx 队列</li>\n<li>10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息</li>\n</ul>\n<h2 id=\"优先级队列\"><a href=\"#优先级队列\" class=\"headerlink\" title=\"优先级队列\"></a>优先级队列</h2><p>具有高优先级的队列有高的优先权，优先级高的消息优先被消费</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder builder <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nbuilder<span class=\"token punctuation\">.</span><span class=\"token function\">priority</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nAMQP<span class=\"token punctuation\">.</span>BasicProperties properties <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"exchange_priority\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"rk_priority\"</span><span class=\"token punctuation\">,</span>properties<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"message\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>默认优先级为0，最高为队列设置的最大优先级</li>\n<li>如果Broker中有消息堆积，优先级高的消息可以被优先消费</li>\n</ul>\n<h2 id=\"RPC实现\"><a href=\"#RPC实现\" class=\"headerlink\" title=\"RPC实现\"></a>RPC实现</h2><p>远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。</p>\n<p>RPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">String callbackQueueName <span class=\"token operator\">=</span> channel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getQueue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nBasicProperties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">BasicProperties<span class=\"token punctuation\">.</span>Builder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">replyTo</span><span class=\"token punctuation\">(</span>callbackQueueName<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"rpc_queue\"</span><span class=\"token punctuation\">,</span>props<span class=\"token punctuation\">,</span>message<span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>RPC 处理流程：</p>\n<ul>\n<li>客户端启动时，创建一个匿名的回调队列</li>\n<li>客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求</li>\n<li>请求被发送到 rpc_queue 队列中</li>\n<li>RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列’’; </li>\n<li>客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果</li>\n</ul>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><p>持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失</p>\n<p>持久化的各种情况</p>\n<p>RabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化</p>\n<ul>\n<li>若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。</li>\n<li>若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失</li>\n<li>若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡</li>\n<li>生产环境会设置镜像队列保证系统的高可用性</li>\n</ul>\n<h2 id=\"生产者确认\"><a href=\"#生产者确认\" class=\"headerlink\" title=\"生产者确认\"></a>生产者确认</h2><p>默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。</p>\n<p><strong>事务机制</strong></p>\n<p>事务方法：</p>\n<ul>\n<li>channel.txSelect： 用于将当前信道设置成事务模式</li>\n<li>channel.txCommit：用于提交事务</li>\n<li>channel.txRollback：用于事务回滚</li>\n</ul>\n<p>事务流程：</p>\n<ul>\n<li>客户端发送 Tx.Select，将信道置为事务模式</li>\n<li>Broker回复 Tx.Select-Ok，确认已将信道置为事务模式</li>\n<li>Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务</li>\n<li>Broker 回复 Tx.Commit，确认事务提交</li>\n</ul>\n<p>事务问题：事务机制会耗尽 RabbitMQ 的性能</p>\n<p><strong>发送方确认机制</strong></p>\n<ol>\n<li>生产者将信道设置成 confirm 模式</li>\n<li>信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID</li>\n<li>消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者</li>\n</ol>\n<p>发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。</p>\n<p>发送方确认机制的优势在于不一定需要同步确认：</p>\n<ul>\n<li>批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回</li>\n<li>异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。</li>\n</ul>\n<p>注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。</p>\n<h2 id=\"消费端要点\"><a href=\"#消费端要点\" class=\"headerlink\" title=\"消费端要点\"></a>消费端要点</h2><p><strong>消息分发</strong></p>\n<ul>\n<li>当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者</li>\n<li>但是这样会造成因为各机器性能不同而引起负载不均</li>\n<li>消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量</li>\n<li>一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果</li>\n<li>Basic.Qos的使用对于拉模式消费方式无效</li>\n</ul>\n<p><strong>消息顺序性</strong></p>\n<p>顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的</p>\n<p>顺序性打破的情况：</p>\n<ul>\n<li>生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现</li>\n<li>启用 publiser confirm时，发生发生超时、中断，导致错序</li>\n<li>生产者设置了延迟队列，但是超时时间设置的不一样</li>\n<li>消息设置了优先级，消费端收到的消息必然不是顺序性的</li>\n</ul>\n<p><strong>弃用 QueueingConsumer</strong></p>\n<ul>\n<li>队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决</li>\n<li>QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低</li>\n<li>同步调用 QueueingConsumer 会产生死锁</li>\n</ul>\n<h2 id=\"消息传输保障\"><a href=\"#消息传输保障\" class=\"headerlink\" title=\"消息传输保障\"></a>消息传输保障</h2><p><strong>消息传输保障等级</strong></p>\n<p>At most once：最多一次。消息可能丢失，但绝不会重复传输<br>At least once：最少一次。消息绝不会丢失，但可能重复传输<br>Exactly once：恰好一次。每条消息肯定会，有且传输一次<br>最少一次：需要考虑 事务、mandatory、持久化处理、autoAck<br>最多一次：无须考虑以上问题，随便发送与接收<br>恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。</p>\n<p>去重一般是通过业务客户端引入GUID实现</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h2><p><strong>mandatory</strong></p>\n<p><code>mandatory=true</code>，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 <code>Basic.Return</code>命令将消息返回给生产者，生产者通过调用 <code>channel.addReturnListener</code>添加监听器接收返回结果<br><code>mandatory=false</code>，上述情形下，RabbitMQ 将消息直接丢弃</p>\n<p><strong>immediate</strong></p>\n<p><code>immediate=true</code>，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 <code>Basic.Return</code> 返回生产者<br><strong>和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息</strong></p>\n<p><strong>备份交换器（Alternate Exchange）</strong></p>\n<p>AE可以将未被路由的消息存储到 RabbitMQ 中。简化了<code>mandatory</code>+<code>addReturnListener</code>的编程逻辑。</p>\n<pre><code class=\"java\">Map&lt;String,Object&gt; args = new HashMap&lt;String,Object&gt;();\nargs.put(&quot;alternate-exchange&quot;,&quot;myAe&quot;);\n\n// 声明普通交换器（AE交换器作为备份交换器）\nchannel.exchangeDeclare(&quot;normalExchange&quot;,&quot;direct&quot;,true,false,args);\n// 声明AE交换器\nchannel.exchangeDeclare(&quot;myAe&quot;,&quot;fanout&quot;,true,false,null);\n\n// 普通队列 绑定 普通交换器\nchannel.queueBind(&quot;normalQueue&quot;,&quot;normalExchange&quot;,&quot;normalKey&quot;);\n\n// 声明 未路由队列\nchannel.queueDeclare(&quot;unroutedQueue&quot;,true,false,false,null);\n// 未路由队列 绑定 AE交换器\nchannel.queueBind(&quot;unroutedQueue&quot;,&quot;myAe&quot;,&quot;&quot;);</code></pre>\n<p>特殊情况</p>\n<ul>\n<li>若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器和mandatory参数一起使用，该参数无效</li>\n</ul>\n<h2 id=\"过期时间（TTL）\"><a href=\"#过期时间（TTL）\" class=\"headerlink\" title=\"过期时间（TTL）\"></a>过期时间（TTL）</h2><p><strong>通过队列属性设置消息TTL</strong></p>\n<pre><code class=\"java\">Map&lt;String,Object&gt; args = new HashMap&lt;String,Object&gt;();\nargs.put(&quot;x-message-ttl&quot;,6000); // 单位毫秒\nchannel.queueDeclare(queueName,durable,exclusive,autoDelete,args);</code></pre>\n<ul>\n<li>不设置TTL：该消息不会过期</li>\n<li>TTL为0：若直接可以投递到消费者，否则立刻被丢弃</li>\n</ul>\n<p>消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。</p>\n<p><strong>设置每条消息TTL</strong></p>\n<p>在 <code>channel.basicPublish</code> 方法中加入 expiration 参数，单位毫秒</p>\n<pre><code class=\"java\">AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.deliveryMode(2);\nbuilder.expiration(&quot;60000&quot;);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(exchangeName,routingKey,mandatory,properties,&quot;ttlTestMessage&quot;.getBytes());</code></pre>\n<p>消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。</p>\n<p><strong>设置队列的TTL</strong></p>\n<p>通过 <code>channel.queueDeclare</code> 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间</p>\n<p>RabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置</p>\n<h2 id=\"死信队列\"><a href=\"#死信队列\" class=\"headerlink\" title=\"死信队列\"></a>死信队列</h2><p>当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列</p>\n<p>死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度</p>\n<p>绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX</p>\n<h2 id=\"延迟队列\"><a href=\"#延迟队列\" class=\"headerlink\" title=\"延迟队列\"></a>延迟队列</h2><p>消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费</p>\n<p><strong>场景：</strong></p>\n<p>订单超时支付，延时队列做异常处理；</p>\n<p>智能设备在指定时间进行工作，延时队列做指令推送；</p>\n<p><strong>用法：</strong></p>\n<ul>\n<li>每条消息设置为10秒过期时间</li>\n<li>通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中</li>\n<li>消费者订阅 queue.dlx 队列</li>\n<li>10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息</li>\n</ul>\n<h2 id=\"优先级队列\"><a href=\"#优先级队列\" class=\"headerlink\" title=\"优先级队列\"></a>优先级队列</h2><p>具有高优先级的队列有高的优先权，优先级高的消息优先被消费</p>\n<pre><code class=\"java\">AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.priority(5);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(&quot;exchange_priority&quot;,&quot;rk_priority&quot;,properties,(&quot;message&quot;).getBytes());</code></pre>\n<ul>\n<li>默认优先级为0，最高为队列设置的最大优先级</li>\n<li>如果Broker中有消息堆积，优先级高的消息可以被优先消费</li>\n</ul>\n<h2 id=\"RPC实现\"><a href=\"#RPC实现\" class=\"headerlink\" title=\"RPC实现\"></a>RPC实现</h2><p>远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。</p>\n<p>RPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。</p>\n<pre><code class=\"java\">String callbackQueueName = channel.queueDeclare().getQueue();\nBasicProperties props = new BasicProperties.Builder().replyTo(callbackQueueName).build();\nchannel.basicPublish(&quot;&quot;,&quot;rpc_queue&quot;,props,message.getBytes());</code></pre>\n<p>RPC 处理流程：</p>\n<ul>\n<li>客户端启动时，创建一个匿名的回调队列</li>\n<li>客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求</li>\n<li>请求被发送到 rpc_queue 队列中</li>\n<li>RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列’’; </li>\n<li>客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果</li>\n</ul>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><p>持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失</p>\n<p>持久化的各种情况</p>\n<p>RabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化</p>\n<ul>\n<li>若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。</li>\n<li>若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失</li>\n<li>若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡</li>\n<li>生产环境会设置镜像队列保证系统的高可用性</li>\n</ul>\n<h2 id=\"生产者确认\"><a href=\"#生产者确认\" class=\"headerlink\" title=\"生产者确认\"></a>生产者确认</h2><p>默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。</p>\n<p><strong>事务机制</strong></p>\n<p>事务方法：</p>\n<ul>\n<li>channel.txSelect： 用于将当前信道设置成事务模式</li>\n<li>channel.txCommit：用于提交事务</li>\n<li>channel.txRollback：用于事务回滚</li>\n</ul>\n<p>事务流程：</p>\n<ul>\n<li>客户端发送 Tx.Select，将信道置为事务模式</li>\n<li>Broker回复 Tx.Select-Ok，确认已将信道置为事务模式</li>\n<li>Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务</li>\n<li>Broker 回复 Tx.Commit，确认事务提交</li>\n</ul>\n<p>事务问题：事务机制会耗尽 RabbitMQ 的性能</p>\n<p><strong>发送方确认机制</strong></p>\n<ol>\n<li>生产者将信道设置成 confirm 模式</li>\n<li>信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID</li>\n<li>消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者</li>\n</ol>\n<p>发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。</p>\n<p>发送方确认机制的优势在于不一定需要同步确认：</p>\n<ul>\n<li>批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回</li>\n<li>异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。</li>\n</ul>\n<p>注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。</p>\n<h2 id=\"消费端要点\"><a href=\"#消费端要点\" class=\"headerlink\" title=\"消费端要点\"></a>消费端要点</h2><p><strong>消息分发</strong></p>\n<ul>\n<li>当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者</li>\n<li>但是这样会造成因为各机器性能不同而引起负载不均</li>\n<li>消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量</li>\n<li>一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果</li>\n<li>Basic.Qos的使用对于拉模式消费方式无效</li>\n</ul>\n<p><strong>消息顺序性</strong></p>\n<p>顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的</p>\n<p>顺序性打破的情况：</p>\n<ul>\n<li>生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现</li>\n<li>启用 publiser confirm时，发生发生超时、中断，导致错序</li>\n<li>生产者设置了延迟队列，但是超时时间设置的不一样</li>\n<li>消息设置了优先级，消费端收到的消息必然不是顺序性的</li>\n</ul>\n<p><strong>弃用 QueueingConsumer</strong></p>\n<ul>\n<li>队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决</li>\n<li>QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低</li>\n<li>同步调用 QueueingConsumer 会产生死锁</li>\n</ul>\n<h2 id=\"消息传输保障\"><a href=\"#消息传输保障\" class=\"headerlink\" title=\"消息传输保障\"></a>消息传输保障</h2><p><strong>消息传输保障等级</strong></p>\n<p>At most once：最多一次。消息可能丢失，但绝不会重复传输<br>At least once：最少一次。消息绝不会丢失，但可能重复传输<br>Exactly once：恰好一次。每条消息肯定会，有且传输一次<br>最少一次：需要考虑 事务、mandatory、持久化处理、autoAck<br>最多一次：无须考虑以上问题，随便发送与接收<br>恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。</p>\n<p>去重一般是通过业务客户端引入GUID实现</p>\n"},{"title":"rabbitmq集群","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:17:41.000Z","password":null,"summary":null,"_content":"\n## 集群概述\n\n------------\n\n### 集群节点类型\n\n- 磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。\n- 内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。\n\n**统计节点**\nrabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。\n\n## 集群设置\n\n**加入集群**\n\n```\n1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n\n```","source":"_posts/rabbitmq集群.md","raw":"---\ntitle: rabbitmq集群\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:17:41\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 集群概述\n\n------------\n\n### 集群节点类型\n\n- 磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。\n- 内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。\n\n**统计节点**\nrabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。\n\n## 集群设置\n\n**加入集群**\n\n```\n1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n\n```","slug":"rabbitmq集群","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss718003cq4ufefotz4iy","content":"<h2 id=\"集群概述\"><a href=\"#集群概述\" class=\"headerlink\" title=\"集群概述\"></a>集群概述</h2><hr>\n<h3 id=\"集群节点类型\"><a href=\"#集群节点类型\" class=\"headerlink\" title=\"集群节点类型\"></a>集群节点类型</h3><ul>\n<li>磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。</li>\n<li>内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。</li>\n</ul>\n<p><strong>统计节点</strong><br>rabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。</p>\n<h2 id=\"集群设置\"><a href=\"#集群设置\" class=\"headerlink\" title=\"集群设置\"></a>集群设置</h2><p><strong>加入集群</strong></p>\n<pre><code>1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n</code></pre>","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"集群概述\"><a href=\"#集群概述\" class=\"headerlink\" title=\"集群概述\"></a>集群概述</h2><hr>\n<h3 id=\"集群节点类型\"><a href=\"#集群节点类型\" class=\"headerlink\" title=\"集群节点类型\"></a>集群节点类型</h3><ul>\n<li>磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。</li>\n<li>内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。</li>\n</ul>\n<p><strong>统计节点</strong><br>rabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。</p>\n<h2 id=\"集群设置\"><a href=\"#集群设置\" class=\"headerlink\" title=\"集群设置\"></a>集群设置</h2><p><strong>加入集群</strong></p>\n<pre><code>1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n</code></pre>"},{"title":"rabbitmq消息重复","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:18:39.000Z","password":null,"summary":null,"_content":"\n## 场景\n\n- 可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。\n- MQ Broker服务与消费端传输消息的过程中出现网络抖动。\n- 消费端故障、异常。\n\n## 解决方案\n\n### 可靠性投递解决\n\n对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：\n（1）全局唯一\n（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽\n有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。\n\n### 消费抖动解决\n业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：\n（1）对于同一个业务场景，全局唯一\n（2）由业务消息发送方生成，业务相关，对MQ透明\n（3）由业务消息消费方负责判重，以保证幂等","source":"_posts/rabbitmq消息重复.md","raw":"---\ntitle: rabbitmq消息重复\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:18:39\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 场景\n\n- 可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。\n- MQ Broker服务与消费端传输消息的过程中出现网络抖动。\n- 消费端故障、异常。\n\n## 解决方案\n\n### 可靠性投递解决\n\n对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：\n（1）全局唯一\n（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽\n有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。\n\n### 消费抖动解决\n业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：\n（1）对于同一个业务场景，全局唯一\n（2）由业务消息发送方生成，业务相关，对MQ透明\n（3）由业务消息消费方负责判重，以保证幂等","slug":"rabbitmq消息重复","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss71h003fq4ufvzdca6wb","content":"<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h2><ul>\n<li>可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。</li>\n<li>MQ Broker服务与消费端传输消息的过程中出现网络抖动。</li>\n<li>消费端故障、异常。</li>\n</ul>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"可靠性投递解决\"><a href=\"#可靠性投递解决\" class=\"headerlink\" title=\"可靠性投递解决\"></a>可靠性投递解决</h3><p>对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：<br>（1）全局唯一<br>（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽<br>有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。</p>\n<h3 id=\"消费抖动解决\"><a href=\"#消费抖动解决\" class=\"headerlink\" title=\"消费抖动解决\"></a>消费抖动解决</h3><p>业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：<br>（1）对于同一个业务场景，全局唯一<br>（2）由业务消息发送方生成，业务相关，对MQ透明<br>（3）由业务消息消费方负责判重，以保证幂等</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h2><ul>\n<li>可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。</li>\n<li>MQ Broker服务与消费端传输消息的过程中出现网络抖动。</li>\n<li>消费端故障、异常。</li>\n</ul>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"可靠性投递解决\"><a href=\"#可靠性投递解决\" class=\"headerlink\" title=\"可靠性投递解决\"></a>可靠性投递解决</h3><p>对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：<br>（1）全局唯一<br>（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽<br>有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。</p>\n<h3 id=\"消费抖动解决\"><a href=\"#消费抖动解决\" class=\"headerlink\" title=\"消费抖动解决\"></a>消费抖动解决</h3><p>业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：<br>（1）对于同一个业务场景，全局唯一<br>（2）由业务消息发送方生成，业务相关，对MQ透明<br>（3）由业务消息消费方负责判重，以保证幂等</p>\n"},{"title":"redis AOF机制","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:07:40.000Z","password":null,"summary":null,"_content":"\n先写内存，在写日志。\n1、命令执行成功才会被记录日志。\n2、避免对当前命令的阻塞。\n\n## 风险\n1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。\n2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续主线程的操作，比如下一次操作请求。\n3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。\n4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。\n\n## 日志写回策略与选择\n- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\n- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\n- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n\n**对比如下**：\n![](aof.jpg)\n\n**选择如下**：\n\n- 高性能，选择 No；\n- 高可靠性，选择 Always；\n- 允许数据丢失，同时性能较好，选择 Everysec。\n\n## 重写机制\n\n后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。\n\n**作用**\n1、避免日志文件过大。\n2、后台线程避免阻塞主线程\n\n**流程**\n一个拷贝，两处日志\n1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程\n2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区\n3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件\n\n","source":"_posts/redis-AOF机制.md","raw":"---\ntitle: redis AOF机制\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:07:40\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n先写内存，在写日志。\n1、命令执行成功才会被记录日志。\n2、避免对当前命令的阻塞。\n\n## 风险\n1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。\n2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续主线程的操作，比如下一次操作请求。\n3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。\n4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。\n\n## 日志写回策略与选择\n- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\n- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\n- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n\n**对比如下**：\n![](aof.jpg)\n\n**选择如下**：\n\n- 高性能，选择 No；\n- 高可靠性，选择 Always；\n- 允许数据丢失，同时性能较好，选择 Everysec。\n\n## 重写机制\n\n后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。\n\n**作用**\n1、避免日志文件过大。\n2、后台线程避免阻塞主线程\n\n**流程**\n一个拷贝，两处日志\n1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程\n2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区\n3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件\n\n","slug":"redis-AOF机制","published":1,"updated":"2021-05-17T11:47:58.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss71r003iq4ufm2ywgqnn","content":"<p>先写内存，在写日志。<br>1、命令执行成功才会被记录日志。<br>2、避免对当前命令的阻塞。</p>\n<h2 id=\"风险\"><a href=\"#风险\" class=\"headerlink\" title=\"风险\"></a>风险</h2><p>1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。<br>2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续主线程的操作，比如下一次操作请求。<br>3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。<br>4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。</p>\n<h2 id=\"日志写回策略与选择\"><a href=\"#日志写回策略与选择\" class=\"headerlink\" title=\"日志写回策略与选择\"></a>日志写回策略与选择</h2><ul>\n<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>\n<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>\n<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>\n</ul>\n<p><strong>对比如下</strong>：<br><img src=\"aof.jpg\" alt></p>\n<p><strong>选择如下</strong>：</p>\n<ul>\n<li>高性能，选择 No；</li>\n<li>高可靠性，选择 Always；</li>\n<li>允许数据丢失，同时性能较好，选择 Everysec。</li>\n</ul>\n<h2 id=\"重写机制\"><a href=\"#重写机制\" class=\"headerlink\" title=\"重写机制\"></a>重写机制</h2><p>后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。</p>\n<p><strong>作用</strong><br>1、避免日志文件过大。<br>2、后台线程避免阻塞主线程</p>\n<p><strong>流程</strong><br>一个拷贝，两处日志<br>1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程<br>2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区<br>3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>先写内存，在写日志。<br>1、命令执行成功才会被记录日志。<br>2、避免对当前命令的阻塞。</p>\n<h2 id=\"风险\"><a href=\"#风险\" class=\"headerlink\" title=\"风险\"></a>风险</h2><p>1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。<br>2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续主线程的操作，比如下一次操作请求。<br>3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。<br>4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。</p>\n<h2 id=\"日志写回策略与选择\"><a href=\"#日志写回策略与选择\" class=\"headerlink\" title=\"日志写回策略与选择\"></a>日志写回策略与选择</h2><ul>\n<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>\n<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>\n<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>\n</ul>\n<p><strong>对比如下</strong>：<br><img src=\"aof.jpg\" alt></p>\n<p><strong>选择如下</strong>：</p>\n<ul>\n<li>高性能，选择 No；</li>\n<li>高可靠性，选择 Always；</li>\n<li>允许数据丢失，同时性能较好，选择 Everysec。</li>\n</ul>\n<h2 id=\"重写机制\"><a href=\"#重写机制\" class=\"headerlink\" title=\"重写机制\"></a>重写机制</h2><p>后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。</p>\n<p><strong>作用</strong><br>1、避免日志文件过大。<br>2、后台线程避免阻塞主线程</p>\n<p><strong>流程</strong><br>一个拷贝，两处日志<br>1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程<br>2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区<br>3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件</p>\n"},{"title":"redis RBD机制","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:09:31.000Z","password":null,"summary":null,"_content":"\nRDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。\n\n## 快照机制\n\n### 引入原因\n\nAOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。\n\n### bgsave命令\n\n- 主进程fork出子进程，共享主线程的所有内存数据。\n- 子进程读取主线程的内存数据，并把它们写入 RDB 文件。\n- 借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。\n- 如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。\n\n![](rdb.jpg)\n\n\n## 增量快照\n做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。\n需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。\n\n\n## 混用 AOF日志和RDB（Redis 4.0）\n\n内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。\n\nAOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n## 备份机制选择\n\n数据不能丢失时，内存快照和 AOF 的混合使用；\n如果允许分钟级别的数据丢失，只使用 RDB；\n如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。","source":"_posts/redis-RDB机制.md","raw":"---\ntitle: redis RBD机制\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:09:31\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\nRDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。\n\n## 快照机制\n\n### 引入原因\n\nAOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。\n\n### bgsave命令\n\n- 主进程fork出子进程，共享主线程的所有内存数据。\n- 子进程读取主线程的内存数据，并把它们写入 RDB 文件。\n- 借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。\n- 如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。\n\n![](rdb.jpg)\n\n\n## 增量快照\n做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。\n需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。\n\n\n## 混用 AOF日志和RDB（Redis 4.0）\n\n内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。\n\nAOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n## 备份机制选择\n\n数据不能丢失时，内存快照和 AOF 的混合使用；\n如果允许分钟级别的数据丢失，只使用 RDB；\n如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。","slug":"redis-RDB机制","published":1,"updated":"2021-05-17T11:47:58.108Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss724003lq4ufhw7z5tft","content":"<p>RDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。</p>\n<h2 id=\"快照机制\"><a href=\"#快照机制\" class=\"headerlink\" title=\"快照机制\"></a>快照机制</h2><h3 id=\"引入原因\"><a href=\"#引入原因\" class=\"headerlink\" title=\"引入原因\"></a>引入原因</h3><p>AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。</p>\n<h3 id=\"bgsave命令\"><a href=\"#bgsave命令\" class=\"headerlink\" title=\"bgsave命令\"></a>bgsave命令</h3><ul>\n<li>主进程fork出子进程，共享主线程的所有内存数据。</li>\n<li>子进程读取主线程的内存数据，并把它们写入 RDB 文件。</li>\n<li>借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。</li>\n<li>如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。</li>\n</ul>\n<p><img src=\"rdb.jpg\" alt></p>\n<h2 id=\"增量快照\"><a href=\"#增量快照\" class=\"headerlink\" title=\"增量快照\"></a>增量快照</h2><p>做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。<br>需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。</p>\n<h2 id=\"混用-AOF日志和RDB（Redis-4-0）\"><a href=\"#混用-AOF日志和RDB（Redis-4-0）\" class=\"headerlink\" title=\"混用 AOF日志和RDB（Redis 4.0）\"></a>混用 AOF日志和RDB（Redis 4.0）</h2><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。</p>\n<p>AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>\n<h2 id=\"备份机制选择\"><a href=\"#备份机制选择\" class=\"headerlink\" title=\"备份机制选择\"></a>备份机制选择</h2><p>数据不能丢失时，内存快照和 AOF 的混合使用；<br>如果允许分钟级别的数据丢失，只使用 RDB；<br>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>RDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。</p>\n<h2 id=\"快照机制\"><a href=\"#快照机制\" class=\"headerlink\" title=\"快照机制\"></a>快照机制</h2><h3 id=\"引入原因\"><a href=\"#引入原因\" class=\"headerlink\" title=\"引入原因\"></a>引入原因</h3><p>AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。</p>\n<h3 id=\"bgsave命令\"><a href=\"#bgsave命令\" class=\"headerlink\" title=\"bgsave命令\"></a>bgsave命令</h3><ul>\n<li>主进程fork出子进程，共享主线程的所有内存数据。</li>\n<li>子进程读取主线程的内存数据，并把它们写入 RDB 文件。</li>\n<li>借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。</li>\n<li>如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。</li>\n</ul>\n<p><img src=\"rdb.jpg\" alt></p>\n<h2 id=\"增量快照\"><a href=\"#增量快照\" class=\"headerlink\" title=\"增量快照\"></a>增量快照</h2><p>做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。<br>需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。</p>\n<h2 id=\"混用-AOF日志和RDB（Redis-4-0）\"><a href=\"#混用-AOF日志和RDB（Redis-4-0）\" class=\"headerlink\" title=\"混用 AOF日志和RDB（Redis 4.0）\"></a>混用 AOF日志和RDB（Redis 4.0）</h2><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。</p>\n<p>AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>\n<h2 id=\"备份机制选择\"><a href=\"#备份机制选择\" class=\"headerlink\" title=\"备份机制选择\"></a>备份机制选择</h2><p>数据不能丢失时，内存快照和 AOF 的混合使用；<br>如果允许分钟级别的数据丢失，只使用 RDB；<br>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</p>\n"},{"title":"redis6.0","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-12-09T05:35:15.000Z","password":null,"summary":null,"_content":"\n## 多线程\n\n### **问题**\n\n单个主线程处理网络请求的速度跟不上底层网络硬件的速度。\n\n### **优化**\n\n多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。\n\n使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。\n\n### **具体流程**\n\n1、服务端和客户端建立 Socket 连接，并分配给IO线程\n\n2、IO 线程读取并解析请求\n\n3、主线程执行请求操作\n\n4、IO 线程回写 Socket 和主线程清空全局队列\n\n相关配置：\n\n```\nio-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数\n```\n\n## 服务端协助的客户端缓存（Tracking）\n\n### **问题**\n\n如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。\n\n### 普通模式\n\n实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。\n\n一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。\n\n> 服务端对于记录的 key 只会报告一次 invalidate 消息\n>\n> 只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息\n\n**设置命令**\n\n```\nCLIENT TRACKING ON|OFF\n```\n\n### 广播模式\n\n服务端会给客户端广播所有 key 的失效情况\n\n如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。\n\n**应用场景**\n\n客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。\n\n**区别**\n\n广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。\n\n## 细粒度的权限控制\n\n1、支持创建不同用户\n\n```\nACL SETUSER normaluser on > abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” \n```\n\n2、支持以用户为粒度设置命令操作的访问权限\n\n![acl_cmd](acl_cmd.jpg)\n\n","source":"_posts/redis6-0.md","raw":"---\ntitle: redis6.0\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-12-09 13:35:15\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 多线程\n\n### **问题**\n\n单个主线程处理网络请求的速度跟不上底层网络硬件的速度。\n\n### **优化**\n\n多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。\n\n使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。\n\n### **具体流程**\n\n1、服务端和客户端建立 Socket 连接，并分配给IO线程\n\n2、IO 线程读取并解析请求\n\n3、主线程执行请求操作\n\n4、IO 线程回写 Socket 和主线程清空全局队列\n\n相关配置：\n\n```\nio-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数\n```\n\n## 服务端协助的客户端缓存（Tracking）\n\n### **问题**\n\n如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。\n\n### 普通模式\n\n实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。\n\n一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。\n\n> 服务端对于记录的 key 只会报告一次 invalidate 消息\n>\n> 只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息\n\n**设置命令**\n\n```\nCLIENT TRACKING ON|OFF\n```\n\n### 广播模式\n\n服务端会给客户端广播所有 key 的失效情况\n\n如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。\n\n**应用场景**\n\n客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。\n\n**区别**\n\n广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。\n\n## 细粒度的权限控制\n\n1、支持创建不同用户\n\n```\nACL SETUSER normaluser on > abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” \n```\n\n2、支持以用户为粒度设置命令操作的访问权限\n\n![acl_cmd](acl_cmd.jpg)\n\n","slug":"redis6-0","published":1,"updated":"2021-05-17T11:47:58.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss72g003qq4ufnlpy3ae8","content":"<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a><strong>问题</strong></h3><p>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p>\n<h3 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a><strong>优化</strong></h3><p>多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。</p>\n<p>使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p>\n<h3 id=\"具体流程\"><a href=\"#具体流程\" class=\"headerlink\" title=\"具体流程\"></a><strong>具体流程</strong></h3><p>1、服务端和客户端建立 Socket 连接，并分配给IO线程</p>\n<p>2、IO 线程读取并解析请求</p>\n<p>3、主线程执行请求操作</p>\n<p>4、IO 线程回写 Socket 和主线程清空全局队列</p>\n<p>相关配置：</p>\n<pre><code>io-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数</code></pre><h2 id=\"服务端协助的客户端缓存（Tracking）\"><a href=\"#服务端协助的客户端缓存（Tracking）\" class=\"headerlink\" title=\"服务端协助的客户端缓存（Tracking）\"></a>服务端协助的客户端缓存（Tracking）</h2><h3 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题\"></a><strong>问题</strong></h3><p>如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。</p>\n<h3 id=\"普通模式\"><a href=\"#普通模式\" class=\"headerlink\" title=\"普通模式\"></a>普通模式</h3><p>实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。</p>\n<p>一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。</p>\n<blockquote>\n<p>服务端对于记录的 key 只会报告一次 invalidate 消息</p>\n<p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息</p>\n</blockquote>\n<p><strong>设置命令</strong></p>\n<pre><code>CLIENT TRACKING ON|OFF</code></pre><h3 id=\"广播模式\"><a href=\"#广播模式\" class=\"headerlink\" title=\"广播模式\"></a>广播模式</h3><p>服务端会给客户端广播所有 key 的失效情况</p>\n<p>如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p>\n<p><strong>应用场景</strong></p>\n<p>客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。</p>\n<p><strong>区别</strong></p>\n<p>广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。</p>\n<h2 id=\"细粒度的权限控制\"><a href=\"#细粒度的权限控制\" class=\"headerlink\" title=\"细粒度的权限控制\"></a>细粒度的权限控制</h2><p>1、支持创建不同用户</p>\n<pre><code>ACL SETUSER normaluser on &gt; abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” </code></pre><p>2、支持以用户为粒度设置命令操作的访问权限</p>\n<p><img src=\"acl_cmd.jpg\" alt=\"acl_cmd\"></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a><strong>问题</strong></h3><p>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p>\n<h3 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a><strong>优化</strong></h3><p>多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。</p>\n<p>使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p>\n<h3 id=\"具体流程\"><a href=\"#具体流程\" class=\"headerlink\" title=\"具体流程\"></a><strong>具体流程</strong></h3><p>1、服务端和客户端建立 Socket 连接，并分配给IO线程</p>\n<p>2、IO 线程读取并解析请求</p>\n<p>3、主线程执行请求操作</p>\n<p>4、IO 线程回写 Socket 和主线程清空全局队列</p>\n<p>相关配置：</p>\n<pre><code>io-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数</code></pre><h2 id=\"服务端协助的客户端缓存（Tracking）\"><a href=\"#服务端协助的客户端缓存（Tracking）\" class=\"headerlink\" title=\"服务端协助的客户端缓存（Tracking）\"></a>服务端协助的客户端缓存（Tracking）</h2><h3 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题\"></a><strong>问题</strong></h3><p>如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。</p>\n<h3 id=\"普通模式\"><a href=\"#普通模式\" class=\"headerlink\" title=\"普通模式\"></a>普通模式</h3><p>实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。</p>\n<p>一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。</p>\n<blockquote>\n<p>服务端对于记录的 key 只会报告一次 invalidate 消息</p>\n<p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息</p>\n</blockquote>\n<p><strong>设置命令</strong></p>\n<pre><code>CLIENT TRACKING ON|OFF</code></pre><h3 id=\"广播模式\"><a href=\"#广播模式\" class=\"headerlink\" title=\"广播模式\"></a>广播模式</h3><p>服务端会给客户端广播所有 key 的失效情况</p>\n<p>如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p>\n<p><strong>应用场景</strong></p>\n<p>客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。</p>\n<p><strong>区别</strong></p>\n<p>广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。</p>\n<h2 id=\"细粒度的权限控制\"><a href=\"#细粒度的权限控制\" class=\"headerlink\" title=\"细粒度的权限控制\"></a>细粒度的权限控制</h2><p>1、支持创建不同用户</p>\n<pre><code>ACL SETUSER normaluser on &gt; abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” </code></pre><p>2、支持以用户为粒度设置命令操作的访问权限</p>\n<p><img src=\"acl_cmd.jpg\" alt=\"acl_cmd\"></p>\n"},{"title":"redis内存碎片","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-11-02T13:35:08.000Z","password":null,"summary":null,"_content":"","source":"_posts/redis内存碎片.md","raw":"---\ntitle: redis内存碎片\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-11-02 21:35:08\npassword:\nsummary:\ntags:\ncategories:\n---\n","slug":"redis内存碎片","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss72o003tq4ufat09i3ci","content":"","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":""},{"title":"redis主从同步","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-25T08:30:01.000Z","password":null,"summary":null,"_content":"\n主从库之间采用读写分离。\n读操作：主库、从库都可以接收；\n写操作：首先到主库执行，然后，主库将写操作同步给从库。\n![读写分离](duxiefenli.jpg)\n\n## CAP\n\nC - Consistent ，一致性\nA - Availability ，可用性\nP - Partition tolerance ，分区容忍性\n\n在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。\n\n一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。\n\n## 同步机制\n\n通过 `replicaof`（Redis 5.0 之前使用 `slaveof`）命令形成主库和从库的关系。\n\n1、主从库间建立连接、协商同步，为全量复制做准备。\n**从库和主库建立起连接，发送 psync 命令**，表示要进行数据同步，**主库确认回复**，FULLRESYNC响应表示第一次复制采用的全量复制。\npsync 命令包含了主库的 runID 和复制进度 offset 两个参数。\n\n2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。\n主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。\n从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。\n\n3、主库会把第二阶段执行过程中新收到的写命令（replication buffer中的修改操作），再发送给从库。\n主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。\n\n![主从第一次同步](zhucongtongbu.jpg)\n\n### 无盘复制\n\n主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。\n所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。\n\n## 主从级联\n\n### 问题\n\n- 从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。\n\n- 传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。\n\n### 解决\n\n通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上\n\n![级联的“主-从-从”模式](master_slave_slave.jpg)\n\n\n\n## 网络闪断\n\n网络闪断后，主从库会采用增量复制的方式继续同步。\n\n### 增量复制机制\n\n- 主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区\n\n- repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。\n- 连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。\n- 库还未读取的操作被主库新写的操作覆盖，需要全量复制\n\n### 应对\n\n- repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了\n\n- 使用切片集群来分担单个主库的请求压力\n\n## 主从数据不一致\n\n根本原因：主从库间的命令复制是异步进行的\n\n直接原因：\n\n- 主从库间的网络可能会有传输延迟\n- 处理其它复杂度高的命令（例如集合操作命令）而阻塞同步\n- 主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致\n\n解决方法\n\n- 尽量保证主从库间的网络连接状况良好\n- 外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接\n\n## 读取数据过期\n\n### 过期策略\n\n定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；\n\n**惰性删除策略**：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。**在 3.2 版本后**，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。\n\n### 过期命令\n\n- EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；\n- **EXPIREAT 和 PEXPIREA**：它们会直接把数据的过期时间设置为具体的一个时间点\n\n当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在**当前时间的基础上加上数据的存活时间**，从库上数据的过期时间就会比主库上延后了\n\n### 解决\n\n- 使用 Redis 3.2 及以上版本和惰性删除策略\n- 在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据\n\n### 同步异常\n\n`protected-mode`：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。\n\n`cluster-node-timeout`:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。\n\n## 其他\n\n`slave-serve-stale-data `: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。\n\n`slave-read-only `：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。\n\n","source":"_posts/redis主从同步.md","raw":"---\ntitle: redis主从同步\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-25 16:30:01\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n主从库之间采用读写分离。\n读操作：主库、从库都可以接收；\n写操作：首先到主库执行，然后，主库将写操作同步给从库。\n![读写分离](duxiefenli.jpg)\n\n## CAP\n\nC - Consistent ，一致性\nA - Availability ，可用性\nP - Partition tolerance ，分区容忍性\n\n在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。\n\n一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。\n\n## 同步机制\n\n通过 `replicaof`（Redis 5.0 之前使用 `slaveof`）命令形成主库和从库的关系。\n\n1、主从库间建立连接、协商同步，为全量复制做准备。\n**从库和主库建立起连接，发送 psync 命令**，表示要进行数据同步，**主库确认回复**，FULLRESYNC响应表示第一次复制采用的全量复制。\npsync 命令包含了主库的 runID 和复制进度 offset 两个参数。\n\n2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。\n主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。\n从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。\n\n3、主库会把第二阶段执行过程中新收到的写命令（replication buffer中的修改操作），再发送给从库。\n主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。\n\n![主从第一次同步](zhucongtongbu.jpg)\n\n### 无盘复制\n\n主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。\n所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。\n\n## 主从级联\n\n### 问题\n\n- 从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。\n\n- 传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。\n\n### 解决\n\n通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上\n\n![级联的“主-从-从”模式](master_slave_slave.jpg)\n\n\n\n## 网络闪断\n\n网络闪断后，主从库会采用增量复制的方式继续同步。\n\n### 增量复制机制\n\n- 主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区\n\n- repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。\n- 连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。\n- 库还未读取的操作被主库新写的操作覆盖，需要全量复制\n\n### 应对\n\n- repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了\n\n- 使用切片集群来分担单个主库的请求压力\n\n## 主从数据不一致\n\n根本原因：主从库间的命令复制是异步进行的\n\n直接原因：\n\n- 主从库间的网络可能会有传输延迟\n- 处理其它复杂度高的命令（例如集合操作命令）而阻塞同步\n- 主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致\n\n解决方法\n\n- 尽量保证主从库间的网络连接状况良好\n- 外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接\n\n## 读取数据过期\n\n### 过期策略\n\n定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；\n\n**惰性删除策略**：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。**在 3.2 版本后**，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。\n\n### 过期命令\n\n- EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；\n- **EXPIREAT 和 PEXPIREA**：它们会直接把数据的过期时间设置为具体的一个时间点\n\n当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在**当前时间的基础上加上数据的存活时间**，从库上数据的过期时间就会比主库上延后了\n\n### 解决\n\n- 使用 Redis 3.2 及以上版本和惰性删除策略\n- 在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据\n\n### 同步异常\n\n`protected-mode`：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。\n\n`cluster-node-timeout`:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。\n\n## 其他\n\n`slave-serve-stale-data `: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。\n\n`slave-read-only `：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。\n\n","slug":"redis主从同步","published":1,"updated":"2021-05-09T13:52:20.230Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss732003vq4uf058ujs3d","content":"<p>主从库之间采用读写分离。<br>读操作：主库、从库都可以接收；<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。<br><img src=\"duxiefenli.jpg\" alt=\"读写分离\"></p>\n<h2 id=\"CAP\"><a href=\"#CAP\" class=\"headerlink\" title=\"CAP\"></a>CAP</h2><p>C - Consistent ，一致性<br>A - Availability ，可用性<br>P - Partition tolerance ，分区容忍性</p>\n<p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。</p>\n<p>一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。</p>\n<h2 id=\"同步机制\"><a href=\"#同步机制\" class=\"headerlink\" title=\"同步机制\"></a>同步机制</h2><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系。</p>\n<p>1、主从库间建立连接、协商同步，为全量复制做准备。<br><strong>从库和主库建立起连接，发送 psync 命令</strong>，表示要进行数据同步，<strong>主库确认回复</strong>，FULLRESYNC响应表示第一次复制采用的全量复制。<br>psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p>\n<p>2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。<br>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。<br>从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。</p>\n<p>3、主库会把第二阶段执行过程中新收到的写命令（replication buffer中的修改操作），再发送给从库。<br>主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p>\n<p><img src=\"zhucongtongbu.jpg\" alt=\"主从第一次同步\"></p>\n<h3 id=\"无盘复制\"><a href=\"#无盘复制\" class=\"headerlink\" title=\"无盘复制\"></a>无盘复制</h3><p>主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。<br>所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。</p>\n<h2 id=\"主从级联\"><a href=\"#主从级联\" class=\"headerlink\" title=\"主从级联\"></a>主从级联</h2><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li><p>从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</p>\n</li>\n<li><p>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。</p>\n</li>\n</ul>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</p>\n<p><img src=\"master_slave_slave.jpg\" alt=\"级联的“主-从-从”模式\"></p>\n<h2 id=\"网络闪断\"><a href=\"#网络闪断\" class=\"headerlink\" title=\"网络闪断\"></a>网络闪断</h2><p>网络闪断后，主从库会采用增量复制的方式继续同步。</p>\n<h3 id=\"增量复制机制\"><a href=\"#增量复制机制\" class=\"headerlink\" title=\"增量复制机制\"></a>增量复制机制</h3><ul>\n<li><p>主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区</p>\n</li>\n<li><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。</p>\n</li>\n<li><p>连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。</p>\n</li>\n<li><p>库还未读取的操作被主库新写的操作覆盖，需要全量复制</p>\n</li>\n</ul>\n<h3 id=\"应对\"><a href=\"#应对\" class=\"headerlink\" title=\"应对\"></a>应对</h3><ul>\n<li><p>repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了</p>\n</li>\n<li><p>使用切片集群来分担单个主库的请求压力</p>\n</li>\n</ul>\n<h2 id=\"主从数据不一致\"><a href=\"#主从数据不一致\" class=\"headerlink\" title=\"主从数据不一致\"></a>主从数据不一致</h2><p>根本原因：主从库间的命令复制是异步进行的</p>\n<p>直接原因：</p>\n<ul>\n<li>主从库间的网络可能会有传输延迟</li>\n<li>处理其它复杂度高的命令（例如集合操作命令）而阻塞同步</li>\n<li>主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致</li>\n</ul>\n<p>解决方法</p>\n<ul>\n<li>尽量保证主从库间的网络连接状况良好</li>\n<li>外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接</li>\n</ul>\n<h2 id=\"读取数据过期\"><a href=\"#读取数据过期\" class=\"headerlink\" title=\"读取数据过期\"></a>读取数据过期</h2><h3 id=\"过期策略\"><a href=\"#过期策略\" class=\"headerlink\" title=\"过期策略\"></a>过期策略</h3><p>定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；</p>\n<p><strong>惰性删除策略</strong>：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。<strong>在 3.2 版本后</strong>，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。</p>\n<h3 id=\"过期命令\"><a href=\"#过期命令\" class=\"headerlink\" title=\"过期命令\"></a>过期命令</h3><ul>\n<li>EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li>\n<li><strong>EXPIREAT 和 PEXPIREA</strong>：它们会直接把数据的过期时间设置为具体的一个时间点</li>\n</ul>\n<p>当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在<strong>当前时间的基础上加上数据的存活时间</strong>，从库上数据的过期时间就会比主库上延后了</p>\n<h3 id=\"解决-1\"><a href=\"#解决-1\" class=\"headerlink\" title=\"解决\"></a>解决</h3><ul>\n<li>使用 Redis 3.2 及以上版本和惰性删除策略</li>\n<li>在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据</li>\n</ul>\n<h3 id=\"同步异常\"><a href=\"#同步异常\" class=\"headerlink\" title=\"同步异常\"></a>同步异常</h3><p><code>protected-mode</code>：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。</p>\n<p><code>cluster-node-timeout</code>:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p><code>slave-serve-stale-data</code>: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。</p>\n<p><code>slave-read-only</code>：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>主从库之间采用读写分离。<br>读操作：主库、从库都可以接收；<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。<br><img src=\"duxiefenli.jpg\" alt=\"读写分离\"></p>\n<h2 id=\"CAP\"><a href=\"#CAP\" class=\"headerlink\" title=\"CAP\"></a>CAP</h2><p>C - Consistent ，一致性<br>A - Availability ，可用性<br>P - Partition tolerance ，分区容忍性</p>\n<p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。</p>\n<p>一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。</p>\n<h2 id=\"同步机制\"><a href=\"#同步机制\" class=\"headerlink\" title=\"同步机制\"></a>同步机制</h2><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系。</p>\n<p>1、主从库间建立连接、协商同步，为全量复制做准备。<br><strong>从库和主库建立起连接，发送 psync 命令</strong>，表示要进行数据同步，<strong>主库确认回复</strong>，FULLRESYNC响应表示第一次复制采用的全量复制。<br>psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p>\n<p>2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。<br>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。<br>从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。</p>\n<p>3、主库会把第二阶段执行过程中新收到的写命令（replication buffer中的修改操作），再发送给从库。<br>主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p>\n<p><img src=\"zhucongtongbu.jpg\" alt=\"主从第一次同步\"></p>\n<h3 id=\"无盘复制\"><a href=\"#无盘复制\" class=\"headerlink\" title=\"无盘复制\"></a>无盘复制</h3><p>主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。<br>所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。</p>\n<h2 id=\"主从级联\"><a href=\"#主从级联\" class=\"headerlink\" title=\"主从级联\"></a>主从级联</h2><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li><p>从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</p>\n</li>\n<li><p>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。</p>\n</li>\n</ul>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</p>\n<p><img src=\"master_slave_slave.jpg\" alt=\"级联的“主-从-从”模式\"></p>\n<h2 id=\"网络闪断\"><a href=\"#网络闪断\" class=\"headerlink\" title=\"网络闪断\"></a>网络闪断</h2><p>网络闪断后，主从库会采用增量复制的方式继续同步。</p>\n<h3 id=\"增量复制机制\"><a href=\"#增量复制机制\" class=\"headerlink\" title=\"增量复制机制\"></a>增量复制机制</h3><ul>\n<li><p>主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区</p>\n</li>\n<li><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。</p>\n</li>\n<li><p>连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。</p>\n</li>\n<li><p>库还未读取的操作被主库新写的操作覆盖，需要全量复制</p>\n</li>\n</ul>\n<h3 id=\"应对\"><a href=\"#应对\" class=\"headerlink\" title=\"应对\"></a>应对</h3><ul>\n<li><p>repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了</p>\n</li>\n<li><p>使用切片集群来分担单个主库的请求压力</p>\n</li>\n</ul>\n<h2 id=\"主从数据不一致\"><a href=\"#主从数据不一致\" class=\"headerlink\" title=\"主从数据不一致\"></a>主从数据不一致</h2><p>根本原因：主从库间的命令复制是异步进行的</p>\n<p>直接原因：</p>\n<ul>\n<li>主从库间的网络可能会有传输延迟</li>\n<li>处理其它复杂度高的命令（例如集合操作命令）而阻塞同步</li>\n<li>主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致</li>\n</ul>\n<p>解决方法</p>\n<ul>\n<li>尽量保证主从库间的网络连接状况良好</li>\n<li>外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接</li>\n</ul>\n<h2 id=\"读取数据过期\"><a href=\"#读取数据过期\" class=\"headerlink\" title=\"读取数据过期\"></a>读取数据过期</h2><h3 id=\"过期策略\"><a href=\"#过期策略\" class=\"headerlink\" title=\"过期策略\"></a>过期策略</h3><p>定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；</p>\n<p><strong>惰性删除策略</strong>：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。<strong>在 3.2 版本后</strong>，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。</p>\n<h3 id=\"过期命令\"><a href=\"#过期命令\" class=\"headerlink\" title=\"过期命令\"></a>过期命令</h3><ul>\n<li>EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li>\n<li><strong>EXPIREAT 和 PEXPIREA</strong>：它们会直接把数据的过期时间设置为具体的一个时间点</li>\n</ul>\n<p>当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在<strong>当前时间的基础上加上数据的存活时间</strong>，从库上数据的过期时间就会比主库上延后了</p>\n<h3 id=\"解决-1\"><a href=\"#解决-1\" class=\"headerlink\" title=\"解决\"></a>解决</h3><ul>\n<li>使用 Redis 3.2 及以上版本和惰性删除策略</li>\n<li>在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据</li>\n</ul>\n<h3 id=\"同步异常\"><a href=\"#同步异常\" class=\"headerlink\" title=\"同步异常\"></a>同步异常</h3><p><code>protected-mode</code>：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。</p>\n<p><code>cluster-node-timeout</code>:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p><code>slave-serve-stale-data</code>: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。</p>\n<p><code>slave-read-only</code>：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。</p>\n"},{"title":"rabbitmq面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-05T12:05:22.000Z","password":null,"summary":null,"_content":"\n## MQ的优缺点\n\n### 优点\n\n- 异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。\n- 解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。\n- 削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。\n\n### 缺点\n\n**系统复杂度提高**：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。\n\n## RabbitMQ选型\n\n可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。\n\n支持集群化、高可用部署、消息高可靠支持，功能较为完善。\n\n缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。\n\nKafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。\n\n## 什么是RabbitMQ\n\nRabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。\n\n## rabbitmq 的使用场景\n\n（1）服务间异步通信\n\n（2）顺序消费\n\n（3）定时任务\n\n（4）请求削峰\n\n## RabbitMQ基本概念\n\n**Producer：生产者**，投递消息的程序\n\n**Consumer：消费者**，接受消息的程序\n\n**Broker：服务节点**，消息队列服务器实体\n\n**Virtual host：**虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型\n\n## RabbitMQ的工作模式\n\n**简单模式**：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。\n\n**工作模式**：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。\n\n**发布/订阅模式**：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。\n\n**路由模式**：根据`路由键`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n**主题模式**：根据`路由键匹配规则`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键匹配规则`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键匹配规则`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n## 消息在什么时候会变成死信?\n\n- 消息拒绝并且没有设置重新入队\n- 消息过期\n- 消息堆积，并且队列达到最大长度，先入队的消息会变成DL\n\n## 如何保证RabbitMQ消息的顺序性？\n\n1、需要保证顺序性的消息使用一个 queue对应一个 consumer。\n\n2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。\n\n## 如何保证消息不丢失？\n\n1. 生产者发送消息至MQ的数据丢失\n\n解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。\n\n2. MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失\n\n解决方式：MQ设置为持久化。将内存数据持久化到磁盘中\n\n3. 消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完\n\n解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。\n\n## 如何保证消息不被重复消费？\n\n1、设置操作的幂等性。\n\n2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。\n\n3、基于数据库的唯一键来保证重复数据不会重复插入多条。\n\n## **消息如何分发？**\n\n若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能\n\n## 消息怎么路由？\n\n消息将拥有一个路由键（routing key），在消息创建时设定。通\n\n过队列路由键，可以把队列绑定到交换器上。\n\n消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；\n\n常用的交换器主要分为一下三种：\n\nfanout：如果交换器收到消息，将会广播到所有绑定的队列上\n\ndirect：如果路由键完全匹配，消息就被投递到相应的队列\n\ntopic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符\n\n## 消息基于什么传输？\n\n由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。\n\n## 什么情况下会出现blackholed问题？\n\nblackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：\n\n向未绑定 queue 的 exchange 发送 message；\n\nexchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。\n\n## 如何防止出现blackholed问题？\n\n如果在执行Basic.Publish时设置`mandatory=true`，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。\n\n## Basic.Reject的用法是什么？\n\n该信令可用于consumer对收到的message进行reject。\n\n若在该信令中设 置`requeue=true`，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。\n\n若设置`requeue=false`，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。\n\n\n## 如何保证消息不被重复消费？\n\n**重复消费场景：**因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。\n\n**解决思路**：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；\n\n比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；\n\n## 如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\n\n**发送方确认模式**\n\n将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。\n\n一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。\n\n如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。\n\n发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。\n\n**接收方确认机制**\n\n消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。\n\n这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；\n\n**特殊情况**\n\n如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）\n如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。\n\n## 如何保证RabbitMQ消息的可靠传输？\n\n丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；\n\n**生产者丢失消息：**RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；\n\ntransaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；\n\nconfirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。\n\n**消息队列丢数据：消息持久化。**开启持久化磁盘的配置。\n\n这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。\n\n队列持久化+消息持久化。\n\n消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；\n\n如果这时处理消息失败，就会丢失该消息；\n\n解决方案：处理消息成功后，手动回复确认消息。\n\n## 为什么不应该对所有的 message 都使用持久化机制？\n\n一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。\n\n其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。\n\n## 如何保证高可用的？RabbitMQ 的集群\n\n普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。\n\n好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。\n\n坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。\n\n## rabbitmq 对集群节点停止顺序有要求吗?\n\nRabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失\n\n## rabbitmq 集群有什么用?\n\n- 高可用: 某个服务器出现问题，整个 RabbitMQ 还可以继续使用;\n- 高容量: 集群可以承载更多的消息量.\n\n## RAM node 和 disk node 的区别？\n\nRAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。\n\n## **rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？**\n\n不是，原因有以下两个：\n\n1. 存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；\n2. 性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。\n\n## **rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？**\n\n如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：\n\n不能创建队列\n\n不能创建交换器\n\n不能创建绑定\n\n不能添加用户\n\n不能更改权限\n\n不能添加和删除集群节点\n\n唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。","source":"_posts/rabbitmq面试.md","raw":"---\ntitle: rabbitmq面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-05 20:05:22\npassword:\nsummary:\ntags:\n- interview\ncategories:\n- interview\n---\n\n## MQ的优缺点\n\n### 优点\n\n- 异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。\n- 解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。\n- 削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。\n\n### 缺点\n\n**系统复杂度提高**：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。\n\n## RabbitMQ选型\n\n可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。\n\n支持集群化、高可用部署、消息高可靠支持，功能较为完善。\n\n缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。\n\nKafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。\n\n## 什么是RabbitMQ\n\nRabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。\n\n## rabbitmq 的使用场景\n\n（1）服务间异步通信\n\n（2）顺序消费\n\n（3）定时任务\n\n（4）请求削峰\n\n## RabbitMQ基本概念\n\n**Producer：生产者**，投递消息的程序\n\n**Consumer：消费者**，接受消息的程序\n\n**Broker：服务节点**，消息队列服务器实体\n\n**Virtual host：**虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型\n\n## RabbitMQ的工作模式\n\n**简单模式**：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。\n\n**工作模式**：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。\n\n**发布/订阅模式**：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。\n\n**路由模式**：根据`路由键`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n**主题模式**：根据`路由键匹配规则`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键匹配规则`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键匹配规则`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n## 消息在什么时候会变成死信?\n\n- 消息拒绝并且没有设置重新入队\n- 消息过期\n- 消息堆积，并且队列达到最大长度，先入队的消息会变成DL\n\n## 如何保证RabbitMQ消息的顺序性？\n\n1、需要保证顺序性的消息使用一个 queue对应一个 consumer。\n\n2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。\n\n## 如何保证消息不丢失？\n\n1. 生产者发送消息至MQ的数据丢失\n\n解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。\n\n2. MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失\n\n解决方式：MQ设置为持久化。将内存数据持久化到磁盘中\n\n3. 消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完\n\n解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。\n\n## 如何保证消息不被重复消费？\n\n1、设置操作的幂等性。\n\n2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。\n\n3、基于数据库的唯一键来保证重复数据不会重复插入多条。\n\n## **消息如何分发？**\n\n若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能\n\n## 消息怎么路由？\n\n消息将拥有一个路由键（routing key），在消息创建时设定。通\n\n过队列路由键，可以把队列绑定到交换器上。\n\n消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；\n\n常用的交换器主要分为一下三种：\n\nfanout：如果交换器收到消息，将会广播到所有绑定的队列上\n\ndirect：如果路由键完全匹配，消息就被投递到相应的队列\n\ntopic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符\n\n## 消息基于什么传输？\n\n由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。\n\n## 什么情况下会出现blackholed问题？\n\nblackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：\n\n向未绑定 queue 的 exchange 发送 message；\n\nexchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。\n\n## 如何防止出现blackholed问题？\n\n如果在执行Basic.Publish时设置`mandatory=true`，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。\n\n## Basic.Reject的用法是什么？\n\n该信令可用于consumer对收到的message进行reject。\n\n若在该信令中设 置`requeue=true`，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。\n\n若设置`requeue=false`，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。\n\n\n## 如何保证消息不被重复消费？\n\n**重复消费场景：**因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。\n\n**解决思路**：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；\n\n比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；\n\n## 如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\n\n**发送方确认模式**\n\n将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。\n\n一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。\n\n如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。\n\n发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。\n\n**接收方确认机制**\n\n消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。\n\n这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；\n\n**特殊情况**\n\n如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）\n如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。\n\n## 如何保证RabbitMQ消息的可靠传输？\n\n丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；\n\n**生产者丢失消息：**RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；\n\ntransaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；\n\nconfirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。\n\n**消息队列丢数据：消息持久化。**开启持久化磁盘的配置。\n\n这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。\n\n队列持久化+消息持久化。\n\n消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；\n\n如果这时处理消息失败，就会丢失该消息；\n\n解决方案：处理消息成功后，手动回复确认消息。\n\n## 为什么不应该对所有的 message 都使用持久化机制？\n\n一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。\n\n其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。\n\n## 如何保证高可用的？RabbitMQ 的集群\n\n普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。\n\n好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。\n\n坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。\n\n## rabbitmq 对集群节点停止顺序有要求吗?\n\nRabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失\n\n## rabbitmq 集群有什么用?\n\n- 高可用: 某个服务器出现问题，整个 RabbitMQ 还可以继续使用;\n- 高容量: 集群可以承载更多的消息量.\n\n## RAM node 和 disk node 的区别？\n\nRAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。\n\n## **rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？**\n\n不是，原因有以下两个：\n\n1. 存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；\n2. 性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。\n\n## **rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？**\n\n如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：\n\n不能创建队列\n\n不能创建交换器\n\n不能创建绑定\n\n不能添加用户\n\n不能更改权限\n\n不能添加和删除集群节点\n\n唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。","slug":"rabbitmq面试","published":1,"updated":"2021-05-18T21:52:44.112Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss7390040q4uf32n48f1q","content":"<h2 id=\"MQ的优缺点\"><a href=\"#MQ的优缺点\" class=\"headerlink\" title=\"MQ的优缺点\"></a>MQ的优缺点</h2><h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><ul>\n<li>异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。</li>\n<li>解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。</li>\n<li>削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。</li>\n</ul>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><p><strong>系统复杂度提高</strong>：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。</p>\n<h2 id=\"RabbitMQ选型\"><a href=\"#RabbitMQ选型\" class=\"headerlink\" title=\"RabbitMQ选型\"></a>RabbitMQ选型</h2><p>可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。</p>\n<p>支持集群化、高可用部署、消息高可靠支持，功能较为完善。</p>\n<p>缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。</p>\n<p>Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。</p>\n<h2 id=\"什么是RabbitMQ\"><a href=\"#什么是RabbitMQ\" class=\"headerlink\" title=\"什么是RabbitMQ\"></a>什么是RabbitMQ</h2><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。</p>\n<h2 id=\"rabbitmq-的使用场景\"><a href=\"#rabbitmq-的使用场景\" class=\"headerlink\" title=\"rabbitmq 的使用场景\"></a>rabbitmq 的使用场景</h2><p>（1）服务间异步通信</p>\n<p>（2）顺序消费</p>\n<p>（3）定时任务</p>\n<p>（4）请求削峰</p>\n<h2 id=\"RabbitMQ基本概念\"><a href=\"#RabbitMQ基本概念\" class=\"headerlink\" title=\"RabbitMQ基本概念\"></a>RabbitMQ基本概念</h2><p><strong>Producer：生产者</strong>，投递消息的程序</p>\n<p><strong>Consumer：消费者</strong>，接受消息的程序</p>\n<p><strong>Broker：服务节点</strong>，消息队列服务器实体</p>\n<p><strong>Virtual host：</strong>虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p>\n<h2 id=\"RabbitMQ的工作模式\"><a href=\"#RabbitMQ的工作模式\" class=\"headerlink\" title=\"RabbitMQ的工作模式\"></a>RabbitMQ的工作模式</h2><p><strong>简单模式</strong>：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。</p>\n<p><strong>工作模式</strong>：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。</p>\n<p><strong>发布/订阅模式</strong>：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。</p>\n<p><strong>路由模式</strong>：根据<code>路由键</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<p><strong>主题模式</strong>：根据<code>路由键匹配规则</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键匹配规则</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键匹配规则</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<h2 id=\"消息在什么时候会变成死信\"><a href=\"#消息在什么时候会变成死信\" class=\"headerlink\" title=\"消息在什么时候会变成死信?\"></a>消息在什么时候会变成死信?</h2><ul>\n<li>消息拒绝并且没有设置重新入队</li>\n<li>消息过期</li>\n<li>消息堆积，并且队列达到最大长度，先入队的消息会变成DL</li>\n</ul>\n<h2 id=\"如何保证RabbitMQ消息的顺序性？\"><a href=\"#如何保证RabbitMQ消息的顺序性？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的顺序性？\"></a>如何保证RabbitMQ消息的顺序性？</h2><p>1、需要保证顺序性的消息使用一个 queue对应一个 consumer。</p>\n<p>2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。</p>\n<h2 id=\"如何保证消息不丢失？\"><a href=\"#如何保证消息不丢失？\" class=\"headerlink\" title=\"如何保证消息不丢失？\"></a>如何保证消息不丢失？</h2><ol>\n<li>生产者发送消息至MQ的数据丢失</li>\n</ol>\n<p>解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。</p>\n<ol start=\"2\">\n<li>MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失</li>\n</ol>\n<p>解决方式：MQ设置为持久化。将内存数据持久化到磁盘中</p>\n<ol start=\"3\">\n<li>消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完</li>\n</ol>\n<p>解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。</p>\n<h2 id=\"如何保证消息不被重复消费？\"><a href=\"#如何保证消息不被重复消费？\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p>1、设置操作的幂等性。</p>\n<p>2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。</p>\n<p>3、基于数据库的唯一键来保证重复数据不会重复插入多条。</p>\n<h2 id=\"消息如何分发？\"><a href=\"#消息如何分发？\" class=\"headerlink\" title=\"消息如何分发？\"></a><strong>消息如何分发？</strong></h2><p>若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能</p>\n<h2 id=\"消息怎么路由？\"><a href=\"#消息怎么路由？\" class=\"headerlink\" title=\"消息怎么路由？\"></a>消息怎么路由？</h2><p>消息将拥有一个路由键（routing key），在消息创建时设定。通</p>\n<p>过队列路由键，可以把队列绑定到交换器上。</p>\n<p>消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；</p>\n<p>常用的交换器主要分为一下三种：</p>\n<p>fanout：如果交换器收到消息，将会广播到所有绑定的队列上</p>\n<p>direct：如果路由键完全匹配，消息就被投递到相应的队列</p>\n<p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p>\n<h2 id=\"消息基于什么传输？\"><a href=\"#消息基于什么传输？\" class=\"headerlink\" title=\"消息基于什么传输？\"></a>消息基于什么传输？</h2><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p>\n<h2 id=\"什么情况下会出现blackholed问题？\"><a href=\"#什么情况下会出现blackholed问题？\" class=\"headerlink\" title=\"什么情况下会出现blackholed问题？\"></a>什么情况下会出现blackholed问题？</h2><p>blackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：</p>\n<p>向未绑定 queue 的 exchange 发送 message；</p>\n<p>exchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。</p>\n<h2 id=\"如何防止出现blackholed问题？\"><a href=\"#如何防止出现blackholed问题？\" class=\"headerlink\" title=\"如何防止出现blackholed问题？\"></a>如何防止出现blackholed问题？</h2><p>如果在执行Basic.Publish时设置<code>mandatory=true</code>，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。</p>\n<h2 id=\"Basic-Reject的用法是什么？\"><a href=\"#Basic-Reject的用法是什么？\" class=\"headerlink\" title=\"Basic.Reject的用法是什么？\"></a>Basic.Reject的用法是什么？</h2><p>该信令可用于consumer对收到的message进行reject。</p>\n<p>若在该信令中设 置<code>requeue=true</code>，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。</p>\n<p>若设置<code>requeue=false</code>，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。</p>\n<h2 id=\"如何保证消息不被重复消费？-1\"><a href=\"#如何保证消息不被重复消费？-1\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p><strong>重复消费场景：</strong>因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。</p>\n<p><strong>解决思路</strong>：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；</p>\n<p>比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；</p>\n<h2 id=\"如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\"><a href=\"#如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\" class=\"headerlink\" title=\"如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\"></a>如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？</h2><p><strong>发送方确认模式</strong></p>\n<p>将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。</p>\n<p>一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。</p>\n<p>如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。</p>\n<p>发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。</p>\n<p><strong>接收方确认机制</strong></p>\n<p>消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。</p>\n<p>这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；</p>\n<p><strong>特殊情况</strong></p>\n<p>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）<br>如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。</p>\n<h2 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h2><p>丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；</p>\n<p><strong>生产者丢失消息：</strong>RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；</p>\n<p>transaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；</p>\n<p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p>\n<p><strong>消息队列丢数据：消息持久化。</strong>开启持久化磁盘的配置。</p>\n<p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p>\n<p>队列持久化+消息持久化。</p>\n<p>消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；</p>\n<p>如果这时处理消息失败，就会丢失该消息；</p>\n<p>解决方案：处理消息成功后，手动回复确认消息。</p>\n<h2 id=\"为什么不应该对所有的-message-都使用持久化机制？\"><a href=\"#为什么不应该对所有的-message-都使用持久化机制？\" class=\"headerlink\" title=\"为什么不应该对所有的 message 都使用持久化机制？\"></a>为什么不应该对所有的 message 都使用持久化机制？</h2><p>一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。</p>\n<p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。</p>\n<h2 id=\"如何保证高可用的？RabbitMQ-的集群\"><a href=\"#如何保证高可用的？RabbitMQ-的集群\" class=\"headerlink\" title=\"如何保证高可用的？RabbitMQ 的集群\"></a>如何保证高可用的？RabbitMQ 的集群</h2><p>普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。</p>\n<p>镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>\n<p>好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。</p>\n<p>坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。</p>\n<h2 id=\"rabbitmq-对集群节点停止顺序有要求吗\"><a href=\"#rabbitmq-对集群节点停止顺序有要求吗\" class=\"headerlink\" title=\"rabbitmq 对集群节点停止顺序有要求吗?\"></a>rabbitmq 对集群节点停止顺序有要求吗?</h2><p>RabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失</p>\n<h2 id=\"rabbitmq-集群有什么用\"><a href=\"#rabbitmq-集群有什么用\" class=\"headerlink\" title=\"rabbitmq 集群有什么用?\"></a>rabbitmq 集群有什么用?</h2><ul>\n<li>高可用: 某个服务器出现问题，整个 RabbitMQ 还可以继续使用;</li>\n<li>高容量: 集群可以承载更多的消息量.</li>\n</ul>\n<h2 id=\"RAM-node-和-disk-node-的区别？\"><a href=\"#RAM-node-和-disk-node-的区别？\" class=\"headerlink\" title=\"RAM node 和 disk node 的区别？\"></a>RAM node 和 disk node 的区别？</h2><p>RAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。</p>\n<h2 id=\"rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\"><a href=\"#rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\" class=\"headerlink\" title=\"rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？\"></a><strong>rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？</strong></h2><p>不是，原因有以下两个：</p>\n<ol>\n<li>存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；</li>\n<li>性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。</li>\n</ol>\n<h2 id=\"rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\"><a href=\"#rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\" class=\"headerlink\" title=\"rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？\"></a><strong>rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？</strong></h2><p>如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：</p>\n<p>不能创建队列</p>\n<p>不能创建交换器</p>\n<p>不能创建绑定</p>\n<p>不能添加用户</p>\n<p>不能更改权限</p>\n<p>不能添加和删除集群节点</p>\n<p>唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"MQ的优缺点\"><a href=\"#MQ的优缺点\" class=\"headerlink\" title=\"MQ的优缺点\"></a>MQ的优缺点</h2><h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><ul>\n<li>异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。</li>\n<li>解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。</li>\n<li>削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。</li>\n</ul>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><p><strong>系统复杂度提高</strong>：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。</p>\n<h2 id=\"RabbitMQ选型\"><a href=\"#RabbitMQ选型\" class=\"headerlink\" title=\"RabbitMQ选型\"></a>RabbitMQ选型</h2><p>可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。</p>\n<p>支持集群化、高可用部署、消息高可靠支持，功能较为完善。</p>\n<p>缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。</p>\n<p>Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。</p>\n<h2 id=\"什么是RabbitMQ\"><a href=\"#什么是RabbitMQ\" class=\"headerlink\" title=\"什么是RabbitMQ\"></a>什么是RabbitMQ</h2><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。</p>\n<h2 id=\"rabbitmq-的使用场景\"><a href=\"#rabbitmq-的使用场景\" class=\"headerlink\" title=\"rabbitmq 的使用场景\"></a>rabbitmq 的使用场景</h2><p>（1）服务间异步通信</p>\n<p>（2）顺序消费</p>\n<p>（3）定时任务</p>\n<p>（4）请求削峰</p>\n<h2 id=\"RabbitMQ基本概念\"><a href=\"#RabbitMQ基本概念\" class=\"headerlink\" title=\"RabbitMQ基本概念\"></a>RabbitMQ基本概念</h2><p><strong>Producer：生产者</strong>，投递消息的程序</p>\n<p><strong>Consumer：消费者</strong>，接受消息的程序</p>\n<p><strong>Broker：服务节点</strong>，消息队列服务器实体</p>\n<p><strong>Virtual host：</strong>虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p>\n<h2 id=\"RabbitMQ的工作模式\"><a href=\"#RabbitMQ的工作模式\" class=\"headerlink\" title=\"RabbitMQ的工作模式\"></a>RabbitMQ的工作模式</h2><p><strong>简单模式</strong>：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。</p>\n<p><strong>工作模式</strong>：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。</p>\n<p><strong>发布/订阅模式</strong>：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。</p>\n<p><strong>路由模式</strong>：根据<code>路由键</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<p><strong>主题模式</strong>：根据<code>路由键匹配规则</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键匹配规则</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键匹配规则</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<h2 id=\"消息在什么时候会变成死信\"><a href=\"#消息在什么时候会变成死信\" class=\"headerlink\" title=\"消息在什么时候会变成死信?\"></a>消息在什么时候会变成死信?</h2><ul>\n<li>消息拒绝并且没有设置重新入队</li>\n<li>消息过期</li>\n<li>消息堆积，并且队列达到最大长度，先入队的消息会变成DL</li>\n</ul>\n<h2 id=\"如何保证RabbitMQ消息的顺序性？\"><a href=\"#如何保证RabbitMQ消息的顺序性？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的顺序性？\"></a>如何保证RabbitMQ消息的顺序性？</h2><p>1、需要保证顺序性的消息使用一个 queue对应一个 consumer。</p>\n<p>2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。</p>\n<h2 id=\"如何保证消息不丢失？\"><a href=\"#如何保证消息不丢失？\" class=\"headerlink\" title=\"如何保证消息不丢失？\"></a>如何保证消息不丢失？</h2><ol>\n<li>生产者发送消息至MQ的数据丢失</li>\n</ol>\n<p>解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。</p>\n<ol start=\"2\">\n<li>MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失</li>\n</ol>\n<p>解决方式：MQ设置为持久化。将内存数据持久化到磁盘中</p>\n<ol start=\"3\">\n<li>消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完</li>\n</ol>\n<p>解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。</p>\n<h2 id=\"如何保证消息不被重复消费？\"><a href=\"#如何保证消息不被重复消费？\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p>1、设置操作的幂等性。</p>\n<p>2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。</p>\n<p>3、基于数据库的唯一键来保证重复数据不会重复插入多条。</p>\n<h2 id=\"消息如何分发？\"><a href=\"#消息如何分发？\" class=\"headerlink\" title=\"消息如何分发？\"></a><strong>消息如何分发？</strong></h2><p>若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能</p>\n<h2 id=\"消息怎么路由？\"><a href=\"#消息怎么路由？\" class=\"headerlink\" title=\"消息怎么路由？\"></a>消息怎么路由？</h2><p>消息将拥有一个路由键（routing key），在消息创建时设定。通</p>\n<p>过队列路由键，可以把队列绑定到交换器上。</p>\n<p>消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；</p>\n<p>常用的交换器主要分为一下三种：</p>\n<p>fanout：如果交换器收到消息，将会广播到所有绑定的队列上</p>\n<p>direct：如果路由键完全匹配，消息就被投递到相应的队列</p>\n<p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p>\n<h2 id=\"消息基于什么传输？\"><a href=\"#消息基于什么传输？\" class=\"headerlink\" title=\"消息基于什么传输？\"></a>消息基于什么传输？</h2><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p>\n<h2 id=\"什么情况下会出现blackholed问题？\"><a href=\"#什么情况下会出现blackholed问题？\" class=\"headerlink\" title=\"什么情况下会出现blackholed问题？\"></a>什么情况下会出现blackholed问题？</h2><p>blackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：</p>\n<p>向未绑定 queue 的 exchange 发送 message；</p>\n<p>exchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。</p>\n<h2 id=\"如何防止出现blackholed问题？\"><a href=\"#如何防止出现blackholed问题？\" class=\"headerlink\" title=\"如何防止出现blackholed问题？\"></a>如何防止出现blackholed问题？</h2><p>如果在执行Basic.Publish时设置<code>mandatory=true</code>，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。</p>\n<h2 id=\"Basic-Reject的用法是什么？\"><a href=\"#Basic-Reject的用法是什么？\" class=\"headerlink\" title=\"Basic.Reject的用法是什么？\"></a>Basic.Reject的用法是什么？</h2><p>该信令可用于consumer对收到的message进行reject。</p>\n<p>若在该信令中设 置<code>requeue=true</code>，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。</p>\n<p>若设置<code>requeue=false</code>，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。</p>\n<h2 id=\"如何保证消息不被重复消费？-1\"><a href=\"#如何保证消息不被重复消费？-1\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p><strong>重复消费场景：</strong>因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。</p>\n<p><strong>解决思路</strong>：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；</p>\n<p>比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；</p>\n<h2 id=\"如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\"><a href=\"#如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\" class=\"headerlink\" title=\"如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\"></a>如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？</h2><p><strong>发送方确认模式</strong></p>\n<p>将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。</p>\n<p>一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。</p>\n<p>如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。</p>\n<p>发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。</p>\n<p><strong>接收方确认机制</strong></p>\n<p>消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。</p>\n<p>这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；</p>\n<p><strong>特殊情况</strong></p>\n<p>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）<br>如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。</p>\n<h2 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h2><p>丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；</p>\n<p><strong>生产者丢失消息：</strong>RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；</p>\n<p>transaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；</p>\n<p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p>\n<p><strong>消息队列丢数据：消息持久化。</strong>开启持久化磁盘的配置。</p>\n<p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p>\n<p>队列持久化+消息持久化。</p>\n<p>消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；</p>\n<p>如果这时处理消息失败，就会丢失该消息；</p>\n<p>解决方案：处理消息成功后，手动回复确认消息。</p>\n<h2 id=\"为什么不应该对所有的-message-都使用持久化机制？\"><a href=\"#为什么不应该对所有的-message-都使用持久化机制？\" class=\"headerlink\" title=\"为什么不应该对所有的 message 都使用持久化机制？\"></a>为什么不应该对所有的 message 都使用持久化机制？</h2><p>一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。</p>\n<p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。</p>\n<h2 id=\"如何保证高可用的？RabbitMQ-的集群\"><a href=\"#如何保证高可用的？RabbitMQ-的集群\" class=\"headerlink\" title=\"如何保证高可用的？RabbitMQ 的集群\"></a>如何保证高可用的？RabbitMQ 的集群</h2><p>普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。</p>\n<p>镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>\n<p>好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。</p>\n<p>坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。</p>\n<h2 id=\"rabbitmq-对集群节点停止顺序有要求吗\"><a href=\"#rabbitmq-对集群节点停止顺序有要求吗\" class=\"headerlink\" title=\"rabbitmq 对集群节点停止顺序有要求吗?\"></a>rabbitmq 对集群节点停止顺序有要求吗?</h2><p>RabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失</p>\n<h2 id=\"rabbitmq-集群有什么用\"><a href=\"#rabbitmq-集群有什么用\" class=\"headerlink\" title=\"rabbitmq 集群有什么用?\"></a>rabbitmq 集群有什么用?</h2><ul>\n<li>高可用: 某个服务器出现问题，整个 RabbitMQ 还可以继续使用;</li>\n<li>高容量: 集群可以承载更多的消息量.</li>\n</ul>\n<h2 id=\"RAM-node-和-disk-node-的区别？\"><a href=\"#RAM-node-和-disk-node-的区别？\" class=\"headerlink\" title=\"RAM node 和 disk node 的区别？\"></a>RAM node 和 disk node 的区别？</h2><p>RAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。</p>\n<h2 id=\"rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\"><a href=\"#rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\" class=\"headerlink\" title=\"rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？\"></a><strong>rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？</strong></h2><p>不是，原因有以下两个：</p>\n<ol>\n<li>存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；</li>\n<li>性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。</li>\n</ol>\n<h2 id=\"rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\"><a href=\"#rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\" class=\"headerlink\" title=\"rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？\"></a><strong>rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？</strong></h2><p>如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：</p>\n<p>不能创建队列</p>\n<p>不能创建交换器</p>\n<p>不能创建绑定</p>\n<p>不能添加用户</p>\n<p>不能更改权限</p>\n<p>不能添加和删除集群节点</p>\n<p>唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。</p>\n"},{"title":"rabbitmq消息可靠性","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:19:29.000Z","password":null,"summary":null,"_content":"\n## 消息丢失场景\n\n\n### 消息从生产者写入到消息队列的过程\n\n**问题原因**：\n网络抖动\n\n**解决办法**：\n\n- 事务\n在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。\n缺点：同步操作。生产者吞吐量大大降低。\n\n- 发布者确认\n一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。\n\n\n- 其他\n1. 使用mandatory 设置true：不可路由消息回发到生产者\n2. 利用备份交换机（alternate-exchange）：处理无法路由到队列的消息\n\n### 消息在消息队列中的存储场景\n\n**问题原因**：\n\n- 持久化了Message，没有持久化队列\n- 唯一的磁盘节点宕机\n\n**解决办法**：\n1、消息持久化+队列持久化\n消息设置delivery-mode为2，队列设置为durable\n\n2、使用HA队列\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n3、集群设置>=1的磁盘节点。\n磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。\n\n\n### 消息被消费者消费的过程\n\n**问题原因**：错误代码\n**解决办法**：\n1、使用消费者手动确认消费\n2、消费者程序使用事务提交和回滚批量操作。","source":"_posts/rabbitmq消息可靠性.md","raw":"---\ntitle: rabbitmq消息可靠性\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:19:29\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 消息丢失场景\n\n\n### 消息从生产者写入到消息队列的过程\n\n**问题原因**：\n网络抖动\n\n**解决办法**：\n\n- 事务\n在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。\n缺点：同步操作。生产者吞吐量大大降低。\n\n- 发布者确认\n一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。\n\n\n- 其他\n1. 使用mandatory 设置true：不可路由消息回发到生产者\n2. 利用备份交换机（alternate-exchange）：处理无法路由到队列的消息\n\n### 消息在消息队列中的存储场景\n\n**问题原因**：\n\n- 持久化了Message，没有持久化队列\n- 唯一的磁盘节点宕机\n\n**解决办法**：\n1、消息持久化+队列持久化\n消息设置delivery-mode为2，队列设置为durable\n\n2、使用HA队列\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n3、集群设置>=1的磁盘节点。\n磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。\n\n\n### 消息被消费者消费的过程\n\n**问题原因**：错误代码\n**解决办法**：\n1、使用消费者手动确认消费\n2、消费者程序使用事务提交和回滚批量操作。","slug":"rabbitmq消息可靠性","published":1,"updated":"2021-05-11T11:33:29.587Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss73e0042q4uf7erq69ao","content":"<h2 id=\"消息丢失场景\"><a href=\"#消息丢失场景\" class=\"headerlink\" title=\"消息丢失场景\"></a>消息丢失场景</h2><h3 id=\"消息从生产者写入到消息队列的过程\"><a href=\"#消息从生产者写入到消息队列的过程\" class=\"headerlink\" title=\"消息从生产者写入到消息队列的过程\"></a>消息从生产者写入到消息队列的过程</h3><p><strong>问题原因</strong>：<br>网络抖动</p>\n<p><strong>解决办法</strong>：</p>\n<ul>\n<li><p>事务<br>在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。<br>缺点：同步操作。生产者吞吐量大大降低。</p>\n</li>\n<li><p>发布者确认<br>一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。</p>\n</li>\n</ul>\n<ul>\n<li>其他</li>\n</ul>\n<ol>\n<li>使用mandatory 设置true：不可路由消息回发到生产者</li>\n<li>利用备份交换机（alternate-exchange）：处理无法路由到队列的消息</li>\n</ol>\n<h3 id=\"消息在消息队列中的存储场景\"><a href=\"#消息在消息队列中的存储场景\" class=\"headerlink\" title=\"消息在消息队列中的存储场景\"></a>消息在消息队列中的存储场景</h3><p><strong>问题原因</strong>：</p>\n<ul>\n<li>持久化了Message，没有持久化队列</li>\n<li>唯一的磁盘节点宕机</li>\n</ul>\n<p><strong>解决办法</strong>：<br>1、消息持久化+队列持久化<br>消息设置delivery-mode为2，队列设置为durable</p>\n<p>2、使用HA队列<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>3、集群设置&gt;=1的磁盘节点。<br>磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。</p>\n<h3 id=\"消息被消费者消费的过程\"><a href=\"#消息被消费者消费的过程\" class=\"headerlink\" title=\"消息被消费者消费的过程\"></a>消息被消费者消费的过程</h3><p><strong>问题原因</strong>：错误代码<br><strong>解决办法</strong>：<br>1、使用消费者手动确认消费<br>2、消费者程序使用事务提交和回滚批量操作。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"消息丢失场景\"><a href=\"#消息丢失场景\" class=\"headerlink\" title=\"消息丢失场景\"></a>消息丢失场景</h2><h3 id=\"消息从生产者写入到消息队列的过程\"><a href=\"#消息从生产者写入到消息队列的过程\" class=\"headerlink\" title=\"消息从生产者写入到消息队列的过程\"></a>消息从生产者写入到消息队列的过程</h3><p><strong>问题原因</strong>：<br>网络抖动</p>\n<p><strong>解决办法</strong>：</p>\n<ul>\n<li><p>事务<br>在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。<br>缺点：同步操作。生产者吞吐量大大降低。</p>\n</li>\n<li><p>发布者确认<br>一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。</p>\n</li>\n</ul>\n<ul>\n<li>其他</li>\n</ul>\n<ol>\n<li>使用mandatory 设置true：不可路由消息回发到生产者</li>\n<li>利用备份交换机（alternate-exchange）：处理无法路由到队列的消息</li>\n</ol>\n<h3 id=\"消息在消息队列中的存储场景\"><a href=\"#消息在消息队列中的存储场景\" class=\"headerlink\" title=\"消息在消息队列中的存储场景\"></a>消息在消息队列中的存储场景</h3><p><strong>问题原因</strong>：</p>\n<ul>\n<li>持久化了Message，没有持久化队列</li>\n<li>唯一的磁盘节点宕机</li>\n</ul>\n<p><strong>解决办法</strong>：<br>1、消息持久化+队列持久化<br>消息设置delivery-mode为2，队列设置为durable</p>\n<p>2、使用HA队列<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>3、集群设置&gt;=1的磁盘节点。<br>磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。</p>\n<h3 id=\"消息被消费者消费的过程\"><a href=\"#消息被消费者消费的过程\" class=\"headerlink\" title=\"消息被消费者消费的过程\"></a>消息被消费者消费的过程</h3><p><strong>问题原因</strong>：错误代码<br><strong>解决办法</strong>：<br>1、使用消费者手动确认消费<br>2、消费者程序使用事务提交和回滚批量操作。</p>\n"},{"title":"redis事务","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-11-01T05:28:57.000Z","password":null,"summary":null,"_content":"\n## 事务实现\n\n### 基本命令\n\n- MULTI\n\n显式地表示一个事务的开启，把这些命令暂存到一个命令队列中\n\n- EXEC \n\n实际执行命令队列中的所有命令\n\n- DISCARD\n\n主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）\n\n- WATCH\n\n在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。\n\n### 异常分析\n\n1、客户端发送的操作命令中存在语法错误\n\n拒绝执行所有提交的命令操作，返回事务失败\n\n2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误\n\nRedis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）\n\n3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败\n\n- 如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。\n\n使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。\n\n- 如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。","source":"_posts/redis事务.md","raw":"---\ntitle: redis事务\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-11-01 13:28:57\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 事务实现\n\n### 基本命令\n\n- MULTI\n\n显式地表示一个事务的开启，把这些命令暂存到一个命令队列中\n\n- EXEC \n\n实际执行命令队列中的所有命令\n\n- DISCARD\n\n主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）\n\n- WATCH\n\n在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。\n\n### 异常分析\n\n1、客户端发送的操作命令中存在语法错误\n\n拒绝执行所有提交的命令操作，返回事务失败\n\n2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误\n\nRedis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）\n\n3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败\n\n- 如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。\n\n使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。\n\n- 如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。","slug":"redis事务","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss73i0047q4ufjhvl11yc","content":"<h2 id=\"事务实现\"><a href=\"#事务实现\" class=\"headerlink\" title=\"事务实现\"></a>事务实现</h2><h3 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h3><ul>\n<li>MULTI</li>\n</ul>\n<p>显式地表示一个事务的开启，把这些命令暂存到一个命令队列中</p>\n<ul>\n<li>EXEC </li>\n</ul>\n<p>实际执行命令队列中的所有命令</p>\n<ul>\n<li>DISCARD</li>\n</ul>\n<p>主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）</p>\n<ul>\n<li>WATCH</li>\n</ul>\n<p>在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。</p>\n<h3 id=\"异常分析\"><a href=\"#异常分析\" class=\"headerlink\" title=\"异常分析\"></a>异常分析</h3><p>1、客户端发送的操作命令中存在语法错误</p>\n<p>拒绝执行所有提交的命令操作，返回事务失败</p>\n<p>2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误</p>\n<p>Redis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）</p>\n<p>3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败</p>\n<ul>\n<li>如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。</li>\n</ul>\n<p>使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。</p>\n<ul>\n<li>如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"事务实现\"><a href=\"#事务实现\" class=\"headerlink\" title=\"事务实现\"></a>事务实现</h2><h3 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h3><ul>\n<li>MULTI</li>\n</ul>\n<p>显式地表示一个事务的开启，把这些命令暂存到一个命令队列中</p>\n<ul>\n<li>EXEC </li>\n</ul>\n<p>实际执行命令队列中的所有命令</p>\n<ul>\n<li>DISCARD</li>\n</ul>\n<p>主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）</p>\n<ul>\n<li>WATCH</li>\n</ul>\n<p>在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。</p>\n<h3 id=\"异常分析\"><a href=\"#异常分析\" class=\"headerlink\" title=\"异常分析\"></a>异常分析</h3><p>1、客户端发送的操作命令中存在语法错误</p>\n<p>拒绝执行所有提交的命令操作，返回事务失败</p>\n<p>2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误</p>\n<p>Redis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）</p>\n<p>3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败</p>\n<ul>\n<li>如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。</li>\n</ul>\n<p>使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。</p>\n<ul>\n<li>如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。</li>\n</ul>\n"},{"title":"redis分布式锁","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-29T15:52:36.000Z","password":null,"summary":null,"_content":"\n为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。\n\n## 原子操作\n\n- 单命令操作（INCR/DECR）；\n- 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本\n\n## 分布式锁\n\n- 分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；\n\n- 共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。\n\n### 单个 Redis 节点的分布式锁\n\n**加锁**\n\n- `SET key value [EX seconds | PX milliseconds]  [NX]`\n\n- key 不存在， key 会被创建。\n\n- Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。\n- 过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。\n\n**解锁**\n\n执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。\n\n**问题**\n\n  - 锁过期的问题\n  - 获取不到锁直接不断尝试获取锁，比较消耗性能\n\n### 多个 Redis 节点的高可靠分布式锁\n\n分布式锁算法 Redlock\n\n- 客户端获取当前时间。\n- 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n- 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功\n\n- 别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。\n\n**缺点**\n\n无法保证加锁的过程一定正确\n\n## 开源框架：Redission\n\n企业级的开源 Redis Client，也提供了分布式锁的支持。\n\n- 所有指令都通过 Lua 脚本执行，Redis 支持 Lua 脚本原子性执行。\n- 设置一个 Key 的默认过期时间为 30s， Watchdog 会在你获取锁之后，每隔 10s 帮你把 Key 的超时时间设为 30s。\n\n**优点**\n\n一直持有锁也不会出现 Key 过期了，其他线程获取到锁的问题；\n\n## Zookeeper 实现\n\n- 使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。\n- 创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。\n- 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。\n- 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。\n\n## 对比\n\n###  Redis 的分布式锁\n\n**缺点**\n\n- 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。\n- 即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。\n- Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。\n\n**优点**\n\n Redis 的性能很高，可以支撑高并发的获取、释放锁操作。\n\n### ZK 分布式锁\n\n**优点**\n\n- ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。\n- 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。\n\n**缺点**\n\n如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。\n\n## 参考\n\nhttps://zhuanlan.zhihu.com/p/73807097","source":"_posts/redis分布式锁.md","raw":"---\ntitle: redis分布式锁\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-29 23:52:36\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。\n\n## 原子操作\n\n- 单命令操作（INCR/DECR）；\n- 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本\n\n## 分布式锁\n\n- 分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；\n\n- 共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。\n\n### 单个 Redis 节点的分布式锁\n\n**加锁**\n\n- `SET key value [EX seconds | PX milliseconds]  [NX]`\n\n- key 不存在， key 会被创建。\n\n- Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。\n- 过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。\n\n**解锁**\n\n执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。\n\n**问题**\n\n  - 锁过期的问题\n  - 获取不到锁直接不断尝试获取锁，比较消耗性能\n\n### 多个 Redis 节点的高可靠分布式锁\n\n分布式锁算法 Redlock\n\n- 客户端获取当前时间。\n- 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n- 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功\n\n- 别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。\n\n**缺点**\n\n无法保证加锁的过程一定正确\n\n## 开源框架：Redission\n\n企业级的开源 Redis Client，也提供了分布式锁的支持。\n\n- 所有指令都通过 Lua 脚本执行，Redis 支持 Lua 脚本原子性执行。\n- 设置一个 Key 的默认过期时间为 30s， Watchdog 会在你获取锁之后，每隔 10s 帮你把 Key 的超时时间设为 30s。\n\n**优点**\n\n一直持有锁也不会出现 Key 过期了，其他线程获取到锁的问题；\n\n## Zookeeper 实现\n\n- 使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。\n- 创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。\n- 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。\n- 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。\n\n## 对比\n\n###  Redis 的分布式锁\n\n**缺点**\n\n- 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。\n- 即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。\n- Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。\n\n**优点**\n\n Redis 的性能很高，可以支撑高并发的获取、释放锁操作。\n\n### ZK 分布式锁\n\n**优点**\n\n- ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。\n- 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。\n\n**缺点**\n\n如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。\n\n## 参考\n\nhttps://zhuanlan.zhihu.com/p/73807097","slug":"redis分布式锁","published":1,"updated":"2021-05-19T11:09:42.123Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss73l004aq4ufdleym3rg","content":"<p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p>\n<h2 id=\"原子操作\"><a href=\"#原子操作\" class=\"headerlink\" title=\"原子操作\"></a>原子操作</h2><ul>\n<li>单命令操作（INCR/DECR）；</li>\n<li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本</li>\n</ul>\n<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><ul>\n<li><p>分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；</p>\n</li>\n<li><p>共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。</p>\n</li>\n</ul>\n<h3 id=\"单个-Redis-节点的分布式锁\"><a href=\"#单个-Redis-节点的分布式锁\" class=\"headerlink\" title=\"单个 Redis 节点的分布式锁\"></a>单个 Redis 节点的分布式锁</h3><p><strong>加锁</strong></p>\n<ul>\n<li><p><code>SET key value [EX seconds | PX milliseconds]  [NX]</code></p>\n</li>\n<li><p>key 不存在， key 会被创建。</p>\n</li>\n<li><p>Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。</p>\n</li>\n<li><p>过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p>\n</li>\n</ul>\n<p><strong>解锁</strong></p>\n<p>执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。</p>\n<p><strong>问题</strong></p>\n<ul>\n<li>锁过期的问题</li>\n<li>获取不到锁直接不断尝试获取锁，比较消耗性能</li>\n</ul>\n<h3 id=\"多个-Redis-节点的高可靠分布式锁\"><a href=\"#多个-Redis-节点的高可靠分布式锁\" class=\"headerlink\" title=\"多个 Redis 节点的高可靠分布式锁\"></a>多个 Redis 节点的高可靠分布式锁</h3><p>分布式锁算法 Redlock</p>\n<ul>\n<li><p>客户端获取当前时间。</p>\n</li>\n<li><p>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p>\n</li>\n<li><p>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</p>\n</li>\n<li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功</p>\n</li>\n<li><p>别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</p>\n</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>无法保证加锁的过程一定正确</p>\n<h2 id=\"开源框架：Redission\"><a href=\"#开源框架：Redission\" class=\"headerlink\" title=\"开源框架：Redission\"></a>开源框架：Redission</h2><p>企业级的开源 Redis Client，也提供了分布式锁的支持。</p>\n<ul>\n<li>所有指令都通过 Lua 脚本执行，Redis 支持 Lua 脚本原子性执行。</li>\n<li>设置一个 Key 的默认过期时间为 30s， Watchdog 会在你获取锁之后，每隔 10s 帮你把 Key 的超时时间设为 30s。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p>一直持有锁也不会出现 Key 过期了，其他线程获取到锁的问题；</p>\n<h2 id=\"Zookeeper-实现\"><a href=\"#Zookeeper-实现\" class=\"headerlink\" title=\"Zookeeper 实现\"></a>Zookeeper 实现</h2><ul>\n<li>使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。</li>\n<li>创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。</li>\n<li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。</li>\n<li>如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。</li>\n</ul>\n<h2 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h2><h3 id=\"Redis-的分布式锁\"><a href=\"#Redis-的分布式锁\" class=\"headerlink\" title=\"Redis 的分布式锁\"></a>Redis 的分布式锁</h3><p><strong>缺点</strong></p>\n<ul>\n<li>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</li>\n<li>即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。</li>\n<li>Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p> Redis 的性能很高，可以支撑高并发的获取、释放锁操作。</p>\n<h3 id=\"ZK-分布式锁\"><a href=\"#ZK-分布式锁\" class=\"headerlink\" title=\"ZK 分布式锁\"></a>ZK 分布式锁</h3><p><strong>优点</strong></p>\n<ul>\n<li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</li>\n<li>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://zhuanlan.zhihu.com/p/73807097\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/73807097</a></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p>\n<h2 id=\"原子操作\"><a href=\"#原子操作\" class=\"headerlink\" title=\"原子操作\"></a>原子操作</h2><ul>\n<li>单命令操作（INCR/DECR）；</li>\n<li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本</li>\n</ul>\n<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><ul>\n<li><p>分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；</p>\n</li>\n<li><p>共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。</p>\n</li>\n</ul>\n<h3 id=\"单个-Redis-节点的分布式锁\"><a href=\"#单个-Redis-节点的分布式锁\" class=\"headerlink\" title=\"单个 Redis 节点的分布式锁\"></a>单个 Redis 节点的分布式锁</h3><p><strong>加锁</strong></p>\n<ul>\n<li><p><code>SET key value [EX seconds | PX milliseconds]  [NX]</code></p>\n</li>\n<li><p>key 不存在， key 会被创建。</p>\n</li>\n<li><p>Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。</p>\n</li>\n<li><p>过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p>\n</li>\n</ul>\n<p><strong>解锁</strong></p>\n<p>执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。</p>\n<p><strong>问题</strong></p>\n<ul>\n<li>锁过期的问题</li>\n<li>获取不到锁直接不断尝试获取锁，比较消耗性能</li>\n</ul>\n<h3 id=\"多个-Redis-节点的高可靠分布式锁\"><a href=\"#多个-Redis-节点的高可靠分布式锁\" class=\"headerlink\" title=\"多个 Redis 节点的高可靠分布式锁\"></a>多个 Redis 节点的高可靠分布式锁</h3><p>分布式锁算法 Redlock</p>\n<ul>\n<li><p>客户端获取当前时间。</p>\n</li>\n<li><p>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p>\n</li>\n<li><p>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</p>\n</li>\n<li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功</p>\n</li>\n<li><p>别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</p>\n</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>无法保证加锁的过程一定正确</p>\n<h2 id=\"开源框架：Redission\"><a href=\"#开源框架：Redission\" class=\"headerlink\" title=\"开源框架：Redission\"></a>开源框架：Redission</h2><p>企业级的开源 Redis Client，也提供了分布式锁的支持。</p>\n<ul>\n<li>所有指令都通过 Lua 脚本执行，Redis 支持 Lua 脚本原子性执行。</li>\n<li>设置一个 Key 的默认过期时间为 30s， Watchdog 会在你获取锁之后，每隔 10s 帮你把 Key 的超时时间设为 30s。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p>一直持有锁也不会出现 Key 过期了，其他线程获取到锁的问题；</p>\n<h2 id=\"Zookeeper-实现\"><a href=\"#Zookeeper-实现\" class=\"headerlink\" title=\"Zookeeper 实现\"></a>Zookeeper 实现</h2><ul>\n<li>使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。</li>\n<li>创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。</li>\n<li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。</li>\n<li>如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。</li>\n</ul>\n<h2 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h2><h3 id=\"Redis-的分布式锁\"><a href=\"#Redis-的分布式锁\" class=\"headerlink\" title=\"Redis 的分布式锁\"></a>Redis 的分布式锁</h3><p><strong>缺点</strong></p>\n<ul>\n<li>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</li>\n<li>即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。</li>\n<li>Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p> Redis 的性能很高，可以支撑高并发的获取、释放锁操作。</p>\n<h3 id=\"ZK-分布式锁\"><a href=\"#ZK-分布式锁\" class=\"headerlink\" title=\"ZK 分布式锁\"></a>ZK 分布式锁</h3><p><strong>优点</strong></p>\n<ul>\n<li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</li>\n<li>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://zhuanlan.zhihu.com/p/73807097\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/73807097</a></p>\n"},{"title":"redis切片集群","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T12:32:35.000Z","password":null,"summary":null,"_content":"\n## 问题\n\n RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。\n\n## 切片集群机制\n\n- 一个切片集群共有 16384 个哈希槽，每个键值对都会根据它的 key，被映射到一个哈希槽中。\n\n  > 映射方法：\n  >\n  > 按照CRC16 算法计算一个 16 bit 的值；\n  >\n  > 再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽\n- Redis 实例把自己的哈希槽信息发给和它相连的其它实例，来完成哈希槽分配信息的扩散。\n- 客户端和集群实例建立连接后，实例把哈希槽的分配信息发给客户端\n\n## 难点\n\n- 集群实例有新增或删除，Redis 需要重新分配哈希槽；\n- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。\n\n## 解决方法\n\n**重定向机制**，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。\n\n注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。","source":"_posts/redis切片集群.md","raw":"---\ntitle: redis切片集群\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 20:32:35\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 问题\n\n RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。\n\n## 切片集群机制\n\n- 一个切片集群共有 16384 个哈希槽，每个键值对都会根据它的 key，被映射到一个哈希槽中。\n\n  > 映射方法：\n  >\n  > 按照CRC16 算法计算一个 16 bit 的值；\n  >\n  > 再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽\n- Redis 实例把自己的哈希槽信息发给和它相连的其它实例，来完成哈希槽分配信息的扩散。\n- 客户端和集群实例建立连接后，实例把哈希槽的分配信息发给客户端\n\n## 难点\n\n- 集群实例有新增或删除，Redis 需要重新分配哈希槽；\n- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。\n\n## 解决方法\n\n**重定向机制**，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。\n\n注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。","slug":"redis切片集群","published":1,"updated":"2021-05-09T13:52:20.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss73q004dq4uf7d4txn4p","content":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p> RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p>\n<h2 id=\"切片集群机制\"><a href=\"#切片集群机制\" class=\"headerlink\" title=\"切片集群机制\"></a>切片集群机制</h2><ul>\n<li><p>一个切片集群共有 16384 个哈希槽，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p>\n<blockquote>\n<p>映射方法：</p>\n<p>按照CRC16 算法计算一个 16 bit 的值；</p>\n<p>再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽</p>\n</blockquote>\n</li>\n<li><p>Redis 实例把自己的哈希槽信息发给和它相连的其它实例，来完成哈希槽分配信息的扩散。</p>\n</li>\n<li><p>客户端和集群实例建立连接后，实例把哈希槽的分配信息发给客户端</p>\n</li>\n</ul>\n<h2 id=\"难点\"><a href=\"#难点\" class=\"headerlink\" title=\"难点\"></a>难点</h2><ul>\n<li>集群实例有新增或删除，Redis 需要重新分配哈希槽；</li>\n<li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li>\n</ul>\n<h2 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h2><p><strong>重定向机制</strong>，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。</p>\n<p>注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p> RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p>\n<h2 id=\"切片集群机制\"><a href=\"#切片集群机制\" class=\"headerlink\" title=\"切片集群机制\"></a>切片集群机制</h2><ul>\n<li><p>一个切片集群共有 16384 个哈希槽，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p>\n<blockquote>\n<p>映射方法：</p>\n<p>按照CRC16 算法计算一个 16 bit 的值；</p>\n<p>再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽</p>\n</blockquote>\n</li>\n<li><p>Redis 实例把自己的哈希槽信息发给和它相连的其它实例，来完成哈希槽分配信息的扩散。</p>\n</li>\n<li><p>客户端和集群实例建立连接后，实例把哈希槽的分配信息发给客户端</p>\n</li>\n</ul>\n<h2 id=\"难点\"><a href=\"#难点\" class=\"headerlink\" title=\"难点\"></a>难点</h2><ul>\n<li>集群实例有新增或删除，Redis 需要重新分配哈希槽；</li>\n<li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li>\n</ul>\n<h2 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h2><p><strong>重定向机制</strong>，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。</p>\n<p>注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。</p>\n"},{"title":"redis思维导图","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-08T00:06:00.000Z","password":null,"summary":"博客中redis相关思维导图。","_content":"\n![思维导图](redis.png)","source":"_posts/redis思维导图.md","raw":"---\ntitle: redis思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-08 08:06:00\npassword:\nsummary: 博客中redis相关思维导图。\ntags:\n- redis\ncategories:\n- redis\n---\n\n![思维导图](redis.png)","slug":"redis思维导图","published":1,"updated":"2021-04-02T13:22:25.489Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss74d004gq4ufwtm3qgp4","content":"<p><img src=\"redis.png\" alt=\"思维导图\"></p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p><img src=\"redis.png\" alt=\"思维导图\"></p>\n"},{"title":"redis应用","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-10T13:22:09.000Z","password":null,"summary":null,"_content":"\n## 分布式锁\n\n实现：`set lock:codehole true ex 5 nx`\n\n注意：不要用于较长任务，可能超时释放\n\n优化：设置value是一个随机值，保证不会被其他线程释放\n\n可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。\n\n## 延时队列\n\n实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。\n\n优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。\n\n## 用户一年的签到统计\n\n使用位图，1天的签到记录只需要占据一个位，一年365位。\n\n## 页面访问量\n\n简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。\n\n优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount\n\n## 数据去重\n\n场景：用户为看过的内容推荐去重；爬虫URL去重；\n\n实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis>4.0）bf.add/bf.exists。\n\n误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。\n\n原理：大型位数组和几个不一样的无偏hash函数。\n\n## 简单限流\n\n场景：限制用户行为在一定时间内的次数\n\n实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，**获取当前剩下行为总数**，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。\n\n缺点：不适合1min操作不超过100万次这种场景。\n\n## 漏斗限流\n\n实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。\n\n非常棒，被拒绝还提供了重试时间。\n\n## 附近的人\n\n实现：使用GeoHash.\n\n原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。\n\n注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。\n\n","source":"_posts/redis应用.md","raw":"---\ntitle: redis应用\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-10 21:22:09\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 分布式锁\n\n实现：`set lock:codehole true ex 5 nx`\n\n注意：不要用于较长任务，可能超时释放\n\n优化：设置value是一个随机值，保证不会被其他线程释放\n\n可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。\n\n## 延时队列\n\n实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。\n\n优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。\n\n## 用户一年的签到统计\n\n使用位图，1天的签到记录只需要占据一个位，一年365位。\n\n## 页面访问量\n\n简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。\n\n优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount\n\n## 数据去重\n\n场景：用户为看过的内容推荐去重；爬虫URL去重；\n\n实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis>4.0）bf.add/bf.exists。\n\n误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。\n\n原理：大型位数组和几个不一样的无偏hash函数。\n\n## 简单限流\n\n场景：限制用户行为在一定时间内的次数\n\n实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，**获取当前剩下行为总数**，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。\n\n缺点：不适合1min操作不超过100万次这种场景。\n\n## 漏斗限流\n\n实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。\n\n非常棒，被拒绝还提供了重试时间。\n\n## 附近的人\n\n实现：使用GeoHash.\n\n原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。\n\n注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。\n\n","slug":"redis应用","published":1,"updated":"2021-04-27T11:52:21.242Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss74r004jq4ufahgdz7hv","content":"<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><p>实现：<code>set lock:codehole true ex 5 nx</code></p>\n<p>注意：不要用于较长任务，可能超时释放</p>\n<p>优化：设置value是一个随机值，保证不会被其他线程释放</p>\n<p>可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。</p>\n<h2 id=\"延时队列\"><a href=\"#延时队列\" class=\"headerlink\" title=\"延时队列\"></a>延时队列</h2><p>实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。</p>\n<p>优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。</p>\n<h2 id=\"用户一年的签到统计\"><a href=\"#用户一年的签到统计\" class=\"headerlink\" title=\"用户一年的签到统计\"></a>用户一年的签到统计</h2><p>使用位图，1天的签到记录只需要占据一个位，一年365位。</p>\n<h2 id=\"页面访问量\"><a href=\"#页面访问量\" class=\"headerlink\" title=\"页面访问量\"></a>页面访问量</h2><p>简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。</p>\n<p>优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount</p>\n<h2 id=\"数据去重\"><a href=\"#数据去重\" class=\"headerlink\" title=\"数据去重\"></a>数据去重</h2><p>场景：用户为看过的内容推荐去重；爬虫URL去重；</p>\n<p>实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis&gt;4.0）bf.add/bf.exists。</p>\n<p>误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。</p>\n<p>原理：大型位数组和几个不一样的无偏hash函数。</p>\n<h2 id=\"简单限流\"><a href=\"#简单限流\" class=\"headerlink\" title=\"简单限流\"></a>简单限流</h2><p>场景：限制用户行为在一定时间内的次数</p>\n<p>实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，<strong>获取当前剩下行为总数</strong>，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。</p>\n<p>缺点：不适合1min操作不超过100万次这种场景。</p>\n<h2 id=\"漏斗限流\"><a href=\"#漏斗限流\" class=\"headerlink\" title=\"漏斗限流\"></a>漏斗限流</h2><p>实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。</p>\n<p>非常棒，被拒绝还提供了重试时间。</p>\n<h2 id=\"附近的人\"><a href=\"#附近的人\" class=\"headerlink\" title=\"附近的人\"></a>附近的人</h2><p>实现：使用GeoHash.</p>\n<p>原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。</p>\n<p>注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><p>实现：<code>set lock:codehole true ex 5 nx</code></p>\n<p>注意：不要用于较长任务，可能超时释放</p>\n<p>优化：设置value是一个随机值，保证不会被其他线程释放</p>\n<p>可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。</p>\n<h2 id=\"延时队列\"><a href=\"#延时队列\" class=\"headerlink\" title=\"延时队列\"></a>延时队列</h2><p>实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。</p>\n<p>优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。</p>\n<h2 id=\"用户一年的签到统计\"><a href=\"#用户一年的签到统计\" class=\"headerlink\" title=\"用户一年的签到统计\"></a>用户一年的签到统计</h2><p>使用位图，1天的签到记录只需要占据一个位，一年365位。</p>\n<h2 id=\"页面访问量\"><a href=\"#页面访问量\" class=\"headerlink\" title=\"页面访问量\"></a>页面访问量</h2><p>简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。</p>\n<p>优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount</p>\n<h2 id=\"数据去重\"><a href=\"#数据去重\" class=\"headerlink\" title=\"数据去重\"></a>数据去重</h2><p>场景：用户为看过的内容推荐去重；爬虫URL去重；</p>\n<p>实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis&gt;4.0）bf.add/bf.exists。</p>\n<p>误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。</p>\n<p>原理：大型位数组和几个不一样的无偏hash函数。</p>\n<h2 id=\"简单限流\"><a href=\"#简单限流\" class=\"headerlink\" title=\"简单限流\"></a>简单限流</h2><p>场景：限制用户行为在一定时间内的次数</p>\n<p>实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，<strong>获取当前剩下行为总数</strong>，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。</p>\n<p>缺点：不适合1min操作不超过100万次这种场景。</p>\n<h2 id=\"漏斗限流\"><a href=\"#漏斗限流\" class=\"headerlink\" title=\"漏斗限流\"></a>漏斗限流</h2><p>实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。</p>\n<p>非常棒，被拒绝还提供了重试时间。</p>\n<h2 id=\"附近的人\"><a href=\"#附近的人\" class=\"headerlink\" title=\"附近的人\"></a>附近的人</h2><p>实现：使用GeoHash.</p>\n<p>原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。</p>\n<p>注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。</p>\n"},{"title":"redis哨兵机制","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-25T13:16:39.000Z","password":null,"summary":null,"_content":"\n## 问题\n\n主库故障的相关问题：\n\n1、确定主库故障\n\n2、选择新的主库\n\n3、新主库信息通知\n\n## 基本功能\n\n### 监控\n\n- 哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。\n\n- 主库或从库对 PING 命令的响应超时了，哨兵会标记为主观下线。\n\n- 需有quorum 个实例判断主库为主观下线，才能判定主库为客观下线\n\n### 选主\n\n- 筛选当前在线从库，且网络连接状况较好；\n\n- 选择从库优先级最高的从库\n\n- 选择从库复制进度最快的\n\n- 选择从库 ID 号小的\n\n### 通知\n\n- 通知从库执行replicaof，与新主库同步\n- 通知客户端，向新主库请求\n\n**通知客户端**的实现方法\n\n1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。\n\n2、客户端需要支持主动去获取最新主从的地址进行访问。\n\n## 基于 pub/sub 机制的哨兵集群\n\n**连接关系的实现**\n\n- 哨兵-哨兵：哨兵订阅主库上的`__sentinel__:hello`，实现哨兵连接信息的发布获取\n- 哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库\n- 哨兵-客户端：客户端订阅哨兵消息\n\n\n**哨兵Leader竞选 （总从切换）**\n\n1、拿到半数以上的赞成票；\n\n2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。","source":"_posts/redis哨兵机制.md","raw":"---\ntitle: redis哨兵机制\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-25 21:16:39\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 问题\n\n主库故障的相关问题：\n\n1、确定主库故障\n\n2、选择新的主库\n\n3、新主库信息通知\n\n## 基本功能\n\n### 监控\n\n- 哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。\n\n- 主库或从库对 PING 命令的响应超时了，哨兵会标记为主观下线。\n\n- 需有quorum 个实例判断主库为主观下线，才能判定主库为客观下线\n\n### 选主\n\n- 筛选当前在线从库，且网络连接状况较好；\n\n- 选择从库优先级最高的从库\n\n- 选择从库复制进度最快的\n\n- 选择从库 ID 号小的\n\n### 通知\n\n- 通知从库执行replicaof，与新主库同步\n- 通知客户端，向新主库请求\n\n**通知客户端**的实现方法\n\n1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。\n\n2、客户端需要支持主动去获取最新主从的地址进行访问。\n\n## 基于 pub/sub 机制的哨兵集群\n\n**连接关系的实现**\n\n- 哨兵-哨兵：哨兵订阅主库上的`__sentinel__:hello`，实现哨兵连接信息的发布获取\n- 哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库\n- 哨兵-客户端：客户端订阅哨兵消息\n\n\n**哨兵Leader竞选 （总从切换）**\n\n1、拿到半数以上的赞成票；\n\n2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。","slug":"redis哨兵机制","published":1,"updated":"2021-05-11T13:59:00.145Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss74z004mq4ufvogr0npv","content":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>主库故障的相关问题：</p>\n<p>1、确定主库故障</p>\n<p>2、选择新的主库</p>\n<p>3、新主库信息通知</p>\n<h2 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h2><h3 id=\"监控\"><a href=\"#监控\" class=\"headerlink\" title=\"监控\"></a>监控</h3><ul>\n<li><p>哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</p>\n</li>\n<li><p>主库或从库对 PING 命令的响应超时了，哨兵会标记为主观下线。</p>\n</li>\n<li><p>需有quorum 个实例判断主库为主观下线，才能判定主库为客观下线</p>\n</li>\n</ul>\n<h3 id=\"选主\"><a href=\"#选主\" class=\"headerlink\" title=\"选主\"></a>选主</h3><ul>\n<li><p>筛选当前在线从库，且网络连接状况较好；</p>\n</li>\n<li><p>选择从库优先级最高的从库</p>\n</li>\n<li><p>选择从库复制进度最快的</p>\n</li>\n<li><p>选择从库 ID 号小的</p>\n</li>\n</ul>\n<h3 id=\"通知\"><a href=\"#通知\" class=\"headerlink\" title=\"通知\"></a>通知</h3><ul>\n<li>通知从库执行replicaof，与新主库同步</li>\n<li>通知客户端，向新主库请求</li>\n</ul>\n<p><strong>通知客户端</strong>的实现方法</p>\n<p>1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。</p>\n<p>2、客户端需要支持主动去获取最新主从的地址进行访问。</p>\n<h2 id=\"基于-pub-sub-机制的哨兵集群\"><a href=\"#基于-pub-sub-机制的哨兵集群\" class=\"headerlink\" title=\"基于 pub/sub 机制的哨兵集群\"></a>基于 pub/sub 机制的哨兵集群</h2><p><strong>连接关系的实现</strong></p>\n<ul>\n<li>哨兵-哨兵：哨兵订阅主库上的<code>__sentinel__:hello</code>，实现哨兵连接信息的发布获取</li>\n<li>哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库</li>\n<li>哨兵-客户端：客户端订阅哨兵消息</li>\n</ul>\n<p><strong>哨兵Leader竞选 （总从切换）</strong></p>\n<p>1、拿到半数以上的赞成票；</p>\n<p>2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>主库故障的相关问题：</p>\n<p>1、确定主库故障</p>\n<p>2、选择新的主库</p>\n<p>3、新主库信息通知</p>\n<h2 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h2><h3 id=\"监控\"><a href=\"#监控\" class=\"headerlink\" title=\"监控\"></a>监控</h3><ul>\n<li><p>哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</p>\n</li>\n<li><p>主库或从库对 PING 命令的响应超时了，哨兵会标记为主观下线。</p>\n</li>\n<li><p>需有quorum 个实例判断主库为主观下线，才能判定主库为客观下线</p>\n</li>\n</ul>\n<h3 id=\"选主\"><a href=\"#选主\" class=\"headerlink\" title=\"选主\"></a>选主</h3><ul>\n<li><p>筛选当前在线从库，且网络连接状况较好；</p>\n</li>\n<li><p>选择从库优先级最高的从库</p>\n</li>\n<li><p>选择从库复制进度最快的</p>\n</li>\n<li><p>选择从库 ID 号小的</p>\n</li>\n</ul>\n<h3 id=\"通知\"><a href=\"#通知\" class=\"headerlink\" title=\"通知\"></a>通知</h3><ul>\n<li>通知从库执行replicaof，与新主库同步</li>\n<li>通知客户端，向新主库请求</li>\n</ul>\n<p><strong>通知客户端</strong>的实现方法</p>\n<p>1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。</p>\n<p>2、客户端需要支持主动去获取最新主从的地址进行访问。</p>\n<h2 id=\"基于-pub-sub-机制的哨兵集群\"><a href=\"#基于-pub-sub-机制的哨兵集群\" class=\"headerlink\" title=\"基于 pub/sub 机制的哨兵集群\"></a>基于 pub/sub 机制的哨兵集群</h2><p><strong>连接关系的实现</strong></p>\n<ul>\n<li>哨兵-哨兵：哨兵订阅主库上的<code>__sentinel__:hello</code>，实现哨兵连接信息的发布获取</li>\n<li>哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库</li>\n<li>哨兵-客户端：客户端订阅哨兵消息</li>\n</ul>\n<p><strong>哨兵Leader竞选 （总从切换）</strong></p>\n<p>1、拿到半数以上的赞成票；</p>\n<p>2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。</p>\n"},{"title":"redis数据结构","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:44:02.000Z","password":null,"summary":null,"_content":"\n\n\n## 基本数据结构\n\n包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）\n\n| 基本数据结构 | 底层实现           |\n| ------------ | ------------------ |\n| string       | 动态字符串         |\n| List         | 双向链表、压缩列表 |\n| Hash         | 哈希表，压缩列表   |\n| Sorted Set   | 跳表，压缩列表     |\n| Set          | 哈希表、数组       |\n\nredis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。\n哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n冲突增多时，Redis 会对哈希表做渐进式 rehash操作。\n\n> rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries\n\n## RedisObject\n\n```c\nstruct RedisObject {\n    int4 type; // 4bits，类型\n    int4 encoding; // 4bits，存储形式\n    int24 lru; // 24bits，LRU 信息\n    int32 refcount; // 4bytes，引用计数\n    void *ptr; // 8bytes，对象内容的具体存储位置\n} robj;\n```\n\n RedisObject 对象头需要占据 16 字节的存储空间。\n\n## 字符串\n\n### 数据结构\n\nRedis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。\n\n```c\nstruct SDS<T> {\n    T capacity; // 数组容量\n    T len; // 数组长度\n    byte flags; // 特殊标识位，不理睬它\n    byte[] content; // 数组内容\n}\n\nstruct SDS {\n    int8 capacity; // 1byte\n    int8 len; // 1byte\n    int8 flags; // 1byte\n    byte[] content; // 内联数组，长度为 capacity\n}\n```\n\n- embstr ：将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。\n- raw ：需要两次 malloc，两个对象头在内存地址上一般是不连续的。\n\n### 扩容策略\n\n- 字符串在长度小于 1M 之前，扩容空间采用加倍策略。\n- 当长度超过 1M 之后，为了避免加倍后导致浪费，多分配 1M 大小的冗余空间。\n\n## 字典\n\n### 应用\n\n- hash 结构的数据\n- 整个 Redis 数据库的所有 key 和 value 组成了一个全局字典。\n- 还有带过期时间的 key 集合也是一个字典。\n- zset 集合中存储 value 和 score 值的映射关系。\n\n### 数据结构\n\n内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。\n\n扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁。\n\n两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。\n\n```c\nstruct dict {\n    ...\n    dictht ht[2];\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}\nstruct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}\n```\n\n### 渐进式rehash\n\n大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，`O(n)`级别的操作。\n\nRedis还会在定时任务中对字典进行主动搬迁。\n\n### 扩容条件\n\n当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。\n\n如果 Redis 正在做 bgsave，为了减少内存页的过多分离 （Copy On Write），Redis 尽量不去扩容 （dict_can_resize）\n\n如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 （dict_force_resize_ratio），说明 hash 表已经过于拥挤了，就会强制扩容。\n\n## 压缩列表\n压缩列表类似于一个数组，数组中的每一个元素都对应保存一个数据。\n\n不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表占用字节数、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。\n\n压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。\n\n```c\nstruct ziplist<T> {\n    int32 zlbytes; // 整个压缩列表占用字节数\n    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点\n    int16 zllength; // 元素个数\n    T[] entries; // 元素内容列表，挨个挨个紧凑存储\n    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF\n}\nstruct entry {\n    int<var> prevlen; // 前一个 entry 的字节长度\n    int<var> encoding; // 元素类型编码\n    optional byte[] content; // 元素内容\n}\n```\n\n## 跳表\n跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。\n\n## 复杂度\n\n各个数据结构的查找时间复杂度\n\n| 数据结构 | 复杂度    |\n| -------- | --------- |\n| 哈希表   | `O(1)`    |\n| 跳表     | `O(logN)` |\n| 双向链表 | `O(N)`    |\n| 压缩列表 | `O(N)`    |\n| 数组     | `O(N)`    |\n\n","source":"_posts/redis数据结构.md","raw":"---\ntitle: redis数据结构\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:44:02\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n\n\n## 基本数据结构\n\n包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）\n\n| 基本数据结构 | 底层实现           |\n| ------------ | ------------------ |\n| string       | 动态字符串         |\n| List         | 双向链表、压缩列表 |\n| Hash         | 哈希表，压缩列表   |\n| Sorted Set   | 跳表，压缩列表     |\n| Set          | 哈希表、数组       |\n\nredis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。\n哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n冲突增多时，Redis 会对哈希表做渐进式 rehash操作。\n\n> rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries\n\n## RedisObject\n\n```c\nstruct RedisObject {\n    int4 type; // 4bits，类型\n    int4 encoding; // 4bits，存储形式\n    int24 lru; // 24bits，LRU 信息\n    int32 refcount; // 4bytes，引用计数\n    void *ptr; // 8bytes，对象内容的具体存储位置\n} robj;\n```\n\n RedisObject 对象头需要占据 16 字节的存储空间。\n\n## 字符串\n\n### 数据结构\n\nRedis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。\n\n```c\nstruct SDS<T> {\n    T capacity; // 数组容量\n    T len; // 数组长度\n    byte flags; // 特殊标识位，不理睬它\n    byte[] content; // 数组内容\n}\n\nstruct SDS {\n    int8 capacity; // 1byte\n    int8 len; // 1byte\n    int8 flags; // 1byte\n    byte[] content; // 内联数组，长度为 capacity\n}\n```\n\n- embstr ：将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。\n- raw ：需要两次 malloc，两个对象头在内存地址上一般是不连续的。\n\n### 扩容策略\n\n- 字符串在长度小于 1M 之前，扩容空间采用加倍策略。\n- 当长度超过 1M 之后，为了避免加倍后导致浪费，多分配 1M 大小的冗余空间。\n\n## 字典\n\n### 应用\n\n- hash 结构的数据\n- 整个 Redis 数据库的所有 key 和 value 组成了一个全局字典。\n- 还有带过期时间的 key 集合也是一个字典。\n- zset 集合中存储 value 和 score 值的映射关系。\n\n### 数据结构\n\n内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。\n\n扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁。\n\n两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。\n\n```c\nstruct dict {\n    ...\n    dictht ht[2];\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}\nstruct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}\n```\n\n### 渐进式rehash\n\n大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，`O(n)`级别的操作。\n\nRedis还会在定时任务中对字典进行主动搬迁。\n\n### 扩容条件\n\n当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。\n\n如果 Redis 正在做 bgsave，为了减少内存页的过多分离 （Copy On Write），Redis 尽量不去扩容 （dict_can_resize）\n\n如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 （dict_force_resize_ratio），说明 hash 表已经过于拥挤了，就会强制扩容。\n\n## 压缩列表\n压缩列表类似于一个数组，数组中的每一个元素都对应保存一个数据。\n\n不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表占用字节数、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。\n\n压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。\n\n```c\nstruct ziplist<T> {\n    int32 zlbytes; // 整个压缩列表占用字节数\n    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点\n    int16 zllength; // 元素个数\n    T[] entries; // 元素内容列表，挨个挨个紧凑存储\n    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF\n}\nstruct entry {\n    int<var> prevlen; // 前一个 entry 的字节长度\n    int<var> encoding; // 元素类型编码\n    optional byte[] content; // 元素内容\n}\n```\n\n## 跳表\n跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。\n\n## 复杂度\n\n各个数据结构的查找时间复杂度\n\n| 数据结构 | 复杂度    |\n| -------- | --------- |\n| 哈希表   | `O(1)`    |\n| 跳表     | `O(logN)` |\n| 双向链表 | `O(N)`    |\n| 压缩列表 | `O(N)`    |\n| 数组     | `O(N)`    |\n\n","slug":"redis数据结构","published":1,"updated":"2021-05-11T11:33:29.606Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss755004pq4ufvqzbbk2s","content":"<h2 id=\"基本数据结构\"><a href=\"#基本数据结构\" class=\"headerlink\" title=\"基本数据结构\"></a>基本数据结构</h2><p>包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）</p>\n<table>\n<thead>\n<tr>\n<th>基本数据结构</th>\n<th>底层实现</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>string</td>\n<td>动态字符串</td>\n</tr>\n<tr>\n<td>List</td>\n<td>双向链表、压缩列表</td>\n</tr>\n<tr>\n<td>Hash</td>\n<td>哈希表，压缩列表</td>\n</tr>\n<tr>\n<td>Sorted Set</td>\n<td>跳表，压缩列表</td>\n</tr>\n<tr>\n<td>Set</td>\n<td>哈希表、数组</td>\n</tr>\n</tbody></table>\n<p>redis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。<br>哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br>冲突增多时，Redis 会对哈希表做渐进式 rehash操作。</p>\n<blockquote>\n<p>rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</p>\n</blockquote>\n<h2 id=\"RedisObject\"><a href=\"#RedisObject\" class=\"headerlink\" title=\"RedisObject\"></a>RedisObject</h2><pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> RedisObject <span class=\"token punctuation\">{</span>\n    int4 type<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 4bits，类型</span>\n    int4 encoding<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 4bits，存储形式</span>\n    int24 lru<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 24bits，LRU 信息</span>\n    int32 refcount<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 4bytes，引用计数</span>\n    <span class=\"token keyword\">void</span> <span class=\"token operator\">*</span>ptr<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 8bytes，对象内容的具体存储位置</span>\n<span class=\"token punctuation\">}</span> robj<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p> RedisObject 对象头需要占据 16 字节的存储空间。</p>\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><p>Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> SDS<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n    T capacity<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 数组容量</span>\n    T len<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 数组长度</span>\n    byte flags<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 特殊标识位，不理睬它</span>\n    byte<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> content<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 数组内容</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">struct</span> SDS <span class=\"token punctuation\">{</span>\n    int8 capacity<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 1byte</span>\n    int8 len<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 1byte</span>\n    int8 flags<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 1byte</span>\n    byte<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> content<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 内联数组，长度为 capacity</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>embstr ：将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。</li>\n<li>raw ：需要两次 malloc，两个对象头在内存地址上一般是不连续的。</li>\n</ul>\n<h3 id=\"扩容策略\"><a href=\"#扩容策略\" class=\"headerlink\" title=\"扩容策略\"></a>扩容策略</h3><ul>\n<li>字符串在长度小于 1M 之前，扩容空间采用加倍策略。</li>\n<li>当长度超过 1M 之后，为了避免加倍后导致浪费，多分配 1M 大小的冗余空间。</li>\n</ul>\n<h2 id=\"字典\"><a href=\"#字典\" class=\"headerlink\" title=\"字典\"></a>字典</h2><h3 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h3><ul>\n<li>hash 结构的数据</li>\n<li>整个 Redis 数据库的所有 key 和 value 组成了一个全局字典。</li>\n<li>还有带过期时间的 key 集合也是一个字典。</li>\n<li>zset 集合中存储 value 和 score 值的映射关系。</li>\n</ul>\n<h3 id=\"数据结构-1\"><a href=\"#数据结构-1\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><p>内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。</p>\n<p>扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁。</p>\n<p>两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> dict <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n    dictht ht<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">struct</span> dictht <span class=\"token punctuation\">{</span>\n    dictEntry<span class=\"token operator\">*</span><span class=\"token operator\">*</span> table<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 二维</span>\n    <span class=\"token keyword\">long</span> size<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 第一维数组的长度</span>\n    <span class=\"token keyword\">long</span> used<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// hash 表中的元素个数</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">struct</span> dictEntry <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">void</span><span class=\"token operator\">*</span> key<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">void</span><span class=\"token operator\">*</span> val<span class=\"token punctuation\">;</span>\n    dictEntry<span class=\"token operator\">*</span> next<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 链接下一个 entry</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"渐进式rehash\"><a href=\"#渐进式rehash\" class=\"headerlink\" title=\"渐进式rehash\"></a>渐进式rehash</h3><p>大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，<code>O(n)</code>级别的操作。</p>\n<p>Redis还会在定时任务中对字典进行主动搬迁。</p>\n<h3 id=\"扩容条件\"><a href=\"#扩容条件\" class=\"headerlink\" title=\"扩容条件\"></a>扩容条件</h3><p>当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。</p>\n<p>如果 Redis 正在做 bgsave，为了减少内存页的过多分离 （Copy On Write），Redis 尽量不去扩容 （dict_can_resize）</p>\n<p>如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 （dict_force_resize_ratio），说明 hash 表已经过于拥挤了，就会强制扩容。</p>\n<h2 id=\"压缩列表\"><a href=\"#压缩列表\" class=\"headerlink\" title=\"压缩列表\"></a>压缩列表</h2><p>压缩列表类似于一个数组，数组中的每一个元素都对应保存一个数据。</p>\n<p>不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表占用字节数、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p>\n<p>压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> ziplist<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n    int32 zlbytes<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 整个压缩列表占用字节数</span>\n    int32 zltail_offset<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点</span>\n    int16 zllength<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素个数</span>\n    T<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> entries<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素内容列表，挨个挨个紧凑存储</span>\n    int8 zlend<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 标志压缩列表的结束，值恒为 0xFF</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">struct</span> entry <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">int</span><span class=\"token operator\">&lt;</span>var<span class=\"token operator\">></span> prevlen<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 前一个 entry 的字节长度</span>\n    <span class=\"token keyword\">int</span><span class=\"token operator\">&lt;</span>var<span class=\"token operator\">></span> encoding<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素类型编码</span>\n    optional byte<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> content<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素内容</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"跳表\"><a href=\"#跳表\" class=\"headerlink\" title=\"跳表\"></a>跳表</h2><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。</p>\n<h2 id=\"复杂度\"><a href=\"#复杂度\" class=\"headerlink\" title=\"复杂度\"></a>复杂度</h2><p>各个数据结构的查找时间复杂度</p>\n<table>\n<thead>\n<tr>\n<th>数据结构</th>\n<th>复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>哈希表</td>\n<td><code>O(1)</code></td>\n</tr>\n<tr>\n<td>跳表</td>\n<td><code>O(logN)</code></td>\n</tr>\n<tr>\n<td>双向链表</td>\n<td><code>O(N)</code></td>\n</tr>\n<tr>\n<td>压缩列表</td>\n<td><code>O(N)</code></td>\n</tr>\n<tr>\n<td>数组</td>\n<td><code>O(N)</code></td>\n</tr>\n</tbody></table>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"基本数据结构\"><a href=\"#基本数据结构\" class=\"headerlink\" title=\"基本数据结构\"></a>基本数据结构</h2><p>包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）</p>\n<table>\n<thead>\n<tr>\n<th>基本数据结构</th>\n<th>底层实现</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>string</td>\n<td>动态字符串</td>\n</tr>\n<tr>\n<td>List</td>\n<td>双向链表、压缩列表</td>\n</tr>\n<tr>\n<td>Hash</td>\n<td>哈希表，压缩列表</td>\n</tr>\n<tr>\n<td>Sorted Set</td>\n<td>跳表，压缩列表</td>\n</tr>\n<tr>\n<td>Set</td>\n<td>哈希表、数组</td>\n</tr>\n</tbody></table>\n<p>redis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。<br>哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br>冲突增多时，Redis 会对哈希表做渐进式 rehash操作。</p>\n<blockquote>\n<p>rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</p>\n</blockquote>\n<h2 id=\"RedisObject\"><a href=\"#RedisObject\" class=\"headerlink\" title=\"RedisObject\"></a>RedisObject</h2><pre><code class=\"c\">struct RedisObject {\n    int4 type; // 4bits，类型\n    int4 encoding; // 4bits，存储形式\n    int24 lru; // 24bits，LRU 信息\n    int32 refcount; // 4bytes，引用计数\n    void *ptr; // 8bytes，对象内容的具体存储位置\n} robj;</code></pre>\n<p> RedisObject 对象头需要占据 16 字节的存储空间。</p>\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><p>Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。</p>\n<pre><code class=\"c\">struct SDS&lt;T&gt; {\n    T capacity; // 数组容量\n    T len; // 数组长度\n    byte flags; // 特殊标识位，不理睬它\n    byte[] content; // 数组内容\n}\n\nstruct SDS {\n    int8 capacity; // 1byte\n    int8 len; // 1byte\n    int8 flags; // 1byte\n    byte[] content; // 内联数组，长度为 capacity\n}</code></pre>\n<ul>\n<li>embstr ：将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。</li>\n<li>raw ：需要两次 malloc，两个对象头在内存地址上一般是不连续的。</li>\n</ul>\n<h3 id=\"扩容策略\"><a href=\"#扩容策略\" class=\"headerlink\" title=\"扩容策略\"></a>扩容策略</h3><ul>\n<li>字符串在长度小于 1M 之前，扩容空间采用加倍策略。</li>\n<li>当长度超过 1M 之后，为了避免加倍后导致浪费，多分配 1M 大小的冗余空间。</li>\n</ul>\n<h2 id=\"字典\"><a href=\"#字典\" class=\"headerlink\" title=\"字典\"></a>字典</h2><h3 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h3><ul>\n<li>hash 结构的数据</li>\n<li>整个 Redis 数据库的所有 key 和 value 组成了一个全局字典。</li>\n<li>还有带过期时间的 key 集合也是一个字典。</li>\n<li>zset 集合中存储 value 和 score 值的映射关系。</li>\n</ul>\n<h3 id=\"数据结构-1\"><a href=\"#数据结构-1\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><p>内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。</p>\n<p>扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁。</p>\n<p>两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。</p>\n<pre><code class=\"c\">struct dict {\n    ...\n    dictht ht[2];\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}\nstruct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}</code></pre>\n<h3 id=\"渐进式rehash\"><a href=\"#渐进式rehash\" class=\"headerlink\" title=\"渐进式rehash\"></a>渐进式rehash</h3><p>大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，<code>O(n)</code>级别的操作。</p>\n<p>Redis还会在定时任务中对字典进行主动搬迁。</p>\n<h3 id=\"扩容条件\"><a href=\"#扩容条件\" class=\"headerlink\" title=\"扩容条件\"></a>扩容条件</h3><p>当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。</p>\n<p>如果 Redis 正在做 bgsave，为了减少内存页的过多分离 （Copy On Write），Redis 尽量不去扩容 （dict_can_resize）</p>\n<p>如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 （dict_force_resize_ratio），说明 hash 表已经过于拥挤了，就会强制扩容。</p>\n<h2 id=\"压缩列表\"><a href=\"#压缩列表\" class=\"headerlink\" title=\"压缩列表\"></a>压缩列表</h2><p>压缩列表类似于一个数组，数组中的每一个元素都对应保存一个数据。</p>\n<p>不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表占用字节数、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p>\n<p>压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。</p>\n<pre><code class=\"c\">struct ziplist&lt;T&gt; {\n    int32 zlbytes; // 整个压缩列表占用字节数\n    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点\n    int16 zllength; // 元素个数\n    T[] entries; // 元素内容列表，挨个挨个紧凑存储\n    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF\n}\nstruct entry {\n    int&lt;var&gt; prevlen; // 前一个 entry 的字节长度\n    int&lt;var&gt; encoding; // 元素类型编码\n    optional byte[] content; // 元素内容\n}</code></pre>\n<h2 id=\"跳表\"><a href=\"#跳表\" class=\"headerlink\" title=\"跳表\"></a>跳表</h2><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。</p>\n<h2 id=\"复杂度\"><a href=\"#复杂度\" class=\"headerlink\" title=\"复杂度\"></a>复杂度</h2><p>各个数据结构的查找时间复杂度</p>\n<table>\n<thead>\n<tr>\n<th>数据结构</th>\n<th>复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>哈希表</td>\n<td><code>O(1)</code></td>\n</tr>\n<tr>\n<td>跳表</td>\n<td><code>O(logN)</code></td>\n</tr>\n<tr>\n<td>双向链表</td>\n<td><code>O(N)</code></td>\n</tr>\n<tr>\n<td>压缩列表</td>\n<td><code>O(N)</code></td>\n</tr>\n<tr>\n<td>数组</td>\n<td><code>O(N)</code></td>\n</tr>\n</tbody></table>\n"},{"title":"redis消息队列","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-11-02T13:35:36.000Z","password":null,"summary":null,"_content":"\n## 需求分析\n\n- 消息保序：消费者需要按照生产者发送消息的顺序来处理消息\n\n- 处理重复的消息：消费者避免多次处理重复的消息\n\n- 保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理\n\n## 基于List\n\n-  LPUSH \n\n把要发送的消息依次写入 List\n\n- BRPOP \n\n阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。\n\n- 消费者程序本身能对重复消息进行判断\n\n消息队列要能给每一个消息提供全局唯一的 ID 号，消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。\n\n- BRPOPLPUSH\n\n让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存\n\n缺点：不支持消费组\n\n## 基于 Streams（Redis 5.0）\n\n![](stream.jpg)\n\nRedis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。\n\n每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。\n\n同一个消费组可以挂接多个消费者，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。\n\n消费者内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。\n\n- XADD：插入消息，保证有序，可以自动生成全局唯一 ID；\n- XREAD：用于读取消息，可以按 ID 读取数据；\n- XREADGROUP：按消费组形式读取消息\n- XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。\n\n## 缺点\n\n在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。\n\n","source":"_posts/redis消息队列.md","raw":"---\ntitle: redis消息队列\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-11-02 21:35:36\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 需求分析\n\n- 消息保序：消费者需要按照生产者发送消息的顺序来处理消息\n\n- 处理重复的消息：消费者避免多次处理重复的消息\n\n- 保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理\n\n## 基于List\n\n-  LPUSH \n\n把要发送的消息依次写入 List\n\n- BRPOP \n\n阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。\n\n- 消费者程序本身能对重复消息进行判断\n\n消息队列要能给每一个消息提供全局唯一的 ID 号，消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。\n\n- BRPOPLPUSH\n\n让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存\n\n缺点：不支持消费组\n\n## 基于 Streams（Redis 5.0）\n\n![](stream.jpg)\n\nRedis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。\n\n每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。\n\n同一个消费组可以挂接多个消费者，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。\n\n消费者内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。\n\n- XADD：插入消息，保证有序，可以自动生成全局唯一 ID；\n- XREAD：用于读取消息，可以按 ID 读取数据；\n- XREADGROUP：按消费组形式读取消息\n- XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。\n\n## 缺点\n\n在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。\n\n","slug":"redis消息队列","published":1,"updated":"2021-05-11T23:27:40.459Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss75b004sq4ufmuy0w5uk","content":"<h2 id=\"需求分析\"><a href=\"#需求分析\" class=\"headerlink\" title=\"需求分析\"></a>需求分析</h2><ul>\n<li><p>消息保序：消费者需要按照生产者发送消息的顺序来处理消息</p>\n</li>\n<li><p>处理重复的消息：消费者避免多次处理重复的消息</p>\n</li>\n<li><p>保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理</p>\n</li>\n</ul>\n<h2 id=\"基于List\"><a href=\"#基于List\" class=\"headerlink\" title=\"基于List\"></a>基于List</h2><ul>\n<li>LPUSH </li>\n</ul>\n<p>把要发送的消息依次写入 List</p>\n<ul>\n<li>BRPOP </li>\n</ul>\n<p>阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。</p>\n<ul>\n<li>消费者程序本身能对重复消息进行判断</li>\n</ul>\n<p>消息队列要能给每一个消息提供全局唯一的 ID 号，消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。</p>\n<ul>\n<li>BRPOPLPUSH</li>\n</ul>\n<p>让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存</p>\n<p>缺点：不支持消费组</p>\n<h2 id=\"基于-Streams（Redis-5-0）\"><a href=\"#基于-Streams（Redis-5-0）\" class=\"headerlink\" title=\"基于 Streams（Redis 5.0）\"></a>基于 Streams（Redis 5.0）</h2><p><img src=\"stream.jpg\" alt></p>\n<p>Redis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。</p>\n<p>每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。</p>\n<p>同一个消费组可以挂接多个消费者，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。</p>\n<p>消费者内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。</p>\n<ul>\n<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li>\n<li>XREAD：用于读取消息，可以按 ID 读取数据；</li>\n<li>XREADGROUP：按消费组形式读取消息</li>\n<li>XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"需求分析\"><a href=\"#需求分析\" class=\"headerlink\" title=\"需求分析\"></a>需求分析</h2><ul>\n<li><p>消息保序：消费者需要按照生产者发送消息的顺序来处理消息</p>\n</li>\n<li><p>处理重复的消息：消费者避免多次处理重复的消息</p>\n</li>\n<li><p>保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理</p>\n</li>\n</ul>\n<h2 id=\"基于List\"><a href=\"#基于List\" class=\"headerlink\" title=\"基于List\"></a>基于List</h2><ul>\n<li>LPUSH </li>\n</ul>\n<p>把要发送的消息依次写入 List</p>\n<ul>\n<li>BRPOP </li>\n</ul>\n<p>阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。</p>\n<ul>\n<li>消费者程序本身能对重复消息进行判断</li>\n</ul>\n<p>消息队列要能给每一个消息提供全局唯一的 ID 号，消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。</p>\n<ul>\n<li>BRPOPLPUSH</li>\n</ul>\n<p>让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存</p>\n<p>缺点：不支持消费组</p>\n<h2 id=\"基于-Streams（Redis-5-0）\"><a href=\"#基于-Streams（Redis-5-0）\" class=\"headerlink\" title=\"基于 Streams（Redis 5.0）\"></a>基于 Streams（Redis 5.0）</h2><p><img src=\"stream.jpg\" alt></p>\n<p>Redis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。</p>\n<p>每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。</p>\n<p>同一个消费组可以挂接多个消费者，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。</p>\n<p>消费者内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。</p>\n<ul>\n<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li>\n<li>XREAD：用于读取消息，可以按 ID 读取数据；</li>\n<li>XREADGROUP：按消费组形式读取消息</li>\n<li>XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。</p>\n"},{"title":"redis缓存","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-27T12:04:59.000Z","password":null,"summary":null,"_content":"\n## redis缓存使用\n\n- 应用读取数据时，需要先读取 Redis；\n\n- 发生缓存缺失时，需要从数据库读取数据并更新缓存。\n\n\nRedis为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。\n\n## 缓存分类\n\n- 只读缓存：加速读请求。\n\n- 读写缓存：加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。\n\n### 只读缓存\n\n- 读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。\n- 写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。\n\n**优点**\n\n数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。\n\n**缺点**\n\n每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。\n\n### 读写缓存\n\n读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。\n\n#### 同步直写\n\n- 写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回\n- 需要在业务应用中使用事务实现\n\n**缺点**：降低缓存的访问性能\n\n**优点**：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存\n\n#### 异步直写\n\n- 所有写请求都先在缓存中处理。\n\n> Redis 本身不提供机制将淘汰数据写回数据库\n\n**Read/Write Throught策略**\n\n应用层读写只需要操作缓存，缓存层会自动从数据库中加载或写回到数据库中\n\n**优点**\n\n对于应用层的使用非常友好，只需要操作缓存即可\n\n**缺点**\n\n需要缓存层支持和后端数据库的联动。\n\n**Write Back策略**\n\n写操作只写缓存。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库。\n\n**优点**\n\n写操作飞快（只写缓存）\n\n**缺点**\n\n如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。\n\n## 缓存淘汰\n\n“八二原理”：80% 的请求实际只访问了 20% 的数据。\n\n**缓存大小设置**：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。\n\n- 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。\n- 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。\n\n**淘汰策略**\n\n- volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。\n-  volatile-ttl key 的剩余寿命 ttl 的值越小越优先被淘汰。\n- volatile-random 设置了过期时间的 key集合中随机的 key。\n-  allkeys-lru全体的 key 集合中最近最少使用的。\n- allkeys-random 全体的 key 集合中随机的 key\n\n**LRU**\n\nRedis 中，LRU 算法被做了简化。\n\n- Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。\n- Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。\n- 再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值\n\n**LFU**\n\n从两个维度来筛选并淘汰数据：\n\n- 数据的被访问次数\n\n- 数据访问的时效性，访问时间离当前时间的远近\n\n**计数规则**：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。\n\n**counter 值的衰减机制**\n\nLFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。\n\n## 缓存一致性\n\n### 原因1：更新操作失败\n\n只读缓存：无法保证删改数据库和删除缓存的原子性。\n\n- 先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。\n- 先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了\n\n**解决办法：重试机制**\n\n- 把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n- 如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n\n### 原因2：大量并发请求\n\n**先删缓存，后更数据库**\n\n![并发缓存不一致](buyizhi.jpg)\n\n**解决办法：延迟双删**\n\n在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。\n\n难点：sleep时间不好控制\n\n**先更数据库，后删缓存**\n\n![并发缓存不一致2](buyizhi2.jpg)\n\n其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。\n\n优点：不存在缓存缺失的问题，推荐！！\n\n**缓存更新替代删除**\n\n写+写并发时，必然会有数据不一致的情况。因此需要配合**分布式锁**使用。\n\n写+读并发时，先更数据库可能会有短时不一致。\n\n## 缓存异常\n\n### 缓存雪崩\n\n大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n**原因**\n\n- 缓存中有大量数据同时过期\n- Redis 缓存实例发生故障宕机了，无法处理请求\n\n**解决办法**\n\n- 原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数\n- 原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取\n- 原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n- 事前预防。建 里Redis 缓存高可靠主从集群。\n\n### 缓存击穿\n\n某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。\n\n**解决办法**\n\n访问特别频繁的热点数据，不设置过期时间\n\n### 缓存穿透\n\n要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。\n\n**原因**\n\n- 业务层误操作：缓存中的数据和数据库中的数据被误删除了\n\n- 恶意攻击：专门访问数据库中没有的数据。\n\n**解决办法**\n\n- 针对穿透查询数据，缓存空值或缺省值。\n- 使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。\n- 前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库\n\n","source":"_posts/redis缓存.md","raw":"---\ntitle: redis缓存\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-27 20:04:59\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## redis缓存使用\n\n- 应用读取数据时，需要先读取 Redis；\n\n- 发生缓存缺失时，需要从数据库读取数据并更新缓存。\n\n\nRedis为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。\n\n## 缓存分类\n\n- 只读缓存：加速读请求。\n\n- 读写缓存：加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。\n\n### 只读缓存\n\n- 读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。\n- 写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。\n\n**优点**\n\n数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。\n\n**缺点**\n\n每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。\n\n### 读写缓存\n\n读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。\n\n#### 同步直写\n\n- 写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回\n- 需要在业务应用中使用事务实现\n\n**缺点**：降低缓存的访问性能\n\n**优点**：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存\n\n#### 异步直写\n\n- 所有写请求都先在缓存中处理。\n\n> Redis 本身不提供机制将淘汰数据写回数据库\n\n**Read/Write Throught策略**\n\n应用层读写只需要操作缓存，缓存层会自动从数据库中加载或写回到数据库中\n\n**优点**\n\n对于应用层的使用非常友好，只需要操作缓存即可\n\n**缺点**\n\n需要缓存层支持和后端数据库的联动。\n\n**Write Back策略**\n\n写操作只写缓存。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库。\n\n**优点**\n\n写操作飞快（只写缓存）\n\n**缺点**\n\n如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。\n\n## 缓存淘汰\n\n“八二原理”：80% 的请求实际只访问了 20% 的数据。\n\n**缓存大小设置**：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。\n\n- 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。\n- 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。\n\n**淘汰策略**\n\n- volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。\n-  volatile-ttl key 的剩余寿命 ttl 的值越小越优先被淘汰。\n- volatile-random 设置了过期时间的 key集合中随机的 key。\n-  allkeys-lru全体的 key 集合中最近最少使用的。\n- allkeys-random 全体的 key 集合中随机的 key\n\n**LRU**\n\nRedis 中，LRU 算法被做了简化。\n\n- Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。\n- Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。\n- 再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值\n\n**LFU**\n\n从两个维度来筛选并淘汰数据：\n\n- 数据的被访问次数\n\n- 数据访问的时效性，访问时间离当前时间的远近\n\n**计数规则**：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。\n\n**counter 值的衰减机制**\n\nLFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。\n\n## 缓存一致性\n\n### 原因1：更新操作失败\n\n只读缓存：无法保证删改数据库和删除缓存的原子性。\n\n- 先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。\n- 先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了\n\n**解决办法：重试机制**\n\n- 把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n- 如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n\n### 原因2：大量并发请求\n\n**先删缓存，后更数据库**\n\n![并发缓存不一致](buyizhi.jpg)\n\n**解决办法：延迟双删**\n\n在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。\n\n难点：sleep时间不好控制\n\n**先更数据库，后删缓存**\n\n![并发缓存不一致2](buyizhi2.jpg)\n\n其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。\n\n优点：不存在缓存缺失的问题，推荐！！\n\n**缓存更新替代删除**\n\n写+写并发时，必然会有数据不一致的情况。因此需要配合**分布式锁**使用。\n\n写+读并发时，先更数据库可能会有短时不一致。\n\n## 缓存异常\n\n### 缓存雪崩\n\n大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n**原因**\n\n- 缓存中有大量数据同时过期\n- Redis 缓存实例发生故障宕机了，无法处理请求\n\n**解决办法**\n\n- 原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数\n- 原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取\n- 原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n- 事前预防。建 里Redis 缓存高可靠主从集群。\n\n### 缓存击穿\n\n某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。\n\n**解决办法**\n\n访问特别频繁的热点数据，不设置过期时间\n\n### 缓存穿透\n\n要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。\n\n**原因**\n\n- 业务层误操作：缓存中的数据和数据库中的数据被误删除了\n\n- 恶意攻击：专门访问数据库中没有的数据。\n\n**解决办法**\n\n- 针对穿透查询数据，缓存空值或缺省值。\n- 使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。\n- 前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库\n\n","slug":"redis缓存","published":1,"updated":"2021-05-11T11:33:29.607Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss75r004vq4ufxdh5cguj","content":"<h2 id=\"redis缓存使用\"><a href=\"#redis缓存使用\" class=\"headerlink\" title=\"redis缓存使用\"></a>redis缓存使用</h2><ul>\n<li><p>应用读取数据时，需要先读取 Redis；</p>\n</li>\n<li><p>发生缓存缺失时，需要从数据库读取数据并更新缓存。</p>\n</li>\n</ul>\n<p>Redis为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p>\n<h2 id=\"缓存分类\"><a href=\"#缓存分类\" class=\"headerlink\" title=\"缓存分类\"></a>缓存分类</h2><ul>\n<li><p>只读缓存：加速读请求。</p>\n</li>\n<li><p>读写缓存：加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。</p>\n</li>\n</ul>\n<h3 id=\"只读缓存\"><a href=\"#只读缓存\" class=\"headerlink\" title=\"只读缓存\"></a>只读缓存</h3><ul>\n<li>读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。</li>\n<li>写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p>数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。</p>\n<p><strong>缺点</strong></p>\n<p>每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p>\n<h3 id=\"读写缓存\"><a href=\"#读写缓存\" class=\"headerlink\" title=\"读写缓存\"></a>读写缓存</h3><p>读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。</p>\n<h4 id=\"同步直写\"><a href=\"#同步直写\" class=\"headerlink\" title=\"同步直写\"></a>同步直写</h4><ul>\n<li>写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回</li>\n<li>需要在业务应用中使用事务实现</li>\n</ul>\n<p><strong>缺点</strong>：降低缓存的访问性能</p>\n<p><strong>优点</strong>：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存</p>\n<h4 id=\"异步直写\"><a href=\"#异步直写\" class=\"headerlink\" title=\"异步直写\"></a>异步直写</h4><ul>\n<li>所有写请求都先在缓存中处理。</li>\n</ul>\n<blockquote>\n<p>Redis 本身不提供机制将淘汰数据写回数据库</p>\n</blockquote>\n<p><strong>Read/Write Throught策略</strong></p>\n<p>应用层读写只需要操作缓存，缓存层会自动从数据库中加载或写回到数据库中</p>\n<p><strong>优点</strong></p>\n<p>对于应用层的使用非常友好，只需要操作缓存即可</p>\n<p><strong>缺点</strong></p>\n<p>需要缓存层支持和后端数据库的联动。</p>\n<p><strong>Write Back策略</strong></p>\n<p>写操作只写缓存。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库。</p>\n<p><strong>优点</strong></p>\n<p>写操作飞快（只写缓存）</p>\n<p><strong>缺点</strong></p>\n<p>如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。</p>\n<h2 id=\"缓存淘汰\"><a href=\"#缓存淘汰\" class=\"headerlink\" title=\"缓存淘汰\"></a>缓存淘汰</h2><p>“八二原理”：80% 的请求实际只访问了 20% 的数据。</p>\n<p><strong>缓存大小设置</strong>：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。</p>\n<ul>\n<li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。</li>\n<li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。</li>\n</ul>\n<p><strong>淘汰策略</strong></p>\n<ul>\n<li>volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。</li>\n<li>volatile-ttl key 的剩余寿命 ttl 的值越小越优先被淘汰。</li>\n<li>volatile-random 设置了过期时间的 key集合中随机的 key。</li>\n<li>allkeys-lru全体的 key 集合中最近最少使用的。</li>\n<li>allkeys-random 全体的 key 集合中随机的 key</li>\n</ul>\n<p><strong>LRU</strong></p>\n<p>Redis 中，LRU 算法被做了简化。</p>\n<ul>\n<li>Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。</li>\n<li>Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</li>\n<li>再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值</li>\n</ul>\n<p><strong>LFU</strong></p>\n<p>从两个维度来筛选并淘汰数据：</p>\n<ul>\n<li><p>数据的被访问次数</p>\n</li>\n<li><p>数据访问的时效性，访问时间离当前时间的远近</p>\n</li>\n</ul>\n<p><strong>计数规则</strong>：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</p>\n<p><strong>counter 值的衰减机制</strong></p>\n<p>LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</p>\n<h2 id=\"缓存一致性\"><a href=\"#缓存一致性\" class=\"headerlink\" title=\"缓存一致性\"></a>缓存一致性</h2><h3 id=\"原因1：更新操作失败\"><a href=\"#原因1：更新操作失败\" class=\"headerlink\" title=\"原因1：更新操作失败\"></a>原因1：更新操作失败</h3><p>只读缓存：无法保证删改数据库和删除缓存的原子性。</p>\n<ul>\n<li>先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。</li>\n<li>先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了</li>\n</ul>\n<p><strong>解决办法：重试机制</strong></p>\n<ul>\n<li>把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</li>\n<li>如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>\n</ul>\n<h3 id=\"原因2：大量并发请求\"><a href=\"#原因2：大量并发请求\" class=\"headerlink\" title=\"原因2：大量并发请求\"></a>原因2：大量并发请求</h3><p><strong>先删缓存，后更数据库</strong></p>\n<p><img src=\"buyizhi.jpg\" alt=\"并发缓存不一致\"></p>\n<p><strong>解决办法：延迟双删</strong></p>\n<p>在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。</p>\n<p>难点：sleep时间不好控制</p>\n<p><strong>先更数据库，后删缓存</strong></p>\n<p><img src=\"buyizhi2.jpg\" alt=\"并发缓存不一致2\"></p>\n<p>其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。</p>\n<p>优点：不存在缓存缺失的问题，推荐！！</p>\n<p><strong>缓存更新替代删除</strong></p>\n<p>写+写并发时，必然会有数据不一致的情况。因此需要配合<strong>分布式锁</strong>使用。</p>\n<p>写+读并发时，先更数据库可能会有短时不一致。</p>\n<h2 id=\"缓存异常\"><a href=\"#缓存异常\" class=\"headerlink\" title=\"缓存异常\"></a>缓存异常</h2><h3 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h3><p>大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li>缓存中有大量数据同时过期</li>\n<li>Redis 缓存实例发生故障宕机了，无法处理请求</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数</li>\n<li>原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取</li>\n<li>原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</li>\n<li>事前预防。建 里Redis 缓存高可靠主从集群。</li>\n</ul>\n<h3 id=\"缓存击穿\"><a href=\"#缓存击穿\" class=\"headerlink\" title=\"缓存击穿\"></a>缓存击穿</h3><p>某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p>\n<p><strong>解决办法</strong></p>\n<p>访问特别频繁的热点数据，不设置过期时间</p>\n<h3 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h3><p>要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li><p>业务层误操作：缓存中的数据和数据库中的数据被误删除了</p>\n</li>\n<li><p>恶意攻击：专门访问数据库中没有的数据。</p>\n</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>针对穿透查询数据，缓存空值或缺省值。</li>\n<li>使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。</li>\n<li>前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"redis缓存使用\"><a href=\"#redis缓存使用\" class=\"headerlink\" title=\"redis缓存使用\"></a>redis缓存使用</h2><ul>\n<li><p>应用读取数据时，需要先读取 Redis；</p>\n</li>\n<li><p>发生缓存缺失时，需要从数据库读取数据并更新缓存。</p>\n</li>\n</ul>\n<p>Redis为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p>\n<h2 id=\"缓存分类\"><a href=\"#缓存分类\" class=\"headerlink\" title=\"缓存分类\"></a>缓存分类</h2><ul>\n<li><p>只读缓存：加速读请求。</p>\n</li>\n<li><p>读写缓存：加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。</p>\n</li>\n</ul>\n<h3 id=\"只读缓存\"><a href=\"#只读缓存\" class=\"headerlink\" title=\"只读缓存\"></a>只读缓存</h3><ul>\n<li>读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。</li>\n<li>写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p>数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。</p>\n<p><strong>缺点</strong></p>\n<p>每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p>\n<h3 id=\"读写缓存\"><a href=\"#读写缓存\" class=\"headerlink\" title=\"读写缓存\"></a>读写缓存</h3><p>读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。</p>\n<h4 id=\"同步直写\"><a href=\"#同步直写\" class=\"headerlink\" title=\"同步直写\"></a>同步直写</h4><ul>\n<li>写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回</li>\n<li>需要在业务应用中使用事务实现</li>\n</ul>\n<p><strong>缺点</strong>：降低缓存的访问性能</p>\n<p><strong>优点</strong>：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存</p>\n<h4 id=\"异步直写\"><a href=\"#异步直写\" class=\"headerlink\" title=\"异步直写\"></a>异步直写</h4><ul>\n<li>所有写请求都先在缓存中处理。</li>\n</ul>\n<blockquote>\n<p>Redis 本身不提供机制将淘汰数据写回数据库</p>\n</blockquote>\n<p><strong>Read/Write Throught策略</strong></p>\n<p>应用层读写只需要操作缓存，缓存层会自动从数据库中加载或写回到数据库中</p>\n<p><strong>优点</strong></p>\n<p>对于应用层的使用非常友好，只需要操作缓存即可</p>\n<p><strong>缺点</strong></p>\n<p>需要缓存层支持和后端数据库的联动。</p>\n<p><strong>Write Back策略</strong></p>\n<p>写操作只写缓存。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库。</p>\n<p><strong>优点</strong></p>\n<p>写操作飞快（只写缓存）</p>\n<p><strong>缺点</strong></p>\n<p>如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。</p>\n<h2 id=\"缓存淘汰\"><a href=\"#缓存淘汰\" class=\"headerlink\" title=\"缓存淘汰\"></a>缓存淘汰</h2><p>“八二原理”：80% 的请求实际只访问了 20% 的数据。</p>\n<p><strong>缓存大小设置</strong>：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。</p>\n<ul>\n<li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。</li>\n<li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。</li>\n</ul>\n<p><strong>淘汰策略</strong></p>\n<ul>\n<li>volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。</li>\n<li>volatile-ttl key 的剩余寿命 ttl 的值越小越优先被淘汰。</li>\n<li>volatile-random 设置了过期时间的 key集合中随机的 key。</li>\n<li>allkeys-lru全体的 key 集合中最近最少使用的。</li>\n<li>allkeys-random 全体的 key 集合中随机的 key</li>\n</ul>\n<p><strong>LRU</strong></p>\n<p>Redis 中，LRU 算法被做了简化。</p>\n<ul>\n<li>Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。</li>\n<li>Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</li>\n<li>再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值</li>\n</ul>\n<p><strong>LFU</strong></p>\n<p>从两个维度来筛选并淘汰数据：</p>\n<ul>\n<li><p>数据的被访问次数</p>\n</li>\n<li><p>数据访问的时效性，访问时间离当前时间的远近</p>\n</li>\n</ul>\n<p><strong>计数规则</strong>：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</p>\n<p><strong>counter 值的衰减机制</strong></p>\n<p>LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</p>\n<h2 id=\"缓存一致性\"><a href=\"#缓存一致性\" class=\"headerlink\" title=\"缓存一致性\"></a>缓存一致性</h2><h3 id=\"原因1：更新操作失败\"><a href=\"#原因1：更新操作失败\" class=\"headerlink\" title=\"原因1：更新操作失败\"></a>原因1：更新操作失败</h3><p>只读缓存：无法保证删改数据库和删除缓存的原子性。</p>\n<ul>\n<li>先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。</li>\n<li>先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了</li>\n</ul>\n<p><strong>解决办法：重试机制</strong></p>\n<ul>\n<li>把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</li>\n<li>如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>\n</ul>\n<h3 id=\"原因2：大量并发请求\"><a href=\"#原因2：大量并发请求\" class=\"headerlink\" title=\"原因2：大量并发请求\"></a>原因2：大量并发请求</h3><p><strong>先删缓存，后更数据库</strong></p>\n<p><img src=\"buyizhi.jpg\" alt=\"并发缓存不一致\"></p>\n<p><strong>解决办法：延迟双删</strong></p>\n<p>在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。</p>\n<p>难点：sleep时间不好控制</p>\n<p><strong>先更数据库，后删缓存</strong></p>\n<p><img src=\"buyizhi2.jpg\" alt=\"并发缓存不一致2\"></p>\n<p>其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。</p>\n<p>优点：不存在缓存缺失的问题，推荐！！</p>\n<p><strong>缓存更新替代删除</strong></p>\n<p>写+写并发时，必然会有数据不一致的情况。因此需要配合<strong>分布式锁</strong>使用。</p>\n<p>写+读并发时，先更数据库可能会有短时不一致。</p>\n<h2 id=\"缓存异常\"><a href=\"#缓存异常\" class=\"headerlink\" title=\"缓存异常\"></a>缓存异常</h2><h3 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h3><p>大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li>缓存中有大量数据同时过期</li>\n<li>Redis 缓存实例发生故障宕机了，无法处理请求</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数</li>\n<li>原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取</li>\n<li>原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</li>\n<li>事前预防。建 里Redis 缓存高可靠主从集群。</li>\n</ul>\n<h3 id=\"缓存击穿\"><a href=\"#缓存击穿\" class=\"headerlink\" title=\"缓存击穿\"></a>缓存击穿</h3><p>某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p>\n<p><strong>解决办法</strong></p>\n<p>访问特别频繁的热点数据，不设置过期时间</p>\n<h3 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h3><p>要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li><p>业务层误操作：缓存中的数据和数据库中的数据被误删除了</p>\n</li>\n<li><p>恶意攻击：专门访问数据库中没有的数据。</p>\n</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>针对穿透查询数据，缓存空值或缺省值。</li>\n<li>使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。</li>\n<li>前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</li>\n</ul>\n"},{"title":"redis变慢以及优化方法","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:42:19.000Z","password":null,"summary":null,"_content":"\n## 确定问题\n\n1、查看 Redis 的响应延迟。\n2、基于当前环境下的 Redis 基线性能做判断\n基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。\n\n\n## 问题定位\n\n1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。\n2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）\n3、检查是否使用了慢查询命令：`KEYS *xxx`\n\n\n## 优化\n1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。\n1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。\n\n2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数\n\n3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行`SCAN $cursor COUNT $count`可以得到一批key以及下一个游标`$cursor`，然后把这个`$cursor`当作SCAN的参数，再次执行，以此往复，直到返回的`$cursor`为0时，就把整个实例中的所有key遍历出来了。","source":"_posts/redis变慢以及优化方法.md","raw":"---\ntitle: redis变慢以及优化方法\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:42:19\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 确定问题\n\n1、查看 Redis 的响应延迟。\n2、基于当前环境下的 Redis 基线性能做判断\n基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。\n\n\n## 问题定位\n\n1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。\n2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）\n3、检查是否使用了慢查询命令：`KEYS *xxx`\n\n\n## 优化\n1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。\n1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。\n\n2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数\n\n3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行`SCAN $cursor COUNT $count`可以得到一批key以及下一个游标`$cursor`，然后把这个`$cursor`当作SCAN的参数，再次执行，以此往复，直到返回的`$cursor`为0时，就把整个实例中的所有key遍历出来了。","slug":"redis变慢以及优化方法","published":1,"updated":"2021-05-17T11:47:58.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss760004yq4uflx6c3hwr","content":"<h2 id=\"确定问题\"><a href=\"#确定问题\" class=\"headerlink\" title=\"确定问题\"></a>确定问题</h2><p>1、查看 Redis 的响应延迟。<br>2、基于当前环境下的 Redis 基线性能做判断<br>基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。</p>\n<h2 id=\"问题定位\"><a href=\"#问题定位\" class=\"headerlink\" title=\"问题定位\"></a>问题定位</h2><p>1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。<br>2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>3、检查是否使用了慢查询命令：<code>KEYS *xxx</code></p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。<br>1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p>\n<p>2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数</p>\n<p>3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行<code>SCAN $cursor COUNT $count</code>可以得到一批key以及下一个游标<code>$cursor</code>，然后把这个<code>$cursor</code>当作SCAN的参数，再次执行，以此往复，直到返回的<code>$cursor</code>为0时，就把整个实例中的所有key遍历出来了。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"确定问题\"><a href=\"#确定问题\" class=\"headerlink\" title=\"确定问题\"></a>确定问题</h2><p>1、查看 Redis 的响应延迟。<br>2、基于当前环境下的 Redis 基线性能做判断<br>基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。</p>\n<h2 id=\"问题定位\"><a href=\"#问题定位\" class=\"headerlink\" title=\"问题定位\"></a>问题定位</h2><p>1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。<br>2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>3、检查是否使用了慢查询命令：<code>KEYS *xxx</code></p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。<br>1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p>\n<p>2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数</p>\n<p>3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行<code>SCAN $cursor COUNT $count</code>可以得到一批key以及下一个游标<code>$cursor</code>，然后把这个<code>$cursor</code>当作SCAN的参数，再次执行，以此往复，直到返回的<code>$cursor</code>为0时，就把整个实例中的所有key遍历出来了。</p>\n"},{"title":"redis阻塞及解决办法","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:39:01.000Z","password":null,"summary":null,"_content":"\n\n\n---\n\n## 阻塞分析\n\n### 客户端\n\n**复杂度高的增删改查操作**\n1、集合全量查询和聚合操作\n2、bigkey 删除\n3、清空数据库\n\n\n### 磁盘\n\n1、AOF 日志同步写\n\n### 主从节点\n\n1、从库接收 RDB 文件后、**清空数据库、加载 RDB 文件**；\n\n### 切片集群\n\n向其他实例传输哈希槽信息，数据迁移时遇到big key。\n\n### 小结\n\n关键路径：集合全量查询和聚合操作和从库加载 RDB 文件\n非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。\n\n## 解决方案\n\n### 异步的子线程机制\n\nRedis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别负责 **AOF 日志写操作、键值对删除以及文件关闭**的异步执行。\n\n主线程通过一个链表形式的任务队列和子线程进行交互。\n\n- 当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。\n- 当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。\n\n> 异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。\n>\n> 之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。\n\n### 分批读取\n集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算\n\n### 控制RBD大小\n从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。","source":"_posts/redis阻塞及解决办法.md","raw":"---\ntitle: redis阻塞及解决办法\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:39:01\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n\n\n---\n\n## 阻塞分析\n\n### 客户端\n\n**复杂度高的增删改查操作**\n1、集合全量查询和聚合操作\n2、bigkey 删除\n3、清空数据库\n\n\n### 磁盘\n\n1、AOF 日志同步写\n\n### 主从节点\n\n1、从库接收 RDB 文件后、**清空数据库、加载 RDB 文件**；\n\n### 切片集群\n\n向其他实例传输哈希槽信息，数据迁移时遇到big key。\n\n### 小结\n\n关键路径：集合全量查询和聚合操作和从库加载 RDB 文件\n非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。\n\n## 解决方案\n\n### 异步的子线程机制\n\nRedis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别负责 **AOF 日志写操作、键值对删除以及文件关闭**的异步执行。\n\n主线程通过一个链表形式的任务队列和子线程进行交互。\n\n- 当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。\n- 当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。\n\n> 异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。\n>\n> 之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。\n\n### 分批读取\n集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算\n\n### 控制RBD大小\n从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。","slug":"redis阻塞及解决办法","published":1,"updated":"2021-05-09T13:52:20.251Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss7690051q4uf501jac2w","content":"<hr>\n<h2 id=\"阻塞分析\"><a href=\"#阻塞分析\" class=\"headerlink\" title=\"阻塞分析\"></a>阻塞分析</h2><h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><p><strong>复杂度高的增删改查操作</strong><br>1、集合全量查询和聚合操作<br>2、bigkey 删除<br>3、清空数据库</p>\n<h3 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h3><p>1、AOF 日志同步写</p>\n<h3 id=\"主从节点\"><a href=\"#主从节点\" class=\"headerlink\" title=\"主从节点\"></a>主从节点</h3><p>1、从库接收 RDB 文件后、<strong>清空数据库、加载 RDB 文件</strong>；</p>\n<h3 id=\"切片集群\"><a href=\"#切片集群\" class=\"headerlink\" title=\"切片集群\"></a>切片集群</h3><p>向其他实例传输哈希槽信息，数据迁移时遇到big key。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>关键路径：集合全量查询和聚合操作和从库加载 RDB 文件<br>非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。</p>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"异步的子线程机制\"><a href=\"#异步的子线程机制\" class=\"headerlink\" title=\"异步的子线程机制\"></a>异步的子线程机制</h3><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别负责 <strong>AOF 日志写操作、键值对删除以及文件关闭</strong>的异步执行。</p>\n<p>主线程通过一个链表形式的任务队列和子线程进行交互。</p>\n<ul>\n<li>当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。</li>\n<li>当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</li>\n</ul>\n<blockquote>\n<p>异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。</p>\n<p>之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>\n</blockquote>\n<h3 id=\"分批读取\"><a href=\"#分批读取\" class=\"headerlink\" title=\"分批读取\"></a>分批读取</h3><p>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算</p>\n<h3 id=\"控制RBD大小\"><a href=\"#控制RBD大小\" class=\"headerlink\" title=\"控制RBD大小\"></a>控制RBD大小</h3><p>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<hr>\n<h2 id=\"阻塞分析\"><a href=\"#阻塞分析\" class=\"headerlink\" title=\"阻塞分析\"></a>阻塞分析</h2><h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><p><strong>复杂度高的增删改查操作</strong><br>1、集合全量查询和聚合操作<br>2、bigkey 删除<br>3、清空数据库</p>\n<h3 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h3><p>1、AOF 日志同步写</p>\n<h3 id=\"主从节点\"><a href=\"#主从节点\" class=\"headerlink\" title=\"主从节点\"></a>主从节点</h3><p>1、从库接收 RDB 文件后、<strong>清空数据库、加载 RDB 文件</strong>；</p>\n<h3 id=\"切片集群\"><a href=\"#切片集群\" class=\"headerlink\" title=\"切片集群\"></a>切片集群</h3><p>向其他实例传输哈希槽信息，数据迁移时遇到big key。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>关键路径：集合全量查询和聚合操作和从库加载 RDB 文件<br>非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。</p>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"异步的子线程机制\"><a href=\"#异步的子线程机制\" class=\"headerlink\" title=\"异步的子线程机制\"></a>异步的子线程机制</h3><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别负责 <strong>AOF 日志写操作、键值对删除以及文件关闭</strong>的异步执行。</p>\n<p>主线程通过一个链表形式的任务队列和子线程进行交互。</p>\n<ul>\n<li>当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。</li>\n<li>当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</li>\n</ul>\n<blockquote>\n<p>异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。</p>\n<p>之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>\n</blockquote>\n<h3 id=\"分批读取\"><a href=\"#分批读取\" class=\"headerlink\" title=\"分批读取\"></a>分批读取</h3><p>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算</p>\n<h3 id=\"控制RBD大小\"><a href=\"#控制RBD大小\" class=\"headerlink\" title=\"控制RBD大小\"></a>控制RBD大小</h3><p>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</p>\n"},{"title":"redis网络IO模型","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:06:23.000Z","password":null,"summary":null,"_content":"\n## 单线程\n\nRedis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\n\n避免了多线程编程模式面临的共享资源的并发访问控制问题。\n\n## 多路复用机制\n\n一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n\n为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。","source":"_posts/redis网络IO模型.md","raw":"---\ntitle: redis网络IO模型\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:06:23\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 单线程\n\nRedis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\n\n避免了多线程编程模式面临的共享资源的并发访问控制问题。\n\n## 多路复用机制\n\n一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n\n为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。","slug":"redis网络IO模型","published":1,"updated":"2021-04-01T23:01:50.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss76h0054q4ufaal34xod","content":"<h2 id=\"单线程\"><a href=\"#单线程\" class=\"headerlink\" title=\"单线程\"></a>单线程</h2><p>Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p>\n<p>避免了多线程编程模式面临的共享资源的并发访问控制问题。</p>\n<h2 id=\"多路复用机制\"><a href=\"#多路复用机制\" class=\"headerlink\" title=\"多路复用机制\"></a>多路复用机制</h2><p>一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p>\n<p>为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"单线程\"><a href=\"#单线程\" class=\"headerlink\" title=\"单线程\"></a>单线程</h2><p>Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p>\n<p>避免了多线程编程模式面临的共享资源的并发访问控制问题。</p>\n<h2 id=\"多路复用机制\"><a href=\"#多路复用机制\" class=\"headerlink\" title=\"多路复用机制\"></a>多路复用机制</h2><p>一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p>\n<p>为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>\n"},{"title":"事务","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-14T11:57:07.000Z","password":null,"summary":"事务ACID、隔离级别及实现。分析了事务可见性，介绍了Binlog、redolog，并加以对比。数据库不丢数据的设置，给出了使用事务的建议。","_content":"\n## 事务\n\n一个不可分割的数据库操作序列，是数据库并发控制的基本单位。\n\n事务是逻辑上的一组操作，要么都执行，要么都不执行。\n\n### ACID\n\n- atomicity（原子性） ：要么全执行，要么全都不执行；\n- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；\n- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；\n- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。\n\n### 并发事务可能存在的问题\n\n- 脏读：读取未提交的事务。\n- 不可重复读：多次读取同一数据，读取的数据不一致。\n- 幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n\n### 事务隔离级别\n\n- READ-UNCOMMITTED：一个事务还没提交时，它做的变更就能被别的事务看到。\n- READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。\n- REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。\n- SERIALIZABLE：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n### 事务隔离的实现\n\n数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n- 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n- 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。\n\n- “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n- “串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n## 事务可见性分析（RR）\n\n事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为**低水位**，最大值加1记为**高水位**。\n\n- row trx_id<低水位：这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n- 低水位<row trx_id<高水位：\n  - 在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；\n  - 不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。\n- row trx_id>高水位：由将来启动的事务生成的，是肯定不可见的；\n\n也可以从事务启动时间来看：\n\n1. 版本未提交，不可见；\n2. 版本已提交，但是是在视图创建后提交的，不可见；\n3. 版本已提交，而且是在视图创建前提交的，可见。\n\n> 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）\n>\n> select * from t where id=1加上lock in share mode 或for update，也是当前读。\n\n## Redo log\n\nRedo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。\n\nRedo log 由两部分组成：\n\n- 内存中的重做日志缓冲（redo log buffer）\n- 重做日志文件（redo log file）\n\n每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：\n\n- 0：表示每次事务提交时都只是把redo log留在**redo log buffer中**;\n- 1（默认值）：表示每次事务提交时都将redo log直接**持久化到磁盘**；\n- 2：表示每次事务提交时都只是把redo log**写到page cache**。\n\n除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。\n\n- redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。\n- 并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。\n\n## Binlog\n\n二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）\n\nBinlog 有以下几个作用：\n\n- 恢复：数据恢复时可以使用二进制日志\n- 复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步\n- 审计：可以通过二进制日志进行审计数据的变更操作\n\nsync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。\n\n- sync_binlog=0，表示每次提交事务都只write，不fsync\n- sync_binlog=1，表示每次提交事务都会执行fsync\n- sync_binlog=N，表示每次提交事务都write，累积N个事务后才fsync\n\n**binlog格式**\n\n- statement：binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用\n- row：binlog里面记录了真实删除行的主键id，不会有主备删除不同行的问题。缺点是很占空间。优点利于恢复数据。\n- mixed格：MySQL自己判断SQL语句是否可能引起主备不一致，是就用row格式，否则就用statement格式。\n\n## redolog和binlog区别\n\n- redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n\n- redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n\n- redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n## 数据库突然断电不丢数据\n\n只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。\n\n## 事务建议\n\n- 循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。\n- 优化事务里的语句顺序，减少锁时间。\n- 关注不同事务访问资源的顺序，避免死锁。\n- 创建事务之前，关注事务隔离级别。\n- 不在事务中混合使用存储引擎（MyISAM无法回滚）\n\n## 分布式事务\n\n分布式事务使用两阶段提交协议：\n第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；\n第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。\n\n### MySQL 自带的分布式事务\n\n```mysql\nxa start 'a','a_1'; //启动分支事务\nxa end 'a','a_1'; //结束分支事务\nxa prepare 'a','a_1'; //进入准备状态\nxa commit 'a','a_1';  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息\n```\n\n","source":"_posts/事务.md","raw":"---\ntitle: 事务\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-14 19:57:07\npassword:\nsummary: 事务ACID、隔离级别及实现。分析了事务可见性，介绍了Binlog、redolog，并加以对比。数据库不丢数据的设置，给出了使用事务的建议。\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 事务\n\n一个不可分割的数据库操作序列，是数据库并发控制的基本单位。\n\n事务是逻辑上的一组操作，要么都执行，要么都不执行。\n\n### ACID\n\n- atomicity（原子性） ：要么全执行，要么全都不执行；\n- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；\n- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；\n- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。\n\n### 并发事务可能存在的问题\n\n- 脏读：读取未提交的事务。\n- 不可重复读：多次读取同一数据，读取的数据不一致。\n- 幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n\n### 事务隔离级别\n\n- READ-UNCOMMITTED：一个事务还没提交时，它做的变更就能被别的事务看到。\n- READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。\n- REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。\n- SERIALIZABLE：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n### 事务隔离的实现\n\n数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n- 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n- 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。\n\n- “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n- “串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n## 事务可见性分析（RR）\n\n事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为**低水位**，最大值加1记为**高水位**。\n\n- row trx_id<低水位：这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n- 低水位<row trx_id<高水位：\n  - 在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；\n  - 不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。\n- row trx_id>高水位：由将来启动的事务生成的，是肯定不可见的；\n\n也可以从事务启动时间来看：\n\n1. 版本未提交，不可见；\n2. 版本已提交，但是是在视图创建后提交的，不可见；\n3. 版本已提交，而且是在视图创建前提交的，可见。\n\n> 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）\n>\n> select * from t where id=1加上lock in share mode 或for update，也是当前读。\n\n## Redo log\n\nRedo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。\n\nRedo log 由两部分组成：\n\n- 内存中的重做日志缓冲（redo log buffer）\n- 重做日志文件（redo log file）\n\n每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：\n\n- 0：表示每次事务提交时都只是把redo log留在**redo log buffer中**;\n- 1（默认值）：表示每次事务提交时都将redo log直接**持久化到磁盘**；\n- 2：表示每次事务提交时都只是把redo log**写到page cache**。\n\n除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。\n\n- redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。\n- 并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。\n\n## Binlog\n\n二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）\n\nBinlog 有以下几个作用：\n\n- 恢复：数据恢复时可以使用二进制日志\n- 复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步\n- 审计：可以通过二进制日志进行审计数据的变更操作\n\nsync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。\n\n- sync_binlog=0，表示每次提交事务都只write，不fsync\n- sync_binlog=1，表示每次提交事务都会执行fsync\n- sync_binlog=N，表示每次提交事务都write，累积N个事务后才fsync\n\n**binlog格式**\n\n- statement：binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用\n- row：binlog里面记录了真实删除行的主键id，不会有主备删除不同行的问题。缺点是很占空间。优点利于恢复数据。\n- mixed格：MySQL自己判断SQL语句是否可能引起主备不一致，是就用row格式，否则就用statement格式。\n\n## redolog和binlog区别\n\n- redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n\n- redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n\n- redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n## 数据库突然断电不丢数据\n\n只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。\n\n## 事务建议\n\n- 循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。\n- 优化事务里的语句顺序，减少锁时间。\n- 关注不同事务访问资源的顺序，避免死锁。\n- 创建事务之前，关注事务隔离级别。\n- 不在事务中混合使用存储引擎（MyISAM无法回滚）\n\n## 分布式事务\n\n分布式事务使用两阶段提交协议：\n第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；\n第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。\n\n### MySQL 自带的分布式事务\n\n```mysql\nxa start 'a','a_1'; //启动分支事务\nxa end 'a','a_1'; //结束分支事务\nxa prepare 'a','a_1'; //进入准备状态\nxa commit 'a','a_1';  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息\n```\n\n","slug":"事务","published":1,"updated":"2021-05-12T12:23:33.154Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss76q0057q4ufxt3s9f1y","content":"<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><p>一个不可分割的数据库操作序列，是数据库并发控制的基本单位。</p>\n<p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>\n<h3 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h3><ul>\n<li>atomicity（原子性） ：要么全执行，要么全都不执行；</li>\n<li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li>\n<li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li>\n<li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li>\n</ul>\n<h3 id=\"并发事务可能存在的问题\"><a href=\"#并发事务可能存在的问题\" class=\"headerlink\" title=\"并发事务可能存在的问题\"></a>并发事务可能存在的问题</h3><ul>\n<li>脏读：读取未提交的事务。</li>\n<li>不可重复读：多次读取同一数据，读取的数据不一致。</li>\n<li>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>\n</ul>\n<h3 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h3><ul>\n<li>READ-UNCOMMITTED：一个事务还没提交时，它做的变更就能被别的事务看到。</li>\n<li>READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。</li>\n<li>REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。</li>\n<li>SERIALIZABLE：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>\n</ul>\n<h3 id=\"事务隔离的实现\"><a href=\"#事务隔离的实现\" class=\"headerlink\" title=\"事务隔离的实现\"></a>事务隔离的实现</h3><p>数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>\n<ul>\n<li><p>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</p>\n</li>\n<li><p>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</p>\n</li>\n<li><p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</p>\n</li>\n<li><p>“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>\n</li>\n</ul>\n<h2 id=\"事务可见性分析（RR）\"><a href=\"#事务可见性分析（RR）\" class=\"headerlink\" title=\"事务可见性分析（RR）\"></a>事务可见性分析（RR）</h2><p>事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为<strong>低水位</strong>，最大值加1记为<strong>高水位</strong>。</p>\n<ul>\n<li>row trx_id&lt;低水位：这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>\n<li>低水位&lt;row trx_id&lt;高水位：<ul>\n<li>在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；</li>\n<li>不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。</li>\n</ul>\n</li>\n<li>row trx_id&gt;高水位：由将来启动的事务生成的，是肯定不可见的；</li>\n</ul>\n<p>也可以从事务启动时间来看：</p>\n<ol>\n<li>版本未提交，不可见；</li>\n<li>版本已提交，但是是在视图创建后提交的，不可见；</li>\n<li>版本已提交，而且是在视图创建前提交的，可见。</li>\n</ol>\n<blockquote>\n<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</p>\n<p>select * from t where id=1加上lock in share mode 或for update，也是当前读。</p>\n</blockquote>\n<h2 id=\"Redo-log\"><a href=\"#Redo-log\" class=\"headerlink\" title=\"Redo log\"></a>Redo log</h2><p>Redo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。</p>\n<p>Redo log 由两部分组成：</p>\n<ul>\n<li>内存中的重做日志缓冲（redo log buffer）</li>\n<li>重做日志文件（redo log file）</li>\n</ul>\n<p>每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：</p>\n<ul>\n<li>0：表示每次事务提交时都只是把redo log留在<strong>redo log buffer中</strong>;</li>\n<li>1（默认值）：表示每次事务提交时都将redo log直接<strong>持久化到磁盘</strong>；</li>\n<li>2：表示每次事务提交时都只是把redo log<strong>写到page cache</strong>。</li>\n</ul>\n<p>除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。</p>\n<ul>\n<li>redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。</li>\n<li>并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。</li>\n</ul>\n<h2 id=\"Binlog\"><a href=\"#Binlog\" class=\"headerlink\" title=\"Binlog\"></a>Binlog</h2><p>二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）</p>\n<p>Binlog 有以下几个作用：</p>\n<ul>\n<li>恢复：数据恢复时可以使用二进制日志</li>\n<li>复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步</li>\n<li>审计：可以通过二进制日志进行审计数据的变更操作</li>\n</ul>\n<p>sync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。</p>\n<ul>\n<li>sync_binlog=0，表示每次提交事务都只write，不fsync</li>\n<li>sync_binlog=1，表示每次提交事务都会执行fsync</li>\n<li>sync_binlog=N，表示每次提交事务都write，累积N个事务后才fsync</li>\n</ul>\n<p><strong>binlog格式</strong></p>\n<ul>\n<li>statement：binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用</li>\n<li>row：binlog里面记录了真实删除行的主键id，不会有主备删除不同行的问题。缺点是很占空间。优点利于恢复数据。</li>\n<li>mixed格：MySQL自己判断SQL语句是否可能引起主备不一致，是就用row格式，否则就用statement格式。</li>\n</ul>\n<h2 id=\"redolog和binlog区别\"><a href=\"#redolog和binlog区别\" class=\"headerlink\" title=\"redolog和binlog区别\"></a>redolog和binlog区别</h2><ul>\n<li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p>\n</li>\n<li><p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</p>\n</li>\n<li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>\n</li>\n</ul>\n<h2 id=\"数据库突然断电不丢数据\"><a href=\"#数据库突然断电不丢数据\" class=\"headerlink\" title=\"数据库突然断电不丢数据\"></a>数据库突然断电不丢数据</h2><p>只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。</p>\n<h2 id=\"事务建议\"><a href=\"#事务建议\" class=\"headerlink\" title=\"事务建议\"></a>事务建议</h2><ul>\n<li>循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。</li>\n<li>优化事务里的语句顺序，减少锁时间。</li>\n<li>关注不同事务访问资源的顺序，避免死锁。</li>\n<li>创建事务之前，关注事务隔离级别。</li>\n<li>不在事务中混合使用存储引擎（MyISAM无法回滚）</li>\n</ul>\n<h2 id=\"分布式事务\"><a href=\"#分布式事务\" class=\"headerlink\" title=\"分布式事务\"></a>分布式事务</h2><p>分布式事务使用两阶段提交协议：<br>第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；<br>第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。</p>\n<h3 id=\"MySQL-自带的分布式事务\"><a href=\"#MySQL-自带的分布式事务\" class=\"headerlink\" title=\"MySQL 自带的分布式事务\"></a>MySQL 自带的分布式事务</h3><pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">xa start 'a','a_1'; //启动分支事务\nxa end 'a','a_1'; //结束分支事务\nxa prepare 'a','a_1'; //进入准备状态\nxa commit 'a','a_1';  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><p>一个不可分割的数据库操作序列，是数据库并发控制的基本单位。</p>\n<p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>\n<h3 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h3><ul>\n<li>atomicity（原子性） ：要么全执行，要么全都不执行；</li>\n<li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li>\n<li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li>\n<li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li>\n</ul>\n<h3 id=\"并发事务可能存在的问题\"><a href=\"#并发事务可能存在的问题\" class=\"headerlink\" title=\"并发事务可能存在的问题\"></a>并发事务可能存在的问题</h3><ul>\n<li>脏读：读取未提交的事务。</li>\n<li>不可重复读：多次读取同一数据，读取的数据不一致。</li>\n<li>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>\n</ul>\n<h3 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h3><ul>\n<li>READ-UNCOMMITTED：一个事务还没提交时，它做的变更就能被别的事务看到。</li>\n<li>READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。</li>\n<li>REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。</li>\n<li>SERIALIZABLE：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>\n</ul>\n<h3 id=\"事务隔离的实现\"><a href=\"#事务隔离的实现\" class=\"headerlink\" title=\"事务隔离的实现\"></a>事务隔离的实现</h3><p>数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>\n<ul>\n<li><p>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</p>\n</li>\n<li><p>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</p>\n</li>\n<li><p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</p>\n</li>\n<li><p>“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>\n</li>\n</ul>\n<h2 id=\"事务可见性分析（RR）\"><a href=\"#事务可见性分析（RR）\" class=\"headerlink\" title=\"事务可见性分析（RR）\"></a>事务可见性分析（RR）</h2><p>事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为<strong>低水位</strong>，最大值加1记为<strong>高水位</strong>。</p>\n<ul>\n<li>row trx_id&lt;低水位：这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>\n<li>低水位&lt;row trx_id&lt;高水位：<ul>\n<li>在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；</li>\n<li>不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。</li>\n</ul>\n</li>\n<li>row trx_id&gt;高水位：由将来启动的事务生成的，是肯定不可见的；</li>\n</ul>\n<p>也可以从事务启动时间来看：</p>\n<ol>\n<li>版本未提交，不可见；</li>\n<li>版本已提交，但是是在视图创建后提交的，不可见；</li>\n<li>版本已提交，而且是在视图创建前提交的，可见。</li>\n</ol>\n<blockquote>\n<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</p>\n<p>select * from t where id=1加上lock in share mode 或for update，也是当前读。</p>\n</blockquote>\n<h2 id=\"Redo-log\"><a href=\"#Redo-log\" class=\"headerlink\" title=\"Redo log\"></a>Redo log</h2><p>Redo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。</p>\n<p>Redo log 由两部分组成：</p>\n<ul>\n<li>内存中的重做日志缓冲（redo log buffer）</li>\n<li>重做日志文件（redo log file）</li>\n</ul>\n<p>每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：</p>\n<ul>\n<li>0：表示每次事务提交时都只是把redo log留在<strong>redo log buffer中</strong>;</li>\n<li>1（默认值）：表示每次事务提交时都将redo log直接<strong>持久化到磁盘</strong>；</li>\n<li>2：表示每次事务提交时都只是把redo log<strong>写到page cache</strong>。</li>\n</ul>\n<p>除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。</p>\n<ul>\n<li>redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。</li>\n<li>并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。</li>\n</ul>\n<h2 id=\"Binlog\"><a href=\"#Binlog\" class=\"headerlink\" title=\"Binlog\"></a>Binlog</h2><p>二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）</p>\n<p>Binlog 有以下几个作用：</p>\n<ul>\n<li>恢复：数据恢复时可以使用二进制日志</li>\n<li>复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步</li>\n<li>审计：可以通过二进制日志进行审计数据的变更操作</li>\n</ul>\n<p>sync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。</p>\n<ul>\n<li>sync_binlog=0，表示每次提交事务都只write，不fsync</li>\n<li>sync_binlog=1，表示每次提交事务都会执行fsync</li>\n<li>sync_binlog=N，表示每次提交事务都write，累积N个事务后才fsync</li>\n</ul>\n<p><strong>binlog格式</strong></p>\n<ul>\n<li>statement：binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用</li>\n<li>row：binlog里面记录了真实删除行的主键id，不会有主备删除不同行的问题。缺点是很占空间。优点利于恢复数据。</li>\n<li>mixed格：MySQL自己判断SQL语句是否可能引起主备不一致，是就用row格式，否则就用statement格式。</li>\n</ul>\n<h2 id=\"redolog和binlog区别\"><a href=\"#redolog和binlog区别\" class=\"headerlink\" title=\"redolog和binlog区别\"></a>redolog和binlog区别</h2><ul>\n<li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p>\n</li>\n<li><p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</p>\n</li>\n<li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>\n</li>\n</ul>\n<h2 id=\"数据库突然断电不丢数据\"><a href=\"#数据库突然断电不丢数据\" class=\"headerlink\" title=\"数据库突然断电不丢数据\"></a>数据库突然断电不丢数据</h2><p>只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。</p>\n<h2 id=\"事务建议\"><a href=\"#事务建议\" class=\"headerlink\" title=\"事务建议\"></a>事务建议</h2><ul>\n<li>循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。</li>\n<li>优化事务里的语句顺序，减少锁时间。</li>\n<li>关注不同事务访问资源的顺序，避免死锁。</li>\n<li>创建事务之前，关注事务隔离级别。</li>\n<li>不在事务中混合使用存储引擎（MyISAM无法回滚）</li>\n</ul>\n<h2 id=\"分布式事务\"><a href=\"#分布式事务\" class=\"headerlink\" title=\"分布式事务\"></a>分布式事务</h2><p>分布式事务使用两阶段提交协议：<br>第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；<br>第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。</p>\n<h3 id=\"MySQL-自带的分布式事务\"><a href=\"#MySQL-自带的分布式事务\" class=\"headerlink\" title=\"MySQL 自带的分布式事务\"></a>MySQL 自带的分布式事务</h3><pre><code class=\"mysql\">xa start &#39;a&#39;,&#39;a_1&#39;; //启动分支事务\nxa end &#39;a&#39;,&#39;a_1&#39;; //结束分支事务\nxa prepare &#39;a&#39;,&#39;a_1&#39;; //进入准备状态\nxa commit &#39;a&#39;,&#39;a_1&#39;;  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息</code></pre>\n"},{"title":"redis面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-12T11:16:53.000Z","password":null,"summary":"主要内容转载自https://thinkwon.blog.csdn.net/article/details/103522351","_content":"\n## 概述\n\n### 什么是Redis\n\nRedis（Remote Dictionary Server） 是一个使用 C 语言编写的，**开源的高性能非关系型（NoSQL）的键值对数据库**。\n\n**Redis 可以存储键和五种不同类型的值之间的映射**。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。\n\n Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应**用于缓存方向**，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。\n\n### Redis有哪些优缺点\n\n**优点**\n\n> **读写性能优异，** Redis能读的速度是110000次/s，写的速度是81000次/s。\n> **支持数据持久化**，支持AOF和RDB两种持久化方式。\n> **支持事务**，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。\n> **数据结构丰富**，支持string、hash、set、zset、list等数据结构。\n> **支持主从复制**，主机会自动将数据同步到从机，支持读写分离。\n\n**缺点**\n\n> 数据库**容量受到物理内存的限制**，不能用作海量数据的高性能读写，适合的场景主要局限在较小数据量的高性能操作和运算上。\n> Redis **不具备自动容错和恢复功能**，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。\n> 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后会引入数据不一致的问题。\n> Redis 较难支持在线扩容，在集群容量达到上限时**在线扩容会变得很复杂**。\n\n### 为什么要用 Redis 而不用 map/guava 做缓存?\n\nJava 自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。\n\n使用 redis 或 memcached 之类的分布式缓存，在多实例的情况下，**各实例共用一份缓存数据，缓存具有一致性**。\n\n### Redis为什么这么快\n\n一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。\n\n另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。\n\n**IO多路复用模型**\n\nLinux 中的 IO 多路复用机制是指一个线程处理多个 IO 流-- select/epoll 机制。\n\n在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。\n\n内核会一直监听这些套接字上的连接请求或数据请求。select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。\n\nredis不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。\n\n> select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。\n\n## 数据类型\n\n### Redis有哪些数据类型\n\nRedis主要有5种数据类型，包括String，List，Set，Zset，Hash.\n\n| 数据类型 | 可存储的值             | 操作                                                         | 应用场景                                                     |\n| -------- | ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作                   | 整数和浮点数自增减操作；键值对缓存                           |\n| LIST     | 列表                   | 从两端压入或者弹出元素;对单个或者多个元素进行修剪，只保留一个范围内的元素 | 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据 |\n| SET      | 无序集合               | 添加、获取、移除单个元素;检查一个元素是否存在于集合中;计算交集、并集、差集 | 可以把两个人的粉丝列表整一个交集                             |\n| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对;获取所有键值对;检查某个键是否存在 | 结构化的数据，比如一个对象                                   |\n| ZSET     | 有序集合               | 添加、获取、删除元素;根据分值范围或者成员来获取元素;计算一个键的排名 | 去重但可以排序，如获取排名前几名的用户                       |\n\n### Redis的应用场景\n\n#### 总结一\n\n**计数器**\n\n可以对 String 进行自增自减运算，从而实现计数器功能。Redis 读写性能非常高，适合存储频繁读写的计数量。\n\n**缓存**\n\n将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n\n**会话缓存**\n\n统一存储多台应用服务器的会话信息。\n\n**全页缓存（FPC）**\n\nRedis还提供很简便的全页缓存平台。Magento提供一个插件来使用Redis作为全页缓存后端。WordPress，使用插件 wp-redis，以最快速度加载曾浏览过的页面。\n\n**查找表**\n\n例如 DNS 记录就很适合使用 Redis 进行存储。利用了 Redis 快速的查找特性。但是查找表的内容不能失效，因为缓存不作为可靠的数据来源。\n\n**消息队列(发布/订阅功能)**\n\nList 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。\n\n**其它**\n\nSet 可以实现交集、并集等操作，从而实现共同好友等功能。\n\nZSet 可以实现有序性操作，从而**实现排行榜**等功能。\n\n## 持久化\n\n### 什么是Redis持久化？\n\n持久化就是把内存的数据写到磁盘中去，防止服务宕机了，内存数据丢失。\n\n### Redis 的持久化机制是什么？各自的优缺点？\n\nRedis 提供两种持久化机制 RDB（默认） 和 AOF 机制。\n\n**RDB（Redis DataBase）：**\n\nRedis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中。\n\n**优点：**\n1、性能最大化，**fork 子进程来完成写操作**，主进程不会进行任何 IO 操作，保证了 redis 的高性能\n2、比 AOF 的启动效率更高。\n**缺点：**\n\n1、如果两次持久化之间 发生故障，会导致数据丢失。\n\n**AOF持久化（Append Only File）**\n\n将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。\n\n**优点：**\n\n1、**支持每进行一次 命令操作就记录到 aof 文件中一次。**\n2、**AOF 机制的 rewrite 模式。**AOF 文件没被 rewrite 之前，可以删除其中的某些命令\n**缺点：**\n\n1、AOF 文件比 RDB 文件大，且恢复速度慢。\n2、数据集大的时候，比 rdb 启动效率低。\n\n### 如何选择合适的持久化方式\n\n**同时使用两种持久化功能**。当 Redis 重启的时候会**优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整**。\n\n如果可以**承受数分钟以内的数据丢失**，可以**只使用RDB持久化**。\n\n如果你只希望你的**数据在服务器运行的时候存在，可以不使用任何持久化方式**。\n\n### Redis持久化数据和缓存怎么做扩容？\n\n如果Redis被当做缓存使用，使用**一致性哈希实现动态扩容缩容**。\n\n如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。\n\n## 过期键的删除策略\n\n### Redis的过期键的删除策略\n\n\n**惰性过期：**只有当访问一个key时，才会判断它是否已过期，过期则清除。该策略可以节省CPU资源，极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。\n**定期过期：**每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。\n**Redis中同时使用了惰性过期和定期过期两种过期策略。**\n\n### Redis key的过期时间和永久有效分别怎么设置？\n\nEXPIRE和PERSIST命令。\n\n## 内存相关\n\n### MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\n\nredis内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。\n\n### Redis的内存淘汰策略有哪些\n\n**全局的键空间选择性移除**\nallkeys-lru：移除最近最少使用的key。\n\nallkeys-lfu：所有键根据数据的被访问次数和访问时效性，进行移除\n\nallkeys-random：随机移除某个key。\n**设置过期时间的键空间选择性移除**\n\nvolatile-lru：在设置了过期时间的键中，移除最近最少使用的key。\n\nvolatile-lfu：在设置了过期时间的键中，根据数据的被访问次数和访问时效性，进行移除\n\nvolatile-random：在设置了过期时间的键中，随机移除某个key。\nvolatile-ttl：在设置了过期时间的键中，有更早过期时间的key优先移除。\n\n### Redis的内存用完了会发生什么？\n\n如果达到设置的上限，Redis的写命令会返回错误信息。或者配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。\n\n### Redis如何做内存优化？？？\n\n可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hash），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面\n\n## 线程模型\n\n### Redis线程模型\n\nRedis基于Reactor模式开发了网络事件处理器（文件事件处理器）。它的组成结构包括：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。\n\n文件事件处理器使用 I/O 多路复用程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。\n当被监听的套接字执行连接应答、读取、写入、关闭等操作时， 对应的文件事件就会产生， 文件事件处理器调用已关联好的事件处理器来处理。\n\n参考：https://www.cnblogs.com/barrywxx/p/8570821.html\n\n## 事务\n\n### 什么是事务？\n\n事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\n### Redis事务的概念\n\nRedis 事务是通过MULTI、EXEC、WATCH等命令完成。\n\n事务支持一次执行多个命令。\n\n在事务执行过程，会按照顺序执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n\n### Redis事务的三个阶段\n\n1. 事务开始 MULTI\n2. 命令入队\n3. 事务执行 EXEC\n\n事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队\n\n### Redis事务相关命令\n\nRedis 在事务失败时不支持回滚，而是继续执行余下的命令\n如果事务中的命令**出现错误，那么所有的命令都不会执行**；\n如果事务中出现**运行错误，那么正确的命令会被执行**。\n\n**WATCH 命令是一个乐观锁**，可以为 Redis 事务提供CAS。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。\n**MULTI命令用于开启一个事务**。 MULTI执行之后，客户端可向服务器发送任意多条命令，这些命令会被放到一个队列中，当EXEC被调用时，队列中的命令才会被执行。\n**EXEC：执行所有事务块内的命令**。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。\n通过调用**DISCARD**，客户端可以**清空事务队列，并放弃执行事务**。\n**UNWATCH命令可以取消watch对所有key的监控**。\n\n### 事务管理（ACID）概述\n\n- 原子性（Atomicity）\n  原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n\n- **一致性（Consistency）**\n  **事务前后数据的完整性必须保持一致。**\n\n- **隔离性（Isolation）**\n  **多个事务并发执行时，一个事务的执行不应影响其他事务的执行**\n\n- 持久性（Durability）\n  持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响\n\nRedis的事务具备**一致性和隔离性**。AOF持久化模式下且appendfsync为always时，事务也具有持久性。\n\n### Redis事务支持隔离性吗\n\n支持。Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。\n\n### Redis事务保证原子性吗，支持回滚吗\n\n单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令可能仍会被执行。\n\n### Redis事务其他实现\n\n- 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行\n\n## 集群\n\n### 哨兵（sentinel）模式\n\n**主要功能**\n\n- 集群监控：负责监控 redis master 和 slave 进程是否正常工作。\n- 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。\n- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。\n- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。\n\n### **redis 集群模式的工作原理？在集群模式下，redis 的 key 如何寻址的？分布式寻址都有哪些算法？一致性 hash 算法？**\n\n**简介**\n\n- Redis Cluster是一种服务端Sharding技术。\n\n- 每个key通过CRC16校验后对16384取模来决定放置哪个槽。每个节点存储一定哈希槽的数据，默认分配了16384 个槽位\n- 每份数据分片会存储在多个互为主从的多节点上\n- 数据写入先写主节点，再同步到从节点\n- 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点\n\n**节点间的内部通信机制**\n\nredis 节点间采用 gossip 协议进行通信。\n\n**分布式寻址算法**\n\n- hash 算法（大量缓存重建）\n- 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）\n- redis cluster 的 哈希槽算法\n\n**优点**\n\n- 无中心架构，支持动态扩容，对业务透明\n- 具备Sentinel的监控和自动Failover能力\n- 高性能，客户端直连redis服务，免去了proxy代理的损耗\n\n**缺点**\n\n- 只能使用0号数据库\n- 不支持批量操作(pipeline管道操作)\n\n### Redis 主从架构\n\n**redis replication 的核心机制**\n\n- 采用异步方式复制数据到 slave 节点，\n- 一个 master node 是可以配置多个 slave node 的；\n- slave node 主要用来做读写分离，提高读的吞吐量。\n\n**主从复制原理**\n\n- 当从库和主库建立MS关系后，会向主数据库发送SYNC命令\n- 主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来\n- 当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis\n- 从Redis接收到后，会载入快照文件并且执行收到的缓存的命令\n- 之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致性\n\n**缺点**\n\n可能会造成master节点压力太大，使用主从从结构来解决\n\n## 分区\n\n### Redis是单线程的，如何提高多核CPU的利用率？\n\n- 可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用。\n- 把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上\n- 把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。\n\n### 为什么要做Redis分区？\n\n分区可以让Redis管理更大的内存。\n\nRDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。\n\n### Redis分区有什么缺点？\n\n- 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例。\n- 同时操作多个key，则不能使用Redis事务.\n\n## 分布式问题\n\n### Redis实现分布式锁\n\n**加锁**\n\n- `SET key value [EX seconds | PX milliseconds]  [NX]`\n\n- key 不存在， key 会被创建。\n\n- Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。\n- 过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。\n\n**解锁**\n\n执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。\n\n**缺点**\n\n- 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。\n- 即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。\n- Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。\n\n**优点**\n\n Redis 的性能很高，可以支撑高并发的获取、释放锁操作\n\n## Zookeeper 实现\n\n- 使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。\n- 创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。\n- 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。\n- 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。\n\n**优点**\n\n- ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。\n- 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。\n\n**缺点**\n\n如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。\n\n### 分布式Redis是前期做还是后期规模上来了再做好？为什么？\n\n一开始就多设置几个Redis实例，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是**仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）**。\n\n### 什么是 RedLock\n\n分布式锁算法 Redlock\n\n- 客户端获取当前时间。\n- 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n- 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功\n\n- 别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。\n\n**缺点**\n\n无法保证加锁的过程一定正确\n\n## 缓存异常\n\nhttps://wangyixin-tom.github.io/2020/10/27/redis-huan-cun\n\n### 缓存预热\n\n缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存\n\n**解决方案**\n\n- 统计出频率较高的热数据，直接写个缓存刷新页面，上线时手工操作一下；\n\n### 热点数据和冷数据\n\n**热点数据，缓存才有价值**\n\n冷数据可能还没有再次访问到就已经被挤出内存，不仅**占用内存，而且价值不大**。\n\n**数据更新前至少读取两次，缓存才有意义**。这个是最基本的策略\n\n### **缓存热点key**过期\n\n一般都会从后端DB加载数据并回设到缓存，大并发的请求可能会瞬间把后端DB压垮。\n\n**解决方案**\n\n对缓存查询加锁：如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；\n\n其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询\n\n## 其他问题\n\n### Redis与Memcached的区别\n\n两者都是非关系型内存键值数据库，现在一般都是用 Redis 来实现缓存， 主要不同：\n(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型\n\n(2) redis的速度比memcached快很多\n\n(3) redis可以持久化其数据\n\n### 如何保证缓存与数据库双写时的数据一致性？\n\n**先更新数据库，然后再删除缓存**会暂时产生短暂不一致的情况，但是发生的几率特别小\n\n### Redis常见性能问题和解决方案？\n\n- Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。\n- 如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。\n\n- 为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。\n- 尽量避免在压力较大的主库上增加从库\n\n### 一个字符串类型的值能存储最大容量是多少？\n\n512M\n\n### Redis如何做大量数据插入？\n\npipe mode的新模式用于执行大量数据插入工作。\n\n### 找出Redis里面有10w个key是以某个固定的已知的前缀开头的\n\n这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。\n\n### 使用Redis做过异步队列吗，是如何实现的\n\n使用list类型保存数据信息，rpush生产消息，\n\n使用blpop消费消息, 在没有信息的时候，会一直阻塞，直到信息的到来。\n\nredis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。\n\n### Redis如何实现延时队列\n\n使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。\n\n### Redis回收进程如何工作的？\n\nRedis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。","source":"_posts/redis面试.md","raw":"---\ntitle: redis面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-12 19:16:53\npassword:\nsummary: 主要内容转载自https://thinkwon.blog.csdn.net/article/details/103522351\ntags:\n- interview\ncategories:\n- interview\n---\n\n## 概述\n\n### 什么是Redis\n\nRedis（Remote Dictionary Server） 是一个使用 C 语言编写的，**开源的高性能非关系型（NoSQL）的键值对数据库**。\n\n**Redis 可以存储键和五种不同类型的值之间的映射**。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。\n\n Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应**用于缓存方向**，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。\n\n### Redis有哪些优缺点\n\n**优点**\n\n> **读写性能优异，** Redis能读的速度是110000次/s，写的速度是81000次/s。\n> **支持数据持久化**，支持AOF和RDB两种持久化方式。\n> **支持事务**，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。\n> **数据结构丰富**，支持string、hash、set、zset、list等数据结构。\n> **支持主从复制**，主机会自动将数据同步到从机，支持读写分离。\n\n**缺点**\n\n> 数据库**容量受到物理内存的限制**，不能用作海量数据的高性能读写，适合的场景主要局限在较小数据量的高性能操作和运算上。\n> Redis **不具备自动容错和恢复功能**，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。\n> 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后会引入数据不一致的问题。\n> Redis 较难支持在线扩容，在集群容量达到上限时**在线扩容会变得很复杂**。\n\n### 为什么要用 Redis 而不用 map/guava 做缓存?\n\nJava 自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。\n\n使用 redis 或 memcached 之类的分布式缓存，在多实例的情况下，**各实例共用一份缓存数据，缓存具有一致性**。\n\n### Redis为什么这么快\n\n一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。\n\n另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。\n\n**IO多路复用模型**\n\nLinux 中的 IO 多路复用机制是指一个线程处理多个 IO 流-- select/epoll 机制。\n\n在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。\n\n内核会一直监听这些套接字上的连接请求或数据请求。select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。\n\nredis不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。\n\n> select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。\n\n## 数据类型\n\n### Redis有哪些数据类型\n\nRedis主要有5种数据类型，包括String，List，Set，Zset，Hash.\n\n| 数据类型 | 可存储的值             | 操作                                                         | 应用场景                                                     |\n| -------- | ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作                   | 整数和浮点数自增减操作；键值对缓存                           |\n| LIST     | 列表                   | 从两端压入或者弹出元素;对单个或者多个元素进行修剪，只保留一个范围内的元素 | 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据 |\n| SET      | 无序集合               | 添加、获取、移除单个元素;检查一个元素是否存在于集合中;计算交集、并集、差集 | 可以把两个人的粉丝列表整一个交集                             |\n| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对;获取所有键值对;检查某个键是否存在 | 结构化的数据，比如一个对象                                   |\n| ZSET     | 有序集合               | 添加、获取、删除元素;根据分值范围或者成员来获取元素;计算一个键的排名 | 去重但可以排序，如获取排名前几名的用户                       |\n\n### Redis的应用场景\n\n#### 总结一\n\n**计数器**\n\n可以对 String 进行自增自减运算，从而实现计数器功能。Redis 读写性能非常高，适合存储频繁读写的计数量。\n\n**缓存**\n\n将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n\n**会话缓存**\n\n统一存储多台应用服务器的会话信息。\n\n**全页缓存（FPC）**\n\nRedis还提供很简便的全页缓存平台。Magento提供一个插件来使用Redis作为全页缓存后端。WordPress，使用插件 wp-redis，以最快速度加载曾浏览过的页面。\n\n**查找表**\n\n例如 DNS 记录就很适合使用 Redis 进行存储。利用了 Redis 快速的查找特性。但是查找表的内容不能失效，因为缓存不作为可靠的数据来源。\n\n**消息队列(发布/订阅功能)**\n\nList 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。\n\n**其它**\n\nSet 可以实现交集、并集等操作，从而实现共同好友等功能。\n\nZSet 可以实现有序性操作，从而**实现排行榜**等功能。\n\n## 持久化\n\n### 什么是Redis持久化？\n\n持久化就是把内存的数据写到磁盘中去，防止服务宕机了，内存数据丢失。\n\n### Redis 的持久化机制是什么？各自的优缺点？\n\nRedis 提供两种持久化机制 RDB（默认） 和 AOF 机制。\n\n**RDB（Redis DataBase）：**\n\nRedis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中。\n\n**优点：**\n1、性能最大化，**fork 子进程来完成写操作**，主进程不会进行任何 IO 操作，保证了 redis 的高性能\n2、比 AOF 的启动效率更高。\n**缺点：**\n\n1、如果两次持久化之间 发生故障，会导致数据丢失。\n\n**AOF持久化（Append Only File）**\n\n将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。\n\n**优点：**\n\n1、**支持每进行一次 命令操作就记录到 aof 文件中一次。**\n2、**AOF 机制的 rewrite 模式。**AOF 文件没被 rewrite 之前，可以删除其中的某些命令\n**缺点：**\n\n1、AOF 文件比 RDB 文件大，且恢复速度慢。\n2、数据集大的时候，比 rdb 启动效率低。\n\n### 如何选择合适的持久化方式\n\n**同时使用两种持久化功能**。当 Redis 重启的时候会**优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整**。\n\n如果可以**承受数分钟以内的数据丢失**，可以**只使用RDB持久化**。\n\n如果你只希望你的**数据在服务器运行的时候存在，可以不使用任何持久化方式**。\n\n### Redis持久化数据和缓存怎么做扩容？\n\n如果Redis被当做缓存使用，使用**一致性哈希实现动态扩容缩容**。\n\n如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。\n\n## 过期键的删除策略\n\n### Redis的过期键的删除策略\n\n\n**惰性过期：**只有当访问一个key时，才会判断它是否已过期，过期则清除。该策略可以节省CPU资源，极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。\n**定期过期：**每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。\n**Redis中同时使用了惰性过期和定期过期两种过期策略。**\n\n### Redis key的过期时间和永久有效分别怎么设置？\n\nEXPIRE和PERSIST命令。\n\n## 内存相关\n\n### MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\n\nredis内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。\n\n### Redis的内存淘汰策略有哪些\n\n**全局的键空间选择性移除**\nallkeys-lru：移除最近最少使用的key。\n\nallkeys-lfu：所有键根据数据的被访问次数和访问时效性，进行移除\n\nallkeys-random：随机移除某个key。\n**设置过期时间的键空间选择性移除**\n\nvolatile-lru：在设置了过期时间的键中，移除最近最少使用的key。\n\nvolatile-lfu：在设置了过期时间的键中，根据数据的被访问次数和访问时效性，进行移除\n\nvolatile-random：在设置了过期时间的键中，随机移除某个key。\nvolatile-ttl：在设置了过期时间的键中，有更早过期时间的key优先移除。\n\n### Redis的内存用完了会发生什么？\n\n如果达到设置的上限，Redis的写命令会返回错误信息。或者配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。\n\n### Redis如何做内存优化？？？\n\n可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hash），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面\n\n## 线程模型\n\n### Redis线程模型\n\nRedis基于Reactor模式开发了网络事件处理器（文件事件处理器）。它的组成结构包括：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。\n\n文件事件处理器使用 I/O 多路复用程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。\n当被监听的套接字执行连接应答、读取、写入、关闭等操作时， 对应的文件事件就会产生， 文件事件处理器调用已关联好的事件处理器来处理。\n\n参考：https://www.cnblogs.com/barrywxx/p/8570821.html\n\n## 事务\n\n### 什么是事务？\n\n事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\n### Redis事务的概念\n\nRedis 事务是通过MULTI、EXEC、WATCH等命令完成。\n\n事务支持一次执行多个命令。\n\n在事务执行过程，会按照顺序执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n\n### Redis事务的三个阶段\n\n1. 事务开始 MULTI\n2. 命令入队\n3. 事务执行 EXEC\n\n事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队\n\n### Redis事务相关命令\n\nRedis 在事务失败时不支持回滚，而是继续执行余下的命令\n如果事务中的命令**出现错误，那么所有的命令都不会执行**；\n如果事务中出现**运行错误，那么正确的命令会被执行**。\n\n**WATCH 命令是一个乐观锁**，可以为 Redis 事务提供CAS。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。\n**MULTI命令用于开启一个事务**。 MULTI执行之后，客户端可向服务器发送任意多条命令，这些命令会被放到一个队列中，当EXEC被调用时，队列中的命令才会被执行。\n**EXEC：执行所有事务块内的命令**。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。\n通过调用**DISCARD**，客户端可以**清空事务队列，并放弃执行事务**。\n**UNWATCH命令可以取消watch对所有key的监控**。\n\n### 事务管理（ACID）概述\n\n- 原子性（Atomicity）\n  原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n\n- **一致性（Consistency）**\n  **事务前后数据的完整性必须保持一致。**\n\n- **隔离性（Isolation）**\n  **多个事务并发执行时，一个事务的执行不应影响其他事务的执行**\n\n- 持久性（Durability）\n  持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响\n\nRedis的事务具备**一致性和隔离性**。AOF持久化模式下且appendfsync为always时，事务也具有持久性。\n\n### Redis事务支持隔离性吗\n\n支持。Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。\n\n### Redis事务保证原子性吗，支持回滚吗\n\n单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令可能仍会被执行。\n\n### Redis事务其他实现\n\n- 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行\n\n## 集群\n\n### 哨兵（sentinel）模式\n\n**主要功能**\n\n- 集群监控：负责监控 redis master 和 slave 进程是否正常工作。\n- 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。\n- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。\n- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。\n\n### **redis 集群模式的工作原理？在集群模式下，redis 的 key 如何寻址的？分布式寻址都有哪些算法？一致性 hash 算法？**\n\n**简介**\n\n- Redis Cluster是一种服务端Sharding技术。\n\n- 每个key通过CRC16校验后对16384取模来决定放置哪个槽。每个节点存储一定哈希槽的数据，默认分配了16384 个槽位\n- 每份数据分片会存储在多个互为主从的多节点上\n- 数据写入先写主节点，再同步到从节点\n- 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点\n\n**节点间的内部通信机制**\n\nredis 节点间采用 gossip 协议进行通信。\n\n**分布式寻址算法**\n\n- hash 算法（大量缓存重建）\n- 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）\n- redis cluster 的 哈希槽算法\n\n**优点**\n\n- 无中心架构，支持动态扩容，对业务透明\n- 具备Sentinel的监控和自动Failover能力\n- 高性能，客户端直连redis服务，免去了proxy代理的损耗\n\n**缺点**\n\n- 只能使用0号数据库\n- 不支持批量操作(pipeline管道操作)\n\n### Redis 主从架构\n\n**redis replication 的核心机制**\n\n- 采用异步方式复制数据到 slave 节点，\n- 一个 master node 是可以配置多个 slave node 的；\n- slave node 主要用来做读写分离，提高读的吞吐量。\n\n**主从复制原理**\n\n- 当从库和主库建立MS关系后，会向主数据库发送SYNC命令\n- 主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来\n- 当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis\n- 从Redis接收到后，会载入快照文件并且执行收到的缓存的命令\n- 之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致性\n\n**缺点**\n\n可能会造成master节点压力太大，使用主从从结构来解决\n\n## 分区\n\n### Redis是单线程的，如何提高多核CPU的利用率？\n\n- 可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用。\n- 把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上\n- 把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。\n\n### 为什么要做Redis分区？\n\n分区可以让Redis管理更大的内存。\n\nRDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。\n\n### Redis分区有什么缺点？\n\n- 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例。\n- 同时操作多个key，则不能使用Redis事务.\n\n## 分布式问题\n\n### Redis实现分布式锁\n\n**加锁**\n\n- `SET key value [EX seconds | PX milliseconds]  [NX]`\n\n- key 不存在， key 会被创建。\n\n- Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。\n- 过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。\n\n**解锁**\n\n执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。\n\n**缺点**\n\n- 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。\n- 即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。\n- Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。\n\n**优点**\n\n Redis 的性能很高，可以支撑高并发的获取、释放锁操作\n\n## Zookeeper 实现\n\n- 使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。\n- 创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。\n- 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。\n- 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。\n\n**优点**\n\n- ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。\n- 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。\n\n**缺点**\n\n如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。\n\n### 分布式Redis是前期做还是后期规模上来了再做好？为什么？\n\n一开始就多设置几个Redis实例，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是**仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）**。\n\n### 什么是 RedLock\n\n分布式锁算法 Redlock\n\n- 客户端获取当前时间。\n- 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n- 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功\n\n- 别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。\n\n**缺点**\n\n无法保证加锁的过程一定正确\n\n## 缓存异常\n\nhttps://wangyixin-tom.github.io/2020/10/27/redis-huan-cun\n\n### 缓存预热\n\n缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存\n\n**解决方案**\n\n- 统计出频率较高的热数据，直接写个缓存刷新页面，上线时手工操作一下；\n\n### 热点数据和冷数据\n\n**热点数据，缓存才有价值**\n\n冷数据可能还没有再次访问到就已经被挤出内存，不仅**占用内存，而且价值不大**。\n\n**数据更新前至少读取两次，缓存才有意义**。这个是最基本的策略\n\n### **缓存热点key**过期\n\n一般都会从后端DB加载数据并回设到缓存，大并发的请求可能会瞬间把后端DB压垮。\n\n**解决方案**\n\n对缓存查询加锁：如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；\n\n其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询\n\n## 其他问题\n\n### Redis与Memcached的区别\n\n两者都是非关系型内存键值数据库，现在一般都是用 Redis 来实现缓存， 主要不同：\n(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型\n\n(2) redis的速度比memcached快很多\n\n(3) redis可以持久化其数据\n\n### 如何保证缓存与数据库双写时的数据一致性？\n\n**先更新数据库，然后再删除缓存**会暂时产生短暂不一致的情况，但是发生的几率特别小\n\n### Redis常见性能问题和解决方案？\n\n- Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。\n- 如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。\n\n- 为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。\n- 尽量避免在压力较大的主库上增加从库\n\n### 一个字符串类型的值能存储最大容量是多少？\n\n512M\n\n### Redis如何做大量数据插入？\n\npipe mode的新模式用于执行大量数据插入工作。\n\n### 找出Redis里面有10w个key是以某个固定的已知的前缀开头的\n\n这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。\n\n### 使用Redis做过异步队列吗，是如何实现的\n\n使用list类型保存数据信息，rpush生产消息，\n\n使用blpop消费消息, 在没有信息的时候，会一直阻塞，直到信息的到来。\n\nredis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。\n\n### Redis如何实现延时队列\n\n使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。\n\n### Redis回收进程如何工作的？\n\nRedis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。","slug":"redis面试","published":1,"updated":"2021-05-19T11:09:42.133Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss76v005aq4uf7es8o8pb","content":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><h3 id=\"什么是Redis\"><a href=\"#什么是Redis\" class=\"headerlink\" title=\"什么是Redis\"></a>什么是Redis</h3><p>Redis（Remote Dictionary Server） 是一个使用 C 语言编写的，<strong>开源的高性能非关系型（NoSQL）的键值对数据库</strong>。</p>\n<p><strong>Redis 可以存储键和五种不同类型的值之间的映射</strong>。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p>\n<p> Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应<strong>用于缓存方向</strong>，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。</p>\n<h3 id=\"Redis有哪些优缺点\"><a href=\"#Redis有哪些优缺点\" class=\"headerlink\" title=\"Redis有哪些优缺点\"></a>Redis有哪些优缺点</h3><p><strong>优点</strong></p>\n<blockquote>\n<p><strong>读写性能优异，</strong> Redis能读的速度是110000次/s，写的速度是81000次/s。<br><strong>支持数据持久化</strong>，支持AOF和RDB两种持久化方式。<br><strong>支持事务</strong>，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。<br><strong>数据结构丰富</strong>，支持string、hash、set、zset、list等数据结构。<br><strong>支持主从复制</strong>，主机会自动将数据同步到从机，支持读写分离。</p>\n</blockquote>\n<p><strong>缺点</strong></p>\n<blockquote>\n<p>数据库<strong>容量受到物理内存的限制</strong>，不能用作海量数据的高性能读写，适合的场景主要局限在较小数据量的高性能操作和运算上。<br>Redis <strong>不具备自动容错和恢复功能</strong>，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。<br>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后会引入数据不一致的问题。<br>Redis 较难支持在线扩容，在集群容量达到上限时<strong>在线扩容会变得很复杂</strong>。</p>\n</blockquote>\n<h3 id=\"为什么要用-Redis-而不用-map-guava-做缓存\"><a href=\"#为什么要用-Redis-而不用-map-guava-做缓存\" class=\"headerlink\" title=\"为什么要用 Redis 而不用 map/guava 做缓存?\"></a>为什么要用 Redis 而不用 map/guava 做缓存?</h3><p>Java 自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>\n<p>使用 redis 或 memcached 之类的分布式缓存，在多实例的情况下，<strong>各实例共用一份缓存数据，缓存具有一致性</strong>。</p>\n<h3 id=\"Redis为什么这么快\"><a href=\"#Redis为什么这么快\" class=\"headerlink\" title=\"Redis为什么这么快\"></a>Redis为什么这么快</h3><p>一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。</p>\n<p>另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p>\n<p><strong>IO多路复用模型</strong></p>\n<p>Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流– select/epoll 机制。</p>\n<p>在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。</p>\n<p>内核会一直监听这些套接字上的连接请求或数据请求。select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。</p>\n<p>redis不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p>\n<blockquote>\n<p>select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>\n</blockquote>\n<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><h3 id=\"Redis有哪些数据类型\"><a href=\"#Redis有哪些数据类型\" class=\"headerlink\" title=\"Redis有哪些数据类型\"></a>Redis有哪些数据类型</h3><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash.</p>\n<table>\n<thead>\n<tr>\n<th>数据类型</th>\n<th>可存储的值</th>\n<th>操作</th>\n<th>应用场景</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>STRING</td>\n<td>字符串、整数或者浮点数</td>\n<td>对整个字符串或者字符串的其中一部分执行操作</td>\n<td>整数和浮点数自增减操作；键值对缓存</td>\n</tr>\n<tr>\n<td>LIST</td>\n<td>列表</td>\n<td>从两端压入或者弹出元素;对单个或者多个元素进行修剪，只保留一个范围内的元素</td>\n<td>存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据</td>\n</tr>\n<tr>\n<td>SET</td>\n<td>无序集合</td>\n<td>添加、获取、移除单个元素;检查一个元素是否存在于集合中;计算交集、并集、差集</td>\n<td>可以把两个人的粉丝列表整一个交集</td>\n</tr>\n<tr>\n<td>HASH</td>\n<td>包含键值对的无序散列表</td>\n<td>添加、获取、移除单个键值对;获取所有键值对;检查某个键是否存在</td>\n<td>结构化的数据，比如一个对象</td>\n</tr>\n<tr>\n<td>ZSET</td>\n<td>有序集合</td>\n<td>添加、获取、删除元素;根据分值范围或者成员来获取元素;计算一个键的排名</td>\n<td>去重但可以排序，如获取排名前几名的用户</td>\n</tr>\n</tbody></table>\n<h3 id=\"Redis的应用场景\"><a href=\"#Redis的应用场景\" class=\"headerlink\" title=\"Redis的应用场景\"></a>Redis的应用场景</h3><h4 id=\"总结一\"><a href=\"#总结一\" class=\"headerlink\" title=\"总结一\"></a>总结一</h4><p><strong>计数器</strong></p>\n<p>可以对 String 进行自增自减运算，从而实现计数器功能。Redis 读写性能非常高，适合存储频繁读写的计数量。</p>\n<p><strong>缓存</strong></p>\n<p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。</p>\n<p><strong>会话缓存</strong></p>\n<p>统一存储多台应用服务器的会话信息。</p>\n<p><strong>全页缓存（FPC）</strong></p>\n<p>Redis还提供很简便的全页缓存平台。Magento提供一个插件来使用Redis作为全页缓存后端。WordPress，使用插件 wp-redis，以最快速度加载曾浏览过的页面。</p>\n<p><strong>查找表</strong></p>\n<p>例如 DNS 记录就很适合使用 Redis 进行存储。利用了 Redis 快速的查找特性。但是查找表的内容不能失效，因为缓存不作为可靠的数据来源。</p>\n<p><strong>消息队列(发布/订阅功能)</strong></p>\n<p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。</p>\n<p><strong>其它</strong></p>\n<p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。</p>\n<p>ZSet 可以实现有序性操作，从而<strong>实现排行榜</strong>等功能。</p>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><h3 id=\"什么是Redis持久化？\"><a href=\"#什么是Redis持久化？\" class=\"headerlink\" title=\"什么是Redis持久化？\"></a>什么是Redis持久化？</h3><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了，内存数据丢失。</p>\n<h3 id=\"Redis-的持久化机制是什么？各自的优缺点？\"><a href=\"#Redis-的持久化机制是什么？各自的优缺点？\" class=\"headerlink\" title=\"Redis 的持久化机制是什么？各自的优缺点？\"></a>Redis 的持久化机制是什么？各自的优缺点？</h3><p>Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制。</p>\n<p><strong>RDB（Redis DataBase）：</strong></p>\n<p>Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中。</p>\n<p><strong>优点：</strong><br>1、性能最大化，<strong>fork 子进程来完成写操作</strong>，主进程不会进行任何 IO 操作，保证了 redis 的高性能<br>2、比 AOF 的启动效率更高。<br><strong>缺点：</strong></p>\n<p>1、如果两次持久化之间 发生故障，会导致数据丢失。</p>\n<p><strong>AOF持久化（Append Only File）</strong></p>\n<p>将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。</p>\n<p><strong>优点：</strong></p>\n<p>1、<strong>支持每进行一次 命令操作就记录到 aof 文件中一次。</strong><br>2、<strong>AOF 机制的 rewrite 模式。</strong>AOF 文件没被 rewrite 之前，可以删除其中的某些命令<br><strong>缺点：</strong></p>\n<p>1、AOF 文件比 RDB 文件大，且恢复速度慢。<br>2、数据集大的时候，比 rdb 启动效率低。</p>\n<h3 id=\"如何选择合适的持久化方式\"><a href=\"#如何选择合适的持久化方式\" class=\"headerlink\" title=\"如何选择合适的持久化方式\"></a>如何选择合适的持久化方式</h3><p><strong>同时使用两种持久化功能</strong>。当 Redis 重启的时候会<strong>优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整</strong>。</p>\n<p>如果可以<strong>承受数分钟以内的数据丢失</strong>，可以<strong>只使用RDB持久化</strong>。</p>\n<p>如果你只希望你的<strong>数据在服务器运行的时候存在，可以不使用任何持久化方式</strong>。</p>\n<h3 id=\"Redis持久化数据和缓存怎么做扩容？\"><a href=\"#Redis持久化数据和缓存怎么做扩容？\" class=\"headerlink\" title=\"Redis持久化数据和缓存怎么做扩容？\"></a>Redis持久化数据和缓存怎么做扩容？</h3><p>如果Redis被当做缓存使用，使用<strong>一致性哈希实现动态扩容缩容</strong>。</p>\n<p>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。</p>\n<h2 id=\"过期键的删除策略\"><a href=\"#过期键的删除策略\" class=\"headerlink\" title=\"过期键的删除策略\"></a>过期键的删除策略</h2><h3 id=\"Redis的过期键的删除策略\"><a href=\"#Redis的过期键的删除策略\" class=\"headerlink\" title=\"Redis的过期键的删除策略\"></a>Redis的过期键的删除策略</h3><p><strong>惰性过期：</strong>只有当访问一个key时，才会判断它是否已过期，过期则清除。该策略可以节省CPU资源，极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。<br><strong>定期过期：</strong>每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。<br><strong>Redis中同时使用了惰性过期和定期过期两种过期策略。</strong></p>\n<h3 id=\"Redis-key的过期时间和永久有效分别怎么设置？\"><a href=\"#Redis-key的过期时间和永久有效分别怎么设置？\" class=\"headerlink\" title=\"Redis key的过期时间和永久有效分别怎么设置？\"></a>Redis key的过期时间和永久有效分别怎么设置？</h3><p>EXPIRE和PERSIST命令。</p>\n<h2 id=\"内存相关\"><a href=\"#内存相关\" class=\"headerlink\" title=\"内存相关\"></a>内存相关</h2><h3 id=\"MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\"><a href=\"#MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\" class=\"headerlink\" title=\"MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\"></a>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</h3><p>redis内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。</p>\n<h3 id=\"Redis的内存淘汰策略有哪些\"><a href=\"#Redis的内存淘汰策略有哪些\" class=\"headerlink\" title=\"Redis的内存淘汰策略有哪些\"></a>Redis的内存淘汰策略有哪些</h3><p><strong>全局的键空间选择性移除</strong><br>allkeys-lru：移除最近最少使用的key。</p>\n<p>allkeys-lfu：所有键根据数据的被访问次数和访问时效性，进行移除</p>\n<p>allkeys-random：随机移除某个key。<br><strong>设置过期时间的键空间选择性移除</strong></p>\n<p>volatile-lru：在设置了过期时间的键中，移除最近最少使用的key。</p>\n<p>volatile-lfu：在设置了过期时间的键中，根据数据的被访问次数和访问时效性，进行移除</p>\n<p>volatile-random：在设置了过期时间的键中，随机移除某个key。<br>volatile-ttl：在设置了过期时间的键中，有更早过期时间的key优先移除。</p>\n<h3 id=\"Redis的内存用完了会发生什么？\"><a href=\"#Redis的内存用完了会发生什么？\" class=\"headerlink\" title=\"Redis的内存用完了会发生什么？\"></a>Redis的内存用完了会发生什么？</h3><p>如果达到设置的上限，Redis的写命令会返回错误信息。或者配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</p>\n<h3 id=\"Redis如何做内存优化？？？\"><a href=\"#Redis如何做内存优化？？？\" class=\"headerlink\" title=\"Redis如何做内存优化？？？\"></a>Redis如何做内存优化？？？</h3><p>可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hash），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面</p>\n<h2 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h2><h3 id=\"Redis线程模型\"><a href=\"#Redis线程模型\" class=\"headerlink\" title=\"Redis线程模型\"></a>Redis线程模型</h3><p>Redis基于Reactor模式开发了网络事件处理器（文件事件处理器）。它的组成结构包括：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。</p>\n<p>文件事件处理器使用 I/O 多路复用程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。<br>当被监听的套接字执行连接应答、读取、写入、关闭等操作时， 对应的文件事件就会产生， 文件事件处理器调用已关联好的事件处理器来处理。</p>\n<p>参考：<a href=\"https://www.cnblogs.com/barrywxx/p/8570821.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/barrywxx/p/8570821.html</a></p>\n<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><h3 id=\"什么是事务？\"><a href=\"#什么是事务？\" class=\"headerlink\" title=\"什么是事务？\"></a>什么是事务？</h3><p>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>\n<h3 id=\"Redis事务的概念\"><a href=\"#Redis事务的概念\" class=\"headerlink\" title=\"Redis事务的概念\"></a>Redis事务的概念</h3><p>Redis 事务是通过MULTI、EXEC、WATCH等命令完成。</p>\n<p>事务支持一次执行多个命令。</p>\n<p>在事务执行过程，会按照顺序执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p>\n<h3 id=\"Redis事务的三个阶段\"><a href=\"#Redis事务的三个阶段\" class=\"headerlink\" title=\"Redis事务的三个阶段\"></a>Redis事务的三个阶段</h3><ol>\n<li>事务开始 MULTI</li>\n<li>命令入队</li>\n<li>事务执行 EXEC</li>\n</ol>\n<p>事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队</p>\n<h3 id=\"Redis事务相关命令\"><a href=\"#Redis事务相关命令\" class=\"headerlink\" title=\"Redis事务相关命令\"></a>Redis事务相关命令</h3><p>Redis 在事务失败时不支持回滚，而是继续执行余下的命令<br>如果事务中的命令<strong>出现错误，那么所有的命令都不会执行</strong>；<br>如果事务中出现<strong>运行错误，那么正确的命令会被执行</strong>。</p>\n<p><strong>WATCH 命令是一个乐观锁</strong>，可以为 Redis 事务提供CAS。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。<br><strong>MULTI命令用于开启一个事务</strong>。 MULTI执行之后，客户端可向服务器发送任意多条命令，这些命令会被放到一个队列中，当EXEC被调用时，队列中的命令才会被执行。<br><strong>EXEC：执行所有事务块内的命令</strong>。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。<br>通过调用<strong>DISCARD</strong>，客户端可以<strong>清空事务队列，并放弃执行事务</strong>。<br><strong>UNWATCH命令可以取消watch对所有key的监控</strong>。</p>\n<h3 id=\"事务管理（ACID）概述\"><a href=\"#事务管理（ACID）概述\" class=\"headerlink\" title=\"事务管理（ACID）概述\"></a>事务管理（ACID）概述</h3><ul>\n<li><p>原子性（Atomicity）<br>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p>\n</li>\n<li><p><strong>一致性（Consistency）</strong><br><strong>事务前后数据的完整性必须保持一致。</strong></p>\n</li>\n<li><p><strong>隔离性（Isolation）</strong><br><strong>多个事务并发执行时，一个事务的执行不应影响其他事务的执行</strong></p>\n</li>\n<li><p>持久性（Durability）<br>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响</p>\n</li>\n</ul>\n<p>Redis的事务具备<strong>一致性和隔离性</strong>。AOF持久化模式下且appendfsync为always时，事务也具有持久性。</p>\n<h3 id=\"Redis事务支持隔离性吗\"><a href=\"#Redis事务支持隔离性吗\" class=\"headerlink\" title=\"Redis事务支持隔离性吗\"></a>Redis事务支持隔离性吗</h3><p>支持。Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。</p>\n<h3 id=\"Redis事务保证原子性吗，支持回滚吗\"><a href=\"#Redis事务保证原子性吗，支持回滚吗\" class=\"headerlink\" title=\"Redis事务保证原子性吗，支持回滚吗\"></a>Redis事务保证原子性吗，支持回滚吗</h3><p>单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令可能仍会被执行。</p>\n<h3 id=\"Redis事务其他实现\"><a href=\"#Redis事务其他实现\" class=\"headerlink\" title=\"Redis事务其他实现\"></a>Redis事务其他实现</h3><ul>\n<li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行</li>\n</ul>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><h3 id=\"哨兵（sentinel）模式\"><a href=\"#哨兵（sentinel）模式\" class=\"headerlink\" title=\"哨兵（sentinel）模式\"></a>哨兵（sentinel）模式</h3><p><strong>主要功能</strong></p>\n<ul>\n<li>集群监控：负责监控 redis master 和 slave 进程是否正常工作。</li>\n<li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>\n<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>\n<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>\n</ul>\n<h3 id=\"redis-集群模式的工作原理？在集群模式下，redis-的-key-如何寻址的？分布式寻址都有哪些算法？一致性-hash-算法？\"><a href=\"#redis-集群模式的工作原理？在集群模式下，redis-的-key-如何寻址的？分布式寻址都有哪些算法？一致性-hash-算法？\" class=\"headerlink\" title=\"redis 集群模式的工作原理？在集群模式下，redis 的 key 如何寻址的？分布式寻址都有哪些算法？一致性 hash 算法？\"></a><strong>redis 集群模式的工作原理？在集群模式下，redis 的 key 如何寻址的？分布式寻址都有哪些算法？一致性 hash 算法？</strong></h3><p><strong>简介</strong></p>\n<ul>\n<li><p>Redis Cluster是一种服务端Sharding技术。</p>\n</li>\n<li><p>每个key通过CRC16校验后对16384取模来决定放置哪个槽。每个节点存储一定哈希槽的数据，默认分配了16384 个槽位</p>\n</li>\n<li><p>每份数据分片会存储在多个互为主从的多节点上</p>\n</li>\n<li><p>数据写入先写主节点，再同步到从节点</p>\n</li>\n<li><p>读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点</p>\n</li>\n</ul>\n<p><strong>节点间的内部通信机制</strong></p>\n<p>redis 节点间采用 gossip 协议进行通信。</p>\n<p><strong>分布式寻址算法</strong></p>\n<ul>\n<li>hash 算法（大量缓存重建）</li>\n<li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li>\n<li>redis cluster 的 哈希槽算法</li>\n</ul>\n<p><strong>优点</strong></p>\n<ul>\n<li>无中心架构，支持动态扩容，对业务透明</li>\n<li>具备Sentinel的监控和自动Failover能力</li>\n<li>高性能，客户端直连redis服务，免去了proxy代理的损耗</li>\n</ul>\n<p><strong>缺点</strong></p>\n<ul>\n<li>只能使用0号数据库</li>\n<li>不支持批量操作(pipeline管道操作)</li>\n</ul>\n<h3 id=\"Redis-主从架构\"><a href=\"#Redis-主从架构\" class=\"headerlink\" title=\"Redis 主从架构\"></a>Redis 主从架构</h3><p><strong>redis replication 的核心机制</strong></p>\n<ul>\n<li>采用异步方式复制数据到 slave 节点，</li>\n<li>一个 master node 是可以配置多个 slave node 的；</li>\n<li>slave node 主要用来做读写分离，提高读的吞吐量。</li>\n</ul>\n<p><strong>主从复制原理</strong></p>\n<ul>\n<li>当从库和主库建立MS关系后，会向主数据库发送SYNC命令</li>\n<li>主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来</li>\n<li>当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis</li>\n<li>从Redis接收到后，会载入快照文件并且执行收到的缓存的命令</li>\n<li>之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致性</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>可能会造成master节点压力太大，使用主从从结构来解决</p>\n<h2 id=\"分区\"><a href=\"#分区\" class=\"headerlink\" title=\"分区\"></a>分区</h2><h3 id=\"Redis是单线程的，如何提高多核CPU的利用率？\"><a href=\"#Redis是单线程的，如何提高多核CPU的利用率？\" class=\"headerlink\" title=\"Redis是单线程的，如何提高多核CPU的利用率？\"></a>Redis是单线程的，如何提高多核CPU的利用率？</h3><ul>\n<li>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用。</li>\n<li>把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上</li>\n<li>把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。</li>\n</ul>\n<h3 id=\"为什么要做Redis分区？\"><a href=\"#为什么要做Redis分区？\" class=\"headerlink\" title=\"为什么要做Redis分区？\"></a>为什么要做Redis分区？</h3><p>分区可以让Redis管理更大的内存。</p>\n<p>RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p>\n<h3 id=\"Redis分区有什么缺点？\"><a href=\"#Redis分区有什么缺点？\" class=\"headerlink\" title=\"Redis分区有什么缺点？\"></a>Redis分区有什么缺点？</h3><ul>\n<li>涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例。</li>\n<li>同时操作多个key，则不能使用Redis事务.</li>\n</ul>\n<h2 id=\"分布式问题\"><a href=\"#分布式问题\" class=\"headerlink\" title=\"分布式问题\"></a>分布式问题</h2><h3 id=\"Redis实现分布式锁\"><a href=\"#Redis实现分布式锁\" class=\"headerlink\" title=\"Redis实现分布式锁\"></a>Redis实现分布式锁</h3><p><strong>加锁</strong></p>\n<ul>\n<li><p><code>SET key value [EX seconds | PX milliseconds]  [NX]</code></p>\n</li>\n<li><p>key 不存在， key 会被创建。</p>\n</li>\n<li><p>Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。</p>\n</li>\n<li><p>过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p>\n</li>\n</ul>\n<p><strong>解锁</strong></p>\n<p>执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。</p>\n<p><strong>缺点</strong></p>\n<ul>\n<li>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</li>\n<li>即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。</li>\n<li>Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p> Redis 的性能很高，可以支撑高并发的获取、释放锁操作</p>\n<h2 id=\"Zookeeper-实现\"><a href=\"#Zookeeper-实现\" class=\"headerlink\" title=\"Zookeeper 实现\"></a>Zookeeper 实现</h2><ul>\n<li>使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。</li>\n<li>创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。</li>\n<li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。</li>\n<li>如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。</li>\n</ul>\n<p><strong>优点</strong></p>\n<ul>\n<li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</li>\n<li>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</p>\n<h3 id=\"分布式Redis是前期做还是后期规模上来了再做好？为什么？\"><a href=\"#分布式Redis是前期做还是后期规模上来了再做好？为什么？\" class=\"headerlink\" title=\"分布式Redis是前期做还是后期规模上来了再做好？为什么？\"></a>分布式Redis是前期做还是后期规模上来了再做好？为什么？</h3><p>一开始就多设置几个Redis实例，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是<strong>仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）</strong>。</p>\n<h3 id=\"什么是-RedLock\"><a href=\"#什么是-RedLock\" class=\"headerlink\" title=\"什么是 RedLock\"></a>什么是 RedLock</h3><p>分布式锁算法 Redlock</p>\n<ul>\n<li><p>客户端获取当前时间。</p>\n</li>\n<li><p>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p>\n</li>\n<li><p>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</p>\n</li>\n<li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功</p>\n</li>\n<li><p>别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</p>\n</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>无法保证加锁的过程一定正确</p>\n<h2 id=\"缓存异常\"><a href=\"#缓存异常\" class=\"headerlink\" title=\"缓存异常\"></a>缓存异常</h2><p><a href=\"https://wangyixin-tom.github.io/2020/10/27/redis-huan-cun\">https://wangyixin-tom.github.io/2020/10/27/redis-huan-cun</a></p>\n<h3 id=\"缓存预热\"><a href=\"#缓存预热\" class=\"headerlink\" title=\"缓存预热\"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存</p>\n<p><strong>解决方案</strong></p>\n<ul>\n<li>统计出频率较高的热数据，直接写个缓存刷新页面，上线时手工操作一下；</li>\n</ul>\n<h3 id=\"热点数据和冷数据\"><a href=\"#热点数据和冷数据\" class=\"headerlink\" title=\"热点数据和冷数据\"></a>热点数据和冷数据</h3><p><strong>热点数据，缓存才有价值</strong></p>\n<p>冷数据可能还没有再次访问到就已经被挤出内存，不仅<strong>占用内存，而且价值不大</strong>。</p>\n<p><strong>数据更新前至少读取两次，缓存才有意义</strong>。这个是最基本的策略</p>\n<h3 id=\"缓存热点key过期\"><a href=\"#缓存热点key过期\" class=\"headerlink\" title=\"缓存热点key过期\"></a><strong>缓存热点key</strong>过期</h3><p>一般都会从后端DB加载数据并回设到缓存，大并发的请求可能会瞬间把后端DB压垮。</p>\n<p><strong>解决方案</strong></p>\n<p>对缓存查询加锁：如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；</p>\n<p>其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询</p>\n<h2 id=\"其他问题\"><a href=\"#其他问题\" class=\"headerlink\" title=\"其他问题\"></a>其他问题</h2><h3 id=\"Redis与Memcached的区别\"><a href=\"#Redis与Memcached的区别\" class=\"headerlink\" title=\"Redis与Memcached的区别\"></a>Redis与Memcached的区别</h3><p>两者都是非关系型内存键值数据库，现在一般都是用 Redis 来实现缓存， 主要不同：<br>(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型</p>\n<p>(2) redis的速度比memcached快很多</p>\n<p>(3) redis可以持久化其数据</p>\n<h3 id=\"如何保证缓存与数据库双写时的数据一致性？\"><a href=\"#如何保证缓存与数据库双写时的数据一致性？\" class=\"headerlink\" title=\"如何保证缓存与数据库双写时的数据一致性？\"></a>如何保证缓存与数据库双写时的数据一致性？</h3><p><strong>先更新数据库，然后再删除缓存</strong>会暂时产生短暂不一致的情况，但是发生的几率特别小</p>\n<h3 id=\"Redis常见性能问题和解决方案？\"><a href=\"#Redis常见性能问题和解决方案？\" class=\"headerlink\" title=\"Redis常见性能问题和解决方案？\"></a>Redis常见性能问题和解决方案？</h3><ul>\n<li><p>Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。</p>\n</li>\n<li><p>如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。</p>\n</li>\n<li><p>为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。</p>\n</li>\n<li><p>尽量避免在压力较大的主库上增加从库</p>\n</li>\n</ul>\n<h3 id=\"一个字符串类型的值能存储最大容量是多少？\"><a href=\"#一个字符串类型的值能存储最大容量是多少？\" class=\"headerlink\" title=\"一个字符串类型的值能存储最大容量是多少？\"></a>一个字符串类型的值能存储最大容量是多少？</h3><p>512M</p>\n<h3 id=\"Redis如何做大量数据插入？\"><a href=\"#Redis如何做大量数据插入？\" class=\"headerlink\" title=\"Redis如何做大量数据插入？\"></a>Redis如何做大量数据插入？</h3><p>pipe mode的新模式用于执行大量数据插入工作。</p>\n<h3 id=\"找出Redis里面有10w个key是以某个固定的已知的前缀开头的\"><a href=\"#找出Redis里面有10w个key是以某个固定的已知的前缀开头的\" class=\"headerlink\" title=\"找出Redis里面有10w个key是以某个固定的已知的前缀开头的\"></a>找出Redis里面有10w个key是以某个固定的已知的前缀开头的</h3><p>这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</p>\n<h3 id=\"使用Redis做过异步队列吗，是如何实现的\"><a href=\"#使用Redis做过异步队列吗，是如何实现的\" class=\"headerlink\" title=\"使用Redis做过异步队列吗，是如何实现的\"></a>使用Redis做过异步队列吗，是如何实现的</h3><p>使用list类型保存数据信息，rpush生产消息，</p>\n<p>使用blpop消费消息, 在没有信息的时候，会一直阻塞，直到信息的到来。</p>\n<p>redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。</p>\n<h3 id=\"Redis如何实现延时队列\"><a href=\"#Redis如何实现延时队列\" class=\"headerlink\" title=\"Redis如何实现延时队列\"></a>Redis如何实现延时队列</h3><p>使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。</p>\n<h3 id=\"Redis回收进程如何工作的？\"><a href=\"#Redis回收进程如何工作的？\" class=\"headerlink\" title=\"Redis回收进程如何工作的？\"></a>Redis回收进程如何工作的？</h3><p>Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><h3 id=\"什么是Redis\"><a href=\"#什么是Redis\" class=\"headerlink\" title=\"什么是Redis\"></a>什么是Redis</h3><p>Redis（Remote Dictionary Server） 是一个使用 C 语言编写的，<strong>开源的高性能非关系型（NoSQL）的键值对数据库</strong>。</p>\n<p><strong>Redis 可以存储键和五种不同类型的值之间的映射</strong>。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p>\n<p> Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应<strong>用于缓存方向</strong>，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。</p>\n<h3 id=\"Redis有哪些优缺点\"><a href=\"#Redis有哪些优缺点\" class=\"headerlink\" title=\"Redis有哪些优缺点\"></a>Redis有哪些优缺点</h3><p><strong>优点</strong></p>\n<blockquote>\n<p><strong>读写性能优异，</strong> Redis能读的速度是110000次/s，写的速度是81000次/s。<br><strong>支持数据持久化</strong>，支持AOF和RDB两种持久化方式。<br><strong>支持事务</strong>，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。<br><strong>数据结构丰富</strong>，支持string、hash、set、zset、list等数据结构。<br><strong>支持主从复制</strong>，主机会自动将数据同步到从机，支持读写分离。</p>\n</blockquote>\n<p><strong>缺点</strong></p>\n<blockquote>\n<p>数据库<strong>容量受到物理内存的限制</strong>，不能用作海量数据的高性能读写，适合的场景主要局限在较小数据量的高性能操作和运算上。<br>Redis <strong>不具备自动容错和恢复功能</strong>，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。<br>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后会引入数据不一致的问题。<br>Redis 较难支持在线扩容，在集群容量达到上限时<strong>在线扩容会变得很复杂</strong>。</p>\n</blockquote>\n<h3 id=\"为什么要用-Redis-而不用-map-guava-做缓存\"><a href=\"#为什么要用-Redis-而不用-map-guava-做缓存\" class=\"headerlink\" title=\"为什么要用 Redis 而不用 map/guava 做缓存?\"></a>为什么要用 Redis 而不用 map/guava 做缓存?</h3><p>Java 自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>\n<p>使用 redis 或 memcached 之类的分布式缓存，在多实例的情况下，<strong>各实例共用一份缓存数据，缓存具有一致性</strong>。</p>\n<h3 id=\"Redis为什么这么快\"><a href=\"#Redis为什么这么快\" class=\"headerlink\" title=\"Redis为什么这么快\"></a>Redis为什么这么快</h3><p>一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。</p>\n<p>另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p>\n<p><strong>IO多路复用模型</strong></p>\n<p>Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流– select/epoll 机制。</p>\n<p>在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。</p>\n<p>内核会一直监听这些套接字上的连接请求或数据请求。select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。</p>\n<p>redis不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p>\n<blockquote>\n<p>select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>\n</blockquote>\n<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><h3 id=\"Redis有哪些数据类型\"><a href=\"#Redis有哪些数据类型\" class=\"headerlink\" title=\"Redis有哪些数据类型\"></a>Redis有哪些数据类型</h3><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash.</p>\n<table>\n<thead>\n<tr>\n<th>数据类型</th>\n<th>可存储的值</th>\n<th>操作</th>\n<th>应用场景</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>STRING</td>\n<td>字符串、整数或者浮点数</td>\n<td>对整个字符串或者字符串的其中一部分执行操作</td>\n<td>整数和浮点数自增减操作；键值对缓存</td>\n</tr>\n<tr>\n<td>LIST</td>\n<td>列表</td>\n<td>从两端压入或者弹出元素;对单个或者多个元素进行修剪，只保留一个范围内的元素</td>\n<td>存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据</td>\n</tr>\n<tr>\n<td>SET</td>\n<td>无序集合</td>\n<td>添加、获取、移除单个元素;检查一个元素是否存在于集合中;计算交集、并集、差集</td>\n<td>可以把两个人的粉丝列表整一个交集</td>\n</tr>\n<tr>\n<td>HASH</td>\n<td>包含键值对的无序散列表</td>\n<td>添加、获取、移除单个键值对;获取所有键值对;检查某个键是否存在</td>\n<td>结构化的数据，比如一个对象</td>\n</tr>\n<tr>\n<td>ZSET</td>\n<td>有序集合</td>\n<td>添加、获取、删除元素;根据分值范围或者成员来获取元素;计算一个键的排名</td>\n<td>去重但可以排序，如获取排名前几名的用户</td>\n</tr>\n</tbody></table>\n<h3 id=\"Redis的应用场景\"><a href=\"#Redis的应用场景\" class=\"headerlink\" title=\"Redis的应用场景\"></a>Redis的应用场景</h3><h4 id=\"总结一\"><a href=\"#总结一\" class=\"headerlink\" title=\"总结一\"></a>总结一</h4><p><strong>计数器</strong></p>\n<p>可以对 String 进行自增自减运算，从而实现计数器功能。Redis 读写性能非常高，适合存储频繁读写的计数量。</p>\n<p><strong>缓存</strong></p>\n<p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。</p>\n<p><strong>会话缓存</strong></p>\n<p>统一存储多台应用服务器的会话信息。</p>\n<p><strong>全页缓存（FPC）</strong></p>\n<p>Redis还提供很简便的全页缓存平台。Magento提供一个插件来使用Redis作为全页缓存后端。WordPress，使用插件 wp-redis，以最快速度加载曾浏览过的页面。</p>\n<p><strong>查找表</strong></p>\n<p>例如 DNS 记录就很适合使用 Redis 进行存储。利用了 Redis 快速的查找特性。但是查找表的内容不能失效，因为缓存不作为可靠的数据来源。</p>\n<p><strong>消息队列(发布/订阅功能)</strong></p>\n<p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。</p>\n<p><strong>其它</strong></p>\n<p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。</p>\n<p>ZSet 可以实现有序性操作，从而<strong>实现排行榜</strong>等功能。</p>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><h3 id=\"什么是Redis持久化？\"><a href=\"#什么是Redis持久化？\" class=\"headerlink\" title=\"什么是Redis持久化？\"></a>什么是Redis持久化？</h3><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了，内存数据丢失。</p>\n<h3 id=\"Redis-的持久化机制是什么？各自的优缺点？\"><a href=\"#Redis-的持久化机制是什么？各自的优缺点？\" class=\"headerlink\" title=\"Redis 的持久化机制是什么？各自的优缺点？\"></a>Redis 的持久化机制是什么？各自的优缺点？</h3><p>Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制。</p>\n<p><strong>RDB（Redis DataBase）：</strong></p>\n<p>Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中。</p>\n<p><strong>优点：</strong><br>1、性能最大化，<strong>fork 子进程来完成写操作</strong>，主进程不会进行任何 IO 操作，保证了 redis 的高性能<br>2、比 AOF 的启动效率更高。<br><strong>缺点：</strong></p>\n<p>1、如果两次持久化之间 发生故障，会导致数据丢失。</p>\n<p><strong>AOF持久化（Append Only File）</strong></p>\n<p>将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。</p>\n<p><strong>优点：</strong></p>\n<p>1、<strong>支持每进行一次 命令操作就记录到 aof 文件中一次。</strong><br>2、<strong>AOF 机制的 rewrite 模式。</strong>AOF 文件没被 rewrite 之前，可以删除其中的某些命令<br><strong>缺点：</strong></p>\n<p>1、AOF 文件比 RDB 文件大，且恢复速度慢。<br>2、数据集大的时候，比 rdb 启动效率低。</p>\n<h3 id=\"如何选择合适的持久化方式\"><a href=\"#如何选择合适的持久化方式\" class=\"headerlink\" title=\"如何选择合适的持久化方式\"></a>如何选择合适的持久化方式</h3><p><strong>同时使用两种持久化功能</strong>。当 Redis 重启的时候会<strong>优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整</strong>。</p>\n<p>如果可以<strong>承受数分钟以内的数据丢失</strong>，可以<strong>只使用RDB持久化</strong>。</p>\n<p>如果你只希望你的<strong>数据在服务器运行的时候存在，可以不使用任何持久化方式</strong>。</p>\n<h3 id=\"Redis持久化数据和缓存怎么做扩容？\"><a href=\"#Redis持久化数据和缓存怎么做扩容？\" class=\"headerlink\" title=\"Redis持久化数据和缓存怎么做扩容？\"></a>Redis持久化数据和缓存怎么做扩容？</h3><p>如果Redis被当做缓存使用，使用<strong>一致性哈希实现动态扩容缩容</strong>。</p>\n<p>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。</p>\n<h2 id=\"过期键的删除策略\"><a href=\"#过期键的删除策略\" class=\"headerlink\" title=\"过期键的删除策略\"></a>过期键的删除策略</h2><h3 id=\"Redis的过期键的删除策略\"><a href=\"#Redis的过期键的删除策略\" class=\"headerlink\" title=\"Redis的过期键的删除策略\"></a>Redis的过期键的删除策略</h3><p><strong>惰性过期：</strong>只有当访问一个key时，才会判断它是否已过期，过期则清除。该策略可以节省CPU资源，极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。<br><strong>定期过期：</strong>每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。<br><strong>Redis中同时使用了惰性过期和定期过期两种过期策略。</strong></p>\n<h3 id=\"Redis-key的过期时间和永久有效分别怎么设置？\"><a href=\"#Redis-key的过期时间和永久有效分别怎么设置？\" class=\"headerlink\" title=\"Redis key的过期时间和永久有效分别怎么设置？\"></a>Redis key的过期时间和永久有效分别怎么设置？</h3><p>EXPIRE和PERSIST命令。</p>\n<h2 id=\"内存相关\"><a href=\"#内存相关\" class=\"headerlink\" title=\"内存相关\"></a>内存相关</h2><h3 id=\"MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\"><a href=\"#MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\" class=\"headerlink\" title=\"MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据\"></a>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</h3><p>redis内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。</p>\n<h3 id=\"Redis的内存淘汰策略有哪些\"><a href=\"#Redis的内存淘汰策略有哪些\" class=\"headerlink\" title=\"Redis的内存淘汰策略有哪些\"></a>Redis的内存淘汰策略有哪些</h3><p><strong>全局的键空间选择性移除</strong><br>allkeys-lru：移除最近最少使用的key。</p>\n<p>allkeys-lfu：所有键根据数据的被访问次数和访问时效性，进行移除</p>\n<p>allkeys-random：随机移除某个key。<br><strong>设置过期时间的键空间选择性移除</strong></p>\n<p>volatile-lru：在设置了过期时间的键中，移除最近最少使用的key。</p>\n<p>volatile-lfu：在设置了过期时间的键中，根据数据的被访问次数和访问时效性，进行移除</p>\n<p>volatile-random：在设置了过期时间的键中，随机移除某个key。<br>volatile-ttl：在设置了过期时间的键中，有更早过期时间的key优先移除。</p>\n<h3 id=\"Redis的内存用完了会发生什么？\"><a href=\"#Redis的内存用完了会发生什么？\" class=\"headerlink\" title=\"Redis的内存用完了会发生什么？\"></a>Redis的内存用完了会发生什么？</h3><p>如果达到设置的上限，Redis的写命令会返回错误信息。或者配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</p>\n<h3 id=\"Redis如何做内存优化？？？\"><a href=\"#Redis如何做内存优化？？？\" class=\"headerlink\" title=\"Redis如何做内存优化？？？\"></a>Redis如何做内存优化？？？</h3><p>可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hash），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面</p>\n<h2 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h2><h3 id=\"Redis线程模型\"><a href=\"#Redis线程模型\" class=\"headerlink\" title=\"Redis线程模型\"></a>Redis线程模型</h3><p>Redis基于Reactor模式开发了网络事件处理器（文件事件处理器）。它的组成结构包括：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。</p>\n<p>文件事件处理器使用 I/O 多路复用程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。<br>当被监听的套接字执行连接应答、读取、写入、关闭等操作时， 对应的文件事件就会产生， 文件事件处理器调用已关联好的事件处理器来处理。</p>\n<p>参考：<a href=\"https://www.cnblogs.com/barrywxx/p/8570821.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/barrywxx/p/8570821.html</a></p>\n<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><h3 id=\"什么是事务？\"><a href=\"#什么是事务？\" class=\"headerlink\" title=\"什么是事务？\"></a>什么是事务？</h3><p>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>\n<h3 id=\"Redis事务的概念\"><a href=\"#Redis事务的概念\" class=\"headerlink\" title=\"Redis事务的概念\"></a>Redis事务的概念</h3><p>Redis 事务是通过MULTI、EXEC、WATCH等命令完成。</p>\n<p>事务支持一次执行多个命令。</p>\n<p>在事务执行过程，会按照顺序执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p>\n<h3 id=\"Redis事务的三个阶段\"><a href=\"#Redis事务的三个阶段\" class=\"headerlink\" title=\"Redis事务的三个阶段\"></a>Redis事务的三个阶段</h3><ol>\n<li>事务开始 MULTI</li>\n<li>命令入队</li>\n<li>事务执行 EXEC</li>\n</ol>\n<p>事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队</p>\n<h3 id=\"Redis事务相关命令\"><a href=\"#Redis事务相关命令\" class=\"headerlink\" title=\"Redis事务相关命令\"></a>Redis事务相关命令</h3><p>Redis 在事务失败时不支持回滚，而是继续执行余下的命令<br>如果事务中的命令<strong>出现错误，那么所有的命令都不会执行</strong>；<br>如果事务中出现<strong>运行错误，那么正确的命令会被执行</strong>。</p>\n<p><strong>WATCH 命令是一个乐观锁</strong>，可以为 Redis 事务提供CAS。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。<br><strong>MULTI命令用于开启一个事务</strong>。 MULTI执行之后，客户端可向服务器发送任意多条命令，这些命令会被放到一个队列中，当EXEC被调用时，队列中的命令才会被执行。<br><strong>EXEC：执行所有事务块内的命令</strong>。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。<br>通过调用<strong>DISCARD</strong>，客户端可以<strong>清空事务队列，并放弃执行事务</strong>。<br><strong>UNWATCH命令可以取消watch对所有key的监控</strong>。</p>\n<h3 id=\"事务管理（ACID）概述\"><a href=\"#事务管理（ACID）概述\" class=\"headerlink\" title=\"事务管理（ACID）概述\"></a>事务管理（ACID）概述</h3><ul>\n<li><p>原子性（Atomicity）<br>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p>\n</li>\n<li><p><strong>一致性（Consistency）</strong><br><strong>事务前后数据的完整性必须保持一致。</strong></p>\n</li>\n<li><p><strong>隔离性（Isolation）</strong><br><strong>多个事务并发执行时，一个事务的执行不应影响其他事务的执行</strong></p>\n</li>\n<li><p>持久性（Durability）<br>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响</p>\n</li>\n</ul>\n<p>Redis的事务具备<strong>一致性和隔离性</strong>。AOF持久化模式下且appendfsync为always时，事务也具有持久性。</p>\n<h3 id=\"Redis事务支持隔离性吗\"><a href=\"#Redis事务支持隔离性吗\" class=\"headerlink\" title=\"Redis事务支持隔离性吗\"></a>Redis事务支持隔离性吗</h3><p>支持。Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。</p>\n<h3 id=\"Redis事务保证原子性吗，支持回滚吗\"><a href=\"#Redis事务保证原子性吗，支持回滚吗\" class=\"headerlink\" title=\"Redis事务保证原子性吗，支持回滚吗\"></a>Redis事务保证原子性吗，支持回滚吗</h3><p>单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令可能仍会被执行。</p>\n<h3 id=\"Redis事务其他实现\"><a href=\"#Redis事务其他实现\" class=\"headerlink\" title=\"Redis事务其他实现\"></a>Redis事务其他实现</h3><ul>\n<li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行</li>\n</ul>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><h3 id=\"哨兵（sentinel）模式\"><a href=\"#哨兵（sentinel）模式\" class=\"headerlink\" title=\"哨兵（sentinel）模式\"></a>哨兵（sentinel）模式</h3><p><strong>主要功能</strong></p>\n<ul>\n<li>集群监控：负责监控 redis master 和 slave 进程是否正常工作。</li>\n<li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>\n<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>\n<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>\n</ul>\n<h3 id=\"redis-集群模式的工作原理？在集群模式下，redis-的-key-如何寻址的？分布式寻址都有哪些算法？一致性-hash-算法？\"><a href=\"#redis-集群模式的工作原理？在集群模式下，redis-的-key-如何寻址的？分布式寻址都有哪些算法？一致性-hash-算法？\" class=\"headerlink\" title=\"redis 集群模式的工作原理？在集群模式下，redis 的 key 如何寻址的？分布式寻址都有哪些算法？一致性 hash 算法？\"></a><strong>redis 集群模式的工作原理？在集群模式下，redis 的 key 如何寻址的？分布式寻址都有哪些算法？一致性 hash 算法？</strong></h3><p><strong>简介</strong></p>\n<ul>\n<li><p>Redis Cluster是一种服务端Sharding技术。</p>\n</li>\n<li><p>每个key通过CRC16校验后对16384取模来决定放置哪个槽。每个节点存储一定哈希槽的数据，默认分配了16384 个槽位</p>\n</li>\n<li><p>每份数据分片会存储在多个互为主从的多节点上</p>\n</li>\n<li><p>数据写入先写主节点，再同步到从节点</p>\n</li>\n<li><p>读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点</p>\n</li>\n</ul>\n<p><strong>节点间的内部通信机制</strong></p>\n<p>redis 节点间采用 gossip 协议进行通信。</p>\n<p><strong>分布式寻址算法</strong></p>\n<ul>\n<li>hash 算法（大量缓存重建）</li>\n<li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li>\n<li>redis cluster 的 哈希槽算法</li>\n</ul>\n<p><strong>优点</strong></p>\n<ul>\n<li>无中心架构，支持动态扩容，对业务透明</li>\n<li>具备Sentinel的监控和自动Failover能力</li>\n<li>高性能，客户端直连redis服务，免去了proxy代理的损耗</li>\n</ul>\n<p><strong>缺点</strong></p>\n<ul>\n<li>只能使用0号数据库</li>\n<li>不支持批量操作(pipeline管道操作)</li>\n</ul>\n<h3 id=\"Redis-主从架构\"><a href=\"#Redis-主从架构\" class=\"headerlink\" title=\"Redis 主从架构\"></a>Redis 主从架构</h3><p><strong>redis replication 的核心机制</strong></p>\n<ul>\n<li>采用异步方式复制数据到 slave 节点，</li>\n<li>一个 master node 是可以配置多个 slave node 的；</li>\n<li>slave node 主要用来做读写分离，提高读的吞吐量。</li>\n</ul>\n<p><strong>主从复制原理</strong></p>\n<ul>\n<li>当从库和主库建立MS关系后，会向主数据库发送SYNC命令</li>\n<li>主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来</li>\n<li>当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis</li>\n<li>从Redis接收到后，会载入快照文件并且执行收到的缓存的命令</li>\n<li>之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致性</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>可能会造成master节点压力太大，使用主从从结构来解决</p>\n<h2 id=\"分区\"><a href=\"#分区\" class=\"headerlink\" title=\"分区\"></a>分区</h2><h3 id=\"Redis是单线程的，如何提高多核CPU的利用率？\"><a href=\"#Redis是单线程的，如何提高多核CPU的利用率？\" class=\"headerlink\" title=\"Redis是单线程的，如何提高多核CPU的利用率？\"></a>Redis是单线程的，如何提高多核CPU的利用率？</h3><ul>\n<li>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用。</li>\n<li>把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上</li>\n<li>把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。</li>\n</ul>\n<h3 id=\"为什么要做Redis分区？\"><a href=\"#为什么要做Redis分区？\" class=\"headerlink\" title=\"为什么要做Redis分区？\"></a>为什么要做Redis分区？</h3><p>分区可以让Redis管理更大的内存。</p>\n<p>RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p>\n<h3 id=\"Redis分区有什么缺点？\"><a href=\"#Redis分区有什么缺点？\" class=\"headerlink\" title=\"Redis分区有什么缺点？\"></a>Redis分区有什么缺点？</h3><ul>\n<li>涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例。</li>\n<li>同时操作多个key，则不能使用Redis事务.</li>\n</ul>\n<h2 id=\"分布式问题\"><a href=\"#分布式问题\" class=\"headerlink\" title=\"分布式问题\"></a>分布式问题</h2><h3 id=\"Redis实现分布式锁\"><a href=\"#Redis实现分布式锁\" class=\"headerlink\" title=\"Redis实现分布式锁\"></a>Redis实现分布式锁</h3><p><strong>加锁</strong></p>\n<ul>\n<li><p><code>SET key value [EX seconds | PX milliseconds]  [NX]</code></p>\n</li>\n<li><p>key 不存在， key 会被创建。</p>\n</li>\n<li><p>Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。</p>\n</li>\n<li><p>过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p>\n</li>\n</ul>\n<p><strong>解锁</strong></p>\n<p>执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。</p>\n<p><strong>缺点</strong></p>\n<ul>\n<li>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</li>\n<li>即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。</li>\n<li>Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p> Redis 的性能很高，可以支撑高并发的获取、释放锁操作</p>\n<h2 id=\"Zookeeper-实现\"><a href=\"#Zookeeper-实现\" class=\"headerlink\" title=\"Zookeeper 实现\"></a>Zookeeper 实现</h2><ul>\n<li>使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。</li>\n<li>创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。</li>\n<li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。</li>\n<li>如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。</li>\n</ul>\n<p><strong>优点</strong></p>\n<ul>\n<li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</li>\n<li>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</p>\n<h3 id=\"分布式Redis是前期做还是后期规模上来了再做好？为什么？\"><a href=\"#分布式Redis是前期做还是后期规模上来了再做好？为什么？\" class=\"headerlink\" title=\"分布式Redis是前期做还是后期规模上来了再做好？为什么？\"></a>分布式Redis是前期做还是后期规模上来了再做好？为什么？</h3><p>一开始就多设置几个Redis实例，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是<strong>仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）</strong>。</p>\n<h3 id=\"什么是-RedLock\"><a href=\"#什么是-RedLock\" class=\"headerlink\" title=\"什么是 RedLock\"></a>什么是 RedLock</h3><p>分布式锁算法 Redlock</p>\n<ul>\n<li><p>客户端获取当前时间。</p>\n</li>\n<li><p>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p>\n</li>\n<li><p>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</p>\n</li>\n<li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功</p>\n</li>\n<li><p>别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</p>\n</li>\n</ul>\n<p><strong>缺点</strong></p>\n<p>无法保证加锁的过程一定正确</p>\n<h2 id=\"缓存异常\"><a href=\"#缓存异常\" class=\"headerlink\" title=\"缓存异常\"></a>缓存异常</h2><p><a href=\"https://wangyixin-tom.github.io/2020/10/27/redis-huan-cun\">https://wangyixin-tom.github.io/2020/10/27/redis-huan-cun</a></p>\n<h3 id=\"缓存预热\"><a href=\"#缓存预热\" class=\"headerlink\" title=\"缓存预热\"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存</p>\n<p><strong>解决方案</strong></p>\n<ul>\n<li>统计出频率较高的热数据，直接写个缓存刷新页面，上线时手工操作一下；</li>\n</ul>\n<h3 id=\"热点数据和冷数据\"><a href=\"#热点数据和冷数据\" class=\"headerlink\" title=\"热点数据和冷数据\"></a>热点数据和冷数据</h3><p><strong>热点数据，缓存才有价值</strong></p>\n<p>冷数据可能还没有再次访问到就已经被挤出内存，不仅<strong>占用内存，而且价值不大</strong>。</p>\n<p><strong>数据更新前至少读取两次，缓存才有意义</strong>。这个是最基本的策略</p>\n<h3 id=\"缓存热点key过期\"><a href=\"#缓存热点key过期\" class=\"headerlink\" title=\"缓存热点key过期\"></a><strong>缓存热点key</strong>过期</h3><p>一般都会从后端DB加载数据并回设到缓存，大并发的请求可能会瞬间把后端DB压垮。</p>\n<p><strong>解决方案</strong></p>\n<p>对缓存查询加锁：如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；</p>\n<p>其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询</p>\n<h2 id=\"其他问题\"><a href=\"#其他问题\" class=\"headerlink\" title=\"其他问题\"></a>其他问题</h2><h3 id=\"Redis与Memcached的区别\"><a href=\"#Redis与Memcached的区别\" class=\"headerlink\" title=\"Redis与Memcached的区别\"></a>Redis与Memcached的区别</h3><p>两者都是非关系型内存键值数据库，现在一般都是用 Redis 来实现缓存， 主要不同：<br>(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型</p>\n<p>(2) redis的速度比memcached快很多</p>\n<p>(3) redis可以持久化其数据</p>\n<h3 id=\"如何保证缓存与数据库双写时的数据一致性？\"><a href=\"#如何保证缓存与数据库双写时的数据一致性？\" class=\"headerlink\" title=\"如何保证缓存与数据库双写时的数据一致性？\"></a>如何保证缓存与数据库双写时的数据一致性？</h3><p><strong>先更新数据库，然后再删除缓存</strong>会暂时产生短暂不一致的情况，但是发生的几率特别小</p>\n<h3 id=\"Redis常见性能问题和解决方案？\"><a href=\"#Redis常见性能问题和解决方案？\" class=\"headerlink\" title=\"Redis常见性能问题和解决方案？\"></a>Redis常见性能问题和解决方案？</h3><ul>\n<li><p>Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。</p>\n</li>\n<li><p>如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。</p>\n</li>\n<li><p>为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。</p>\n</li>\n<li><p>尽量避免在压力较大的主库上增加从库</p>\n</li>\n</ul>\n<h3 id=\"一个字符串类型的值能存储最大容量是多少？\"><a href=\"#一个字符串类型的值能存储最大容量是多少？\" class=\"headerlink\" title=\"一个字符串类型的值能存储最大容量是多少？\"></a>一个字符串类型的值能存储最大容量是多少？</h3><p>512M</p>\n<h3 id=\"Redis如何做大量数据插入？\"><a href=\"#Redis如何做大量数据插入？\" class=\"headerlink\" title=\"Redis如何做大量数据插入？\"></a>Redis如何做大量数据插入？</h3><p>pipe mode的新模式用于执行大量数据插入工作。</p>\n<h3 id=\"找出Redis里面有10w个key是以某个固定的已知的前缀开头的\"><a href=\"#找出Redis里面有10w个key是以某个固定的已知的前缀开头的\" class=\"headerlink\" title=\"找出Redis里面有10w个key是以某个固定的已知的前缀开头的\"></a>找出Redis里面有10w个key是以某个固定的已知的前缀开头的</h3><p>这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</p>\n<h3 id=\"使用Redis做过异步队列吗，是如何实现的\"><a href=\"#使用Redis做过异步队列吗，是如何实现的\" class=\"headerlink\" title=\"使用Redis做过异步队列吗，是如何实现的\"></a>使用Redis做过异步队列吗，是如何实现的</h3><p>使用list类型保存数据信息，rpush生产消息，</p>\n<p>使用blpop消费消息, 在没有信息的时候，会一直阻塞，直到信息的到来。</p>\n<p>redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。</p>\n<h3 id=\"Redis如何实现延时队列\"><a href=\"#Redis如何实现延时队列\" class=\"headerlink\" title=\"Redis如何实现延时队列\"></a>Redis如何实现延时队列</h3><p>使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。</p>\n<h3 id=\"Redis回收进程如何工作的？\"><a href=\"#Redis回收进程如何工作的？\" class=\"headerlink\" title=\"Redis回收进程如何工作的？\"></a>Redis回收进程如何工作的？</h3><p>Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。</p>\n"},{"title":"分库分表","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-15T11:41:26.000Z","password":null,"summary":"垂直拆分和水平拆分的概述；分库分表的场景；","_content":"\n## 垂直拆分\n\n- 有多个业务，每个业务单独分到一个实例里面。\n- 在一个库中存在过多的表，把这些表拆分到多个库中。\n- 把字段过多的表拆分成多个表，每张表包含一部分字段。\n\n## 水平拆分\n\n把同一张表分为多张表结构相同的表，每张表里存储一部分数据。\n\n拆分的算法也比较多，常见的就是取模、范围、和全局表等。\n\n## 场景\n\n1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟\n\n2、不同库表之间性能相互影响\n\n","source":"_posts/分库分表.md","raw":"---\ntitle: 分库分表\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-15 19:41:26\npassword:\nsummary: 垂直拆分和水平拆分的概述；分库分表的场景；\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 垂直拆分\n\n- 有多个业务，每个业务单独分到一个实例里面。\n- 在一个库中存在过多的表，把这些表拆分到多个库中。\n- 把字段过多的表拆分成多个表，每张表包含一部分字段。\n\n## 水平拆分\n\n把同一张表分为多张表结构相同的表，每张表里存储一部分数据。\n\n拆分的算法也比较多，常见的就是取模、范围、和全局表等。\n\n## 场景\n\n1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟\n\n2、不同库表之间性能相互影响\n\n","slug":"分库分表","published":1,"updated":"2021-04-29T12:15:42.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss775005dq4uf1lisw9o0","content":"<h2 id=\"垂直拆分\"><a href=\"#垂直拆分\" class=\"headerlink\" title=\"垂直拆分\"></a>垂直拆分</h2><ul>\n<li>有多个业务，每个业务单独分到一个实例里面。</li>\n<li>在一个库中存在过多的表，把这些表拆分到多个库中。</li>\n<li>把字段过多的表拆分成多个表，每张表包含一部分字段。</li>\n</ul>\n<h2 id=\"水平拆分\"><a href=\"#水平拆分\" class=\"headerlink\" title=\"水平拆分\"></a>水平拆分</h2><p>把同一张表分为多张表结构相同的表，每张表里存储一部分数据。</p>\n<p>拆分的算法也比较多，常见的就是取模、范围、和全局表等。</p>\n<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h2><p>1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟</p>\n<p>2、不同库表之间性能相互影响</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"垂直拆分\"><a href=\"#垂直拆分\" class=\"headerlink\" title=\"垂直拆分\"></a>垂直拆分</h2><ul>\n<li>有多个业务，每个业务单独分到一个实例里面。</li>\n<li>在一个库中存在过多的表，把这些表拆分到多个库中。</li>\n<li>把字段过多的表拆分成多个表，每张表包含一部分字段。</li>\n</ul>\n<h2 id=\"水平拆分\"><a href=\"#水平拆分\" class=\"headerlink\" title=\"水平拆分\"></a>水平拆分</h2><p>把同一张表分为多张表结构相同的表，每张表里存储一部分数据。</p>\n<p>拆分的算法也比较多，常见的就是取模、范围、和全局表等。</p>\n<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h2><p>1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟</p>\n<p>2、不同库表之间性能相互影响</p>\n"},{"title":"基础架构","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-21T07:01:22.000Z","password":null,"summary":null,"_content":"\nMySQL可以分为Server层和存储引擎层两部分。\n\n- Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。\n- 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。\n\n## **连接器**\n\n连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n\n尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：\n\n1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2. 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n## **查询缓存**\n\nMySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。\n\n> **建议不要使用查询缓存。**\n\n## **分析器**\n\n词法分析和语法分析。\n\n## **优化器**\n\n确定语句的执行方案。\n\n## **执行器**\n\n开始执行语句。\n\n","source":"_posts/基础架构.md","raw":"---\ntitle: 基础架构\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-21 15:01:22\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\nMySQL可以分为Server层和存储引擎层两部分。\n\n- Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。\n- 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。\n\n## **连接器**\n\n连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n\n尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：\n\n1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2. 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n## **查询缓存**\n\nMySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。\n\n> **建议不要使用查询缓存。**\n\n## **分析器**\n\n词法分析和语法分析。\n\n## **优化器**\n\n确定语句的执行方案。\n\n## **执行器**\n\n开始执行语句。\n\n","slug":"基础架构","published":1,"updated":"2021-04-29T12:21:02.476Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss77r005gq4ufsi5k9ljx","content":"<p>MySQL可以分为Server层和存储引擎层两部分。</p>\n<ul>\n<li>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。</li>\n<li>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。</li>\n</ul>\n<h2 id=\"连接器\"><a href=\"#连接器\" class=\"headerlink\" title=\"连接器\"></a><strong>连接器</strong></h2><p>连接器负责跟客户端建立连接、获取权限、维持和管理连接。</p>\n<p>尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：</p>\n<ol>\n<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>\n<li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>\n</ol>\n<h2 id=\"查询缓存\"><a href=\"#查询缓存\" class=\"headerlink\" title=\"查询缓存\"></a><strong>查询缓存</strong></h2><p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。</p>\n<blockquote>\n<p><strong>建议不要使用查询缓存。</strong></p>\n</blockquote>\n<h2 id=\"分析器\"><a href=\"#分析器\" class=\"headerlink\" title=\"分析器\"></a><strong>分析器</strong></h2><p>词法分析和语法分析。</p>\n<h2 id=\"优化器\"><a href=\"#优化器\" class=\"headerlink\" title=\"优化器\"></a><strong>优化器</strong></h2><p>确定语句的执行方案。</p>\n<h2 id=\"执行器\"><a href=\"#执行器\" class=\"headerlink\" title=\"执行器\"></a><strong>执行器</strong></h2><p>开始执行语句。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>MySQL可以分为Server层和存储引擎层两部分。</p>\n<ul>\n<li>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。</li>\n<li>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。</li>\n</ul>\n<h2 id=\"连接器\"><a href=\"#连接器\" class=\"headerlink\" title=\"连接器\"></a><strong>连接器</strong></h2><p>连接器负责跟客户端建立连接、获取权限、维持和管理连接。</p>\n<p>尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：</p>\n<ol>\n<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>\n<li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>\n</ol>\n<h2 id=\"查询缓存\"><a href=\"#查询缓存\" class=\"headerlink\" title=\"查询缓存\"></a><strong>查询缓存</strong></h2><p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。</p>\n<blockquote>\n<p><strong>建议不要使用查询缓存。</strong></p>\n</blockquote>\n<h2 id=\"分析器\"><a href=\"#分析器\" class=\"headerlink\" title=\"分析器\"></a><strong>分析器</strong></h2><p>词法分析和语法分析。</p>\n<h2 id=\"优化器\"><a href=\"#优化器\" class=\"headerlink\" title=\"优化器\"></a><strong>优化器</strong></h2><p>确定语句的执行方案。</p>\n<h2 id=\"执行器\"><a href=\"#执行器\" class=\"headerlink\" title=\"执行器\"></a><strong>执行器</strong></h2><p>开始执行语句。</p>\n"},{"title":"十大经典排序算法整理汇总（附代码）","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-02-16T07:09:23.000Z","password":null,"summary":"本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。","_content":"\n## 前言\n\n本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。\n\n**本文并不会详细讲解每种排序算法的原理**，网上有很多很好的教程，大家可以自己去搜了看。\n\n最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 [LeetCode 912. 排序数组](https://leetcode-cn.com/problems/sort-an-array/ \"LeetCode 912. 排序数组\") 这道题。\n\n## 性质汇总\n\n> 如果发现表中有错误，请留言告知。\n\n|   算法  |   最好  |  最坏   |  平均   |  空间   |  稳定性   | 是否基于比较\n| --- | --- | --- | --- | --- | :---: | :---: |\n|  冒泡排序   |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|   选择排序  |  $O(n^2)$  |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\times$  | $\\checkmark$ |\n|   插入排序  |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|  快速排序   |  $O(n\\log n)$   |  $O(n^2)$   |  $O(n\\log n)$   |  $O(\\log n)$~$O(n)$   |  $\\times$   | $\\checkmark$ |\n|  归并排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(n)$  |  $\\checkmark$   | $\\checkmark$ |\n|   希尔排序  |  $O(n^{1.3})$   |   $O(n^2)$  |  $O(n\\log n)$~$O(n^2)$   |  $O(1)$   | $\\times$    | $\\checkmark$ |\n|  计数排序   |  $O(n+k)$   |   $O(n+k)$  |   $O(n+k)$  |  $O(n+k)$   |  $\\checkmark$   | $\\times$ |\n|   基数排序  |   $O(nk)$  |  $O(nk)$   |   $O(nk)$  |   $O(n+k)$  |  $\\checkmark$   | $\\times$ |\n|  桶排序   |   $O(n)$  |   $O(n)$  |   $O(n)$  |  $O(n+m)$   |  $\\checkmark$   | $\\times$ |\n|  堆排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(1)$  |  $\\times$   | $\\checkmark$ |\n\n\n\n> 如果表格显示有问题的话，还可以直接看下面的汇总图：\n\n![十大经典排序算法性质汇总](1.png)\n\n### 维基百科\n\n我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。\n\n**冒泡排序**  \n[https://en.wikipedia.org/wiki/Bubble_sort](https://en.wikipedia.org/wiki/Bubble_sort)\n\n**选择排序**  \n[https://en.wikipedia.org/wiki/Selection_sort](https://en.wikipedia.org/wiki/Selection_sort)\n\n**插入排序**  \n[https://en.wikipedia.org/wiki/Insertion_sort](https://en.wikipedia.org/wiki/Insertion_sort)\n\n**快速排序**  \n[https://en.wikipedia.org/wiki/Quicksort](https://en.wikipedia.org/wiki/Quicksort)\n\n**归并排序**  \n[https://en.wikipedia.org/wiki/Merge_sort](https://en.wikipedia.org/wiki/Merge_sort)\n\n**希尔排序**  \n[https://en.wikipedia.org/wiki/Shellsort](https://en.wikipedia.org/wiki/Shellsort)\n\n**计数排序**  \n[https://en.wikipedia.org/wiki/Counting_sort](https://en.wikipedia.org/wiki/Counting_sort)\n\n**基数排序**  \n[https://en.wikipedia.org/wiki/Radix_sort](https://en.wikipedia.org/wiki/Radix_sort)\n\n**桶排序**  \n[https://en.wikipedia.org/wiki/Bucket_sort](https://en.wikipedia.org/wiki/Bucket_sort)\n\n**堆排序**  \n[https://en.wikipedia.org/wiki/Heapsort](https://en.wikipedia.org/wiki/Heapsort)\n\n## 代码实现\n\n所有的排序算法接口都是相同的，也就是 `vector<int> xxxSort(vector<int>& nums)` 。只需要你传入一个 `vector<int>` 类型的数组，就能返回排序后的结果。\n\n运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。\n\n```cpp\nclass Solution {\npublic:\n    vector<int> sortArray(vector<int>& nums) {\n        return quickSort(nums);\n    }\n\n    // 冒泡排序（超时）\n    vector<int> bubbleSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = n-2; j >= i; --j) {\n                if (nums[j] > nums[j+1]) {\n                    swap(nums[j], nums[j+1]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 选择排序（超时）\n    vector<int> selectSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            int idx = i;\n            for (int j = i; j < n; ++j) {\n                if (nums[j] < nums[idx]) {\n                    idx = j;\n                }\n            }\n            swap(nums[i], nums[idx]);\n        }\n        return nums;\n    }\n\n    // 插入排序（超时）\n    vector<int> insertSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = i; j > 0 && nums[j] < nums[j-1]; --j) {\n                swap(nums[j], nums[j-1]);\n            }\n        }\n        return nums;\n    }\n\n    // 快速排序（24 ms）\n    void qSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return;\n        int m = l;\n        for (int i = l; i < r; ++i) {\n            if (nums[i] < nums[r]) {\n                swap(nums[m++], nums[i]);\n            }\n        }\n        swap(nums[m], nums[r]);\n        qSort(nums, l, m-1);\n        qSort(nums, m+1, r);\n    }\n\n    vector<int> quickSort(vector<int>& nums) {\n        int n = nums.size();\n        qSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序（192 ms）\n    vector<int> mSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return {nums[l]};\n        int m = l+(r-l)/2;\n        vector<int> lnums = mSort(nums, l, m);\n        vector<int> rnums = mSort(nums, m+1, r);\n        vector<int> res;\n        int i = 0, j = 0;\n        while (i <= m-l && j <= r-m-1) {\n            if (lnums[i] < rnums[j]) {\n                res.push_back(lnums[i++]);\n            } else {\n                res.push_back(rnums[j++]);\n            }\n        }\n        while (i <= m-l) {\n            res.push_back(lnums[i++]);\n        }\n        while (j <= r-m-1) {\n            res.push_back(rnums[j++]);\n        }\n        return res;\n    }\n\n    vector<int> mergeSort(vector<int>& nums) {\n        int n = nums.size();\n        nums = mSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序 + 非递归（80 ms）\n    vector<int> mergeSortNR(vector<int>& nums) {\n        int n = nums.size();\n        for (int len = 1; len < n; len <<= 1) {\n            for (int l = 0; l < n-len; l += 2*len) {\n                int m = l+len-1;\n                int r = min(n-1, l+2*len-1);\n                vector<int> res;\n                int i = l, j = m+1;\n                while (i <= m && j <= r) {\n                    if (nums[i] < nums[j]) {\n                        res.push_back(nums[i++]);\n                    } else {\n                        res.push_back(nums[j++]);\n                    }\n                }\n                while (i <= m) {\n                    res.push_back(nums[i++]);\n                }\n                while (j <= r) {\n                    res.push_back(nums[j++]);\n                }\n                for (int i = l; i <= r; ++i) {\n                    nums[i] = res[i-l];\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 希尔排序（40 ms）\n    vector<int> shellSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int gap = n/2; gap > 0; gap /= 2) {\n            for (int i = gap; i < n; ++i) {\n                for (int j = i; j-gap >= 0 && nums[j-gap] > nums[j]; j -= gap) {\n                    swap(nums[j-gap], nums[j]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 计数排序（32 ms）\n    vector<int> countSort(vector<int>& nums) {\n        int n = nums.size();\n        if (!n) return {};\n        int minv = *min_element(nums.begin(), nums.end());\n        int maxv = *max_element(nums.begin(), nums.end());\n        int m = maxv-minv+1;\n        vector<int> count(m, 0);\n        for (int i = 0; i < n; ++i) {\n            count[nums[i]-minv]++;\n        }\n        vector<int> res;\n        for (int i = 0; i < m; ++i) {\n            for (int j = 0; j < count[i]; ++j) {\n                res.push_back(i+minv);\n            }\n        }\n        return res;\n    }\n\n    // 基数排序（不适用于负数）\n    vector<int> radixSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int maxd = 0;\n        while (maxv > 0) {\n            maxv /= 10;\n            maxd++;\n        }\n        vector<int> count(10, 0), rank(n, 0);\n        int base = 1;\n        while (maxd > 0) {\n            count.assign(10, 0);\n            for (int i = 0; i < n; ++i) {\n                count[(nums[i]/base)%10]++;\n            }\n            for (int i = 1; i < 10; ++i) {\n                count[i] += count[i-1];\n            }\n            for (int i = n-1; i >= 0; --i) {\n                rank[--count[(nums[i]/base)%10]] = nums[i];\n            }\n            for (int i = 0; i < n; ++i) {\n                nums[i] = rank[i];\n            }\n            maxd--;\n            base *= 10;\n        }\n        return nums;\n    }\n\n    // 桶排序 (20 ms)\n    vector<int> bucketSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int minv = *min_element(nums.begin(), nums.end());\n        int bs = 1000;\n        int m = (maxv-minv)/bs+1;\n        vector<vector<int> > bucket(m);\n        for (int i = 0; i < n; ++i) {\n            bucket[(nums[i]-minv)/bs].push_back(nums[i]);\n        }\n        int idx = 0;\n        for (int i = 0; i < m; ++i) {\n            int sz = bucket[i].size();\n            bucket[i] = quickSort(bucket[i]);\n            for (int j = 0; j < sz; ++j) {\n                nums[idx++] = bucket[i][j];\n            }\n        }\n        return nums;\n    }\n\n    // 堆排序（32 ms）\n    void adjust(vector<int>& nums, int p, int s) {\n        while (2*p+1 < s) {\n            int c1 = 2*p+1;\n            int c2 = 2*p+2;\n            int c = (c2<s && nums[c2]>nums[c1]) ? c2 : c1;\n            if (nums[c] > nums[p]) swap(nums[c], nums[p]);\n            else break;\n            p = c;\n        }\n    }\n\n    vector<int> heapSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = n/2-1; i >= 0; --i) {\n            adjust(nums, i, n);\n        }\n        for (int i = n-1; i > 0; --i) {\n            swap(nums[0], nums[i]);\n            adjust(nums, 0, i);\n        }\n        return nums;\n    }\n};\n```","source":"_posts/sort-algorithms.md","raw":"---\ntitle: 十大经典排序算法整理汇总（附代码）\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-02-16 15:09:23\npassword:\nsummary: 本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。\ntags:\n- 算法\ncategories:\n- 算法\n---\n\n## 前言\n\n本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。\n\n**本文并不会详细讲解每种排序算法的原理**，网上有很多很好的教程，大家可以自己去搜了看。\n\n最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 [LeetCode 912. 排序数组](https://leetcode-cn.com/problems/sort-an-array/ \"LeetCode 912. 排序数组\") 这道题。\n\n## 性质汇总\n\n> 如果发现表中有错误，请留言告知。\n\n|   算法  |   最好  |  最坏   |  平均   |  空间   |  稳定性   | 是否基于比较\n| --- | --- | --- | --- | --- | :---: | :---: |\n|  冒泡排序   |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|   选择排序  |  $O(n^2)$  |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\times$  | $\\checkmark$ |\n|   插入排序  |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|  快速排序   |  $O(n\\log n)$   |  $O(n^2)$   |  $O(n\\log n)$   |  $O(\\log n)$~$O(n)$   |  $\\times$   | $\\checkmark$ |\n|  归并排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(n)$  |  $\\checkmark$   | $\\checkmark$ |\n|   希尔排序  |  $O(n^{1.3})$   |   $O(n^2)$  |  $O(n\\log n)$~$O(n^2)$   |  $O(1)$   | $\\times$    | $\\checkmark$ |\n|  计数排序   |  $O(n+k)$   |   $O(n+k)$  |   $O(n+k)$  |  $O(n+k)$   |  $\\checkmark$   | $\\times$ |\n|   基数排序  |   $O(nk)$  |  $O(nk)$   |   $O(nk)$  |   $O(n+k)$  |  $\\checkmark$   | $\\times$ |\n|  桶排序   |   $O(n)$  |   $O(n)$  |   $O(n)$  |  $O(n+m)$   |  $\\checkmark$   | $\\times$ |\n|  堆排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(1)$  |  $\\times$   | $\\checkmark$ |\n\n\n\n> 如果表格显示有问题的话，还可以直接看下面的汇总图：\n\n![十大经典排序算法性质汇总](1.png)\n\n### 维基百科\n\n我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。\n\n**冒泡排序**  \n[https://en.wikipedia.org/wiki/Bubble_sort](https://en.wikipedia.org/wiki/Bubble_sort)\n\n**选择排序**  \n[https://en.wikipedia.org/wiki/Selection_sort](https://en.wikipedia.org/wiki/Selection_sort)\n\n**插入排序**  \n[https://en.wikipedia.org/wiki/Insertion_sort](https://en.wikipedia.org/wiki/Insertion_sort)\n\n**快速排序**  \n[https://en.wikipedia.org/wiki/Quicksort](https://en.wikipedia.org/wiki/Quicksort)\n\n**归并排序**  \n[https://en.wikipedia.org/wiki/Merge_sort](https://en.wikipedia.org/wiki/Merge_sort)\n\n**希尔排序**  \n[https://en.wikipedia.org/wiki/Shellsort](https://en.wikipedia.org/wiki/Shellsort)\n\n**计数排序**  \n[https://en.wikipedia.org/wiki/Counting_sort](https://en.wikipedia.org/wiki/Counting_sort)\n\n**基数排序**  \n[https://en.wikipedia.org/wiki/Radix_sort](https://en.wikipedia.org/wiki/Radix_sort)\n\n**桶排序**  \n[https://en.wikipedia.org/wiki/Bucket_sort](https://en.wikipedia.org/wiki/Bucket_sort)\n\n**堆排序**  \n[https://en.wikipedia.org/wiki/Heapsort](https://en.wikipedia.org/wiki/Heapsort)\n\n## 代码实现\n\n所有的排序算法接口都是相同的，也就是 `vector<int> xxxSort(vector<int>& nums)` 。只需要你传入一个 `vector<int>` 类型的数组，就能返回排序后的结果。\n\n运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。\n\n```cpp\nclass Solution {\npublic:\n    vector<int> sortArray(vector<int>& nums) {\n        return quickSort(nums);\n    }\n\n    // 冒泡排序（超时）\n    vector<int> bubbleSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = n-2; j >= i; --j) {\n                if (nums[j] > nums[j+1]) {\n                    swap(nums[j], nums[j+1]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 选择排序（超时）\n    vector<int> selectSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            int idx = i;\n            for (int j = i; j < n; ++j) {\n                if (nums[j] < nums[idx]) {\n                    idx = j;\n                }\n            }\n            swap(nums[i], nums[idx]);\n        }\n        return nums;\n    }\n\n    // 插入排序（超时）\n    vector<int> insertSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = i; j > 0 && nums[j] < nums[j-1]; --j) {\n                swap(nums[j], nums[j-1]);\n            }\n        }\n        return nums;\n    }\n\n    // 快速排序（24 ms）\n    void qSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return;\n        int m = l;\n        for (int i = l; i < r; ++i) {\n            if (nums[i] < nums[r]) {\n                swap(nums[m++], nums[i]);\n            }\n        }\n        swap(nums[m], nums[r]);\n        qSort(nums, l, m-1);\n        qSort(nums, m+1, r);\n    }\n\n    vector<int> quickSort(vector<int>& nums) {\n        int n = nums.size();\n        qSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序（192 ms）\n    vector<int> mSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return {nums[l]};\n        int m = l+(r-l)/2;\n        vector<int> lnums = mSort(nums, l, m);\n        vector<int> rnums = mSort(nums, m+1, r);\n        vector<int> res;\n        int i = 0, j = 0;\n        while (i <= m-l && j <= r-m-1) {\n            if (lnums[i] < rnums[j]) {\n                res.push_back(lnums[i++]);\n            } else {\n                res.push_back(rnums[j++]);\n            }\n        }\n        while (i <= m-l) {\n            res.push_back(lnums[i++]);\n        }\n        while (j <= r-m-1) {\n            res.push_back(rnums[j++]);\n        }\n        return res;\n    }\n\n    vector<int> mergeSort(vector<int>& nums) {\n        int n = nums.size();\n        nums = mSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序 + 非递归（80 ms）\n    vector<int> mergeSortNR(vector<int>& nums) {\n        int n = nums.size();\n        for (int len = 1; len < n; len <<= 1) {\n            for (int l = 0; l < n-len; l += 2*len) {\n                int m = l+len-1;\n                int r = min(n-1, l+2*len-1);\n                vector<int> res;\n                int i = l, j = m+1;\n                while (i <= m && j <= r) {\n                    if (nums[i] < nums[j]) {\n                        res.push_back(nums[i++]);\n                    } else {\n                        res.push_back(nums[j++]);\n                    }\n                }\n                while (i <= m) {\n                    res.push_back(nums[i++]);\n                }\n                while (j <= r) {\n                    res.push_back(nums[j++]);\n                }\n                for (int i = l; i <= r; ++i) {\n                    nums[i] = res[i-l];\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 希尔排序（40 ms）\n    vector<int> shellSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int gap = n/2; gap > 0; gap /= 2) {\n            for (int i = gap; i < n; ++i) {\n                for (int j = i; j-gap >= 0 && nums[j-gap] > nums[j]; j -= gap) {\n                    swap(nums[j-gap], nums[j]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 计数排序（32 ms）\n    vector<int> countSort(vector<int>& nums) {\n        int n = nums.size();\n        if (!n) return {};\n        int minv = *min_element(nums.begin(), nums.end());\n        int maxv = *max_element(nums.begin(), nums.end());\n        int m = maxv-minv+1;\n        vector<int> count(m, 0);\n        for (int i = 0; i < n; ++i) {\n            count[nums[i]-minv]++;\n        }\n        vector<int> res;\n        for (int i = 0; i < m; ++i) {\n            for (int j = 0; j < count[i]; ++j) {\n                res.push_back(i+minv);\n            }\n        }\n        return res;\n    }\n\n    // 基数排序（不适用于负数）\n    vector<int> radixSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int maxd = 0;\n        while (maxv > 0) {\n            maxv /= 10;\n            maxd++;\n        }\n        vector<int> count(10, 0), rank(n, 0);\n        int base = 1;\n        while (maxd > 0) {\n            count.assign(10, 0);\n            for (int i = 0; i < n; ++i) {\n                count[(nums[i]/base)%10]++;\n            }\n            for (int i = 1; i < 10; ++i) {\n                count[i] += count[i-1];\n            }\n            for (int i = n-1; i >= 0; --i) {\n                rank[--count[(nums[i]/base)%10]] = nums[i];\n            }\n            for (int i = 0; i < n; ++i) {\n                nums[i] = rank[i];\n            }\n            maxd--;\n            base *= 10;\n        }\n        return nums;\n    }\n\n    // 桶排序 (20 ms)\n    vector<int> bucketSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int minv = *min_element(nums.begin(), nums.end());\n        int bs = 1000;\n        int m = (maxv-minv)/bs+1;\n        vector<vector<int> > bucket(m);\n        for (int i = 0; i < n; ++i) {\n            bucket[(nums[i]-minv)/bs].push_back(nums[i]);\n        }\n        int idx = 0;\n        for (int i = 0; i < m; ++i) {\n            int sz = bucket[i].size();\n            bucket[i] = quickSort(bucket[i]);\n            for (int j = 0; j < sz; ++j) {\n                nums[idx++] = bucket[i][j];\n            }\n        }\n        return nums;\n    }\n\n    // 堆排序（32 ms）\n    void adjust(vector<int>& nums, int p, int s) {\n        while (2*p+1 < s) {\n            int c1 = 2*p+1;\n            int c2 = 2*p+2;\n            int c = (c2<s && nums[c2]>nums[c1]) ? c2 : c1;\n            if (nums[c] > nums[p]) swap(nums[c], nums[p]);\n            else break;\n            p = c;\n        }\n    }\n\n    vector<int> heapSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = n/2-1; i >= 0; --i) {\n            adjust(nums, i, n);\n        }\n        for (int i = n-1; i > 0; --i) {\n            swap(nums[0], nums[i]);\n            adjust(nums, 0, i);\n        }\n        return nums;\n    }\n};\n```","slug":"sort-algorithms","published":1,"updated":"2021-04-01T23:01:50.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss77w005jq4uf41b0lo0e","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。</p>\n<p><strong>本文并不会详细讲解每种排序算法的原理</strong>，网上有很多很好的教程，大家可以自己去搜了看。</p>\n<p>最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 <a href=\"https://leetcode-cn.com/problems/sort-an-array/\" title=\"LeetCode 912. 排序数组\" target=\"_blank\" rel=\"noopener\">LeetCode 912. 排序数组</a> 这道题。</p>\n<h2 id=\"性质汇总\"><a href=\"#性质汇总\" class=\"headerlink\" title=\"性质汇总\"></a>性质汇总</h2><blockquote>\n<p>如果发现表中有错误，请留言告知。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>最好</th>\n<th>最坏</th>\n<th>平均</th>\n<th>空间</th>\n<th align=\"center\">稳定性</th>\n<th align=\"center\">是否基于比较</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>冒泡排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>选择排序</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>插入排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>快速排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(\\log n)$~$O(n)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>归并排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>希尔排序</td>\n<td>$O(n^{1.3})$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$~$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>计数排序</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>基数排序</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>桶排序</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n+m)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>堆排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>如果表格显示有问题的话，还可以直接看下面的汇总图：</p>\n</blockquote>\n<p><img src=\"1.png\" alt=\"十大经典排序算法性质汇总\"></p>\n<h3 id=\"维基百科\"><a href=\"#维基百科\" class=\"headerlink\" title=\"维基百科\"></a>维基百科</h3><p>我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。</p>\n<p><strong>冒泡排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bubble_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bubble_sort</a></p>\n<p><strong>选择排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Selection_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Selection_sort</a></p>\n<p><strong>插入排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Insertion_sort</a></p>\n<p><strong>快速排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Quicksort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Quicksort</a></p>\n<p><strong>归并排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Merge_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Merge_sort</a></p>\n<p><strong>希尔排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Shellsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Shellsort</a></p>\n<p><strong>计数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Counting_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Counting_sort</a></p>\n<p><strong>基数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Radix_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Radix_sort</a></p>\n<p><strong>桶排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bucket_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bucket_sort</a></p>\n<p><strong>堆排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Heapsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Heapsort</a></p>\n<h2 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>所有的排序算法接口都是相同的，也就是 <code>vector&lt;int&gt; xxxSort(vector&lt;int&gt;&amp; nums)</code> 。只需要你传入一个 <code>vector&lt;int&gt;</code> 类型的数组，就能返回排序后的结果。</p>\n<p>运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。</p>\n<pre class=\"line-numbers language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Solution</span> <span class=\"token punctuation\">{</span>\n<span class=\"token keyword\">public</span><span class=\"token operator\">:</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">sortArray</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">quickSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 冒泡排序（超时）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">bubbleSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> n<span class=\"token number\">-2</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">>=</span> i<span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 选择排序（超时）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">selectSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    idx <span class=\"token operator\">=</span> j<span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 插入排序（超时）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">insertSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token operator\">&amp;&amp;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 快速排序（24 ms）</span>\n    <span class=\"token keyword\">void</span> <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> l<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>l <span class=\"token operator\">>=</span> r<span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> r<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>r<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>m<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>r<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> l<span class=\"token punctuation\">,</span> m<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> m<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">quickSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 归并排序（192 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> l<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>l <span class=\"token operator\">>=</span> r<span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>nums<span class=\"token punctuation\">[</span>l<span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> l<span class=\"token operator\">+</span><span class=\"token punctuation\">(</span>r<span class=\"token operator\">-</span>l<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> lnums <span class=\"token operator\">=</span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> l<span class=\"token punctuation\">,</span> m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> rnums <span class=\"token operator\">=</span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> m<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> res<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> j <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m<span class=\"token operator\">-</span>l <span class=\"token operator\">&amp;&amp;</span> j <span class=\"token operator\">&lt;=</span> r<span class=\"token operator\">-</span>m<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>lnums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> rnums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>lnums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n                res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>rnums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m<span class=\"token operator\">-</span>l<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>lnums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>j <span class=\"token operator\">&lt;=</span> r<span class=\"token operator\">-</span>m<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>rnums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> res<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">mergeSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        nums <span class=\"token operator\">=</span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 归并排序 + 非递归（80 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">mergeSortNR</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> len <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> len <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> len <span class=\"token operator\">&lt;&lt;=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> l <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> l <span class=\"token operator\">&lt;</span> n<span class=\"token operator\">-</span>len<span class=\"token punctuation\">;</span> l <span class=\"token operator\">+</span><span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>len<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> l<span class=\"token operator\">+</span>len<span class=\"token number\">-1</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">int</span> r <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span>n<span class=\"token number\">-1</span><span class=\"token punctuation\">,</span> l<span class=\"token operator\">+</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>len<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> res<span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> l<span class=\"token punctuation\">,</span> j <span class=\"token operator\">=</span> m<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m <span class=\"token operator\">&amp;&amp;</span> j <span class=\"token operator\">&lt;=</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                        res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n                        res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span>\n                <span class=\"token punctuation\">}</span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>j <span class=\"token operator\">&lt;=</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n                <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;=</span> r<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> res<span class=\"token punctuation\">[</span>i<span class=\"token operator\">-</span>l<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 希尔排序（40 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">shellSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> gap <span class=\"token operator\">=</span> n<span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span> gap <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> gap <span class=\"token operator\">/</span><span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> gap<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j<span class=\"token operator\">-</span>gap <span class=\"token operator\">>=</span> <span class=\"token number\">0</span> <span class=\"token operator\">&amp;&amp;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">-</span>gap<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">-</span><span class=\"token operator\">=</span> gap<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">-</span>gap<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 计数排序（32 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">countSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> minv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">min_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">max_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> maxv<span class=\"token operator\">-</span>minv<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            count<span class=\"token punctuation\">[</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">-</span>minv<span class=\"token punctuation\">]</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> res<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> m<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">&lt;</span> count<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>i<span class=\"token operator\">+</span>minv<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> res<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 基数排序（不适用于负数）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">radixSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">max_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxd <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>maxv <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            maxv <span class=\"token operator\">/</span><span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n            maxd<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token function\">rank</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> base <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>maxd <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            count<span class=\"token punctuation\">.</span><span class=\"token function\">assign</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                count<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>base<span class=\"token punctuation\">)</span><span class=\"token operator\">%</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                count<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span><span class=\"token operator\">=</span> count<span class=\"token punctuation\">[</span>i<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                rank<span class=\"token punctuation\">[</span><span class=\"token operator\">--</span>count<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>base<span class=\"token punctuation\">)</span><span class=\"token operator\">%</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> rank<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            maxd<span class=\"token operator\">--</span><span class=\"token punctuation\">;</span>\n            base <span class=\"token operator\">*</span><span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 桶排序 (20 ms)</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">bucketSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">max_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> minv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">min_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> bs <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>maxv<span class=\"token operator\">-</span>minv<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>bs<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token operator\">></span> <span class=\"token function\">bucket</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            bucket<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">-</span>minv<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>bs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> m<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">int</span> sz <span class=\"token operator\">=</span> bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token function\">quickSort</span><span class=\"token punctuation\">(</span>bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">&lt;</span> sz<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                nums<span class=\"token punctuation\">[</span>idx<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 堆排序（32 ms）</span>\n    <span class=\"token keyword\">void</span> <span class=\"token function\">adjust</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> p<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>p<span class=\"token operator\">+</span><span class=\"token number\">1</span> <span class=\"token operator\">&lt;</span> s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">int</span> c1 <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>p<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">int</span> c2 <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>p<span class=\"token operator\">+</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">int</span> c <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>c2<span class=\"token operator\">&lt;</span>s <span class=\"token operator\">&amp;&amp;</span> nums<span class=\"token punctuation\">[</span>c2<span class=\"token punctuation\">]</span><span class=\"token operator\">></span>nums<span class=\"token punctuation\">[</span>c1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">?</span> c2 <span class=\"token operator\">:</span> c1<span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>c<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>p<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>c<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>p<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">else</span> <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n            p <span class=\"token operator\">=</span> c<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">heapSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> n<span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token function\">adjust</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token function\">adjust</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。</p>\n<p><strong>本文并不会详细讲解每种排序算法的原理</strong>，网上有很多很好的教程，大家可以自己去搜了看。</p>\n<p>最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 <a href=\"https://leetcode-cn.com/problems/sort-an-array/\" title=\"LeetCode 912. 排序数组\" target=\"_blank\" rel=\"noopener\">LeetCode 912. 排序数组</a> 这道题。</p>\n<h2 id=\"性质汇总\"><a href=\"#性质汇总\" class=\"headerlink\" title=\"性质汇总\"></a>性质汇总</h2><blockquote>\n<p>如果发现表中有错误，请留言告知。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>最好</th>\n<th>最坏</th>\n<th>平均</th>\n<th>空间</th>\n<th align=\"center\">稳定性</th>\n<th align=\"center\">是否基于比较</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>冒泡排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>选择排序</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>插入排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>快速排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(\\log n)$~$O(n)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>归并排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>希尔排序</td>\n<td>$O(n^{1.3})$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$~$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>计数排序</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>基数排序</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>桶排序</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n+m)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>堆排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>如果表格显示有问题的话，还可以直接看下面的汇总图：</p>\n</blockquote>\n<p><img src=\"1.png\" alt=\"十大经典排序算法性质汇总\"></p>\n<h3 id=\"维基百科\"><a href=\"#维基百科\" class=\"headerlink\" title=\"维基百科\"></a>维基百科</h3><p>我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。</p>\n<p><strong>冒泡排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bubble_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bubble_sort</a></p>\n<p><strong>选择排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Selection_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Selection_sort</a></p>\n<p><strong>插入排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Insertion_sort</a></p>\n<p><strong>快速排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Quicksort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Quicksort</a></p>\n<p><strong>归并排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Merge_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Merge_sort</a></p>\n<p><strong>希尔排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Shellsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Shellsort</a></p>\n<p><strong>计数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Counting_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Counting_sort</a></p>\n<p><strong>基数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Radix_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Radix_sort</a></p>\n<p><strong>桶排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bucket_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bucket_sort</a></p>\n<p><strong>堆排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Heapsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Heapsort</a></p>\n<h2 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>所有的排序算法接口都是相同的，也就是 <code>vector&lt;int&gt; xxxSort(vector&lt;int&gt;&amp; nums)</code> 。只需要你传入一个 <code>vector&lt;int&gt;</code> 类型的数组，就能返回排序后的结果。</p>\n<p>运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。</p>\n<pre><code class=\"cpp\">class Solution {\npublic:\n    vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) {\n        return quickSort(nums);\n    }\n\n    // 冒泡排序（超时）\n    vector&lt;int&gt; bubbleSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = 0; i &lt; n; ++i) {\n            for (int j = n-2; j &gt;= i; --j) {\n                if (nums[j] &gt; nums[j+1]) {\n                    swap(nums[j], nums[j+1]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 选择排序（超时）\n    vector&lt;int&gt; selectSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = 0; i &lt; n; ++i) {\n            int idx = i;\n            for (int j = i; j &lt; n; ++j) {\n                if (nums[j] &lt; nums[idx]) {\n                    idx = j;\n                }\n            }\n            swap(nums[i], nums[idx]);\n        }\n        return nums;\n    }\n\n    // 插入排序（超时）\n    vector&lt;int&gt; insertSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = 0; i &lt; n; ++i) {\n            for (int j = i; j &gt; 0 &amp;&amp; nums[j] &lt; nums[j-1]; --j) {\n                swap(nums[j], nums[j-1]);\n            }\n        }\n        return nums;\n    }\n\n    // 快速排序（24 ms）\n    void qSort(vector&lt;int&gt;&amp; nums, int l, int r) {\n        if (l &gt;= r) return;\n        int m = l;\n        for (int i = l; i &lt; r; ++i) {\n            if (nums[i] &lt; nums[r]) {\n                swap(nums[m++], nums[i]);\n            }\n        }\n        swap(nums[m], nums[r]);\n        qSort(nums, l, m-1);\n        qSort(nums, m+1, r);\n    }\n\n    vector&lt;int&gt; quickSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        qSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序（192 ms）\n    vector&lt;int&gt; mSort(vector&lt;int&gt;&amp; nums, int l, int r) {\n        if (l &gt;= r) return {nums[l]};\n        int m = l+(r-l)/2;\n        vector&lt;int&gt; lnums = mSort(nums, l, m);\n        vector&lt;int&gt; rnums = mSort(nums, m+1, r);\n        vector&lt;int&gt; res;\n        int i = 0, j = 0;\n        while (i &lt;= m-l &amp;&amp; j &lt;= r-m-1) {\n            if (lnums[i] &lt; rnums[j]) {\n                res.push_back(lnums[i++]);\n            } else {\n                res.push_back(rnums[j++]);\n            }\n        }\n        while (i &lt;= m-l) {\n            res.push_back(lnums[i++]);\n        }\n        while (j &lt;= r-m-1) {\n            res.push_back(rnums[j++]);\n        }\n        return res;\n    }\n\n    vector&lt;int&gt; mergeSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        nums = mSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序 + 非递归（80 ms）\n    vector&lt;int&gt; mergeSortNR(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int len = 1; len &lt; n; len &lt;&lt;= 1) {\n            for (int l = 0; l &lt; n-len; l += 2*len) {\n                int m = l+len-1;\n                int r = min(n-1, l+2*len-1);\n                vector&lt;int&gt; res;\n                int i = l, j = m+1;\n                while (i &lt;= m &amp;&amp; j &lt;= r) {\n                    if (nums[i] &lt; nums[j]) {\n                        res.push_back(nums[i++]);\n                    } else {\n                        res.push_back(nums[j++]);\n                    }\n                }\n                while (i &lt;= m) {\n                    res.push_back(nums[i++]);\n                }\n                while (j &lt;= r) {\n                    res.push_back(nums[j++]);\n                }\n                for (int i = l; i &lt;= r; ++i) {\n                    nums[i] = res[i-l];\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 希尔排序（40 ms）\n    vector&lt;int&gt; shellSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int gap = n/2; gap &gt; 0; gap /= 2) {\n            for (int i = gap; i &lt; n; ++i) {\n                for (int j = i; j-gap &gt;= 0 &amp;&amp; nums[j-gap] &gt; nums[j]; j -= gap) {\n                    swap(nums[j-gap], nums[j]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 计数排序（32 ms）\n    vector&lt;int&gt; countSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        if (!n) return {};\n        int minv = *min_element(nums.begin(), nums.end());\n        int maxv = *max_element(nums.begin(), nums.end());\n        int m = maxv-minv+1;\n        vector&lt;int&gt; count(m, 0);\n        for (int i = 0; i &lt; n; ++i) {\n            count[nums[i]-minv]++;\n        }\n        vector&lt;int&gt; res;\n        for (int i = 0; i &lt; m; ++i) {\n            for (int j = 0; j &lt; count[i]; ++j) {\n                res.push_back(i+minv);\n            }\n        }\n        return res;\n    }\n\n    // 基数排序（不适用于负数）\n    vector&lt;int&gt; radixSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int maxd = 0;\n        while (maxv &gt; 0) {\n            maxv /= 10;\n            maxd++;\n        }\n        vector&lt;int&gt; count(10, 0), rank(n, 0);\n        int base = 1;\n        while (maxd &gt; 0) {\n            count.assign(10, 0);\n            for (int i = 0; i &lt; n; ++i) {\n                count[(nums[i]/base)%10]++;\n            }\n            for (int i = 1; i &lt; 10; ++i) {\n                count[i] += count[i-1];\n            }\n            for (int i = n-1; i &gt;= 0; --i) {\n                rank[--count[(nums[i]/base)%10]] = nums[i];\n            }\n            for (int i = 0; i &lt; n; ++i) {\n                nums[i] = rank[i];\n            }\n            maxd--;\n            base *= 10;\n        }\n        return nums;\n    }\n\n    // 桶排序 (20 ms)\n    vector&lt;int&gt; bucketSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int minv = *min_element(nums.begin(), nums.end());\n        int bs = 1000;\n        int m = (maxv-minv)/bs+1;\n        vector&lt;vector&lt;int&gt; &gt; bucket(m);\n        for (int i = 0; i &lt; n; ++i) {\n            bucket[(nums[i]-minv)/bs].push_back(nums[i]);\n        }\n        int idx = 0;\n        for (int i = 0; i &lt; m; ++i) {\n            int sz = bucket[i].size();\n            bucket[i] = quickSort(bucket[i]);\n            for (int j = 0; j &lt; sz; ++j) {\n                nums[idx++] = bucket[i][j];\n            }\n        }\n        return nums;\n    }\n\n    // 堆排序（32 ms）\n    void adjust(vector&lt;int&gt;&amp; nums, int p, int s) {\n        while (2*p+1 &lt; s) {\n            int c1 = 2*p+1;\n            int c2 = 2*p+2;\n            int c = (c2&lt;s &amp;&amp; nums[c2]&gt;nums[c1]) ? c2 : c1;\n            if (nums[c] &gt; nums[p]) swap(nums[c], nums[p]);\n            else break;\n            p = c;\n        }\n    }\n\n    vector&lt;int&gt; heapSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = n/2-1; i &gt;= 0; --i) {\n            adjust(nums, i, n);\n        }\n        for (int i = n-1; i &gt; 0; --i) {\n            swap(nums[0], nums[i]);\n            adjust(nums, 0, i);\n        }\n        return nums;\n    }\n};</code></pre>\n"},{"title":"基于多CPU多核架构的redis性能优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:40:55.000Z","password":null,"summary":null,"_content":"\n## CPU架构\n\n- 一个 CPU 处理器中一般有多个物理核。\n- 每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。\n- 不同的物理核还会共享一个共同的三级缓存\n- 每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存\n- 不同处理器间通过总线连接\n\n## 问题\n\n1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）\n\n2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。\n\n3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。\n\n## 优化\n\n1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上\n2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。\n3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。\n\n注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。","source":"_posts/基于多CPU多核架构的redis性能优化.md","raw":"---\ntitle: 基于多CPU多核架构的redis性能优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:40:55\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## CPU架构\n\n- 一个 CPU 处理器中一般有多个物理核。\n- 每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。\n- 不同的物理核还会共享一个共同的三级缓存\n- 每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存\n- 不同处理器间通过总线连接\n\n## 问题\n\n1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）\n\n2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。\n\n3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。\n\n## 优化\n\n1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上\n2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。\n3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。\n\n注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。","slug":"基于多CPU多核架构的redis性能优化","published":1,"updated":"2021-04-01T23:01:50.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss781005mq4ufgst3z0fd","content":"<h2 id=\"CPU架构\"><a href=\"#CPU架构\" class=\"headerlink\" title=\"CPU架构\"></a>CPU架构</h2><ul>\n<li>一个 CPU 处理器中一般有多个物理核。</li>\n<li>每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。</li>\n<li>不同的物理核还会共享一个共同的三级缓存</li>\n<li>每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存</li>\n<li>不同处理器间通过总线连接</li>\n</ul>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）</p>\n<p>2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。</p>\n<p>3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上<br>2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。<br>3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。</p>\n<p>注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"CPU架构\"><a href=\"#CPU架构\" class=\"headerlink\" title=\"CPU架构\"></a>CPU架构</h2><ul>\n<li>一个 CPU 处理器中一般有多个物理核。</li>\n<li>每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。</li>\n<li>不同的物理核还会共享一个共同的三级缓存</li>\n<li>每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存</li>\n<li>不同处理器间通过总线连接</li>\n</ul>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）</p>\n<p>2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。</p>\n<p>3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上<br>2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。<br>3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。</p>\n<p>注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p>\n"},{"title":"批量数据导入优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T03:53:46.000Z","password":null,"summary":"批量数据导入优化方法：一次插入多行的值，关闭自动提交，redo log和bin log刷盘次数。","_content":"\n插入行所需的时间由以下因素决定[mysql manual](https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html)\n\n- 连接：30%\n- 向服务器发送查询：20%\n- 解析查询：20%\n- 插入行：10% * 行的大小\n- 插入索引：10% * 索引数\n- 结束：10%\n\n## 一次插入多行的值\n\n有大批量导入时，推荐一条insert语句插入多行数据。\n\n原因：减少服务器通信时间\n\n## 关闭自动提交\n\nAutocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。\n\n原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。\n\n## 参数调整\n\ninnodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略\n\n- 0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；\n- 1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；\n- 2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。\n\nsync_binlog：控制binlog的刷盘时机\n\n- 0：二进制日志从不同步到磁盘，依赖OS刷盘机制；\n- 1：二进制日志每次提交都会刷盘；\n- n : 每n次提交落盘一次。\n\ninnodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。","source":"_posts/批量数据导入优化.md","raw":"---\ntitle: 批量数据导入优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 11:53:46\npassword:\nsummary: 批量数据导入优化方法：一次插入多行的值，关闭自动提交，redo log和bin log刷盘次数。\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n插入行所需的时间由以下因素决定[mysql manual](https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html)\n\n- 连接：30%\n- 向服务器发送查询：20%\n- 解析查询：20%\n- 插入行：10% * 行的大小\n- 插入索引：10% * 索引数\n- 结束：10%\n\n## 一次插入多行的值\n\n有大批量导入时，推荐一条insert语句插入多行数据。\n\n原因：减少服务器通信时间\n\n## 关闭自动提交\n\nAutocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。\n\n原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。\n\n## 参数调整\n\ninnodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略\n\n- 0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；\n- 1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；\n- 2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。\n\nsync_binlog：控制binlog的刷盘时机\n\n- 0：二进制日志从不同步到磁盘，依赖OS刷盘机制；\n- 1：二进制日志每次提交都会刷盘；\n- n : 每n次提交落盘一次。\n\ninnodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。","slug":"批量数据导入优化","published":1,"updated":"2021-05-11T12:09:07.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss789005rq4uf2pnbs0u1","content":"<p>插入行所需的时间由以下因素决定<a href=\"https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html\" target=\"_blank\" rel=\"noopener\">mysql manual</a></p>\n<ul>\n<li>连接：30%</li>\n<li>向服务器发送查询：20%</li>\n<li>解析查询：20%</li>\n<li>插入行：10% * 行的大小</li>\n<li>插入索引：10% * 索引数</li>\n<li>结束：10%</li>\n</ul>\n<h2 id=\"一次插入多行的值\"><a href=\"#一次插入多行的值\" class=\"headerlink\" title=\"一次插入多行的值\"></a>一次插入多行的值</h2><p>有大批量导入时，推荐一条insert语句插入多行数据。</p>\n<p>原因：减少服务器通信时间</p>\n<h2 id=\"关闭自动提交\"><a href=\"#关闭自动提交\" class=\"headerlink\" title=\"关闭自动提交\"></a>关闭自动提交</h2><p>Autocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。</p>\n<p>原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。</p>\n<h2 id=\"参数调整\"><a href=\"#参数调整\" class=\"headerlink\" title=\"参数调整\"></a>参数调整</h2><p>innodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略</p>\n<ul>\n<li>0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。</li>\n</ul>\n<p>sync_binlog：控制binlog的刷盘时机</p>\n<ul>\n<li>0：二进制日志从不同步到磁盘，依赖OS刷盘机制；</li>\n<li>1：二进制日志每次提交都会刷盘；</li>\n<li>n : 每n次提交落盘一次。</li>\n</ul>\n<p>innodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>插入行所需的时间由以下因素决定<a href=\"https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html\" target=\"_blank\" rel=\"noopener\">mysql manual</a></p>\n<ul>\n<li>连接：30%</li>\n<li>向服务器发送查询：20%</li>\n<li>解析查询：20%</li>\n<li>插入行：10% * 行的大小</li>\n<li>插入索引：10% * 索引数</li>\n<li>结束：10%</li>\n</ul>\n<h2 id=\"一次插入多行的值\"><a href=\"#一次插入多行的值\" class=\"headerlink\" title=\"一次插入多行的值\"></a>一次插入多行的值</h2><p>有大批量导入时，推荐一条insert语句插入多行数据。</p>\n<p>原因：减少服务器通信时间</p>\n<h2 id=\"关闭自动提交\"><a href=\"#关闭自动提交\" class=\"headerlink\" title=\"关闭自动提交\"></a>关闭自动提交</h2><p>Autocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。</p>\n<p>原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。</p>\n<h2 id=\"参数调整\"><a href=\"#参数调整\" class=\"headerlink\" title=\"参数调整\"></a>参数调整</h2><p>innodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略</p>\n<ul>\n<li>0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。</li>\n</ul>\n<p>sync_binlog：控制binlog的刷盘时机</p>\n<ul>\n<li>0：二进制日志从不同步到磁盘，依赖OS刷盘机制；</li>\n<li>1：二进制日志每次提交都会刷盘；</li>\n<li>n : 每n次提交落盘一次。</li>\n</ul>\n<p>innodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。</p>\n"},{"title":"慢查询定位与分析","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-11T13:58:12.000Z","password":null,"summary":"慢查询的定位和分析方法。","_content":"\n## 定位慢sql\n\n### 1、查看慢查询日志确定已经执行完的慢查询\n\n```mysql\nmysql> set global slow_query_log = on;\nmysql> set global long_query_time = 1;\nmysql> show global variables like \"datadir\";\nmysql> show global variables like \"slow_query_log_file\";\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);\n```\n\n可以看到查询时间、表锁时间、扫描行数Rows_examined。\n\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。\n\n### 2、show processlist 查看正在执行的慢查询\n\n```mysql\nmysql> show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`\n```\n\n可以看到执行时间和SQL语句\n\n## 分析慢查询\n\n### 1、使用 explain 分析慢查询\n\n获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：\n\n- select_type ：查询类型，是简单还是复杂查询\n\n- type ：查询的表连接类型\n\n- key ：实际选择的索引\n\n- rows： 预计需要扫描的行数，对 InnoDB 来说，这个值是估值\n\n- Extra ：附加信息\n\n| select_type          | 含义                                                        |\n| :------------------- | ----------------------------------------------------------- |\n| SIMPLE               | 简单查询，不使用关联查询或子查询                            |\n| PRIMARY              | 如果包含关联查询或者子查询，则最外层的查询部分标记为primary |\n| UNION                | 联合查询中第二个及后面的查询                                |\n| DEPENDENT UNION      | 满足依赖外部的关联查询中第二个及以后的查询                  |\n| UNION RESULT         | 联合查询的结果                                              |\n| SUBQUERY             | 子查询中的第一个查询                                        |\n| DEPENDENT SUBQUERY   | 子查询中的第一个查询，并且依赖外部查询                      |\n| DERIVED              | 用到派生表的查询                                            |\n| MATERIALIZED         | 被物化的子查询                                              |\n| UNCACHEABLE SUBQUERY | 一个子查询的结果不能被缓存，必须重新评估外层查询的每一行    |\n| UNCACHEABLE UNION    | 关联查询第二个或后面的语句属于不可缓存的子查询              |\n\n| type            | 含义                                     |\n| :-------------- | :--------------------------------------- |\n| system          | 查询对象表只有一行数据                   |\n| const           | 基于主键或唯一索引查询，最多返回一条结果 |\n| eq_ref          | 最多只返回一条符合条件的记录。           |\n| ref             | 基于普通索引的等值查询，或者表间等值连接 |\n| fulltext        | 全文检索                                 |\n| ref_or_null     | 表连接类型是                             |\n| index_merge     | 利用多个索引                             |\n| unique_subquery | 子查询中使用唯一索引                     |\n| index_subquery  | 子查询中使用普通索引                     |\n| range           | 利用索引进行范围查询                     |\n| index           | 全索引扫描                               |\n| ALL             | 全表扫描                                 |\n\n| Extra                                 | 解释                                                         |\n| :------------------------------------ | :----------------------------------------------------------- |\n| Using filesort                        | 将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序 |\n| Using temporary                       | 需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时 |\n| Using index                           | 使用覆盖索引                                                 |\n| Using where                           | 使用 where 语句来处理结果                                    |\n| Impossible WHERE                      | 对 where 子句判断的结果总是 false 而不能选择任何数据         |\n| Using join buffer（BlockNested Loop） | 关联查询中，被驱动表的关联字段没索引                         |\n| Using index condition                 | 先条件过滤索引，再查数据                                     |\n| Select tables optimized away          | 使用某些聚合函数（比如 max、min）来访问存在索引的某个字段    |\n\n### 2、show profile\n\n了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节\n\n```mysql\nmysql> select @@have_profiling;\nmysql> select @@profiling;\nmysql> set profiling=1;\nmysql> select * from t1 where b=1000;\nmysql> show profiles;  /*获取query id*/\nmysql> show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)\n```\n\n### 3、trace\n\n使用 trace 查看优化器如何选择执行计划\n\n```mysql\nmysql> set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;\n/* optimizer_trace=\"enabled=on\" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql> select * from t1 where a >900 and b > 910 order by a;\nmysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n\n```\n\nTRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。\n\n也可以看number_of_tmp_files中判断是否使用了临时文件。\n\n","source":"_posts/慢查询定位与分析.md","raw":"---\ntitle: 慢查询定位与分析\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-11 21:58:12\npassword:\nsummary: 慢查询的定位和分析方法。\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 定位慢sql\n\n### 1、查看慢查询日志确定已经执行完的慢查询\n\n```mysql\nmysql> set global slow_query_log = on;\nmysql> set global long_query_time = 1;\nmysql> show global variables like \"datadir\";\nmysql> show global variables like \"slow_query_log_file\";\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);\n```\n\n可以看到查询时间、表锁时间、扫描行数Rows_examined。\n\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。\n\n### 2、show processlist 查看正在执行的慢查询\n\n```mysql\nmysql> show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`\n```\n\n可以看到执行时间和SQL语句\n\n## 分析慢查询\n\n### 1、使用 explain 分析慢查询\n\n获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：\n\n- select_type ：查询类型，是简单还是复杂查询\n\n- type ：查询的表连接类型\n\n- key ：实际选择的索引\n\n- rows： 预计需要扫描的行数，对 InnoDB 来说，这个值是估值\n\n- Extra ：附加信息\n\n| select_type          | 含义                                                        |\n| :------------------- | ----------------------------------------------------------- |\n| SIMPLE               | 简单查询，不使用关联查询或子查询                            |\n| PRIMARY              | 如果包含关联查询或者子查询，则最外层的查询部分标记为primary |\n| UNION                | 联合查询中第二个及后面的查询                                |\n| DEPENDENT UNION      | 满足依赖外部的关联查询中第二个及以后的查询                  |\n| UNION RESULT         | 联合查询的结果                                              |\n| SUBQUERY             | 子查询中的第一个查询                                        |\n| DEPENDENT SUBQUERY   | 子查询中的第一个查询，并且依赖外部查询                      |\n| DERIVED              | 用到派生表的查询                                            |\n| MATERIALIZED         | 被物化的子查询                                              |\n| UNCACHEABLE SUBQUERY | 一个子查询的结果不能被缓存，必须重新评估外层查询的每一行    |\n| UNCACHEABLE UNION    | 关联查询第二个或后面的语句属于不可缓存的子查询              |\n\n| type            | 含义                                     |\n| :-------------- | :--------------------------------------- |\n| system          | 查询对象表只有一行数据                   |\n| const           | 基于主键或唯一索引查询，最多返回一条结果 |\n| eq_ref          | 最多只返回一条符合条件的记录。           |\n| ref             | 基于普通索引的等值查询，或者表间等值连接 |\n| fulltext        | 全文检索                                 |\n| ref_or_null     | 表连接类型是                             |\n| index_merge     | 利用多个索引                             |\n| unique_subquery | 子查询中使用唯一索引                     |\n| index_subquery  | 子查询中使用普通索引                     |\n| range           | 利用索引进行范围查询                     |\n| index           | 全索引扫描                               |\n| ALL             | 全表扫描                                 |\n\n| Extra                                 | 解释                                                         |\n| :------------------------------------ | :----------------------------------------------------------- |\n| Using filesort                        | 将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序 |\n| Using temporary                       | 需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时 |\n| Using index                           | 使用覆盖索引                                                 |\n| Using where                           | 使用 where 语句来处理结果                                    |\n| Impossible WHERE                      | 对 where 子句判断的结果总是 false 而不能选择任何数据         |\n| Using join buffer（BlockNested Loop） | 关联查询中，被驱动表的关联字段没索引                         |\n| Using index condition                 | 先条件过滤索引，再查数据                                     |\n| Select tables optimized away          | 使用某些聚合函数（比如 max、min）来访问存在索引的某个字段    |\n\n### 2、show profile\n\n了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节\n\n```mysql\nmysql> select @@have_profiling;\nmysql> select @@profiling;\nmysql> set profiling=1;\nmysql> select * from t1 where b=1000;\nmysql> show profiles;  /*获取query id*/\nmysql> show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)\n```\n\n### 3、trace\n\n使用 trace 查看优化器如何选择执行计划\n\n```mysql\nmysql> set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;\n/* optimizer_trace=\"enabled=on\" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql> select * from t1 where a >900 and b > 910 order by a;\nmysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n\n```\n\nTRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。\n\n也可以看number_of_tmp_files中判断是否使用了临时文件。\n\n","slug":"慢查询定位与分析","published":1,"updated":"2021-04-29T13:11:26.025Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78e005uq4uf1cx1ownc","content":"<h2 id=\"定位慢sql\"><a href=\"#定位慢sql\" class=\"headerlink\" title=\"定位慢sql\"></a>定位慢sql</h2><h3 id=\"1、查看慢查询日志确定已经执行完的慢查询\"><a href=\"#1、查看慢查询日志确定已经执行完的慢查询\" class=\"headerlink\" title=\"1、查看慢查询日志确定已经执行完的慢查询\"></a>1、查看慢查询日志确定已经执行完的慢查询</h3><pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> set global slow_query_log = on;\nmysql> set global long_query_time = 1;\nmysql> show global variables like \"datadir\";\nmysql> show global variables like \"slow_query_log_file\";\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>可以看到查询时间、表锁时间、扫描行数Rows_examined。</p>\n<p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p>\n<h3 id=\"2、show-processlist-查看正在执行的慢查询\"><a href=\"#2、show-processlist-查看正在执行的慢查询\" class=\"headerlink\" title=\"2、show processlist 查看正在执行的慢查询\"></a>2、show processlist 查看正在执行的慢查询</h3><pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>可以看到执行时间和SQL语句</p>\n<h2 id=\"分析慢查询\"><a href=\"#分析慢查询\" class=\"headerlink\" title=\"分析慢查询\"></a>分析慢查询</h2><h3 id=\"1、使用-explain-分析慢查询\"><a href=\"#1、使用-explain-分析慢查询\" class=\"headerlink\" title=\"1、使用 explain 分析慢查询\"></a>1、使用 explain 分析慢查询</h3><p>获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：</p>\n<ul>\n<li><p>select_type ：查询类型，是简单还是复杂查询</p>\n</li>\n<li><p>type ：查询的表连接类型</p>\n</li>\n<li><p>key ：实际选择的索引</p>\n</li>\n<li><p>rows： 预计需要扫描的行数，对 InnoDB 来说，这个值是估值</p>\n</li>\n<li><p>Extra ：附加信息</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"left\">select_type</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">SIMPLE</td>\n<td>简单查询，不使用关联查询或子查询</td>\n</tr>\n<tr>\n<td align=\"left\">PRIMARY</td>\n<td>如果包含关联查询或者子查询，则最外层的查询部分标记为primary</td>\n</tr>\n<tr>\n<td align=\"left\">UNION</td>\n<td>联合查询中第二个及后面的查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT UNION</td>\n<td>满足依赖外部的关联查询中第二个及以后的查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNION RESULT</td>\n<td>联合查询的结果</td>\n</tr>\n<tr>\n<td align=\"left\">SUBQUERY</td>\n<td>子查询中的第一个查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT SUBQUERY</td>\n<td>子查询中的第一个查询，并且依赖外部查询</td>\n</tr>\n<tr>\n<td align=\"left\">DERIVED</td>\n<td>用到派生表的查询</td>\n</tr>\n<tr>\n<td align=\"left\">MATERIALIZED</td>\n<td>被物化的子查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE SUBQUERY</td>\n<td>一个子查询的结果不能被缓存，必须重新评估外层查询的每一行</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE UNION</td>\n<td>关联查询第二个或后面的语句属于不可缓存的子查询</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">type</th>\n<th align=\"left\">含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">system</td>\n<td align=\"left\">查询对象表只有一行数据</td>\n</tr>\n<tr>\n<td align=\"left\">const</td>\n<td align=\"left\">基于主键或唯一索引查询，最多返回一条结果</td>\n</tr>\n<tr>\n<td align=\"left\">eq_ref</td>\n<td align=\"left\">最多只返回一条符合条件的记录。</td>\n</tr>\n<tr>\n<td align=\"left\">ref</td>\n<td align=\"left\">基于普通索引的等值查询，或者表间等值连接</td>\n</tr>\n<tr>\n<td align=\"left\">fulltext</td>\n<td align=\"left\">全文检索</td>\n</tr>\n<tr>\n<td align=\"left\">ref_or_null</td>\n<td align=\"left\">表连接类型是</td>\n</tr>\n<tr>\n<td align=\"left\">index_merge</td>\n<td align=\"left\">利用多个索引</td>\n</tr>\n<tr>\n<td align=\"left\">unique_subquery</td>\n<td align=\"left\">子查询中使用唯一索引</td>\n</tr>\n<tr>\n<td align=\"left\">index_subquery</td>\n<td align=\"left\">子查询中使用普通索引</td>\n</tr>\n<tr>\n<td align=\"left\">range</td>\n<td align=\"left\">利用索引进行范围查询</td>\n</tr>\n<tr>\n<td align=\"left\">index</td>\n<td align=\"left\">全索引扫描</td>\n</tr>\n<tr>\n<td align=\"left\">ALL</td>\n<td align=\"left\">全表扫描</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Extra</th>\n<th align=\"left\">解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Using filesort</td>\n<td align=\"left\">将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序</td>\n</tr>\n<tr>\n<td align=\"left\">Using temporary</td>\n<td align=\"left\">需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时</td>\n</tr>\n<tr>\n<td align=\"left\">Using index</td>\n<td align=\"left\">使用覆盖索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using where</td>\n<td align=\"left\">使用 where 语句来处理结果</td>\n</tr>\n<tr>\n<td align=\"left\">Impossible WHERE</td>\n<td align=\"left\">对 where 子句判断的结果总是 false 而不能选择任何数据</td>\n</tr>\n<tr>\n<td align=\"left\">Using join buffer（BlockNested Loop）</td>\n<td align=\"left\">关联查询中，被驱动表的关联字段没索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using index condition</td>\n<td align=\"left\">先条件过滤索引，再查数据</td>\n</tr>\n<tr>\n<td align=\"left\">Select tables optimized away</td>\n<td align=\"left\">使用某些聚合函数（比如 max、min）来访问存在索引的某个字段</td>\n</tr>\n</tbody></table>\n<h3 id=\"2、show-profile\"><a href=\"#2、show-profile\" class=\"headerlink\" title=\"2、show profile\"></a>2、show profile</h3><p>了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> select @@have_profiling;\nmysql> select @@profiling;\nmysql> set profiling=1;\nmysql> select * from t1 where b=1000;\nmysql> show profiles;  /*获取query id*/\nmysql> show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"3、trace\"><a href=\"#3、trace\" class=\"headerlink\" title=\"3、trace\"></a>3、trace</h3><p>使用 trace 查看优化器如何选择执行计划</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;\n/* optimizer_trace=\"enabled=on\" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql> select * from t1 where a >900 and b > 910 order by a;\nmysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>TRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。</p>\n<p>也可以看number_of_tmp_files中判断是否使用了临时文件。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"定位慢sql\"><a href=\"#定位慢sql\" class=\"headerlink\" title=\"定位慢sql\"></a>定位慢sql</h2><h3 id=\"1、查看慢查询日志确定已经执行完的慢查询\"><a href=\"#1、查看慢查询日志确定已经执行完的慢查询\" class=\"headerlink\" title=\"1、查看慢查询日志确定已经执行完的慢查询\"></a>1、查看慢查询日志确定已经执行完的慢查询</h3><pre><code class=\"mysql\">mysql&gt; set global slow_query_log = on;\nmysql&gt; set global long_query_time = 1;\nmysql&gt; show global variables like &quot;datadir&quot;;\nmysql&gt; show global variables like &quot;slow_query_log_file&quot;;\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);</code></pre>\n<p>可以看到查询时间、表锁时间、扫描行数Rows_examined。</p>\n<p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p>\n<h3 id=\"2、show-processlist-查看正在执行的慢查询\"><a href=\"#2、show-processlist-查看正在执行的慢查询\" class=\"headerlink\" title=\"2、show processlist 查看正在执行的慢查询\"></a>2、show processlist 查看正在执行的慢查询</h3><pre><code class=\"mysql\">mysql&gt; show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`</code></pre>\n<p>可以看到执行时间和SQL语句</p>\n<h2 id=\"分析慢查询\"><a href=\"#分析慢查询\" class=\"headerlink\" title=\"分析慢查询\"></a>分析慢查询</h2><h3 id=\"1、使用-explain-分析慢查询\"><a href=\"#1、使用-explain-分析慢查询\" class=\"headerlink\" title=\"1、使用 explain 分析慢查询\"></a>1、使用 explain 分析慢查询</h3><p>获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：</p>\n<ul>\n<li><p>select_type ：查询类型，是简单还是复杂查询</p>\n</li>\n<li><p>type ：查询的表连接类型</p>\n</li>\n<li><p>key ：实际选择的索引</p>\n</li>\n<li><p>rows： 预计需要扫描的行数，对 InnoDB 来说，这个值是估值</p>\n</li>\n<li><p>Extra ：附加信息</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"left\">select_type</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">SIMPLE</td>\n<td>简单查询，不使用关联查询或子查询</td>\n</tr>\n<tr>\n<td align=\"left\">PRIMARY</td>\n<td>如果包含关联查询或者子查询，则最外层的查询部分标记为primary</td>\n</tr>\n<tr>\n<td align=\"left\">UNION</td>\n<td>联合查询中第二个及后面的查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT UNION</td>\n<td>满足依赖外部的关联查询中第二个及以后的查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNION RESULT</td>\n<td>联合查询的结果</td>\n</tr>\n<tr>\n<td align=\"left\">SUBQUERY</td>\n<td>子查询中的第一个查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT SUBQUERY</td>\n<td>子查询中的第一个查询，并且依赖外部查询</td>\n</tr>\n<tr>\n<td align=\"left\">DERIVED</td>\n<td>用到派生表的查询</td>\n</tr>\n<tr>\n<td align=\"left\">MATERIALIZED</td>\n<td>被物化的子查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE SUBQUERY</td>\n<td>一个子查询的结果不能被缓存，必须重新评估外层查询的每一行</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE UNION</td>\n<td>关联查询第二个或后面的语句属于不可缓存的子查询</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">type</th>\n<th align=\"left\">含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">system</td>\n<td align=\"left\">查询对象表只有一行数据</td>\n</tr>\n<tr>\n<td align=\"left\">const</td>\n<td align=\"left\">基于主键或唯一索引查询，最多返回一条结果</td>\n</tr>\n<tr>\n<td align=\"left\">eq_ref</td>\n<td align=\"left\">最多只返回一条符合条件的记录。</td>\n</tr>\n<tr>\n<td align=\"left\">ref</td>\n<td align=\"left\">基于普通索引的等值查询，或者表间等值连接</td>\n</tr>\n<tr>\n<td align=\"left\">fulltext</td>\n<td align=\"left\">全文检索</td>\n</tr>\n<tr>\n<td align=\"left\">ref_or_null</td>\n<td align=\"left\">表连接类型是</td>\n</tr>\n<tr>\n<td align=\"left\">index_merge</td>\n<td align=\"left\">利用多个索引</td>\n</tr>\n<tr>\n<td align=\"left\">unique_subquery</td>\n<td align=\"left\">子查询中使用唯一索引</td>\n</tr>\n<tr>\n<td align=\"left\">index_subquery</td>\n<td align=\"left\">子查询中使用普通索引</td>\n</tr>\n<tr>\n<td align=\"left\">range</td>\n<td align=\"left\">利用索引进行范围查询</td>\n</tr>\n<tr>\n<td align=\"left\">index</td>\n<td align=\"left\">全索引扫描</td>\n</tr>\n<tr>\n<td align=\"left\">ALL</td>\n<td align=\"left\">全表扫描</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Extra</th>\n<th align=\"left\">解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Using filesort</td>\n<td align=\"left\">将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序</td>\n</tr>\n<tr>\n<td align=\"left\">Using temporary</td>\n<td align=\"left\">需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时</td>\n</tr>\n<tr>\n<td align=\"left\">Using index</td>\n<td align=\"left\">使用覆盖索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using where</td>\n<td align=\"left\">使用 where 语句来处理结果</td>\n</tr>\n<tr>\n<td align=\"left\">Impossible WHERE</td>\n<td align=\"left\">对 where 子句判断的结果总是 false 而不能选择任何数据</td>\n</tr>\n<tr>\n<td align=\"left\">Using join buffer（BlockNested Loop）</td>\n<td align=\"left\">关联查询中，被驱动表的关联字段没索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using index condition</td>\n<td align=\"left\">先条件过滤索引，再查数据</td>\n</tr>\n<tr>\n<td align=\"left\">Select tables optimized away</td>\n<td align=\"left\">使用某些聚合函数（比如 max、min）来访问存在索引的某个字段</td>\n</tr>\n</tbody></table>\n<h3 id=\"2、show-profile\"><a href=\"#2、show-profile\" class=\"headerlink\" title=\"2、show profile\"></a>2、show profile</h3><p>了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节</p>\n<pre><code class=\"mysql\">mysql&gt; select @@have_profiling;\nmysql&gt; select @@profiling;\nmysql&gt; set profiling=1;\nmysql&gt; select * from t1 where b=1000;\nmysql&gt; show profiles;  /*获取query id*/\nmysql&gt; show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)</code></pre>\n<h3 id=\"3、trace\"><a href=\"#3、trace\" class=\"headerlink\" title=\"3、trace\"></a>3、trace</h3><p>使用 trace 查看优化器如何选择执行计划</p>\n<pre><code class=\"mysql\">mysql&gt; set session optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;\n/* optimizer_trace=&quot;enabled=on&quot; 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql&gt; select * from t1 where a &gt;900 and b &gt; 910 order by a;\nmysql&gt; SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n</code></pre>\n<p>TRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。</p>\n<p>也可以看number_of_tmp_files中判断是否使用了临时文件。</p>\n"},{"title":"分页查询优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T09:15:47.000Z","password":null,"summary":"分页查询性能优化，转换为主键查询或者排序和分页操作先查出主键，然后根据主键查到对应的记录。","_content":"\n## 自增且连续主键的分页查询\n\n避免前n条记录的读取[mysql manual](https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html)，可以采用：\n\n```mysql\nselect * from t1 where id >99000 limit 2;\n```\n\n要求主链连续且自增，否则很多时候不适用。\n\n## 非主键字段排序的分页查询\n\n可能不走索引\n\n```mysql\nselect * from t1 order by a limit 99000,2;\n```\n\n优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录\n\n```mysql\nselect * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;\n```\n\n","source":"_posts/分页查询优化.md","raw":"---\ntitle: 分页查询优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 17:15:47\npassword:\nsummary: 分页查询性能优化，转换为主键查询或者排序和分页操作先查出主键，然后根据主键查到对应的记录。\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 自增且连续主键的分页查询\n\n避免前n条记录的读取[mysql manual](https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html)，可以采用：\n\n```mysql\nselect * from t1 where id >99000 limit 2;\n```\n\n要求主链连续且自增，否则很多时候不适用。\n\n## 非主键字段排序的分页查询\n\n可能不走索引\n\n```mysql\nselect * from t1 order by a limit 99000,2;\n```\n\n优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录\n\n```mysql\nselect * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;\n```\n\n","slug":"分页查询优化","published":1,"updated":"2021-05-11T12:56:57.258Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78g005xq4ufqne7b7ng","content":"<h2 id=\"自增且连续主键的分页查询\"><a href=\"#自增且连续主键的分页查询\" class=\"headerlink\" title=\"自增且连续主键的分页查询\"></a>自增且连续主键的分页查询</h2><p>避免前n条记录的读取<a href=\"https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html\" target=\"_blank\" rel=\"noopener\">mysql manual</a>，可以采用：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where id >99000 limit 2;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>要求主链连续且自增，否则很多时候不适用。</p>\n<h2 id=\"非主键字段排序的分页查询\"><a href=\"#非主键字段排序的分页查询\" class=\"headerlink\" title=\"非主键字段排序的分页查询\"></a>非主键字段排序的分页查询</h2><p>可能不走索引</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 order by a limit 99000,2;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"自增且连续主键的分页查询\"><a href=\"#自增且连续主键的分页查询\" class=\"headerlink\" title=\"自增且连续主键的分页查询\"></a>自增且连续主键的分页查询</h2><p>避免前n条记录的读取<a href=\"https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html\" target=\"_blank\" rel=\"noopener\">mysql manual</a>，可以采用：</p>\n<pre><code class=\"mysql\">select * from t1 where id &gt;99000 limit 2;</code></pre>\n<p>要求主链连续且自增，否则很多时候不适用。</p>\n<h2 id=\"非主键字段排序的分页查询\"><a href=\"#非主键字段排序的分页查询\" class=\"headerlink\" title=\"非主键字段排序的分页查询\"></a>非主键字段排序的分页查询</h2><p>可能不走索引</p>\n<pre><code class=\"mysql\">select * from t1 order by a limit 99000,2;</code></pre>\n<p>优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录</p>\n<pre><code class=\"mysql\">select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;</code></pre>\n"},{"title":"数据恢复","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-21T12:27:16.000Z","password":null,"summary":"介绍了delete误删行、truncate/drop误删库/表时不跑路方法，以及如何预防。","_content":"\n## delete误删行\n\nFlashback工具通过闪回把数据恢复回来。\n\n> Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。前提是，确保binlog_format=row 和binlog_row_image=FULL。\n\n**具体操作**\n\n- 恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作\n- 将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。\n\n> 用truncate /drop table和drop database命令删除的数据记录的binlog还是**statement格式**。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。\n\n## truncate/drop误删库/表\n\n需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。\n\n1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；\n2. 用备份恢复出一个临时库；\n3. 从日志备份里面，取出凌晨0点之后的日志；\n4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。\n\n> 跳过误操作方法：\n>\n> 如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；\n> 如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。\n\n## 预防\n\n### 搭建延迟复制备库\n\n- 延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。\n\n> 只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。\n\n### 账号分离\n\n- 我们只给业务开发同学DML权限，而不给truncate/drop权限。如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。\n- 即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。\n\n### 制定操作规范\n\n- 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。\n- 改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表","source":"_posts/数据恢复.md","raw":"---\ntitle: 数据恢复\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-21 20:27:16\npassword:\nsummary: 介绍了delete误删行、truncate/drop误删库/表时不跑路方法，以及如何预防。\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## delete误删行\n\nFlashback工具通过闪回把数据恢复回来。\n\n> Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。前提是，确保binlog_format=row 和binlog_row_image=FULL。\n\n**具体操作**\n\n- 恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作\n- 将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。\n\n> 用truncate /drop table和drop database命令删除的数据记录的binlog还是**statement格式**。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。\n\n## truncate/drop误删库/表\n\n需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。\n\n1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；\n2. 用备份恢复出一个临时库；\n3. 从日志备份里面，取出凌晨0点之后的日志；\n4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。\n\n> 跳过误操作方法：\n>\n> 如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；\n> 如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。\n\n## 预防\n\n### 搭建延迟复制备库\n\n- 延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。\n\n> 只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。\n\n### 账号分离\n\n- 我们只给业务开发同学DML权限，而不给truncate/drop权限。如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。\n- 即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。\n\n### 制定操作规范\n\n- 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。\n- 改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表","slug":"数据恢复","published":1,"updated":"2021-04-29T14:19:32.274Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78i0060q4ufadzms2az","content":"<h2 id=\"delete误删行\"><a href=\"#delete误删行\" class=\"headerlink\" title=\"delete误删行\"></a>delete误删行</h2><p>Flashback工具通过闪回把数据恢复回来。</p>\n<blockquote>\n<p>Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。前提是，确保binlog_format=row 和binlog_row_image=FULL。</p>\n</blockquote>\n<p><strong>具体操作</strong></p>\n<ul>\n<li>恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作</li>\n<li>将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。</li>\n</ul>\n<blockquote>\n<p>用truncate /drop table和drop database命令删除的数据记录的binlog还是<strong>statement格式</strong>。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。</p>\n</blockquote>\n<h2 id=\"truncate-drop误删库-表\"><a href=\"#truncate-drop误删库-表\" class=\"headerlink\" title=\"truncate/drop误删库/表\"></a>truncate/drop误删库/表</h2><p>需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。</p>\n<ol>\n<li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</li>\n<li>用备份恢复出一个临时库；</li>\n<li>从日志备份里面，取出凌晨0点之后的日志；</li>\n<li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li>\n</ol>\n<blockquote>\n<p>跳过误操作方法：</p>\n<p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；<br>如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。</p>\n</blockquote>\n<h2 id=\"预防\"><a href=\"#预防\" class=\"headerlink\" title=\"预防\"></a>预防</h2><h3 id=\"搭建延迟复制备库\"><a href=\"#搭建延迟复制备库\" class=\"headerlink\" title=\"搭建延迟复制备库\"></a>搭建延迟复制备库</h3><ul>\n<li>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</li>\n</ul>\n<blockquote>\n<p>只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。</p>\n</blockquote>\n<h3 id=\"账号分离\"><a href=\"#账号分离\" class=\"headerlink\" title=\"账号分离\"></a>账号分离</h3><ul>\n<li>我们只给业务开发同学DML权限，而不给truncate/drop权限。如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。</li>\n<li>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li>\n</ul>\n<h3 id=\"制定操作规范\"><a href=\"#制定操作规范\" class=\"headerlink\" title=\"制定操作规范\"></a>制定操作规范</h3><ul>\n<li>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。</li>\n<li>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表</li>\n</ul>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"delete误删行\"><a href=\"#delete误删行\" class=\"headerlink\" title=\"delete误删行\"></a>delete误删行</h2><p>Flashback工具通过闪回把数据恢复回来。</p>\n<blockquote>\n<p>Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。前提是，确保binlog_format=row 和binlog_row_image=FULL。</p>\n</blockquote>\n<p><strong>具体操作</strong></p>\n<ul>\n<li>恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作</li>\n<li>将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。</li>\n</ul>\n<blockquote>\n<p>用truncate /drop table和drop database命令删除的数据记录的binlog还是<strong>statement格式</strong>。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。</p>\n</blockquote>\n<h2 id=\"truncate-drop误删库-表\"><a href=\"#truncate-drop误删库-表\" class=\"headerlink\" title=\"truncate/drop误删库/表\"></a>truncate/drop误删库/表</h2><p>需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。</p>\n<ol>\n<li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</li>\n<li>用备份恢复出一个临时库；</li>\n<li>从日志备份里面，取出凌晨0点之后的日志；</li>\n<li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li>\n</ol>\n<blockquote>\n<p>跳过误操作方法：</p>\n<p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；<br>如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。</p>\n</blockquote>\n<h2 id=\"预防\"><a href=\"#预防\" class=\"headerlink\" title=\"预防\"></a>预防</h2><h3 id=\"搭建延迟复制备库\"><a href=\"#搭建延迟复制备库\" class=\"headerlink\" title=\"搭建延迟复制备库\"></a>搭建延迟复制备库</h3><ul>\n<li>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</li>\n</ul>\n<blockquote>\n<p>只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。</p>\n</blockquote>\n<h3 id=\"账号分离\"><a href=\"#账号分离\" class=\"headerlink\" title=\"账号分离\"></a>账号分离</h3><ul>\n<li>我们只给业务开发同学DML权限，而不给truncate/drop权限。如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。</li>\n<li>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li>\n</ul>\n<h3 id=\"制定操作规范\"><a href=\"#制定操作规范\" class=\"headerlink\" title=\"制定操作规范\"></a>制定操作规范</h3><ul>\n<li>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。</li>\n<li>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表</li>\n</ul>\n"},{"title":"网络","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-05-19T22:20:37.000Z","password":null,"summary":null,"_content":"\n## TCP头格式\n\n![](baowen.jpg)\n\n- 源端口号和目标端口号\n- 包的序号（seq）\n- 确认序号（ack）\n- 状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。\n- 窗口大小\n\n## 三次握手\n\n![](woshou.jpg)\n\n- 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。\n- 客户端主动发起连接 SYN，发送的**序列号**是X，之后处于 SYN-SENT 状态。\n- 服务端收到发起的连接，返回 SYN，序列号为Y，并且ACK 客户端的 SYN，ack的值为X+1，之后处于 SYN-RCVD 状态。\n- 客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。\n- 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。\n\n### 客户端发送的SYN丢失\n\n在TCP的可靠传输中，如果SYN包在传输的过程中**丢失**，此时Client段会触发**重传机制**，但是也不是无脑的一直重传过去，重传的次数是受限制的，可以通过 tcp_syn_retries 这个配置项来决定。\n\n- 如果此时 tcp_syn_retries 的配置为3，如果过了1s还没有收到 Server 的回应，那么进行第一次的重传。\n- 如果经过了2s没有收到Sever的响应进行第二次的重传，一直重传tcp_syn_retries次。\n- 这里的重传三次，意味着当第一次发送SYN后，需要等待(1 +2 +4 +8)秒，如果还是没有响应，connect就会通过**ETIMEOUT**的错误返回。\n\n### 为什么不是2次\n\n B 的应答包不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。\n\n如果仅是两次连接。可能出现：\n\n- A发送完请报文发起连接，由于网络情况不好，B延时很长时间后收到报文。A将此报文认定为失效的报文，因为中间可能已经建立连接并断开了。\n- B收到报文后，会向A发起连接。此时两次握手完毕。\n- B会认为已经建立了连接可以通信，B会一直等到A发送的连接请求，而A对失效的报文回复自然不会处理。会陷入B忙等的僵局，造成资源的浪费。\n\n## 四次挥手\n\n![](huishou.jpg)\n\n- 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN，其序列号为seq=u，此时，客户端进入FIN-WAIT-1（终止等待1）状态。 \n- 服务器收到连接释放报文，发出确认报文，ACK，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。\n\n   - 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。\n- 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。\n- 客户端收到服务器的连接释放报文后，必须发出确认，ACK，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，才进入CLOSED状态。\n     - 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。\n\n### 2MSL作用\n\n服务端发送的FIN+ACK报文请求，客户端没有回应，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。\n\nB 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就就直接发送 RST，B 就知道 A 早就跑了。\n\n### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？\n\n建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。\n而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以服务器方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，服务器方ACK和FIN一般都会分开发送，从而导致多了一次。\n\n## 如果已经建立了连接，但是客户端突然出现故障了怎么办？\n\nTCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。\n\n服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。\n","source":"_posts/网络.md","raw":"---\ntitle: 网络\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-05-20 06:20:37\npassword:\nsummary:\ntags:\n- interview\ncategories:\n- interview\n---\n\n## TCP头格式\n\n![](baowen.jpg)\n\n- 源端口号和目标端口号\n- 包的序号（seq）\n- 确认序号（ack）\n- 状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。\n- 窗口大小\n\n## 三次握手\n\n![](woshou.jpg)\n\n- 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。\n- 客户端主动发起连接 SYN，发送的**序列号**是X，之后处于 SYN-SENT 状态。\n- 服务端收到发起的连接，返回 SYN，序列号为Y，并且ACK 客户端的 SYN，ack的值为X+1，之后处于 SYN-RCVD 状态。\n- 客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。\n- 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。\n\n### 客户端发送的SYN丢失\n\n在TCP的可靠传输中，如果SYN包在传输的过程中**丢失**，此时Client段会触发**重传机制**，但是也不是无脑的一直重传过去，重传的次数是受限制的，可以通过 tcp_syn_retries 这个配置项来决定。\n\n- 如果此时 tcp_syn_retries 的配置为3，如果过了1s还没有收到 Server 的回应，那么进行第一次的重传。\n- 如果经过了2s没有收到Sever的响应进行第二次的重传，一直重传tcp_syn_retries次。\n- 这里的重传三次，意味着当第一次发送SYN后，需要等待(1 +2 +4 +8)秒，如果还是没有响应，connect就会通过**ETIMEOUT**的错误返回。\n\n### 为什么不是2次\n\n B 的应答包不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。\n\n如果仅是两次连接。可能出现：\n\n- A发送完请报文发起连接，由于网络情况不好，B延时很长时间后收到报文。A将此报文认定为失效的报文，因为中间可能已经建立连接并断开了。\n- B收到报文后，会向A发起连接。此时两次握手完毕。\n- B会认为已经建立了连接可以通信，B会一直等到A发送的连接请求，而A对失效的报文回复自然不会处理。会陷入B忙等的僵局，造成资源的浪费。\n\n## 四次挥手\n\n![](huishou.jpg)\n\n- 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN，其序列号为seq=u，此时，客户端进入FIN-WAIT-1（终止等待1）状态。 \n- 服务器收到连接释放报文，发出确认报文，ACK，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。\n\n   - 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。\n- 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。\n- 客户端收到服务器的连接释放报文后，必须发出确认，ACK，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，才进入CLOSED状态。\n     - 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。\n\n### 2MSL作用\n\n服务端发送的FIN+ACK报文请求，客户端没有回应，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。\n\nB 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就就直接发送 RST，B 就知道 A 早就跑了。\n\n### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？\n\n建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。\n而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以服务器方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，服务器方ACK和FIN一般都会分开发送，从而导致多了一次。\n\n## 如果已经建立了连接，但是客户端突然出现故障了怎么办？\n\nTCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。\n\n服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。\n","slug":"网络","published":1,"updated":"2021-05-20T00:08:59.155Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78l0063q4ufko4xot53","content":"<h2 id=\"TCP头格式\"><a href=\"#TCP头格式\" class=\"headerlink\" title=\"TCP头格式\"></a>TCP头格式</h2><p><img src=\"baowen.jpg\" alt></p>\n<ul>\n<li>源端口号和目标端口号</li>\n<li>包的序号（seq）</li>\n<li>确认序号（ack）</li>\n<li>状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</li>\n<li>窗口大小</li>\n</ul>\n<h2 id=\"三次握手\"><a href=\"#三次握手\" class=\"headerlink\" title=\"三次握手\"></a>三次握手</h2><p><img src=\"woshou.jpg\" alt></p>\n<ul>\n<li>一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。</li>\n<li>客户端主动发起连接 SYN，发送的<strong>序列号</strong>是X，之后处于 SYN-SENT 状态。</li>\n<li>服务端收到发起的连接，返回 SYN，序列号为Y，并且ACK 客户端的 SYN，ack的值为X+1，之后处于 SYN-RCVD 状态。</li>\n<li>客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。</li>\n<li>服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。</li>\n</ul>\n<h3 id=\"客户端发送的SYN丢失\"><a href=\"#客户端发送的SYN丢失\" class=\"headerlink\" title=\"客户端发送的SYN丢失\"></a>客户端发送的SYN丢失</h3><p>在TCP的可靠传输中，如果SYN包在传输的过程中<strong>丢失</strong>，此时Client段会触发<strong>重传机制</strong>，但是也不是无脑的一直重传过去，重传的次数是受限制的，可以通过 tcp_syn_retries 这个配置项来决定。</p>\n<ul>\n<li>如果此时 tcp_syn_retries 的配置为3，如果过了1s还没有收到 Server 的回应，那么进行第一次的重传。</li>\n<li>如果经过了2s没有收到Sever的响应进行第二次的重传，一直重传tcp_syn_retries次。</li>\n<li>这里的重传三次，意味着当第一次发送SYN后，需要等待(1 +2 +4 +8)秒，如果还是没有响应，connect就会通过<strong>ETIMEOUT</strong>的错误返回。</li>\n</ul>\n<h3 id=\"为什么不是2次\"><a href=\"#为什么不是2次\" class=\"headerlink\" title=\"为什么不是2次\"></a>为什么不是2次</h3><p> B 的应答包不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。</p>\n<p>如果仅是两次连接。可能出现：</p>\n<ul>\n<li>A发送完请报文发起连接，由于网络情况不好，B延时很长时间后收到报文。A将此报文认定为失效的报文，因为中间可能已经建立连接并断开了。</li>\n<li>B收到报文后，会向A发起连接。此时两次握手完毕。</li>\n<li>B会认为已经建立了连接可以通信，B会一直等到A发送的连接请求，而A对失效的报文回复自然不会处理。会陷入B忙等的僵局，造成资源的浪费。</li>\n</ul>\n<h2 id=\"四次挥手\"><a href=\"#四次挥手\" class=\"headerlink\" title=\"四次挥手\"></a>四次挥手</h2><p><img src=\"huishou.jpg\" alt></p>\n<ul>\n<li><p>客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN，其序列号为seq=u，此时，客户端进入FIN-WAIT-1（终止等待1）状态。 </p>\n</li>\n<li><p>服务器收到连接释放报文，发出确认报文，ACK，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。</p>\n<ul>\n<li>客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。</li>\n</ul>\n</li>\n<li><p>服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。</p>\n</li>\n<li><p>客户端收到服务器的连接释放报文后，必须发出确认，ACK，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，才进入CLOSED状态。</p>\n<ul>\n<li>服务器只要收到了客户端发出的确认，立即进入CLOSED状态。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2MSL作用\"><a href=\"#2MSL作用\" class=\"headerlink\" title=\"2MSL作用\"></a>2MSL作用</h3><p>服务端发送的FIN+ACK报文请求，客户端没有回应，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。</p>\n<p>B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就就直接发送 RST，B 就知道 A 早就跑了。</p>\n<h3 id=\"为什么建立连接是三次握手，关闭连接确是四次挥手呢？\"><a href=\"#为什么建立连接是三次握手，关闭连接确是四次挥手呢？\" class=\"headerlink\" title=\"为什么建立连接是三次握手，关闭连接确是四次挥手呢？\"></a>为什么建立连接是三次握手，关闭连接确是四次挥手呢？</h3><p>建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。<br>而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以服务器方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，服务器方ACK和FIN一般都会分开发送，从而导致多了一次。</p>\n<h2 id=\"如果已经建立了连接，但是客户端突然出现故障了怎么办？\"><a href=\"#如果已经建立了连接，但是客户端突然出现故障了怎么办？\" class=\"headerlink\" title=\"如果已经建立了连接，但是客户端突然出现故障了怎么办？\"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h2><p>TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。</p>\n<p>服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"TCP头格式\"><a href=\"#TCP头格式\" class=\"headerlink\" title=\"TCP头格式\"></a>TCP头格式</h2><p><img src=\"baowen.jpg\" alt></p>\n<ul>\n<li>源端口号和目标端口号</li>\n<li>包的序号（seq）</li>\n<li>确认序号（ack）</li>\n<li>状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</li>\n<li>窗口大小</li>\n</ul>\n<h2 id=\"三次握手\"><a href=\"#三次握手\" class=\"headerlink\" title=\"三次握手\"></a>三次握手</h2><p><img src=\"woshou.jpg\" alt></p>\n<ul>\n<li>一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。</li>\n<li>客户端主动发起连接 SYN，发送的<strong>序列号</strong>是X，之后处于 SYN-SENT 状态。</li>\n<li>服务端收到发起的连接，返回 SYN，序列号为Y，并且ACK 客户端的 SYN，ack的值为X+1，之后处于 SYN-RCVD 状态。</li>\n<li>客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。</li>\n<li>服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。</li>\n</ul>\n<h3 id=\"客户端发送的SYN丢失\"><a href=\"#客户端发送的SYN丢失\" class=\"headerlink\" title=\"客户端发送的SYN丢失\"></a>客户端发送的SYN丢失</h3><p>在TCP的可靠传输中，如果SYN包在传输的过程中<strong>丢失</strong>，此时Client段会触发<strong>重传机制</strong>，但是也不是无脑的一直重传过去，重传的次数是受限制的，可以通过 tcp_syn_retries 这个配置项来决定。</p>\n<ul>\n<li>如果此时 tcp_syn_retries 的配置为3，如果过了1s还没有收到 Server 的回应，那么进行第一次的重传。</li>\n<li>如果经过了2s没有收到Sever的响应进行第二次的重传，一直重传tcp_syn_retries次。</li>\n<li>这里的重传三次，意味着当第一次发送SYN后，需要等待(1 +2 +4 +8)秒，如果还是没有响应，connect就会通过<strong>ETIMEOUT</strong>的错误返回。</li>\n</ul>\n<h3 id=\"为什么不是2次\"><a href=\"#为什么不是2次\" class=\"headerlink\" title=\"为什么不是2次\"></a>为什么不是2次</h3><p> B 的应答包不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。</p>\n<p>如果仅是两次连接。可能出现：</p>\n<ul>\n<li>A发送完请报文发起连接，由于网络情况不好，B延时很长时间后收到报文。A将此报文认定为失效的报文，因为中间可能已经建立连接并断开了。</li>\n<li>B收到报文后，会向A发起连接。此时两次握手完毕。</li>\n<li>B会认为已经建立了连接可以通信，B会一直等到A发送的连接请求，而A对失效的报文回复自然不会处理。会陷入B忙等的僵局，造成资源的浪费。</li>\n</ul>\n<h2 id=\"四次挥手\"><a href=\"#四次挥手\" class=\"headerlink\" title=\"四次挥手\"></a>四次挥手</h2><p><img src=\"huishou.jpg\" alt></p>\n<ul>\n<li><p>客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN，其序列号为seq=u，此时，客户端进入FIN-WAIT-1（终止等待1）状态。 </p>\n</li>\n<li><p>服务器收到连接释放报文，发出确认报文，ACK，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。</p>\n<ul>\n<li>客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。</li>\n</ul>\n</li>\n<li><p>服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。</p>\n</li>\n<li><p>客户端收到服务器的连接释放报文后，必须发出确认，ACK，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，才进入CLOSED状态。</p>\n<ul>\n<li>服务器只要收到了客户端发出的确认，立即进入CLOSED状态。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2MSL作用\"><a href=\"#2MSL作用\" class=\"headerlink\" title=\"2MSL作用\"></a>2MSL作用</h3><p>服务端发送的FIN+ACK报文请求，客户端没有回应，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。</p>\n<p>B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就就直接发送 RST，B 就知道 A 早就跑了。</p>\n<h3 id=\"为什么建立连接是三次握手，关闭连接确是四次挥手呢？\"><a href=\"#为什么建立连接是三次握手，关闭连接确是四次挥手呢？\" class=\"headerlink\" title=\"为什么建立连接是三次握手，关闭连接确是四次挥手呢？\"></a>为什么建立连接是三次握手，关闭连接确是四次挥手呢？</h3><p>建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。<br>而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以服务器方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，服务器方ACK和FIN一般都会分开发送，从而导致多了一次。</p>\n<h2 id=\"如果已经建立了连接，但是客户端突然出现故障了怎么办？\"><a href=\"#如果已经建立了连接，但是客户端突然出现故障了怎么办？\" class=\"headerlink\" title=\"如果已经建立了连接，但是客户端突然出现故障了怎么办？\"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h2><p>TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。</p>\n<p>服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p>\n"},{"title":"索引","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T14:06:54.000Z","password":null,"summary":null,"_content":"\n## 数据结构\n\n### B 树\n\nB 树每个节点都包含 key 值和 data 值。\n\n如果 data 比较大时，每一页存储的 key 会比较少；\n\n当数据比较多时，要经历多层节点才能查询在叶子节点的数据。\n\n### B+ 树\n\n- 所有叶子节点中包含了全部关键字的信息\n- 各叶子节点用指针进行连接\n- 非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。\n- B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”\n\n## 索引\n\n### 聚集索引\n\n实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。\n\nInnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。\n\n### 辅助索引\n\nInnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。\n\n当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。\n\n### 覆盖索引\n\n辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。\n\n### 使用场景\n\n- 数据检索\n- 聚合函数（max/count）\n- 排序\n- 避免回表（覆盖索引）\n- 关联查询\n\n### 普通索引和唯一索引\n\n#### **Insert Buffer**\n\n- 对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。\n\n- 如果在，则直接插入；如果不在，则先放入 Insert Buffer 中\n- 然后再以一定频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作。\n\n> **要求不是唯一索引**\n>\n> 意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。\n\n#### **Change Buffer**\n\nInsert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update操作都进行缓存。\n\n> **要求不是唯一索引**\n>\n> 唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。\n>\n> - innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。\n> - innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。\n\n**适用场景**\n\n对于**写多读少**的业务来说，页面在**写完以后马上被访问到的概率比较小**，此时changebuffer的使用效果最好。这种业务模型常见的就是**账单类、日志类**的系统。\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。\n\n**区别**\n\n1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。\n\n2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。\n\n3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。\n\n4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。\n\n**选择**\n\n1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引\n\n2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。\n\n### 联合索引\n\n对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。\n\n使用：\n\n- where 条件中，经常同时出现的列放在联合索引中。\n- 把选择性最大的列放在联合索引的最左边。\n\n联合索引应用：\n\n```mysql\n/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;\n```\n\n### 前缀索引\n\n当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。\n\n根据“索引选择性”（Index Selectivity）确定前缀长度。\n\n**其他方式**\n\n第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。\n\n第二种方式是使用hash字段。不支持范围查询。\n\n### 最左前缀\n\n不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。\n\n### 主键\n\n如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。\n\n### 优化器索引选择\n\n`show index from t`可以看到索引的Cardinality，即索引中不重复记录数量的预估值。\n\nCardinality 统计信息的更新时机：\n\n- 表中 1/16 的数据已经发生过变化\n- 表中数据发生变化次数超过 2000000000\n\n**统计方法**\n\n随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数\n\n**问题**\n\n通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。\n\n**应对**\n\n```mysql\nanalyze table t13;//更新统计信息\n```\n\n**问题**\n\n如果单次选取的数据量过大，可能也会导致“选错”索引\n\n```mysql\nselect a from t13 where a>70000 limit 1000;//走了主键索引\n```\n\n**应对**\n\nforce index 来强制走索引\n\n```mysql\nselect a from t13 force index(idx_a) where a>70000 limit 1000;\n```\n\n**其他应对**\n\n1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n\n2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n\n","source":"_posts/索引.md","raw":"---\ntitle: 索引\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 22:06:54\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 数据结构\n\n### B 树\n\nB 树每个节点都包含 key 值和 data 值。\n\n如果 data 比较大时，每一页存储的 key 会比较少；\n\n当数据比较多时，要经历多层节点才能查询在叶子节点的数据。\n\n### B+ 树\n\n- 所有叶子节点中包含了全部关键字的信息\n- 各叶子节点用指针进行连接\n- 非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。\n- B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”\n\n## 索引\n\n### 聚集索引\n\n实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。\n\nInnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。\n\n### 辅助索引\n\nInnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。\n\n当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。\n\n### 覆盖索引\n\n辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。\n\n### 使用场景\n\n- 数据检索\n- 聚合函数（max/count）\n- 排序\n- 避免回表（覆盖索引）\n- 关联查询\n\n### 普通索引和唯一索引\n\n#### **Insert Buffer**\n\n- 对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。\n\n- 如果在，则直接插入；如果不在，则先放入 Insert Buffer 中\n- 然后再以一定频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作。\n\n> **要求不是唯一索引**\n>\n> 意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。\n\n#### **Change Buffer**\n\nInsert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update操作都进行缓存。\n\n> **要求不是唯一索引**\n>\n> 唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。\n>\n> - innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。\n> - innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。\n\n**适用场景**\n\n对于**写多读少**的业务来说，页面在**写完以后马上被访问到的概率比较小**，此时changebuffer的使用效果最好。这种业务模型常见的就是**账单类、日志类**的系统。\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。\n\n**区别**\n\n1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。\n\n2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。\n\n3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。\n\n4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。\n\n**选择**\n\n1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引\n\n2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。\n\n### 联合索引\n\n对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。\n\n使用：\n\n- where 条件中，经常同时出现的列放在联合索引中。\n- 把选择性最大的列放在联合索引的最左边。\n\n联合索引应用：\n\n```mysql\n/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;\n```\n\n### 前缀索引\n\n当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。\n\n根据“索引选择性”（Index Selectivity）确定前缀长度。\n\n**其他方式**\n\n第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。\n\n第二种方式是使用hash字段。不支持范围查询。\n\n### 最左前缀\n\n不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。\n\n### 主键\n\n如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。\n\n### 优化器索引选择\n\n`show index from t`可以看到索引的Cardinality，即索引中不重复记录数量的预估值。\n\nCardinality 统计信息的更新时机：\n\n- 表中 1/16 的数据已经发生过变化\n- 表中数据发生变化次数超过 2000000000\n\n**统计方法**\n\n随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数\n\n**问题**\n\n通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。\n\n**应对**\n\n```mysql\nanalyze table t13;//更新统计信息\n```\n\n**问题**\n\n如果单次选取的数据量过大，可能也会导致“选错”索引\n\n```mysql\nselect a from t13 where a>70000 limit 1000;//走了主键索引\n```\n\n**应对**\n\nforce index 来强制走索引\n\n```mysql\nselect a from t13 force index(idx_a) where a>70000 limit 1000;\n```\n\n**其他应对**\n\n1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n\n2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n\n","slug":"索引","published":1,"updated":"2021-04-29T14:37:10.068Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78n0066q4uf2zd7rgd5","content":"<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><h3 id=\"B-树\"><a href=\"#B-树\" class=\"headerlink\" title=\"B 树\"></a>B 树</h3><p>B 树每个节点都包含 key 值和 data 值。</p>\n<p>如果 data 比较大时，每一页存储的 key 会比较少；</p>\n<p>当数据比较多时，要经历多层节点才能查询在叶子节点的数据。</p>\n<h3 id=\"B-树-1\"><a href=\"#B-树-1\" class=\"headerlink\" title=\"B+ 树\"></a>B+ 树</h3><ul>\n<li>所有叶子节点中包含了全部关键字的信息</li>\n<li>各叶子节点用指针进行连接</li>\n<li>非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。</li>\n<li>B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”</li>\n</ul>\n<h2 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h2><h3 id=\"聚集索引\"><a href=\"#聚集索引\" class=\"headerlink\" title=\"聚集索引\"></a>聚集索引</h3><p>实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。</p>\n<p>InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。</p>\n<h3 id=\"辅助索引\"><a href=\"#辅助索引\" class=\"headerlink\" title=\"辅助索引\"></a>辅助索引</h3><p>InnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。</p>\n<p>当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。</p>\n<h3 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h3><p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p>\n<h3 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a>使用场景</h3><ul>\n<li>数据检索</li>\n<li>聚合函数（max/count）</li>\n<li>排序</li>\n<li>避免回表（覆盖索引）</li>\n<li>关联查询</li>\n</ul>\n<h3 id=\"普通索引和唯一索引\"><a href=\"#普通索引和唯一索引\" class=\"headerlink\" title=\"普通索引和唯一索引\"></a>普通索引和唯一索引</h3><h4 id=\"Insert-Buffer\"><a href=\"#Insert-Buffer\" class=\"headerlink\" title=\"Insert Buffer\"></a><strong>Insert Buffer</strong></h4><ul>\n<li><p>对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。</p>\n</li>\n<li><p>如果在，则直接插入；如果不在，则先放入 Insert Buffer 中</p>\n</li>\n<li><p>然后再以一定频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作。</p>\n</li>\n</ul>\n<blockquote>\n<p><strong>要求不是唯一索引</strong></p>\n<p>意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。</p>\n</blockquote>\n<h4 id=\"Change-Buffer\"><a href=\"#Change-Buffer\" class=\"headerlink\" title=\"Change Buffer\"></a><strong>Change Buffer</strong></h4><p>Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update操作都进行缓存。</p>\n<blockquote>\n<p><strong>要求不是唯一索引</strong></p>\n<p>唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。</p>\n<ul>\n<li>innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。</li>\n<li>innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。</li>\n</ul>\n</blockquote>\n<p><strong>适用场景</strong></p>\n<p>对于<strong>写多读少</strong>的业务来说，页面在<strong>写完以后马上被访问到的概率比较小</strong>，此时changebuffer的使用效果最好。这种业务模型常见的就是<strong>账单类、日志类</strong>的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</p>\n<p><strong>区别</strong></p>\n<p>1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。</p>\n<p>2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。</p>\n<p>3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。</p>\n<p>4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。</p>\n<p><strong>选择</strong></p>\n<p>1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引</p>\n<p>2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。</p>\n<h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a>联合索引</h3><p>对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。</p>\n<p>使用：</p>\n<ul>\n<li>where 条件中，经常同时出现的列放在联合索引中。</li>\n<li>把选择性最大的列放在联合索引的最左边。</li>\n</ul>\n<p>联合索引应用：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h3><p>当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。</p>\n<p>根据“索引选择性”（Index Selectivity）确定前缀长度。</p>\n<p><strong>其他方式</strong></p>\n<p>第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。</p>\n<p>第二种方式是使用hash字段。不支持范围查询。</p>\n<h3 id=\"最左前缀\"><a href=\"#最左前缀\" class=\"headerlink\" title=\"最左前缀\"></a>最左前缀</h3><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p>\n<h3 id=\"主键\"><a href=\"#主键\" class=\"headerlink\" title=\"主键\"></a>主键</h3><p>如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。</p>\n<h3 id=\"优化器索引选择\"><a href=\"#优化器索引选择\" class=\"headerlink\" title=\"优化器索引选择\"></a>优化器索引选择</h3><p><code>show index from t</code>可以看到索引的Cardinality，即索引中不重复记录数量的预估值。</p>\n<p>Cardinality 统计信息的更新时机：</p>\n<ul>\n<li>表中 1/16 的数据已经发生过变化</li>\n<li>表中数据发生变化次数超过 2000000000</li>\n</ul>\n<p><strong>统计方法</strong></p>\n<p>随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数</p>\n<p><strong>问题</strong></p>\n<p>通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。</p>\n<p><strong>应对</strong></p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">analyze table t13;//更新统计信息<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>问题</strong></p>\n<p>如果单次选取的数据量过大，可能也会导致“选错”索引</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select a from t13 where a>70000 limit 1000;//走了主键索引<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>应对</strong></p>\n<p>force index 来强制走索引</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select a from t13 force index(idx_a) where a>70000 limit 1000;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>其他应对</strong></p>\n<p>1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p>\n<p>2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><h3 id=\"B-树\"><a href=\"#B-树\" class=\"headerlink\" title=\"B 树\"></a>B 树</h3><p>B 树每个节点都包含 key 值和 data 值。</p>\n<p>如果 data 比较大时，每一页存储的 key 会比较少；</p>\n<p>当数据比较多时，要经历多层节点才能查询在叶子节点的数据。</p>\n<h3 id=\"B-树-1\"><a href=\"#B-树-1\" class=\"headerlink\" title=\"B+ 树\"></a>B+ 树</h3><ul>\n<li>所有叶子节点中包含了全部关键字的信息</li>\n<li>各叶子节点用指针进行连接</li>\n<li>非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。</li>\n<li>B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”</li>\n</ul>\n<h2 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h2><h3 id=\"聚集索引\"><a href=\"#聚集索引\" class=\"headerlink\" title=\"聚集索引\"></a>聚集索引</h3><p>实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。</p>\n<p>InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。</p>\n<h3 id=\"辅助索引\"><a href=\"#辅助索引\" class=\"headerlink\" title=\"辅助索引\"></a>辅助索引</h3><p>InnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。</p>\n<p>当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。</p>\n<h3 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h3><p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p>\n<h3 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a>使用场景</h3><ul>\n<li>数据检索</li>\n<li>聚合函数（max/count）</li>\n<li>排序</li>\n<li>避免回表（覆盖索引）</li>\n<li>关联查询</li>\n</ul>\n<h3 id=\"普通索引和唯一索引\"><a href=\"#普通索引和唯一索引\" class=\"headerlink\" title=\"普通索引和唯一索引\"></a>普通索引和唯一索引</h3><h4 id=\"Insert-Buffer\"><a href=\"#Insert-Buffer\" class=\"headerlink\" title=\"Insert Buffer\"></a><strong>Insert Buffer</strong></h4><ul>\n<li><p>对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。</p>\n</li>\n<li><p>如果在，则直接插入；如果不在，则先放入 Insert Buffer 中</p>\n</li>\n<li><p>然后再以一定频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作。</p>\n</li>\n</ul>\n<blockquote>\n<p><strong>要求不是唯一索引</strong></p>\n<p>意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。</p>\n</blockquote>\n<h4 id=\"Change-Buffer\"><a href=\"#Change-Buffer\" class=\"headerlink\" title=\"Change Buffer\"></a><strong>Change Buffer</strong></h4><p>Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update操作都进行缓存。</p>\n<blockquote>\n<p><strong>要求不是唯一索引</strong></p>\n<p>唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。</p>\n<ul>\n<li>innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。</li>\n<li>innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。</li>\n</ul>\n</blockquote>\n<p><strong>适用场景</strong></p>\n<p>对于<strong>写多读少</strong>的业务来说，页面在<strong>写完以后马上被访问到的概率比较小</strong>，此时changebuffer的使用效果最好。这种业务模型常见的就是<strong>账单类、日志类</strong>的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</p>\n<p><strong>区别</strong></p>\n<p>1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。</p>\n<p>2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。</p>\n<p>3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。</p>\n<p>4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。</p>\n<p><strong>选择</strong></p>\n<p>1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引</p>\n<p>2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。</p>\n<h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a>联合索引</h3><p>对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。</p>\n<p>使用：</p>\n<ul>\n<li>where 条件中，经常同时出现的列放在联合索引中。</li>\n<li>把选择性最大的列放在联合索引的最左边。</li>\n</ul>\n<p>联合索引应用：</p>\n<pre><code class=\"mysql\">/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;</code></pre>\n<h3 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h3><p>当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。</p>\n<p>根据“索引选择性”（Index Selectivity）确定前缀长度。</p>\n<p><strong>其他方式</strong></p>\n<p>第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。</p>\n<p>第二种方式是使用hash字段。不支持范围查询。</p>\n<h3 id=\"最左前缀\"><a href=\"#最左前缀\" class=\"headerlink\" title=\"最左前缀\"></a>最左前缀</h3><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p>\n<h3 id=\"主键\"><a href=\"#主键\" class=\"headerlink\" title=\"主键\"></a>主键</h3><p>如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。</p>\n<h3 id=\"优化器索引选择\"><a href=\"#优化器索引选择\" class=\"headerlink\" title=\"优化器索引选择\"></a>优化器索引选择</h3><p><code>show index from t</code>可以看到索引的Cardinality，即索引中不重复记录数量的预估值。</p>\n<p>Cardinality 统计信息的更新时机：</p>\n<ul>\n<li>表中 1/16 的数据已经发生过变化</li>\n<li>表中数据发生变化次数超过 2000000000</li>\n</ul>\n<p><strong>统计方法</strong></p>\n<p>随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数</p>\n<p><strong>问题</strong></p>\n<p>通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。</p>\n<p><strong>应对</strong></p>\n<pre><code class=\"mysql\">analyze table t13;//更新统计信息</code></pre>\n<p><strong>问题</strong></p>\n<p>如果单次选取的数据量过大，可能也会导致“选错”索引</p>\n<pre><code class=\"mysql\">select a from t13 where a&gt;70000 limit 1000;//走了主键索引</code></pre>\n<p><strong>应对</strong></p>\n<p>force index 来强制走索引</p>\n<pre><code class=\"mysql\">select a from t13 force index(idx_a) where a&gt;70000 limit 1000;</code></pre>\n<p><strong>其他应对</strong></p>\n<p>1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p>\n<p>2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p>\n"},{"title":"索引失效","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T03:07:49.000Z","password":null,"summary":null,"_content":"\n## 函数操作\n\n对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。\n\n```mysql\nselect * from t1 where date(c) ='2019-05-21';\n```\n\n优化：改成范围查询\n\n```mysql\nselect * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';\n```\n\n## 隐式转换\n\n操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */\n```\n\n实际会做函数操作：\n\n```mysql\nselect user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; \n```\n\n优化：类型统一\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字\n```\n\n## 模糊查询\n\n通配符在前面\n\n```mysql\nselect * from t1 where a like '%1111%';\n```\n\n优化:模糊查询必须包含条件字段前面的值\n\n```mysql\nselect * from t1 where a like '1111%';\n```\n\n## 范围查询\n\n范围查询数据量太多，需要回表，因此不走索引。\n\n```mysql\nselect * from t1 where b>=1 and b <=2000;\n```\n\n优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）\n\n```\nselect * from t1 where b>=1 and b <=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b>=1 and b <=1000 |\n|        2 | 0.00605625 | select * from t1 where b>=1 and b <=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n## 计算操作\n\n即使是简单的计算\n\n```mysql\nexplain select * from t1 where b-1 =1000;\n```\n\n优化：将计算操作放在等号后面\n\n```mysql\nexplain select * from t1 where b =1000 + 1;\n```\n\n\n\n\n\n","source":"_posts/索引失效.md","raw":"---\ntitle: 索引失效\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 11:07:49\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 函数操作\n\n对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。\n\n```mysql\nselect * from t1 where date(c) ='2019-05-21';\n```\n\n优化：改成范围查询\n\n```mysql\nselect * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';\n```\n\n## 隐式转换\n\n操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */\n```\n\n实际会做函数操作：\n\n```mysql\nselect user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; \n```\n\n优化：类型统一\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字\n```\n\n## 模糊查询\n\n通配符在前面\n\n```mysql\nselect * from t1 where a like '%1111%';\n```\n\n优化:模糊查询必须包含条件字段前面的值\n\n```mysql\nselect * from t1 where a like '1111%';\n```\n\n## 范围查询\n\n范围查询数据量太多，需要回表，因此不走索引。\n\n```mysql\nselect * from t1 where b>=1 and b <=2000;\n```\n\n优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）\n\n```\nselect * from t1 where b>=1 and b <=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b>=1 and b <=1000 |\n|        2 | 0.00605625 | select * from t1 where b>=1 and b <=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n## 计算操作\n\n即使是简单的计算\n\n```mysql\nexplain select * from t1 where b-1 =1000;\n```\n\n优化：将计算操作放在等号后面\n\n```mysql\nexplain select * from t1 where b =1000 + 1;\n```\n\n\n\n\n\n","slug":"索引失效","published":1,"updated":"2021-04-29T14:37:57.747Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78p0069q4uf3dz6lvwi","content":"<h2 id=\"函数操作\"><a href=\"#函数操作\" class=\"headerlink\" title=\"函数操作\"></a>函数操作</h2><p>对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where date(c) ='2019-05-21';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：改成范围查询</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"隐式转换\"><a href=\"#隐式转换\" class=\"headerlink\" title=\"隐式转换\"></a>隐式转换</h2><p>操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>实际会做函数操作：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：类型统一</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"模糊查询\"><a href=\"#模糊查询\" class=\"headerlink\" title=\"模糊查询\"></a>模糊查询</h2><p>通配符在前面</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where a like '%1111%';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化:模糊查询必须包含条件字段前面的值</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where a like '1111%';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"范围查询\"><a href=\"#范围查询\" class=\"headerlink\" title=\"范围查询\"></a>范围查询</h2><p>范围查询数据量太多，需要回表，因此不走索引。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where b>=1 and b <=2000;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）</p>\n<pre><code>select * from t1 where b&gt;=1 and b &lt;=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b&gt;=1 and b &lt;=1000 |\n|        2 | 0.00605625 | select * from t1 where b&gt;=1 and b &lt;=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)</code></pre><h2 id=\"计算操作\"><a href=\"#计算操作\" class=\"headerlink\" title=\"计算操作\"></a>计算操作</h2><p>即使是简单的计算</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">explain select * from t1 where b-1 =1000;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：将计算操作放在等号后面</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">explain select * from t1 where b =1000 + 1;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"函数操作\"><a href=\"#函数操作\" class=\"headerlink\" title=\"函数操作\"></a>函数操作</h2><p>对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。</p>\n<pre><code class=\"mysql\">select * from t1 where date(c) =&#39;2019-05-21&#39;;</code></pre>\n<p>优化：改成范围查询</p>\n<pre><code class=\"mysql\">select * from t1 where c&gt;=&#39;2019-05-21 00:00:00&#39; and c&lt;=&#39;2019-05-21 23:59:59&#39;;</code></pre>\n<h2 id=\"隐式转换\"><a href=\"#隐式转换\" class=\"headerlink\" title=\"隐式转换\"></a>隐式转换</h2><p>操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。</p>\n<pre><code class=\"mysql\">select user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */</code></pre>\n<p>实际会做函数操作：</p>\n<pre><code class=\"mysql\">select user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; </code></pre>\n<p>优化：类型统一</p>\n<pre><code class=\"mysql\">select user_name,tele_phone from user_info where tele_phone =&#39;11111111111&#39;;//字符串转数字</code></pre>\n<h2 id=\"模糊查询\"><a href=\"#模糊查询\" class=\"headerlink\" title=\"模糊查询\"></a>模糊查询</h2><p>通配符在前面</p>\n<pre><code class=\"mysql\">select * from t1 where a like &#39;%1111%&#39;;</code></pre>\n<p>优化:模糊查询必须包含条件字段前面的值</p>\n<pre><code class=\"mysql\">select * from t1 where a like &#39;1111%&#39;;</code></pre>\n<h2 id=\"范围查询\"><a href=\"#范围查询\" class=\"headerlink\" title=\"范围查询\"></a>范围查询</h2><p>范围查询数据量太多，需要回表，因此不走索引。</p>\n<pre><code class=\"mysql\">select * from t1 where b&gt;=1 and b &lt;=2000;</code></pre>\n<p>优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）</p>\n<pre><code>select * from t1 where b&gt;=1 and b &lt;=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b&gt;=1 and b &lt;=1000 |\n|        2 | 0.00605625 | select * from t1 where b&gt;=1 and b &lt;=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)</code></pre><h2 id=\"计算操作\"><a href=\"#计算操作\" class=\"headerlink\" title=\"计算操作\"></a>计算操作</h2><p>即使是简单的计算</p>\n<pre><code class=\"mysql\">explain select * from t1 where b-1 =1000;</code></pre>\n<p>优化：将计算操作放在等号后面</p>\n<pre><code class=\"mysql\">explain select * from t1 where b =1000 + 1;</code></pre>\n"},{"title":"锁","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-14T03:14:09.000Z","password":null,"summary":null,"_content":"\n锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。\n\n## 全局锁\n\nMySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。\n\n```mysql\nFLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;\n```\n\n当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。\n\n**场景**\n\n一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。\n\n> mysqldump 包含一个参数 `--single-transaction`，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。\n\n## 表级锁\n\n表级锁有两种：表锁和元数据锁。\n\n### 表锁\n\n**场景**\n\n1. 事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；\n2. 事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。\n\n```mysql\nlock tables t14 read;\nlock tables t14 write;\n```\n\n表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。\n\n### 元数据锁\n\nMDL不需要显式使用，在访问一个表的时候会被自动加上。\n\nMDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。\n\n> 对开发而言尽量避免慢查询，事务要及时提交，避免大事务。\n>\n> 对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。\n\n在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。\n\n```mysql\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n```\n\n## 行锁\n\n- InnoDB 支持事务：适合在并发条件下要求数据一致的场景。\n- InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。\n\n### 两阶段锁\n\n行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。\n\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n\n### 行锁\n\n两种类型的行锁：\n\n- 共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；\n- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。\n\n共享锁（S）：`select * from table_name where … lock in share mode;`\n排他锁（X）：`select * from table_name where … for update(当前读)`。\n\n### 行锁算法\n\nRecord Lock：单个记录上的索引加锁。\nGap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。\nNext-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。\n\n### 加锁规则\n\n5.x系列<=5.7.24，8.0系列 <=8.0.13\n\n1. 原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。\n2. 原则2：查找过程中访问到的对象才会加锁。\n3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。\n4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。\n5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n### 加锁分析\n\n#### 非索引字段查询（RC）\n\n如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。\n\n#### 唯一索引查询（RC）\n\n如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。\n\n#### 非唯一索引查询（RC）\n\n如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。\n\n#### 非索引字段查询（RR）\n\nRR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）\n\n#### 唯一索引查询（RR）\n\n如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。\n\n以唯一索引为条件的当前读，不会有 GAP 锁。\n\n#### 非唯一索引查询（RR）\n\n新增GAP锁+对应数据的X锁\n\n## 悲观锁\n\n借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制。\n\n**优点：**利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳\n**缺点：**一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量\n\n**适用场景**：写入操作比较频繁的场景\n\n## 乐观锁\n\n假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据冲突与否进行检测。\n\n**优点：**由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高\n**缺点：**锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈\n\n**适用场景**：读取操作比较频繁的场景\n\n## 锁定位\n\n1、show processlist，查看state\n\n## 死锁\n\n死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。\n\n**“唯一键”引起的死锁**\n\n会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。\n\n之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。\n\n**解决方法**\n\n1. 检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；\n2. 等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。\n\n方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。\n\n**降低死锁概率**\n\n1. 更新 SQL 的 where 条件尽量用索引；\n2. 基于 primary 或 unique key 更新数据；\n3. 减少范围更新，尤其非主键、非唯一索引上的范围更新；\n4. 加锁顺序一致，尽可能一次性锁定所有需要行；\n5. 将 RR 隔离级别调整为 RC 隔离级别。\n\n**分析死锁**\n\n```mysql\nSHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息\n```\n\n另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。\n\nINNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。\n\nINNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。\n\nINNODB_LOCK_WAITS记录了事务的锁等待状态。","source":"_posts/锁.md","raw":"---\ntitle: 锁\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-14 11:14:09\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。\n\n## 全局锁\n\nMySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。\n\n```mysql\nFLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;\n```\n\n当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。\n\n**场景**\n\n一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。\n\n> mysqldump 包含一个参数 `--single-transaction`，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。\n\n## 表级锁\n\n表级锁有两种：表锁和元数据锁。\n\n### 表锁\n\n**场景**\n\n1. 事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；\n2. 事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。\n\n```mysql\nlock tables t14 read;\nlock tables t14 write;\n```\n\n表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。\n\n### 元数据锁\n\nMDL不需要显式使用，在访问一个表的时候会被自动加上。\n\nMDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。\n\n> 对开发而言尽量避免慢查询，事务要及时提交，避免大事务。\n>\n> 对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。\n\n在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。\n\n```mysql\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n```\n\n## 行锁\n\n- InnoDB 支持事务：适合在并发条件下要求数据一致的场景。\n- InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。\n\n### 两阶段锁\n\n行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。\n\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n\n### 行锁\n\n两种类型的行锁：\n\n- 共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；\n- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。\n\n共享锁（S）：`select * from table_name where … lock in share mode;`\n排他锁（X）：`select * from table_name where … for update(当前读)`。\n\n### 行锁算法\n\nRecord Lock：单个记录上的索引加锁。\nGap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。\nNext-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。\n\n### 加锁规则\n\n5.x系列<=5.7.24，8.0系列 <=8.0.13\n\n1. 原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。\n2. 原则2：查找过程中访问到的对象才会加锁。\n3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。\n4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。\n5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n### 加锁分析\n\n#### 非索引字段查询（RC）\n\n如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。\n\n#### 唯一索引查询（RC）\n\n如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。\n\n#### 非唯一索引查询（RC）\n\n如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。\n\n#### 非索引字段查询（RR）\n\nRR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）\n\n#### 唯一索引查询（RR）\n\n如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。\n\n以唯一索引为条件的当前读，不会有 GAP 锁。\n\n#### 非唯一索引查询（RR）\n\n新增GAP锁+对应数据的X锁\n\n## 悲观锁\n\n借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制。\n\n**优点：**利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳\n**缺点：**一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量\n\n**适用场景**：写入操作比较频繁的场景\n\n## 乐观锁\n\n假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据冲突与否进行检测。\n\n**优点：**由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高\n**缺点：**锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈\n\n**适用场景**：读取操作比较频繁的场景\n\n## 锁定位\n\n1、show processlist，查看state\n\n## 死锁\n\n死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。\n\n**“唯一键”引起的死锁**\n\n会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。\n\n之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。\n\n**解决方法**\n\n1. 检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；\n2. 等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。\n\n方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。\n\n**降低死锁概率**\n\n1. 更新 SQL 的 where 条件尽量用索引；\n2. 基于 primary 或 unique key 更新数据；\n3. 减少范围更新，尤其非主键、非唯一索引上的范围更新；\n4. 加锁顺序一致，尽可能一次性锁定所有需要行；\n5. 将 RR 隔离级别调整为 RC 隔离级别。\n\n**分析死锁**\n\n```mysql\nSHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息\n```\n\n另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。\n\nINNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。\n\nINNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。\n\nINNODB_LOCK_WAITS记录了事务的锁等待状态。","slug":"锁","published":1,"updated":"2021-05-12T11:53:48.536Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78s006cq4ufqh8fquyy","content":"<p>锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。</p>\n<h2 id=\"全局锁\"><a href=\"#全局锁\" class=\"headerlink\" title=\"全局锁\"></a>全局锁</h2><p>MySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">FLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。</p>\n<p><strong>场景</strong></p>\n<p>一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。</p>\n<blockquote>\n<p>mysqldump 包含一个参数 <code>--single-transaction</code>，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。</p>\n</blockquote>\n<h2 id=\"表级锁\"><a href=\"#表级锁\" class=\"headerlink\" title=\"表级锁\"></a>表级锁</h2><p>表级锁有两种：表锁和元数据锁。</p>\n<h3 id=\"表锁\"><a href=\"#表锁\" class=\"headerlink\" title=\"表锁\"></a>表锁</h3><p><strong>场景</strong></p>\n<ol>\n<li>事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；</li>\n<li>事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。</li>\n</ol>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">lock tables t14 read;\nlock tables t14 write;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。</p>\n<h3 id=\"元数据锁\"><a href=\"#元数据锁\" class=\"headerlink\" title=\"元数据锁\"></a>元数据锁</h3><p>MDL不需要显式使用，在访问一个表的时候会被自动加上。</p>\n<p>MDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。</p>\n<blockquote>\n<p>对开发而言尽量避免慢查询，事务要及时提交，避免大事务。</p>\n<p>对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。</p>\n</blockquote>\n<p>在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">ALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h2 id=\"行锁\"><a href=\"#行锁\" class=\"headerlink\" title=\"行锁\"></a>行锁</h2><ul>\n<li>InnoDB 支持事务：适合在并发条件下要求数据一致的场景。</li>\n<li>InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。</li>\n</ul>\n<h3 id=\"两阶段锁\"><a href=\"#两阶段锁\" class=\"headerlink\" title=\"两阶段锁\"></a>两阶段锁</h3><p>行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。</p>\n<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>\n<h3 id=\"行锁-1\"><a href=\"#行锁-1\" class=\"headerlink\" title=\"行锁\"></a>行锁</h3><p>两种类型的行锁：</p>\n<ul>\n<li>共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；</li>\n<li>排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。</li>\n</ul>\n<p>共享锁（S）：<code>select * from table_name where … lock in share mode;</code><br>排他锁（X）：<code>select * from table_name where … for update(当前读)</code>。</p>\n<h3 id=\"行锁算法\"><a href=\"#行锁算法\" class=\"headerlink\" title=\"行锁算法\"></a>行锁算法</h3><p>Record Lock：单个记录上的索引加锁。<br>Gap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。<br>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。</p>\n<h3 id=\"加锁规则\"><a href=\"#加锁规则\" class=\"headerlink\" title=\"加锁规则\"></a>加锁规则</h3><p>5.x系列&lt;=5.7.24，8.0系列 &lt;=8.0.13</p>\n<ol>\n<li>原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。</li>\n<li>原则2：查找过程中访问到的对象才会加锁。</li>\n<li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li>\n<li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li>\n<li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>\n</ol>\n<h3 id=\"加锁分析\"><a href=\"#加锁分析\" class=\"headerlink\" title=\"加锁分析\"></a>加锁分析</h3><h4 id=\"非索引字段查询（RC）\"><a href=\"#非索引字段查询（RC）\" class=\"headerlink\" title=\"非索引字段查询（RC）\"></a>非索引字段查询（RC）</h4><p>如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。</p>\n<h4 id=\"唯一索引查询（RC）\"><a href=\"#唯一索引查询（RC）\" class=\"headerlink\" title=\"唯一索引查询（RC）\"></a>唯一索引查询（RC）</h4><p>如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。</p>\n<h4 id=\"非唯一索引查询（RC）\"><a href=\"#非唯一索引查询（RC）\" class=\"headerlink\" title=\"非唯一索引查询（RC）\"></a>非唯一索引查询（RC）</h4><p>如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。</p>\n<h4 id=\"非索引字段查询（RR）\"><a href=\"#非索引字段查询（RR）\" class=\"headerlink\" title=\"非索引字段查询（RR）\"></a>非索引字段查询（RR）</h4><p>RR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）</p>\n<h4 id=\"唯一索引查询（RR）\"><a href=\"#唯一索引查询（RR）\" class=\"headerlink\" title=\"唯一索引查询（RR）\"></a>唯一索引查询（RR）</h4><p>如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。</p>\n<p>以唯一索引为条件的当前读，不会有 GAP 锁。</p>\n<h4 id=\"非唯一索引查询（RR）\"><a href=\"#非唯一索引查询（RR）\" class=\"headerlink\" title=\"非唯一索引查询（RR）\"></a>非唯一索引查询（RR）</h4><p>新增GAP锁+对应数据的X锁</p>\n<h2 id=\"悲观锁\"><a href=\"#悲观锁\" class=\"headerlink\" title=\"悲观锁\"></a>悲观锁</h2><p>借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制。</p>\n<p><strong>优点：</strong>利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳<br><strong>缺点：</strong>一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量</p>\n<p><strong>适用场景</strong>：写入操作比较频繁的场景</p>\n<h2 id=\"乐观锁\"><a href=\"#乐观锁\" class=\"headerlink\" title=\"乐观锁\"></a>乐观锁</h2><p>假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据冲突与否进行检测。</p>\n<p><strong>优点：</strong>由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高<br><strong>缺点：</strong>锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈</p>\n<p><strong>适用场景</strong>：读取操作比较频繁的场景</p>\n<h2 id=\"锁定位\"><a href=\"#锁定位\" class=\"headerlink\" title=\"锁定位\"></a>锁定位</h2><p>1、show processlist，查看state</p>\n<h2 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h2><p>死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。</p>\n<p><strong>“唯一键”引起的死锁</strong></p>\n<p>会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。</p>\n<p>之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。</p>\n<p><strong>解决方法</strong></p>\n<ol>\n<li>检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；</li>\n<li>等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。</li>\n</ol>\n<p>方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。</p>\n<p><strong>降低死锁概率</strong></p>\n<ol>\n<li>更新 SQL 的 where 条件尽量用索引；</li>\n<li>基于 primary 或 unique key 更新数据；</li>\n<li>减少范围更新，尤其非主键、非唯一索引上的范围更新；</li>\n<li>加锁顺序一致，尽可能一次性锁定所有需要行；</li>\n<li>将 RR 隔离级别调整为 RC 隔离级别。</li>\n</ol>\n<p><strong>分析死锁</strong></p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">SHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。</p>\n<p>INNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。</p>\n<p>INNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。</p>\n<p>INNODB_LOCK_WAITS记录了事务的锁等待状态。</p>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<p>锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。</p>\n<h2 id=\"全局锁\"><a href=\"#全局锁\" class=\"headerlink\" title=\"全局锁\"></a>全局锁</h2><p>MySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。</p>\n<pre><code class=\"mysql\">FLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;</code></pre>\n<p>当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。</p>\n<p><strong>场景</strong></p>\n<p>一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。</p>\n<blockquote>\n<p>mysqldump 包含一个参数 <code>--single-transaction</code>，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。</p>\n</blockquote>\n<h2 id=\"表级锁\"><a href=\"#表级锁\" class=\"headerlink\" title=\"表级锁\"></a>表级锁</h2><p>表级锁有两种：表锁和元数据锁。</p>\n<h3 id=\"表锁\"><a href=\"#表锁\" class=\"headerlink\" title=\"表锁\"></a>表锁</h3><p><strong>场景</strong></p>\n<ol>\n<li>事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；</li>\n<li>事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。</li>\n</ol>\n<pre><code class=\"mysql\">lock tables t14 read;\nlock tables t14 write;</code></pre>\n<p>表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。</p>\n<h3 id=\"元数据锁\"><a href=\"#元数据锁\" class=\"headerlink\" title=\"元数据锁\"></a>元数据锁</h3><p>MDL不需要显式使用，在访问一个表的时候会被自动加上。</p>\n<p>MDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。</p>\n<blockquote>\n<p>对开发而言尽量避免慢查询，事务要及时提交，避免大事务。</p>\n<p>对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。</p>\n</blockquote>\n<p>在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。</p>\n<pre><code class=\"mysql\">ALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...</code></pre>\n<h2 id=\"行锁\"><a href=\"#行锁\" class=\"headerlink\" title=\"行锁\"></a>行锁</h2><ul>\n<li>InnoDB 支持事务：适合在并发条件下要求数据一致的场景。</li>\n<li>InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。</li>\n</ul>\n<h3 id=\"两阶段锁\"><a href=\"#两阶段锁\" class=\"headerlink\" title=\"两阶段锁\"></a>两阶段锁</h3><p>行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。</p>\n<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>\n<h3 id=\"行锁-1\"><a href=\"#行锁-1\" class=\"headerlink\" title=\"行锁\"></a>行锁</h3><p>两种类型的行锁：</p>\n<ul>\n<li>共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；</li>\n<li>排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。</li>\n</ul>\n<p>共享锁（S）：<code>select * from table_name where … lock in share mode;</code><br>排他锁（X）：<code>select * from table_name where … for update(当前读)</code>。</p>\n<h3 id=\"行锁算法\"><a href=\"#行锁算法\" class=\"headerlink\" title=\"行锁算法\"></a>行锁算法</h3><p>Record Lock：单个记录上的索引加锁。<br>Gap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。<br>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。</p>\n<h3 id=\"加锁规则\"><a href=\"#加锁规则\" class=\"headerlink\" title=\"加锁规则\"></a>加锁规则</h3><p>5.x系列&lt;=5.7.24，8.0系列 &lt;=8.0.13</p>\n<ol>\n<li>原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。</li>\n<li>原则2：查找过程中访问到的对象才会加锁。</li>\n<li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li>\n<li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li>\n<li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>\n</ol>\n<h3 id=\"加锁分析\"><a href=\"#加锁分析\" class=\"headerlink\" title=\"加锁分析\"></a>加锁分析</h3><h4 id=\"非索引字段查询（RC）\"><a href=\"#非索引字段查询（RC）\" class=\"headerlink\" title=\"非索引字段查询（RC）\"></a>非索引字段查询（RC）</h4><p>如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。</p>\n<h4 id=\"唯一索引查询（RC）\"><a href=\"#唯一索引查询（RC）\" class=\"headerlink\" title=\"唯一索引查询（RC）\"></a>唯一索引查询（RC）</h4><p>如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。</p>\n<h4 id=\"非唯一索引查询（RC）\"><a href=\"#非唯一索引查询（RC）\" class=\"headerlink\" title=\"非唯一索引查询（RC）\"></a>非唯一索引查询（RC）</h4><p>如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。</p>\n<h4 id=\"非索引字段查询（RR）\"><a href=\"#非索引字段查询（RR）\" class=\"headerlink\" title=\"非索引字段查询（RR）\"></a>非索引字段查询（RR）</h4><p>RR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）</p>\n<h4 id=\"唯一索引查询（RR）\"><a href=\"#唯一索引查询（RR）\" class=\"headerlink\" title=\"唯一索引查询（RR）\"></a>唯一索引查询（RR）</h4><p>如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。</p>\n<p>以唯一索引为条件的当前读，不会有 GAP 锁。</p>\n<h4 id=\"非唯一索引查询（RR）\"><a href=\"#非唯一索引查询（RR）\" class=\"headerlink\" title=\"非唯一索引查询（RR）\"></a>非唯一索引查询（RR）</h4><p>新增GAP锁+对应数据的X锁</p>\n<h2 id=\"悲观锁\"><a href=\"#悲观锁\" class=\"headerlink\" title=\"悲观锁\"></a>悲观锁</h2><p>借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制。</p>\n<p><strong>优点：</strong>利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳<br><strong>缺点：</strong>一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量</p>\n<p><strong>适用场景</strong>：写入操作比较频繁的场景</p>\n<h2 id=\"乐观锁\"><a href=\"#乐观锁\" class=\"headerlink\" title=\"乐观锁\"></a>乐观锁</h2><p>假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据冲突与否进行检测。</p>\n<p><strong>优点：</strong>由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高<br><strong>缺点：</strong>锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈</p>\n<p><strong>适用场景</strong>：读取操作比较频繁的场景</p>\n<h2 id=\"锁定位\"><a href=\"#锁定位\" class=\"headerlink\" title=\"锁定位\"></a>锁定位</h2><p>1、show processlist，查看state</p>\n<h2 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h2><p>死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。</p>\n<p><strong>“唯一键”引起的死锁</strong></p>\n<p>会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。</p>\n<p>之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。</p>\n<p><strong>解决方法</strong></p>\n<ol>\n<li>检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；</li>\n<li>等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。</li>\n</ol>\n<p>方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。</p>\n<p><strong>降低死锁概率</strong></p>\n<ol>\n<li>更新 SQL 的 where 条件尽量用索引；</li>\n<li>基于 primary 或 unique key 更新数据；</li>\n<li>减少范围更新，尤其非主键、非唯一索引上的范围更新；</li>\n<li>加锁顺序一致，尽可能一次性锁定所有需要行；</li>\n<li>将 RR 隔离级别调整为 RC 隔离级别。</li>\n</ol>\n<p><strong>分析死锁</strong></p>\n<pre><code class=\"mysql\">SHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息</code></pre>\n<p>另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。</p>\n<p>INNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。</p>\n<p>INNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。</p>\n<p>INNODB_LOCK_WAITS记录了事务的锁等待状态。</p>\n"},{"title":"读写分离","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-15T11:27:16.000Z","password":null,"summary":"mysql主从复制中异步复制和半同步复制的原理；可靠性/可用性优先策略下的主从切换；备库并行复制策略;主从延迟的原因和判断方法；主备切换的多种方法；过期读的解决方案；","_content":"\n## 主从复制\n\n### 异步复制\n\n- 在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。\n- 主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）\n- 从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。\n\n### 半同步复制\n\n- 在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。\n- 主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，**从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功**\n- 从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。\n\n## 主从切换\n\n### 可靠性优先策略\n\n1. 判断备库的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；\n2. 把主库改成只读状态，把readonly设为true；\n3. 判断备库的seconds_behind_master的值，直到这个值变成0为止；\n4. 把备库改成可读写状态，把readonly 设为false；\n5. 把业务请求切到备库B。\n\n> 如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。\n\n### 可用性优先策略\n\n不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。\n\n> 可能出现不一致的数据。\n>\n> 设置binlog_format=row，会出现duplicate key error并停止；\n>\n> 使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了\n\n## 备库并行复制策略\n\n### 按库并行\n\n用于决定分发策略的hash表里，key就是数据库名。\n\n> 如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；\n>\n> 或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n\n### MariaDB的并行复制策略\n\n> 利用redo log组提交特性：\n>\n> - 能够在同一组里提交的事务，一定不会修改同一行；\n>\n> - 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n实现方法\n\n1. 在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；\n2. commit_id直接写到binlog里面；\n3. 传到备库应用的时候，相同commit_id的事务分发到多个worker执行；\n4. 这一组全部执行完成后，coordinator再去取下一批。\n\n### MySQL 5.7.22的新增并行复制策略\n\n基于WRITESET的并行复制。\n\n参数`binlog-transaction-dependency-tracking`，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n1. COMMIT_ORDER，根据同时进入prepare和commit来判断是否可以并行的策略。\n2. WRITESET，表示的是对于事务涉及更新的每一行，计算出它的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。\n3. WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n## 主从延迟\n\n### 可能原因\n\n- 大表 DDL\n- 大事务\n- 主库 DML 并发大\n- 从库配置差\n\n### 判断主从延迟\n\n1、判断 Seconds_Behind_Master 是否等于 0。\n\n2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。\n\n3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。\n\n## 主备切换\n\n### **基于位点的主备切换**\n\n考虑到切换过程中不能丢数据，所以找位点时，找一个“稍微往前”的。再通过判断，跳过那些在从库上已经执行过的事务。\n\n通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。\n\n- 主动跳过一个事务。\n- 通过设置slave_skip_errors参数，直接设置跳过指定的错误。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos\n```\n\n### **基于GTID的主备切换**\n\nGTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1\n```\n\n主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:\n1. 实例B指定主库A’，基于主备协议建立连接。\n2. 实例B把set_b发给主库A’。\n3. 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。\na. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；\nb. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；\n4. 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。\n\n## 过期读\n\n问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。\n\n### **强制走主库方案**\n\n1. 对于必须要拿到最新结果的请求，强制将其发到主库上\n2. 对于可以读到旧数据的请求，才将其发到从库上。\n\n### **sleep方案**\n\n大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条`select sleep(1)`命令。\n\n以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。\n\n**缺点**\n\n1. 如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；\n2. 如果延迟超过1秒，还是会出现过期读。\n\n### **判断主备无延迟方案**\n\n- 第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。\n\n- 第二种方法，对比位点确保主备无延迟（show slave status）：\n  Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；\n  Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。\n  如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成\n\n- 第三种方法，对比GTID集合确保主备无延迟（show slave status）：\n\n  Auto_Position=1 ，表示这对主备关系使用了GTID协议。\n  Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；\n  Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。\n\n  缺点：仍可能过期读。备库收到的日志都执行完成了。还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n### **配合semi-sync方案**\n\n引入半同步复制，配合前面关于位点的判断。\n\n> 在一主多从场景中，如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。\n>\n> 在持续延迟的情况下，可能出现过度等待的问题。\n\n### **等主库位点方案**\n\n1. trx1事务更新完成后，马上执行`show master status`得到当前主库执行到的File和Position；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行`select master_pos_wait(File, Position, 1)`；\n4. 如果返回值是>=0的正整数，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n> 等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n### **等GTID方案**\n\n1. trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行 `select wait_for_executed_gtid_set(gtid1, 1)`；\n4. 如果返回值是0，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n> 等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n","source":"_posts/读写分离.md","raw":"---\ntitle: 读写分离\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-15 19:27:16\npassword:\nsummary: mysql主从复制中异步复制和半同步复制的原理；可靠性/可用性优先策略下的主从切换；备库并行复制策略;主从延迟的原因和判断方法；主备切换的多种方法；过期读的解决方案；\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 主从复制\n\n### 异步复制\n\n- 在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。\n- 主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）\n- 从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。\n\n### 半同步复制\n\n- 在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。\n- 主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，**从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功**\n- 从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。\n\n## 主从切换\n\n### 可靠性优先策略\n\n1. 判断备库的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；\n2. 把主库改成只读状态，把readonly设为true；\n3. 判断备库的seconds_behind_master的值，直到这个值变成0为止；\n4. 把备库改成可读写状态，把readonly 设为false；\n5. 把业务请求切到备库B。\n\n> 如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。\n\n### 可用性优先策略\n\n不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。\n\n> 可能出现不一致的数据。\n>\n> 设置binlog_format=row，会出现duplicate key error并停止；\n>\n> 使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了\n\n## 备库并行复制策略\n\n### 按库并行\n\n用于决定分发策略的hash表里，key就是数据库名。\n\n> 如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；\n>\n> 或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n\n### MariaDB的并行复制策略\n\n> 利用redo log组提交特性：\n>\n> - 能够在同一组里提交的事务，一定不会修改同一行；\n>\n> - 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n实现方法\n\n1. 在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；\n2. commit_id直接写到binlog里面；\n3. 传到备库应用的时候，相同commit_id的事务分发到多个worker执行；\n4. 这一组全部执行完成后，coordinator再去取下一批。\n\n### MySQL 5.7.22的新增并行复制策略\n\n基于WRITESET的并行复制。\n\n参数`binlog-transaction-dependency-tracking`，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n1. COMMIT_ORDER，根据同时进入prepare和commit来判断是否可以并行的策略。\n2. WRITESET，表示的是对于事务涉及更新的每一行，计算出它的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。\n3. WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n## 主从延迟\n\n### 可能原因\n\n- 大表 DDL\n- 大事务\n- 主库 DML 并发大\n- 从库配置差\n\n### 判断主从延迟\n\n1、判断 Seconds_Behind_Master 是否等于 0。\n\n2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。\n\n3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。\n\n## 主备切换\n\n### **基于位点的主备切换**\n\n考虑到切换过程中不能丢数据，所以找位点时，找一个“稍微往前”的。再通过判断，跳过那些在从库上已经执行过的事务。\n\n通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。\n\n- 主动跳过一个事务。\n- 通过设置slave_skip_errors参数，直接设置跳过指定的错误。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos\n```\n\n### **基于GTID的主备切换**\n\nGTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1\n```\n\n主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:\n1. 实例B指定主库A’，基于主备协议建立连接。\n2. 实例B把set_b发给主库A’。\n3. 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。\na. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；\nb. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；\n4. 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。\n\n## 过期读\n\n问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。\n\n### **强制走主库方案**\n\n1. 对于必须要拿到最新结果的请求，强制将其发到主库上\n2. 对于可以读到旧数据的请求，才将其发到从库上。\n\n### **sleep方案**\n\n大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条`select sleep(1)`命令。\n\n以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。\n\n**缺点**\n\n1. 如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；\n2. 如果延迟超过1秒，还是会出现过期读。\n\n### **判断主备无延迟方案**\n\n- 第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。\n\n- 第二种方法，对比位点确保主备无延迟（show slave status）：\n  Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；\n  Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。\n  如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成\n\n- 第三种方法，对比GTID集合确保主备无延迟（show slave status）：\n\n  Auto_Position=1 ，表示这对主备关系使用了GTID协议。\n  Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；\n  Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。\n\n  缺点：仍可能过期读。备库收到的日志都执行完成了。还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n### **配合semi-sync方案**\n\n引入半同步复制，配合前面关于位点的判断。\n\n> 在一主多从场景中，如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。\n>\n> 在持续延迟的情况下，可能出现过度等待的问题。\n\n### **等主库位点方案**\n\n1. trx1事务更新完成后，马上执行`show master status`得到当前主库执行到的File和Position；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行`select master_pos_wait(File, Position, 1)`；\n4. 如果返回值是>=0的正整数，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n> 等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n### **等GTID方案**\n\n1. trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行 `select wait_for_executed_gtid_set(gtid1, 1)`；\n4. 如果返回值是0，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n> 等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n","slug":"读写分离","published":1,"updated":"2021-04-29T12:10:57.202Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckowss78x006fq4ufehdtx013","content":"<h2 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h2><h3 id=\"异步复制\"><a href=\"#异步复制\" class=\"headerlink\" title=\"异步复制\"></a>异步复制</h3><ul>\n<li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li>\n<li>主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）</li>\n<li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li>\n</ul>\n<h3 id=\"半同步复制\"><a href=\"#半同步复制\" class=\"headerlink\" title=\"半同步复制\"></a>半同步复制</h3><ul>\n<li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li>\n<li>主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，<strong>从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功</strong></li>\n<li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li>\n</ul>\n<h2 id=\"主从切换\"><a href=\"#主从切换\" class=\"headerlink\" title=\"主从切换\"></a>主从切换</h2><h3 id=\"可靠性优先策略\"><a href=\"#可靠性优先策略\" class=\"headerlink\" title=\"可靠性优先策略\"></a>可靠性优先策略</h3><ol>\n<li>判断备库的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；</li>\n<li>把主库改成只读状态，把readonly设为true；</li>\n<li>判断备库的seconds_behind_master的值，直到这个值变成0为止；</li>\n<li>把备库改成可读写状态，把readonly 设为false；</li>\n<li>把业务请求切到备库B。</li>\n</ol>\n<blockquote>\n<p>如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。</p>\n</blockquote>\n<h3 id=\"可用性优先策略\"><a href=\"#可用性优先策略\" class=\"headerlink\" title=\"可用性优先策略\"></a>可用性优先策略</h3><p>不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。</p>\n<blockquote>\n<p>可能出现不一致的数据。</p>\n<p>设置binlog_format=row，会出现duplicate key error并停止；</p>\n<p>使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了</p>\n</blockquote>\n<h2 id=\"备库并行复制策略\"><a href=\"#备库并行复制策略\" class=\"headerlink\" title=\"备库并行复制策略\"></a>备库并行复制策略</h2><h3 id=\"按库并行\"><a href=\"#按库并行\" class=\"headerlink\" title=\"按库并行\"></a>按库并行</h3><p>用于决定分发策略的hash表里，key就是数据库名。</p>\n<blockquote>\n<p>如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；</p>\n<p>或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。</p>\n</blockquote>\n<h3 id=\"MariaDB的并行复制策略\"><a href=\"#MariaDB的并行复制策略\" class=\"headerlink\" title=\"MariaDB的并行复制策略\"></a>MariaDB的并行复制策略</h3><blockquote>\n<p>利用redo log组提交特性：</p>\n<ul>\n<li><p>能够在同一组里提交的事务，一定不会修改同一行；</p>\n</li>\n<li><p>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</p>\n</li>\n</ul>\n</blockquote>\n<p>实现方法</p>\n<ol>\n<li>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；</li>\n<li>commit_id直接写到binlog里面；</li>\n<li>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；</li>\n<li>这一组全部执行完成后，coordinator再去取下一批。</li>\n</ol>\n<h3 id=\"MySQL-5-7-22的新增并行复制策略\"><a href=\"#MySQL-5-7-22的新增并行复制策略\" class=\"headerlink\" title=\"MySQL 5.7.22的新增并行复制策略\"></a>MySQL 5.7.22的新增并行复制策略</h3><p>基于WRITESET的并行复制。</p>\n<p>参数<code>binlog-transaction-dependency-tracking</code>，用来控制是否启用这个新策略。这个参数的可选值有以下三种。</p>\n<ol>\n<li>COMMIT_ORDER，根据同时进入prepare和commit来判断是否可以并行的策略。</li>\n<li>WRITESET，表示的是对于事务涉及更新的每一行，计算出它的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。</li>\n<li>WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li>\n</ol>\n<h2 id=\"主从延迟\"><a href=\"#主从延迟\" class=\"headerlink\" title=\"主从延迟\"></a>主从延迟</h2><h3 id=\"可能原因\"><a href=\"#可能原因\" class=\"headerlink\" title=\"可能原因\"></a>可能原因</h3><ul>\n<li>大表 DDL</li>\n<li>大事务</li>\n<li>主库 DML 并发大</li>\n<li>从库配置差</li>\n</ul>\n<h3 id=\"判断主从延迟\"><a href=\"#判断主从延迟\" class=\"headerlink\" title=\"判断主从延迟\"></a>判断主从延迟</h3><p>1、判断 Seconds_Behind_Master 是否等于 0。</p>\n<p>2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。</p>\n<p>3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。</p>\n<h2 id=\"主备切换\"><a href=\"#主备切换\" class=\"headerlink\" title=\"主备切换\"></a>主备切换</h2><h3 id=\"基于位点的主备切换\"><a href=\"#基于位点的主备切换\" class=\"headerlink\" title=\"基于位点的主备切换\"></a><strong>基于位点的主备切换</strong></h3><p>考虑到切换过程中不能丢数据，所以找位点时，找一个“稍微往前”的。再通过判断，跳过那些在从库上已经执行过的事务。</p>\n<p>通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。</p>\n<ul>\n<li>主动跳过一个事务。</li>\n<li>通过设置slave_skip_errors参数，直接设置跳过指定的错误。</li>\n</ul>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"基于GTID的主备切换\"><a href=\"#基于GTID的主备切换\" class=\"headerlink\" title=\"基于GTID的主备切换\"></a><strong>基于GTID的主备切换</strong></h3><p>GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:</p>\n<ol>\n<li>实例B指定主库A’，基于主备协议建立连接。</li>\n<li>实例B把set_b发给主库A’。</li>\n<li>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。<br>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；<br>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</li>\n<li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。</li>\n</ol>\n<h2 id=\"过期读\"><a href=\"#过期读\" class=\"headerlink\" title=\"过期读\"></a>过期读</h2><p>问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。</p>\n<h3 id=\"强制走主库方案\"><a href=\"#强制走主库方案\" class=\"headerlink\" title=\"强制走主库方案\"></a><strong>强制走主库方案</strong></h3><ol>\n<li>对于必须要拿到最新结果的请求，强制将其发到主库上</li>\n<li>对于可以读到旧数据的请求，才将其发到从库上。</li>\n</ol>\n<h3 id=\"sleep方案\"><a href=\"#sleep方案\" class=\"headerlink\" title=\"sleep方案\"></a><strong>sleep方案</strong></h3><p>大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条<code>select sleep(1)</code>命令。</p>\n<p>以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。</p>\n<p><strong>缺点</strong></p>\n<ol>\n<li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</li>\n<li>如果延迟超过1秒，还是会出现过期读。</li>\n</ol>\n<h3 id=\"判断主备无延迟方案\"><a href=\"#判断主备无延迟方案\" class=\"headerlink\" title=\"判断主备无延迟方案\"></a><strong>判断主备无延迟方案</strong></h3><ul>\n<li><p>第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。</p>\n</li>\n<li><p>第二种方法，对比位点确保主备无延迟（show slave status）：<br>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；<br>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。<br>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成</p>\n</li>\n<li><p>第三种方法，对比GTID集合确保主备无延迟（show slave status）：</p>\n<p>Auto_Position=1 ，表示这对主备关系使用了GTID协议。<br>Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；<br>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。</p>\n<p>缺点：仍可能过期读。备库收到的日志都执行完成了。还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p>\n</li>\n</ul>\n<h3 id=\"配合semi-sync方案\"><a href=\"#配合semi-sync方案\" class=\"headerlink\" title=\"配合semi-sync方案\"></a><strong>配合semi-sync方案</strong></h3><p>引入半同步复制，配合前面关于位点的判断。</p>\n<blockquote>\n<p>在一主多从场景中，如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</p>\n<p>在持续延迟的情况下，可能出现过度等待的问题。</p>\n</blockquote>\n<h3 id=\"等主库位点方案\"><a href=\"#等主库位点方案\" class=\"headerlink\" title=\"等主库位点方案\"></a><strong>等主库位点方案</strong></h3><ol>\n<li>trx1事务更新完成后，马上执行<code>show master status</code>得到当前主库执行到的File和Position；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行<code>select master_pos_wait(File, Position, 1)</code>；</li>\n<li>如果返回值是&gt;=0的正整数，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<blockquote>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n</blockquote>\n<h3 id=\"等GTID方案\"><a href=\"#等GTID方案\" class=\"headerlink\" title=\"等GTID方案\"></a><strong>等GTID方案</strong></h3><ol>\n<li>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行 <code>select wait_for_executed_gtid_set(gtid1, 1)</code>；</li>\n<li>如果返回值是0，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<blockquote>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n</blockquote>\n","site":{"data":{"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}],"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]}},"excerpt":"","more":"<h2 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h2><h3 id=\"异步复制\"><a href=\"#异步复制\" class=\"headerlink\" title=\"异步复制\"></a>异步复制</h3><ul>\n<li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li>\n<li>主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）</li>\n<li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li>\n</ul>\n<h3 id=\"半同步复制\"><a href=\"#半同步复制\" class=\"headerlink\" title=\"半同步复制\"></a>半同步复制</h3><ul>\n<li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li>\n<li>主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，<strong>从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功</strong></li>\n<li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li>\n</ul>\n<h2 id=\"主从切换\"><a href=\"#主从切换\" class=\"headerlink\" title=\"主从切换\"></a>主从切换</h2><h3 id=\"可靠性优先策略\"><a href=\"#可靠性优先策略\" class=\"headerlink\" title=\"可靠性优先策略\"></a>可靠性优先策略</h3><ol>\n<li>判断备库的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；</li>\n<li>把主库改成只读状态，把readonly设为true；</li>\n<li>判断备库的seconds_behind_master的值，直到这个值变成0为止；</li>\n<li>把备库改成可读写状态，把readonly 设为false；</li>\n<li>把业务请求切到备库B。</li>\n</ol>\n<blockquote>\n<p>如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。</p>\n</blockquote>\n<h3 id=\"可用性优先策略\"><a href=\"#可用性优先策略\" class=\"headerlink\" title=\"可用性优先策略\"></a>可用性优先策略</h3><p>不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。</p>\n<blockquote>\n<p>可能出现不一致的数据。</p>\n<p>设置binlog_format=row，会出现duplicate key error并停止；</p>\n<p>使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了</p>\n</blockquote>\n<h2 id=\"备库并行复制策略\"><a href=\"#备库并行复制策略\" class=\"headerlink\" title=\"备库并行复制策略\"></a>备库并行复制策略</h2><h3 id=\"按库并行\"><a href=\"#按库并行\" class=\"headerlink\" title=\"按库并行\"></a>按库并行</h3><p>用于决定分发策略的hash表里，key就是数据库名。</p>\n<blockquote>\n<p>如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；</p>\n<p>或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。</p>\n</blockquote>\n<h3 id=\"MariaDB的并行复制策略\"><a href=\"#MariaDB的并行复制策略\" class=\"headerlink\" title=\"MariaDB的并行复制策略\"></a>MariaDB的并行复制策略</h3><blockquote>\n<p>利用redo log组提交特性：</p>\n<ul>\n<li><p>能够在同一组里提交的事务，一定不会修改同一行；</p>\n</li>\n<li><p>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</p>\n</li>\n</ul>\n</blockquote>\n<p>实现方法</p>\n<ol>\n<li>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；</li>\n<li>commit_id直接写到binlog里面；</li>\n<li>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；</li>\n<li>这一组全部执行完成后，coordinator再去取下一批。</li>\n</ol>\n<h3 id=\"MySQL-5-7-22的新增并行复制策略\"><a href=\"#MySQL-5-7-22的新增并行复制策略\" class=\"headerlink\" title=\"MySQL 5.7.22的新增并行复制策略\"></a>MySQL 5.7.22的新增并行复制策略</h3><p>基于WRITESET的并行复制。</p>\n<p>参数<code>binlog-transaction-dependency-tracking</code>，用来控制是否启用这个新策略。这个参数的可选值有以下三种。</p>\n<ol>\n<li>COMMIT_ORDER，根据同时进入prepare和commit来判断是否可以并行的策略。</li>\n<li>WRITESET，表示的是对于事务涉及更新的每一行，计算出它的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。</li>\n<li>WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li>\n</ol>\n<h2 id=\"主从延迟\"><a href=\"#主从延迟\" class=\"headerlink\" title=\"主从延迟\"></a>主从延迟</h2><h3 id=\"可能原因\"><a href=\"#可能原因\" class=\"headerlink\" title=\"可能原因\"></a>可能原因</h3><ul>\n<li>大表 DDL</li>\n<li>大事务</li>\n<li>主库 DML 并发大</li>\n<li>从库配置差</li>\n</ul>\n<h3 id=\"判断主从延迟\"><a href=\"#判断主从延迟\" class=\"headerlink\" title=\"判断主从延迟\"></a>判断主从延迟</h3><p>1、判断 Seconds_Behind_Master 是否等于 0。</p>\n<p>2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。</p>\n<p>3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。</p>\n<h2 id=\"主备切换\"><a href=\"#主备切换\" class=\"headerlink\" title=\"主备切换\"></a>主备切换</h2><h3 id=\"基于位点的主备切换\"><a href=\"#基于位点的主备切换\" class=\"headerlink\" title=\"基于位点的主备切换\"></a><strong>基于位点的主备切换</strong></h3><p>考虑到切换过程中不能丢数据，所以找位点时，找一个“稍微往前”的。再通过判断，跳过那些在从库上已经执行过的事务。</p>\n<p>通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。</p>\n<ul>\n<li>主动跳过一个事务。</li>\n<li>通过设置slave_skip_errors参数，直接设置跳过指定的错误。</li>\n</ul>\n<pre><code class=\"mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos</code></pre>\n<h3 id=\"基于GTID的主备切换\"><a href=\"#基于GTID的主备切换\" class=\"headerlink\" title=\"基于GTID的主备切换\"></a><strong>基于GTID的主备切换</strong></h3><p>GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。</p>\n<pre><code class=\"mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1</code></pre>\n<p>主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:</p>\n<ol>\n<li>实例B指定主库A’，基于主备协议建立连接。</li>\n<li>实例B把set_b发给主库A’。</li>\n<li>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。<br>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；<br>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</li>\n<li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。</li>\n</ol>\n<h2 id=\"过期读\"><a href=\"#过期读\" class=\"headerlink\" title=\"过期读\"></a>过期读</h2><p>问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。</p>\n<h3 id=\"强制走主库方案\"><a href=\"#强制走主库方案\" class=\"headerlink\" title=\"强制走主库方案\"></a><strong>强制走主库方案</strong></h3><ol>\n<li>对于必须要拿到最新结果的请求，强制将其发到主库上</li>\n<li>对于可以读到旧数据的请求，才将其发到从库上。</li>\n</ol>\n<h3 id=\"sleep方案\"><a href=\"#sleep方案\" class=\"headerlink\" title=\"sleep方案\"></a><strong>sleep方案</strong></h3><p>大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条<code>select sleep(1)</code>命令。</p>\n<p>以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。</p>\n<p><strong>缺点</strong></p>\n<ol>\n<li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</li>\n<li>如果延迟超过1秒，还是会出现过期读。</li>\n</ol>\n<h3 id=\"判断主备无延迟方案\"><a href=\"#判断主备无延迟方案\" class=\"headerlink\" title=\"判断主备无延迟方案\"></a><strong>判断主备无延迟方案</strong></h3><ul>\n<li><p>第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。</p>\n</li>\n<li><p>第二种方法，对比位点确保主备无延迟（show slave status）：<br>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；<br>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。<br>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成</p>\n</li>\n<li><p>第三种方法，对比GTID集合确保主备无延迟（show slave status）：</p>\n<p>Auto_Position=1 ，表示这对主备关系使用了GTID协议。<br>Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；<br>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。</p>\n<p>缺点：仍可能过期读。备库收到的日志都执行完成了。还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p>\n</li>\n</ul>\n<h3 id=\"配合semi-sync方案\"><a href=\"#配合semi-sync方案\" class=\"headerlink\" title=\"配合semi-sync方案\"></a><strong>配合semi-sync方案</strong></h3><p>引入半同步复制，配合前面关于位点的判断。</p>\n<blockquote>\n<p>在一主多从场景中，如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</p>\n<p>在持续延迟的情况下，可能出现过度等待的问题。</p>\n</blockquote>\n<h3 id=\"等主库位点方案\"><a href=\"#等主库位点方案\" class=\"headerlink\" title=\"等主库位点方案\"></a><strong>等主库位点方案</strong></h3><ol>\n<li>trx1事务更新完成后，马上执行<code>show master status</code>得到当前主库执行到的File和Position；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行<code>select master_pos_wait(File, Position, 1)</code>；</li>\n<li>如果返回值是&gt;=0的正整数，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<blockquote>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n</blockquote>\n<h3 id=\"等GTID方案\"><a href=\"#等GTID方案\" class=\"headerlink\" title=\"等GTID方案\"></a><strong>等GTID方案</strong></h3><ol>\n<li>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行 <code>select wait_for_executed_gtid_set(gtid1, 1)</code>；</li>\n<li>如果返回值是0，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<blockquote>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n</blockquote>\n"}],"PostAsset":[{"_id":"source/_posts/redis主从同步/duxiefenli.jpg","slug":"duxiefenli.jpg","post":"ckowss732003vq4uf058ujs3d","modified":1,"renderable":0},{"_id":"source/_posts/kafka认证/compare.jpg","slug":"compare.jpg","post":"ckowss6ob0019q4uf7x7kf8wm","modified":1,"renderable":0},{"_id":"source/_posts/rabbitmq概念/moxin.png","slug":"moxin.png","post":"ckowss70j0033q4ufejdlwyys","modified":1,"renderable":0},{"_id":"source/_posts/KafkaAdminClient/yuanli.jpg","slug":"yuanli.jpg","post":"ckowss6kf0002q4ufroc7dwge","modified":1,"renderable":0},{"_id":"source/_posts/kafka思维导图/kafka.png","slug":"kafka.png","post":"ckowss6m1000iq4uf7etfdn6x","modified":1,"renderable":0},{"_id":"source/_posts/kafka-Broker请求处理/reactor.jpg","slug":"reactor.jpg","post":"ckowss6ld000bq4ufmtghgzb4","modified":1,"renderable":0},{"_id":"source/_posts/kafka-Broker请求处理/work.jpg","slug":"work.jpg","post":"ckowss6ld000bq4ufmtghgzb4","modified":1,"renderable":0},{"_id":"source/_posts/Kafka控制器/Failover.jpg","slug":"Failover.jpg","post":"ckowss6mi000lq4ufecnel9ts","modified":1,"renderable":0},{"_id":"source/_posts/Kafka控制器/data.jpg","slug":"data.jpg","post":"ckowss6mi000lq4ufecnel9ts","modified":1,"renderable":0},{"_id":"source/_posts/Kafka控制器/zookeeper.jpg","slug":"zookeeper.jpg","post":"ckowss6mi000lq4ufecnel9ts","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/compare.jpg","slug":"compare.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/comsumedown.jpg","slug":"comsumedown.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/groups_shell.png","post":"ckowss6ny0013q4uf2y8staid","slug":"groups_shell.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka消费者/leavegroup.jpg","slug":"leavegroup.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/newadd.jpg","slug":"newadd.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/plan1.jpg","slug":"plan1.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/plan2.jpg","slug":"plan2.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/state.jpeg","post":"ckowss6ny0013q4uf2y8staid","slug":"state.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/kafka消费者/stragey.jpg","slug":"stragey.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/transport.jpg","slug":"transport.jpg","post":"ckowss6ny0013q4uf2y8staid","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/water.jpg","slug":"water.jpg","post":"ckowss6va0020q4ufb8mssjuj","modified":1,"renderable":0},{"_id":"source/_posts/kafka集群配置/atoconfig.png","post":"ckowss6ud001sq4uf22cr7xrv","slug":"atoconfig.png","modified":1,"renderable":1},{"_id":"source/_posts/rabbitmq思维导图/rabbitmq.png","slug":"rabbitmq.png","post":"ckowss6wq002lq4ufhxybvkwe","modified":1,"renderable":0},{"_id":"source/_posts/redis-AOF机制/aof.jpg","slug":"aof.jpg","post":"ckowss71r003iq4ufm2ywgqnn","modified":1,"renderable":0},{"_id":"source/_posts/redis-RDB机制/rdb.jpg","slug":"rdb.jpg","post":"ckowss724003lq4ufhw7z5tft","modified":1,"renderable":0},{"_id":"source/_posts/redis6-0/acl_cmd.jpg","slug":"acl_cmd.jpg","post":"ckowss72g003qq4ufnlpy3ae8","modified":1,"renderable":0},{"_id":"source/_posts/redis思维导图/redis.png","slug":"redis.png","post":"ckowss74d004gq4ufwtm3qgp4","modified":1,"renderable":0},{"_id":"source/_posts/redis消息队列/stream.jpg","post":"ckowss75b004sq4ufmuy0w5uk","slug":"stream.jpg","modified":1,"renderable":1},{"_id":"source/_posts/sort-algorithms/1.png","post":"ckowss77w005jq4uf41b0lo0e","slug":"1.png","modified":1,"renderable":1},{"_id":"source/_posts/redis缓存/buyizhi.jpg","slug":"buyizhi.jpg","post":"ckowss75r004vq4ufxdh5cguj","modified":1,"renderable":0},{"_id":"source/_posts/redis缓存/buyizhi2.jpg","slug":"buyizhi2.jpg","post":"ckowss75r004vq4ufxdh5cguj","modified":1,"renderable":0},{"_id":"source/_posts/redis主从同步/master_slave_slave.jpg","slug":"master_slave_slave.jpg","post":"ckowss732003vq4uf058ujs3d","modified":1,"renderable":0},{"_id":"source/_posts/redis主从同步/zhucongtongbu.jpg","slug":"zhucongtongbu.jpg","post":"ckowss732003vq4uf058ujs3d","modified":1,"renderable":0},{"_id":"source/_posts/网络/baowen.jpg","post":"ckowss78l0063q4ufko4xot53","slug":"baowen.jpg","modified":1,"renderable":1},{"_id":"source/_posts/网络/huishou.jpg","post":"ckowss78l0063q4ufko4xot53","slug":"huishou.jpg","modified":1,"renderable":1},{"_id":"source/_posts/网络/woshou.jpg","post":"ckowss78l0063q4ufko4xot53","slug":"woshou.jpg","modified":1,"renderable":1},{"_id":"source/_posts/kafka高水位和Leader-Epoch/bad.jpg","slug":"bad.jpg","post":"ckowss6va0020q4ufb8mssjuj","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/good.jpg","slug":"good.jpg","post":"ckowss6va0020q4ufb8mssjuj","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/watertime.jpg","slug":"watertime.jpg","post":"ckowss6va0020q4ufb8mssjuj","modified":1,"renderable":0}],"PostCategory":[{"post_id":"ckowss6ky0006q4ufed5z7qnj","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6lu000eq4ufhbszxy8k"},{"post_id":"ckowss6ju0001q4ufbxsegzv1","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6m8000jq4uf9nn5i4o5"},{"post_id":"ckowss6l30007q4ufwc0flyy8","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6ml000mq4uf40lbeo7r"},{"post_id":"ckowss6ld000bq4ufmtghgzb4","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6n1000pq4ufdbkh16rs"},{"post_id":"ckowss6kf0002q4ufroc7dwge","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6n9000sq4ufttnaok2r"},{"post_id":"ckowss6lm000dq4ufl44kt2pz","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6ni000vq4ufx3vziku1"},{"post_id":"ckowss6m1000iq4uf7etfdn6x","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6np000yq4ufnkfe489c"},{"post_id":"ckowss6kr0005q4uf5sxz3zf9","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss6nw0011q4uf48yb1fp6"},{"post_id":"ckowss6mi000lq4ufecnel9ts","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6o40014q4ufs6d2slk6"},{"post_id":"ckowss6mu000oq4ufhwj95egj","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6o90017q4ufnsf8vavb"},{"post_id":"ckowss6n5000rq4ufbe04kcd9","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6oh001aq4ufn9rbupsh"},{"post_id":"ckowss6nf000uq4ufl288qzu0","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6on001dq4ufjvnxss9w"},{"post_id":"ckowss6nn000xq4ufraqzm32h","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6ox001gq4ufj6m4nqha"},{"post_id":"ckowss6nt0010q4uffy4kz589","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6p2001iq4uf8a4l4btw"},{"post_id":"ckowss6ny0013q4uf2y8staid","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6p5001kq4uf2l2g112a"},{"post_id":"ckowss6o70016q4uf4w4bnhqv","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6p7001mq4uftg9nu2xj"},{"post_id":"ckowss6ob0019q4uf7x7kf8wm","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6p9001oq4ufnsbxqymf"},{"post_id":"ckowss6ol001cq4uf03z6bdkh","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6pa001qq4ufk4gzfq1w"},{"post_id":"ckowss6or001fq4ufh5g5is60","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6pb001rq4ufaewr1fl6"},{"post_id":"ckowss6ud001sq4uf22cr7xrv","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6vc0021q4ufm4494auu"},{"post_id":"ckowss6uj001uq4uf2kip4udp","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6vm0025q4ufy8s2ebj0"},{"post_id":"ckowss6v0001xq4ufvjotaaxd","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6vv0029q4ufx8djsr1g"},{"post_id":"ckowss6va0020q4ufb8mssjuj","category_id":"ckowss6l60008q4ufofkp6zzw","_id":"ckowss6w9002dq4ufw9lhgo4y"},{"post_id":"ckowss6vk0024q4ufxgaq4uay","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss6wj002gq4ufaq37wgq8"},{"post_id":"ckowss6vs0028q4ufkxdopd6s","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6wo002jq4ufxvw5hvfm"},{"post_id":"ckowss6w5002cq4uff8ni5v6c","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6ws002mq4uf8e0uw3hs"},{"post_id":"ckowss6wb002fq4uf6l4fgh18","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6x7002pq4uf9c9t5w5m"},{"post_id":"ckowss6wm002iq4ufxuaapxqp","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss6xt002tq4ufwui1odnx"},{"post_id":"ckowss6x3002oq4ufmivveoap","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss6ye002xq4ufct761ga2"},{"post_id":"ckowss6xw002vq4ufqj6x75zf","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss70n0034q4ufraq35m1a"},{"post_id":"ckowss6wq002lq4ufhxybvkwe","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss70w0037q4ufpzjx74iv"},{"post_id":"ckowss6yc002wq4uf2anf2fbd","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss713003aq4ufz6m1d0q7"},{"post_id":"ckowss70e0031q4uf682jz9xz","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss71d003dq4ufewgjygen"},{"post_id":"ckowss6xd002sq4ufkxy6hiyo","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss71l003gq4ufvnq049lm"},{"post_id":"ckowss70j0033q4ufejdlwyys","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss720003jq4ufkzs3cwch"},{"post_id":"ckowss70t0036q4ufpr3av5ob","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss727003mq4uf26du3l49"},{"post_id":"ckowss70z0039q4uf7cza5zfy","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss72m003rq4ufiyraokzs"},{"post_id":"ckowss718003cq4ufefotz4iy","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss72r003uq4ufvgzdz5ue"},{"post_id":"ckowss71h003fq4ufvzdca6wb","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss736003yq4ufnlb9i5xn"},{"post_id":"ckowss71r003iq4ufm2ywgqnn","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss73g0044q4ufynf7dv7x"},{"post_id":"ckowss732003vq4uf058ujs3d","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss73j0048q4ufyi0q0oel"},{"post_id":"ckowss7390040q4uf32n48f1q","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss73p004bq4ufjj401d15"},{"post_id":"ckowss724003lq4ufhw7z5tft","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss741004eq4ufk3girzdo"},{"post_id":"ckowss73e0042q4uf7erq69ao","category_id":"ckowss6xa002qq4ufnwgp5wbq","_id":"ckowss74o004hq4ufx3eyt7yx"},{"post_id":"ckowss73i0047q4ufjhvl11yc","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss74v004kq4ufk8a4r0ow"},{"post_id":"ckowss72g003qq4ufnlpy3ae8","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss752004nq4ufchtpu447"},{"post_id":"ckowss73l004aq4ufdleym3rg","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss758004qq4uftik62nns"},{"post_id":"ckowss73q004dq4uf7d4txn4p","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss75j004tq4uf1a5gafw4"},{"post_id":"ckowss74d004gq4ufwtm3qgp4","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss75v004wq4ufly5fontd"},{"post_id":"ckowss74r004jq4ufahgdz7hv","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss765004zq4ufbh83tiuh"},{"post_id":"ckowss74z004mq4ufvogr0npv","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss76e0052q4ufo77jk1sd"},{"post_id":"ckowss755004pq4ufvqzbbk2s","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss76n0055q4uf5gfsl7ha"},{"post_id":"ckowss75b004sq4ufmuy0w5uk","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss76t0058q4uf98acka4t"},{"post_id":"ckowss75r004vq4ufxdh5cguj","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss76x005bq4ufzfduegwy"},{"post_id":"ckowss760004yq4uflx6c3hwr","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss777005eq4uft0b5xn03"},{"post_id":"ckowss7690051q4uf501jac2w","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss77t005hq4ufgwsozrw2"},{"post_id":"ckowss76h0054q4ufaal34xod","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss77z005kq4ufl5cstpw1"},{"post_id":"ckowss76q0057q4ufxt3s9f1y","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss786005nq4ufv96aegts"},{"post_id":"ckowss76v005aq4uf7es8o8pb","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss78c005sq4ufuvw0cax6"},{"post_id":"ckowss775005dq4uf1lisw9o0","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss78f005vq4ufwrt1udfw"},{"post_id":"ckowss77r005gq4ufsi5k9ljx","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss78h005yq4ufr2d662pm"},{"post_id":"ckowss781005mq4ufgst3z0fd","category_id":"ckowss72b003nq4uf6klybocc","_id":"ckowss78k0061q4ufxrwtvrsl"},{"post_id":"ckowss789005rq4uf2pnbs0u1","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss78m0064q4ufmsvceof9"},{"post_id":"ckowss78e005uq4uf1cx1ownc","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss78o0067q4ufrqy7gj7g"},{"post_id":"ckowss77w005jq4uf41b0lo0e","category_id":"ckowss787005oq4uf6m56iojt","_id":"ckowss78r006aq4ufuu9tne59"},{"post_id":"ckowss78g005xq4ufqne7b7ng","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss78v006dq4ufc8bnxzil"},{"post_id":"ckowss78i0060q4ufadzms2az","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss78z006gq4ufhi6emaio"},{"post_id":"ckowss78l0063q4ufko4xot53","category_id":"ckowss6lv000fq4ufkqwtxhz5","_id":"ckowss791006iq4uf2ijxj1pk"},{"post_id":"ckowss78n0066q4uf2zd7rgd5","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss792006kq4uf0j4w5mro"},{"post_id":"ckowss78p0069q4uf3dz6lvwi","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss794006mq4ufzckzo1qo"},{"post_id":"ckowss78s006cq4ufqh8fquyy","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss796006oq4uf3ljzk9fs"},{"post_id":"ckowss78x006fq4ufehdtx013","category_id":"ckowss6kk0003q4ufl0haowgf","_id":"ckowss796006pq4uf42b3u8qk"}],"PostTag":[{"post_id":"ckowss6ky0006q4ufed5z7qnj","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6lc000aq4ufjs1gxumu"},{"post_id":"ckowss6ju0001q4ufbxsegzv1","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6lj000cq4uf7y517b6g"},{"post_id":"ckowss6l30007q4ufwc0flyy8","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6ly000hq4ufvy7bgc67"},{"post_id":"ckowss6ld000bq4ufmtghgzb4","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6mg000kq4uf6cb1j5pf"},{"post_id":"ckowss6kf0002q4ufroc7dwge","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6mt000nq4ufjtejj1sg"},{"post_id":"ckowss6lm000dq4ufl44kt2pz","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6n3000qq4uf0lkfe5pc"},{"post_id":"ckowss6m1000iq4uf7etfdn6x","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6nd000tq4ufyuj9pjxm"},{"post_id":"ckowss6kr0005q4uf5sxz3zf9","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss6nm000wq4uf494e5vo3"},{"post_id":"ckowss6mi000lq4ufecnel9ts","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6nr000zq4uf9s8rtqpv"},{"post_id":"ckowss6mu000oq4ufhwj95egj","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6nx0012q4ufcjhne976"},{"post_id":"ckowss6n5000rq4ufbe04kcd9","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6o60015q4uftyr463tk"},{"post_id":"ckowss6nf000uq4ufl288qzu0","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6oa0018q4ufmft1wmbb"},{"post_id":"ckowss6nn000xq4ufraqzm32h","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6oj001bq4ufv2vi0u1e"},{"post_id":"ckowss6nt0010q4uffy4kz589","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6op001eq4ufv6fhts17"},{"post_id":"ckowss6ny0013q4uf2y8staid","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6oz001hq4ufv9qgukja"},{"post_id":"ckowss6o70016q4uf4w4bnhqv","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6p3001jq4ufskr6s4e9"},{"post_id":"ckowss6ob0019q4uf7x7kf8wm","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6p6001lq4uf3jtwu3ue"},{"post_id":"ckowss6ol001cq4uf03z6bdkh","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6p8001nq4ufyxc7dtk4"},{"post_id":"ckowss6or001fq4ufh5g5is60","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6pa001pq4ufx8k6g2cq"},{"post_id":"ckowss6ud001sq4uf22cr7xrv","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6uz001wq4ufmd0j6yoy"},{"post_id":"ckowss6uj001uq4uf2kip4udp","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6v9001zq4ufnotl2cjd"},{"post_id":"ckowss6v0001xq4ufvjotaaxd","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6vj0023q4uf43exl05z"},{"post_id":"ckowss6va0020q4ufb8mssjuj","tag_id":"ckowss6l70009q4uf462up2gb","_id":"ckowss6vr0027q4ufaotzjgg6"},{"post_id":"ckowss6vk0024q4ufxgaq4uay","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss6w4002bq4uf8w4fxzj4"},{"post_id":"ckowss6vs0028q4ufkxdopd6s","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6wa002eq4ufibxb0lun"},{"post_id":"ckowss6w5002cq4uff8ni5v6c","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6wl002hq4ufmf0upeb5"},{"post_id":"ckowss6wb002fq4uf6l4fgh18","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6wp002kq4ufcalstitm"},{"post_id":"ckowss6wm002iq4ufxuaapxqp","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss6x2002nq4uflpydtptg"},{"post_id":"ckowss6x3002oq4ufmivveoap","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss6xv002uq4ufdfztfm6l"},{"post_id":"ckowss6xw002vq4ufqj6x75zf","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss70d0030q4uf8uggwj20"},{"post_id":"ckowss6wq002lq4ufhxybvkwe","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss70i0032q4ufaiodfj1d"},{"post_id":"ckowss6yc002wq4uf2anf2fbd","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss70r0035q4ufv0artm48"},{"post_id":"ckowss70e0031q4uf682jz9xz","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss70y0038q4ufdpmpozk1"},{"post_id":"ckowss6xd002sq4ufkxy6hiyo","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss717003bq4uf2b7yicaa"},{"post_id":"ckowss70j0033q4ufejdlwyys","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss71e003eq4ufn5rv4pa6"},{"post_id":"ckowss70t0036q4ufpr3av5ob","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss71o003hq4uf10cbvuje"},{"post_id":"ckowss70z0039q4uf7cza5zfy","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss723003kq4uf88cc0150"},{"post_id":"ckowss718003cq4ufefotz4iy","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss72e003pq4ufqd1savy4"},{"post_id":"ckowss71h003fq4ufvzdca6wb","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss72n003sq4ufeh0l7ejm"},{"post_id":"ckowss71r003iq4ufm2ywgqnn","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss739003zq4ufahpo8oup"},{"post_id":"ckowss732003vq4uf058ujs3d","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss73d0041q4uf3g1bb8qo"},{"post_id":"ckowss7390040q4uf32n48f1q","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss73i0046q4ufqulsivd6"},{"post_id":"ckowss724003lq4ufhw7z5tft","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss73k0049q4ufd6nr9jm3"},{"post_id":"ckowss73e0042q4uf7erq69ao","tag_id":"ckowss6xb002rq4uf29fe0pqz","_id":"ckowss73q004cq4ufh2fnrkjg"},{"post_id":"ckowss73i0047q4ufjhvl11yc","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss74b004fq4ufuwljq3hh"},{"post_id":"ckowss72g003qq4ufnlpy3ae8","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss74q004iq4ufnlfqv5qn"},{"post_id":"ckowss73l004aq4ufdleym3rg","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss74x004lq4ufc694wqkt"},{"post_id":"ckowss73q004dq4uf7d4txn4p","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss753004oq4uff0bdll58"},{"post_id":"ckowss74d004gq4ufwtm3qgp4","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss75a004rq4ufmii7i1ko"},{"post_id":"ckowss74r004jq4ufahgdz7hv","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss75p004uq4uf4y3mxw0a"},{"post_id":"ckowss74z004mq4ufvogr0npv","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss75x004xq4ufbv9c112h"},{"post_id":"ckowss755004pq4ufvqzbbk2s","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss7680050q4ufbfmlmbrn"},{"post_id":"ckowss75b004sq4ufmuy0w5uk","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss76g0053q4ufuq1gstkx"},{"post_id":"ckowss75r004vq4ufxdh5cguj","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss76p0056q4ufzt8iy35q"},{"post_id":"ckowss760004yq4uflx6c3hwr","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss76u0059q4ufv0w5mqom"},{"post_id":"ckowss7690051q4uf501jac2w","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss770005cq4ufekkorvz4"},{"post_id":"ckowss76h0054q4ufaal34xod","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss77r005fq4ufnddimtkl"},{"post_id":"ckowss76q0057q4ufxt3s9f1y","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss77v005iq4uf21t83q1y"},{"post_id":"ckowss76v005aq4uf7es8o8pb","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss780005lq4ufrwa768ul"},{"post_id":"ckowss775005dq4uf1lisw9o0","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss789005qq4uf2lo9jrsk"},{"post_id":"ckowss77r005gq4ufsi5k9ljx","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss78d005tq4ufgkgm3kml"},{"post_id":"ckowss781005mq4ufgst3z0fd","tag_id":"ckowss72d003oq4ufu8qay71r","_id":"ckowss78g005wq4uf08qjdeal"},{"post_id":"ckowss789005rq4uf2pnbs0u1","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss78i005zq4ufibzi5v9j"},{"post_id":"ckowss78e005uq4uf1cx1ownc","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss78l0062q4ufpusa728p"},{"post_id":"ckowss77w005jq4uf41b0lo0e","tag_id":"ckowss788005pq4ufdhzu9oi3","_id":"ckowss78n0065q4ufuby1qy26"},{"post_id":"ckowss78g005xq4ufqne7b7ng","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss78p0068q4ufiixc959m"},{"post_id":"ckowss78i0060q4ufadzms2az","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss78r006bq4ufghb4wjay"},{"post_id":"ckowss78l0063q4ufko4xot53","tag_id":"ckowss6lw000gq4uf77u1eht8","_id":"ckowss78w006eq4ufhlsv38gt"},{"post_id":"ckowss78n0066q4uf2zd7rgd5","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss790006hq4uf886mslmm"},{"post_id":"ckowss78p0069q4uf3dz6lvwi","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss791006jq4uf6kwdtf35"},{"post_id":"ckowss78s006cq4ufqh8fquyy","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss794006lq4uf6fgb2k67"},{"post_id":"ckowss78x006fq4ufehdtx013","tag_id":"ckowss6kp0004q4ufberz1f9i","_id":"ckowss795006nq4ufdcopb1al"}],"Tag":[{"name":"mysql","_id":"ckowss6kp0004q4ufberz1f9i"},{"name":"kafka","_id":"ckowss6l70009q4uf462up2gb"},{"name":"interview","_id":"ckowss6lw000gq4uf77u1eht8"},{"name":"rabbitmq","_id":"ckowss6xb002rq4uf29fe0pqz"},{"name":"redis","_id":"ckowss72d003oq4ufu8qay71r"},{"name":"算法","_id":"ckowss788005pq4ufdhzu9oi3"}]}}