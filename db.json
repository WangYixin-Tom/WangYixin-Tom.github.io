{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/matery/source/favicon.png","path":"favicon.png","modified":1,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":1,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/logo.png","path":"medias/logo.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","path":"libs/codeBlock/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/explosion.min.js","path":"libs/others/explosion.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/text.js","path":"libs/others/text.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/snow.js","path":"libs/others/snow.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/fireworks.js","path":"libs/others/fireworks.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ajin.jpg","path":"medias/avatars/ajin.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/feibar.jpg","path":"medias/avatars/feibar.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/cww97.jpg","path":"medias/avatars/cww97.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/babyq.png","path":"medias/avatars/babyq.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/hael.jpg","path":"medias/avatars/hael.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/fun4go.png","path":"medias/avatars/fun4go.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/huaji.jpg","path":"medias/avatars/huaji.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/kewlgrl.jpg","path":"medias/avatars/kewlgrl.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ldy.jpg","path":"medias/avatars/ldy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/liyucheng.jpg","path":"medias/avatars/liyucheng.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/liyangzone.jpg","path":"medias/avatars/liyangzone.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lijiaqian.png","path":"medias/avatars/lijiaqian.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mpy634.png","path":"medias/avatars/mpy634.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/michael.jpg","path":"medias/avatars/michael.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/masterx.jpg","path":"medias/avatars/masterx.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mouse.jpg","path":"medias/avatars/mouse.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/taotao.jpg","path":"medias/avatars/taotao.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/sunchangzhi.jpg","path":"medias/avatars/sunchangzhi.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/spacesac.png","path":"medias/avatars/spacesac.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qiqiang.jpg","path":"medias/avatars/qiqiang.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/tawn.jpg","path":"medias/avatars/tawn.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/taowei.jpg","path":"medias/avatars/taowei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhaokangzhe.jpg","path":"medias/avatars/zhaokangzhe.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","path":"libs/jquery/jquery-2.2.0.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/antnlp.ico","path":"medias/avatars/antnlp.ico","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/duyupei.jpg","path":"medias/avatars/duyupei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/gsy.jpg","path":"medias/avatars/gsy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/yezijie.png","path":"medias/avatars/yezijie.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jiejie.jpg","path":"medias/avatars/jiejie.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/hzwer.jpg","path":"medias/avatars/hzwer.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/ids2.jpg","path":"medias/avatars/ids2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/milyyy.jpg","path":"medias/avatars/milyyy.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mizunashi.png","path":"medias/avatars/mizunashi.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qiandongwei.jpg","path":"medias/avatars/qiandongwei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","path":"medias/avatars/myzhihu.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhangting.jpg","path":"medias/avatars/zhangting.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/xuzhongyou.jpg","path":"medias/avatars/xuzhongyou.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/xiejiadong.jpg","path":"medias/avatars/xiejiadong.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","path":"libs/awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","path":"medias/music/avatars/tiantangdemogui.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","path":"medias/music/avatars/yiluxiangbei.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","path":"medias/music/avatars/yequ.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zzw.jpg","path":"medias/avatars/zzw.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/0xbird.png","path":"medias/avatars/0xbird.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lzh.png","path":"medias/avatars/lzh.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/lyn-draw.jpg","path":"medias/avatars/lyn-draw.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/qianqian.png","path":"medias/avatars/qianqian.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/mashiro.jpg","path":"medias/avatars/mashiro.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/28.jpg","path":"medias/featureimages/28.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","path":"libs/awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jitao.jpg","path":"medias/avatars/jitao.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","path":"libs/awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","path":"libs/awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","path":"libs/awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/25.jpg","path":"medias/featureimages/25.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/27.jpg","path":"medias/featureimages/27.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/feibar.png","path":"medias/avatars/feibar.png","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","path":"medias/music/avatars/daoshu.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","path":"libs/awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/zhangyi.jpg","path":"medias/avatars/zhangyi.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/24.jpg","path":"medias/featureimages/24.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/26.jpg","path":"medias/featureimages/26.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/jingjing.jpg","path":"medias/avatars/jingjing.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatars/myphoto.jpg","path":"medias/avatars/myphoto.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","path":"libs/awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/404.md","hash":"d97f69ff63501de89cfd341c68e4d6ed5c8a5b3a","modified":1586000622000},{"_id":"themes/matery/.gitignore","hash":"eaa3d84cb77d92a21b111fd1e37f53edc1ff9de0","modified":1586000622000},{"_id":"themes/matery/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1586000622000},{"_id":"themes/matery/README.md","hash":"7ef16198a2c5ff580f006582286354caf160c7fe","modified":1586000622000},{"_id":"themes/matery/README_CN.md","hash":"a94324950e0299bcfcbc106cf2ca65c93e1fe843","modified":1586000622000},{"_id":"themes/matery/_config.yml","hash":"ae89fade84450b8ab59b50c35776152a126358dd","modified":1617318110207},{"_id":"source/_posts/InnoDB-LRU-优化.md","hash":"5689718035fc24cdccaf95868c1f1b2496011c32","modified":1617318109586},{"_id":"source/_posts/KafkaAdminClient.md","hash":"02846459b13fd6ec50782753dada61304ff03386","modified":1617369179201},{"_id":"source/_posts/Kafka控制器.md","hash":"0147b921f85a1cd294f1e0791438b50c5352e3c3","modified":1617372108263},{"_id":"source/_posts/MVCC.md","hash":"9ea43a5aa140dfc5ed8571444f3bfdffe36096fb","modified":1617318109656},{"_id":"source/_posts/count优化.md","hash":"bbdb758cc52082c1a56353b68885beb279228b78","modified":1617318109666},{"_id":"source/_posts/join优化.md","hash":"54f27c62157fdf7c138a1c26ce68ddf6faa40057","modified":1617318109676},{"_id":"source/_posts/kafka思维导图.md","hash":"0d545b23c5fa82e1955c11f16d0bf871e056b8d0","modified":1617369689499},{"_id":"source/_posts/kafka-Broker请求处理.md","hash":"da19aa09377e0b9182a88aeefb8e154a063ce175","modified":1617318109676},{"_id":"source/_posts/kafka主题管理.md","hash":"8a3300750c865730fe4b1c8f355073ca1c3157d7","modified":1617369057097},{"_id":"source/_posts/kafka副本.md","hash":"c864245d7dfaec37e9f51e1f00036e9d707a29a5","modified":1617318109716},{"_id":"source/_posts/kafka拦截器.md","hash":"7a331ee08a3a286a0fa07c24fb4a3f4e176ffcab","modified":1617318109716},{"_id":"source/_posts/kafka授权.md","hash":"6d5c141b699b85b195724e4c2456c4c347004764","modified":1617318109726},{"_id":"source/_posts/kafka消息丢失.md","hash":"5b7809ad23f0d71cdbd6988ef2bf5e2015c81107","modified":1617318109726},{"_id":"source/_posts/kafka生产者.md","hash":"2038558783e6fec6d0ea281c36a5096bb0d78701","modified":1617318109856},{"_id":"source/_posts/kafka消费者.md","hash":"60b95323da80800e9582c17ad1813eef2dd88839","modified":1617318109726},{"_id":"source/_posts/kafka精确一次.md","hash":"f1d5df81ad1aea7e956b61577341ecabec291c53","modified":1617318109856},{"_id":"source/_posts/kafka脚本.md","hash":"53613d6356aa449ee5fad4bf12706f7f84814dd3","modified":1617318109876},{"_id":"source/_posts/kafka面试.md","hash":"a1fc512faa7eda59565f196d7366858feef0428d","modified":1617882922845},{"_id":"source/_posts/kafka认证.md","hash":"d86deed02701dcb74ff454b9bb569e56f9181e60","modified":1617371185827},{"_id":"source/_posts/mysql思维导图.md","hash":"70b86f9dd9047515f01a82f6e32f4895589008d5","modified":1617370199029},{"_id":"source/_posts/kafka调优.md","hash":"63537ddfa42511ae6ff804d1af61ad01c86233f8","modified":1617369377846},{"_id":"source/_posts/kafka集群配置.md","hash":"67f86fa6941f79143ce929665d39b5075db17802","modified":1617318109926},{"_id":"source/_posts/rabbitmq思维导图.md","hash":"772cce03cda1e49674d981fe4e4f66572ecb6f21","modified":1617519585233},{"_id":"source/_posts/rabbitmq概念.md","hash":"244c9956af34f15e494ebffa03843976d00241a5","modified":1617585745696},{"_id":"source/_posts/kafka高水位和Leader-Epoch.md","hash":"7db37808727b5d40f16264d43e9c08bd3682229d","modified":1617320316364},{"_id":"source/_posts/rabbitmq客户端开发.md","hash":"78540047e8d6fcdf5b8d370452b724de879de509","modified":1617456623423},{"_id":"source/_posts/order-group-by优化.md","hash":"dac21a93bb20e077667a1f675de44be3405899a6","modified":1617318109986},{"_id":"source/_posts/rabbitmq消息可靠性.md","hash":"8ae066221a2ce921c52a50c3f1adae14c0a8254f","modified":1617318109986},{"_id":"source/_posts/rabbitmq消息发布.md","hash":"e4a1986f26a4c455f3fd755eff0aa2ce26a494e5","modified":1617318109986},{"_id":"source/_posts/rabbitmq消息消费.md","hash":"72eeaccf57f5e4792542d59a8ea18dabe691aa8c","modified":1617318109986},{"_id":"source/_posts/rabbitmq面试.md","hash":"5d03d4fd856ced0cdba5c90aaafcf15a5616aa6f","modified":1617882950903},{"_id":"source/_posts/rabbitmq消息路由.md","hash":"6e05992bed1999acaf80b6f2b67c362fc1916b86","modified":1617318109986},{"_id":"source/_posts/rabbitmq消息重复.md","hash":"c4ce418e68fe93c5b1ae94f9392c1667dd234ffe","modified":1617318109986},{"_id":"source/_posts/redis-RDB机制.md","hash":"d271486d072383d1669d204afb3c0e95b457609d","modified":1617318109986},{"_id":"source/_posts/rabbitmq集群.md","hash":"3aade54627ab1f19ec09691072cb5397da84266b","modified":1617318109986},{"_id":"source/_posts/redis-AOF机制.md","hash":"613801a44a457f4e42aa395fd2a62ecc5c8e9e29","modified":1617318109986},{"_id":"source/_posts/rabbitmq进阶.md","hash":"99a3f8be23fafb46dee89ba32c40ee71390cb99b","modified":1617512526522},{"_id":"source/_posts/redis6-0.md","hash":"f953d03a626bb6ea2fd953d4aaee9edcc3a49b74","modified":1617318109986},{"_id":"source/_posts/redis事务.md","hash":"4e9d882f2cc47923390e9aefc13601afe1a8906f","modified":1617318110047},{"_id":"source/_posts/redis内存碎片.md","hash":"0e6c54f4ffb18a372f0d3f100734564a096be3bd","modified":1617318110047},{"_id":"source/_posts/redis切片集群.md","hash":"496d1bd7166c758c8056f200e01ac2cdd35c11fd","modified":1617318110047},{"_id":"source/_posts/redis主从同步.md","hash":"1416d1f9a97c56700cd7ccadbd06d7c941d553d3","modified":1617318110016},{"_id":"source/_posts/redis分布式锁.md","hash":"3f03c283635e3e7fec4d123393ac73534193a461","modified":1617318110047},{"_id":"source/_posts/redis哨兵机制.md","hash":"e1bbfa47cd918fa0fb6ef78ddfe0763e6b23c222","modified":1617318110047},{"_id":"source/_posts/redis变慢以及优化方法.md","hash":"e223b9704c5436c2821fde7e906685a506cffe87","modified":1617318110047},{"_id":"source/_posts/redis思维导图.md","hash":"0f88b7f4b4c0977076244faca5945c9374e98691","modified":1617369745489},{"_id":"source/_posts/redis数据结构.md","hash":"38c930d471b5a53462b38b121e683be9b23f13ce","modified":1617318110077},{"_id":"source/_posts/redis应用.md","hash":"2a16a3568a8b58ed37fbfa0c52d6622b30857529","modified":1617318110047},{"_id":"source/_posts/redis消息队列.md","hash":"5a06a9bfee79825822c46c744417547fb84533fb","modified":1617318110077},{"_id":"source/_posts/redis缓存.md","hash":"48bcb80f6d458bc241e99eab0231c06c464efe84","modified":1617318110097},{"_id":"source/_posts/redis网络IO模型.md","hash":"dcafef778f31bce6234b04f4fa195ef8304db14f","modified":1617318110117},{"_id":"source/_posts/redis阻塞及解决办法.md","hash":"0e712363517ef8a93ac9bec3323b1b0880a60e74","modified":1617318110117},{"_id":"source/_posts/事务.md","hash":"d3d419fbd087f5ff4c70d6d886bed31d42eeb01e","modified":1617318110137},{"_id":"source/_posts/分库分表.md","hash":"aceb2a10143e62c127cc328ab29cb2bb6109da4b","modified":1617318110137},{"_id":"source/_posts/分页查询优化.md","hash":"f0808acfb2a74e2b156154b1367fa5ee746d0f73","modified":1617318110137},{"_id":"source/_posts/基于多CPU多核架构的redis性能优化.md","hash":"23a3ed9399e007f4d336a0eb0e35e02943955229","modified":1617318110137},{"_id":"source/_posts/sort-algorithms.md","hash":"d0672536d3f6e8ff8d3d3a39a470d6e60343ac65","modified":1617318110127},{"_id":"source/_posts/慢查询定位与分析.md","hash":"bd7b033f5cea7e19f89e79de2471cf452c3705b8","modified":1617318110177},{"_id":"source/_posts/基础架构.md","hash":"9d61c644862252ff4ce7076946cc2661dc171e9c","modified":1617318110157},{"_id":"source/_posts/批量数据导入优化.md","hash":"87d9a9a34a05c48e47cac3ddb44e89abf51f968f","modified":1617318110177},{"_id":"source/_posts/数据恢复.md","hash":"3437f62876273d44d2f05e8af6c8e1e3cc6b7481","modified":1617318110177},{"_id":"source/_posts/操作规范.md","hash":"308ecfb8d1434c84c8db2ce3923218d1d30c7448","modified":1617318110177},{"_id":"source/_posts/索引.md","hash":"b1763cff22d038e4e5e5ed9b13d9c3afd48d6f79","modified":1617318110177},{"_id":"source/_posts/读写分离.md","hash":"8ab14997bc1005fe91f7a2c46ad9fc98bf58963c","modified":1617318110197},{"_id":"source/_posts/索引失效.md","hash":"b788f033fa88340cdb906d01fd56a022ed29fc7e","modified":1617318110177},{"_id":"source/_posts/锁.md","hash":"9559fcc51ce56dc3061b3afab8f54498475be900","modified":1617318110197},{"_id":"source/_data/musics.json","hash":"32bc061f34721b4ff55f880de1d0ec5787acd2f9","modified":1586000622000},{"_id":"source/archives/index.md","hash":"30a0e3a59be650ae34d7bb86ac7da53e21e9cf5b","modified":1586000622000},{"_id":"source/contact/index.md","hash":"19978439f7c1d202d1a792f687604642936fffe1","modified":1617318110207},{"_id":"source/categories/index.md","hash":"67687d3f908737f7c680f096b3e80d9412f23b0e","modified":1586000622000},{"_id":"source/about/index.md","hash":"a4ad6be6bdba3debe7108373729bc6ebdd405091","modified":1617318110207},{"_id":"source/tags/index.md","hash":"fe3d7ecc91b81b062a6a60c06859dc24b9d704ac","modified":1586000622000},{"_id":"source/friends/index.md","hash":"6cedb9ebc46ecbcf44f1ccdb8c0c6d74f265ed08","modified":1617318110207},{"_id":"source/_data/friends.json","hash":"c43c4d3a74db36e032cf2e7f7490c5d4d34e9210","modified":1617318109586},{"_id":"themes/matery/languages/default.yml","hash":"527c795b8c41fe62bf35603ffebfa6d4a7929a2c","modified":1586000622000},{"_id":"themes/matery/languages/zh-CN.yml","hash":"d92db4b986bb6f0d228e9a8249383103bf56342d","modified":1586000622000},{"_id":"themes/matery/source/favicon.png","hash":"979ccca1f7334916e1407716ef8a79736997535a","modified":1617318110218},{"_id":"themes/matery/layout/404.ejs","hash":"f08a0f507b36f3652520a41381f71167488405c7","modified":1586000622000},{"_id":"themes/matery/layout/about.ejs","hash":"e87752e59f021b5139b1155a264da11ab469a9aa","modified":1586000622000},{"_id":"themes/matery/layout/categories.ejs","hash":"c431e772d0f7700592228bbd9502793bdc28a893","modified":1586000622000},{"_id":"themes/matery/layout/archive.ejs","hash":"1b5023571894404d75caffa28128fc9c49f9095d","modified":1586000622000},{"_id":"themes/matery/layout/contact.ejs","hash":"1513c5a40b7cc0b6e5854cf8c3253958bcb486cb","modified":1586000622000},{"_id":"themes/matery/layout/category.ejs","hash":"2d421e10c3b8fd2c4f725e5eaa967c4a1429c707","modified":1586000622000},{"_id":"themes/matery/layout/friends.ejs","hash":"895e40a864796680fbef581e4b09f252fbdd963a","modified":1586000622000},{"_id":"themes/matery/layout/tags.ejs","hash":"851c0ee599e91e7b1d657673859e8b6ff79cf50b","modified":1586000622000},{"_id":"themes/matery/layout/post.ejs","hash":"f1a35f32e5901e167ae9a750e7cb3635549cea2e","modified":1586000622000},{"_id":"themes/matery/layout/layout.ejs","hash":"2ba4110dc596424b1220a259c8e594da774e7f59","modified":1586000622000},{"_id":"themes/matery/layout/tag.ejs","hash":"5cdf3a1d72f54285ee9cb826fd0e4a0449093215","modified":1586000622000},{"_id":"themes/matery/layout/index.ejs","hash":"7fc5a6c4f0229c0be43b7d1315524c468346fbb8","modified":1586000622000},{"_id":"source/_posts/kafka集群配置/atoconfig.png","hash":"0648ff94d92bc6832ba0e9d96a6af4e51975adfb","modified":1617318109926},{"_id":"source/_posts/redis消息队列/stream.jpg","hash":"8abb860ea69a87d2106c44436c171e93f7a3378b","modified":1617318110087},{"_id":"source/_posts/kafka消费者/groups_shell.png","hash":"2874043395d38ec6050236abeee92317de4438d9","modified":1617318109766},{"_id":"source/_posts/kafka消费者/state.jpeg","hash":"f158aceee4f56f0349c231014f3706bd4dc2c923","modified":1617318109826},{"_id":"themes/matery/source/css/matery.css","hash":"0d345a72318fd7aadcb6fcaa6f3abac94b91001c","modified":1586000622000},{"_id":"themes/matery/source/css/gitment.css","hash":"d5ef623065d1fbc897119f7b70ccf7563e329917","modified":1586000622000},{"_id":"themes/matery/source/css/my.css","hash":"37683a9f11c68903a53e2b8593ca8c095a721896","modified":1586000622000},{"_id":"source/_posts/sort-algorithms/1.png","hash":"cb9865eb782b293168e69406b212a0f3097b82a4","modified":1586000622000},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"4e3e855767ac5a48b13af1d6a42df13d8975e03f","modified":1586000622000},{"_id":"themes/matery/source/js/matery.js","hash":"208b7806caa943c115aa0825c9c72a0781404775","modified":1586000622000},{"_id":"themes/matery/source/js/search.js","hash":"77ecae23dd3edd8ad962c5b12954652bb2f7a1b6","modified":1586000622000},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"cb99dc352397ec5d0765794d7b8884972e61973b","modified":1586000622000},{"_id":"themes/matery/source/medias/logo.png","hash":"979ccca1f7334916e1407716ef8a79736997535a","modified":1617318110229},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"ab610754bf6aea844b5ae0802ed37c73b5f1dc9f","modified":1586000622000},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"42dda8e67f7f09d148347887e52f18aea546df26","modified":1586000622000},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"d5a7b9bb96e04c0a3485dd873748f19c50a6a04f","modified":1586000622000},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"890c8f04c1f4905dfceb3ea9fd6efdd040d79c01","modified":1586000622000},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"fd4034bca2eb3987dcf113e6477260bee97eb1e7","modified":1586000622000},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"a3a140e6aeeb6f289e4b821a577ef548267f3de1","modified":1586000622000},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"d3333a22bc29b36f216fddec0f089dffe1f89c0c","modified":1617372496038},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"d8c40dbc8106b5bc53ceb727ad968c1d8f234261","modified":1586000622000},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"9007283743db3361c026a9879eb2376c41ff9c6c","modified":1617318110207},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"821e1af65990521c9e0288178d8e5b18c73a9cab","modified":1586000622000},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"42728561c09589f79b698eb059ab4def53ed3642","modified":1586000622000},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"d4042e5521ceb5f3255cd4455ac7ccd227fee6df","modified":1586000622000},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"e761f0104fbf431671bbe6bebc91ca82f737f4d2","modified":1586000622000},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"3a82fcb6f31d69971cb564985842c14ac02cdca0","modified":1586000622000},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"dfdeea9c59d157acb851d4bf44bf95f81787523c","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"166c0b9753f3f913bd801e82ad5b268004be198d","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"82cb8090cde663fa7ad67418a802997b3057e957","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"3b42900247d5ea4ea5b68e2be44420a0d54785ad","modified":1586000622000},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"3f208f33e4e12becdb8323e6e64e20ad60c3fb2a","modified":1586000622000},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"f85a222ec3f9bc27eb7978015e63a16514b38791","modified":1586000622000},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"0f2e1e27d21492cf228e786daead985b1e1dcea4","modified":1586000622000},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"4e73f10eacb5d00a0681cb44fe5c039cd8ab03cd","modified":1586000622000},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"e859fe6e0259e0c123cb7ceda6e4cac836318ffc","modified":1586000622000},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"73624d9db81e87ff0c12310bb873fbd0b5221021","modified":1586000622000},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"e2865b3003ec07892e9112692e7ec786ee926ae8","modified":1586000622000},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"c3039180ddb2eb17e724b8441e5f93e79859aef7","modified":1586000622000},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"b2b22d4fc4e46b051f67216c391f629f4ff552b5","modified":1586000622000},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"6ae58a57b83a5999d0b6a737ec868f084d208f89","modified":1586000622000},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"785cb588a31215876f6737213054ba0e8552fff0","modified":1586000622000},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"5284712d84bbaa4f0d88026ac3ec5a8c13e00056","modified":1586000622000},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"fc50cb4bbc1f4d0e4c9f5941f1c3c74bea742db7","modified":1586000622000},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"9ea672db65f1e5b8fad1ffafb1614f25adc97e63","modified":1586000622000},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"c6f713316ce75ad08ac5d1587bd8ce42e894e9ae","modified":1586000622000},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"4608af6151f0e32f668c89f09343748340021478","modified":1586000622000},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"0aaf0a111b9aa07ff37f6286eeac5506283f47f8","modified":1586000622000},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"d439d86818de179d64965d4f7f5fa56147fd9221","modified":1586000622000},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"05f5e2acace5730cdf7bed650375ad88f6b5d1b7","modified":1586000622000},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"bf604fe9c435f0fb9a559cac9c35772579b590e8","modified":1586000622000},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"6310903eb0e434d6f9a59ca669aab7fae38d4797","modified":1586000622000},{"_id":"source/_posts/rabbitmq概念/moxin.png","hash":"1ef43d749bffcb0f6e82af7e1b72bbbe115b9852","modified":1617447279897},{"_id":"source/_posts/redis主从同步/duxiefenli.jpg","hash":"c42908d4a016e55ca0e85a69c7c4509e1b0ebfc9","modified":1617318110026},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"5a8e6d07ffa55642418ab3fd4b263aa08284b77a","modified":1586000622000},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"ded9739f803d114c9168d3351fded72b3b478b4c","modified":1586000622000},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"5dfcbcee866e9dc564916416281885f3e320871e","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeCopy.js","hash":"b74a381adf6ef8404d6a0452c2b9f44b47219c80","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeLang.js","hash":"ea8b51e4d75e7b2cd63e4d5bcb8db2cf7f23f5db","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/codeShrink.js","hash":"215910dc8f63fd50b97957e5fcdc8480aa2728cb","modified":1586000622000},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"7f4f8913f2d46ade2def5134e2cc8684a4b87939","modified":1586000622000},{"_id":"themes/matery/source/libs/codeBlock/clipboard.min.js","hash":"9cd57c67fbd3e3067f80793ef8445f5ff7783563","modified":1586000622000},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"5d52d3b34fceb9d7e11f1beaf7ed380b4249dec4","modified":1586000622000},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"33810b2b757fc4327bc1d3b83bb5e0d3dc1fec5b","modified":1586000622000},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"021898a16279ac2ffe75af4f902fab2a0a39f11a","modified":1586000622000},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"a0625d8b432af8bdc820f8768d36cde439e7257c","modified":1586000622000},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"26849509f196a2d21bbfd15696e5d5153163b8f1","modified":1586000622000},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"4e6538c8312aeeab845d361c37a8c1a0931241f0","modified":1586000622000},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1586000622000},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1586000622000},{"_id":"themes/matery/source/libs/others/explosion.min.js","hash":"417b68e2cf2c6de2119c57626f4412105a8457f5","modified":1586000622000},{"_id":"themes/matery/source/libs/others/text.js","hash":"1791782cde0d1e4197f2ed58ecb7dd6aefddd169","modified":1586000622000},{"_id":"themes/matery/source/libs/others/snow.js","hash":"b393f069781eef788a0ae66b2681cece8fea2851","modified":1586000622000},{"_id":"themes/matery/source/libs/others/fireworks.js","hash":"53981959bc6def4a85bbbb41b07e4b1474a2124d","modified":1586000622000},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"f646f2bb75bcd1eb65b2788ac7bf15d4fd243ce9","modified":1586000622000},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"f81cd7bfcf7aa2d043bd3e6077df42656fc44b82","modified":1586000622000},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1586000622000},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/0.jpg","hash":"1f8bbfbd625448b4b2a748b75636e456b826dcd3","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/5.jpg","hash":"c4cc724f4572a9bcede7443a4f4c0393d3073868","modified":1586000622000},{"_id":"source/_posts/kafka消费者/transport.jpg","hash":"1054da2267e08446511c1066e7ac1fc6064c9dd8","modified":1617318109856},{"_id":"source/_posts/kafka认证/compare.jpg","hash":"ee042251e517eda5a971e780aa33c3bfb571c05c","modified":1617318109896},{"_id":"themes/matery/source/medias/reward/alipay.jpg","hash":"105c06576d1a1136bdf3a81905c7ddcc43ede294","modified":1617318110239},{"_id":"themes/matery/source/medias/avatars/ajin.jpg","hash":"76cb8e872472ff47a1b061c3bcff1c03f30c02b8","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/feibar.jpg","hash":"343f47cb5c83cd866a1c824cbe2a112d02516d06","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/cww97.jpg","hash":"6af987cafc55d8d031534dd5e0f722fff19f70ec","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/babyq.png","hash":"be5432588003e5a52c02e690622eec72b5f7346c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/hael.jpg","hash":"e66ccedab38bb2e8fc45fac024e234ab8e7b9d54","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/fun4go.png","hash":"0f4333973a972a629cfbabf601bc7c192b65376c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/huaji.jpg","hash":"86be7eed2a491455ccfe3e7da46366ff477765ca","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/kewlgrl.jpg","hash":"3af0fd1029a1511bb3c0e90871e41b35e714b01f","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/ldy.jpg","hash":"906ef214d1f2fe52a663738340ad5623f826bd82","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/liyucheng.jpg","hash":"12055a27fa667c87d2319475968056e1a8ad0f08","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/liyangzone.jpg","hash":"febab557e4c0d859ab4cc14b57d8106f5e3fccfb","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/lijiaqian.png","hash":"9d96b3838acfae9a23b6e290fcfafceff0419c63","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mpy634.png","hash":"30f88e09c02b37c2dc684d4ee3237e327bb23f8b","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/michael.jpg","hash":"331a2ab20c299196f5a3089b8445fc8f55346cb6","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/masterx.jpg","hash":"c9f7e83d895fa241cefd6e742f356106b35f1b89","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mouse.jpg","hash":"2eae273885b9859150a1f98f74b3df12ca9a207c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/taotao.jpg","hash":"e668254375ddd40a684ff4669c3421851bebd36e","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/sunchangzhi.jpg","hash":"bbe2a15fd474ab62dbd14fea72deb1113a4fb005","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/spacesac.png","hash":"ff1bdb058f1f0499312da1a082ba97d78590db1a","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/qiqiang.jpg","hash":"081459866f922d9558a88cd4d7155d91fa730322","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/tawn.jpg","hash":"68a1cbacbb2370912b000c9d8d2b16196c918a50","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/taowei.jpg","hash":"e58b03b70656aa7a27238be38dac3896d9d16f10","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/zhaokangzhe.jpg","hash":"c8242bd13f08a9ddb97e26f216bc729b12ed9058","modified":1586000622000},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"70c0c4a9bf698747b7c058c21287ad617355e5dd","modified":1586000622000},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"82276be41d2001e820020a219b90ad5b026302d1","modified":1586000622000},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"5a13983930b019450e4fe01a407c64b3dd316be4","modified":1586000622000},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","hash":"7a551393b8360731104fdef1af36a6f3638f5855","modified":1586000622000},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"f1558f12d96a352e490166d543a8e821dd3bb2bc","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/1.jpg","hash":"309f484b6e69e877de6a7fb847d66497d22bbd65","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/antnlp.ico","hash":"29475f350b989331cebd702a315f020917d06ed8","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/duyupei.jpg","hash":"3c02ed4cf57dc37e4f4b8314bf5094833a854cb0","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/gsy.jpg","hash":"6a175e2ba56a2280d40a2e654b559be41c3a0a48","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/yezijie.png","hash":"8a53537eb69f749115e512b6da061e7f23cd04e5","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/jiejie.jpg","hash":"a52476e25bec2391674e77a889a89341fbb29791","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/hzwer.jpg","hash":"53a66bb5e65d2abd5b7412edf094c1e0b1094492","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/ids2.jpg","hash":"2c8d3ac6ab5ac6196bac83766fde975daca91c32","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/milyyy.jpg","hash":"ac2826d9c28346efeb967df01465a2c74d9041fe","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/mizunashi.png","hash":"5fc300701d3b4250a307ed70e3a3aa0d5395c808","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/qiandongwei.jpg","hash":"6873551596a4513d01898ad866c4073c68270c57","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/myzhihu.png","hash":"992e0d803160d2ae867be5eb0032d324d1cedffb","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/zhangting.jpg","hash":"10ee25ae3531f046a8bd3696c1cc8a16f0f25e1b","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/xuzhongyou.jpg","hash":"1db4dfaf23cf250f222a398326562d4170d3aaa1","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/xiejiadong.jpg","hash":"f1a31f89426bd4dccdaba2170f4fc701336702e1","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"3480f00d284c812d623ed16a9e0ead3fb964c72e","modified":1586000622000},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"f63c7c489524ccb5d95e74fcd6618116c58fb305","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1586000622000},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c843f0dc497314574c608ca28cc742bb041786d5","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1586000622000},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"f8cd48e1fff82ecd54a7ce3e69de8dba7c92d113","modified":1586000622000},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"7126de5cec8371e580b7b1f22512da0985cc39e5","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1586000622000},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1586000622000},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"04c6b2782ce4610c429563110f6a20a47432fc4c","modified":1586000622000},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1586000622000},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/2.jpg","hash":"280fa1c6493d7fdccfc18bd486446bacd9afe623","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/6.jpg","hash":"4fcbc9dd8ec0316e9dd5bfd0caf86f1520b10b3f","modified":1586000622000},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"2c27939768606603bee3b5e6c8a722596a667e60","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/0.jpg","hash":"d4db93afdff4ce889dd8271bcf9e80eb3c0bf866","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/22.jpg","hash":"02ec4566225102778c3837f08b24de02faf460a6","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/14.jpg","hash":"1c1063c29f827cf52eeef7ca8dc2d7e4efa31a76","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/13.jpg","hash":"d8cc7a730668943dcb0776cfa240a0cf76826363","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/tiantangdemogui.jpg","hash":"f005578ddb4d3d731838db89a708f39f18d50e60","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/yiluxiangbei.jpg","hash":"01b12e3aca7385a88412c12539e1a608a78896fa","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/yequ.jpg","hash":"103beb9ab33434b434fa37a30aecdb29db633024","modified":1586000622000},{"_id":"source/_posts/kafka高水位和Leader-Epoch/water.jpg","hash":"3d073059ee3de487ba7780979c2f10efc0b2b1c0","modified":1617318109936},{"_id":"themes/matery/source/medias/avatars/zzw.jpg","hash":"5d385b5732644b07b937a4919abc83cb95e14513","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/0xbird.png","hash":"f9d597dfcb49e1e2be06138b24028291f5638610","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/lzh.png","hash":"8ffcbf19d6b38b891dbe408d9a4e9513b56f247e","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/lyn-draw.jpg","hash":"837d5d5df4dcb086d2da114d0d85084b4ec18768","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/qianqian.png","hash":"fed254c4e7eb58ee22d647acb83f1d08f4508f8f","modified":1586000622000},{"_id":"source/_posts/kafka高水位和Leader-Epoch/bad.jpg","hash":"f0b3341ee83b34a8ffbc71ed8d4d317fd501d117","modified":1617320070668},{"_id":"source/_posts/redis主从同步/master_slave_slave.jpg","hash":"08d5a49519bf88de6d9596593c4bc56ea7a28aa9","modified":1617318110037},{"_id":"themes/matery/source/medias/avatars/mashiro.jpg","hash":"250e911c16eeb6acb1e6214ad3e6a3d762850a8e","modified":1586000622000},{"_id":"themes/matery/source/medias/reward/wechat.png","hash":"b22124cb6498bf1b896b28f7a8edad2d4bc95d68","modified":1617318110249},{"_id":"themes/matery/source/medias/featureimages/12.jpg","hash":"c2892770fd5617418fd33d6f834879e05b2cdafd","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/4.jpg","hash":"a3cfdee2120195ab36b2fdd074d5558852e69297","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/28.jpg","hash":"c73036359640a67a8b17db7ba0e968c088957ab8","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/2.jpg","hash":"1d8863277d744e1a18a2778ac26041bda5b03a98","modified":1586000622000},{"_id":"source/_posts/Kafka控制器/zookeeper.jpg","hash":"326d2bf2ed33838c5385d265fc42ea40b5aa91f3","modified":1617318109656},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/jitao.jpg","hash":"5934b9baccebccbc2be2ead5d84ad32dd41f9559","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/3.jpg","hash":"255aaa4375da855bd80b38cfcc253de892a9d4cf","modified":1586000622000},{"_id":"themes/matery/source/medias/banner/5.jpg","hash":"6ddd1bcbb62a2d28c5be3b9acb7418849d60b2e7","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/17.jpg","hash":"11a6de283124964370dbfaf0e74f2f1e9ac8394d","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/23.jpg","hash":"ee598933707f8bb98ecbf36925f24e8a1c4bd2d6","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/25.jpg","hash":"d0668539783fc615f14178644e486a6befb90c0c","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/3.jpg","hash":"ceb8e0c195a7fe7420334efa114e98cd0e1c6523","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/27.jpg","hash":"7ea6f890cc59def8b1c9f393e4ae77cd16c79aad","modified":1586000622000},{"_id":"source/_posts/kafka思维导图/kafka.png","hash":"b74906e98d780baa859f9c83b83b75e1f0e6fe5c","modified":1617369532420},{"_id":"source/_posts/kafka-Broker请求处理/work.jpg","hash":"0d2ff3cf192c5796b0702f659395cf573bae61d5","modified":1617318109696},{"_id":"themes/matery/source/medias/avatars/feibar.png","hash":"eceaefcbbca1bf49b582eaa649d311cf4fe69dd6","modified":1586000622000},{"_id":"themes/matery/source/medias/music/avatars/daoshu.jpg","hash":"eee120fdf5ccbe86aa7d51826c4c773e76e6357f","modified":1586000622000},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1586000622000},{"_id":"source/_posts/redis思维导图/redis.png","hash":"316e710e31e0f9e9d6c32fc3a27f93facc6f8034","modified":1617318110057},{"_id":"themes/matery/source/medias/avatars/zhangyi.jpg","hash":"c9130036aac9a7ac8d62e33550a9d64896cdc364","modified":1586000622000},{"_id":"source/_posts/redis缓存/buyizhi2.jpg","hash":"a6450b90fe504f52318ac5163bcf7ee6e8913366","modified":1617318110117},{"_id":"themes/matery/source/medias/featureimages/10.jpg","hash":"66de48d963e7f221931e550b2442da0cd40cbaa8","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/20.jpg","hash":"84ba9cf61045de789426eeb6333910266ce29b8c","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/18.jpg","hash":"c74ce6fa4eee122e147ec55532744f34a87ae2bf","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/24.jpg","hash":"72bc68fb0673b84ab9f863d2979396cdc268a76c","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/16.jpg","hash":"0801e96a2f4cbd14b2ad44547e5ffbb23822e751","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/26.jpg","hash":"c66a4e7a2e670b63759a091f9428ee7f971d7b56","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/7.jpg","hash":"bd400da9123424afe7ba6c839be9ad7697c1245b","modified":1586000622000},{"_id":"source/_posts/KafkaAdminClient/yuanli.jpg","hash":"b33c9a9f9235c216f78b405061c10579df31ebb9","modified":1617318109626},{"_id":"source/_posts/kafka消费者/plan1.jpg","hash":"f2a78bd9297b4e6b6391c17f28232e8a71c24e2e","modified":1617318109796},{"_id":"source/_posts/kafka消费者/comsumedown.jpg","hash":"f6e8762b6f1d057a3268daafb73d45f22fda79c9","modified":1617318109746},{"_id":"source/_posts/kafka高水位和Leader-Epoch/good.jpg","hash":"e3721bbb3f844930f232f16f1c7212a427dfe3fc","modified":1617320314235},{"_id":"themes/matery/source/medias/featureimages/19.jpg","hash":"2a47d1123d9c4c6255b7b4817a582d2fa9aea808","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/11.jpg","hash":"2b30186c6d78ed76fa5f278be57290c1bd22c96a","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/6.jpg","hash":"698fc46e97428d73c9d4e3d254e88b9b66fb38cd","modified":1586000622000},{"_id":"source/_posts/kafka消费者/plan2.jpg","hash":"4c372732d8adda9285c477db4649b70c0c7e99fe","modified":1617318109806},{"_id":"source/_posts/kafka消费者/newadd.jpg","hash":"2e60ac2598fff0a9d162504063beb64e4dc0c30a","modified":1617318109796},{"_id":"source/_posts/kafka消费者/leavegroup.jpg","hash":"c3224fb7eb35028b3225a202a0a19b2428d82ad8","modified":1617318109786},{"_id":"themes/matery/source/medias/avatars/jingjing.jpg","hash":"bfcab0139edb2509de984cb0a9b156879c355158","modified":1586000622000},{"_id":"themes/matery/source/medias/avatars/myphoto.jpg","hash":"669f8b38abb3ded420786054c86f95fef9ef4527","modified":1617318110229},{"_id":"themes/matery/source/medias/featureimages/1.jpg","hash":"f1d720039d654d693c32150c06c78cfc3663b0b4","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/21.jpg","hash":"a77810cc2224446f5d4e1a857a8d480f21e81f83","modified":1586000622000},{"_id":"source/_posts/Kafka控制器/data.jpg","hash":"5ef7a438b505613befe402feaf45ae4ee956211e","modified":1617318109656},{"_id":"source/_posts/Kafka控制器/Failover.jpg","hash":"32652c973bbdebece0c6baa92bd4270cd874a595","modified":1617318109646},{"_id":"source/_posts/redis主从同步/zhucongtongbu.jpg","hash":"09776048a670719e96d92ef2f14ee62f082167c3","modified":1617318110047},{"_id":"source/_posts/kafka-Broker请求处理/reactor.jpg","hash":"ecc58bdb597b9438004a2036b4b769bbfc0c6f48","modified":1617318109686},{"_id":"themes/matery/source/medias/featureimages/8.jpg","hash":"f81e97edf705ab45b989b2b15d6a13c005ccaa32","modified":1586000622000},{"_id":"source/_posts/redis缓存/buyizhi.jpg","hash":"2e01f8fa0c307cdd02731705115a8f4e0751f50a","modified":1617318110107},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1586000622000},{"_id":"source/_posts/redis6-0/acl_cmd.jpg","hash":"450f8fc436cabfa7fc6fdc4685fac3b96617c458","modified":1617318110006},{"_id":"themes/matery/source/medias/featureimages/15.jpg","hash":"aff885598033614639944c7559b4849f883e2b34","modified":1586000622000},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"8789b5e4daf0029a6c88f238f10e54d01c4fce82","modified":1586000622000},{"_id":"themes/matery/source/medias/featureimages/9.jpg","hash":"cd54b116609f5741cc7db0f7f49bf56ac356ddfb","modified":1586000622000},{"_id":"source/_posts/kafka消费者/stragey.jpg","hash":"28af504b239bb0e24597f9b4348c1a4021199b6a","modified":1617318109846},{"_id":"themes/matery/source/medias/featureimages/4.jpg","hash":"e06afe32a867f7a6e861618e0b5ac9d93cd71d05","modified":1586000622000},{"_id":"source/_posts/kafka消费者/compare.jpg","hash":"12d59e4df857edd4971b28fb49b9eebe0f81f236","modified":1617318109736},{"_id":"source/_posts/rabbitmq思维导图/rabbitmq.png","hash":"f1dcc6d138bbf4aeaddf7bc3d73ee46022851ec9","modified":1617519540892},{"_id":"source/_posts/kafka高水位和Leader-Epoch/watertime.jpg","hash":"a4614413d175521e3744cdb2e9f661da1148df21","modified":1617318109966}],"Category":[{"name":"mysql","_id":"ckn8tqws80003ncufd8z44tlo"},{"name":"kafka","_id":"ckn8tqwsh0008ncuf73e35nud"},{"name":"rabbitmq","_id":"ckn8tqxi70022ncufr31mvab9"},{"name":"面试","parent":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxj4002xncuffxrgxq9r"},{"name":"redis","_id":"ckn8tqxja0036ncufqkyzd15y"},{"name":"算法","_id":"ckn8tqxm70054ncufrnagd167"}],"Data":[{"_id":"musics","data":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}]},{"_id":"friends","data":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}],"Page":[{"title":"404","date":"2019-07-19T08:41:10.000Z","type":"404","layout":"404","description":"你来到了没有知识的荒原 :(","_content":"","source":"404.md","raw":"---\ntitle: 404\ndate: 2019-07-19 16:41:10\ntype: \"404\"\nlayout: \"404\"\ndescription: \"你来到了没有知识的荒原 :(\"\n---\n","updated":"2020-04-04T11:43:42.000Z","path":"404.html","comments":1,"_id":"ckn8tqwch0000ncuf9479h4oq","content":"","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":""},{"title":"archives","date":"2019-07-19T08:39:20.000Z","type":"archives","layout":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-07-19 16:39:20\ntype: \"archives\"\nlayout: \"archives\"\n---","updated":"2020-04-04T11:43:42.000Z","path":"archives/index.html","comments":1,"_id":"ckn8tqxhf001qncufyyvy2x1f","content":"","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":""},{"title":"contact","date":"2021-03-07T08:04:02.000Z","type":"contact","layout":"contact","_content":"\n# 欢迎留言\n大家有任何问题，都可以在评论区给我留言。\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在评论区留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n* \n","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2021-03-07 16:04:02\ntype: \"contact\"\nlayout: \"contact\"\n---\n\n# 欢迎留言\n大家有任何问题，都可以在评论区给我留言。\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在评论区留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n\n* \n","updated":"2021-04-01T23:01:50.207Z","path":"contact/index.html","comments":1,"_id":"ckn8tqxhj001sncufv3n0iojf","content":"<h1 id=\"欢迎留言\"><a href=\"#欢迎留言\" class=\"headerlink\" title=\"欢迎留言\"></a>欢迎留言</h1><p>大家有任何问题，都可以在评论区给我留言。</p>\n<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在评论区留言，留言格式：</p>\n<ul>\n<li><p><strong>名称：</strong>你的博客名称</p>\n</li>\n<li><p><strong>地址：</strong>你的博客地址</p>\n</li>\n<li><p><strong>简介：</strong>一句话简介</p>\n</li>\n<li><p><strong>头像：</strong>你的头像地址</p>\n</li>\n<li></li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h1 id=\"欢迎留言\"><a href=\"#欢迎留言\" class=\"headerlink\" title=\"欢迎留言\"></a>欢迎留言</h1><p>大家有任何问题，都可以在评论区给我留言。</p>\n<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在评论区留言，留言格式：</p>\n<ul>\n<li><p><strong>名称：</strong>你的博客名称</p>\n</li>\n<li><p><strong>地址：</strong>你的博客地址</p>\n</li>\n<li><p><strong>简介：</strong>一句话简介</p>\n</li>\n<li><p><strong>头像：</strong>你的头像地址</p>\n</li>\n<li></li>\n</ul>\n"},{"title":"categories","date":"2019-07-19T08:39:20.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-07-19 16:39:20\ntype: \"categories\"\nlayout: \"categories\"\n---","updated":"2020-04-04T11:43:42.000Z","path":"categories/index.html","comments":1,"_id":"ckn8tqxhn001uncufmjhik7t9","content":"","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":""},{"title":"about","date":"2021-03-07T08:41:10.000Z","type":"about","layout":"about","_content":"\n\n## 教育经历\n* <b>硕士 信号与信息处理</b>\n西安电子科技大学\n2015/06 - 2018-06\n* <b>本科 电子信息工程</b>\n苏州大学\n2011/09 - 2015/06\n\n## 联系方式\n* <b>电子邮箱</b>\n2276505170@qq.com\n\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2021-03-07 16:41:10\ntype: \"about\"\nlayout: \"about\"\n---\n\n\n## 教育经历\n* <b>硕士 信号与信息处理</b>\n西安电子科技大学\n2015/06 - 2018-06\n* <b>本科 电子信息工程</b>\n苏州大学\n2011/09 - 2015/06\n\n## 联系方式\n* <b>电子邮箱</b>\n2276505170@qq.com\n\n","updated":"2021-04-01T23:01:50.207Z","path":"about/index.html","comments":1,"_id":"ckn8tqxi2001xncuf684bdh6b","content":"<h2 id=\"教育经历\"><a href=\"#教育经历\" class=\"headerlink\" title=\"教育经历\"></a>教育经历</h2><ul>\n<li><b>硕士 信号与信息处理</b><br>西安电子科技大学<br>2015/06 - 2018-06</li>\n<li><b>本科 电子信息工程</b><br>苏州大学<br>2011/09 - 2015/06</li>\n</ul>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li><b>电子邮箱</b><br><a href=\"mailto:2276505170@qq.com\" target=\"_blank\" rel=\"noopener\">2276505170@qq.com</a></li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"教育经历\"><a href=\"#教育经历\" class=\"headerlink\" title=\"教育经历\"></a>教育经历</h2><ul>\n<li><b>硕士 信号与信息处理</b><br>西安电子科技大学<br>2015/06 - 2018-06</li>\n<li><b>本科 电子信息工程</b><br>苏州大学<br>2011/09 - 2015/06</li>\n</ul>\n<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li><b>电子邮箱</b><br><a href=\"mailto:2276505170@qq.com\" target=\"_blank\" rel=\"noopener\">2276505170@qq.com</a></li>\n</ul>\n"},{"title":"tags","date":"2019-07-19T08:40:27.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-07-19 16:40:27\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2020-04-04T11:43:42.000Z","path":"tags/index.html","comments":1,"_id":"ckn8tqxi60021ncufw2oc03qi","content":"","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":""},{"title":"friends","date":"2021-03-07T07:53:10.000Z","type":"friends","layout":"friends","_content":"\n# 友链交换\n想要交换友链的小伙伴，欢迎在留言板留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2021-03-07 15:53:10\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n# 友链交换\n想要交换友链的小伙伴，欢迎在留言板留言，留言格式：\n* **名称：**你的博客名称\n* **地址：**你的博客地址\n* **简介：**一句话简介\n* **头像：**你的头像地址\n","updated":"2021-04-01T23:01:50.207Z","path":"friends/index.html","comments":1,"_id":"ckn8tqxia0026ncuf0covv4jl","content":"<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在留言板留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h1 id=\"友链交换\"><a href=\"#友链交换\" class=\"headerlink\" title=\"友链交换\"></a>友链交换</h1><p>想要交换友链的小伙伴，欢迎在留言板留言，留言格式：</p>\n<ul>\n<li><strong>名称：</strong>你的博客名称</li>\n<li><strong>地址：</strong>你的博客地址</li>\n<li><strong>简介：</strong>一句话简介</li>\n<li><strong>头像：</strong>你的头像地址</li>\n</ul>\n"}],"Post":[{"title":"InnoDB LRU 优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-21T12:42:36.000Z","password":null,"summary":null,"_content":"\nInnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。\n\n在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。\n\n1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部\n\n2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。\n\n3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：\n\n- 若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；\n- 如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。其默认值是1000，单位毫秒。","source":"_posts/InnoDB-LRU-优化.md","raw":"---\ntitle: InnoDB LRU 优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-21 20:42:36\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\nInnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。\n\n在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。\n\n1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部\n\n2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。\n\n3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：\n\n- 若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；\n- 如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。其默认值是1000，单位毫秒。","slug":"InnoDB-LRU-优化","published":1,"updated":"2021-04-01T23:01:49.586Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwrq0001ncufrcjt05it","content":"<p>InnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。</p>\n<p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。</p>\n<p>1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部</p>\n<p>2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p>\n<p>3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p>\n<ul>\n<li>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</li>\n<li>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。其默认值是1000，单位毫秒。</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>InnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。</p>\n<p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。</p>\n<p>1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部</p>\n<p>2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p>\n<p>3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p>\n<ul>\n<li>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</li>\n<li>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。其默认值是1000，单位毫秒。</li>\n</ul>\n"},{"title":"KafkaAdminClient","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T12:54:48.000Z","password":null,"summary":null,"_content":"\n## 功能\n\n主题管理：包括主题的创建、删除和查询。\n\n权限管理：包括具体权限的配置与删除。\n\n配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。\n\n副本日志管理：包括副本底层日志路径的变更和详情查询。\n\n分区管理：即创建额外的主题分区。\n\n消息删除：即删除指定位移之前的分区消息。\n\nDelegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。\n\n消费者组管理：包括消费者组的查询、位移查询和删除。\n\nPreferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。\n\n## 工作原理\n\nAdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。\n\n前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；\n\n而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。\n\n![](yuanli.jpg)\n\n## 应用\n\n### 创建实例\n\n```java\nProperties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka-host:port\");\nprops.put(\"request.timeout.ms\", 600000);\n\ntry (AdminClient client = AdminClient.create(props)) {\n    // 执行你要做的操作……\n}\n```\n\n### 创建主题\n\n```java\nString newTopicName = \"test-topic\";\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 3); //主题名称、分区数和副本数\n    CreateTopicsResult result = client.createTopics(Arrays.asList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}\n```\n\n### 查询消费者组位移\n\n```java\nString groupID = \"test-group\";\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n    Map<TopicPartition, OffsetAndMetadata> offsets = \n        result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}\n```\n\n### 获取 Broker 磁盘占用\n\n```java\n\ntry (AdminClient client = AdminClient.create(props)) {\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(targetBrokerId)); // 指定Broker id\n    long size = 0L;\n    for (Map<String, DescribeLogDirsResponse.LogDirInfo> logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -> logDirInfo.replicaInfos).flatMap(\n            topicPartitionReplicaInfoMap ->\n            topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -> replicaInfo.size))\n            .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size);\n}\n```\n\n","source":"_posts/KafkaAdminClient.md","raw":"---\ntitle: KafkaAdminClient\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 20:54:48\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 功能\n\n主题管理：包括主题的创建、删除和查询。\n\n权限管理：包括具体权限的配置与删除。\n\n配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。\n\n副本日志管理：包括副本底层日志路径的变更和详情查询。\n\n分区管理：即创建额外的主题分区。\n\n消息删除：即删除指定位移之前的分区消息。\n\nDelegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。\n\n消费者组管理：包括消费者组的查询、位移查询和删除。\n\nPreferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。\n\n## 工作原理\n\nAdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。\n\n前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；\n\n而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。\n\n![](yuanli.jpg)\n\n## 应用\n\n### 创建实例\n\n```java\nProperties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka-host:port\");\nprops.put(\"request.timeout.ms\", 600000);\n\ntry (AdminClient client = AdminClient.create(props)) {\n    // 执行你要做的操作……\n}\n```\n\n### 创建主题\n\n```java\nString newTopicName = \"test-topic\";\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 3); //主题名称、分区数和副本数\n    CreateTopicsResult result = client.createTopics(Arrays.asList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}\n```\n\n### 查询消费者组位移\n\n```java\nString groupID = \"test-group\";\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n    Map<TopicPartition, OffsetAndMetadata> offsets = \n        result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}\n```\n\n### 获取 Broker 磁盘占用\n\n```java\n\ntry (AdminClient client = AdminClient.create(props)) {\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(targetBrokerId)); // 指定Broker id\n    long size = 0L;\n    for (Map<String, DescribeLogDirsResponse.LogDirInfo> logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -> logDirInfo.replicaInfos).flatMap(\n            topicPartitionReplicaInfoMap ->\n            topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -> replicaInfo.size))\n            .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size);\n}\n```\n\n","slug":"KafkaAdminClient","published":1,"updated":"2021-04-02T13:12:59.201Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqws20002ncufjk01u37y","content":"<h2 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h2><p>主题管理：包括主题的创建、删除和查询。</p>\n<p>权限管理：包括具体权限的配置与删除。</p>\n<p>配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。</p>\n<p>副本日志管理：包括副本底层日志路径的变更和详情查询。</p>\n<p>分区管理：即创建额外的主题分区。</p>\n<p>消息删除：即删除指定位移之前的分区消息。</p>\n<p>Delegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。</p>\n<p>消费者组管理：包括消费者组的查询、位移查询和删除。</p>\n<p>Preferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。</p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>AdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。</p>\n<p>前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；</p>\n<p>而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。</p>\n<p><img src=\"yuanli.jpg\" alt></p>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><h3 id=\"创建实例\"><a href=\"#创建实例\" class=\"headerlink\" title=\"创建实例\"></a>创建实例</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>AdminClientConfig<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token string\">\"kafka-host:port\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"request.timeout.ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">600000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\" spellcheck=\"true\">// 执行你要做的操作……</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"创建主题\"><a href=\"#创建主题\" class=\"headerlink\" title=\"创建主题\"></a>创建主题</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">String newTopicName <span class=\"token operator\">=</span> <span class=\"token string\">\"test-topic\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    NewTopic newTopic <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">NewTopic</span><span class=\"token punctuation\">(</span>newTopicName<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">short</span><span class=\"token punctuation\">)</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//主题名称、分区数和副本数</span>\n    CreateTopicsResult result <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">createTopics</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span>newTopic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    result<span class=\"token punctuation\">.</span><span class=\"token function\">all</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>SECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"查询消费者组位移\"><a href=\"#查询消费者组位移\" class=\"headerlink\" title=\"查询消费者组位移\"></a>查询消费者组位移</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">String groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"test-group\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ListConsumerGroupOffsetsResult result <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">listConsumerGroupOffsets</span><span class=\"token punctuation\">(</span>groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets <span class=\"token operator\">=</span> \n        result<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsToOffsetAndMetadata</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>SECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"获取-Broker-磁盘占用\"><a href=\"#获取-Broker-磁盘占用\" class=\"headerlink\" title=\"获取 Broker 磁盘占用\"></a>获取 Broker 磁盘占用</h3><pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    DescribeLogDirsResult ret <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">describeLogDirs</span><span class=\"token punctuation\">(</span>Collections<span class=\"token punctuation\">.</span><span class=\"token function\">singletonList</span><span class=\"token punctuation\">(</span>targetBrokerId<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 指定Broker id</span>\n    <span class=\"token keyword\">long</span> size <span class=\"token operator\">=</span> 0L<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> DescribeLogDirsResponse<span class=\"token punctuation\">.</span>LogDirInfo<span class=\"token operator\">></span> logDirInfoMap <span class=\"token operator\">:</span> ret<span class=\"token punctuation\">.</span><span class=\"token function\">all</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        size <span class=\"token operator\">+=</span> logDirInfoMap<span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>logDirInfo <span class=\"token operator\">-</span><span class=\"token operator\">></span> logDirInfo<span class=\"token punctuation\">.</span>replicaInfos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">flatMap</span><span class=\"token punctuation\">(</span>\n            topicPartitionReplicaInfoMap <span class=\"token operator\">-</span><span class=\"token operator\">></span>\n            topicPartitionReplicaInfoMap<span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>replicaInfo <span class=\"token operator\">-</span><span class=\"token operator\">></span> replicaInfo<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">.</span><span class=\"token function\">mapToLong</span><span class=\"token punctuation\">(</span>Long<span class=\"token operator\">:</span><span class=\"token operator\">:</span>longValue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h2><p>主题管理：包括主题的创建、删除和查询。</p>\n<p>权限管理：包括具体权限的配置与删除。</p>\n<p>配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。</p>\n<p>副本日志管理：包括副本底层日志路径的变更和详情查询。</p>\n<p>分区管理：即创建额外的主题分区。</p>\n<p>消息删除：即删除指定位移之前的分区消息。</p>\n<p>Delegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。</p>\n<p>消费者组管理：包括消费者组的查询、位移查询和删除。</p>\n<p>Preferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。</p>\n<h2 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h2><p>AdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。</p>\n<p>前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；</p>\n<p>而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。</p>\n<p><img src=\"yuanli.jpg\" alt></p>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><h3 id=\"创建实例\"><a href=\"#创建实例\" class=\"headerlink\" title=\"创建实例\"></a>创建实例</h3><pre><code class=\"java\">Properties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;kafka-host:port&quot;);\nprops.put(&quot;request.timeout.ms&quot;, 600000);\n\ntry (AdminClient client = AdminClient.create(props)) {\n    // 执行你要做的操作……\n}</code></pre>\n<h3 id=\"创建主题\"><a href=\"#创建主题\" class=\"headerlink\" title=\"创建主题\"></a>创建主题</h3><pre><code class=\"java\">String newTopicName = &quot;test-topic&quot;;\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 3); //主题名称、分区数和副本数\n    CreateTopicsResult result = client.createTopics(Arrays.asList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}</code></pre>\n<h3 id=\"查询消费者组位移\"><a href=\"#查询消费者组位移\" class=\"headerlink\" title=\"查询消费者组位移\"></a>查询消费者组位移</h3><pre><code class=\"java\">String groupID = &quot;test-group&quot;;\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n    Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = \n        result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}</code></pre>\n<h3 id=\"获取-Broker-磁盘占用\"><a href=\"#获取-Broker-磁盘占用\" class=\"headerlink\" title=\"获取 Broker 磁盘占用\"></a>获取 Broker 磁盘占用</h3><pre><code class=\"java\">\ntry (AdminClient client = AdminClient.create(props)) {\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(targetBrokerId)); // 指定Broker id\n    long size = 0L;\n    for (Map&lt;String, DescribeLogDirsResponse.LogDirInfo&gt; logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -&gt; logDirInfo.replicaInfos).flatMap(\n            topicPartitionReplicaInfoMap -&gt;\n            topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -&gt; replicaInfo.size))\n            .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size);\n}</code></pre>\n"},{"title":"Kafka控制器","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T11:48:00.000Z","password":null,"summary":null,"_content":"\n控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。\n\n![](zookeeper.jpg)\n\n## **控制器选举**\n\nBroker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n\n## **控制器作用**\n\n- 主题管理（创建、删除、增加分区）\n- 分区重分配\n- Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案\n- 集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。\n- 数据服务：保存了最全的集群元数据信息\n\n![](data.jpg)\n\n## **控制器故障转移**\n\n故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。\n\n![](Failover.jpg)\n\n","source":"_posts/Kafka控制器.md","raw":"---\ntitle: Kafka控制器\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 19:48:00\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。\n\n![](zookeeper.jpg)\n\n## **控制器选举**\n\nBroker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n\n## **控制器作用**\n\n- 主题管理（创建、删除、增加分区）\n- 分区重分配\n- Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案\n- 集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。\n- 数据服务：保存了最全的集群元数据信息\n\n![](data.jpg)\n\n## **控制器故障转移**\n\n故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。\n\n![](Failover.jpg)\n\n","slug":"Kafka控制器","published":1,"updated":"2021-04-02T14:01:48.263Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsb0005ncufbcw0yt9l","content":"<p>控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。</p>\n<p><img src=\"zookeeper.jpg\" alt></p>\n<h2 id=\"控制器选举\"><a href=\"#控制器选举\" class=\"headerlink\" title=\"控制器选举\"></a><strong>控制器选举</strong></h2><p>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。</p>\n<h2 id=\"控制器作用\"><a href=\"#控制器作用\" class=\"headerlink\" title=\"控制器作用\"></a><strong>控制器作用</strong></h2><ul>\n<li>主题管理（创建、删除、增加分区）</li>\n<li>分区重分配</li>\n<li>Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案</li>\n<li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。</li>\n<li>数据服务：保存了最全的集群元数据信息</li>\n</ul>\n<p><img src=\"data.jpg\" alt></p>\n<h2 id=\"控制器故障转移\"><a href=\"#控制器故障转移\" class=\"headerlink\" title=\"控制器故障转移\"></a><strong>控制器故障转移</strong></h2><p>故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。</p>\n<p><img src=\"Failover.jpg\" alt></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。</p>\n<p><img src=\"zookeeper.jpg\" alt></p>\n<h2 id=\"控制器选举\"><a href=\"#控制器选举\" class=\"headerlink\" title=\"控制器选举\"></a><strong>控制器选举</strong></h2><p>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。</p>\n<h2 id=\"控制器作用\"><a href=\"#控制器作用\" class=\"headerlink\" title=\"控制器作用\"></a><strong>控制器作用</strong></h2><ul>\n<li>主题管理（创建、删除、增加分区）</li>\n<li>分区重分配</li>\n<li>Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案</li>\n<li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。</li>\n<li>数据服务：保存了最全的集群元数据信息</li>\n</ul>\n<p><img src=\"data.jpg\" alt></p>\n<h2 id=\"控制器故障转移\"><a href=\"#控制器故障转移\" class=\"headerlink\" title=\"控制器故障转移\"></a><strong>控制器故障转移</strong></h2><p>故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。</p>\n<p><img src=\"Failover.jpg\" alt></p>\n"},{"title":"MVCC","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-14T12:14:27.000Z","password":null,"summary":null,"_content":"\n## MVCC\n\n多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。\n\n不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。\n\nMCCC 只在 RC 和 RR 两个隔离级别下工作。\n\n## Undo log\n\nundo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。\n\nundo log 的另一个作用是 MVCC，InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。\n\n## MVCC 的实现原理\n\nInnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。\n\n## MVCC 的优势\n\nMVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。\n通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。","source":"_posts/MVCC.md","raw":"---\ntitle: MVCC\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-14 20:14:27\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## MVCC\n\n多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。\n\n不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。\n\nMCCC 只在 RC 和 RR 两个隔离级别下工作。\n\n## Undo log\n\nundo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。\n\nundo log 的另一个作用是 MVCC，InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。\n\n## MVCC 的实现原理\n\nInnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。\n\n## MVCC 的优势\n\nMVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。\n通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。","slug":"MVCC","published":1,"updated":"2021-04-01T23:01:49.656Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsd0006ncufkou3y1s4","content":"<h2 id=\"MVCC\"><a href=\"#MVCC\" class=\"headerlink\" title=\"MVCC\"></a>MVCC</h2><p>多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。</p>\n<p>不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p>\n<p>MCCC 只在 RC 和 RR 两个隔离级别下工作。</p>\n<h2 id=\"Undo-log\"><a href=\"#Undo-log\" class=\"headerlink\" title=\"Undo log\"></a>Undo log</h2><p>undo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。</p>\n<p>undo log 的另一个作用是 MVCC，InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。</p>\n<h2 id=\"MVCC-的实现原理\"><a href=\"#MVCC-的实现原理\" class=\"headerlink\" title=\"MVCC 的实现原理\"></a>MVCC 的实现原理</h2><p>InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。</p>\n<h2 id=\"MVCC-的优势\"><a href=\"#MVCC-的优势\" class=\"headerlink\" title=\"MVCC 的优势\"></a>MVCC 的优势</h2><p>MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。<br>通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"MVCC\"><a href=\"#MVCC\" class=\"headerlink\" title=\"MVCC\"></a>MVCC</h2><p>多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。</p>\n<p>不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p>\n<p>MCCC 只在 RC 和 RR 两个隔离级别下工作。</p>\n<h2 id=\"Undo-log\"><a href=\"#Undo-log\" class=\"headerlink\" title=\"Undo log\"></a>Undo log</h2><p>undo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了。</p>\n<p>undo log 的另一个作用是 MVCC，InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。</p>\n<h2 id=\"MVCC-的实现原理\"><a href=\"#MVCC-的实现原理\" class=\"headerlink\" title=\"MVCC 的实现原理\"></a>MVCC 的实现原理</h2><p>InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。</p>\n<h2 id=\"MVCC-的优势\"><a href=\"#MVCC-的优势\" class=\"headerlink\" title=\"MVCC 的优势\"></a>MVCC 的优势</h2><p>MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。<br>通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。</p>\n"},{"title":"count优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T10:30:14.000Z","password":null,"summary":null,"_content":"\n## count说明\n\n### count(a) 和 count(*)\n\n当 count() 统计某一列时，比如 count(a)，a 表示列名，是不统计 null 的。\n\n而 count(*) 无论是否包含空值，都会统计。\n\n### MyISAM 引擎和 InnoDB 引擎 count(*) 的区别\n\n对于 MyISAM 引擎，如果没有 where 子句，也没检索其它列，那么 count(*) 将会非常快。因为 MyISAM 引擎会把\n表的总行数存在磁盘上。\n\nInnoDB 并不会保留表中的行数，因为并发事务可能同时读取到不同的行数。所以执行 count(*) 时都是临时去\n计算的，会比 MyISAM 引擎慢很多。\n\n### MySQL 5.7.18 前后 count(*) 的区别\n\nMySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理 count(*) 语句。\n\nMySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 count(*) 语句。\n\n优化器基于成本的考虑，优先选择的是二级索引。所以 count(主键) 其实没 count (*)快。\n\n### count(1)   count(*)\n\n执行计划相同，速度没有明显差别\n\n## count 优化\n\n1、show table status,Rows 这列就表示这张表的行数。\n\n```mysql\nshow table status like 't1';\n```\n\n估算值，可能与实际值相差 40% 到 50%。\n\n2、用 Redis 做计数器\n\nredis 和数据库访问存在时间先后，可能会读到错误的值。\n\n3、增加计数表\n\n维持了计数的准确性\n\n","source":"_posts/count优化.md","raw":"---\ntitle: count优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 18:30:14\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## count说明\n\n### count(a) 和 count(*)\n\n当 count() 统计某一列时，比如 count(a)，a 表示列名，是不统计 null 的。\n\n而 count(*) 无论是否包含空值，都会统计。\n\n### MyISAM 引擎和 InnoDB 引擎 count(*) 的区别\n\n对于 MyISAM 引擎，如果没有 where 子句，也没检索其它列，那么 count(*) 将会非常快。因为 MyISAM 引擎会把\n表的总行数存在磁盘上。\n\nInnoDB 并不会保留表中的行数，因为并发事务可能同时读取到不同的行数。所以执行 count(*) 时都是临时去\n计算的，会比 MyISAM 引擎慢很多。\n\n### MySQL 5.7.18 前后 count(*) 的区别\n\nMySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理 count(*) 语句。\n\nMySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 count(*) 语句。\n\n优化器基于成本的考虑，优先选择的是二级索引。所以 count(主键) 其实没 count (*)快。\n\n### count(1)   count(*)\n\n执行计划相同，速度没有明显差别\n\n## count 优化\n\n1、show table status,Rows 这列就表示这张表的行数。\n\n```mysql\nshow table status like 't1';\n```\n\n估算值，可能与实际值相差 40% 到 50%。\n\n2、用 Redis 做计数器\n\nredis 和数据库访问存在时间先后，可能会读到错误的值。\n\n3、增加计数表\n\n维持了计数的准确性\n\n","slug":"count优化","published":1,"updated":"2021-04-01T23:01:49.666Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsg0007ncuf5eiiqd86","content":"<h2 id=\"count说明\"><a href=\"#count说明\" class=\"headerlink\" title=\"count说明\"></a>count说明</h2><h3 id=\"count-a-和-count\"><a href=\"#count-a-和-count\" class=\"headerlink\" title=\"count(a) 和 count(*)\"></a>count(a) 和 count(*)</h3><p>当 count() 统计某一列时，比如 count(a)，a 表示列名，是不统计 null 的。</p>\n<p>而 count(*) 无论是否包含空值，都会统计。</p>\n<h3 id=\"MyISAM-引擎和-InnoDB-引擎-count-的区别\"><a href=\"#MyISAM-引擎和-InnoDB-引擎-count-的区别\" class=\"headerlink\" title=\"MyISAM 引擎和 InnoDB 引擎 count(*) 的区别\"></a>MyISAM 引擎和 InnoDB 引擎 count(*) 的区别</h3><p>对于 MyISAM 引擎，如果没有 where 子句，也没检索其它列，那么 count(*) 将会非常快。因为 MyISAM 引擎会把<br>表的总行数存在磁盘上。</p>\n<p>InnoDB 并不会保留表中的行数，因为并发事务可能同时读取到不同的行数。所以执行 count(*) 时都是临时去<br>计算的，会比 MyISAM 引擎慢很多。</p>\n<h3 id=\"MySQL-5-7-18-前后-count-的区别\"><a href=\"#MySQL-5-7-18-前后-count-的区别\" class=\"headerlink\" title=\"MySQL 5.7.18 前后 count(*) 的区别\"></a>MySQL 5.7.18 前后 count(*) 的区别</h3><p>MySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理 count(*) 语句。</p>\n<p>MySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 count(*) 语句。</p>\n<p>优化器基于成本的考虑，优先选择的是二级索引。所以 count(主键) 其实没 count (*)快。</p>\n<h3 id=\"count-1-count\"><a href=\"#count-1-count\" class=\"headerlink\" title=\"count(1)   count(*)\"></a>count(1)   count(*)</h3><p>执行计划相同，速度没有明显差别</p>\n<h2 id=\"count-优化\"><a href=\"#count-优化\" class=\"headerlink\" title=\"count 优化\"></a>count 优化</h2><p>1、show table status,Rows 这列就表示这张表的行数。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">show table status like 't1';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>估算值，可能与实际值相差 40% 到 50%。</p>\n<p>2、用 Redis 做计数器</p>\n<p>redis 和数据库访问存在时间先后，可能会读到错误的值。</p>\n<p>3、增加计数表</p>\n<p>维持了计数的准确性</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"count说明\"><a href=\"#count说明\" class=\"headerlink\" title=\"count说明\"></a>count说明</h2><h3 id=\"count-a-和-count\"><a href=\"#count-a-和-count\" class=\"headerlink\" title=\"count(a) 和 count(*)\"></a>count(a) 和 count(*)</h3><p>当 count() 统计某一列时，比如 count(a)，a 表示列名，是不统计 null 的。</p>\n<p>而 count(*) 无论是否包含空值，都会统计。</p>\n<h3 id=\"MyISAM-引擎和-InnoDB-引擎-count-的区别\"><a href=\"#MyISAM-引擎和-InnoDB-引擎-count-的区别\" class=\"headerlink\" title=\"MyISAM 引擎和 InnoDB 引擎 count(*) 的区别\"></a>MyISAM 引擎和 InnoDB 引擎 count(*) 的区别</h3><p>对于 MyISAM 引擎，如果没有 where 子句，也没检索其它列，那么 count(*) 将会非常快。因为 MyISAM 引擎会把<br>表的总行数存在磁盘上。</p>\n<p>InnoDB 并不会保留表中的行数，因为并发事务可能同时读取到不同的行数。所以执行 count(*) 时都是临时去<br>计算的，会比 MyISAM 引擎慢很多。</p>\n<h3 id=\"MySQL-5-7-18-前后-count-的区别\"><a href=\"#MySQL-5-7-18-前后-count-的区别\" class=\"headerlink\" title=\"MySQL 5.7.18 前后 count(*) 的区别\"></a>MySQL 5.7.18 前后 count(*) 的区别</h3><p>MySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理 count(*) 语句。</p>\n<p>MySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 count(*) 语句。</p>\n<p>优化器基于成本的考虑，优先选择的是二级索引。所以 count(主键) 其实没 count (*)快。</p>\n<h3 id=\"count-1-count\"><a href=\"#count-1-count\" class=\"headerlink\" title=\"count(1)   count(*)\"></a>count(1)   count(*)</h3><p>执行计划相同，速度没有明显差别</p>\n<h2 id=\"count-优化\"><a href=\"#count-优化\" class=\"headerlink\" title=\"count 优化\"></a>count 优化</h2><p>1、show table status,Rows 这列就表示这张表的行数。</p>\n<pre><code class=\"mysql\">show table status like &#39;t1&#39;;</code></pre>\n<p>估算值，可能与实际值相差 40% 到 50%。</p>\n<p>2、用 Redis 做计数器</p>\n<p>redis 和数据库访问存在时间先后，可能会读到错误的值。</p>\n<p>3、增加计数表</p>\n<p>维持了计数的准确性</p>\n"},{"title":"kafka思维导图","top":true,"cover":false,"toc":true,"mathjax":false,"date":"2021-04-02T13:19:32.000Z","password":null,"summary":"博客中kafka相关的思维导图。","_content":"\n![](kafka.png)","source":"_posts/kafka思维导图.md","raw":"---\ntitle: kafka思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: false\ndate: 2021-04-02 21:19:32\npassword:\nsummary: 博客中kafka相关的思维导图。\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n![](kafka.png)","slug":"kafka思维导图","published":1,"updated":"2021-04-02T13:21:29.499Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsj000bncufimld3qw2","content":"<p><img src=\"kafka.png\" alt></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p><img src=\"kafka.png\" alt></p>\n"},{"title":"join优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T09:35:27.000Z","password":null,"summary":null,"_content":"\n## 关联查询\n\n### Nested-Loop Join\n\n思想：一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。[manual][https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html]\n\n在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。\n\n一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ\n\n### Block Nested-Loop Join \n\n思想：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。[manual][https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization. html]\n\njoin_buffer减少了磁盘扫描次数。\n\n主要影响\n\n1. 可能会多次扫描被驱动表，占用磁盘IO资源；\n2. 判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；\n3. 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。\n\n### Batched Key Access\n\n**MRR**\n\n尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n\nMRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。\n\n\n\n思想：结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read(MRR) 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。\n\n```mysql\nset optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/\n```\n\nExtra显示Using join buffer (Batched Key Access)\n\n## 优化关联查询\n\n### 关联字段添加索引\n\n被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。\n\n### 小表做驱动表\n\n小表必定需要扫描，那么做举动表是小表更加合适。\n\n### 临时表\n\n因为某条关联查询只是临时查一次，如果再去添加索引可能会浪费资源。\n\n如果不方便在关联字段上添加索引，不妨尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。\n\n\n\n","source":"_posts/join优化.md","raw":"---\ntitle: join优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 17:35:27\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 关联查询\n\n### Nested-Loop Join\n\n思想：一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。[manual][https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html]\n\n在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。\n\n一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ\n\n### Block Nested-Loop Join \n\n思想：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。[manual][https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization. html]\n\njoin_buffer减少了磁盘扫描次数。\n\n主要影响\n\n1. 可能会多次扫描被驱动表，占用磁盘IO资源；\n2. 判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；\n3. 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。\n\n### Batched Key Access\n\n**MRR**\n\n尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n\nMRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。\n\n\n\n思想：结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read(MRR) 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。\n\n```mysql\nset optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/\n```\n\nExtra显示Using join buffer (Batched Key Access)\n\n## 优化关联查询\n\n### 关联字段添加索引\n\n被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。\n\n### 小表做驱动表\n\n小表必定需要扫描，那么做举动表是小表更加合适。\n\n### 临时表\n\n因为某条关联查询只是临时查一次，如果再去添加索引可能会浪费资源。\n\n如果不方便在关联字段上添加索引，不妨尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。\n\n\n\n","slug":"join优化","published":1,"updated":"2021-04-01T23:01:49.676Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsn000dncuf2vqirlxg","content":"<h2 id=\"关联查询\"><a href=\"#关联查询\" class=\"headerlink\" title=\"关联查询\"></a>关联查询</h2><h3 id=\"Nested-Loop-Join\"><a href=\"#Nested-Loop-Join\" class=\"headerlink\" title=\"Nested-Loop Join\"></a>Nested-Loop Join</h3><p>思想：一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。[manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html]\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html]</a></p>\n<p>在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。</p>\n<p>一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ</p>\n<h3 id=\"Block-Nested-Loop-Join\"><a href=\"#Block-Nested-Loop-Join\" class=\"headerlink\" title=\"Block Nested-Loop Join\"></a>Block Nested-Loop Join</h3><p>思想：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。[manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization</a>. html]</p>\n<p>join_buffer减少了磁盘扫描次数。</p>\n<p>主要影响</p>\n<ol>\n<li>可能会多次扫描被驱动表，占用磁盘IO资源；</li>\n<li>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</li>\n<li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</li>\n</ol>\n<h3 id=\"Batched-Key-Access\"><a href=\"#Batched-Key-Access\" class=\"headerlink\" title=\"Batched Key Access\"></a>Batched Key Access</h3><p><strong>MRR</strong></p>\n<p>尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p>\n<p>MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>\n<p>思想：结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read(MRR) 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>Extra显示Using join buffer (Batched Key Access)</p>\n<h2 id=\"优化关联查询\"><a href=\"#优化关联查询\" class=\"headerlink\" title=\"优化关联查询\"></a>优化关联查询</h2><h3 id=\"关联字段添加索引\"><a href=\"#关联字段添加索引\" class=\"headerlink\" title=\"关联字段添加索引\"></a>关联字段添加索引</h3><p>被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。</p>\n<h3 id=\"小表做驱动表\"><a href=\"#小表做驱动表\" class=\"headerlink\" title=\"小表做驱动表\"></a>小表做驱动表</h3><p>小表必定需要扫描，那么做举动表是小表更加合适。</p>\n<h3 id=\"临时表\"><a href=\"#临时表\" class=\"headerlink\" title=\"临时表\"></a>临时表</h3><p>因为某条关联查询只是临时查一次，如果再去添加索引可能会浪费资源。</p>\n<p>如果不方便在关联字段上添加索引，不妨尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"关联查询\"><a href=\"#关联查询\" class=\"headerlink\" title=\"关联查询\"></a>关联查询</h2><h3 id=\"Nested-Loop-Join\"><a href=\"#Nested-Loop-Join\" class=\"headerlink\" title=\"Nested-Loop Join\"></a>Nested-Loop Join</h3><p>思想：一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。[manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html]\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html]</a></p>\n<p>在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。</p>\n<p>一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ</p>\n<h3 id=\"Block-Nested-Loop-Join\"><a href=\"#Block-Nested-Loop-Join\" class=\"headerlink\" title=\"Block Nested-Loop Join\"></a>Block Nested-Loop Join</h3><p>思想：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。[manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization</a>. html]</p>\n<p>join_buffer减少了磁盘扫描次数。</p>\n<p>主要影响</p>\n<ol>\n<li>可能会多次扫描被驱动表，占用磁盘IO资源；</li>\n<li>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</li>\n<li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</li>\n</ol>\n<h3 id=\"Batched-Key-Access\"><a href=\"#Batched-Key-Access\" class=\"headerlink\" title=\"Batched Key Access\"></a>Batched Key Access</h3><p><strong>MRR</strong></p>\n<p>尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p>\n<p>MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>\n<p>思想：结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read(MRR) 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。</p>\n<pre><code class=\"mysql\">set optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;/*开启BKA*/</code></pre>\n<p>Extra显示Using join buffer (Batched Key Access)</p>\n<h2 id=\"优化关联查询\"><a href=\"#优化关联查询\" class=\"headerlink\" title=\"优化关联查询\"></a>优化关联查询</h2><h3 id=\"关联字段添加索引\"><a href=\"#关联字段添加索引\" class=\"headerlink\" title=\"关联字段添加索引\"></a>关联字段添加索引</h3><p>被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。</p>\n<h3 id=\"小表做驱动表\"><a href=\"#小表做驱动表\" class=\"headerlink\" title=\"小表做驱动表\"></a>小表做驱动表</h3><p>小表必定需要扫描，那么做举动表是小表更加合适。</p>\n<h3 id=\"临时表\"><a href=\"#临时表\" class=\"headerlink\" title=\"临时表\"></a>临时表</h3><p>因为某条关联查询只是临时查一次，如果再去添加索引可能会浪费资源。</p>\n<p>如果不方便在关联字段上添加索引，不妨尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。</p>\n"},{"title":"kafka Broker请求处理","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T09:58:17.000Z","password":null,"summary":null,"_content":"\n所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。\n\nKafka 使用的是 Reactor 模式处理请求。\n\n**Reactor 模式**是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。\n\n![](reactor.jpg)\n\nKafka 提供了 Broker 端参数 `num.network.threads`，用于调整该**网络线程池**的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 **个网络线程**，专门处理客户端发送的请求。\n\n![](work.jpg)\n\n当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个**共享请求队列**中。Broker 端还有个 **IO 线程池**，负责从该队列中取出请求，执行真正的处理--如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。\n\nBroker 端参数 `num.io.threads` 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。\n\n**Purgatory**\n\n缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。\n\n比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 `acks=all`，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。","source":"_posts/kafka-Broker请求处理.md","raw":"---\ntitle: kafka Broker请求处理\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 17:58:17\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。\n\nKafka 使用的是 Reactor 模式处理请求。\n\n**Reactor 模式**是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。\n\n![](reactor.jpg)\n\nKafka 提供了 Broker 端参数 `num.network.threads`，用于调整该**网络线程池**的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 **个网络线程**，专门处理客户端发送的请求。\n\n![](work.jpg)\n\n当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个**共享请求队列**中。Broker 端还有个 **IO 线程池**，负责从该队列中取出请求，执行真正的处理--如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。\n\nBroker 端参数 `num.io.threads` 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。\n\n**Purgatory**\n\n缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。\n\n比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 `acks=all`，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。","slug":"kafka-Broker请求处理","published":1,"updated":"2021-04-01T23:01:49.676Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsu000incufq7oohd7z","content":"<p>所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。</p>\n<p>Kafka 使用的是 Reactor 模式处理请求。</p>\n<p><strong>Reactor 模式</strong>是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。</p>\n<p><img src=\"reactor.jpg\" alt></p>\n<p>Kafka 提供了 Broker 端参数 <code>num.network.threads</code>，用于调整该<strong>网络线程池</strong>的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 <strong>个网络线程</strong>，专门处理客户端发送的请求。</p>\n<p><img src=\"work.jpg\" alt></p>\n<p>当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个<strong>共享请求队列</strong>中。Broker 端还有个 <strong>IO 线程池</strong>，负责从该队列中取出请求，执行真正的处理–如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。</p>\n<p>Broker 端参数 <code>num.io.threads</code> 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。</p>\n<p><strong>Purgatory</strong></p>\n<p>缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。</p>\n<p>比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 <code>acks=all</code>，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。</p>\n<p>Kafka 使用的是 Reactor 模式处理请求。</p>\n<p><strong>Reactor 模式</strong>是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。</p>\n<p><img src=\"reactor.jpg\" alt></p>\n<p>Kafka 提供了 Broker 端参数 <code>num.network.threads</code>，用于调整该<strong>网络线程池</strong>的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 <strong>个网络线程</strong>，专门处理客户端发送的请求。</p>\n<p><img src=\"work.jpg\" alt></p>\n<p>当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个<strong>共享请求队列</strong>中。Broker 端还有个 <strong>IO 线程池</strong>，负责从该队列中取出请求，执行真正的处理–如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。</p>\n<p>Broker 端参数 <code>num.io.threads</code> 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。</p>\n<p><strong>Purgatory</strong></p>\n<p>缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。</p>\n<p>比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 <code>acks=all</code>，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。</p>\n"},{"title":"kafka主题管理","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T13:49:14.000Z","password":null,"summary":null,"_content":"\n## **主题增删改查**\n\n### 创建\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1\n```\n\n从 Kafka 2.2 版本开始，社区推荐用 --bootstrap-server 参数替换 --zookeeper 参数\n\n### 查询\n\n```shell\n# 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name>\n```\n\n### 修改\n\n```shell\n# 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数>\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{\"version\":1, \"partitions\":[\n {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n  {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]},\n  ...\n  {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions\n```\n\n### 删除\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name>\n```\n\n## 特殊主体管理\n\n### 查看消费者组提交的位移数\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning\n```\n\n### 查看消费者组的状态信息\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning\n```\n\n## 常见主题错误处理\n\n### 主题删除失败\n\n- 副本所在的 Broker 宕机了；--重启即可\n- 待删除主题的部分分区依然在执行迁移过程\n\n**解决**\n\n第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。\n\n第 2 步，手动删除该主题在磁盘上的分区目录。\n\n第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。--非必须，可能造成大面积的分区 Leader 重选举\n\n### __consumer_offsets 占用太多的磁盘\n\n jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。\n\n","source":"_posts/kafka主题管理.md","raw":"---\ntitle: kafka主题管理\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 21:49:14\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## **主题增删改查**\n\n### 创建\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1\n```\n\n从 Kafka 2.2 版本开始，社区推荐用 --bootstrap-server 参数替换 --zookeeper 参数\n\n### 查询\n\n```shell\n# 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name>\n```\n\n### 修改\n\n```shell\n# 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数>\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{\"version\":1, \"partitions\":[\n {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n  {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]},\n  ...\n  {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions\n```\n\n### 删除\n\n```shell\nbin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name>\n```\n\n## 特殊主体管理\n\n### 查看消费者组提交的位移数\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning\n```\n\n### 查看消费者组的状态信息\n\n```shell\nbin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning\n```\n\n## 常见主题错误处理\n\n### 主题删除失败\n\n- 副本所在的 Broker 宕机了；--重启即可\n- 待删除主题的部分分区依然在执行迁移过程\n\n**解决**\n\n第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。\n\n第 2 步，手动删除该主题在磁盘上的分区目录。\n\n第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。--非必须，可能造成大面积的分区 Leader 重选举\n\n### __consumer_offsets 占用太多的磁盘\n\n jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。\n\n","slug":"kafka主题管理","published":1,"updated":"2021-04-02T13:10:57.097Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwsz000lncuftxw4v7et","content":"<h2 id=\"主题增删改查\"><a href=\"#主题增删改查\" class=\"headerlink\" title=\"主题增删改查\"></a><strong>主题增删改查</strong></h2><h3 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a>创建</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>从 Kafka 2.2 版本开始，社区推荐用 –bootstrap-server 参数替换 –zookeeper 参数</p>\n<h3 id=\"查询\"><a href=\"#查询\" class=\"headerlink\" title=\"查询\"></a>查询</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"修改\"><a href=\"#修改\" class=\"headerlink\" title=\"修改\"></a>修改</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数>\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{\"version\":1, \"partitions\":[\n {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n  {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n  {\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]},\n  ...\n  {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"特殊主体管理\"><a href=\"#特殊主体管理\" class=\"headerlink\" title=\"特殊主体管理\"></a>特殊主体管理</h2><h3 id=\"查看消费者组提交的位移数\"><a href=\"#查看消费者组提交的位移数\" class=\"headerlink\" title=\"查看消费者组提交的位移数\"></a>查看消费者组提交的位移数</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"查看消费者组的状态信息\"><a href=\"#查看消费者组的状态信息\" class=\"headerlink\" title=\"查看消费者组的状态信息\"></a>查看消费者组的状态信息</h3><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"常见主题错误处理\"><a href=\"#常见主题错误处理\" class=\"headerlink\" title=\"常见主题错误处理\"></a>常见主题错误处理</h2><h3 id=\"主题删除失败\"><a href=\"#主题删除失败\" class=\"headerlink\" title=\"主题删除失败\"></a>主题删除失败</h3><ul>\n<li>副本所在的 Broker 宕机了；–重启即可</li>\n<li>待删除主题的部分分区依然在执行迁移过程</li>\n</ul>\n<p><strong>解决</strong></p>\n<p>第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。</p>\n<p>第 2 步，手动删除该主题在磁盘上的分区目录。</p>\n<p>第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。–非必须，可能造成大面积的分区 Leader 重选举</p>\n<h3 id=\"consumer-offsets-占用太多的磁盘\"><a href=\"#consumer-offsets-占用太多的磁盘\" class=\"headerlink\" title=\"__consumer_offsets 占用太多的磁盘\"></a>__consumer_offsets 占用太多的磁盘</h3><p> jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"主题增删改查\"><a href=\"#主题增删改查\" class=\"headerlink\" title=\"主题增删改查\"></a><strong>主题增删改查</strong></h2><h3 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a>创建</h3><pre><code class=\"shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1</code></pre>\n<p>从 Kafka 2.2 版本开始，社区推荐用 –bootstrap-server 参数替换 –zookeeper 参数</p>\n<h3 id=\"查询\"><a href=\"#查询\" class=\"headerlink\" title=\"查询\"></a>查询</h3><pre><code class=\"shell\"># 查询所有主题的列表\nbin/kafka-topics.sh --bootstrap-server broker_host:port --list\n# 查询单个主题的详细数据\nbin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic &lt;topic_name&gt;</code></pre>\n<h3 id=\"修改\"><a href=\"#修改\" class=\"headerlink\" title=\"修改\"></a>修改</h3><pre><code class=\"shell\"># 增加分区\nbin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt;新分区数&gt;\n\n# 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server \nbin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name &lt;topic_name&gt; --alter --add-config max.message.bytes=10485760\n\n# 变更副本数\n# reassign.json\n{&quot;version&quot;:1, &quot;partitions&quot;:[\n {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]}, \n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,2,1]},\n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0,2]},\n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,2,0]},\n  ...\n  {&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:49,&quot;replicas&quot;:[0,1,2]}\n]}` \nbin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute\n\n # 修改test主题限速\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#39;leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600&#39; --entity-type brokers --entity-name 0\nbin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#39;leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*&#39; --entity-type topics --entity-name test\n\n# 主题分区迁移\nkafka-reassign-partitions</code></pre>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><pre><code class=\"shell\">bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic &lt;topic_name&gt;</code></pre>\n<h2 id=\"特殊主体管理\"><a href=\"#特殊主体管理\" class=\"headerlink\" title=\"特殊主体管理\"></a>特殊主体管理</h2><h3 id=\"查看消费者组提交的位移数\"><a href=\"#查看消费者组提交的位移数\" class=\"headerlink\" title=\"查看消费者组提交的位移数\"></a>查看消费者组提交的位移数</h3><pre><code class=\"shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; --from-beginning</code></pre>\n<h3 id=\"查看消费者组的状态信息\"><a href=\"#查看消费者组的状态信息\" class=\"headerlink\" title=\"查看消费者组的状态信息\"></a>查看消费者组的状态信息</h3><pre><code class=\"shell\">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter&quot; --from-beginning</code></pre>\n<h2 id=\"常见主题错误处理\"><a href=\"#常见主题错误处理\" class=\"headerlink\" title=\"常见主题错误处理\"></a>常见主题错误处理</h2><h3 id=\"主题删除失败\"><a href=\"#主题删除失败\" class=\"headerlink\" title=\"主题删除失败\"></a>主题删除失败</h3><ul>\n<li>副本所在的 Broker 宕机了；–重启即可</li>\n<li>待删除主题的部分分区依然在执行迁移过程</li>\n</ul>\n<p><strong>解决</strong></p>\n<p>第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。</p>\n<p>第 2 步，手动删除该主题在磁盘上的分区目录。</p>\n<p>第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。–非必须，可能造成大面积的分区 Leader 重选举</p>\n<h3 id=\"consumer-offsets-占用太多的磁盘\"><a href=\"#consumer-offsets-占用太多的磁盘\" class=\"headerlink\" title=\"__consumer_offsets 占用太多的磁盘\"></a>__consumer_offsets 占用太多的磁盘</h3><p> jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。</p>\n"},{"title":"kafka副本","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T09:45:20.000Z","password":null,"summary":null,"_content":"\n主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能**追加写消息的提交日志**。\n\n## 副本分类\n\n副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n\n- 所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。\n\n- 追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。\n- 领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。\n\n**优势**\n\n1.方便实现“Read-your-writes”：\n\n2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。\n\n## In-sync Replicas（ISR）\n\n与 Leader 同步的副本，包括 Leader 副本。\n\n标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。\n\n## Unclean 领导者选举\n\n非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。\n\nBroker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。","source":"_posts/kafka副本.md","raw":"---\ntitle: kafka副本\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 17:45:20\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能**追加写消息的提交日志**。\n\n## 副本分类\n\n副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n\n- 所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。\n\n- 追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。\n- 领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。\n\n**优势**\n\n1.方便实现“Read-your-writes”：\n\n2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。\n\n## In-sync Replicas（ISR）\n\n与 Leader 同步的副本，包括 Leader 副本。\n\n标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。\n\n## Unclean 领导者选举\n\n非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。\n\nBroker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。","slug":"kafka副本","published":1,"updated":"2021-04-01T23:01:49.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwt5000oncuf5boda6ub","content":"<p>主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能<strong>追加写消息的提交日志</strong>。</p>\n<h2 id=\"副本分类\"><a href=\"#副本分类\" class=\"headerlink\" title=\"副本分类\"></a>副本分类</h2><p>副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p>\n<ul>\n<li><p>所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。</p>\n</li>\n<li><p>追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p>\n</li>\n<li><p>领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</p>\n</li>\n</ul>\n<p><strong>优势</strong></p>\n<p>1.方便实现“Read-your-writes”：</p>\n<p>2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。</p>\n<h2 id=\"In-sync-Replicas（ISR）\"><a href=\"#In-sync-Replicas（ISR）\" class=\"headerlink\" title=\"In-sync Replicas（ISR）\"></a>In-sync Replicas（ISR）</h2><p>与 Leader 同步的副本，包括 Leader 副本。</p>\n<p>标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。</p>\n<h2 id=\"Unclean-领导者选举\"><a href=\"#Unclean-领导者选举\" class=\"headerlink\" title=\"Unclean 领导者选举\"></a>Unclean 领导者选举</h2><p>非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。</p>\n<p>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能<strong>追加写消息的提交日志</strong>。</p>\n<h2 id=\"副本分类\"><a href=\"#副本分类\" class=\"headerlink\" title=\"副本分类\"></a>副本分类</h2><p>副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p>\n<ul>\n<li><p>所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。</p>\n</li>\n<li><p>追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p>\n</li>\n<li><p>领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</p>\n</li>\n</ul>\n<p><strong>优势</strong></p>\n<p>1.方便实现“Read-your-writes”：</p>\n<p>2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。</p>\n<h2 id=\"In-sync-Replicas（ISR）\"><a href=\"#In-sync-Replicas（ISR）\" class=\"headerlink\" title=\"In-sync Replicas（ISR）\"></a>In-sync Replicas（ISR）</h2><p>与 Leader 同步的副本，包括 Leader 副本。</p>\n<p>标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。</p>\n<h2 id=\"Unclean-领导者选举\"><a href=\"#Unclean-领导者选举\" class=\"headerlink\" title=\"Unclean 领导者选举\"></a>Unclean 领导者选举</h2><p>非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。</p>\n<p>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</p>\n"},{"title":"kafka拦截器","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T11:18:48.000Z","password":null,"summary":null,"_content":"\nKafka 拦截器分为生产者拦截器和消费者拦截器。\n\n生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；\n\n而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。\n\n**使用**\n\n当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫` interceptor.classes`，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。\n\n```java\nProperties props = new Properties();\nList<String> interceptors = new ArrayList<>();\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"); // 拦截器1\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n```\n\n`AddTimeStampInterceptor` 和 `UpdateCounterInterceptor `这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 `org.apache.kafka.clients.producer.ProducerInterceptor `接口。该接口是 Kafka 提供的，里面有两个核心的方法。\n\n- `onSend`：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。\n- `onAcknowledgement`：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。\n\n\n\n消费者拦截器具体的实现类要实现 `org.apache.kafka.clients.consumer.ConsumerInterceptor` 接口，这里面也有两个核心方法。\n\n- `onConsume`：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。\n- `onCommit`：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。\n\n**场景**\n\nKafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。\n\n如：业务消息从被生产出来到最后被消费的平均总时长统计\n\n```java\n// 生产者\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor<String, String> {\n\n\n    private Jedis jedis; // 省略Jedis初始化\n\n\n    @Override\n    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n        jedis.incr(\"totalSentMessage\");\n        return record;\n    }\n\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<java.lang.String, ?> configs) {\n    }\n //消费者\n    \n\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {\n\n\n    private Jedis jedis; //省略Jedis初始化\n\n\n    @Override\n    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {\n        long lantency = 0L;\n        for (ConsumerRecord<String, String> record : records) {\n            lantency += (System.currentTimeMillis() - record.timestamp());\n        }\n        jedis.incrBy(\"totalLatency\", lantency);\n        long totalLatency = Long.parseLong(jedis.get(\"totalLatency\"));\n        long totalSentMsgs = Long.parseLong(jedis.get(\"totalSentMessage\"));\n        jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMsgs));\n        return records;\n    }\n\n\n    @Override\n    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n    }\n}\n```\n\n","source":"_posts/kafka拦截器.md","raw":"---\ntitle: kafka拦截器\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 19:18:48\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\nKafka 拦截器分为生产者拦截器和消费者拦截器。\n\n生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；\n\n而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。\n\n**使用**\n\n当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫` interceptor.classes`，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。\n\n```java\nProperties props = new Properties();\nList<String> interceptors = new ArrayList<>();\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"); // 拦截器1\ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n```\n\n`AddTimeStampInterceptor` 和 `UpdateCounterInterceptor `这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 `org.apache.kafka.clients.producer.ProducerInterceptor `接口。该接口是 Kafka 提供的，里面有两个核心的方法。\n\n- `onSend`：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。\n- `onAcknowledgement`：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。\n\n\n\n消费者拦截器具体的实现类要实现 `org.apache.kafka.clients.consumer.ConsumerInterceptor` 接口，这里面也有两个核心方法。\n\n- `onConsume`：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。\n- `onCommit`：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。\n\n**场景**\n\nKafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。\n\n如：业务消息从被生产出来到最后被消费的平均总时长统计\n\n```java\n// 生产者\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor<String, String> {\n\n\n    private Jedis jedis; // 省略Jedis初始化\n\n\n    @Override\n    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n        jedis.incr(\"totalSentMessage\");\n        return record;\n    }\n\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<java.lang.String, ?> configs) {\n    }\n //消费者\n    \n\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {\n\n\n    private Jedis jedis; //省略Jedis初始化\n\n\n    @Override\n    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {\n        long lantency = 0L;\n        for (ConsumerRecord<String, String> record : records) {\n            lantency += (System.currentTimeMillis() - record.timestamp());\n        }\n        jedis.incrBy(\"totalLatency\", lantency);\n        long totalLatency = Long.parseLong(jedis.get(\"totalLatency\"));\n        long totalSentMsgs = Long.parseLong(jedis.get(\"totalSentMessage\"));\n        jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMsgs));\n        return records;\n    }\n\n\n    @Override\n    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n    }\n}\n```\n\n","slug":"kafka拦截器","published":1,"updated":"2021-04-01T23:01:49.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwt9000rncuflb0abd41","content":"<p>Kafka 拦截器分为生产者拦截器和消费者拦截器。</p>\n<p>生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；</p>\n<p>而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</p>\n<p><strong>使用</strong></p>\n<p>当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫<code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nList<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> interceptors <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayList</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ninterceptors<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 拦截器1</span>\ninterceptors<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 拦截器2</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ProducerConfig<span class=\"token punctuation\">.</span>INTERCEPTOR_CLASSES_CONFIG<span class=\"token punctuation\">,</span> interceptors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>AddTimeStampInterceptor</code> 和 <code>UpdateCounterInterceptor</code>这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code>接口。该接口是 Kafka 提供的，里面有两个核心的方法。</p>\n<ul>\n<li><code>onSend</code>：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。</li>\n<li><code>onAcknowledgement</code>：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。</li>\n</ul>\n<p>消费者拦截器具体的实现类要实现 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里面也有两个核心方法。</p>\n<ul>\n<li><code>onConsume</code>：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。</li>\n<li><code>onCommit</code>：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。</li>\n</ul>\n<p><strong>场景</strong></p>\n<p>Kafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。</p>\n<p>如：业务消息从被生产出来到最后被消费的平均总时长统计</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 生产者</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">AvgLatencyProducerInterceptor</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ProducerInterceptor</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n\n\n    <span class=\"token keyword\">private</span> Jedis jedis<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 省略Jedis初始化</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> ProducerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token function\">onSend</span><span class=\"token punctuation\">(</span>ProducerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">incr</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalSentMessage\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> record<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onAcknowledgement</span><span class=\"token punctuation\">(</span>RecordMetadata metadata<span class=\"token punctuation\">,</span> Exception exception<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">configure</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>String<span class=\"token punctuation\">,</span> <span class=\"token operator\">?</span><span class=\"token operator\">></span> configs<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n <span class=\"token comment\" spellcheck=\"true\">//消费者</span>\n\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">AvgLatencyConsumerInterceptor</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ConsumerInterceptor</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n\n\n    <span class=\"token keyword\">private</span> Jedis jedis<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//省略Jedis初始化</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> <span class=\"token function\">onConsume</span><span class=\"token punctuation\">(</span>ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">long</span> lantency <span class=\"token operator\">=</span> 0L<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            lantency <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span>System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">timestamp</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">incrBy</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalLatency\"</span><span class=\"token punctuation\">,</span> lantency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">long</span> totalLatency <span class=\"token operator\">=</span> Long<span class=\"token punctuation\">.</span><span class=\"token function\">parseLong</span><span class=\"token punctuation\">(</span>jedis<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalLatency\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">long</span> totalSentMsgs <span class=\"token operator\">=</span> Long<span class=\"token punctuation\">.</span><span class=\"token function\">parseLong</span><span class=\"token punctuation\">(</span>jedis<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"totalSentMessage\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"avgLatency\"</span><span class=\"token punctuation\">,</span> String<span class=\"token punctuation\">.</span><span class=\"token function\">valueOf</span><span class=\"token punctuation\">(</span>totalLatency <span class=\"token operator\">/</span> totalSentMsgs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> records<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onCommit</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">configure</span><span class=\"token punctuation\">(</span>Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> <span class=\"token operator\">?</span><span class=\"token operator\">></span> configs<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>Kafka 拦截器分为生产者拦截器和消费者拦截器。</p>\n<p>生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；</p>\n<p>而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</p>\n<p><strong>使用</strong></p>\n<p>当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫<code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p>\n<pre><code class=\"java\">Properties props = new Properties();\nList&lt;String&gt; interceptors = new ArrayList&lt;&gt;();\ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1\ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</code></pre>\n<p><code>AddTimeStampInterceptor</code> 和 <code>UpdateCounterInterceptor</code>这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code>接口。该接口是 Kafka 提供的，里面有两个核心的方法。</p>\n<ul>\n<li><code>onSend</code>：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。</li>\n<li><code>onAcknowledgement</code>：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。</li>\n</ul>\n<p>消费者拦截器具体的实现类要实现 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里面也有两个核心方法。</p>\n<ul>\n<li><code>onConsume</code>：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。</li>\n<li><code>onCommit</code>：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。</li>\n</ul>\n<p><strong>场景</strong></p>\n<p>Kafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。</p>\n<p>如：业务消息从被生产出来到最后被消费的平均总时长统计</p>\n<pre><code class=\"java\">// 生产者\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor&lt;String, String&gt; {\n\n\n    private Jedis jedis; // 省略Jedis初始化\n\n\n    @Override\n    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) {\n        jedis.incr(&quot;totalSentMessage&quot;);\n        return record;\n    }\n\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map&lt;java.lang.String, ?&gt; configs) {\n    }\n //消费者\n\n\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; {\n\n\n    private Jedis jedis; //省略Jedis初始化\n\n\n    @Override\n    public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) {\n        long lantency = 0L;\n        for (ConsumerRecord&lt;String, String&gt; record : records) {\n            lantency += (System.currentTimeMillis() - record.timestamp());\n        }\n        jedis.incrBy(&quot;totalLatency&quot;, lantency);\n        long totalLatency = Long.parseLong(jedis.get(&quot;totalLatency&quot;));\n        long totalSentMsgs = Long.parseLong(jedis.get(&quot;totalSentMessage&quot;));\n        jedis.set(&quot;avgLatency&quot;, String.valueOf(totalLatency / totalSentMsgs));\n        return records;\n    }\n\n\n    @Override\n    public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) {\n    }\n\n\n    @Override\n    public void close() {\n    }\n\n\n    @Override\n    public void configure(Map&lt;String, ?&gt; configs) {\n    }\n}</code></pre>\n"},{"title":"kafka授权","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T13:47:25.000Z","password":null,"summary":null,"_content":"\n授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。\n\nKafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。\n\n## kafka-acls 脚本\n\n```shell\n# Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic\n```\n\n","source":"_posts/kafka授权.md","raw":"---\ntitle: kafka授权\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 21:47:25\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。\n\nKafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。\n\n## kafka-acls 脚本\n\n```shell\n# Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic\n```\n\n","slug":"kafka授权","published":1,"updated":"2021-04-01T23:01:49.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwtb000uncuf7m41c13z","content":"<p>授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。</p>\n<p>Kafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。</p>\n<h2 id=\"kafka-acls-脚本\"><a href=\"#kafka-acls-脚本\" class=\"headerlink\" title=\"kafka-acls 脚本\"></a>kafka-acls 脚本</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。</p>\n<p>Kafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。</p>\n<h2 id=\"kafka-acls-脚本\"><a href=\"#kafka-acls-脚本\" class=\"headerlink\" title=\"kafka-acls 脚本\"></a>kafka-acls 脚本</h2><pre><code class=\"shell\"># Alice 增加了集群级别的所有权限\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic &#39;*&#39; --cluster\n\n\n$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:&#39;*&#39; --allow-host &#39;*&#39; --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic</code></pre>\n"},{"title":"kafka消息丢失","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T11:13:33.000Z","password":null,"summary":null,"_content":"\nkafka 只对“已提交”的消息（committed ）做有限度的持久化保证。\n\n## 避免消息丢失\n\n- 不要使用 `producer.send(msg)`，而要使用` producer.send(msg, callback)`。一定要使用带有回调通知的 send 方法。\n- 设置 `acks = all`。`acks `是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。\n- 设置 `retries` 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 `retries > 0` 的 Producer 能够自动重试消息发送，避免消息丢失。\n- 设置 `unclean.leader.election.enable = false`。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。\n- 设置 `replication.factor >= 3`。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。\n- 设置 `min.insync.replicas > 1`。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。\n- 确保 `replication.factor > min.insync.replicas`。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 `replication.factor = min.insync.replicas + 1`。\n- 确保消息消费完成再提交。Consumer 端有个参数 `enable.auto.commit`，最好把它设置成 `false`，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的","source":"_posts/kafka消息丢失.md","raw":"---\ntitle: kafka消息丢失\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 19:13:33\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\nkafka 只对“已提交”的消息（committed ）做有限度的持久化保证。\n\n## 避免消息丢失\n\n- 不要使用 `producer.send(msg)`，而要使用` producer.send(msg, callback)`。一定要使用带有回调通知的 send 方法。\n- 设置 `acks = all`。`acks `是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。\n- 设置 `retries` 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 `retries > 0` 的 Producer 能够自动重试消息发送，避免消息丢失。\n- 设置 `unclean.leader.election.enable = false`。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。\n- 设置 `replication.factor >= 3`。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。\n- 设置 `min.insync.replicas > 1`。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。\n- 确保 `replication.factor > min.insync.replicas`。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 `replication.factor = min.insync.replicas + 1`。\n- 确保消息消费完成再提交。Consumer 端有个参数 `enable.auto.commit`，最好把它设置成 `false`，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的","slug":"kafka消息丢失","published":1,"updated":"2021-04-01T23:01:49.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqwte000xncufud02ada5","content":"<p>kafka 只对“已提交”的消息（committed ）做有限度的持久化保证。</p>\n<h2 id=\"避免消息丢失\"><a href=\"#避免消息丢失\" class=\"headerlink\" title=\"避免消息丢失\"></a>避免消息丢失</h2><ul>\n<li>不要使用 <code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>。一定要使用带有回调通知的 send 方法。</li>\n<li>设置 <code>acks = all</code>。<code>acks</code>是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>\n<li>设置 <code>retries</code> 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</li>\n<li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li>\n<li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li>\n<li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>\n<li>确保 <code>replication.factor &gt; min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li>\n<li>确保消息消费完成再提交。Consumer 端有个参数 <code>enable.auto.commit</code>，最好把它设置成 <code>false</code>，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>kafka 只对“已提交”的消息（committed ）做有限度的持久化保证。</p>\n<h2 id=\"避免消息丢失\"><a href=\"#避免消息丢失\" class=\"headerlink\" title=\"避免消息丢失\"></a>避免消息丢失</h2><ul>\n<li>不要使用 <code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>。一定要使用带有回调通知的 send 方法。</li>\n<li>设置 <code>acks = all</code>。<code>acks</code>是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>\n<li>设置 <code>retries</code> 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</li>\n<li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li>\n<li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li>\n<li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>\n<li>确保 <code>replication.factor &gt; min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li>\n<li>确保消息消费完成再提交。Consumer 端有个参数 <code>enable.auto.commit</code>，最好把它设置成 <code>false</code>，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的</li>\n</ul>\n"},{"title":"kafka生产者","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T10:45:20.000Z","password":null,"summary":null,"_content":"\n## 消息分区机制\n\n### 为什么分区\n\n提供负载均衡的能力，实现系统的高伸缩性）。\n\n不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。\n\n### 分区策略\n\n**自定义分区策略**\n\n编写一个具体的类实现`org.apache.kafka.clients.producer.Partitioner`接口。这个接口只定义了两个方法：`partition()`和`close()`，一般只需要实现 `partition `方法。\n\n**轮询策略**\n\n` Round-robin` 策略，即顺序分配。轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\n\n**随机策略**\n\n`Randomness `策略。所谓随机就是将消息放置到任意一个分区上。\n\n**按消息键保序策略**\n\nKafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。\n\n```java\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n\n//可以根据 Broker 所在的 IP 地址实现定制化的分区策略\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(\n    p -> isSouth(p.leader().host())\n).map(PartitionInfo::partition).findAny().get();\n```\n\n## 压缩\n\nKafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。\n\n### V1 版本和 V2 版本区别\n\n1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。\n\n2、消息的 CRC 校验工作就被移到了消息集合这一层。\n\n3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩\n\n### 何时压缩\n\n1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。\n\n```java\n Properties props = new Properties();\n props.put(\"bootstrap.servers\", \"localhost:9092\");\n props.put(\"acks\", \"all\");\n props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n // 开启GZIP压缩\n props.put(\"compression.type\", \"gzip\");\n \n Producer<String, String> producer = new KafkaProducer<>(props);\n```\n\n2、Broker 重新压缩消息\n\n- Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。\n\n- Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性\n\n### 解压缩\n\n通常来说解压缩发生在消费者程序中。\n\n Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。\n\n### 压缩算法\n\n吞吐量：LZ4 > Snappy > zstd 和 GZIP；\n\n压缩比：zstd > LZ4 > GZIP > Snappy\n\n## Kafka 生产者程序\n\n第 1 步：构造生产者对象所需的参数对象。\n\n第 2 步：利用参数对象，创建 KafkaProducer 对象实例。\n\n第 3 步：使用 KafkaProducer 的 send 方法发送消息。\n\n第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。\n\n```java\nProperties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer<String, String> producer = new KafkaProducer<>(props)) {\n    producer.send(new ProducerRecord<String, String>(……), callback);\n  ……\n}\n```\n\n## 生产者的TCP\n\n在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会**创建与 Broker 的TCP连接**。它会连接 `bootstrap.servers` 参数指定的所有 Broker。\n\n`KafkaProducer `实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 `RecordAccumulator `类，维护了 `RecordAccumulator` 类的线程安全，也就实现了 KafkaProducer 类的线程安全。\n\n**其他TCP连接创建**\n\n- 当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。\n\n- 当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。\n\n**更新元数据场景**\n\n1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。\n\n2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。\n\n**关闭TCP连接**\n\n- 用户主动关闭\n\n- Kafka 自动关闭\n\nconnections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。\n\n可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或 `props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要**事务**或者依赖**事务型 Producer**\n\n","source":"_posts/kafka生产者.md","raw":"---\ntitle: kafka生产者\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 18:45:20\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 消息分区机制\n\n### 为什么分区\n\n提供负载均衡的能力，实现系统的高伸缩性）。\n\n不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。\n\n### 分区策略\n\n**自定义分区策略**\n\n编写一个具体的类实现`org.apache.kafka.clients.producer.Partitioner`接口。这个接口只定义了两个方法：`partition()`和`close()`，一般只需要实现 `partition `方法。\n\n**轮询策略**\n\n` Round-robin` 策略，即顺序分配。轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\n\n**随机策略**\n\n`Randomness `策略。所谓随机就是将消息放置到任意一个分区上。\n\n**按消息键保序策略**\n\nKafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。\n\n```java\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n\n//可以根据 Broker 所在的 IP 地址实现定制化的分区策略\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(\n    p -> isSouth(p.leader().host())\n).map(PartitionInfo::partition).findAny().get();\n```\n\n## 压缩\n\nKafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。\n\n### V1 版本和 V2 版本区别\n\n1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。\n\n2、消息的 CRC 校验工作就被移到了消息集合这一层。\n\n3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩\n\n### 何时压缩\n\n1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。\n\n```java\n Properties props = new Properties();\n props.put(\"bootstrap.servers\", \"localhost:9092\");\n props.put(\"acks\", \"all\");\n props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n // 开启GZIP压缩\n props.put(\"compression.type\", \"gzip\");\n \n Producer<String, String> producer = new KafkaProducer<>(props);\n```\n\n2、Broker 重新压缩消息\n\n- Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。\n\n- Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性\n\n### 解压缩\n\n通常来说解压缩发生在消费者程序中。\n\n Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。\n\n### 压缩算法\n\n吞吐量：LZ4 > Snappy > zstd 和 GZIP；\n\n压缩比：zstd > LZ4 > GZIP > Snappy\n\n## Kafka 生产者程序\n\n第 1 步：构造生产者对象所需的参数对象。\n\n第 2 步：利用参数对象，创建 KafkaProducer 对象实例。\n\n第 3 步：使用 KafkaProducer 的 send 方法发送消息。\n\n第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。\n\n```java\nProperties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer<String, String> producer = new KafkaProducer<>(props)) {\n    producer.send(new ProducerRecord<String, String>(……), callback);\n  ……\n}\n```\n\n## 生产者的TCP\n\n在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会**创建与 Broker 的TCP连接**。它会连接 `bootstrap.servers` 参数指定的所有 Broker。\n\n`KafkaProducer `实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 `RecordAccumulator `类，维护了 `RecordAccumulator` 类的线程安全，也就实现了 KafkaProducer 类的线程安全。\n\n**其他TCP连接创建**\n\n- 当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。\n\n- 当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。\n\n**更新元数据场景**\n\n1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。\n\n2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。\n\n**关闭TCP连接**\n\n- 用户主动关闭\n\n- Kafka 自动关闭\n\nconnections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。\n\n可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或 `props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要**事务**或者依赖**事务型 Producer**\n\n","slug":"kafka生产者","published":1,"updated":"2021-04-01T23:01:49.856Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxgg001ancufi0mv8wae","content":"<h2 id=\"消息分区机制\"><a href=\"#消息分区机制\" class=\"headerlink\" title=\"消息分区机制\"></a>消息分区机制</h2><h3 id=\"为什么分区\"><a href=\"#为什么分区\" class=\"headerlink\" title=\"为什么分区\"></a>为什么分区</h3><p>提供负载均衡的能力，实现系统的高伸缩性）。</p>\n<p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。</p>\n<h3 id=\"分区策略\"><a href=\"#分区策略\" class=\"headerlink\" title=\"分区策略\"></a>分区策略</h3><p><strong>自定义分区策略</strong></p>\n<p>编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口。这个接口只定义了两个方法：<code>partition()</code>和<code>close()</code>，一般只需要实现 <code>partition</code>方法。</p>\n<p><strong>轮询策略</strong></p>\n<p><code>Round-robin</code> 策略，即顺序分配。轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。</p>\n<p><strong>随机策略</strong></p>\n<p><code>Randomness</code>策略。所谓随机就是将消息放置到任意一个分区上。</p>\n<p><strong>按消息键保序策略</strong></p>\n<p>Kafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">List<span class=\"token operator\">&lt;</span>PartitionInfo<span class=\"token operator\">></span> partitions <span class=\"token operator\">=</span> cluster<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsForTopic</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">return</span> Math<span class=\"token punctuation\">.</span><span class=\"token function\">abs</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">.</span><span class=\"token function\">hashCode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> partitions<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">//可以根据 Broker 所在的 IP 地址实现定制化的分区策略</span>\nList<span class=\"token operator\">&lt;</span>PartitionInfo<span class=\"token operator\">></span> partitions <span class=\"token operator\">=</span> cluster<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsForTopic</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">return</span> partitions<span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">filter</span><span class=\"token punctuation\">(</span>\n    p <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token function\">isSouth</span><span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">.</span><span class=\"token function\">leader</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">host</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>PartitionInfo<span class=\"token operator\">:</span><span class=\"token operator\">:</span>partition<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">findAny</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"压缩\"><a href=\"#压缩\" class=\"headerlink\" title=\"压缩\"></a>压缩</h2><p>Kafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。</p>\n<h3 id=\"V1-版本和-V2-版本区别\"><a href=\"#V1-版本和-V2-版本区别\" class=\"headerlink\" title=\"V1 版本和 V2 版本区别\"></a>V1 版本和 V2 版本区别</h3><p>1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。</p>\n<p>2、消息的 CRC 校验工作就被移到了消息集合这一层。</p>\n<p>3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩</p>\n<h3 id=\"何时压缩\"><a href=\"#何时压缩\" class=\"headerlink\" title=\"何时压缩\"></a>何时压缩</h3><p>1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"> Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"bootstrap.servers\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"localhost:9092\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"acks\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"all\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"key.serializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringSerializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"value.serializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringSerializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n <span class=\"token comment\" spellcheck=\"true\">// 开启GZIP压缩</span>\n props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"compression.type\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"gzip\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n Producer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaProducer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>2、Broker 重新压缩消息</p>\n<ul>\n<li><p>Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。</p>\n</li>\n<li><p>Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性</p>\n</li>\n</ul>\n<h3 id=\"解压缩\"><a href=\"#解压缩\" class=\"headerlink\" title=\"解压缩\"></a>解压缩</h3><p>通常来说解压缩发生在消费者程序中。</p>\n<p> Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。</p>\n<h3 id=\"压缩算法\"><a href=\"#压缩算法\" class=\"headerlink\" title=\"压缩算法\"></a>压缩算法</h3><p>吞吐量：LZ4 &gt; Snappy &gt; zstd 和 GZIP；</p>\n<p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy</p>\n<h2 id=\"Kafka-生产者程序\"><a href=\"#Kafka-生产者程序\" class=\"headerlink\" title=\"Kafka 生产者程序\"></a>Kafka 生产者程序</h2><p>第 1 步：构造生产者对象所需的参数对象。</p>\n<p>第 2 步：利用参数对象，创建 KafkaProducer 对象实例。</p>\n<p>第 3 步：使用 KafkaProducer 的 send 方法发送消息。</p>\n<p>第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>“参数<span class=\"token number\">1</span>”<span class=\"token punctuation\">,</span> “参数<span class=\"token number\">1</span>的值”<span class=\"token punctuation\">)</span>；\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>“参数<span class=\"token number\">2</span>”<span class=\"token punctuation\">,</span> “参数<span class=\"token number\">2</span>的值”<span class=\"token punctuation\">)</span>；\n……\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>Producer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaProducer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">ProducerRecord</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span><span class=\"token punctuation\">(</span>……<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> callback<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  ……\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"生产者的TCP\"><a href=\"#生产者的TCP\" class=\"headerlink\" title=\"生产者的TCP\"></a>生产者的TCP</h2><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会<strong>创建与 Broker 的TCP连接</strong>。它会连接 <code>bootstrap.servers</code> 参数指定的所有 Broker。</p>\n<p><code>KafkaProducer</code>实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 <code>RecordAccumulator</code>类，维护了 <code>RecordAccumulator</code> 类的线程安全，也就实现了 KafkaProducer 类的线程安全。</p>\n<p><strong>其他TCP连接创建</strong></p>\n<ul>\n<li><p>当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。</p>\n</li>\n<li><p>当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。</p>\n</li>\n</ul>\n<p><strong>更新元数据场景</strong></p>\n<p>1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。</p>\n<p>2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。</p>\n<p><strong>关闭TCP连接</strong></p>\n<ul>\n<li><p>用户主动关闭</p>\n</li>\n<li><p>Kafka 自动关闭</p>\n</li>\n</ul>\n<p>connections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。</p>\n<p>可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或 <code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要<strong>事务</strong>或者依赖<strong>事务型 Producer</strong></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"消息分区机制\"><a href=\"#消息分区机制\" class=\"headerlink\" title=\"消息分区机制\"></a>消息分区机制</h2><h3 id=\"为什么分区\"><a href=\"#为什么分区\" class=\"headerlink\" title=\"为什么分区\"></a>为什么分区</h3><p>提供负载均衡的能力，实现系统的高伸缩性）。</p>\n<p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。</p>\n<h3 id=\"分区策略\"><a href=\"#分区策略\" class=\"headerlink\" title=\"分区策略\"></a>分区策略</h3><p><strong>自定义分区策略</strong></p>\n<p>编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口。这个接口只定义了两个方法：<code>partition()</code>和<code>close()</code>，一般只需要实现 <code>partition</code>方法。</p>\n<p><strong>轮询策略</strong></p>\n<p><code>Round-robin</code> 策略，即顺序分配。轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。</p>\n<p><strong>随机策略</strong></p>\n<p><code>Randomness</code>策略。所谓随机就是将消息放置到任意一个分区上。</p>\n<p><strong>按消息键保序策略</strong></p>\n<p>Kafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。</p>\n<pre><code class=\"java\">List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n\n//可以根据 Broker 所在的 IP 地址实现定制化的分区策略\nList&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(\n    p -&gt; isSouth(p.leader().host())\n).map(PartitionInfo::partition).findAny().get();</code></pre>\n<h2 id=\"压缩\"><a href=\"#压缩\" class=\"headerlink\" title=\"压缩\"></a>压缩</h2><p>Kafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。</p>\n<h3 id=\"V1-版本和-V2-版本区别\"><a href=\"#V1-版本和-V2-版本区别\" class=\"headerlink\" title=\"V1 版本和 V2 版本区别\"></a>V1 版本和 V2 版本区别</h3><p>1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。</p>\n<p>2、消息的 CRC 校验工作就被移到了消息集合这一层。</p>\n<p>3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩</p>\n<h3 id=\"何时压缩\"><a href=\"#何时压缩\" class=\"headerlink\" title=\"何时压缩\"></a>何时压缩</h3><p>1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。</p>\n<pre><code class=\"java\"> Properties props = new Properties();\n props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\n props.put(&quot;acks&quot;, &quot;all&quot;);\n props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n // 开启GZIP压缩\n props.put(&quot;compression.type&quot;, &quot;gzip&quot;);\n\n Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre>\n<p>2、Broker 重新压缩消息</p>\n<ul>\n<li><p>Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。</p>\n</li>\n<li><p>Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性</p>\n</li>\n</ul>\n<h3 id=\"解压缩\"><a href=\"#解压缩\" class=\"headerlink\" title=\"解压缩\"></a>解压缩</h3><p>通常来说解压缩发生在消费者程序中。</p>\n<p> Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。</p>\n<h3 id=\"压缩算法\"><a href=\"#压缩算法\" class=\"headerlink\" title=\"压缩算法\"></a>压缩算法</h3><p>吞吐量：LZ4 &gt; Snappy &gt; zstd 和 GZIP；</p>\n<p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy</p>\n<h2 id=\"Kafka-生产者程序\"><a href=\"#Kafka-生产者程序\" class=\"headerlink\" title=\"Kafka 生产者程序\"></a>Kafka 生产者程序</h2><p>第 1 步：构造生产者对象所需的参数对象。</p>\n<p>第 2 步：利用参数对象，创建 KafkaProducer 对象实例。</p>\n<p>第 3 步：使用 KafkaProducer 的 send 方法发送消息。</p>\n<p>第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。</p>\n<pre><code class=\"java\">Properties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props)) {\n    producer.send(new ProducerRecord&lt;String, String&gt;(……), callback);\n  ……\n}</code></pre>\n<h2 id=\"生产者的TCP\"><a href=\"#生产者的TCP\" class=\"headerlink\" title=\"生产者的TCP\"></a>生产者的TCP</h2><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会<strong>创建与 Broker 的TCP连接</strong>。它会连接 <code>bootstrap.servers</code> 参数指定的所有 Broker。</p>\n<p><code>KafkaProducer</code>实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 <code>RecordAccumulator</code>类，维护了 <code>RecordAccumulator</code> 类的线程安全，也就实现了 KafkaProducer 类的线程安全。</p>\n<p><strong>其他TCP连接创建</strong></p>\n<ul>\n<li><p>当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。</p>\n</li>\n<li><p>当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。</p>\n</li>\n</ul>\n<p><strong>更新元数据场景</strong></p>\n<p>1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。</p>\n<p>2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。</p>\n<p><strong>关闭TCP连接</strong></p>\n<ul>\n<li><p>用户主动关闭</p>\n</li>\n<li><p>Kafka 自动关闭</p>\n</li>\n</ul>\n<p>connections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。</p>\n<p>可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或 <code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要<strong>事务</strong>或者依赖<strong>事务型 Producer</strong></p>\n"},{"title":"kafka消费者","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T13:07:18.000Z","password":null,"summary":null,"_content":"\n## 消费者组\n\nConsumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\n\n- Consumer Group 下可以有一个或多个 Consumer 实例。\n- Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。\n- 单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。\n- 理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数\n\n### 重平衡\n\nRebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。\n\n协调者（Coordinator），负责为 Group 执行 **Rebalance 以及提供位移管理和组成员管理**等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。\n\n**Consumer Group 确定 Coordinator 所在的 Broker** \n\n第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：`partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)`。\n\n第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。\n\n注： Java Consumer API，能够自动发现并连接正确的 Coordinator。\n\n**Rebalance 触发条件**\n\n- 组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。\n- 订阅主题数发生变更。\n- 订阅主题的分区数发生变更。\n\n**重平衡的通知**\n\n通过心跳线程来完成。\n\n- 0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 `KafkaConsumer.poll `方法的线程。\n- 0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。\n\n**Rebalance影响**\n\n1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成\n\n2、Rebalance 效率不高，需要重新分配所有分区\n\n3、Rebalance很慢\n\n**消费者组状态机**\n\n\n![](state.jpeg)\n\n![](transport.jpg)\n\n**消费者端重平衡流程**\n\n- 加入组\n\n向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。\n\n协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。\n\n- 等待领导者消费者（Leader Consumer）分配方案\n\n领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。\n\n其他成员也会向协调者发送 SyncGroup 请求.\n\n协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。\n\n**Broker端重平衡流程**\n\n场景一：新成员入组\n\n![](newadd.jpg)\n\n场景二：组成员主动离组。\n\n![](leavegroup.jpg)\n\n场景三：组成员崩溃离组\n\n![](comsumedown.jpg)\n\n**避免 Rebalance**\n\n主要方法：**避免组成员数发生减少的情况**。\n\nConsumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。`session.timeout.ms `+ `heartbeat.interval.ms`\n\nConsumer 端应用程序两次调用` poll` 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。`max.poll.interval.ms`\n\n## 位移主题\n\n当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是`offsets.topic.num.partitions` 50，副本数是`offsets.topic.replication.factor` 3。\n\n1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 `__consumer_offsets `中。\n\n位移主题消息的 Key 中格式：<Group ID，主题名，分区号 >，消息体保存了**位移值**和位移提交的元数据，诸如时间戳和用户自定义的数据等。\n\n2、保存 Consumer Group 相关信息的消息\n\n3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息\n\n**消费位移**\n\n记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。\n\n提交位移的配置：`enable.auto.commit` + `auto.commit.interval.ms `控制。\n\n### **自动提交位移**\n\n- Kafka 会保证在开始调用 `poll` 方法时，提交上次 `poll` 返回的所有消息。\n\n- 从顺序上来说，`poll `方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。\n\n- 问题：重平衡出现时可能会出现重复消费\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\nprops.put(\"enable.auto.commit\", \"true\");\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", \n                          record.offset(), record.key(), record.value());\n}\n```\n\n### 手动提交位移\n\n**手动提交，需要将 `commitSync` 和 `commitAsync` 组合使用。**\n\n`commitSync()`会提交 `poll() `返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。\n\n缺陷：调用 `commitSync() `时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。\n\n```java\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}\n```\n\n`commitAsync()`，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数callback`，供你实现提交之后的逻辑，比如记录日志或处理异常等。\n缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。\n\n```java\ntry {\n    while(true) {\n        ConsumerRecords<String, String> records =\n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n`commitSync(Map<TopicPartition, OffsetAndMetadata>) `和 `commitAsync(Map<TopicPartition, OffsetAndMetadata>)`。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 `OffsetAndMetadata` 对象，保存位移数据。\n\n```java\nprivate Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1)；\n        if（count % 100 == 0）\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n         count++;\n    }\n}\n```\n\n### CommitFailedException\n\n提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例\n**解决**\n\n- 缩短单条消息处理的时间\n- 增加 Consumer 端允许下游系统消费一批消息的最大时长`max.poll.interval.ms` \n- 减少下游系统一次性消费的消息总数`max.poll.records `\n- 下游系统使用多线程来加速消费\n\n### **过期消息删除**\n\nkafka 使用 Compact 策略来删除位移主题中的过期消息。\n\nKafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。\n\n对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。\n\n### 重设消费者组位移\n\n由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。\n\n#### 重设位移策略\n\n![](stragey.jpg)\n\n#### 重设方式\n\n通过消费者 API 来实现。\n\n```java\nProperties consumerProperties = new Properties();\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); //禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\nString topic = \"test\";  // 要重设位移的Kafka主题 \ntry (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    consumer.poll(0);\n    consumer.seekToBeginning(\n        consumer.partitionsFor(topic).stream().map(\n            partitionInfo -> new TopicPartition(topic, partitionInfo.partition())\n   \t\t).collect(Collectors.toList()));// 需要一次性构造主题的所有分区对象\n} \n// Current\nconsumer.partitionsFor(topic).stream().map(\n    info -> new TopicPartition(topic, info.partition())\n  ).forEach(tp -> {\n  long committedOffset = consumer.committed(tp).offset();\n  consumer.seek(tp, committedOffset);\n});\n//Specified-Offset\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n  TopicPartition tp = new TopicPartition(topic, info.partition());\n  consumer.seek(tp, targetOffset);\n}\n//Shift-By-N \nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n         TopicPartition tp = new TopicPartition(topic, info.partition());\n  // 假设向前跳123条消息\n         long targetOffset = consumer.committed(tp).offset() + 123L; \n         consumer.seek(tp, targetOffset);\n}\n//DateTime \nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0).toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\nMap<TopicPartition, Long> timeToSearch = \n         consumer.partitionsFor(topic).stream().map(info -> \n  new TopicPartition(topic, info.partition()))\n  .collect(Collectors.toMap(Function.identity(), tp -> ts));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n  consumer.offsetsForTimes(timeToSearch).entrySet()) {\nconsumer.seek(entry.getKey(), entry.getValue().offset());\n}\n//Duration\n\nMap<TopicPartition, Long> timeToSearch = consumer.partitionsFor(topic).stream()\n         .map(info -> new TopicPartition(topic, info.partition()))\n         .collect(Collectors.toMap(Function.identity(), tp -> System.currentTimeMillis() - 30 * 1000  * 60));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n     consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}\n```\n\n通过 kafka-consumer-groups 命令行脚本来实现\n\n```shell\n# to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute\n```\n\n##  独立消费者\n\n每个消费者实例都是独立工作的，彼此之间毫无联系。\n\n## KafkaConsumer \n\n用户主线程，启动 Consumer 应用程序 main 方法的那个线程。\n\n心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）\n\n### 多线程方案\n\nKafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 `ConcurrentModificationException `异常\n\n1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程\n\n![](plan1.jpg)\n\n```java\n\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n\n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(\"topic\"));\n             while (!closed.get()) {\n      ConsumerRecords records = \n        consumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n\n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}\n```\n\n2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。\n\n![](plan2.jpg)\n\n```java\n\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n\n\nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n  workerNum,\n  workerNum,\n  0L, \n  TimeUnit.MILLISECONDS,\n  new ArrayBlockingQueue<>(1000), \n  new ThreadPoolExecutor.CallerRunsPolicy()\n);\n\n\n...\nwhile (true)  {\n  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n  for (final ConsumerRecord record : records) {\n    executors.submit(new Worker(record));\n  }\n}\n..\n```\n\n**方案比较**\n\n![](compare.jpg)\n\n### TCP 连接\n\n**TCP 连接是在调用 `KafkaConsumer.poll `方法时被创建的。**\n\n1.发起 `FindCoordinator` 请求时。\n\n当消费者程序首次启动调用 `poll `方法时，它需要向 Kafka 集群发送一个名为 `FindCoordinator` 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。\n\n2.连接协调者时。\n\n消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。\n\n3.消费数据时。\n\n消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP\n\n**消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。**\n\n1、手动调用` KafkaConsumer.close() `方法，或者是执行 Kill 命令\n\n2、Kafka 自动关闭是由消费者端参数 `connection.max.idle.ms` 控制的，默认值是 9 分钟\n\n注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。\n\n## 消费进度\n\n消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。\n\n**监控方法**\n\n1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。\n\n```shell\n# Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称>\n```\n\n![](groups_shell.png)\n\n2、使用 Kafka Java Consumer API 编程。\n\n```java\n\npublic static Map<TopicPartition, Long> lagOf(String groupID, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n        try {\n            //获取订阅分区的最新消息位移\n            Map<TopicPartition, OffsetAndMetadata> consumedOffsets = \n                result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n                //最新消费消息的位移\n                Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedOffsets.keySet()); \n                return endOffsets.entrySet().stream().collect(Collectors.toMap(\n                    entry -> entry.getKey(),\n                    entry -> entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            // 处理中断异常\n            // ...\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            // 处理ExecutionException\n            // ...\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(\"Timed out when getting lag for consumer group \" + groupID);\n        }\n    }\n}\n```\n\n3、使用 Kafka 自带的 JMX 监控指标。\n\nKafka 消费者的JMX 指标 `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”`，其中：`records-lag-max` 和 `records-lead-min`，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。\n\n **Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。**\n\n一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。\n\nKafka 消费者还在分区级别提供了 JMX 指标，用于监控**分区级别的 Lag 和 Lead 值**。JMX 名称为：`kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”`","source":"_posts/kafka消费者.md","raw":"---\ntitle: kafka消费者\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 21:07:18\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 消费者组\n\nConsumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\n\n- Consumer Group 下可以有一个或多个 Consumer 实例。\n- Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。\n- 单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。\n- 理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数\n\n### 重平衡\n\nRebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。\n\n协调者（Coordinator），负责为 Group 执行 **Rebalance 以及提供位移管理和组成员管理**等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。\n\n**Consumer Group 确定 Coordinator 所在的 Broker** \n\n第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：`partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)`。\n\n第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。\n\n注： Java Consumer API，能够自动发现并连接正确的 Coordinator。\n\n**Rebalance 触发条件**\n\n- 组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。\n- 订阅主题数发生变更。\n- 订阅主题的分区数发生变更。\n\n**重平衡的通知**\n\n通过心跳线程来完成。\n\n- 0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 `KafkaConsumer.poll `方法的线程。\n- 0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。\n\n**Rebalance影响**\n\n1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成\n\n2、Rebalance 效率不高，需要重新分配所有分区\n\n3、Rebalance很慢\n\n**消费者组状态机**\n\n\n![](state.jpeg)\n\n![](transport.jpg)\n\n**消费者端重平衡流程**\n\n- 加入组\n\n向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。\n\n协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。\n\n- 等待领导者消费者（Leader Consumer）分配方案\n\n领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。\n\n其他成员也会向协调者发送 SyncGroup 请求.\n\n协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。\n\n**Broker端重平衡流程**\n\n场景一：新成员入组\n\n![](newadd.jpg)\n\n场景二：组成员主动离组。\n\n![](leavegroup.jpg)\n\n场景三：组成员崩溃离组\n\n![](comsumedown.jpg)\n\n**避免 Rebalance**\n\n主要方法：**避免组成员数发生减少的情况**。\n\nConsumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。`session.timeout.ms `+ `heartbeat.interval.ms`\n\nConsumer 端应用程序两次调用` poll` 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。`max.poll.interval.ms`\n\n## 位移主题\n\n当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是`offsets.topic.num.partitions` 50，副本数是`offsets.topic.replication.factor` 3。\n\n1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 `__consumer_offsets `中。\n\n位移主题消息的 Key 中格式：<Group ID，主题名，分区号 >，消息体保存了**位移值**和位移提交的元数据，诸如时间戳和用户自定义的数据等。\n\n2、保存 Consumer Group 相关信息的消息\n\n3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息\n\n**消费位移**\n\n记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。\n\n提交位移的配置：`enable.auto.commit` + `auto.commit.interval.ms `控制。\n\n### **自动提交位移**\n\n- Kafka 会保证在开始调用 `poll` 方法时，提交上次 `poll` 返回的所有消息。\n\n- 从顺序上来说，`poll `方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。\n\n- 问题：重平衡出现时可能会出现重复消费\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\nprops.put(\"enable.auto.commit\", \"true\");\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", \n                          record.offset(), record.key(), record.value());\n}\n```\n\n### 手动提交位移\n\n**手动提交，需要将 `commitSync` 和 `commitAsync` 组合使用。**\n\n`commitSync()`会提交 `poll() `返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。\n\n缺陷：调用 `commitSync() `时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。\n\n```java\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}\n```\n\n`commitAsync()`，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数callback`，供你实现提交之后的逻辑，比如记录日志或处理异常等。\n缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。\n\n```java\ntry {\n    while(true) {\n        ConsumerRecords<String, String> records =\n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n`commitSync(Map<TopicPartition, OffsetAndMetadata>) `和 `commitAsync(Map<TopicPartition, OffsetAndMetadata>)`。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 `OffsetAndMetadata` 对象，保存位移数据。\n\n```java\nprivate Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords<String, String> records =\n        consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1)；\n        if（count % 100 == 0）\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n         count++;\n    }\n}\n```\n\n### CommitFailedException\n\n提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例\n**解决**\n\n- 缩短单条消息处理的时间\n- 增加 Consumer 端允许下游系统消费一批消息的最大时长`max.poll.interval.ms` \n- 减少下游系统一次性消费的消息总数`max.poll.records `\n- 下游系统使用多线程来加速消费\n\n### **过期消息删除**\n\nkafka 使用 Compact 策略来删除位移主题中的过期消息。\n\nKafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。\n\n对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。\n\n### 重设消费者组位移\n\n由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。\n\n#### 重设位移策略\n\n![](stragey.jpg)\n\n#### 重设方式\n\n通过消费者 API 来实现。\n\n```java\nProperties consumerProperties = new Properties();\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); //禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\nString topic = \"test\";  // 要重设位移的Kafka主题 \ntry (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    consumer.poll(0);\n    consumer.seekToBeginning(\n        consumer.partitionsFor(topic).stream().map(\n            partitionInfo -> new TopicPartition(topic, partitionInfo.partition())\n   \t\t).collect(Collectors.toList()));// 需要一次性构造主题的所有分区对象\n} \n// Current\nconsumer.partitionsFor(topic).stream().map(\n    info -> new TopicPartition(topic, info.partition())\n  ).forEach(tp -> {\n  long committedOffset = consumer.committed(tp).offset();\n  consumer.seek(tp, committedOffset);\n});\n//Specified-Offset\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n  TopicPartition tp = new TopicPartition(topic, info.partition());\n  consumer.seek(tp, targetOffset);\n}\n//Shift-By-N \nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n         TopicPartition tp = new TopicPartition(topic, info.partition());\n  // 假设向前跳123条消息\n         long targetOffset = consumer.committed(tp).offset() + 123L; \n         consumer.seek(tp, targetOffset);\n}\n//DateTime \nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0).toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\nMap<TopicPartition, Long> timeToSearch = \n         consumer.partitionsFor(topic).stream().map(info -> \n  new TopicPartition(topic, info.partition()))\n  .collect(Collectors.toMap(Function.identity(), tp -> ts));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n  consumer.offsetsForTimes(timeToSearch).entrySet()) {\nconsumer.seek(entry.getKey(), entry.getValue().offset());\n}\n//Duration\n\nMap<TopicPartition, Long> timeToSearch = consumer.partitionsFor(topic).stream()\n         .map(info -> new TopicPartition(topic, info.partition()))\n         .collect(Collectors.toMap(Function.identity(), tp -> System.currentTimeMillis() - 30 * 1000  * 60));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : \n     consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}\n```\n\n通过 kafka-consumer-groups 命令行脚本来实现\n\n```shell\n# to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute\n```\n\n##  独立消费者\n\n每个消费者实例都是独立工作的，彼此之间毫无联系。\n\n## KafkaConsumer \n\n用户主线程，启动 Consumer 应用程序 main 方法的那个线程。\n\n心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）\n\n### 多线程方案\n\nKafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 `ConcurrentModificationException `异常\n\n1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程\n\n![](plan1.jpg)\n\n```java\n\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n\n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(\"topic\"));\n             while (!closed.get()) {\n      ConsumerRecords records = \n        consumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n\n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}\n```\n\n2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。\n\n![](plan2.jpg)\n\n```java\n\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n\n\nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n  workerNum,\n  workerNum,\n  0L, \n  TimeUnit.MILLISECONDS,\n  new ArrayBlockingQueue<>(1000), \n  new ThreadPoolExecutor.CallerRunsPolicy()\n);\n\n\n...\nwhile (true)  {\n  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n  for (final ConsumerRecord record : records) {\n    executors.submit(new Worker(record));\n  }\n}\n..\n```\n\n**方案比较**\n\n![](compare.jpg)\n\n### TCP 连接\n\n**TCP 连接是在调用 `KafkaConsumer.poll `方法时被创建的。**\n\n1.发起 `FindCoordinator` 请求时。\n\n当消费者程序首次启动调用 `poll `方法时，它需要向 Kafka 集群发送一个名为 `FindCoordinator` 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。\n\n2.连接协调者时。\n\n消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。\n\n3.消费数据时。\n\n消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP\n\n**消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。**\n\n1、手动调用` KafkaConsumer.close() `方法，或者是执行 Kill 命令\n\n2、Kafka 自动关闭是由消费者端参数 `connection.max.idle.ms` 控制的，默认值是 9 分钟\n\n注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。\n\n## 消费进度\n\n消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。\n\n**监控方法**\n\n1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。\n\n```shell\n# Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称>\n```\n\n![](groups_shell.png)\n\n2、使用 Kafka Java Consumer API 编程。\n\n```java\n\npublic static Map<TopicPartition, Long> lagOf(String groupID, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n        try {\n            //获取订阅分区的最新消息位移\n            Map<TopicPartition, OffsetAndMetadata> consumedOffsets = \n                result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n                //最新消费消息的位移\n                Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedOffsets.keySet()); \n                return endOffsets.entrySet().stream().collect(Collectors.toMap(\n                    entry -> entry.getKey(),\n                    entry -> entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            // 处理中断异常\n            // ...\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            // 处理ExecutionException\n            // ...\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(\"Timed out when getting lag for consumer group \" + groupID);\n        }\n    }\n}\n```\n\n3、使用 Kafka 自带的 JMX 监控指标。\n\nKafka 消费者的JMX 指标 `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”`，其中：`records-lag-max` 和 `records-lead-min`，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。\n\n **Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。**\n\n一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。\n\nKafka 消费者还在分区级别提供了 JMX 指标，用于监控**分区级别的 Lag 和 Lead 值**。JMX 名称为：`kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”`","slug":"kafka消费者","published":1,"updated":"2021-04-01T23:01:49.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxgh001bncufekvo8dmw","content":"<h2 id=\"消费者组\"><a href=\"#消费者组\" class=\"headerlink\" title=\"消费者组\"></a>消费者组</h2><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。</p>\n<ul>\n<li>Consumer Group 下可以有一个或多个 Consumer 实例。</li>\n<li>Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li>\n<li>单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。</li>\n<li>理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数</li>\n</ul>\n<h3 id=\"重平衡\"><a href=\"#重平衡\" class=\"headerlink\" title=\"重平衡\"></a>重平衡</h3><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p>\n<p>协调者（Coordinator），负责为 Group 执行 <strong>Rebalance 以及提供位移管理和组成员管理</strong>等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。</p>\n<p><strong>Consumer Group 确定 Coordinator 所在的 Broker</strong> </p>\n<p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p>\n<p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p>\n<p>注： Java Consumer API，能够自动发现并连接正确的 Coordinator。</p>\n<p><strong>Rebalance 触发条件</strong></p>\n<ul>\n<li>组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。</li>\n<li>订阅主题数发生变更。</li>\n<li>订阅主题的分区数发生变更。</li>\n</ul>\n<p><strong>重平衡的通知</strong></p>\n<p>通过心跳线程来完成。</p>\n<ul>\n<li>0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 <code>KafkaConsumer.poll</code>方法的线程。</li>\n<li>0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。</li>\n</ul>\n<p><strong>Rebalance影响</strong></p>\n<p>1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成</p>\n<p>2、Rebalance 效率不高，需要重新分配所有分区</p>\n<p>3、Rebalance很慢</p>\n<p><strong>消费者组状态机</strong></p>\n<p><img src=\"state.jpeg\" alt></p>\n<p><img src=\"transport.jpg\" alt></p>\n<p><strong>消费者端重平衡流程</strong></p>\n<ul>\n<li>加入组</li>\n</ul>\n<p>向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。</p>\n<p>协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。</p>\n<ul>\n<li>等待领导者消费者（Leader Consumer）分配方案</li>\n</ul>\n<p>领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。</p>\n<p>其他成员也会向协调者发送 SyncGroup 请求.</p>\n<p>协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。</p>\n<p><strong>Broker端重平衡流程</strong></p>\n<p>场景一：新成员入组</p>\n<p><img src=\"newadd.jpg\" alt></p>\n<p>场景二：组成员主动离组。</p>\n<p><img src=\"leavegroup.jpg\" alt></p>\n<p>场景三：组成员崩溃离组</p>\n<p><img src=\"comsumedown.jpg\" alt></p>\n<p><strong>避免 Rebalance</strong></p>\n<p>主要方法：<strong>避免组成员数发生减少的情况</strong>。</p>\n<p>Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。<code>session.timeout.ms</code>+ <code>heartbeat.interval.ms</code></p>\n<p>Consumer 端应用程序两次调用<code>poll</code> 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。<code>max.poll.interval.ms</code></p>\n<h2 id=\"位移主题\"><a href=\"#位移主题\" class=\"headerlink\" title=\"位移主题\"></a>位移主题</h2><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是<code>offsets.topic.num.partitions</code> 50，副本数是<code>offsets.topic.replication.factor</code> 3。</p>\n<p>1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 <code>__consumer_offsets</code>中。</p>\n<p>位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等。</p>\n<p>2、保存 Consumer Group 相关信息的消息</p>\n<p>3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息</p>\n<p><strong>消费位移</strong></p>\n<p>记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。</p>\n<p>提交位移的配置：<code>enable.auto.commit</code> + <code>auto.commit.interval.ms</code>控制。</p>\n<h3 id=\"自动提交位移\"><a href=\"#自动提交位移\" class=\"headerlink\" title=\"自动提交位移\"></a><strong>自动提交位移</strong></h3><ul>\n<li><p>Kafka 会保证在开始调用 <code>poll</code> 方法时，提交上次 <code>poll</code> 返回的所有消息。</p>\n</li>\n<li><p>从顺序上来说，<code>poll</code>方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。</p>\n</li>\n<li><p>问题：重平衡出现时可能会出现重复消费</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"bootstrap.servers\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"localhost:9092\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"group.id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"test\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"enable.auto.commit\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"auto.commit.interval.ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2000\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"key.deserializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringDeserializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nprops<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"value.deserializer\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"org.apache.kafka.common.serialization.StringDeserializer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nKafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"foo\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"bar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"offset = %d, key = %s, value = %s%n\"</span><span class=\"token punctuation\">,</span> \n                          record<span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">key</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">value</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"手动提交位移\"><a href=\"#手动提交位移\" class=\"headerlink\" title=\"手动提交位移\"></a>手动提交位移</h3><p><strong>手动提交，需要将 <code>commitSync</code> 和 <code>commitAsync</code> 组合使用。</strong></p>\n<p><code>commitSync()</code>会提交 <code>poll()</code>返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。</p>\n<p>缺陷：调用 <code>commitSync()</code>时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">process</span><span class=\"token punctuation\">(</span>records<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理消息</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitSync</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">CommitFailedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token function\">handle</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理提交失败异常</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>commitAsync()</code>，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数callback`，供你实现提交之后的逻辑，比如记录日志或处理异常等。<br>缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span>\n            consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">process</span><span class=\"token punctuation\">(</span>records<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理消息</span>\n        <span class=\"token function\">commitAysnc</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 使用异步提交规避阻塞</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span><span class=\"token punctuation\">(</span>Exception e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token function\">handle</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 处理异常</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitSync</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 最后一次提交使用同步阻塞式提交</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>和 <code>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 <code>OffsetAndMetadata</code> 对象，保存位移数据。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">private</span> Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> offsets <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">int</span> count <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n……\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>ConsumerRecord<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> record<span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token function\">process</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">// 处理消息</span>\n        offsets<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">.</span><span class=\"token function\">topic</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> record<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token keyword\">new</span> <span class=\"token class-name\">OffsetAndMetadata</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>；\n        <span class=\"token keyword\">if</span>（count <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span>）\n            consumer<span class=\"token punctuation\">.</span><span class=\"token function\">commitAsync</span><span class=\"token punctuation\">(</span>offsets<span class=\"token punctuation\">,</span> null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 回调处理逻辑是null</span>\n         count<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"CommitFailedException\"><a href=\"#CommitFailedException\" class=\"headerlink\" title=\"CommitFailedException\"></a>CommitFailedException</h3><p>提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例<br><strong>解决</strong></p>\n<ul>\n<li>缩短单条消息处理的时间</li>\n<li>增加 Consumer 端允许下游系统消费一批消息的最大时长<code>max.poll.interval.ms</code> </li>\n<li>减少下游系统一次性消费的消息总数<code>max.poll.records</code></li>\n<li>下游系统使用多线程来加速消费</li>\n</ul>\n<h3 id=\"过期消息删除\"><a href=\"#过期消息删除\" class=\"headerlink\" title=\"过期消息删除\"></a><strong>过期消息删除</strong></h3><p>kafka 使用 Compact 策略来删除位移主题中的过期消息。</p>\n<p>Kafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。</p>\n<p>对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p>\n<h3 id=\"重设消费者组位移\"><a href=\"#重设消费者组位移\" class=\"headerlink\" title=\"重设消费者组位移\"></a>重设消费者组位移</h3><p>由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。</p>\n<h4 id=\"重设位移策略\"><a href=\"#重设位移策略\" class=\"headerlink\" title=\"重设位移策略\"></a>重设位移策略</h4><p><img src=\"stragey.jpg\" alt></p>\n<h4 id=\"重设方式\"><a href=\"#重设方式\" class=\"headerlink\" title=\"重设方式\"></a>重设方式</h4><p>通过消费者 API 来实现。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Properties consumerProperties <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">//禁止自动提交位移</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>GROUP_ID_CONFIG<span class=\"token punctuation\">,</span> groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>AUTO_OFFSET_RESET_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token string\">\"earliest\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconsumerProperties<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> brokerList<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\nString topic <span class=\"token operator\">=</span> <span class=\"token string\">\"test\"</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\" spellcheck=\"true\">// 要重设位移的Kafka主题 </span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>consumerProperties<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Collections<span class=\"token punctuation\">.</span><span class=\"token function\">singleton</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seekToBeginning</span><span class=\"token punctuation\">(</span>\n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>\n            partitionInfo <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> partitionInfo<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n           <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toList</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\" spellcheck=\"true\">// 需要一次性构造主题的所有分区对象</span>\n<span class=\"token punctuation\">}</span> \n<span class=\"token comment\" spellcheck=\"true\">// Current</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>\n    info <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">forEach</span><span class=\"token punctuation\">(</span>tp <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">long</span> committedOffset <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">committed</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> committedOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">//Specified-Offset</span>\n<span class=\"token keyword\">long</span> targetOffset <span class=\"token operator\">=</span> 1234L<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>PartitionInfo info <span class=\"token operator\">:</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  TopicPartition tp <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> targetOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//Shift-By-N </span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>PartitionInfo info <span class=\"token operator\">:</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         TopicPartition tp <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\" spellcheck=\"true\">// 假设向前跳123条消息</span>\n         <span class=\"token keyword\">long</span> targetOffset <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">committed</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> 123L<span class=\"token punctuation\">;</span> \n         consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>tp<span class=\"token punctuation\">,</span> targetOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//DateTime </span>\n<span class=\"token keyword\">long</span> ts <span class=\"token operator\">=</span> LocalDateTime<span class=\"token punctuation\">.</span><span class=\"token function\">of</span><span class=\"token punctuation\">(</span><span class=\"token number\">2019</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">toInstant</span><span class=\"token punctuation\">(</span>ZoneOffset<span class=\"token punctuation\">.</span><span class=\"token function\">ofHours</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">toEpochMilli</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nMap<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> timeToSearch <span class=\"token operator\">=</span> \n         consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>info <span class=\"token operator\">-</span><span class=\"token operator\">></span> \n  <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toMap</span><span class=\"token punctuation\">(</span>Function<span class=\"token punctuation\">.</span><span class=\"token function\">identity</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tp <span class=\"token operator\">-</span><span class=\"token operator\">></span> ts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Map<span class=\"token punctuation\">.</span>Entry<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndTimestamp<span class=\"token operator\">></span> entry <span class=\"token operator\">:</span> \n  consumer<span class=\"token punctuation\">.</span><span class=\"token function\">offsetsForTimes</span><span class=\"token punctuation\">(</span>timeToSearch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">entrySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//Duration</span>\n\nMap<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> timeToSearch <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsFor</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n         <span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>info <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TopicPartition</span><span class=\"token punctuation\">(</span>topic<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">.</span><span class=\"token function\">partition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n         <span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toMap</span><span class=\"token punctuation\">(</span>Function<span class=\"token punctuation\">.</span><span class=\"token function\">identity</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tp <span class=\"token operator\">-</span><span class=\"token operator\">></span> System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">30</span> <span class=\"token operator\">*</span> <span class=\"token number\">1000</span>  <span class=\"token operator\">*</span> <span class=\"token number\">60</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Map<span class=\"token punctuation\">.</span>Entry<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndTimestamp<span class=\"token operator\">></span> entry <span class=\"token operator\">:</span> \n     consumer<span class=\"token punctuation\">.</span><span class=\"token function\">offsetsForTimes</span><span class=\"token punctuation\">(</span>timeToSearch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">entrySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    consumer<span class=\"token punctuation\">.</span><span class=\"token function\">seek</span><span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>通过 kafka-consumer-groups 命令行脚本来实现</p>\n<pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"独立消费者\"><a href=\"#独立消费者\" class=\"headerlink\" title=\"独立消费者\"></a>独立消费者</h2><p>每个消费者实例都是独立工作的，彼此之间毫无联系。</p>\n<h2 id=\"KafkaConsumer\"><a href=\"#KafkaConsumer\" class=\"headerlink\" title=\"KafkaConsumer\"></a>KafkaConsumer</h2><p>用户主线程，启动 Consumer 应用程序 main 方法的那个线程。</p>\n<p>心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）</p>\n<h3 id=\"多线程方案\"><a href=\"#多线程方案\" class=\"headerlink\" title=\"多线程方案\"></a>多线程方案</h3><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p>\n<p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p>\n<p><img src=\"plan1.jpg\" alt></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">KafkaConsumerRunner</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Runnable</span> <span class=\"token punctuation\">{</span>\n     <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> AtomicBoolean closed <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AtomicBoolean</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> KafkaConsumer consumer<span class=\"token punctuation\">;</span>\n\n     <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n             consumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>Arrays<span class=\"token punctuation\">.</span><span class=\"token function\">asList</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"topic\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n             <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>closed<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      ConsumerRecords records <span class=\"token operator\">=</span> \n        consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofMillis</span><span class=\"token punctuation\">(</span><span class=\"token number\">10000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                 <span class=\"token comment\" spellcheck=\"true\">//  执行消息处理逻辑</span>\n             <span class=\"token punctuation\">}</span>\n         <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">WakeupException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n             <span class=\"token comment\" spellcheck=\"true\">// Ignore exception if closing</span>\n             <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>closed<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throw</span> e<span class=\"token punctuation\">;</span>\n         <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n             consumer<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         <span class=\"token punctuation\">}</span>\n     <span class=\"token punctuation\">}</span>\n\n     <span class=\"token comment\" spellcheck=\"true\">// Shutdown hook which can be called from a separate thread</span>\n     <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">shutdown</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         closed<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         consumer<span class=\"token punctuation\">.</span><span class=\"token function\">wakeup</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n     <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p>\n<p><img src=\"plan2.jpg\" alt></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">private</span> ExecutorService executors<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n\n<span class=\"token keyword\">private</span> <span class=\"token keyword\">int</span> workerNum <span class=\"token operator\">=</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">;</span>\nexecutors <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ThreadPoolExecutor</span><span class=\"token punctuation\">(</span>\n  workerNum<span class=\"token punctuation\">,</span>\n  workerNum<span class=\"token punctuation\">,</span>\n  0L<span class=\"token punctuation\">,</span> \n  TimeUnit<span class=\"token punctuation\">.</span>MILLISECONDS<span class=\"token punctuation\">,</span>\n  <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayBlockingQueue</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> \n  <span class=\"token keyword\">new</span> <span class=\"token class-name\">ThreadPoolExecutor<span class=\"token punctuation\">.</span>CallerRunsPolicy</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span>  <span class=\"token punctuation\">{</span>\n  ConsumerRecords<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span>Duration<span class=\"token punctuation\">.</span><span class=\"token function\">ofSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> ConsumerRecord record <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    executors<span class=\"token punctuation\">.</span><span class=\"token function\">submit</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">Worker</span><span class=\"token punctuation\">(</span>record<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>方案比较</strong></p>\n<p><img src=\"compare.jpg\" alt></p>\n<h3 id=\"TCP-连接\"><a href=\"#TCP-连接\" class=\"headerlink\" title=\"TCP 连接\"></a>TCP 连接</h3><p><strong>TCP 连接是在调用 <code>KafkaConsumer.poll</code>方法时被创建的。</strong></p>\n<p>1.发起 <code>FindCoordinator</code> 请求时。</p>\n<p>当消费者程序首次启动调用 <code>poll</code>方法时，它需要向 Kafka 集群发送一个名为 <code>FindCoordinator</code> 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。</p>\n<p>2.连接协调者时。</p>\n<p>消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。</p>\n<p>3.消费数据时。</p>\n<p>消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP</p>\n<p><strong>消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。</strong></p>\n<p>1、手动调用<code>KafkaConsumer.close()</code>方法，或者是执行 Kill 命令</p>\n<p>2、Kafka 自动关闭是由消费者端参数 <code>connection.max.idle.ms</code> 控制的，默认值是 9 分钟</p>\n<p>注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。</p>\n<h2 id=\"消费进度\"><a href=\"#消费进度\" class=\"headerlink\" title=\"消费进度\"></a>消费进度</h2><p>消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。</p>\n<p><strong>监控方法</strong></p>\n<p>1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。</p>\n<pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><img src=\"groups_shell.png\" alt></p>\n<p>2、使用 Kafka Java Consumer API 编程。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> <span class=\"token function\">lagOf</span><span class=\"token punctuation\">(</span>String groupID<span class=\"token punctuation\">,</span> String bootstrapServers<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> TimeoutException <span class=\"token punctuation\">{</span>\n    Properties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>CommonClientConfigs<span class=\"token punctuation\">.</span>BOOTSTRAP_SERVERS_CONFIG<span class=\"token punctuation\">,</span> bootstrapServers<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span>AdminClient client <span class=\"token operator\">=</span> AdminClient<span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        ListConsumerGroupOffsetsResult result <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span><span class=\"token function\">listConsumerGroupOffsets</span><span class=\"token punctuation\">(</span>groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token comment\" spellcheck=\"true\">//获取订阅分区的最新消息位移</span>\n            Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> OffsetAndMetadata<span class=\"token operator\">></span> consumedOffsets <span class=\"token operator\">=</span> \n                result<span class=\"token punctuation\">.</span><span class=\"token function\">partitionsToOffsetAndMetadata</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> TimeUnit<span class=\"token punctuation\">.</span>SECONDS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 禁止自动提交位移</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>GROUP_ID_CONFIG<span class=\"token punctuation\">,</span> groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            props<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span>ConsumerConfig<span class=\"token punctuation\">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class=\"token punctuation\">,</span> StringDeserializer<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> KafkaConsumer<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token comment\" spellcheck=\"true\">//最新消费消息的位移</span>\n                Map<span class=\"token operator\">&lt;</span>TopicPartition<span class=\"token punctuation\">,</span> Long<span class=\"token operator\">></span> endOffsets <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">endOffsets</span><span class=\"token punctuation\">(</span>consumedOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">keySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n                <span class=\"token keyword\">return</span> endOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">entrySet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>Collectors<span class=\"token punctuation\">.</span><span class=\"token function\">toMap</span><span class=\"token punctuation\">(</span>\n                    entry <span class=\"token operator\">-</span><span class=\"token operator\">></span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    entry <span class=\"token operator\">-</span><span class=\"token operator\">></span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> consumedOffsets<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">offset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">InterruptedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            Thread<span class=\"token punctuation\">.</span><span class=\"token function\">currentThread</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">interrupt</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token comment\" spellcheck=\"true\">// 处理中断异常</span>\n            <span class=\"token comment\" spellcheck=\"true\">// ...</span>\n            <span class=\"token keyword\">return</span> Collections<span class=\"token punctuation\">.</span><span class=\"token function\">emptyMap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">ExecutionException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token comment\" spellcheck=\"true\">// 处理ExecutionException</span>\n            <span class=\"token comment\" spellcheck=\"true\">// ...</span>\n            <span class=\"token keyword\">return</span> Collections<span class=\"token punctuation\">.</span><span class=\"token function\">emptyMap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">TimeoutException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TimeoutException</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Timed out when getting lag for consumer group \"</span> <span class=\"token operator\">+</span> groupID<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>3、使用 Kafka 自带的 JMX 监控指标。</p>\n<p>Kafka 消费者的JMX 指标 <code>kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”</code>，其中：<code>records-lag-max</code> 和 <code>records-lead-min</code>，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。</p>\n<p> <strong>Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。</strong></p>\n<p>一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。</p>\n<p>Kafka 消费者还在分区级别提供了 JMX 指标，用于监控<strong>分区级别的 Lag 和 Lead 值</strong>。JMX 名称为：<code>kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”</code></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"消费者组\"><a href=\"#消费者组\" class=\"headerlink\" title=\"消费者组\"></a>消费者组</h2><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。</p>\n<ul>\n<li>Consumer Group 下可以有一个或多个 Consumer 实例。</li>\n<li>Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li>\n<li>单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。</li>\n<li>理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数</li>\n</ul>\n<h3 id=\"重平衡\"><a href=\"#重平衡\" class=\"headerlink\" title=\"重平衡\"></a>重平衡</h3><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p>\n<p>协调者（Coordinator），负责为 Group 执行 <strong>Rebalance 以及提供位移管理和组成员管理</strong>等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。</p>\n<p><strong>Consumer Group 确定 Coordinator 所在的 Broker</strong> </p>\n<p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p>\n<p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p>\n<p>注： Java Consumer API，能够自动发现并连接正确的 Coordinator。</p>\n<p><strong>Rebalance 触发条件</strong></p>\n<ul>\n<li>组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。</li>\n<li>订阅主题数发生变更。</li>\n<li>订阅主题的分区数发生变更。</li>\n</ul>\n<p><strong>重平衡的通知</strong></p>\n<p>通过心跳线程来完成。</p>\n<ul>\n<li>0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 <code>KafkaConsumer.poll</code>方法的线程。</li>\n<li>0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。</li>\n</ul>\n<p><strong>Rebalance影响</strong></p>\n<p>1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成</p>\n<p>2、Rebalance 效率不高，需要重新分配所有分区</p>\n<p>3、Rebalance很慢</p>\n<p><strong>消费者组状态机</strong></p>\n<p><img src=\"state.jpeg\" alt></p>\n<p><img src=\"transport.jpg\" alt></p>\n<p><strong>消费者端重平衡流程</strong></p>\n<ul>\n<li>加入组</li>\n</ul>\n<p>向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。</p>\n<p>协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。</p>\n<ul>\n<li>等待领导者消费者（Leader Consumer）分配方案</li>\n</ul>\n<p>领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。</p>\n<p>其他成员也会向协调者发送 SyncGroup 请求.</p>\n<p>协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。</p>\n<p><strong>Broker端重平衡流程</strong></p>\n<p>场景一：新成员入组</p>\n<p><img src=\"newadd.jpg\" alt></p>\n<p>场景二：组成员主动离组。</p>\n<p><img src=\"leavegroup.jpg\" alt></p>\n<p>场景三：组成员崩溃离组</p>\n<p><img src=\"comsumedown.jpg\" alt></p>\n<p><strong>避免 Rebalance</strong></p>\n<p>主要方法：<strong>避免组成员数发生减少的情况</strong>。</p>\n<p>Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。<code>session.timeout.ms</code>+ <code>heartbeat.interval.ms</code></p>\n<p>Consumer 端应用程序两次调用<code>poll</code> 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。<code>max.poll.interval.ms</code></p>\n<h2 id=\"位移主题\"><a href=\"#位移主题\" class=\"headerlink\" title=\"位移主题\"></a>位移主题</h2><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是<code>offsets.topic.num.partitions</code> 50，副本数是<code>offsets.topic.replication.factor</code> 3。</p>\n<p>1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 <code>__consumer_offsets</code>中。</p>\n<p>位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等。</p>\n<p>2、保存 Consumer Group 相关信息的消息</p>\n<p>3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息</p>\n<p><strong>消费位移</strong></p>\n<p>记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。</p>\n<p>提交位移的配置：<code>enable.auto.commit</code> + <code>auto.commit.interval.ms</code>控制。</p>\n<h3 id=\"自动提交位移\"><a href=\"#自动提交位移\" class=\"headerlink\" title=\"自动提交位移\"></a><strong>自动提交位移</strong></h3><ul>\n<li><p>Kafka 会保证在开始调用 <code>poll</code> 方法时，提交上次 <code>poll</code> 返回的所有消息。</p>\n</li>\n<li><p>从顺序上来说，<code>poll</code>方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。</p>\n</li>\n<li><p>问题：重平衡出现时可能会出现重复消费</p>\n</li>\n</ul>\n<pre><code class=\"java\">Properties props = new Properties();\nprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\nprops.put(&quot;group.id&quot;, &quot;test&quot;);\nprops.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);\nprops.put(&quot;auto.commit.interval.ms&quot;, &quot;2000&quot;);\nprops.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nprops.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nKafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);\nconsumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));\nwhile (true) {\n    ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);\n    for (ConsumerRecord&lt;String, String&gt; record : records)\n        System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, \n                          record.offset(), record.key(), record.value());\n}</code></pre>\n<h3 id=\"手动提交位移\"><a href=\"#手动提交位移\" class=\"headerlink\" title=\"手动提交位移\"></a>手动提交位移</h3><p><strong>手动提交，需要将 <code>commitSync</code> 和 <code>commitAsync</code> 组合使用。</strong></p>\n<p><code>commitSync()</code>会提交 <code>poll()</code>返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。</p>\n<p>缺陷：调用 <code>commitSync()</code>时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。</p>\n<pre><code class=\"java\">while (true) {\n    ConsumerRecords&lt;String, String&gt; records =\n        consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}</code></pre>\n<p><code>commitAsync()</code>，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数callback`，供你实现提交之后的逻辑，比如记录日志或处理异常等。<br>缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。</p>\n<pre><code class=\"java\">try {\n    while(true) {\n        ConsumerRecords&lt;String, String&gt; records =\n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}</code></pre>\n<p><code>commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>和 <code>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 <code>OffsetAndMetadata</code> 对象，保存位移数据。</p>\n<pre><code class=\"java\">private Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords&lt;String, String&gt; records =\n        consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord&lt;String, String&gt; record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1)；\n        if（count % 100 == 0）\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n         count++;\n    }\n}</code></pre>\n<h3 id=\"CommitFailedException\"><a href=\"#CommitFailedException\" class=\"headerlink\" title=\"CommitFailedException\"></a>CommitFailedException</h3><p>提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例<br><strong>解决</strong></p>\n<ul>\n<li>缩短单条消息处理的时间</li>\n<li>增加 Consumer 端允许下游系统消费一批消息的最大时长<code>max.poll.interval.ms</code> </li>\n<li>减少下游系统一次性消费的消息总数<code>max.poll.records</code></li>\n<li>下游系统使用多线程来加速消费</li>\n</ul>\n<h3 id=\"过期消息删除\"><a href=\"#过期消息删除\" class=\"headerlink\" title=\"过期消息删除\"></a><strong>过期消息删除</strong></h3><p>kafka 使用 Compact 策略来删除位移主题中的过期消息。</p>\n<p>Kafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。</p>\n<p>对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p>\n<h3 id=\"重设消费者组位移\"><a href=\"#重设消费者组位移\" class=\"headerlink\" title=\"重设消费者组位移\"></a>重设消费者组位移</h3><p>由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。</p>\n<h4 id=\"重设位移策略\"><a href=\"#重设位移策略\" class=\"headerlink\" title=\"重设位移策略\"></a>重设位移策略</h4><p><img src=\"stragey.jpg\" alt></p>\n<h4 id=\"重设方式\"><a href=\"#重设方式\" class=\"headerlink\" title=\"重设方式\"></a>重设方式</h4><p>通过消费者 API 来实现。</p>\n<pre><code class=\"java\">Properties consumerProperties = new Properties();\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); //禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\nString topic = &quot;test&quot;;  // 要重设位移的Kafka主题 \ntry (final KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    consumer.poll(0);\n    consumer.seekToBeginning(\n        consumer.partitionsFor(topic).stream().map(\n            partitionInfo -&gt; new TopicPartition(topic, partitionInfo.partition())\n           ).collect(Collectors.toList()));// 需要一次性构造主题的所有分区对象\n} \n// Current\nconsumer.partitionsFor(topic).stream().map(\n    info -&gt; new TopicPartition(topic, info.partition())\n  ).forEach(tp -&gt; {\n  long committedOffset = consumer.committed(tp).offset();\n  consumer.seek(tp, committedOffset);\n});\n//Specified-Offset\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n  TopicPartition tp = new TopicPartition(topic, info.partition());\n  consumer.seek(tp, targetOffset);\n}\n//Shift-By-N \nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n         TopicPartition tp = new TopicPartition(topic, info.partition());\n  // 假设向前跳123条消息\n         long targetOffset = consumer.committed(tp).offset() + 123L; \n         consumer.seek(tp, targetOffset);\n}\n//DateTime \nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0).toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\nMap&lt;TopicPartition, Long&gt; timeToSearch = \n         consumer.partitionsFor(topic).stream().map(info -&gt; \n  new TopicPartition(topic, info.partition()))\n  .collect(Collectors.toMap(Function.identity(), tp -&gt; ts));\n\nfor (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : \n  consumer.offsetsForTimes(timeToSearch).entrySet()) {\nconsumer.seek(entry.getKey(), entry.getValue().offset());\n}\n//Duration\n\nMap&lt;TopicPartition, Long&gt; timeToSearch = consumer.partitionsFor(topic).stream()\n         .map(info -&gt; new TopicPartition(topic, info.partition()))\n         .collect(Collectors.toMap(Function.identity(), tp -&gt; System.currentTimeMillis() - 30 * 1000  * 60));\n\nfor (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : \n     consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}</code></pre>\n<p>通过 kafka-consumer-groups 命令行脚本来实现</p>\n<pre><code class=\"shell\"># to-earliest\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute\n# Latest \nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset &lt;offset&gt; --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by &lt;offset_N&gt; --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute\n\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute</code></pre>\n<h2 id=\"独立消费者\"><a href=\"#独立消费者\" class=\"headerlink\" title=\"独立消费者\"></a>独立消费者</h2><p>每个消费者实例都是独立工作的，彼此之间毫无联系。</p>\n<h2 id=\"KafkaConsumer\"><a href=\"#KafkaConsumer\" class=\"headerlink\" title=\"KafkaConsumer\"></a>KafkaConsumer</h2><p>用户主线程，启动 Consumer 应用程序 main 方法的那个线程。</p>\n<p>心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）</p>\n<h3 id=\"多线程方案\"><a href=\"#多线程方案\" class=\"headerlink\" title=\"多线程方案\"></a>多线程方案</h3><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p>\n<p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p>\n<p><img src=\"plan1.jpg\" alt></p>\n<pre><code class=\"java\">\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n\n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(&quot;topic&quot;));\n             while (!closed.get()) {\n      ConsumerRecords records = \n        consumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n\n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}</code></pre>\n<p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p>\n<p><img src=\"plan2.jpg\" alt></p>\n<pre><code class=\"java\">\nprivate final KafkaConsumer&lt;String, String&gt; consumer;\nprivate ExecutorService executors;\n...\n\n\nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n  workerNum,\n  workerNum,\n  0L, \n  TimeUnit.MILLISECONDS,\n  new ArrayBlockingQueue&lt;&gt;(1000), \n  new ThreadPoolExecutor.CallerRunsPolicy()\n);\n\n\n...\nwhile (true)  {\n  ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));\n  for (final ConsumerRecord record : records) {\n    executors.submit(new Worker(record));\n  }\n}\n..</code></pre>\n<p><strong>方案比较</strong></p>\n<p><img src=\"compare.jpg\" alt></p>\n<h3 id=\"TCP-连接\"><a href=\"#TCP-连接\" class=\"headerlink\" title=\"TCP 连接\"></a>TCP 连接</h3><p><strong>TCP 连接是在调用 <code>KafkaConsumer.poll</code>方法时被创建的。</strong></p>\n<p>1.发起 <code>FindCoordinator</code> 请求时。</p>\n<p>当消费者程序首次启动调用 <code>poll</code>方法时，它需要向 Kafka 集群发送一个名为 <code>FindCoordinator</code> 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。</p>\n<p>2.连接协调者时。</p>\n<p>消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。</p>\n<p>3.消费数据时。</p>\n<p>消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP</p>\n<p><strong>消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。</strong></p>\n<p>1、手动调用<code>KafkaConsumer.close()</code>方法，或者是执行 Kill 命令</p>\n<p>2、Kafka 自动关闭是由消费者端参数 <code>connection.max.idle.ms</code> 控制的，默认值是 9 分钟</p>\n<p>注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。</p>\n<h2 id=\"消费进度\"><a href=\"#消费进度\" class=\"headerlink\" title=\"消费进度\"></a>消费进度</h2><p>消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。</p>\n<p><strong>监控方法</strong></p>\n<p>1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。</p>\n<pre><code class=\"shell\"># Kafka 连接信息就是 &lt; 主机名：端口 &gt; 对，而 group 名称就是消费者程序中设置的 group.id 值.\n$ bin/kafka-consumer-groups.sh --bootstrap-server &lt;Kafka broker连接信息&gt; --describe --group &lt;group名称&gt;</code></pre>\n<p><img src=\"groups_shell.png\" alt></p>\n<p>2、使用 Kafka Java Consumer API 编程。</p>\n<pre><code class=\"java\">\npublic static Map&lt;TopicPartition, Long&gt; lagOf(String groupID, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupID);\n        try {\n            //获取订阅分区的最新消息位移\n            Map&lt;TopicPartition, OffsetAndMetadata&gt; consumedOffsets = \n                result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props)) {\n                //最新消费消息的位移\n                Map&lt;TopicPartition, Long&gt; endOffsets = consumer.endOffsets(consumedOffsets.keySet()); \n                return endOffsets.entrySet().stream().collect(Collectors.toMap(\n                    entry -&gt; entry.getKey(),\n                    entry -&gt; entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            // 处理中断异常\n            // ...\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            // 处理ExecutionException\n            // ...\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(&quot;Timed out when getting lag for consumer group &quot; + groupID);\n        }\n    }\n}</code></pre>\n<p>3、使用 Kafka 自带的 JMX 监控指标。</p>\n<p>Kafka 消费者的JMX 指标 <code>kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”</code>，其中：<code>records-lag-max</code> 和 <code>records-lead-min</code>，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。</p>\n<p> <strong>Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。</strong></p>\n<p>一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。</p>\n<p>Kafka 消费者还在分区级别提供了 JMX 指标，用于监控<strong>分区级别的 Lag 和 Lead 值</strong>。JMX 名称为：<code>kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”</code></p>\n"},{"title":"kafka精确一次","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-23T12:59:45.000Z","password":null,"summary":null,"_content":"\nkafka通过**幂等性（Idempotence）**和**事务（Transaction）**实现消息精确一次（exactly once）的可靠性保障。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或` props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要依赖**事务型 Producer**.\n\n## **事务型 Producer**\n\n事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。\n\n设置事务型 Producer 的方法：\n\n- 开启`enable.idempotence = true`。\n\n- 设置 Producer 端参数` transactional.id`。最好为其设置一个有意义的名字。\n\n```java\nproducer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(record1);\n    producer.send(record2);\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}\n```\n\n`isolation.level`支持`read_uncommitted`和`read_committed`","source":"_posts/kafka精确一次.md","raw":"---\ntitle: kafka精确一次\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-23 20:59:45\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\nkafka通过**幂等性（Idempotence）**和**事务（Transaction）**实现消息精确一次（exactly once）的可靠性保障。\n\n## 幂等性 Producer\n\n设置`props.put(“enable.idempotence”, ture)`，或` props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)`\n\n**底层原理：**用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。\n\n**作用范围：**它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。\n\n多分区以及多会话上的消息无重复，需要依赖**事务型 Producer**.\n\n## **事务型 Producer**\n\n事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。\n\n设置事务型 Producer 的方法：\n\n- 开启`enable.idempotence = true`。\n\n- 设置 Producer 端参数` transactional.id`。最好为其设置一个有意义的名字。\n\n```java\nproducer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(record1);\n    producer.send(record2);\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}\n```\n\n`isolation.level`支持`read_uncommitted`和`read_committed`","slug":"kafka精确一次","published":1,"updated":"2021-04-01T23:01:49.856Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxgj001dncufnlvfhqh5","content":"<p>kafka通过<strong>幂等性（Idempotence）</strong>和<strong>事务（Transaction）</strong>实现消息精确一次（exactly once）的可靠性保障。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或<code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要依赖<strong>事务型 Producer</strong>.</p>\n<h2 id=\"事务型-Producer\"><a href=\"#事务型-Producer\" class=\"headerlink\" title=\"事务型 Producer\"></a><strong>事务型 Producer</strong></h2><p>事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。</p>\n<p>设置事务型 Producer 的方法：</p>\n<ul>\n<li><p>开启<code>enable.idempotence = true</code>。</p>\n</li>\n<li><p>设置 Producer 端参数<code>transactional.id</code>。最好为其设置一个有意义的名字。</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">producer<span class=\"token punctuation\">.</span><span class=\"token function\">initTransactions</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">beginTransaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span>record1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span>record2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">commitTransaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">KafkaException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    producer<span class=\"token punctuation\">.</span><span class=\"token function\">abortTransaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><code>isolation.level</code>支持<code>read_uncommitted</code>和<code>read_committed</code></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>kafka通过<strong>幂等性（Idempotence）</strong>和<strong>事务（Transaction）</strong>实现消息精确一次（exactly once）的可靠性保障。</p>\n<h2 id=\"幂等性-Producer\"><a href=\"#幂等性-Producer\" class=\"headerlink\" title=\"幂等性 Producer\"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或<code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code></p>\n<p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p>\n<p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p>\n<p>多分区以及多会话上的消息无重复，需要依赖<strong>事务型 Producer</strong>.</p>\n<h2 id=\"事务型-Producer\"><a href=\"#事务型-Producer\" class=\"headerlink\" title=\"事务型 Producer\"></a><strong>事务型 Producer</strong></h2><p>事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。</p>\n<p>设置事务型 Producer 的方法：</p>\n<ul>\n<li><p>开启<code>enable.idempotence = true</code>。</p>\n</li>\n<li><p>设置 Producer 端参数<code>transactional.id</code>。最好为其设置一个有意义的名字。</p>\n</li>\n</ul>\n<pre><code class=\"java\">producer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(record1);\n    producer.send(record2);\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}</code></pre>\n<p><code>isolation.level</code>支持<code>read_uncommitted</code>和<code>read_committed</code></p>\n"},{"title":"kafka脚本","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T11:52:44.000Z","password":null,"summary":null,"_content":"\n## 生产消息\n\n```shell\n# 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n>\n```\n\n## 消费消息\n\n```shell\n# 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false \n```\n\n## 测试生产者性能\n\n```shell\n# 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.\n```\n\n## 测试消费者性能\n\n```shell\n$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012\n```\n\n## 查看主题消息总数\n\n```shell\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w\n```\n\n## 查看消息文件数据\n\n```shell\n\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n```\n\n## 查看消费者组位移\n\n```shell\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe--group test-group\n```\n\n","source":"_posts/kafka脚本.md","raw":"---\ntitle: kafka脚本\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 19:52:44\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 生产消息\n\n```shell\n# 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n>\n```\n\n## 消费消息\n\n```shell\n# 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false \n```\n\n## 测试生产者性能\n\n```shell\n# 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.\n```\n\n## 测试消费者性能\n\n```shell\n$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012\n```\n\n## 查看主题消息总数\n\n```shell\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w\n```\n\n## 查看消息文件数据\n\n```shell\n\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n```\n\n## 查看消费者组位移\n\n```shell\nbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe--group test-group\n```\n\n","slug":"kafka脚本","published":1,"updated":"2021-04-01T23:01:49.876Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxgl001fncufwc1pct05","content":"<h2 id=\"生产消息\"><a href=\"#生产消息\" class=\"headerlink\" title=\"生产消息\"></a>生产消息</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h2 id=\"测试生产者性能\"><a href=\"#测试生产者性能\" class=\"headerlink\" title=\"测试生产者性能\"></a>测试生产者性能</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"测试消费者性能\"><a href=\"#测试消费者性能\" class=\"headerlink\" title=\"测试消费者性能\"></a>测试消费者性能</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看主题消息总数\"><a href=\"#查看主题消息总数\" class=\"headerlink\" title=\"查看主题消息总数\"></a>查看主题消息总数</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看消息文件数据\"><a href=\"#查看消息文件数据\" class=\"headerlink\" title=\"查看消息文件数据\"></a>查看消息文件数据</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"查看消费者组位移\"><a href=\"#查看消费者组位移\" class=\"headerlink\" title=\"查看消费者组位移\"></a>查看消费者组位移</h2><pre class=\"line-numbers language-shell\"><code class=\"language-shell\">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe--group test-group<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"生产消息\"><a href=\"#生产消息\" class=\"headerlink\" title=\"生产消息\"></a>生产消息</h2><pre><code class=\"shell\"># 使用控制台来向 Kafka 的指定主题发送消息\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n&gt;</code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><pre><code class=\"shell\"># 禁掉了自动提交位移,一些简单的测试\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false </code></pre>\n<h2 id=\"测试生产者性能\"><a href=\"#测试生产者性能\" class=\"headerlink\" title=\"测试生产者性能\"></a>测试生产者性能</h2><pre><code class=\"shell\"># 向指定主题发送了 1 千万条消息，每条消息大小是 1K\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n\n2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.\n4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.\n10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.</code></pre>\n<h2 id=\"测试消费者性能\"><a href=\"#测试消费者性能\" class=\"headerlink\" title=\"测试消费者性能\"></a>测试消费者性能</h2><pre><code class=\"shell\">$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012</code></pre>\n<h2 id=\"查看主题消息总数\"><a href=\"#查看主题消息总数\" class=\"headerlink\" title=\"查看主题消息总数\"></a>查看主题消息总数</h2><pre><code class=\"shell\">$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n\n#最早位移\ntest-topic:0:0\ntest-topic:1:0\n\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n# 最新位移\ntest-topic:0:5500000 + 5500000 \ntest-topic:1:5500000\n# 5500000 + 5500000 =1100w</code></pre>\n<h2 id=\"查看消息文件数据\"><a href=\"#查看消息文件数据\" class=\"headerlink\" title=\"查看消息文件数据\"></a>查看消息文件数据</h2><pre><code class=\"shell\">\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log \nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......\n\n# 查看详细信息\n$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration\nDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true\n| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n......\n| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true\n......</code></pre>\n<h2 id=\"查看消费者组位移\"><a href=\"#查看消费者组位移\" class=\"headerlink\" title=\"查看消费者组位移\"></a>查看消费者组位移</h2><pre><code class=\"shell\">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe--group test-group</code></pre>\n"},{"title":"kafka认证","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-29T13:37:09.000Z","password":null,"summary":null,"_content":"\n认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。\n\n## Kafka 认证机制\n\n**基于 SSL 的认证**主要是指 Broker 和客户端的双路认证。\n\n客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。\n\n**基于 SASL 的安全认证机制**\n\nSASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：\n\nGSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。\n\nPLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。\n\nSCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。\n\nOAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。\n\nDelegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。\n\n## 认证机制的比较\n\n可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。\n\n![](compare.jpg)\n\n","source":"_posts/kafka认证.md","raw":"---\ntitle: kafka认证\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-29 21:37:09\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。\n\n## Kafka 认证机制\n\n**基于 SSL 的认证**主要是指 Broker 和客户端的双路认证。\n\n客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。\n\n**基于 SASL 的安全认证机制**\n\nSASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：\n\nGSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。\n\nPLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。\n\nSCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。\n\nOAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。\n\nDelegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。\n\n## 认证机制的比较\n\n可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。\n\n![](compare.jpg)\n\n","slug":"kafka认证","published":1,"updated":"2021-04-02T13:46:25.827Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxgo001incufg0inc3ip","content":"<p>认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。</p>\n<h2 id=\"Kafka-认证机制\"><a href=\"#Kafka-认证机制\" class=\"headerlink\" title=\"Kafka 认证机制\"></a>Kafka 认证机制</h2><p><strong>基于 SSL 的认证</strong>主要是指 Broker 和客户端的双路认证。</p>\n<p>客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。</p>\n<p><strong>基于 SASL 的安全认证机制</strong></p>\n<p>SASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：</p>\n<p>GSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。</p>\n<p>PLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。</p>\n<p>SCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。</p>\n<p>OAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。</p>\n<p>Delegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。</p>\n<h2 id=\"认证机制的比较\"><a href=\"#认证机制的比较\" class=\"headerlink\" title=\"认证机制的比较\"></a>认证机制的比较</h2><p>可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。</p>\n<p><img src=\"compare.jpg\" alt></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。</p>\n<h2 id=\"Kafka-认证机制\"><a href=\"#Kafka-认证机制\" class=\"headerlink\" title=\"Kafka 认证机制\"></a>Kafka 认证机制</h2><p><strong>基于 SSL 的认证</strong>主要是指 Broker 和客户端的双路认证。</p>\n<p>客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。</p>\n<p><strong>基于 SASL 的安全认证机制</strong></p>\n<p>SASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：</p>\n<p>GSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。</p>\n<p>PLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。</p>\n<p>SCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。</p>\n<p>OAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。</p>\n<p>Delegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。</p>\n<h2 id=\"认证机制的比较\"><a href=\"#认证机制的比较\" class=\"headerlink\" title=\"认证机制的比较\"></a>认证机制的比较</h2><p>可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。</p>\n<p><img src=\"compare.jpg\" alt></p>\n"},{"title":"kafka面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-08T11:55:21.000Z","password":null,"summary":null,"_content":"","source":"_posts/kafka面试.md","raw":"---\ntitle: kafka面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-08 19:55:21\npassword:\nsummary:\ntags:\ncategories:\n---\n","slug":"kafka面试","published":1,"updated":"2021-04-08T11:55:22.845Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxhe001pncufbpi1yblz","content":"","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":""},{"title":"mysql思维导图","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-02T13:28:18.000Z","password":null,"summary":"博客中mysql相关思维导图","_content":"\n![](mysql.png)","source":"_posts/mysql思维导图.md","raw":"---\ntitle: mysql思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-02 21:28:18\npassword:\nsummary: 博客中mysql相关思维导图\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n![](mysql.png)","slug":"mysql思维导图","published":1,"updated":"2021-04-02T13:29:59.029Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxhh001rncufuncuq2rs","content":"<p><img src=\"mysql.png\" alt></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p><img src=\"mysql.png\" alt></p>\n"},{"title":"kafka调优","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-30T13:30:58.000Z","password":null,"summary":null,"_content":"\n## 调优目标\n\n吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。\n\n延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。\n\n## 优化\n\n### 操作系统调优\n\n1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。\n\n2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程\n\n3、ulimit -n 不宜太小\n\n4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。\n\n### JVM 层调优\n\n1. 设置堆大小。6～8GB\n2. GC 收集器使用 G1 收集器。\n\n### Broker 端调优\n\n保持客户端版本和 Broker 端版本一致。\n\n### 应用层调优\n\n1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。\n\n2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。\n\n## 性能指标调优\n\n### 调优吞吐量\n\n1、broker 端参数 `num.replica.fetchers `表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。\n\n2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 `batch.size` 和 `linger.ms`。\n\n3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd\n\n4、Consumer端使用多线程方案\n\n### 调优延时\n\n1、在 Broker 端，我们依然要增加 `num.replica.fetchers` 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时\n\n2、设置 `linger.ms=0`，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。\n\n3、Consumer 端，我们保持` fetch.min.bytes=1` 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。","source":"_posts/kafka调优.md","raw":"---\ntitle: kafka调优\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-30 21:30:58\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 调优目标\n\n吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。\n\n延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。\n\n## 优化\n\n### 操作系统调优\n\n1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。\n\n2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程\n\n3、ulimit -n 不宜太小\n\n4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。\n\n### JVM 层调优\n\n1. 设置堆大小。6～8GB\n2. GC 收集器使用 G1 收集器。\n\n### Broker 端调优\n\n保持客户端版本和 Broker 端版本一致。\n\n### 应用层调优\n\n1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。\n\n2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。\n\n## 性能指标调优\n\n### 调优吞吐量\n\n1、broker 端参数 `num.replica.fetchers `表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。\n\n2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 `batch.size` 和 `linger.ms`。\n\n3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd\n\n4、Consumer端使用多线程方案\n\n### 调优延时\n\n1、在 Broker 端，我们依然要增加 `num.replica.fetchers` 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时\n\n2、设置 `linger.ms=0`，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。\n\n3、Consumer 端，我们保持` fetch.min.bytes=1` 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。","slug":"kafka调优","published":1,"updated":"2021-04-02T13:16:17.846Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxhk001tncuf9ukaylqa","content":"<h2 id=\"调优目标\"><a href=\"#调优目标\" class=\"headerlink\" title=\"调优目标\"></a>调优目标</h2><p>吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。</p>\n<p>延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><h3 id=\"操作系统调优\"><a href=\"#操作系统调优\" class=\"headerlink\" title=\"操作系统调优\"></a>操作系统调优</h3><p>1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。</p>\n<p>2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程</p>\n<p>3、ulimit -n 不宜太小</p>\n<p>4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。</p>\n<h3 id=\"JVM-层调优\"><a href=\"#JVM-层调优\" class=\"headerlink\" title=\"JVM 层调优\"></a>JVM 层调优</h3><ol>\n<li>设置堆大小。6～8GB</li>\n<li>GC 收集器使用 G1 收集器。</li>\n</ol>\n<h3 id=\"Broker-端调优\"><a href=\"#Broker-端调优\" class=\"headerlink\" title=\"Broker 端调优\"></a>Broker 端调优</h3><p>保持客户端版本和 Broker 端版本一致。</p>\n<h3 id=\"应用层调优\"><a href=\"#应用层调优\" class=\"headerlink\" title=\"应用层调优\"></a>应用层调优</h3><p>1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。</p>\n<p>2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。</p>\n<h2 id=\"性能指标调优\"><a href=\"#性能指标调优\" class=\"headerlink\" title=\"性能指标调优\"></a>性能指标调优</h2><h3 id=\"调优吞吐量\"><a href=\"#调优吞吐量\" class=\"headerlink\" title=\"调优吞吐量\"></a>调优吞吐量</h3><p>1、broker 端参数 <code>num.replica.fetchers</code>表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。</p>\n<p>2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 <code>batch.size</code> 和 <code>linger.ms</code>。</p>\n<p>3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd</p>\n<p>4、Consumer端使用多线程方案</p>\n<h3 id=\"调优延时\"><a href=\"#调优延时\" class=\"headerlink\" title=\"调优延时\"></a>调优延时</h3><p>1、在 Broker 端，我们依然要增加 <code>num.replica.fetchers</code> 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时</p>\n<p>2、设置 <code>linger.ms=0</code>，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。</p>\n<p>3、Consumer 端，我们保持<code>fetch.min.bytes=1</code> 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"调优目标\"><a href=\"#调优目标\" class=\"headerlink\" title=\"调优目标\"></a>调优目标</h2><p>吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。</p>\n<p>延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><h3 id=\"操作系统调优\"><a href=\"#操作系统调优\" class=\"headerlink\" title=\"操作系统调优\"></a>操作系统调优</h3><p>1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。</p>\n<p>2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程</p>\n<p>3、ulimit -n 不宜太小</p>\n<p>4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。</p>\n<h3 id=\"JVM-层调优\"><a href=\"#JVM-层调优\" class=\"headerlink\" title=\"JVM 层调优\"></a>JVM 层调优</h3><ol>\n<li>设置堆大小。6～8GB</li>\n<li>GC 收集器使用 G1 收集器。</li>\n</ol>\n<h3 id=\"Broker-端调优\"><a href=\"#Broker-端调优\" class=\"headerlink\" title=\"Broker 端调优\"></a>Broker 端调优</h3><p>保持客户端版本和 Broker 端版本一致。</p>\n<h3 id=\"应用层调优\"><a href=\"#应用层调优\" class=\"headerlink\" title=\"应用层调优\"></a>应用层调优</h3><p>1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。</p>\n<p>2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。</p>\n<h2 id=\"性能指标调优\"><a href=\"#性能指标调优\" class=\"headerlink\" title=\"性能指标调优\"></a>性能指标调优</h2><h3 id=\"调优吞吐量\"><a href=\"#调优吞吐量\" class=\"headerlink\" title=\"调优吞吐量\"></a>调优吞吐量</h3><p>1、broker 端参数 <code>num.replica.fetchers</code>表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。</p>\n<p>2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 <code>batch.size</code> 和 <code>linger.ms</code>。</p>\n<p>3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd</p>\n<p>4、Consumer端使用多线程方案</p>\n<h3 id=\"调优延时\"><a href=\"#调优延时\" class=\"headerlink\" title=\"调优延时\"></a>调优延时</h3><p>1、在 Broker 端，我们依然要增加 <code>num.replica.fetchers</code> 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时</p>\n<p>2、设置 <code>linger.ms=0</code>，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。</p>\n<p>3、Consumer 端，我们保持<code>fetch.min.bytes=1</code> 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。</p>\n"},{"title":"rabbitmq思维导图","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-04T06:58:19.000Z","password":null,"summary":"博客中涉及到的rabbitmq相关概念。","_content":"\n![](rabbitmq.png)","source":"_posts/rabbitmq思维导图.md","raw":"---\ntitle: rabbitmq思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-04 14:58:19\npassword:\nsummary: 博客中涉及到的rabbitmq相关概念。\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n![](rabbitmq.png)","slug":"rabbitmq思维导图","published":1,"updated":"2021-04-04T06:59:45.233Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxi0001wncufr7j49qj5","content":"<p><img src=\"rabbitmq.png\" alt></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p><img src=\"rabbitmq.png\" alt></p>\n"},{"title":"kafka集群配置","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-12-10T13:12:03.000Z","password":null,"summary":null,"_content":"\n## Broker 端参数\n\n- log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移\n- log.dir：单个路径\n\n- zookeeper.connect：zookeeper端口\n- listeners：访问kafka的监听器\n- advertised.listeners：Broker 用于对外发布的监听器\n- auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false\n- unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false\n- auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false\n- log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低\n- log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1\n- message.max.bytes：控制 Broker 能够接收的最大消息大小。\n\n## Topic 级别参数\n\n- retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。\n\n- retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。\n- max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小\n\n创建topic时设置:\n\n```\n\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880\n```\n\n修改topic(推荐)：\n\n```\n\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760\n```\n\n## JVM参数\n\n JVM 堆大小设置成 6GB ，用默认的 G1 收集器\n\n- KAFKA_HEAP_OPTS：指定堆大小。\n- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。\n\n启动broker前设置：\n\n```\n$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$> bin/kafka-server-start.sh config/server.properties\n```\n\n## 操作系统参数\n\n文件描述符限制：`ulimit -n 1000000`，通常将它设置成一个超大的值\n\n文件系统类型：最好选择xfs\n\nSwap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。\n\n提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作\n\n## 动态 Broker 参数配置\n\n**配置的类别**\n\nread-only。只有重启 Broker，才能令修改生效。\n\nper-broker。修改它之后，只会在对应的 Broker 上生效。\n\ncluster-wide。被修改它之后，会在整个集群范围内生效。\n\n**使用场景**\n\n- 动态调整 Broker 端各种线程池大小，实时应对突发流量。\n- 动态调整 Broker 端连接信息或安全配置信息。\n- 动态更新 SSL Keystore 有效期。\n- 动态调整 Broker 端 Compact 操作性能。\n- 实时变更 JMX 指标收集器 (JMX Metrics Reporter)。\n\n**实现**\n\nKafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。\n\n[](atoconfig.png)\n\nchanges 是用来实时监测动态参数变更的；\n\ntopics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。\n\nusers 和 clients 则是用于动态调整客户端配额（Quota）的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。\n\n/config/brokers znode 才是保存动态 Broker 参数。第一类子节点< default >，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。\n\n**设置**\n\n```shell\n# 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable\n```\n\n**常用动态参数**\n\n- log.retention.ms：日志留存时间\n- num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。\n- num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。\n\n","source":"_posts/kafka集群配置.md","raw":"---\ntitle: kafka集群配置\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-12-10 21:12:03\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## Broker 端参数\n\n- log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移\n- log.dir：单个路径\n\n- zookeeper.connect：zookeeper端口\n- listeners：访问kafka的监听器\n- advertised.listeners：Broker 用于对外发布的监听器\n- auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false\n- unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false\n- auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false\n- log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低\n- log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1\n- message.max.bytes：控制 Broker 能够接收的最大消息大小。\n\n## Topic 级别参数\n\n- retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。\n\n- retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。\n- max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小\n\n创建topic时设置:\n\n```\n\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880\n```\n\n修改topic(推荐)：\n\n```\n\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760\n```\n\n## JVM参数\n\n JVM 堆大小设置成 6GB ，用默认的 G1 收集器\n\n- KAFKA_HEAP_OPTS：指定堆大小。\n- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。\n\n启动broker前设置：\n\n```\n$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$> bin/kafka-server-start.sh config/server.properties\n```\n\n## 操作系统参数\n\n文件描述符限制：`ulimit -n 1000000`，通常将它设置成一个超大的值\n\n文件系统类型：最好选择xfs\n\nSwap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。\n\n提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作\n\n## 动态 Broker 参数配置\n\n**配置的类别**\n\nread-only。只有重启 Broker，才能令修改生效。\n\nper-broker。修改它之后，只会在对应的 Broker 上生效。\n\ncluster-wide。被修改它之后，会在整个集群范围内生效。\n\n**使用场景**\n\n- 动态调整 Broker 端各种线程池大小，实时应对突发流量。\n- 动态调整 Broker 端连接信息或安全配置信息。\n- 动态更新 SSL Keystore 有效期。\n- 动态调整 Broker 端 Compact 操作性能。\n- 实时变更 JMX 指标收集器 (JMX Metrics Reporter)。\n\n**实现**\n\nKafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。\n\n[](atoconfig.png)\n\nchanges 是用来实时监测动态参数变更的；\n\ntopics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。\n\nusers 和 clients 则是用于动态调整客户端配额（Quota）的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。\n\n/config/brokers znode 才是保存动态 Broker 参数。第一类子节点< default >，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。\n\n**设置**\n\n```shell\n# 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable\n```\n\n**常用动态参数**\n\n- log.retention.ms：日志留存时间\n- num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。\n- num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。\n\n","slug":"kafka集群配置","published":1,"updated":"2021-04-01T23:01:49.926Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxi4001zncufk2qe9pny","content":"<h2 id=\"Broker-端参数\"><a href=\"#Broker-端参数\" class=\"headerlink\" title=\"Broker 端参数\"></a>Broker 端参数</h2><ul>\n<li><p>log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移</p>\n</li>\n<li><p>log.dir：单个路径</p>\n</li>\n<li><p>zookeeper.connect：zookeeper端口</p>\n</li>\n<li><p>listeners：访问kafka的监听器</p>\n</li>\n<li><p>advertised.listeners：Broker 用于对外发布的监听器</p>\n</li>\n<li><p>auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false</p>\n</li>\n<li><p>unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false</p>\n</li>\n<li><p>auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false</p>\n</li>\n<li><p>log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低</p>\n</li>\n<li><p>log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1</p>\n</li>\n<li><p>message.max.bytes：控制 Broker 能够接收的最大消息大小。</p>\n</li>\n</ul>\n<h2 id=\"Topic-级别参数\"><a href=\"#Topic-级别参数\" class=\"headerlink\" title=\"Topic 级别参数\"></a>Topic 级别参数</h2><ul>\n<li><p>retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。</p>\n</li>\n<li><p>retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。</p>\n</li>\n<li><p>max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小</p>\n</li>\n</ul>\n<p>创建topic时设置:</p>\n<pre><code>\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880</code></pre><p>修改topic(推荐)：</p>\n<pre><code>\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760</code></pre><h2 id=\"JVM参数\"><a href=\"#JVM参数\" class=\"headerlink\" title=\"JVM参数\"></a>JVM参数</h2><p> JVM 堆大小设置成 6GB ，用默认的 G1 收集器</p>\n<ul>\n<li>KAFKA_HEAP_OPTS：指定堆大小。</li>\n<li>KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。</li>\n</ul>\n<p>启动broker前设置：</p>\n<pre><code>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$&gt; bin/kafka-server-start.sh config/server.properties</code></pre><h2 id=\"操作系统参数\"><a href=\"#操作系统参数\" class=\"headerlink\" title=\"操作系统参数\"></a>操作系统参数</h2><p>文件描述符限制：<code>ulimit -n 1000000</code>，通常将它设置成一个超大的值</p>\n<p>文件系统类型：最好选择xfs</p>\n<p>Swap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。</p>\n<p>提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作</p>\n<h2 id=\"动态-Broker-参数配置\"><a href=\"#动态-Broker-参数配置\" class=\"headerlink\" title=\"动态 Broker 参数配置\"></a>动态 Broker 参数配置</h2><p><strong>配置的类别</strong></p>\n<p>read-only。只有重启 Broker，才能令修改生效。</p>\n<p>per-broker。修改它之后，只会在对应的 Broker 上生效。</p>\n<p>cluster-wide。被修改它之后，会在整个集群范围内生效。</p>\n<p><strong>使用场景</strong></p>\n<ul>\n<li>动态调整 Broker 端各种线程池大小，实时应对突发流量。</li>\n<li>动态调整 Broker 端连接信息或安全配置信息。</li>\n<li>动态更新 SSL Keystore 有效期。</li>\n<li>动态调整 Broker 端 Compact 操作性能。</li>\n<li>实时变更 JMX 指标收集器 (JMX Metrics Reporter)。</li>\n</ul>\n<p><strong>实现</strong></p>\n<p>Kafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。</p>\n<p><a href=\"atoconfig.png\"></a></p>\n<p>changes 是用来实时监测动态参数变更的；</p>\n<p>topics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。</p>\n<p>users 和 clients 则是用于动态调整客户端配额（Quota）的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。</p>\n<p>/config/brokers znode 才是保存动态 Broker 参数。第一类子节点&lt; default &gt;，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。</p>\n<p><strong>设置</strong></p>\n<pre class=\"line-numbers language-shell\"><code class=\"language-shell\"># 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>常用动态参数</strong></p>\n<ul>\n<li>log.retention.ms：日志留存时间</li>\n<li>num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。</li>\n<li>num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"Broker-端参数\"><a href=\"#Broker-端参数\" class=\"headerlink\" title=\"Broker 端参数\"></a>Broker 端参数</h2><ul>\n<li><p>log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移</p>\n</li>\n<li><p>log.dir：单个路径</p>\n</li>\n<li><p>zookeeper.connect：zookeeper端口</p>\n</li>\n<li><p>listeners：访问kafka的监听器</p>\n</li>\n<li><p>advertised.listeners：Broker 用于对外发布的监听器</p>\n</li>\n<li><p>auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false</p>\n</li>\n<li><p>unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false</p>\n</li>\n<li><p>auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false</p>\n</li>\n<li><p>log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低</p>\n</li>\n<li><p>log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1</p>\n</li>\n<li><p>message.max.bytes：控制 Broker 能够接收的最大消息大小。</p>\n</li>\n</ul>\n<h2 id=\"Topic-级别参数\"><a href=\"#Topic-级别参数\" class=\"headerlink\" title=\"Topic 级别参数\"></a>Topic 级别参数</h2><ul>\n<li><p>retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。</p>\n</li>\n<li><p>retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。</p>\n</li>\n<li><p>max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小</p>\n</li>\n</ul>\n<p>创建topic时设置:</p>\n<pre><code>\nbin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880</code></pre><p>修改topic(推荐)：</p>\n<pre><code>\nbin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760</code></pre><h2 id=\"JVM参数\"><a href=\"#JVM参数\" class=\"headerlink\" title=\"JVM参数\"></a>JVM参数</h2><p> JVM 堆大小设置成 6GB ，用默认的 G1 收集器</p>\n<ul>\n<li>KAFKA_HEAP_OPTS：指定堆大小。</li>\n<li>KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。</li>\n</ul>\n<p>启动broker前设置：</p>\n<pre><code>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$&gt; bin/kafka-server-start.sh config/server.properties</code></pre><h2 id=\"操作系统参数\"><a href=\"#操作系统参数\" class=\"headerlink\" title=\"操作系统参数\"></a>操作系统参数</h2><p>文件描述符限制：<code>ulimit -n 1000000</code>，通常将它设置成一个超大的值</p>\n<p>文件系统类型：最好选择xfs</p>\n<p>Swap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。</p>\n<p>提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作</p>\n<h2 id=\"动态-Broker-参数配置\"><a href=\"#动态-Broker-参数配置\" class=\"headerlink\" title=\"动态 Broker 参数配置\"></a>动态 Broker 参数配置</h2><p><strong>配置的类别</strong></p>\n<p>read-only。只有重启 Broker，才能令修改生效。</p>\n<p>per-broker。修改它之后，只会在对应的 Broker 上生效。</p>\n<p>cluster-wide。被修改它之后，会在整个集群范围内生效。</p>\n<p><strong>使用场景</strong></p>\n<ul>\n<li>动态调整 Broker 端各种线程池大小，实时应对突发流量。</li>\n<li>动态调整 Broker 端连接信息或安全配置信息。</li>\n<li>动态更新 SSL Keystore 有效期。</li>\n<li>动态调整 Broker 端 Compact 操作性能。</li>\n<li>实时变更 JMX 指标收集器 (JMX Metrics Reporter)。</li>\n</ul>\n<p><strong>实现</strong></p>\n<p>Kafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。</p>\n<p><a href=\"atoconfig.png\"></a></p>\n<p>changes 是用来实时监测动态参数变更的；</p>\n<p>topics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。</p>\n<p>users 和 clients 则是用于动态调整客户端配额（Quota）的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。</p>\n<p>/config/brokers znode 才是保存动态 Broker 参数。第一类子节点&lt; default &gt;，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。</p>\n<p><strong>设置</strong></p>\n<pre><code class=\"shell\"># 设置 cluster-wide 范围值,entity-default\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe\n# 设置ID 为 1 的 Broker\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false\n# 查看设置\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe\n\n\n# 删除cluster-wide范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\n\n# 删除per-broker范围参数，删除动态参数要指定 delete-config\n$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable</code></pre>\n<p><strong>常用动态参数</strong></p>\n<ul>\n<li>log.retention.ms：日志留存时间</li>\n<li>num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。</li>\n<li>num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。</li>\n</ul>\n"},{"title":"rabbitmq概念","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-03T10:50:50.000Z","password":null,"summary":"rabbit相关概念介绍","_content":"\nRabbitmq是生产者与消费者模型，负责接收、存储、转发消息。\n\n![](moxin.png)\n\n**Producer：生产者**\n\n**消息**包含2部分：\n\n- **消息体（payload）：**一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。\n\n- **标签（Label）：**用来描述这条消息，比如一个交换器的名称和一个路由键。\n\n**Consumer：消费者**\n\n当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。\n\n**Broker：服务节点**\n\n**Virtual host：**虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型\n\n**交换器类型**\n\nfanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中\n\ndirect：把消息路由到BindingKey和RoutingKey完全匹配的队列中\n\ntopic：把消息路由到BindingKey和RoutingKey相匹配的队列中\n\nheaders：根据发送消息内容中的headers进行匹配，性能比较差\n**运转流程**\n**生产者发送消息**\n\n- 生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）\n\n- 生产者声明一个交换器，并设置相关属性（交换机类型、持久化）\n\n- 生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）\n\n- 生产者通过路由键将交换器和队列绑定起来\n\n- 生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）\n\n- 相应的交换器根据接收到的路由键查找相匹配的队列\n\n- 若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者\n\n- 关闭信道\n\n- 关闭连接\n\n**消费者接收消息**\n\n- 消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）\n- 消费者向 RabbitMQ Broker 请求消费对应队列中的消息\n- 等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息\n- 消费者确认（ack）接收到的消息\n- RabbitMQ 从队列中删除相应已经被确认的消息\n- 关闭信道\n- 关闭连接\n\n","source":"_posts/rabbitmq概念.md","raw":"---\ntitle: rabbitmq概念\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-03 18:50:50\npassword:\nsummary: rabbit相关概念介绍\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\nRabbitmq是生产者与消费者模型，负责接收、存储、转发消息。\n\n![](moxin.png)\n\n**Producer：生产者**\n\n**消息**包含2部分：\n\n- **消息体（payload）：**一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。\n\n- **标签（Label）：**用来描述这条消息，比如一个交换器的名称和一个路由键。\n\n**Consumer：消费者**\n\n当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。\n\n**Broker：服务节点**\n\n**Virtual host：**虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型\n\n**交换器类型**\n\nfanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中\n\ndirect：把消息路由到BindingKey和RoutingKey完全匹配的队列中\n\ntopic：把消息路由到BindingKey和RoutingKey相匹配的队列中\n\nheaders：根据发送消息内容中的headers进行匹配，性能比较差\n**运转流程**\n**生产者发送消息**\n\n- 生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）\n\n- 生产者声明一个交换器，并设置相关属性（交换机类型、持久化）\n\n- 生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）\n\n- 生产者通过路由键将交换器和队列绑定起来\n\n- 生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）\n\n- 相应的交换器根据接收到的路由键查找相匹配的队列\n\n- 若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者\n\n- 关闭信道\n\n- 关闭连接\n\n**消费者接收消息**\n\n- 消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）\n- 消费者向 RabbitMQ Broker 请求消费对应队列中的消息\n- 等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息\n- 消费者确认（ack）接收到的消息\n- RabbitMQ 从队列中删除相应已经被确认的消息\n- 关闭信道\n- 关闭连接\n\n","slug":"rabbitmq概念","published":1,"updated":"2021-04-05T01:22:25.696Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxi80024ncufxl19csvf","content":"<p>Rabbitmq是生产者与消费者模型，负责接收、存储、转发消息。</p>\n<p><img src=\"moxin.png\" alt></p>\n<p><strong>Producer：生产者</strong></p>\n<p><strong>消息</strong>包含2部分：</p>\n<ul>\n<li><p><strong>消息体（payload）：</strong>一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。</p>\n</li>\n<li><p><strong>标签（Label）：</strong>用来描述这条消息，比如一个交换器的名称和一个路由键。</p>\n</li>\n</ul>\n<p><strong>Consumer：消费者</strong></p>\n<p>当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。</p>\n<p><strong>Broker：服务节点</strong></p>\n<p><strong>Virtual host：</strong>虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p>\n<p><strong>交换器类型</strong></p>\n<p>fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中</p>\n<p>direct：把消息路由到BindingKey和RoutingKey完全匹配的队列中</p>\n<p>topic：把消息路由到BindingKey和RoutingKey相匹配的队列中</p>\n<p>headers：根据发送消息内容中的headers进行匹配，性能比较差<br><strong>运转流程</strong><br><strong>生产者发送消息</strong></p>\n<ul>\n<li><p>生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）</p>\n</li>\n<li><p>生产者声明一个交换器，并设置相关属性（交换机类型、持久化）</p>\n</li>\n<li><p>生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）</p>\n</li>\n<li><p>生产者通过路由键将交换器和队列绑定起来</p>\n</li>\n<li><p>生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）</p>\n</li>\n<li><p>相应的交换器根据接收到的路由键查找相匹配的队列</p>\n</li>\n<li><p>若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者</p>\n</li>\n<li><p>关闭信道</p>\n</li>\n<li><p>关闭连接</p>\n</li>\n</ul>\n<p><strong>消费者接收消息</strong></p>\n<ul>\n<li>消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）</li>\n<li>消费者向 RabbitMQ Broker 请求消费对应队列中的消息</li>\n<li>等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息</li>\n<li>消费者确认（ack）接收到的消息</li>\n<li>RabbitMQ 从队列中删除相应已经被确认的消息</li>\n<li>关闭信道</li>\n<li>关闭连接</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>Rabbitmq是生产者与消费者模型，负责接收、存储、转发消息。</p>\n<p><img src=\"moxin.png\" alt></p>\n<p><strong>Producer：生产者</strong></p>\n<p><strong>消息</strong>包含2部分：</p>\n<ul>\n<li><p><strong>消息体（payload）：</strong>一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。</p>\n</li>\n<li><p><strong>标签（Label）：</strong>用来描述这条消息，比如一个交换器的名称和一个路由键。</p>\n</li>\n</ul>\n<p><strong>Consumer：消费者</strong></p>\n<p>当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。</p>\n<p><strong>Broker：服务节点</strong></p>\n<p><strong>Virtual host：</strong>虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p>\n<p><strong>交换器类型</strong></p>\n<p>fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中</p>\n<p>direct：把消息路由到BindingKey和RoutingKey完全匹配的队列中</p>\n<p>topic：把消息路由到BindingKey和RoutingKey相匹配的队列中</p>\n<p>headers：根据发送消息内容中的headers进行匹配，性能比较差<br><strong>运转流程</strong><br><strong>生产者发送消息</strong></p>\n<ul>\n<li><p>生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）</p>\n</li>\n<li><p>生产者声明一个交换器，并设置相关属性（交换机类型、持久化）</p>\n</li>\n<li><p>生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）</p>\n</li>\n<li><p>生产者通过路由键将交换器和队列绑定起来</p>\n</li>\n<li><p>生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）</p>\n</li>\n<li><p>相应的交换器根据接收到的路由键查找相匹配的队列</p>\n</li>\n<li><p>若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者</p>\n</li>\n<li><p>关闭信道</p>\n</li>\n<li><p>关闭连接</p>\n</li>\n</ul>\n<p><strong>消费者接收消息</strong></p>\n<ul>\n<li>消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）</li>\n<li>消费者向 RabbitMQ Broker 请求消费对应队列中的消息</li>\n<li>等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息</li>\n<li>消费者确认（ack）接收到的消息</li>\n<li>RabbitMQ 从队列中删除相应已经被确认的消息</li>\n<li>关闭信道</li>\n<li>关闭连接</li>\n</ul>\n"},{"title":"kafka高水位和Leader Epoch","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-28T12:07:34.000Z","password":null,"summary":null,"_content":"\n## 高水位\n\n在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。\n\n**作用**\n\n- 定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。\n- 帮助 Kafka 完成副本同步。\n\n**LEO（Log End Offset）**表示副本写入下一条消息的位移值。\n\n## 高水位更新机制\n\n![](water.jpg)\n\n![](watertime.jpg)\n\n### **Leader 副本高水位**\n\n**处理生产者请求**的逻辑如下：\n\n1、写入消息到本地磁盘。\n\n2、更新分区高水位值。\n\ni. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。\n\nii. 获取 Leader 副本高水位值：currentHW。\n\niii. 更新 `currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}`。\n\n**处理 Follower 副本拉取消息**的逻辑如下：\n\n1、读取磁盘（或页缓存）中的消息数据。\n\n2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。\n\n3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。\n\n### **Follower 副本高水位**\n\n**从 Leader 拉取消息的处理逻辑**如下：\n\n1、写入消息到本地磁盘。\n\n2、更新 LEO 值。\n\n3、更新高水位值。\n\ni. 获取 Leader 发送的高水位值：currentHW。\n\nii. 获取步骤 2 中更新过的 LEO 值：currentLEO。\n\niii. 更新高水位为 `min(currentHW, currentLEO)`。\n\n### 高水位更新说明\n\n新消息写入时，先更新leader副本LEO，\n\nfollower副本新消息写入后第一次拉消息，更新了follower副本的LEO，\n\nfollower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位\n\n**问题**：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。\n\n**背景**：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。\n\n![](bad.jpg)\n\n1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 **LEO 值由2调整为之前的高水位值**，也就是 1。\n\n2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。\n\n**影响：**位移值为 1 的消息丢失。\n\n## Leader Epoch\n\n它由两部分数据组成。\n\n- Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。\n- 起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。\n\nKafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。\n\n**解决：**\n\n![](good.jpg)\n\nFollower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 **Leader 的 LEO 值**。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 > 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。\n\n副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。\n\n后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。","source":"_posts/kafka高水位和Leader-Epoch.md","raw":"---\ntitle: kafka高水位和Leader Epoch\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-28 20:07:34\npassword:\nsummary:\ntags:\n- kafka\ncategories:\n- kafka\n---\n\n## 高水位\n\n在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。\n\n**作用**\n\n- 定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。\n- 帮助 Kafka 完成副本同步。\n\n**LEO（Log End Offset）**表示副本写入下一条消息的位移值。\n\n## 高水位更新机制\n\n![](water.jpg)\n\n![](watertime.jpg)\n\n### **Leader 副本高水位**\n\n**处理生产者请求**的逻辑如下：\n\n1、写入消息到本地磁盘。\n\n2、更新分区高水位值。\n\ni. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。\n\nii. 获取 Leader 副本高水位值：currentHW。\n\niii. 更新 `currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}`。\n\n**处理 Follower 副本拉取消息**的逻辑如下：\n\n1、读取磁盘（或页缓存）中的消息数据。\n\n2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。\n\n3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。\n\n### **Follower 副本高水位**\n\n**从 Leader 拉取消息的处理逻辑**如下：\n\n1、写入消息到本地磁盘。\n\n2、更新 LEO 值。\n\n3、更新高水位值。\n\ni. 获取 Leader 发送的高水位值：currentHW。\n\nii. 获取步骤 2 中更新过的 LEO 值：currentLEO。\n\niii. 更新高水位为 `min(currentHW, currentLEO)`。\n\n### 高水位更新说明\n\n新消息写入时，先更新leader副本LEO，\n\nfollower副本新消息写入后第一次拉消息，更新了follower副本的LEO，\n\nfollower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位\n\n**问题**：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。\n\n**背景**：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。\n\n![](bad.jpg)\n\n1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 **LEO 值由2调整为之前的高水位值**，也就是 1。\n\n2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。\n\n**影响：**位移值为 1 的消息丢失。\n\n## Leader Epoch\n\n它由两部分数据组成。\n\n- Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。\n- 起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。\n\nKafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。\n\n**解决：**\n\n![](good.jpg)\n\nFollower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 **Leader 的 LEO 值**。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 > 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。\n\n副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。\n\n后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。","slug":"kafka高水位和Leader-Epoch","published":1,"updated":"2021-04-01T23:38:36.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxib0028ncufh44tkbai","content":"<h2 id=\"高水位\"><a href=\"#高水位\" class=\"headerlink\" title=\"高水位\"></a>高水位</h2><p>在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。</p>\n<p><strong>作用</strong></p>\n<ul>\n<li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。</li>\n<li>帮助 Kafka 完成副本同步。</li>\n</ul>\n<p><strong>LEO（Log End Offset）</strong>表示副本写入下一条消息的位移值。</p>\n<h2 id=\"高水位更新机制\"><a href=\"#高水位更新机制\" class=\"headerlink\" title=\"高水位更新机制\"></a>高水位更新机制</h2><p><img src=\"water.jpg\" alt></p>\n<p><img src=\"watertime.jpg\" alt></p>\n<h3 id=\"Leader-副本高水位\"><a href=\"#Leader-副本高水位\" class=\"headerlink\" title=\"Leader 副本高水位\"></a><strong>Leader 副本高水位</strong></h3><p><strong>处理生产者请求</strong>的逻辑如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新分区高水位值。</p>\n<p>i. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。</p>\n<p>ii. 获取 Leader 副本高水位值：currentHW。</p>\n<p>iii. 更新 <code>currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}</code>。</p>\n<p><strong>处理 Follower 副本拉取消息</strong>的逻辑如下：</p>\n<p>1、读取磁盘（或页缓存）中的消息数据。</p>\n<p>2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。</p>\n<p>3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。</p>\n<h3 id=\"Follower-副本高水位\"><a href=\"#Follower-副本高水位\" class=\"headerlink\" title=\"Follower 副本高水位\"></a><strong>Follower 副本高水位</strong></h3><p><strong>从 Leader 拉取消息的处理逻辑</strong>如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新 LEO 值。</p>\n<p>3、更新高水位值。</p>\n<p>i. 获取 Leader 发送的高水位值：currentHW。</p>\n<p>ii. 获取步骤 2 中更新过的 LEO 值：currentLEO。</p>\n<p>iii. 更新高水位为 <code>min(currentHW, currentLEO)</code>。</p>\n<h3 id=\"高水位更新说明\"><a href=\"#高水位更新说明\" class=\"headerlink\" title=\"高水位更新说明\"></a>高水位更新说明</h3><p>新消息写入时，先更新leader副本LEO，</p>\n<p>follower副本新消息写入后第一次拉消息，更新了follower副本的LEO，</p>\n<p>follower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位</p>\n<p><strong>问题</strong>：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。</p>\n<p><strong>背景</strong>：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。</p>\n<p><img src=\"bad.jpg\" alt></p>\n<p>1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 <strong>LEO 值由2调整为之前的高水位值</strong>，也就是 1。</p>\n<p>2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。</p>\n<p><strong>影响：</strong>位移值为 1 的消息丢失。</p>\n<h2 id=\"Leader-Epoch\"><a href=\"#Leader-Epoch\" class=\"headerlink\" title=\"Leader Epoch\"></a>Leader Epoch</h2><p>它由两部分数据组成。</p>\n<ul>\n<li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>\n<li>起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。</li>\n</ul>\n<p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。</p>\n<p><strong>解决：</strong></p>\n<p><img src=\"good.jpg\" alt></p>\n<p>Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 <strong>Leader 的 LEO 值</strong>。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。</p>\n<p>副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。</p>\n<p>后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"高水位\"><a href=\"#高水位\" class=\"headerlink\" title=\"高水位\"></a>高水位</h2><p>在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。</p>\n<p><strong>作用</strong></p>\n<ul>\n<li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。</li>\n<li>帮助 Kafka 完成副本同步。</li>\n</ul>\n<p><strong>LEO（Log End Offset）</strong>表示副本写入下一条消息的位移值。</p>\n<h2 id=\"高水位更新机制\"><a href=\"#高水位更新机制\" class=\"headerlink\" title=\"高水位更新机制\"></a>高水位更新机制</h2><p><img src=\"water.jpg\" alt></p>\n<p><img src=\"watertime.jpg\" alt></p>\n<h3 id=\"Leader-副本高水位\"><a href=\"#Leader-副本高水位\" class=\"headerlink\" title=\"Leader 副本高水位\"></a><strong>Leader 副本高水位</strong></h3><p><strong>处理生产者请求</strong>的逻辑如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新分区高水位值。</p>\n<p>i. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。</p>\n<p>ii. 获取 Leader 副本高水位值：currentHW。</p>\n<p>iii. 更新 <code>currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}</code>。</p>\n<p><strong>处理 Follower 副本拉取消息</strong>的逻辑如下：</p>\n<p>1、读取磁盘（或页缓存）中的消息数据。</p>\n<p>2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。</p>\n<p>3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。</p>\n<h3 id=\"Follower-副本高水位\"><a href=\"#Follower-副本高水位\" class=\"headerlink\" title=\"Follower 副本高水位\"></a><strong>Follower 副本高水位</strong></h3><p><strong>从 Leader 拉取消息的处理逻辑</strong>如下：</p>\n<p>1、写入消息到本地磁盘。</p>\n<p>2、更新 LEO 值。</p>\n<p>3、更新高水位值。</p>\n<p>i. 获取 Leader 发送的高水位值：currentHW。</p>\n<p>ii. 获取步骤 2 中更新过的 LEO 值：currentLEO。</p>\n<p>iii. 更新高水位为 <code>min(currentHW, currentLEO)</code>。</p>\n<h3 id=\"高水位更新说明\"><a href=\"#高水位更新说明\" class=\"headerlink\" title=\"高水位更新说明\"></a>高水位更新说明</h3><p>新消息写入时，先更新leader副本LEO，</p>\n<p>follower副本新消息写入后第一次拉消息，更新了follower副本的LEO，</p>\n<p>follower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位</p>\n<p><strong>问题</strong>：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。</p>\n<p><strong>背景</strong>：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。</p>\n<p><img src=\"bad.jpg\" alt></p>\n<p>1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 <strong>LEO 值由2调整为之前的高水位值</strong>，也就是 1。</p>\n<p>2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。</p>\n<p><strong>影响：</strong>位移值为 1 的消息丢失。</p>\n<h2 id=\"Leader-Epoch\"><a href=\"#Leader-Epoch\" class=\"headerlink\" title=\"Leader Epoch\"></a>Leader Epoch</h2><p>它由两部分数据组成。</p>\n<ul>\n<li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>\n<li>起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。</li>\n</ul>\n<p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。</p>\n<p><strong>解决：</strong></p>\n<p><img src=\"good.jpg\" alt></p>\n<p>Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 <strong>Leader 的 LEO 值</strong>。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。</p>\n<p>副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。</p>\n<p>后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。</p>\n"},{"title":"rabbitmq客户端开发","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-03T12:58:05.000Z","password":null,"summary":"rabbitmq客户端开发的说明。","_content":"\n## 连接 RabbitMQ\n\n```java\nConnectionFactory factory = new ConnectionFactory();\nfactory.setUsername(USERNAME);\nfactory.setPassword(PASSWORD);\nfactory.setVirtualHost(virtualHost);\nfacotry.setHost(IP_ADRESS);\nfactory.setPort(PORT);\n// 通过URI方式\n// factory.setUri(\"amqp://userName;password@ipAddress:portNumber/virtualHost\");\nConnection conn = factory.newConnection();\nChannel channel = conn.createChannel();\n```\n\nConnection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel\n\n## 使用交换器和队列\n\n```java\n// 持久化的、非自动删除的、绑定类型为direct的交换器\nchannel.exchangeDeclare(exchangeName,\"direct\",true);\n// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名\nString queueName = channel.queueDeclare().getQueue();\n// 持久化的、非排他的、非自动删除的、确定的已知名称\n// channel.queueDeclare(queueName,true,false,false,null);\nchannel.queueBind(queueName,exchangeName,routingKey);\n```\n\nexchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置\n\nqueueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。\n\nqueueBind定义：队列名称、交换器名称、路由键\n\n## 发送消息\n\n```java\nbyte[] messageBodyBytes = \"Hello,world\".getBytes();\n// 普通发送\nchannel.basicPublish(exchangeName,routingKey,null,messageBodyBytes);\n// 控制发送,使用mandatory\nchannel.basicPublish(exchangeName,routingKey,mandatory,MessageProperties.PERSiSTENT_TEXT_PLAIN,messageBodyBytes);\n```\n\n## 消费消息\n\n消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get\n\n**推模式**\n\n```java\nboolean autoAck = false;\nchannel.basicQos(64);\nchannel.basicConsume(queueName,autoAck,\"myConsumerTag\",\n    new DefaultConsumer(channel){\n        @Override\n        public void handleDelivery(String consumerTag,Envelope envelope,AMQP.BasicProperties properties,byte[] body) throws IOException{\n            String routingKey = envelope.getRoutingKey();\n            String contentType = properties.getContentType();\n            long deliveryTag = envelope.getDeliveryTag();\n            channel.basicAck(deliveryTag, false);\n        }\n    }\n);\n```\n\n显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失\n\n每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者\n\n如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁\n\n**拉模式**\n\n```java\nGetResponse response = channel.basicGet(QUEUE_NAME,false);\nSystem.out.pringln(new String(response.getBody()));\nchannel.basicAck(response.getEnvelope().getDeliveryTag(),false);\n```\n\n如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收\n\n如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。\n\n## 消费端的确认与拒绝\n\n**消息确认机制**\n\nRabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数\nautoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息\nautoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除\n**拒绝消息**\n\n消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack\n如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者\n如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除\n如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题\n**注意要点**\n\nRabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息\n如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者\nRabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。\n\n## 关闭连接\n\n```java\nchannel.close();\nconn.close();\n```\n\n显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭","source":"_posts/rabbitmq客户端开发.md","raw":"---\ntitle: rabbitmq客户端开发\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-03 20:58:05\npassword:\nsummary: rabbitmq客户端开发的说明。\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 连接 RabbitMQ\n\n```java\nConnectionFactory factory = new ConnectionFactory();\nfactory.setUsername(USERNAME);\nfactory.setPassword(PASSWORD);\nfactory.setVirtualHost(virtualHost);\nfacotry.setHost(IP_ADRESS);\nfactory.setPort(PORT);\n// 通过URI方式\n// factory.setUri(\"amqp://userName;password@ipAddress:portNumber/virtualHost\");\nConnection conn = factory.newConnection();\nChannel channel = conn.createChannel();\n```\n\nConnection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel\n\n## 使用交换器和队列\n\n```java\n// 持久化的、非自动删除的、绑定类型为direct的交换器\nchannel.exchangeDeclare(exchangeName,\"direct\",true);\n// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名\nString queueName = channel.queueDeclare().getQueue();\n// 持久化的、非排他的、非自动删除的、确定的已知名称\n// channel.queueDeclare(queueName,true,false,false,null);\nchannel.queueBind(queueName,exchangeName,routingKey);\n```\n\nexchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置\n\nqueueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。\n\nqueueBind定义：队列名称、交换器名称、路由键\n\n## 发送消息\n\n```java\nbyte[] messageBodyBytes = \"Hello,world\".getBytes();\n// 普通发送\nchannel.basicPublish(exchangeName,routingKey,null,messageBodyBytes);\n// 控制发送,使用mandatory\nchannel.basicPublish(exchangeName,routingKey,mandatory,MessageProperties.PERSiSTENT_TEXT_PLAIN,messageBodyBytes);\n```\n\n## 消费消息\n\n消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get\n\n**推模式**\n\n```java\nboolean autoAck = false;\nchannel.basicQos(64);\nchannel.basicConsume(queueName,autoAck,\"myConsumerTag\",\n    new DefaultConsumer(channel){\n        @Override\n        public void handleDelivery(String consumerTag,Envelope envelope,AMQP.BasicProperties properties,byte[] body) throws IOException{\n            String routingKey = envelope.getRoutingKey();\n            String contentType = properties.getContentType();\n            long deliveryTag = envelope.getDeliveryTag();\n            channel.basicAck(deliveryTag, false);\n        }\n    }\n);\n```\n\n显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失\n\n每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者\n\n如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁\n\n**拉模式**\n\n```java\nGetResponse response = channel.basicGet(QUEUE_NAME,false);\nSystem.out.pringln(new String(response.getBody()));\nchannel.basicAck(response.getEnvelope().getDeliveryTag(),false);\n```\n\n如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收\n\n如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。\n\n## 消费端的确认与拒绝\n\n**消息确认机制**\n\nRabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数\nautoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息\nautoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除\n**拒绝消息**\n\n消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack\n如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者\n如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除\n如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题\n**注意要点**\n\nRabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息\n如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者\nRabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。\n\n## 关闭连接\n\n```java\nchannel.close();\nconn.close();\n```\n\n显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭","slug":"rabbitmq客户端开发","published":1,"updated":"2021-04-03T13:30:23.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxid0029ncuffezyhggb","content":"<h2 id=\"连接-RabbitMQ\"><a href=\"#连接-RabbitMQ\" class=\"headerlink\" title=\"连接 RabbitMQ\"></a>连接 RabbitMQ</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\">ConnectionFactory factory <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ConnectionFactory</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setUsername</span><span class=\"token punctuation\">(</span>USERNAME<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setPassword</span><span class=\"token punctuation\">(</span>PASSWORD<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setVirtualHost</span><span class=\"token punctuation\">(</span>virtualHost<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfacotry<span class=\"token punctuation\">.</span><span class=\"token function\">setHost</span><span class=\"token punctuation\">(</span>IP_ADRESS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfactory<span class=\"token punctuation\">.</span><span class=\"token function\">setPort</span><span class=\"token punctuation\">(</span>PORT<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 通过URI方式</span>\n<span class=\"token comment\" spellcheck=\"true\">// factory.setUri(\"amqp://userName;password@ipAddress:portNumber/virtualHost\");</span>\nConnection conn <span class=\"token operator\">=</span> factory<span class=\"token punctuation\">.</span><span class=\"token function\">newConnection</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nChannel channel <span class=\"token operator\">=</span> conn<span class=\"token punctuation\">.</span><span class=\"token function\">createChannel</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Connection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel</p>\n<h2 id=\"使用交换器和队列\"><a href=\"#使用交换器和队列\" class=\"headerlink\" title=\"使用交换器和队列\"></a>使用交换器和队列</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 持久化的、非自动删除的、绑定类型为direct的交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">exchangeDeclare</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span><span class=\"token string\">\"direct\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名</span>\nString queueName <span class=\"token operator\">=</span> channel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getQueue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 持久化的、非排他的、非自动删除的、确定的已知名称</span>\n<span class=\"token comment\" spellcheck=\"true\">// channel.queueDeclare(queueName,true,false,false,null);</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueBind</span><span class=\"token punctuation\">(</span>queueName<span class=\"token punctuation\">,</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>exchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置</p>\n<p>queueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。</p>\n<p>queueBind定义：队列名称、交换器名称、路由键</p>\n<h2 id=\"发送消息\"><a href=\"#发送消息\" class=\"headerlink\" title=\"发送消息\"></a>发送消息</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> messageBodyBytes <span class=\"token operator\">=</span> <span class=\"token string\">\"Hello,world\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 普通发送</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">,</span>null<span class=\"token punctuation\">,</span>messageBodyBytes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 控制发送,使用mandatory</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">,</span>mandatory<span class=\"token punctuation\">,</span>MessageProperties<span class=\"token punctuation\">.</span>PERSiSTENT_TEXT_PLAIN<span class=\"token punctuation\">,</span>messageBodyBytes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><p>消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get</p>\n<p><strong>推模式</strong></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">boolean</span> autoAck <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicQos</span><span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicConsume</span><span class=\"token punctuation\">(</span>queueName<span class=\"token punctuation\">,</span>autoAck<span class=\"token punctuation\">,</span><span class=\"token string\">\"myConsumerTag\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token keyword\">new</span> <span class=\"token class-name\">DefaultConsumer</span><span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">handleDelivery</span><span class=\"token punctuation\">(</span>String consumerTag<span class=\"token punctuation\">,</span>Envelope envelope<span class=\"token punctuation\">,</span>AMQP<span class=\"token punctuation\">.</span>BasicProperties properties<span class=\"token punctuation\">,</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> body<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> IOException<span class=\"token punctuation\">{</span>\n            String routingKey <span class=\"token operator\">=</span> envelope<span class=\"token punctuation\">.</span><span class=\"token function\">getRoutingKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            String contentType <span class=\"token operator\">=</span> properties<span class=\"token punctuation\">.</span><span class=\"token function\">getContentType</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">long</span> deliveryTag <span class=\"token operator\">=</span> envelope<span class=\"token punctuation\">.</span><span class=\"token function\">getDeliveryTag</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            channel<span class=\"token punctuation\">.</span><span class=\"token function\">basicAck</span><span class=\"token punctuation\">(</span>deliveryTag<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失</p>\n<p>每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者</p>\n<p>如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁</p>\n<p><strong>拉模式</strong></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">GetResponse response <span class=\"token operator\">=</span> channel<span class=\"token punctuation\">.</span><span class=\"token function\">basicGet</span><span class=\"token punctuation\">(</span>QUEUE_NAME<span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nSystem<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">pringln</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">String</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span><span class=\"token function\">getBody</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicAck</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span><span class=\"token function\">getEnvelope</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getDeliveryTag</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收</p>\n<p>如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。</p>\n<h2 id=\"消费端的确认与拒绝\"><a href=\"#消费端的确认与拒绝\" class=\"headerlink\" title=\"消费端的确认与拒绝\"></a>消费端的确认与拒绝</h2><p><strong>消息确认机制</strong></p>\n<p>RabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数<br>autoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息<br>autoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除<br><strong>拒绝消息</strong></p>\n<p>消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack<br>如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者<br>如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除<br>如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题<br><strong>注意要点</strong></p>\n<p>RabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息<br>如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者<br>RabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。</p>\n<h2 id=\"关闭连接\"><a href=\"#关闭连接\" class=\"headerlink\" title=\"关闭连接\"></a>关闭连接</h2><pre class=\"line-numbers language-java\"><code class=\"language-java\">channel<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nconn<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"连接-RabbitMQ\"><a href=\"#连接-RabbitMQ\" class=\"headerlink\" title=\"连接 RabbitMQ\"></a>连接 RabbitMQ</h2><pre><code class=\"java\">ConnectionFactory factory = new ConnectionFactory();\nfactory.setUsername(USERNAME);\nfactory.setPassword(PASSWORD);\nfactory.setVirtualHost(virtualHost);\nfacotry.setHost(IP_ADRESS);\nfactory.setPort(PORT);\n// 通过URI方式\n// factory.setUri(&quot;amqp://userName;password@ipAddress:portNumber/virtualHost&quot;);\nConnection conn = factory.newConnection();\nChannel channel = conn.createChannel();</code></pre>\n<p>Connection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel</p>\n<h2 id=\"使用交换器和队列\"><a href=\"#使用交换器和队列\" class=\"headerlink\" title=\"使用交换器和队列\"></a>使用交换器和队列</h2><pre><code class=\"java\">// 持久化的、非自动删除的、绑定类型为direct的交换器\nchannel.exchangeDeclare(exchangeName,&quot;direct&quot;,true);\n// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名\nString queueName = channel.queueDeclare().getQueue();\n// 持久化的、非排他的、非自动删除的、确定的已知名称\n// channel.queueDeclare(queueName,true,false,false,null);\nchannel.queueBind(queueName,exchangeName,routingKey);</code></pre>\n<p>exchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置</p>\n<p>queueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。</p>\n<p>queueBind定义：队列名称、交换器名称、路由键</p>\n<h2 id=\"发送消息\"><a href=\"#发送消息\" class=\"headerlink\" title=\"发送消息\"></a>发送消息</h2><pre><code class=\"java\">byte[] messageBodyBytes = &quot;Hello,world&quot;.getBytes();\n// 普通发送\nchannel.basicPublish(exchangeName,routingKey,null,messageBodyBytes);\n// 控制发送,使用mandatory\nchannel.basicPublish(exchangeName,routingKey,mandatory,MessageProperties.PERSiSTENT_TEXT_PLAIN,messageBodyBytes);</code></pre>\n<h2 id=\"消费消息\"><a href=\"#消费消息\" class=\"headerlink\" title=\"消费消息\"></a>消费消息</h2><p>消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get</p>\n<p><strong>推模式</strong></p>\n<pre><code class=\"java\">boolean autoAck = false;\nchannel.basicQos(64);\nchannel.basicConsume(queueName,autoAck,&quot;myConsumerTag&quot;,\n    new DefaultConsumer(channel){\n        @Override\n        public void handleDelivery(String consumerTag,Envelope envelope,AMQP.BasicProperties properties,byte[] body) throws IOException{\n            String routingKey = envelope.getRoutingKey();\n            String contentType = properties.getContentType();\n            long deliveryTag = envelope.getDeliveryTag();\n            channel.basicAck(deliveryTag, false);\n        }\n    }\n);</code></pre>\n<p>显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失</p>\n<p>每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者</p>\n<p>如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁</p>\n<p><strong>拉模式</strong></p>\n<pre><code class=\"java\">GetResponse response = channel.basicGet(QUEUE_NAME,false);\nSystem.out.pringln(new String(response.getBody()));\nchannel.basicAck(response.getEnvelope().getDeliveryTag(),false);</code></pre>\n<p>如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收</p>\n<p>如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。</p>\n<h2 id=\"消费端的确认与拒绝\"><a href=\"#消费端的确认与拒绝\" class=\"headerlink\" title=\"消费端的确认与拒绝\"></a>消费端的确认与拒绝</h2><p><strong>消息确认机制</strong></p>\n<p>RabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数<br>autoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息<br>autoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除<br><strong>拒绝消息</strong></p>\n<p>消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack<br>如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者<br>如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除<br>如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题<br><strong>注意要点</strong></p>\n<p>RabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息<br>如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者<br>RabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。</p>\n<h2 id=\"关闭连接\"><a href=\"#关闭连接\" class=\"headerlink\" title=\"关闭连接\"></a>关闭连接</h2><pre><code class=\"java\">channel.close();\nconn.close();</code></pre>\n<p>显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭</p>\n"},{"title":"rabbitmq消息可靠性","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:19:29.000Z","password":null,"summary":null,"_content":"\n## 消息丢失场景\n\n\n### 消息从生产者写入到消息队列的过程\n\n**问题原因**：\n网络抖动\n\n**解决办法**：\n\n- 事务\n在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。\n缺点：同步操作。生产者吞吐量大大降低。\n\n- 发布者确认\n一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。\n\n\n- 其他\n1. 使用mandatory 设置true：不可路由消息回发到生产者（正常都是可路由的，路由的队列所在节点宕机？）\n2. 利用备份交换机（alternate-exchange）：处理无法路由到队列的消息（正常都是可路由的，路由的队列所在节点宕机？）\n\n### 消息在消息队列中的存储场景\n\n**问题原因**：\n\n- 持久化了Message，没有持久化队列\n- 唯一的磁盘节点宕机\n\n\n**解决办法**：\n1、消息持久化+队列持久化\n消息设置delivery-mode为2，队列设置为durable\n\n2、使用HA队列\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n\n3、集群设置>=1的磁盘节点。\n磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。\n\n\n\n\n### 消息被消费者消费的过程\n\n**问题原因**：错误代码\n**解决办法**：\n1、使用消费者手动确认消费\n2、消费者程序使用事务提交和回滚批量操作。","source":"_posts/rabbitmq消息可靠性.md","raw":"---\ntitle: rabbitmq消息可靠性\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:19:29\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 消息丢失场景\n\n\n### 消息从生产者写入到消息队列的过程\n\n**问题原因**：\n网络抖动\n\n**解决办法**：\n\n- 事务\n在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。\n缺点：同步操作。生产者吞吐量大大降低。\n\n- 发布者确认\n一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。\n\n\n- 其他\n1. 使用mandatory 设置true：不可路由消息回发到生产者（正常都是可路由的，路由的队列所在节点宕机？）\n2. 利用备份交换机（alternate-exchange）：处理无法路由到队列的消息（正常都是可路由的，路由的队列所在节点宕机？）\n\n### 消息在消息队列中的存储场景\n\n**问题原因**：\n\n- 持久化了Message，没有持久化队列\n- 唯一的磁盘节点宕机\n\n\n**解决办法**：\n1、消息持久化+队列持久化\n消息设置delivery-mode为2，队列设置为durable\n\n2、使用HA队列\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n\n3、集群设置>=1的磁盘节点。\n磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。\n\n\n\n\n### 消息被消费者消费的过程\n\n**问题原因**：错误代码\n**解决办法**：\n1、使用消费者手动确认消费\n2、消费者程序使用事务提交和回滚批量操作。","slug":"rabbitmq消息可靠性","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxih002encufq5pxzox2","content":"<h2 id=\"消息丢失场景\"><a href=\"#消息丢失场景\" class=\"headerlink\" title=\"消息丢失场景\"></a>消息丢失场景</h2><h3 id=\"消息从生产者写入到消息队列的过程\"><a href=\"#消息从生产者写入到消息队列的过程\" class=\"headerlink\" title=\"消息从生产者写入到消息队列的过程\"></a>消息从生产者写入到消息队列的过程</h3><p><strong>问题原因</strong>：<br>网络抖动</p>\n<p><strong>解决办法</strong>：</p>\n<ul>\n<li><p>事务<br>在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。<br>缺点：同步操作。生产者吞吐量大大降低。</p>\n</li>\n<li><p>发布者确认<br>一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。</p>\n</li>\n</ul>\n<ul>\n<li>其他</li>\n</ul>\n<ol>\n<li>使用mandatory 设置true：不可路由消息回发到生产者（正常都是可路由的，路由的队列所在节点宕机？）</li>\n<li>利用备份交换机（alternate-exchange）：处理无法路由到队列的消息（正常都是可路由的，路由的队列所在节点宕机？）</li>\n</ol>\n<h3 id=\"消息在消息队列中的存储场景\"><a href=\"#消息在消息队列中的存储场景\" class=\"headerlink\" title=\"消息在消息队列中的存储场景\"></a>消息在消息队列中的存储场景</h3><p><strong>问题原因</strong>：</p>\n<ul>\n<li>持久化了Message，没有持久化队列</li>\n<li>唯一的磁盘节点宕机</li>\n</ul>\n<p><strong>解决办法</strong>：<br>1、消息持久化+队列持久化<br>消息设置delivery-mode为2，队列设置为durable</p>\n<p>2、使用HA队列<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>3、集群设置&gt;=1的磁盘节点。<br>磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。</p>\n<h3 id=\"消息被消费者消费的过程\"><a href=\"#消息被消费者消费的过程\" class=\"headerlink\" title=\"消息被消费者消费的过程\"></a>消息被消费者消费的过程</h3><p><strong>问题原因</strong>：错误代码<br><strong>解决办法</strong>：<br>1、使用消费者手动确认消费<br>2、消费者程序使用事务提交和回滚批量操作。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"消息丢失场景\"><a href=\"#消息丢失场景\" class=\"headerlink\" title=\"消息丢失场景\"></a>消息丢失场景</h2><h3 id=\"消息从生产者写入到消息队列的过程\"><a href=\"#消息从生产者写入到消息队列的过程\" class=\"headerlink\" title=\"消息从生产者写入到消息队列的过程\"></a>消息从生产者写入到消息队列的过程</h3><p><strong>问题原因</strong>：<br>网络抖动</p>\n<p><strong>解决办法</strong>：</p>\n<ul>\n<li><p>事务<br>在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。<br>缺点：同步操作。生产者吞吐量大大降低。</p>\n</li>\n<li><p>发布者确认<br>一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。</p>\n</li>\n</ul>\n<ul>\n<li>其他</li>\n</ul>\n<ol>\n<li>使用mandatory 设置true：不可路由消息回发到生产者（正常都是可路由的，路由的队列所在节点宕机？）</li>\n<li>利用备份交换机（alternate-exchange）：处理无法路由到队列的消息（正常都是可路由的，路由的队列所在节点宕机？）</li>\n</ol>\n<h3 id=\"消息在消息队列中的存储场景\"><a href=\"#消息在消息队列中的存储场景\" class=\"headerlink\" title=\"消息在消息队列中的存储场景\"></a>消息在消息队列中的存储场景</h3><p><strong>问题原因</strong>：</p>\n<ul>\n<li>持久化了Message，没有持久化队列</li>\n<li>唯一的磁盘节点宕机</li>\n</ul>\n<p><strong>解决办法</strong>：<br>1、消息持久化+队列持久化<br>消息设置delivery-mode为2，队列设置为durable</p>\n<p>2、使用HA队列<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>3、集群设置&gt;=1的磁盘节点。<br>磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。</p>\n<h3 id=\"消息被消费者消费的过程\"><a href=\"#消息被消费者消费的过程\" class=\"headerlink\" title=\"消息被消费者消费的过程\"></a>消息被消费者消费的过程</h3><p><strong>问题原因</strong>：错误代码<br><strong>解决办法</strong>：<br>1、使用消费者手动确认消费<br>2、消费者程序使用事务提交和回滚批量操作。</p>\n"},{"title":"rabbitmq消息发布","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:13:06.000Z","password":null,"summary":null,"_content":"\n## 可靠投递\n\n------------\n\n### mandatory\n\n当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。\nBasic.Return是异步的，在消息发布后的任何时候都可能发生。\n在rabbitpy库中，客户端自动接收Basic.Return，并触发异常\n\n示例程序：发布失败\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        # Create the message to send\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel,\n                                   body,\n                                   {'content_type': 'text/plain',\n                                    'timestamp': datetime.datetime.now(),\n                                    'message_type': 'graphite metric'})\n\n        # Publish the message to the exchange with the routing key\n        # \"server-metrics\" and make sure it is routed to the exchange\n        message.publish('chapter2-example', 'server-metrics', mandatory=True)\n```\n\n示例程序：异常捕获\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        properties = {'content_type': 'text/plain',\n                      'timestamp': datetime.datetime.now(),\n                      'message_type': 'graphite metric'}\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel, body, properties)\n        message.publish('chapter2-example',\n                        'server-metrics',\n                        mandatory=True)\nexcept rabbitpy.exceptions.MessageReturnedException as error:\n    print('Publish failure: %s' % error)\n```\n\n### 发布者确认\n\n发布者发送给RabbitMQ的每条消息，服务器发送一个确认(Basic.Ack)或者否认相应（Basic.Nack）。\n\n示例程序：发布者确认\n```python\nimport rabbitpy\n\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'chapter4-example')\n        exchange.declare()\n        channel.enable_publisher_confirms()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'message_type': 'very important'})\n        if message.publish('chapter4-example', 'important.message'):\n            print('The message was confirmed')\n```\n\nrabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。\n\n### 备用交换器\n\n处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。\n\n\n示例程序：备用交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        my_ae = rabbitpy.Exchange(channel, 'my-ae',\n                                  exchange_type='fanout')\n        my_ae.declare()\n        args = {'alternate-exchange': my_ae.name}\n        exchange = rabbitpy.Exchange(channel,\n                                     'graphite',\n                                     exchange_type='topic',\n                                     arguments=args)\n        exchange.declare()\n        queue = rabbitpy.Queue(channel, 'unroutable-messages')\n        queue.declare()\n        if queue.bind(my_ae, '#'):\n            print('Queue bound to alternate-exchange')\n```\n\n### 基于事务的批量处理\n\n确保消息投递成功。\n\n\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tx = rabbitpy.Tx(channel)\n        tx.select()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'delivery_mode': 2,\n                                    'message_type': 'important'})\n        message.publish('chapter4-example', 'important.message')\n        try:\n            if tx.commit():\n                print('Transaction committed')\n        except rabbitpy.exceptions.NoActiveTransactionError:\n            print('Tried to commit without active transaction')\n```\n\n由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。\n\n### HA队列\n\n允许队列在多个服务器拥有冗余副本。\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n示例代码：HA队列声明\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel,\n                               'my-ha-queue',\n                               arguments={'x-ha-policy': 'all'})\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n\n示例代码：HA队列指定节点\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        arguments = {'x-ha-policy': 'nodes',\n                     'x-ha-nodes': ['rabbit@node1',\n                                    'rabbit@node2',\n                                    'rabbit@node3']}\n        queue = rabbitpy.Queue(channel,\n                               'my-2nd-ha-queue',\n                               arguments=arguments)\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n### 消息持久化\n\ndelivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。\n\n如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。\n\n\n## rabbitmq回推\n\n发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。\n\n示例代码：检测连接状态\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\nprint('Channel is Blocked? %s' % connection.blocked)\n\n```","source":"_posts/rabbitmq消息发布.md","raw":"---\ntitle: rabbitmq消息发布\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:13:06\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 可靠投递\n\n------------\n\n### mandatory\n\n当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。\nBasic.Return是异步的，在消息发布后的任何时候都可能发生。\n在rabbitpy库中，客户端自动接收Basic.Return，并触发异常\n\n示例程序：发布失败\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        # Create the message to send\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel,\n                                   body,\n                                   {'content_type': 'text/plain',\n                                    'timestamp': datetime.datetime.now(),\n                                    'message_type': 'graphite metric'})\n\n        # Publish the message to the exchange with the routing key\n        # \"server-metrics\" and make sure it is routed to the exchange\n        message.publish('chapter2-example', 'server-metrics', mandatory=True)\n```\n\n示例程序：异常捕获\n```python\nimport datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        properties = {'content_type': 'text/plain',\n                      'timestamp': datetime.datetime.now(),\n                      'message_type': 'graphite metric'}\n        body = 'server.cpu.utilization 25.5 1350884514'\n        message = rabbitpy.Message(channel, body, properties)\n        message.publish('chapter2-example',\n                        'server-metrics',\n                        mandatory=True)\nexcept rabbitpy.exceptions.MessageReturnedException as error:\n    print('Publish failure: %s' % error)\n```\n\n### 发布者确认\n\n发布者发送给RabbitMQ的每条消息，服务器发送一个确认(Basic.Ack)或者否认相应（Basic.Nack）。\n\n示例程序：发布者确认\n```python\nimport rabbitpy\n\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'chapter4-example')\n        exchange.declare()\n        channel.enable_publisher_confirms()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'message_type': 'very important'})\n        if message.publish('chapter4-example', 'important.message'):\n            print('The message was confirmed')\n```\n\nrabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。\n\n### 备用交换器\n\n处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。\n\n\n示例程序：备用交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        my_ae = rabbitpy.Exchange(channel, 'my-ae',\n                                  exchange_type='fanout')\n        my_ae.declare()\n        args = {'alternate-exchange': my_ae.name}\n        exchange = rabbitpy.Exchange(channel,\n                                     'graphite',\n                                     exchange_type='topic',\n                                     arguments=args)\n        exchange.declare()\n        queue = rabbitpy.Queue(channel, 'unroutable-messages')\n        queue.declare()\n        if queue.bind(my_ae, '#'):\n            print('Queue bound to alternate-exchange')\n```\n\n### 基于事务的批量处理\n\n确保消息投递成功。\n\n\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tx = rabbitpy.Tx(channel)\n        tx.select()\n        message = rabbitpy.Message(channel,\n                                   'This is an important message',\n                                   {'content_type': 'text/plain',\n                                    'delivery_mode': 2,\n                                    'message_type': 'important'})\n        message.publish('chapter4-example', 'important.message')\n        try:\n            if tx.commit():\n                print('Transaction committed')\n        except rabbitpy.exceptions.NoActiveTransactionError:\n            print('Tried to commit without active transaction')\n```\n\n由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。\n\n### HA队列\n\n允许队列在多个服务器拥有冗余副本。\n发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。\n\n示例代码：HA队列声明\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel,\n                               'my-ha-queue',\n                               arguments={'x-ha-policy': 'all'})\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n\n示例代码：HA队列指定节点\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        arguments = {'x-ha-policy': 'nodes',\n                     'x-ha-nodes': ['rabbit@node1',\n                                    'rabbit@node2',\n                                    'rabbit@node3']}\n        queue = rabbitpy.Queue(channel,\n                               'my-2nd-ha-queue',\n                               arguments=arguments)\n        if queue.declare():\n            print('Queue declared')\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print('Queue declare failed: %s' % error)\n```\n\n### 消息持久化\n\ndelivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。\n\n如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。\n\n\n## rabbitmq回推\n\n发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。\n\n示例代码：检测连接状态\n```python\nimport rabbitpy\n\nconnection = rabbitpy.Connection()\nprint('Channel is Blocked? %s' % connection.blocked)\n\n```","slug":"rabbitmq消息发布","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxij002gncufhkjn9tyv","content":"<h2 id=\"可靠投递\"><a href=\"#可靠投递\" class=\"headerlink\" title=\"可靠投递\"></a>可靠投递</h2><hr>\n<h3 id=\"mandatory\"><a href=\"#mandatory\" class=\"headerlink\" title=\"mandatory\"></a>mandatory</h3><p>当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。<br>Basic.Return是异步的，在消息发布后的任何时候都可能发生。<br>在rabbitpy库中，客户端自动接收Basic.Return，并触发异常</p>\n<p>示例程序：发布失败</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token comment\" spellcheck=\"true\"># Connect to the default URL of amqp://guest:guest@localhost:15672/%2F</span>\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\"># Create the message to send</span>\n        body <span class=\"token operator\">=</span> <span class=\"token string\">'server.cpu.utilization 25.5 1350884514'</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                   body<span class=\"token punctuation\">,</span>\n                                   <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'graphite metric'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\" spellcheck=\"true\"># Publish the message to the exchange with the routing key</span>\n        <span class=\"token comment\" spellcheck=\"true\"># \"server-metrics\" and make sure it is routed to the exchange</span>\n        message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter2-example'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'server-metrics'</span><span class=\"token punctuation\">,</span> mandatory<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：异常捕获</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token comment\" spellcheck=\"true\"># Connect to the default URL of amqp://guest:guest@localhost:15672/%2F</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                      <span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                      <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'graphite metric'</span><span class=\"token punctuation\">}</span>\n        body <span class=\"token operator\">=</span> <span class=\"token string\">'server.cpu.utilization 25.5 1350884514'</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span>\n        message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter2-example'</span><span class=\"token punctuation\">,</span>\n                        <span class=\"token string\">'server-metrics'</span><span class=\"token punctuation\">,</span>\n                        mandatory<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>MessageReturnedException <span class=\"token keyword\">as</span> error<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Publish failure: %s'</span> <span class=\"token operator\">%</span> error<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"发布者确认\"><a href=\"#发布者确认\" class=\"headerlink\" title=\"发布者确认\"></a>发布者确认</h3><p>发布者发送给RabbitMQ的每条消息，服务器发送一个确认(Basic.Ack)或者否认相应（Basic.Nack）。</p>\n<p>示例程序：发布者确认</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'chapter4-example'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        channel<span class=\"token punctuation\">.</span>enable_publisher_confirms<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                   <span class=\"token string\">'This is an important message'</span><span class=\"token punctuation\">,</span>\n                                   <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'very important'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter4-example'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'important.message'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'The message was confirmed'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>rabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。</p>\n<h3 id=\"备用交换器\"><a href=\"#备用交换器\" class=\"headerlink\" title=\"备用交换器\"></a>备用交换器</h3><p>处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。</p>\n<p>示例程序：备用交换器</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        my_ae <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'my-ae'</span><span class=\"token punctuation\">,</span>\n                                  exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'fanout'</span><span class=\"token punctuation\">)</span>\n        my_ae<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        args <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'alternate-exchange'</span><span class=\"token punctuation\">:</span> my_ae<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">}</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                     <span class=\"token string\">'graphite'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'topic'</span><span class=\"token punctuation\">,</span>\n                                     arguments<span class=\"token operator\">=</span>args<span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'unroutable-messages'</span><span class=\"token punctuation\">)</span>\n        queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span>my_ae<span class=\"token punctuation\">,</span> <span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue bound to alternate-exchange'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"基于事务的批量处理\"><a href=\"#基于事务的批量处理\" class=\"headerlink\" title=\"基于事务的批量处理\"></a>基于事务的批量处理</h3><p>确保消息投递成功。</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        tx <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Tx<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">)</span>\n        tx<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                   <span class=\"token string\">'This is an important message'</span><span class=\"token punctuation\">,</span>\n                                   <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'text/plain'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'delivery_mode'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'message_type'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'important'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'chapter4-example'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'important.message'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> tx<span class=\"token punctuation\">.</span>commit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Transaction committed'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>NoActiveTransactionError<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Tried to commit without active transaction'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。</p>\n<h3 id=\"HA队列\"><a href=\"#HA队列\" class=\"headerlink\" title=\"HA队列\"></a>HA队列</h3><p>允许队列在多个服务器拥有冗余副本。<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>示例代码：HA队列声明</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               <span class=\"token string\">'my-ha-queue'</span><span class=\"token punctuation\">,</span>\n                               arguments<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'x-ha-policy'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'all'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declared'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>RemoteClosedChannelException <span class=\"token keyword\">as</span> error<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declare failed: %s'</span> <span class=\"token operator\">%</span> error<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：HA队列指定节点</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        arguments <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'x-ha-policy'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'nodes'</span><span class=\"token punctuation\">,</span>\n                     <span class=\"token string\">'x-ha-nodes'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'rabbit@node1'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'rabbit@node2'</span><span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'rabbit@node3'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               <span class=\"token string\">'my-2nd-ha-queue'</span><span class=\"token punctuation\">,</span>\n                               arguments<span class=\"token operator\">=</span>arguments<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declared'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> rabbitpy<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>RemoteClosedChannelException <span class=\"token keyword\">as</span> error<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Queue declare failed: %s'</span> <span class=\"token operator\">%</span> error<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"消息持久化\"><a href=\"#消息持久化\" class=\"headerlink\" title=\"消息持久化\"></a>消息持久化</h3><p>delivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。</p>\n<p>如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。</p>\n<h2 id=\"rabbitmq回推\"><a href=\"#rabbitmq回推\" class=\"headerlink\" title=\"rabbitmq回推\"></a>rabbitmq回推</h2><p>发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。</p>\n<p>示例代码：检测连接状态</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Channel is Blocked? %s'</span> <span class=\"token operator\">%</span> connection<span class=\"token punctuation\">.</span>blocked<span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"可靠投递\"><a href=\"#可靠投递\" class=\"headerlink\" title=\"可靠投递\"></a>可靠投递</h2><hr>\n<h3 id=\"mandatory\"><a href=\"#mandatory\" class=\"headerlink\" title=\"mandatory\"></a>mandatory</h3><p>当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。<br>Basic.Return是异步的，在消息发布后的任何时候都可能发生。<br>在rabbitpy库中，客户端自动接收Basic.Return，并触发异常</p>\n<p>示例程序：发布失败</p>\n<pre><code class=\"python\">import datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        # Create the message to send\n        body = &#39;server.cpu.utilization 25.5 1350884514&#39;\n        message = rabbitpy.Message(channel,\n                                   body,\n                                   {&#39;content_type&#39;: &#39;text/plain&#39;,\n                                    &#39;timestamp&#39;: datetime.datetime.now(),\n                                    &#39;message_type&#39;: &#39;graphite metric&#39;})\n\n        # Publish the message to the exchange with the routing key\n        # &quot;server-metrics&quot; and make sure it is routed to the exchange\n        message.publish(&#39;chapter2-example&#39;, &#39;server-metrics&#39;, mandatory=True)</code></pre>\n<p>示例程序：异常捕获</p>\n<pre><code class=\"python\">import datetime\nimport rabbitpy\n\n# Connect to the default URL of amqp://guest:guest@localhost:15672/%2F\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        properties = {&#39;content_type&#39;: &#39;text/plain&#39;,\n                      &#39;timestamp&#39;: datetime.datetime.now(),\n                      &#39;message_type&#39;: &#39;graphite metric&#39;}\n        body = &#39;server.cpu.utilization 25.5 1350884514&#39;\n        message = rabbitpy.Message(channel, body, properties)\n        message.publish(&#39;chapter2-example&#39;,\n                        &#39;server-metrics&#39;,\n                        mandatory=True)\nexcept rabbitpy.exceptions.MessageReturnedException as error:\n    print(&#39;Publish failure: %s&#39; % error)</code></pre>\n<h3 id=\"发布者确认\"><a href=\"#发布者确认\" class=\"headerlink\" title=\"发布者确认\"></a>发布者确认</h3><p>发布者发送给RabbitMQ的每条消息，服务器发送一个确认(Basic.Ack)或者否认相应（Basic.Nack）。</p>\n<p>示例程序：发布者确认</p>\n<pre><code class=\"python\">import rabbitpy\n\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;chapter4-example&#39;)\n        exchange.declare()\n        channel.enable_publisher_confirms()\n        message = rabbitpy.Message(channel,\n                                   &#39;This is an important message&#39;,\n                                   {&#39;content_type&#39;: &#39;text/plain&#39;,\n                                    &#39;message_type&#39;: &#39;very important&#39;})\n        if message.publish(&#39;chapter4-example&#39;, &#39;important.message&#39;):\n            print(&#39;The message was confirmed&#39;)</code></pre>\n<p>rabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。</p>\n<h3 id=\"备用交换器\"><a href=\"#备用交换器\" class=\"headerlink\" title=\"备用交换器\"></a>备用交换器</h3><p>处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。</p>\n<p>示例程序：备用交换器</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        my_ae = rabbitpy.Exchange(channel, &#39;my-ae&#39;,\n                                  exchange_type=&#39;fanout&#39;)\n        my_ae.declare()\n        args = {&#39;alternate-exchange&#39;: my_ae.name}\n        exchange = rabbitpy.Exchange(channel,\n                                     &#39;graphite&#39;,\n                                     exchange_type=&#39;topic&#39;,\n                                     arguments=args)\n        exchange.declare()\n        queue = rabbitpy.Queue(channel, &#39;unroutable-messages&#39;)\n        queue.declare()\n        if queue.bind(my_ae, &#39;#&#39;):\n            print(&#39;Queue bound to alternate-exchange&#39;)</code></pre>\n<h3 id=\"基于事务的批量处理\"><a href=\"#基于事务的批量处理\" class=\"headerlink\" title=\"基于事务的批量处理\"></a>基于事务的批量处理</h3><p>确保消息投递成功。</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tx = rabbitpy.Tx(channel)\n        tx.select()\n        message = rabbitpy.Message(channel,\n                                   &#39;This is an important message&#39;,\n                                   {&#39;content_type&#39;: &#39;text/plain&#39;,\n                                    &#39;delivery_mode&#39;: 2,\n                                    &#39;message_type&#39;: &#39;important&#39;})\n        message.publish(&#39;chapter4-example&#39;, &#39;important.message&#39;)\n        try:\n            if tx.commit():\n                print(&#39;Transaction committed&#39;)\n        except rabbitpy.exceptions.NoActiveTransactionError:\n            print(&#39;Tried to commit without active transaction&#39;)</code></pre>\n<p>由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。</p>\n<h3 id=\"HA队列\"><a href=\"#HA队列\" class=\"headerlink\" title=\"HA队列\"></a>HA队列</h3><p>允许队列在多个服务器拥有冗余副本。<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p>\n<p>示例代码：HA队列声明</p>\n<pre><code class=\"python\">import rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel,\n                               &#39;my-ha-queue&#39;,\n                               arguments={&#39;x-ha-policy&#39;: &#39;all&#39;})\n        if queue.declare():\n            print(&#39;Queue declared&#39;)\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print(&#39;Queue declare failed: %s&#39; % error)</code></pre>\n<p>示例代码：HA队列指定节点</p>\n<pre><code class=\"python\">import rabbitpy\n\nconnection = rabbitpy.Connection()\ntry:\n    with connection.channel() as channel:\n        arguments = {&#39;x-ha-policy&#39;: &#39;nodes&#39;,\n                     &#39;x-ha-nodes&#39;: [&#39;rabbit@node1&#39;,\n                                    &#39;rabbit@node2&#39;,\n                                    &#39;rabbit@node3&#39;]}\n        queue = rabbitpy.Queue(channel,\n                               &#39;my-2nd-ha-queue&#39;,\n                               arguments=arguments)\n        if queue.declare():\n            print(&#39;Queue declared&#39;)\nexcept rabbitpy.exceptions.RemoteClosedChannelException as error:\n    print(&#39;Queue declare failed: %s&#39; % error)</code></pre>\n<h3 id=\"消息持久化\"><a href=\"#消息持久化\" class=\"headerlink\" title=\"消息持久化\"></a>消息持久化</h3><p>delivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。</p>\n<p>如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。</p>\n<h2 id=\"rabbitmq回推\"><a href=\"#rabbitmq回推\" class=\"headerlink\" title=\"rabbitmq回推\"></a>rabbitmq回推</h2><p>发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。</p>\n<p>示例代码：检测连接状态</p>\n<pre><code class=\"python\">import rabbitpy\n\nconnection = rabbitpy.Connection()\nprint(&#39;Channel is Blocked? %s&#39; % connection.blocked)\n</code></pre>\n"},{"title":"order/group by优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T07:45:38.000Z","password":null,"summary":null,"_content":"\n## order by 原理\n\n按照排序原理分[manual][https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html]，MySQL 排序方式分两种：\n\n- 通过有序索引直接返回有序数据：Using index\n- 通过 Filesort 进行的排序：Using filesort\n\nFilesort是内存排序还是磁盘排序取决于排序的数据大小和 sort_buffer_size 配置的大小：\n\n- 如果 “排序的数据大小” < sort_buffer_size: 内存排序\n- 如果 “排序的数据大小” > sort_buffer_size: 磁盘排序\n\n通过trace中的number_of_tmp_files，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。\n\n**Filesort 下的排序模式**\n\n- < sort_key, rowid >双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；\n- < sort_key, additional_fields >单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；\n- < sort_key, packed_additional_fields >打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。\n\n单路和双路的选择：\n\n- 如果 max_length_for_sort_data 比查询字段的总长度大，那么使用 < sort_key, additional_fields >排序模式；\n- 如果 max_length_for_sort_data 比查询字段的总长度小，那么使用 <sort_key, rowid> 排序模式。\n\n如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。\n\n## order by 优化\n\n###  添加合适索引\n\n1、 排序字段添加索引\n\n2、多个字段排序添加联合索引\n\n3、先等值查询再排序，在条件字段和排序字段添加联合索引\n\n### 去掉不必要的返回字段\n\n过多返回字段可能需要扫描索引再回表，成本全表扫描更高。\n\n```mysql\nselect id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */\n```\n\n### 修改参数\n\nmax_length_for_sort_data：如果觉得排序效率比较低，可以适当加大 max_length_for_sort_data 的值\n\nsort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。\n\n### 无法使用索引\n\n1、 使用范围查询再排序：\n\n```mysql\nselect id,a,b from t1 where a>9000 order by b;\n```\n\n2、ASC 和 DESC 混合使用\n\n```mysql\nselect id,a,b from t1 order by a asc,b desc;\n```\n\n## group by优化\n\n默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致，如果目的只是分组而不用排序，可以指定 order by null 禁止排序。\n\n","source":"_posts/order-group-by优化.md","raw":"---\ntitle: order/group by优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 15:45:38\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## order by 原理\n\n按照排序原理分[manual][https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html]，MySQL 排序方式分两种：\n\n- 通过有序索引直接返回有序数据：Using index\n- 通过 Filesort 进行的排序：Using filesort\n\nFilesort是内存排序还是磁盘排序取决于排序的数据大小和 sort_buffer_size 配置的大小：\n\n- 如果 “排序的数据大小” < sort_buffer_size: 内存排序\n- 如果 “排序的数据大小” > sort_buffer_size: 磁盘排序\n\n通过trace中的number_of_tmp_files，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。\n\n**Filesort 下的排序模式**\n\n- < sort_key, rowid >双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；\n- < sort_key, additional_fields >单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；\n- < sort_key, packed_additional_fields >打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。\n\n单路和双路的选择：\n\n- 如果 max_length_for_sort_data 比查询字段的总长度大，那么使用 < sort_key, additional_fields >排序模式；\n- 如果 max_length_for_sort_data 比查询字段的总长度小，那么使用 <sort_key, rowid> 排序模式。\n\n如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。\n\n## order by 优化\n\n###  添加合适索引\n\n1、 排序字段添加索引\n\n2、多个字段排序添加联合索引\n\n3、先等值查询再排序，在条件字段和排序字段添加联合索引\n\n### 去掉不必要的返回字段\n\n过多返回字段可能需要扫描索引再回表，成本全表扫描更高。\n\n```mysql\nselect id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */\n```\n\n### 修改参数\n\nmax_length_for_sort_data：如果觉得排序效率比较低，可以适当加大 max_length_for_sort_data 的值\n\nsort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。\n\n### 无法使用索引\n\n1、 使用范围查询再排序：\n\n```mysql\nselect id,a,b from t1 where a>9000 order by b;\n```\n\n2、ASC 和 DESC 混合使用\n\n```mysql\nselect id,a,b from t1 order by a asc,b desc;\n```\n\n## group by优化\n\n默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致，如果目的只是分组而不用排序，可以指定 order by null 禁止排序。\n\n","slug":"order-group-by优化","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxio002jncufbqmlpy9j","content":"<h2 id=\"order-by-原理\"><a href=\"#order-by-原理\" class=\"headerlink\" title=\"order by 原理\"></a>order by 原理</h2><p>按照排序原理分[manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html]，MySQL\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html]，MySQL</a> 排序方式分两种：</p>\n<ul>\n<li>通过有序索引直接返回有序数据：Using index</li>\n<li>通过 Filesort 进行的排序：Using filesort</li>\n</ul>\n<p>Filesort是内存排序还是磁盘排序取决于排序的数据大小和 sort_buffer_size 配置的大小：</p>\n<ul>\n<li>如果 “排序的数据大小” &lt; sort_buffer_size: 内存排序</li>\n<li>如果 “排序的数据大小” &gt; sort_buffer_size: 磁盘排序</li>\n</ul>\n<p>通过trace中的number_of_tmp_files，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。</p>\n<p><strong>Filesort 下的排序模式</strong></p>\n<ul>\n<li>&lt; sort_key, rowid &gt;双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；</li>\n<li>&lt; sort_key, additional_fields &gt;单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；</li>\n<li>&lt; sort_key, packed_additional_fields &gt;打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。</li>\n</ul>\n<p>单路和双路的选择：</p>\n<ul>\n<li>如果 max_length_for_sort_data 比查询字段的总长度大，那么使用 &lt; sort_key, additional_fields &gt;排序模式；</li>\n<li>如果 max_length_for_sort_data 比查询字段的总长度小，那么使用 &lt;sort_key, rowid&gt; 排序模式。</li>\n</ul>\n<p>如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。</p>\n<h2 id=\"order-by-优化\"><a href=\"#order-by-优化\" class=\"headerlink\" title=\"order by 优化\"></a>order by 优化</h2><h3 id=\"添加合适索引\"><a href=\"#添加合适索引\" class=\"headerlink\" title=\"添加合适索引\"></a>添加合适索引</h3><p>1、 排序字段添加索引</p>\n<p>2、多个字段排序添加联合索引</p>\n<p>3、先等值查询再排序，在条件字段和排序字段添加联合索引</p>\n<h3 id=\"去掉不必要的返回字段\"><a href=\"#去掉不必要的返回字段\" class=\"headerlink\" title=\"去掉不必要的返回字段\"></a>去掉不必要的返回字段</h3><p>过多返回字段可能需要扫描索引再回表，成本全表扫描更高。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"修改参数\"><a href=\"#修改参数\" class=\"headerlink\" title=\"修改参数\"></a>修改参数</h3><p>max_length_for_sort_data：如果觉得排序效率比较低，可以适当加大 max_length_for_sort_data 的值</p>\n<p>sort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。</p>\n<h3 id=\"无法使用索引\"><a href=\"#无法使用索引\" class=\"headerlink\" title=\"无法使用索引\"></a>无法使用索引</h3><p>1、 使用范围查询再排序：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select id,a,b from t1 where a>9000 order by b;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>2、ASC 和 DESC 混合使用</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select id,a,b from t1 order by a asc,b desc;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"group-by优化\"><a href=\"#group-by优化\" class=\"headerlink\" title=\"group by优化\"></a>group by优化</h2><p>默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致，如果目的只是分组而不用排序，可以指定 order by null 禁止排序。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"order-by-原理\"><a href=\"#order-by-原理\" class=\"headerlink\" title=\"order by 原理\"></a>order by 原理</h2><p>按照排序原理分[manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html]，MySQL\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html]，MySQL</a> 排序方式分两种：</p>\n<ul>\n<li>通过有序索引直接返回有序数据：Using index</li>\n<li>通过 Filesort 进行的排序：Using filesort</li>\n</ul>\n<p>Filesort是内存排序还是磁盘排序取决于排序的数据大小和 sort_buffer_size 配置的大小：</p>\n<ul>\n<li>如果 “排序的数据大小” &lt; sort_buffer_size: 内存排序</li>\n<li>如果 “排序的数据大小” &gt; sort_buffer_size: 磁盘排序</li>\n</ul>\n<p>通过trace中的number_of_tmp_files，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。</p>\n<p><strong>Filesort 下的排序模式</strong></p>\n<ul>\n<li>&lt; sort_key, rowid &gt;双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；</li>\n<li>&lt; sort_key, additional_fields &gt;单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；</li>\n<li>&lt; sort_key, packed_additional_fields &gt;打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。</li>\n</ul>\n<p>单路和双路的选择：</p>\n<ul>\n<li>如果 max_length_for_sort_data 比查询字段的总长度大，那么使用 &lt; sort_key, additional_fields &gt;排序模式；</li>\n<li>如果 max_length_for_sort_data 比查询字段的总长度小，那么使用 &lt;sort_key, rowid&gt; 排序模式。</li>\n</ul>\n<p>如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。</p>\n<h2 id=\"order-by-优化\"><a href=\"#order-by-优化\" class=\"headerlink\" title=\"order by 优化\"></a>order by 优化</h2><h3 id=\"添加合适索引\"><a href=\"#添加合适索引\" class=\"headerlink\" title=\"添加合适索引\"></a>添加合适索引</h3><p>1、 排序字段添加索引</p>\n<p>2、多个字段排序添加联合索引</p>\n<p>3、先等值查询再排序，在条件字段和排序字段添加联合索引</p>\n<h3 id=\"去掉不必要的返回字段\"><a href=\"#去掉不必要的返回字段\" class=\"headerlink\" title=\"去掉不必要的返回字段\"></a>去掉不必要的返回字段</h3><p>过多返回字段可能需要扫描索引再回表，成本全表扫描更高。</p>\n<pre><code class=\"mysql\">select id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */</code></pre>\n<h3 id=\"修改参数\"><a href=\"#修改参数\" class=\"headerlink\" title=\"修改参数\"></a>修改参数</h3><p>max_length_for_sort_data：如果觉得排序效率比较低，可以适当加大 max_length_for_sort_data 的值</p>\n<p>sort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。</p>\n<h3 id=\"无法使用索引\"><a href=\"#无法使用索引\" class=\"headerlink\" title=\"无法使用索引\"></a>无法使用索引</h3><p>1、 使用范围查询再排序：</p>\n<pre><code class=\"mysql\">select id,a,b from t1 where a&gt;9000 order by b;</code></pre>\n<p>2、ASC 和 DESC 混合使用</p>\n<pre><code class=\"mysql\">select id,a,b from t1 order by a asc,b desc;</code></pre>\n<h2 id=\"group-by优化\"><a href=\"#group-by优化\" class=\"headerlink\" title=\"group by优化\"></a>group by优化</h2><p>默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致，如果目的只是分组而不用排序，可以指定 order by null 禁止排序。</p>\n"},{"title":"rabbitmq消息消费","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:16:01.000Z","password":null,"summary":null,"_content":"\n\n\n## 消费方法\n\n------------\n\n### **Basic.Get**\n\n - 每次接收消息必须发送一次请求 \n - 有消息可用，RabbitMQ返回Basic.GetOk以及消息\n - 无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。\n\n示例程序\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == 'stop':\n                    break\n```\n\n###**Basic.Consume**\n\n- 消费者可用时，异步方式发送消息\n- 应用程序自动接收消息，直到Basic.Cancel\n- 仍然需要确认消息\n\n示例程序\n```python\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint(）\n    # 消息确认\n    message.ack()\n```\n\n**消费者标签**\n应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。\n客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。\n\n示例代码：监听消息直到，收到停止消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n            if message.body == 'stop':\n                break\n```\n\n\n### **对比**\nConsume吞吐量更大。Get包含了每条消息的同步通信开销。\n\n\n---------------\n\n## 消费性能优化\n\n----------------\n\n### 1、no-ack\n\n应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。\n\n示例代码：消费不确认\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()\n```\n\n### 2、预取\n\nQoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。\n\n示例程序：指定QoS\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #预取数为10\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n```\n\n应用程序不需要确认每条消息，可确认所有以前未读消息。\n\n示例程序：多消息确认\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            unacknowledged += 1\n            if unacknowledged == 10:\n                # 确认所有未确认消息\n                message.ack(all_previous=True)\n                unacknowledged = 0\n\n```\n\n### 3、事务\n\n事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。\n\n---------\n\n## 拒绝消息\n\n--------\n\n### Basic.Reject\n\n通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。\n\n示例程序：消息拒绝\n```\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint()\n    print('Redelivered: %s' % message.redelivered)\n    message.reject(True)\n```\n\n### Basic.Nack\n\n同时拒绝多个消息\n\n### 死信交换器（DLX）\n\n创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。\n\n示例程序：指定死信交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #死信交换器\n        rabbitpy.Exchange(channel, 'rejected-messages').declare()\n        queue = rabbitpy.Queue(channel, 'dlx-example',\n                               dead_letter_exchange='rejected-messages')\n        queue.declare()\n\n```\n\n---------\n\n## 控制队列\n\n----------\n\n### 临时队列\n\n**自动删除队列**\n消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。\n\n示例程序：自动删除队列auto_delete=True\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'ad-example', auto_delete=True)\n        queue.declare()\n```\n\n**只允许单个消费者**\n只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。\n\n示例程序：独占队列exclusive\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'exclusive-example',\n                               exclusive=True)\n        queue.declare()\n```\n\n**自动过期队列**\n如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。\n\n示例程序：自动过期队列\n```\nimport rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-queue',\n                               arguments={'x-expires': 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print('The queue no longer exists')\n```\n\n### 永久队列\n\n**队列持久性**\n服务器重启后队列仍然存在。\n示例程序：持久队列\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'durable-queue',\n                               durable=True)\n        if queue.declare():\n            print('Queue declared')\n```\n\n**队列消息自动过期**\n同时指定死信交换器和消息TTL，过期消息将成为死信消息。\n\n示例程序：消息TTL\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-msg-queue',\n                               arguments={'x-message-ttl': 1000})\n         queue.declare()\n\n```\n\n**最大队列长度**\n一旦达到最大值，添加新消息时，删除队列前端的消息。声明队列时，如果指定死信交换器，前端移除的消息将成为死信。\n\n示例程序：最大长度队列\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'max-length-queue',\n                               arguments={'x-max-length': 1000})\n        queue.declare()\n\n```\n\n\n### 队列设置参数\n\n| 参数                      | 说明                                 |\n| ------------------------- | ------------------------------------ |\n| x-dead-letter-exchange    | 死信交换器，路由不重发且被拒绝的消息 |\n| x-dead-letter-routing-key | 死信消息的可选路由键                 |\n| x-expires                 | 队列在指定的毫秒数后删除             |\n| x-ha-proxy                | 创建HA队列                           |\n| x-ha-nodes                | HA队列分布的节点                     |\n| x-max-length              | 队列的最大消息数                     |\n| x-message-ttl             | 毫秒为单位的队列过期时间             |\n| x-max-priority            | 队列优先级排序                       |","source":"_posts/rabbitmq消息消费.md","raw":"---\ntitle: rabbitmq消息消费\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:16:01\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n\n\n## 消费方法\n\n------------\n\n### **Basic.Get**\n\n - 每次接收消息必须发送一次请求 \n - 有消息可用，RabbitMQ返回Basic.GetOk以及消息\n - 无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。\n\n示例程序\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == 'stop':\n                    break\n```\n\n###**Basic.Consume**\n\n- 消费者可用时，异步方式发送消息\n- 应用程序自动接收消息，直到Basic.Cancel\n- 仍然需要确认消息\n\n示例程序\n```python\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint(）\n    # 消息确认\n    message.ack()\n```\n\n**消费者标签**\n应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。\n客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。\n\n示例代码：监听消息直到，收到停止消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n            if message.body == 'stop':\n                break\n```\n\n\n### **对比**\nConsume吞吐量更大。Get包含了每条消息的同步通信开销。\n\n\n---------------\n\n## 消费性能优化\n\n----------------\n\n### 1、no-ack\n\n应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。\n\n示例代码：消费不确认\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'test-messages')\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()\n```\n\n### 2、预取\n\nQoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。\n\n示例程序：指定QoS\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #预取数为10\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            message.ack()\n```\n\n应用程序不需要确认每条消息，可确认所有以前未读消息。\n\n示例程序：多消息确认\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, 'test-messages'):\n            message.pprint()\n            unacknowledged += 1\n            if unacknowledged == 10:\n                # 确认所有未确认消息\n                message.ack(all_previous=True)\n                unacknowledged = 0\n\n```\n\n### 3、事务\n\n事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。\n\n---------\n\n## 拒绝消息\n\n--------\n\n### Basic.Reject\n\n通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。\n\n示例程序：消息拒绝\n```\nimport rabbitpy\n\nfor message in rabbitpy.consume('amqp://guest:guest@localhost:5672/%2f',\n                                'test-messages'):\n    message.pprint()\n    print('Redelivered: %s' % message.redelivered)\n    message.reject(True)\n```\n\n### Basic.Nack\n\n同时拒绝多个消息\n\n### 死信交换器（DLX）\n\n创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。\n\n示例程序：指定死信交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #死信交换器\n        rabbitpy.Exchange(channel, 'rejected-messages').declare()\n        queue = rabbitpy.Queue(channel, 'dlx-example',\n                               dead_letter_exchange='rejected-messages')\n        queue.declare()\n\n```\n\n---------\n\n## 控制队列\n\n----------\n\n### 临时队列\n\n**自动删除队列**\n消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。\n\n示例程序：自动删除队列auto_delete=True\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'ad-example', auto_delete=True)\n        queue.declare()\n```\n\n**只允许单个消费者**\n只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。\n\n示例程序：独占队列exclusive\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'exclusive-example',\n                               exclusive=True)\n        queue.declare()\n```\n\n**自动过期队列**\n如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。\n\n示例程序：自动过期队列\n```\nimport rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-queue',\n                               arguments={'x-expires': 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print('The queue no longer exists')\n```\n\n### 永久队列\n\n**队列持久性**\n服务器重启后队列仍然存在。\n示例程序：持久队列\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'durable-queue',\n                               durable=True)\n        if queue.declare():\n            print('Queue declared')\n```\n\n**队列消息自动过期**\n同时指定死信交换器和消息TTL，过期消息将成为死信消息。\n\n示例程序：消息TTL\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'expiring-msg-queue',\n                               arguments={'x-message-ttl': 1000})\n         queue.declare()\n\n```\n\n**最大队列长度**\n一旦达到最大值，添加新消息时，删除队列前端的消息。声明队列时，如果指定死信交换器，前端移除的消息将成为死信。\n\n示例程序：最大长度队列\n```\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, 'max-length-queue',\n                               arguments={'x-max-length': 1000})\n        queue.declare()\n\n```\n\n\n### 队列设置参数\n\n| 参数                      | 说明                                 |\n| ------------------------- | ------------------------------------ |\n| x-dead-letter-exchange    | 死信交换器，路由不重发且被拒绝的消息 |\n| x-dead-letter-routing-key | 死信消息的可选路由键                 |\n| x-expires                 | 队列在指定的毫秒数后删除             |\n| x-ha-proxy                | 创建HA队列                           |\n| x-ha-nodes                | HA队列分布的节点                     |\n| x-max-length              | 队列的最大消息数                     |\n| x-message-ttl             | 毫秒为单位的队列过期时间             |\n| x-max-priority            | 队列优先级排序                       |","slug":"rabbitmq消息消费","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxis002mncufhf7b10v3","content":"<h2 id=\"消费方法\"><a href=\"#消费方法\" class=\"headerlink\" title=\"消费方法\"></a>消费方法</h2><hr>\n<h3 id=\"Basic-Get\"><a href=\"#Basic-Get\" class=\"headerlink\" title=\"Basic.Get\"></a><strong>Basic.Get</strong></h3><ul>\n<li>每次接收消息必须发送一次请求 </li>\n<li>有消息可用，RabbitMQ返回Basic.GetOk以及消息</li>\n<li>无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。</li>\n</ul>\n<p>示例程序</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == &#39;stop&#39;:\n                    break</code></pre><p>###<strong>Basic.Consume</strong></p>\n<ul>\n<li>消费者可用时，异步方式发送消息</li>\n<li>应用程序自动接收消息，直到Basic.Cancel</li>\n<li>仍然需要确认消息</li>\n</ul>\n<p>示例程序</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>consume<span class=\"token punctuation\">(</span><span class=\"token string\">'amqp://guest:guest@localhost:5672/%2f'</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span>）\n    <span class=\"token comment\" spellcheck=\"true\"># 消息确认</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>消费者标签</strong><br>应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。<br>客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。</p>\n<p>示例代码：监听消息直到，收到停止消息</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> message<span class=\"token punctuation\">.</span>body <span class=\"token operator\">==</span> <span class=\"token string\">'stop'</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">break</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a><strong>对比</strong></h3><p>Consume吞吐量更大。Get包含了每条消息的同步通信开销。</p>\n<hr>\n<h2 id=\"消费性能优化\"><a href=\"#消费性能优化\" class=\"headerlink\" title=\"消费性能优化\"></a>消费性能优化</h2><hr>\n<h3 id=\"1、no-ack\"><a href=\"#1、no-ack\" class=\"headerlink\" title=\"1、no-ack\"></a>1、no-ack</h3><p>应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。</p>\n<p>示例代码：消费不确认</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()</code></pre><h3 id=\"2、预取\"><a href=\"#2、预取\" class=\"headerlink\" title=\"2、预取\"></a>2、预取</h3><p>QoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。</p>\n<p>示例程序：指定QoS</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\">#预取数为10</span>\n        channel<span class=\"token punctuation\">.</span>prefetch_count<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>应用程序不需要确认每条消息，可确认所有以前未读消息。</p>\n<p>示例程序：多消息确认</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        channel<span class=\"token punctuation\">.</span>prefetch_count<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'test-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            message<span class=\"token punctuation\">.</span>pprint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            unacknowledged <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">if</span> unacknowledged <span class=\"token operator\">==</span> <span class=\"token number\">10</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\" spellcheck=\"true\"># 确认所有未确认消息</span>\n                message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span>all_previous<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n                unacknowledged <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"3、事务\"><a href=\"#3、事务\" class=\"headerlink\" title=\"3、事务\"></a>3、事务</h3><p>事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。</p>\n<hr>\n<h2 id=\"拒绝消息\"><a href=\"#拒绝消息\" class=\"headerlink\" title=\"拒绝消息\"></a>拒绝消息</h2><hr>\n<h3 id=\"Basic-Reject\"><a href=\"#Basic-Reject\" class=\"headerlink\" title=\"Basic.Reject\"></a>Basic.Reject</h3><p>通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。</p>\n<p>示例程序：消息拒绝</p>\n<pre><code>import rabbitpy\n\nfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,\n                                &#39;test-messages&#39;):\n    message.pprint()\n    print(&#39;Redelivered: %s&#39; % message.redelivered)\n    message.reject(True)</code></pre><h3 id=\"Basic-Nack\"><a href=\"#Basic-Nack\" class=\"headerlink\" title=\"Basic.Nack\"></a>Basic.Nack</h3><p>同时拒绝多个消息</p>\n<h3 id=\"死信交换器（DLX）\"><a href=\"#死信交换器（DLX）\" class=\"headerlink\" title=\"死信交换器（DLX）\"></a>死信交换器（DLX）</h3><p>创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。</p>\n<p>示例程序：指定死信交换器</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\">#死信交换器</span>\n        rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'rejected-messages'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'dlx-example'</span><span class=\"token punctuation\">,</span>\n                               dead_letter_exchange<span class=\"token operator\">=</span><span class=\"token string\">'rejected-messages'</span><span class=\"token punctuation\">)</span>\n        queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<hr>\n<h2 id=\"控制队列\"><a href=\"#控制队列\" class=\"headerlink\" title=\"控制队列\"></a>控制队列</h2><hr>\n<h3 id=\"临时队列\"><a href=\"#临时队列\" class=\"headerlink\" title=\"临时队列\"></a>临时队列</h3><p><strong>自动删除队列</strong><br>消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。</p>\n<p>示例程序：自动删除队列auto_delete=True</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;ad-example&#39;, auto_delete=True)\n        queue.declare()</code></pre><p><strong>只允许单个消费者</strong><br>只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。</p>\n<p>示例程序：独占队列exclusive</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;exclusive-example&#39;,\n                               exclusive=True)\n        queue.declare()</code></pre><p><strong>自动过期队列</strong><br>如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。</p>\n<p>示例程序：自动过期队列</p>\n<pre><code>import rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-queue&#39;,\n                               arguments={&#39;x-expires&#39;: 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print(&#39;The queue no longer exists&#39;)</code></pre><h3 id=\"永久队列\"><a href=\"#永久队列\" class=\"headerlink\" title=\"永久队列\"></a>永久队列</h3><p><strong>队列持久性</strong><br>服务器重启后队列仍然存在。<br>示例程序：持久队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;durable-queue&#39;,\n                               durable=True)\n        if queue.declare():\n            print(&#39;Queue declared&#39;)</code></pre><p><strong>队列消息自动过期</strong><br>同时指定死信交换器和消息TTL，过期消息将成为死信消息。</p>\n<p>示例程序：消息TTL</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-msg-queue&#39;,\n                               arguments={&#39;x-message-ttl&#39;: 1000})\n         queue.declare()\n</code></pre><p><strong>最大队列长度</strong><br>一旦达到最大值，添加新消息时，删除队列前端的消息。声明队列时，如果指定死信交换器，前端移除的消息将成为死信。</p>\n<p>示例程序：最大长度队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;max-length-queue&#39;,\n                               arguments={&#39;x-max-length&#39;: 1000})\n        queue.declare()\n</code></pre><h3 id=\"队列设置参数\"><a href=\"#队列设置参数\" class=\"headerlink\" title=\"队列设置参数\"></a>队列设置参数</h3><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>x-dead-letter-exchange</td>\n<td>死信交换器，路由不重发且被拒绝的消息</td>\n</tr>\n<tr>\n<td>x-dead-letter-routing-key</td>\n<td>死信消息的可选路由键</td>\n</tr>\n<tr>\n<td>x-expires</td>\n<td>队列在指定的毫秒数后删除</td>\n</tr>\n<tr>\n<td>x-ha-proxy</td>\n<td>创建HA队列</td>\n</tr>\n<tr>\n<td>x-ha-nodes</td>\n<td>HA队列分布的节点</td>\n</tr>\n<tr>\n<td>x-max-length</td>\n<td>队列的最大消息数</td>\n</tr>\n<tr>\n<td>x-message-ttl</td>\n<td>毫秒为单位的队列过期时间</td>\n</tr>\n<tr>\n<td>x-max-priority</td>\n<td>队列优先级排序</td>\n</tr>\n</tbody></table>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"消费方法\"><a href=\"#消费方法\" class=\"headerlink\" title=\"消费方法\"></a>消费方法</h2><hr>\n<h3 id=\"Basic-Get\"><a href=\"#Basic-Get\" class=\"headerlink\" title=\"Basic.Get\"></a><strong>Basic.Get</strong></h3><ul>\n<li>每次接收消息必须发送一次请求 </li>\n<li>有消息可用，RabbitMQ返回Basic.GetOk以及消息</li>\n<li>无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。</li>\n</ul>\n<p>示例程序</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        queue.declare()\n        while True:\n            message = queue.get()\n            if message:\n                message.pprint()\n                # 确认消息\n                message.ack()\n                if message.body == &#39;stop&#39;:\n                    break</code></pre><p>###<strong>Basic.Consume</strong></p>\n<ul>\n<li>消费者可用时，异步方式发送消息</li>\n<li>应用程序自动接收消息，直到Basic.Cancel</li>\n<li>仍然需要确认消息</li>\n</ul>\n<p>示例程序</p>\n<pre><code class=\"python\">import rabbitpy\n\nfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,\n                                &#39;test-messages&#39;):\n    message.pprint(）\n    # 消息确认\n    message.ack()</code></pre>\n<p><strong>消费者标签</strong><br>应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。<br>客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。</p>\n<p>示例代码：监听消息直到，收到停止消息</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for message in rabbitpy.Queue(channel, &#39;test-messages&#39;):\n            message.pprint()\n            message.ack()\n            if message.body == &#39;stop&#39;:\n                break</code></pre>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a><strong>对比</strong></h3><p>Consume吞吐量更大。Get包含了每条消息的同步通信开销。</p>\n<hr>\n<h2 id=\"消费性能优化\"><a href=\"#消费性能优化\" class=\"headerlink\" title=\"消费性能优化\"></a>消费性能优化</h2><hr>\n<h3 id=\"1、no-ack\"><a href=\"#1、no-ack\" class=\"headerlink\" title=\"1、no-ack\"></a>1、no-ack</h3><p>应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。</p>\n<p>示例代码：消费不确认</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)\n        for message in queue.consume_messages(no_ack=True):\n            message.pprint()</code></pre><h3 id=\"2、预取\"><a href=\"#2、预取\" class=\"headerlink\" title=\"2、预取\"></a>2、预取</h3><p>QoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。</p>\n<p>示例程序：指定QoS</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #预取数为10\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, &#39;test-messages&#39;):\n            message.pprint()\n            message.ack()</code></pre>\n<p>应用程序不需要确认每条消息，可确认所有以前未读消息。</p>\n<p>示例程序：多消息确认</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        channel.prefetch_count(10)\n        for message in rabbitpy.Queue(channel, &#39;test-messages&#39;):\n            message.pprint()\n            unacknowledged += 1\n            if unacknowledged == 10:\n                # 确认所有未确认消息\n                message.ack(all_previous=True)\n                unacknowledged = 0\n</code></pre>\n<h3 id=\"3、事务\"><a href=\"#3、事务\" class=\"headerlink\" title=\"3、事务\"></a>3、事务</h3><p>事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。</p>\n<hr>\n<h2 id=\"拒绝消息\"><a href=\"#拒绝消息\" class=\"headerlink\" title=\"拒绝消息\"></a>拒绝消息</h2><hr>\n<h3 id=\"Basic-Reject\"><a href=\"#Basic-Reject\" class=\"headerlink\" title=\"Basic.Reject\"></a>Basic.Reject</h3><p>通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。</p>\n<p>示例程序：消息拒绝</p>\n<pre><code>import rabbitpy\n\nfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,\n                                &#39;test-messages&#39;):\n    message.pprint()\n    print(&#39;Redelivered: %s&#39; % message.redelivered)\n    message.reject(True)</code></pre><h3 id=\"Basic-Nack\"><a href=\"#Basic-Nack\" class=\"headerlink\" title=\"Basic.Nack\"></a>Basic.Nack</h3><p>同时拒绝多个消息</p>\n<h3 id=\"死信交换器（DLX）\"><a href=\"#死信交换器（DLX）\" class=\"headerlink\" title=\"死信交换器（DLX）\"></a>死信交换器（DLX）</h3><p>创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。</p>\n<p>示例程序：指定死信交换器</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        #死信交换器\n        rabbitpy.Exchange(channel, &#39;rejected-messages&#39;).declare()\n        queue = rabbitpy.Queue(channel, &#39;dlx-example&#39;,\n                               dead_letter_exchange=&#39;rejected-messages&#39;)\n        queue.declare()\n</code></pre>\n<hr>\n<h2 id=\"控制队列\"><a href=\"#控制队列\" class=\"headerlink\" title=\"控制队列\"></a>控制队列</h2><hr>\n<h3 id=\"临时队列\"><a href=\"#临时队列\" class=\"headerlink\" title=\"临时队列\"></a>临时队列</h3><p><strong>自动删除队列</strong><br>消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。</p>\n<p>示例程序：自动删除队列auto_delete=True</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;ad-example&#39;, auto_delete=True)\n        queue.declare()</code></pre><p><strong>只允许单个消费者</strong><br>只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。</p>\n<p>示例程序：独占队列exclusive</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;exclusive-example&#39;,\n                               exclusive=True)\n        queue.declare()</code></pre><p><strong>自动过期队列</strong><br>如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。</p>\n<p>示例程序：自动过期队列</p>\n<pre><code>import rabbitpy\nimport time\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-queue&#39;,\n                               arguments={&#39;x-expires&#39;: 1000})\n        queue.declare()\n        messages, consumers = queue.declare(passive=True)\n        time.sleep(2)\n        try:\n            messages, consumers = queue.declare(passive=True)\n        except rabbitpy.exceptions.AMQPNotFound:\n            print(&#39;The queue no longer exists&#39;)</code></pre><h3 id=\"永久队列\"><a href=\"#永久队列\" class=\"headerlink\" title=\"永久队列\"></a>永久队列</h3><p><strong>队列持久性</strong><br>服务器重启后队列仍然存在。<br>示例程序：持久队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;durable-queue&#39;,\n                               durable=True)\n        if queue.declare():\n            print(&#39;Queue declared&#39;)</code></pre><p><strong>队列消息自动过期</strong><br>同时指定死信交换器和消息TTL，过期消息将成为死信消息。</p>\n<p>示例程序：消息TTL</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;expiring-msg-queue&#39;,\n                               arguments={&#39;x-message-ttl&#39;: 1000})\n         queue.declare()\n</code></pre><p><strong>最大队列长度</strong><br>一旦达到最大值，添加新消息时，删除队列前端的消息。声明队列时，如果指定死信交换器，前端移除的消息将成为死信。</p>\n<p>示例程序：最大长度队列</p>\n<pre><code>import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        queue = rabbitpy.Queue(channel, &#39;max-length-queue&#39;,\n                               arguments={&#39;x-max-length&#39;: 1000})\n        queue.declare()\n</code></pre><h3 id=\"队列设置参数\"><a href=\"#队列设置参数\" class=\"headerlink\" title=\"队列设置参数\"></a>队列设置参数</h3><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>x-dead-letter-exchange</td>\n<td>死信交换器，路由不重发且被拒绝的消息</td>\n</tr>\n<tr>\n<td>x-dead-letter-routing-key</td>\n<td>死信消息的可选路由键</td>\n</tr>\n<tr>\n<td>x-expires</td>\n<td>队列在指定的毫秒数后删除</td>\n</tr>\n<tr>\n<td>x-ha-proxy</td>\n<td>创建HA队列</td>\n</tr>\n<tr>\n<td>x-ha-nodes</td>\n<td>HA队列分布的节点</td>\n</tr>\n<tr>\n<td>x-max-length</td>\n<td>队列的最大消息数</td>\n</tr>\n<tr>\n<td>x-message-ttl</td>\n<td>毫秒为单位的队列过期时间</td>\n</tr>\n<tr>\n<td>x-max-priority</td>\n<td>队列优先级排序</td>\n</tr>\n</tbody></table>\n"},{"title":"rabbitmq面试","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-05T12:05:22.000Z","password":null,"summary":null,"_content":"\n## MQ的优缺点\n\n### 优点\n\n- 异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。\n- 解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。\n- 削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。\n\n### 缺点\n\n**系统复杂度提高**：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。\n\n## RabbitMQ选型\n\n可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。\n\n支持集群化、高可用部署、消息高可靠支持，功能较为完善。\n\n缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。\n\nKafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。\n\n## 什么是RabbitMQ\n\nRabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。\n\n## rabbitmq 的使用场景\n\n（1）服务间异步通信\n\n（2）顺序消费\n\n（3）定时任务\n\n（4）请求削峰\n\n## RabbitMQ基本概念\n\n**Producer：生产者**，投递消息的程序\n\n**Consumer：消费者**，接受消息的程序\n\n**Broker：服务节点**，消息队列服务器实体\n\n**Virtual host：**虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型\n\n## RabbitMQ的工作模式\n\n**简单模式**：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。\n\n**工作模式**：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。\n\n**发布/订阅模式**：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。\n\n**路由模式**：根据`路由键`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n**主题模式**：根据`路由键匹配规则`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键匹配规则`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键匹配规则`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n## 消息在什么时候会变成死信?\n\n- 消息拒绝并且没有设置重新入队\n- 消息过期\n- 消息堆积，并且队列达到最大长度，先入队的消息会变成DL\n\n## 如何保证RabbitMQ消息的顺序性？\n\n1、需要保证顺序性的消息使用一个 queue对应一个 consumer。\n\n2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。\n\n## 如何保证消息不丢失？\n\n1. 生产者发送消息至MQ的数据丢失\n\n解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。\n\n2. MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失\n\n解决方式：MQ设置为持久化。将内存数据持久化到磁盘中\n\n3. 消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完\n\n解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。\n\n## 如何保证消息不被重复消费？\n\n1、设置操作的幂等性。\n\n2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。\n\n3、基于数据库的唯一键来保证重复数据不会重复插入多条。\n\n## **消息如何分发？**\n\n若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能\n\n## **消息怎么路由？**\n\n消息将拥有一个路由键（routing key），在消息创建时设定。通\n\n过队列路由键，可以把队列绑定到交换器上。\n\n消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；\n\n常用的交换器主要分为一下三种：\n\nfanout：如果交换器收到消息，将会广播到所有绑定的队列上\n\ndirect：如果路由键完全匹配，消息就被投递到相应的队列\n\ntopic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符\n\n## 消息基于什么传输？\n\n由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。\n\n## 什么情况下会出现blackholed问题？\n\nblackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：\n\n向未绑定 queue 的 exchange 发送 message；\n\nexchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。\n\n## 如何防止出现blackholed问题？\n\n如果在执行Basic.Publish时设置mandatory=true，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。\n\n## Basic.Reject的用法是什么？\n\n该信令可用于consumer对收到的message进行reject。\n\n若在该信令中设 置`requeue=true`，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。\n\n若设置`requeue=false`，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。\n\n\n## 如何保证消息不被重复消费？\n\n**重复消费场景：**因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。\n\n**解决思路**：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；\n\n比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；\n\n## 如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\n\n**发送方确认模式**\n\n将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。\n\n一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。\n\n如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。\n\n发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。\n\n**接收方确认机制**\n\n消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。\n\n这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；\n\n**特殊情况**\n\n如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）\n如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。\n\n## 如何保证RabbitMQ消息的可靠传输？\n\n丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；\n\n**生产者丢失消息：**RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；\n\ntransaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；\n\nconfirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。\n\n**消息队列丢数据：消息持久化。**开启持久化磁盘的配置。\n\n这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。\n\n队列持久化+消息持久化。\n\n消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；\n\n如果这时处理消息失败，就会丢失该消息；\n\n解决方案：处理消息成功后，手动回复确认消息。\n\n## 为什么不应该对所有的 message 都使用持久化机制？\n\n一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。\n\n其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。\n\n## 如何保证高可用的？RabbitMQ 的集群\n\n普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。\n\n好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。\n\n坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。\n\n## rabbitmq 对集群节点停止顺序有要求吗?\n\nRabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失\n\n## rabbitmq 集群有什么用?\n\n- 高可用: 某个服务器出现问题,整个 RabbitMQ 还可以继续使用;\n- 高容量: 集群可以承载更多的消息量.\n\n## RAM node 和 disk node 的区别？\n\nRAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。\n\n## **rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？**\n\n不是，原因有以下两个：\n\n1. 存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；\n2. 性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。\n\n## **rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？**\n\n如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：\n\n不能创建队列\n\n不能创建交换器\n\n不能创建绑定\n\n不能添加用户\n\n不能更改权限\n\n不能添加和删除集群节点\n\n唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。","source":"_posts/rabbitmq面试.md","raw":"---\ntitle: rabbitmq面试\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-05 20:05:22\npassword:\nsummary:\ntags:\n- rabbitmq\n- 面试\ncategories:\n- rabbitmq\n- 面试\n---\n\n## MQ的优缺点\n\n### 优点\n\n- 异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。\n- 解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。\n- 削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。\n\n### 缺点\n\n**系统复杂度提高**：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。\n\n## RabbitMQ选型\n\n可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。\n\n支持集群化、高可用部署、消息高可靠支持，功能较为完善。\n\n缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。\n\nKafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。\n\n## 什么是RabbitMQ\n\nRabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。\n\n## rabbitmq 的使用场景\n\n（1）服务间异步通信\n\n（2）顺序消费\n\n（3）定时任务\n\n（4）请求削峰\n\n## RabbitMQ基本概念\n\n**Producer：生产者**，投递消息的程序\n\n**Consumer：消费者**，接受消息的程序\n\n**Broker：服务节点**，消息队列服务器实体\n\n**Virtual host：**虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。\n\n**Queue：队列**，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。\n\n**Exchange：交换器**，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中\n\n**RoutingKey：路由键**，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则\n\n**Binding：绑定**，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey\n\n**Connection：连接**，生产者或消费者和Broker之间的一条TCP连接\n\n**Channel：信道**，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型\n\n## RabbitMQ的工作模式\n\n**简单模式**：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。\n\n**工作模式**：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。\n\n**发布/订阅模式**：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。\n\n**路由模式**：根据`路由键`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n**主题模式**：根据`路由键匹配规则`选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过`路由键匹配规则`绑定到交换机上去。生产者发送消息到交换机，交换机通过`路由键匹配规则`转发到不同队列，队列绑定的消费者接收并消费消息。\n\n## 消息在什么时候会变成死信?\n\n- 消息拒绝并且没有设置重新入队\n- 消息过期\n- 消息堆积，并且队列达到最大长度，先入队的消息会变成DL\n\n## 如何保证RabbitMQ消息的顺序性？\n\n1、需要保证顺序性的消息使用一个 queue对应一个 consumer。\n\n2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。\n\n## 如何保证消息不丢失？\n\n1. 生产者发送消息至MQ的数据丢失\n\n解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。\n\n2. MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失\n\n解决方式：MQ设置为持久化。将内存数据持久化到磁盘中\n\n3. 消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完\n\n解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。\n\n## 如何保证消息不被重复消费？\n\n1、设置操作的幂等性。\n\n2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。\n\n3、基于数据库的唯一键来保证重复数据不会重复插入多条。\n\n## **消息如何分发？**\n\n若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能\n\n## **消息怎么路由？**\n\n消息将拥有一个路由键（routing key），在消息创建时设定。通\n\n过队列路由键，可以把队列绑定到交换器上。\n\n消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；\n\n常用的交换器主要分为一下三种：\n\nfanout：如果交换器收到消息，将会广播到所有绑定的队列上\n\ndirect：如果路由键完全匹配，消息就被投递到相应的队列\n\ntopic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符\n\n## 消息基于什么传输？\n\n由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。\n\n## 什么情况下会出现blackholed问题？\n\nblackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：\n\n向未绑定 queue 的 exchange 发送 message；\n\nexchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。\n\n## 如何防止出现blackholed问题？\n\n如果在执行Basic.Publish时设置mandatory=true，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。\n\n## Basic.Reject的用法是什么？\n\n该信令可用于consumer对收到的message进行reject。\n\n若在该信令中设 置`requeue=true`，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。\n\n若设置`requeue=false`，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。\n\n\n## 如何保证消息不被重复消费？\n\n**重复消费场景：**因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。\n\n**解决思路**：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；\n\n比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；\n\n## 如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\n\n**发送方确认模式**\n\n将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。\n\n一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。\n\n如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。\n\n发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。\n\n**接收方确认机制**\n\n消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。\n\n这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；\n\n**特殊情况**\n\n如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）\n如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。\n\n## 如何保证RabbitMQ消息的可靠传输？\n\n丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；\n\n**生产者丢失消息：**RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；\n\ntransaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；\n\nconfirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。\n\n**消息队列丢数据：消息持久化。**开启持久化磁盘的配置。\n\n这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。\n\n队列持久化+消息持久化。\n\n消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；\n\n如果这时处理消息失败，就会丢失该消息；\n\n解决方案：处理消息成功后，手动回复确认消息。\n\n## 为什么不应该对所有的 message 都使用持久化机制？\n\n一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。\n\n其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。\n\n## 如何保证高可用的？RabbitMQ 的集群\n\n普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。\n\n镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。\n\n好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。\n\n坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。\n\n## rabbitmq 对集群节点停止顺序有要求吗?\n\nRabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失\n\n## rabbitmq 集群有什么用?\n\n- 高可用: 某个服务器出现问题,整个 RabbitMQ 还可以继续使用;\n- 高容量: 集群可以承载更多的消息量.\n\n## RAM node 和 disk node 的区别？\n\nRAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。\n\n## **rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？**\n\n不是，原因有以下两个：\n\n1. 存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；\n2. 性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。\n\n## **rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？**\n\n如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：\n\n不能创建队列\n\n不能创建交换器\n\n不能创建绑定\n\n不能添加用户\n\n不能更改权限\n\n不能添加和删除集群节点\n\n唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。","slug":"rabbitmq面试","published":1,"updated":"2021-04-08T11:55:50.903Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxiv002pncufbk5llwbn","content":"<h2 id=\"MQ的优缺点\"><a href=\"#MQ的优缺点\" class=\"headerlink\" title=\"MQ的优缺点\"></a>MQ的优缺点</h2><h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><ul>\n<li>异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。</li>\n<li>解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。</li>\n<li>削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。</li>\n</ul>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><p><strong>系统复杂度提高</strong>：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。</p>\n<h2 id=\"RabbitMQ选型\"><a href=\"#RabbitMQ选型\" class=\"headerlink\" title=\"RabbitMQ选型\"></a>RabbitMQ选型</h2><p>可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。</p>\n<p>支持集群化、高可用部署、消息高可靠支持，功能较为完善。</p>\n<p>缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。</p>\n<p>Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。</p>\n<h2 id=\"什么是RabbitMQ\"><a href=\"#什么是RabbitMQ\" class=\"headerlink\" title=\"什么是RabbitMQ\"></a>什么是RabbitMQ</h2><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。</p>\n<h2 id=\"rabbitmq-的使用场景\"><a href=\"#rabbitmq-的使用场景\" class=\"headerlink\" title=\"rabbitmq 的使用场景\"></a>rabbitmq 的使用场景</h2><p>（1）服务间异步通信</p>\n<p>（2）顺序消费</p>\n<p>（3）定时任务</p>\n<p>（4）请求削峰</p>\n<h2 id=\"RabbitMQ基本概念\"><a href=\"#RabbitMQ基本概念\" class=\"headerlink\" title=\"RabbitMQ基本概念\"></a>RabbitMQ基本概念</h2><p><strong>Producer：生产者</strong>，投递消息的程序</p>\n<p><strong>Consumer：消费者</strong>，接受消息的程序</p>\n<p><strong>Broker：服务节点</strong>，消息队列服务器实体</p>\n<p><strong>Virtual host：</strong>虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p>\n<h2 id=\"RabbitMQ的工作模式\"><a href=\"#RabbitMQ的工作模式\" class=\"headerlink\" title=\"RabbitMQ的工作模式\"></a>RabbitMQ的工作模式</h2><p><strong>简单模式</strong>：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。</p>\n<p><strong>工作模式</strong>：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。</p>\n<p><strong>发布/订阅模式</strong>：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。</p>\n<p><strong>路由模式</strong>：根据<code>路由键</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<p><strong>主题模式</strong>：根据<code>路由键匹配规则</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键匹配规则</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键匹配规则</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<h2 id=\"消息在什么时候会变成死信\"><a href=\"#消息在什么时候会变成死信\" class=\"headerlink\" title=\"消息在什么时候会变成死信?\"></a>消息在什么时候会变成死信?</h2><ul>\n<li>消息拒绝并且没有设置重新入队</li>\n<li>消息过期</li>\n<li>消息堆积，并且队列达到最大长度，先入队的消息会变成DL</li>\n</ul>\n<h2 id=\"如何保证RabbitMQ消息的顺序性？\"><a href=\"#如何保证RabbitMQ消息的顺序性？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的顺序性？\"></a>如何保证RabbitMQ消息的顺序性？</h2><p>1、需要保证顺序性的消息使用一个 queue对应一个 consumer。</p>\n<p>2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。</p>\n<h2 id=\"如何保证消息不丢失？\"><a href=\"#如何保证消息不丢失？\" class=\"headerlink\" title=\"如何保证消息不丢失？\"></a>如何保证消息不丢失？</h2><ol>\n<li>生产者发送消息至MQ的数据丢失</li>\n</ol>\n<p>解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。</p>\n<ol start=\"2\">\n<li>MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失</li>\n</ol>\n<p>解决方式：MQ设置为持久化。将内存数据持久化到磁盘中</p>\n<ol start=\"3\">\n<li>消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完</li>\n</ol>\n<p>解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。</p>\n<h2 id=\"如何保证消息不被重复消费？\"><a href=\"#如何保证消息不被重复消费？\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p>1、设置操作的幂等性。</p>\n<p>2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。</p>\n<p>3、基于数据库的唯一键来保证重复数据不会重复插入多条。</p>\n<h2 id=\"消息如何分发？\"><a href=\"#消息如何分发？\" class=\"headerlink\" title=\"消息如何分发？\"></a><strong>消息如何分发？</strong></h2><p>若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能</p>\n<h2 id=\"消息怎么路由？\"><a href=\"#消息怎么路由？\" class=\"headerlink\" title=\"消息怎么路由？\"></a><strong>消息怎么路由？</strong></h2><p>消息将拥有一个路由键（routing key），在消息创建时设定。通</p>\n<p>过队列路由键，可以把队列绑定到交换器上。</p>\n<p>消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；</p>\n<p>常用的交换器主要分为一下三种：</p>\n<p>fanout：如果交换器收到消息，将会广播到所有绑定的队列上</p>\n<p>direct：如果路由键完全匹配，消息就被投递到相应的队列</p>\n<p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p>\n<h2 id=\"消息基于什么传输？\"><a href=\"#消息基于什么传输？\" class=\"headerlink\" title=\"消息基于什么传输？\"></a>消息基于什么传输？</h2><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p>\n<h2 id=\"什么情况下会出现blackholed问题？\"><a href=\"#什么情况下会出现blackholed问题？\" class=\"headerlink\" title=\"什么情况下会出现blackholed问题？\"></a>什么情况下会出现blackholed问题？</h2><p>blackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：</p>\n<p>向未绑定 queue 的 exchange 发送 message；</p>\n<p>exchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。</p>\n<h2 id=\"如何防止出现blackholed问题？\"><a href=\"#如何防止出现blackholed问题？\" class=\"headerlink\" title=\"如何防止出现blackholed问题？\"></a>如何防止出现blackholed问题？</h2><p>如果在执行Basic.Publish时设置mandatory=true，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。</p>\n<h2 id=\"Basic-Reject的用法是什么？\"><a href=\"#Basic-Reject的用法是什么？\" class=\"headerlink\" title=\"Basic.Reject的用法是什么？\"></a>Basic.Reject的用法是什么？</h2><p>该信令可用于consumer对收到的message进行reject。</p>\n<p>若在该信令中设 置<code>requeue=true</code>，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。</p>\n<p>若设置<code>requeue=false</code>，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。</p>\n<h2 id=\"如何保证消息不被重复消费？-1\"><a href=\"#如何保证消息不被重复消费？-1\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p><strong>重复消费场景：</strong>因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。</p>\n<p><strong>解决思路</strong>：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；</p>\n<p>比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；</p>\n<h2 id=\"如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\"><a href=\"#如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\" class=\"headerlink\" title=\"如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\"></a>如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？</h2><p><strong>发送方确认模式</strong></p>\n<p>将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。</p>\n<p>一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。</p>\n<p>如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。</p>\n<p>发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。</p>\n<p><strong>接收方确认机制</strong></p>\n<p>消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。</p>\n<p>这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；</p>\n<p><strong>特殊情况</strong></p>\n<p>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）<br>如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。</p>\n<h2 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h2><p>丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；</p>\n<p><strong>生产者丢失消息：</strong>RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；</p>\n<p>transaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；</p>\n<p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p>\n<p><strong>消息队列丢数据：消息持久化。</strong>开启持久化磁盘的配置。</p>\n<p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p>\n<p>队列持久化+消息持久化。</p>\n<p>消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；</p>\n<p>如果这时处理消息失败，就会丢失该消息；</p>\n<p>解决方案：处理消息成功后，手动回复确认消息。</p>\n<h2 id=\"为什么不应该对所有的-message-都使用持久化机制？\"><a href=\"#为什么不应该对所有的-message-都使用持久化机制？\" class=\"headerlink\" title=\"为什么不应该对所有的 message 都使用持久化机制？\"></a>为什么不应该对所有的 message 都使用持久化机制？</h2><p>一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。</p>\n<p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。</p>\n<h2 id=\"如何保证高可用的？RabbitMQ-的集群\"><a href=\"#如何保证高可用的？RabbitMQ-的集群\" class=\"headerlink\" title=\"如何保证高可用的？RabbitMQ 的集群\"></a>如何保证高可用的？RabbitMQ 的集群</h2><p>普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。</p>\n<p>镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>\n<p>好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。</p>\n<p>坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。</p>\n<h2 id=\"rabbitmq-对集群节点停止顺序有要求吗\"><a href=\"#rabbitmq-对集群节点停止顺序有要求吗\" class=\"headerlink\" title=\"rabbitmq 对集群节点停止顺序有要求吗?\"></a>rabbitmq 对集群节点停止顺序有要求吗?</h2><p>RabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失</p>\n<h2 id=\"rabbitmq-集群有什么用\"><a href=\"#rabbitmq-集群有什么用\" class=\"headerlink\" title=\"rabbitmq 集群有什么用?\"></a>rabbitmq 集群有什么用?</h2><ul>\n<li>高可用: 某个服务器出现问题,整个 RabbitMQ 还可以继续使用;</li>\n<li>高容量: 集群可以承载更多的消息量.</li>\n</ul>\n<h2 id=\"RAM-node-和-disk-node-的区别？\"><a href=\"#RAM-node-和-disk-node-的区别？\" class=\"headerlink\" title=\"RAM node 和 disk node 的区别？\"></a>RAM node 和 disk node 的区别？</h2><p>RAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。</p>\n<h2 id=\"rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\"><a href=\"#rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\" class=\"headerlink\" title=\"rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？\"></a><strong>rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？</strong></h2><p>不是，原因有以下两个：</p>\n<ol>\n<li>存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；</li>\n<li>性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。</li>\n</ol>\n<h2 id=\"rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\"><a href=\"#rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\" class=\"headerlink\" title=\"rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？\"></a><strong>rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？</strong></h2><p>如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：</p>\n<p>不能创建队列</p>\n<p>不能创建交换器</p>\n<p>不能创建绑定</p>\n<p>不能添加用户</p>\n<p>不能更改权限</p>\n<p>不能添加和删除集群节点</p>\n<p>唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"MQ的优缺点\"><a href=\"#MQ的优缺点\" class=\"headerlink\" title=\"MQ的优缺点\"></a>MQ的优缺点</h2><h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><ul>\n<li>异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。</li>\n<li>解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。</li>\n<li>削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。</li>\n</ul>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><p><strong>系统复杂度提高</strong>：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。</p>\n<h2 id=\"RabbitMQ选型\"><a href=\"#RabbitMQ选型\" class=\"headerlink\" title=\"RabbitMQ选型\"></a>RabbitMQ选型</h2><p>可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。</p>\n<p>支持集群化、高可用部署、消息高可靠支持，功能较为完善。</p>\n<p>缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。</p>\n<p>Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。</p>\n<h2 id=\"什么是RabbitMQ\"><a href=\"#什么是RabbitMQ\" class=\"headerlink\" title=\"什么是RabbitMQ\"></a>什么是RabbitMQ</h2><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。</p>\n<h2 id=\"rabbitmq-的使用场景\"><a href=\"#rabbitmq-的使用场景\" class=\"headerlink\" title=\"rabbitmq 的使用场景\"></a>rabbitmq 的使用场景</h2><p>（1）服务间异步通信</p>\n<p>（2）顺序消费</p>\n<p>（3）定时任务</p>\n<p>（4）请求削峰</p>\n<h2 id=\"RabbitMQ基本概念\"><a href=\"#RabbitMQ基本概念\" class=\"headerlink\" title=\"RabbitMQ基本概念\"></a>RabbitMQ基本概念</h2><p><strong>Producer：生产者</strong>，投递消息的程序</p>\n<p><strong>Consumer：消费者</strong>，接受消息的程序</p>\n<p><strong>Broker：服务节点</strong>，消息队列服务器实体</p>\n<p><strong>Virtual host：</strong>虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。</p>\n<p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p>\n<p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p>\n<p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p>\n<p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p>\n<p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p>\n<p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p>\n<h2 id=\"RabbitMQ的工作模式\"><a href=\"#RabbitMQ的工作模式\" class=\"headerlink\" title=\"RabbitMQ的工作模式\"></a>RabbitMQ的工作模式</h2><p><strong>简单模式</strong>：它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。</p>\n<p><strong>工作模式</strong>：向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。</p>\n<p><strong>发布/订阅模式</strong>：同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。</p>\n<p><strong>路由模式</strong>：根据<code>路由键</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<p><strong>主题模式</strong>：根据<code>路由键匹配规则</code>选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者监听各自队列，两个队列通过<code>路由键匹配规则</code>绑定到交换机上去。生产者发送消息到交换机，交换机通过<code>路由键匹配规则</code>转发到不同队列，队列绑定的消费者接收并消费消息。</p>\n<h2 id=\"消息在什么时候会变成死信\"><a href=\"#消息在什么时候会变成死信\" class=\"headerlink\" title=\"消息在什么时候会变成死信?\"></a>消息在什么时候会变成死信?</h2><ul>\n<li>消息拒绝并且没有设置重新入队</li>\n<li>消息过期</li>\n<li>消息堆积，并且队列达到最大长度，先入队的消息会变成DL</li>\n</ul>\n<h2 id=\"如何保证RabbitMQ消息的顺序性？\"><a href=\"#如何保证RabbitMQ消息的顺序性？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的顺序性？\"></a>如何保证RabbitMQ消息的顺序性？</h2><p>1、需要保证顺序性的消息使用一个 queue对应一个 consumer。</p>\n<p>2、消息在被创建时,都将被赋予一个全局唯一的、单调递增的、连续的序列号(SerialNumber,SN),可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。</p>\n<h2 id=\"如何保证消息不丢失？\"><a href=\"#如何保证消息不丢失？\" class=\"headerlink\" title=\"如何保证消息不丢失？\"></a>如何保证消息不丢失？</h2><ol>\n<li>生产者发送消息至MQ的数据丢失</li>\n</ol>\n<p>解决方法:在生产者端开启comfirm 确认模式，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。</p>\n<ol start=\"2\">\n<li>MQ收到消息，暂存内存中，还没消费，自己挂掉，数据会都丢失</li>\n</ol>\n<p>解决方式：MQ设置为持久化。将内存数据持久化到磁盘中</p>\n<ol start=\"3\">\n<li>消费者刚拿到消息，还没处理，挂掉了，MQ又以为消费者处理完</li>\n</ol>\n<p>解决方式：用 RabbitMQ 提供的 ack 机制，每次处理完的时候， ack 一把。</p>\n<h2 id=\"如何保证消息不被重复消费？\"><a href=\"#如何保证消息不被重复消费？\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p>1、设置操作的幂等性。</p>\n<p>2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。</p>\n<p>3、基于数据库的唯一键来保证重复数据不会重复插入多条。</p>\n<h2 id=\"消息如何分发？\"><a href=\"#消息如何分发？\" class=\"headerlink\" title=\"消息如何分发？\"></a><strong>消息如何分发？</strong></h2><p>若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能</p>\n<h2 id=\"消息怎么路由？\"><a href=\"#消息怎么路由？\" class=\"headerlink\" title=\"消息怎么路由？\"></a><strong>消息怎么路由？</strong></h2><p>消息将拥有一个路由键（routing key），在消息创建时设定。通</p>\n<p>过队列路由键，可以把队列绑定到交换器上。</p>\n<p>消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；</p>\n<p>常用的交换器主要分为一下三种：</p>\n<p>fanout：如果交换器收到消息，将会广播到所有绑定的队列上</p>\n<p>direct：如果路由键完全匹配，消息就被投递到相应的队列</p>\n<p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p>\n<h2 id=\"消息基于什么传输？\"><a href=\"#消息基于什么传输？\" class=\"headerlink\" title=\"消息基于什么传输？\"></a>消息基于什么传输？</h2><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p>\n<h2 id=\"什么情况下会出现blackholed问题？\"><a href=\"#什么情况下会出现blackholed问题？\" class=\"headerlink\" title=\"什么情况下会出现blackholed问题？\"></a>什么情况下会出现blackholed问题？</h2><p>blackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：</p>\n<p>向未绑定 queue 的 exchange 发送 message；</p>\n<p>exchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。</p>\n<h2 id=\"如何防止出现blackholed问题？\"><a href=\"#如何防止出现blackholed问题？\" class=\"headerlink\" title=\"如何防止出现blackholed问题？\"></a>如何防止出现blackholed问题？</h2><p>如果在执行Basic.Publish时设置mandatory=true，则在遇到 可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。</p>\n<h2 id=\"Basic-Reject的用法是什么？\"><a href=\"#Basic-Reject的用法是什么？\" class=\"headerlink\" title=\"Basic.Reject的用法是什么？\"></a>Basic.Reject的用法是什么？</h2><p>该信令可用于consumer对收到的message进行reject。</p>\n<p>若在该信令中设 置<code>requeue=true</code>，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。</p>\n<p>若设置<code>requeue=false</code>，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移 除。</p>\n<h2 id=\"如何保证消息不被重复消费？-1\"><a href=\"#如何保证消息不被重复消费？-1\" class=\"headerlink\" title=\"如何保证消息不被重复消费？\"></a>如何保证消息不被重复消费？</h2><p><strong>重复消费场景：</strong>因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。</p>\n<p><strong>解决思路</strong>：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；</p>\n<p>比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；</p>\n<h2 id=\"如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\"><a href=\"#如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？\" class=\"headerlink\" title=\"如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？\"></a>如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？</h2><p><strong>发送方确认模式</strong></p>\n<p>将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。</p>\n<p>一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。</p>\n<p>如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。</p>\n<p>发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。</p>\n<p><strong>接收方确认机制</strong></p>\n<p>消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。</p>\n<p>这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；</p>\n<p><strong>特殊情况</strong></p>\n<p>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）<br>如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。</p>\n<h2 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h2><p>丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；</p>\n<p><strong>生产者丢失消息：</strong>RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；</p>\n<p>transaction机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；</p>\n<p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p>\n<p><strong>消息队列丢数据：消息持久化。</strong>开启持久化磁盘的配置。</p>\n<p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p>\n<p>队列持久化+消息持久化。</p>\n<p>消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；</p>\n<p>如果这时处理消息失败，就会丢失该消息；</p>\n<p>解决方案：处理消息成功后，手动回复确认消息。</p>\n<h2 id=\"为什么不应该对所有的-message-都使用持久化机制？\"><a href=\"#为什么不应该对所有的-message-都使用持久化机制？\" class=\"headerlink\" title=\"为什么不应该对所有的 message 都使用持久化机制？\"></a>为什么不应该对所有的 message 都使用持久化机制？</h2><p>一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。</p>\n<p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。</p>\n<h2 id=\"如何保证高可用的？RabbitMQ-的集群\"><a href=\"#如何保证高可用的？RabbitMQ-的集群\" class=\"headerlink\" title=\"如何保证高可用的？RabbitMQ 的集群\"></a>如何保证高可用的？RabbitMQ 的集群</h2><p>普通集群模式，在多台机器上启动多个 RabbitMQ 实例。 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。</p>\n<p>镜像集群模式： RabbitMQ 的高可用模式。，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>\n<p>好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。</p>\n<p>坏处在于，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。</p>\n<h2 id=\"rabbitmq-对集群节点停止顺序有要求吗\"><a href=\"#rabbitmq-对集群节点停止顺序有要求吗\" class=\"headerlink\" title=\"rabbitmq 对集群节点停止顺序有要求吗?\"></a>rabbitmq 对集群节点停止顺序有要求吗?</h2><p>RabbitMQ 对集群的停止的顺序是有要求的,应该先关闭内存节点,最后再关闭磁盘节点.如果顺序恰好相反的话,可能会造成消息的丢失</p>\n<h2 id=\"rabbitmq-集群有什么用\"><a href=\"#rabbitmq-集群有什么用\" class=\"headerlink\" title=\"rabbitmq 集群有什么用?\"></a>rabbitmq 集群有什么用?</h2><ul>\n<li>高可用: 某个服务器出现问题,整个 RabbitMQ 还可以继续使用;</li>\n<li>高容量: 集群可以承载更多的消息量.</li>\n</ul>\n<h2 id=\"RAM-node-和-disk-node-的区别？\"><a href=\"#RAM-node-和-disk-node-的区别？\" class=\"headerlink\" title=\"RAM node 和 disk node 的区别？\"></a>RAM node 和 disk node 的区别？</h2><p>RAM node 仅将相关元数据保存到内存中，但disk node会在内存和磁盘中均进行存储。要求在RabbitMQ cluster中至少存在一个disk node。</p>\n<h2 id=\"rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\"><a href=\"#rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？\" class=\"headerlink\" title=\"rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？\"></a><strong>rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？</strong></h2><p>不是，原因有以下两个：</p>\n<ol>\n<li>存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；</li>\n<li>性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。</li>\n</ol>\n<h2 id=\"rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\"><a href=\"#rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？\" class=\"headerlink\" title=\"rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？\"></a><strong>rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？</strong></h2><p>如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：</p>\n<p>不能创建队列</p>\n<p>不能创建交换器</p>\n<p>不能创建绑定</p>\n<p>不能添加用户</p>\n<p>不能更改权限</p>\n<p>不能添加和删除集群节点</p>\n<p>唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。</p>\n"},{"title":"rabbitmq消息重复","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:18:39.000Z","password":null,"summary":null,"_content":"\n## 场景\n\n- 可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。\n- MQ Broker服务与消费端传输消息的过程中出现网络抖动。\n- 消费端故障、异常。\n\n## 解决方案\n\n### 可靠性投递解决\n\n对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：\n（1）全局唯一\n（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽\n有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。\n\n### 消费抖动解决\n业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：\n（1）对于同一个业务场景，全局唯一\n（2）由业务消息发送方生成，业务相关，对MQ透明\n（3）由业务消息消费方负责判重，以保证幂等","source":"_posts/rabbitmq消息重复.md","raw":"---\ntitle: rabbitmq消息重复\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:18:39\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 场景\n\n- 可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。\n- MQ Broker服务与消费端传输消息的过程中出现网络抖动。\n- 消费端故障、异常。\n\n## 解决方案\n\n### 可靠性投递解决\n\n对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：\n（1）全局唯一\n（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽\n有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。\n\n### 消费抖动解决\n业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：\n（1）对于同一个业务场景，全局唯一\n（2）由业务消息发送方生成，业务相关，对MQ透明\n（3）由业务消息消费方负责判重，以保证幂等","slug":"rabbitmq消息重复","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxiy002sncuf7wpmkd5s","content":"<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h2><ul>\n<li>可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。</li>\n<li>MQ Broker服务与消费端传输消息的过程中出现网络抖动。</li>\n<li>消费端故障、异常。</li>\n</ul>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"可靠性投递解决\"><a href=\"#可靠性投递解决\" class=\"headerlink\" title=\"可靠性投递解决\"></a>可靠性投递解决</h3><p>对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：<br>（1）全局唯一<br>（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽<br>有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。</p>\n<h3 id=\"消费抖动解决\"><a href=\"#消费抖动解决\" class=\"headerlink\" title=\"消费抖动解决\"></a>消费抖动解决</h3><p>业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：<br>（1）对于同一个业务场景，全局唯一<br>（2）由业务消息发送方生成，业务相关，对MQ透明<br>（3）由业务消息消费方负责判重，以保证幂等</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"场景\"><a href=\"#场景\" class=\"headerlink\" title=\"场景\"></a>场景</h2><ul>\n<li>可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。</li>\n<li>MQ Broker服务与消费端传输消息的过程中出现网络抖动。</li>\n<li>消费端故障、异常。</li>\n</ul>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"可靠性投递解决\"><a href=\"#可靠性投递解决\" class=\"headerlink\" title=\"可靠性投递解决\"></a>可靠性投递解决</h3><p>对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：<br>（1）全局唯一<br>（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽<br>有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。</p>\n<h3 id=\"消费抖动解决\"><a href=\"#消费抖动解决\" class=\"headerlink\" title=\"消费抖动解决\"></a>消费抖动解决</h3><p>业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：<br>（1）对于同一个业务场景，全局唯一<br>（2）由业务消息发送方生成，业务相关，对MQ透明<br>（3）由业务消息消费方负责判重，以保证幂等</p>\n"},{"title":"redis RBD机制","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:09:31.000Z","password":null,"summary":null,"_content":"\nRDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。\n\n## 快照机制\n\n引入原因：AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。\n\nbgsave命令：主进程fork出子进程，共享主线程的所有内存数据。子进程读取主线程的内存数据，并把它们写入 RDB 文件。\n借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。\n如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201024165305565-62767733.jpg)\n\n\n## 增量快照\n做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。\n需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。\n\n\n## 混用 AOF日志和RDB(Redis 4.0)\n\n内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n## 备份机制选择\n\n数据不能丢失时，内存快照和 AOF 的混合使用；\n如果允许分钟级别的数据丢失，只使用 RDB；\n如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。","source":"_posts/redis-RDB机制.md","raw":"---\ntitle: redis RBD机制\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:09:31\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\nRDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。\n\n## 快照机制\n\n引入原因：AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。\n\nbgsave命令：主进程fork出子进程，共享主线程的所有内存数据。子进程读取主线程的内存数据，并把它们写入 RDB 文件。\n借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。\n如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201024165305565-62767733.jpg)\n\n\n## 增量快照\n做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。\n需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。\n\n\n## 混用 AOF日志和RDB(Redis 4.0)\n\n内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n## 备份机制选择\n\n数据不能丢失时，内存快照和 AOF 的混合使用；\n如果允许分钟级别的数据丢失，只使用 RDB；\n如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。","slug":"redis-RDB机制","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxj2002wncuf0wrnruh6","content":"<p>RDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。</p>\n<h2 id=\"快照机制\"><a href=\"#快照机制\" class=\"headerlink\" title=\"快照机制\"></a>快照机制</h2><p>引入原因：AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。</p>\n<p>bgsave命令：主进程fork出子进程，共享主线程的所有内存数据。子进程读取主线程的内存数据，并把它们写入 RDB 文件。<br>借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。<br>如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201024165305565-62767733.jpg\" alt></p>\n<h2 id=\"增量快照\"><a href=\"#增量快照\" class=\"headerlink\" title=\"增量快照\"></a>增量快照</h2><p>做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。<br>需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。</p>\n<h2 id=\"混用-AOF日志和RDB-Redis-4-0\"><a href=\"#混用-AOF日志和RDB-Redis-4-0\" class=\"headerlink\" title=\"混用 AOF日志和RDB(Redis 4.0)\"></a>混用 AOF日志和RDB(Redis 4.0)</h2><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>\n<h2 id=\"备份机制选择\"><a href=\"#备份机制选择\" class=\"headerlink\" title=\"备份机制选择\"></a>备份机制选择</h2><p>数据不能丢失时，内存快照和 AOF 的混合使用；<br>如果允许分钟级别的数据丢失，只使用 RDB；<br>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>RDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。</p>\n<h2 id=\"快照机制\"><a href=\"#快照机制\" class=\"headerlink\" title=\"快照机制\"></a>快照机制</h2><p>引入原因：AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。</p>\n<p>bgsave命令：主进程fork出子进程，共享主线程的所有内存数据。子进程读取主线程的内存数据，并把它们写入 RDB 文件。<br>借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。<br>如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201024165305565-62767733.jpg\" alt></p>\n<h2 id=\"增量快照\"><a href=\"#增量快照\" class=\"headerlink\" title=\"增量快照\"></a>增量快照</h2><p>做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。<br>需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。</p>\n<h2 id=\"混用-AOF日志和RDB-Redis-4-0\"><a href=\"#混用-AOF日志和RDB-Redis-4-0\" class=\"headerlink\" title=\"混用 AOF日志和RDB(Redis 4.0)\"></a>混用 AOF日志和RDB(Redis 4.0)</h2><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>\n<h2 id=\"备份机制选择\"><a href=\"#备份机制选择\" class=\"headerlink\" title=\"备份机制选择\"></a>备份机制选择</h2><p>数据不能丢失时，内存快照和 AOF 的混合使用；<br>如果允许分钟级别的数据丢失，只使用 RDB；<br>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</p>\n"},{"title":"rabbitmq消息路由","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:15:04.000Z","password":null,"summary":null,"_content":"\n---\n[toc]\n\n------------\n\n## direct交换器\n\n------------\n\n### 特点\n- 投递的消息有一个或者多个确定的目标。\n- 检查字符串是否相等，不允许使用模式匹配。\n- 绑定相同路由键的队列都能收到该路由键对应的消息。\n- 适用于RPC消息通信模式下的路由应答消息\n\n示例代码：Direct交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'direct-example',\n                                     exchange_type='direct')\n        exchange.declare()\n```\n\n### 示例场景\nRPC worker消费图片实现面部识别，将结果发回给消息发布方。\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg)\n\n\n\n- 客户端应用程序上传图像\n- 应用程序处理请求，用唯一ID标识远程请求并创建一条消息\n- 图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID\n- 消息路由到队列，\n- 消费者消费队列中的消息\n- 结果以RPC请求形式返回前端。\n\n注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。\n\n示例代码：RPC Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\nexchange = rabbitpy.DirectExchange(channel, 'rpc-replies')\nexchange.declare()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('direct-rpc-requests', 'detect-faces')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例代码：RPC worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('direct-rpc-requests', 'detect-faces'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## fanout交换器\n\n### 特点\n\n- 所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。\n- 消息投递不需要检测路由键，性能更好\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                    'fanout-rpc-requests',\n                                     exchange_type='fanout')\n        exchange.declare()\n```\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg)\n\n\n\n\n示例程序：Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print 'Sending request for image #%s: %s' % (img_id, filename)\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('fanout-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint 'RPC requests processed'\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例程序：detect worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n示例程序：Hash Consumer\n```python\nimport os\nimport hashlib\nimport rabbitpy\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'hashing-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Create the hashing object\n    hash_obj = hashlib.md5(message.body)\n\n    # Print out the info, this might go into a database or log file\n    print('Image with correlation-id of %s has a hash of %s' %\n          (message.properties['correlation_id'],\n           hash_obj.hexdigest()))\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n\n## topic交换器\n\n### 特点\n\n- 消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。\n\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg)\n\n\n\n## headers交换器\n\n### 特点\n\n- 使用消息属性中的headers属性匹配。\n- queue.bind，x-match指定匹配策略，其他参数表示绑定值\n- 绑定策略可能会使得性能降低\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                     'headers-rpc-requests',\n                                     exchange_type='headers')\n        exchange.declare()\n\n```\n\n示例程序：publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'headers': {'source': 'profile',\n                                            'object': 'image',\n                                            'action': 'new'},\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('headers-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n\n示例程序：worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('headers-rpc-requests',\n              arguments={'x-match': 'all',\n                         'source': 'profile',\n                         'object': 'image',\n                         'action': 'new'}):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## 交换器路由\n\n交换器间绑定，使用RPC方法Exchange.Bind。\n\n### 示例场景\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg)\n\n\n示例代码：\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tpc = rabbitpy.Exchange(channel, 'events',\n                                exchange_type='topic')\n        tpc.declare()\n        xch = rabbitpy.Exchange(channel, 'distributed-events',\n                                exchange_type='x-consistent-hash')\n        xch.declare()\n        xch.bind(foo, '#')\n```\n\n\n## 一致性哈希交换器\n\n用于消息队列的负载均衡，可以提升吞吐量\n\n### 示例场景\n\n\n示例代码：采用路由键的哈希值来分发消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash')\n        exchange.declare()\n```\n\n示例代码：header中的属性值作为哈希值\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash',\n                                     arguments={'hash-header': 'image-hash'})\n        exchange.declare()\n\n```\n\n示例代码：队列的创建与绑定\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for queue_num in range(4):\n            queue = rabbitpy.Queue (channel, 'server%s' % queue_num)\n            queue.declare()\n            queue.bind('image-storage', '10')\n```","source":"_posts/rabbitmq消息路由.md","raw":"---\ntitle: rabbitmq消息路由\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:15:04\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n---\n[toc]\n\n------------\n\n## direct交换器\n\n------------\n\n### 特点\n- 投递的消息有一个或者多个确定的目标。\n- 检查字符串是否相等，不允许使用模式匹配。\n- 绑定相同路由键的队列都能收到该路由键对应的消息。\n- 适用于RPC消息通信模式下的路由应答消息\n\n示例代码：Direct交换器\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'direct-example',\n                                     exchange_type='direct')\n        exchange.declare()\n```\n\n### 示例场景\nRPC worker消费图片实现面部识别，将结果发回给消息发布方。\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg)\n\n\n\n- 客户端应用程序上传图像\n- 应用程序处理请求，用唯一ID标识远程请求并创建一条消息\n- 图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID\n- 消息路由到队列，\n- 消费者消费队列中的消息\n- 结果以RPC请求形式返回前端。\n\n注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。\n\n示例代码：RPC Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\nexchange = rabbitpy.DirectExchange(channel, 'rpc-replies')\nexchange.declare()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('direct-rpc-requests', 'detect-faces')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例代码：RPC worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('direct-rpc-requests', 'detect-faces'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## fanout交换器\n\n### 特点\n\n- 所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。\n- 消息投递不需要检测路由键，性能更好\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                    'fanout-rpc-requests',\n                                     exchange_type='fanout')\n        exchange.declare()\n```\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg)\n\n\n\n\n示例程序：Publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print 'Sending request for image #%s: %s' % (img_id, filename)\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('fanout-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint 'RPC requests processed'\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n示例程序：detect worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n示例程序：Hash Consumer\n```python\nimport os\nimport hashlib\nimport rabbitpy\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'hashing-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('fanout-rpc-requests'):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Create the hashing object\n    hash_obj = hashlib.md5(message.body)\n\n    # Print out the info, this might go into a database or log file\n    print('Image with correlation-id of %s has a hash of %s' %\n          (message.properties['correlation_id'],\n           hash_obj.hexdigest()))\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n\n## topic交换器\n\n### 特点\n\n- 消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。\n\n### 示例场景\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg)\n\n\n\n## headers交换器\n\n### 特点\n\n- 使用消息属性中的headers属性匹配。\n- queue.bind，x-match指定匹配策略，其他参数表示绑定值\n- 绑定策略可能会使得性能降低\n\n示例代码\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                     'headers-rpc-requests',\n                                     exchange_type='headers')\n        exchange.declare()\n\n```\n\n示例程序：publisher\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = 'response-queue-%s' % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print('Response queue declared')\n\n# Bind the response queue\nif response_queue.bind('rpc-replies', queue_name):\n    print('Response queue bound')\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print('Sending request for image #%s: %s' % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {'content_type': utils.mime_type(filename),\n                                'correlation_id': str(img_id),\n                                'headers': {'source': 'profile',\n                                            'object': 'image',\n                                            'action': 'new'},\n                                'reply_to': queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish('headers-rpc-requests')\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties['headers']['first_publish']))\n\n    print('Facial detection RPC call for image %s total duration: %s' %\n          (message.properties['correlation_id'], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties['content_type'])\n\nprint('RPC requests processed')\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n\n```\n\n\n示例程序：worker\n```python\nimport os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = 'rpc-worker-%s' % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print('Worker queue declared')\n\n# Bind the worker queue\nif queue.bind('headers-rpc-requests',\n              arguments={'x-match': 'all',\n                         'source': 'profile',\n                         'object': 'image',\n                         'action': 'new'}):\n    print('Worker queue bound')\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties['timestamp'].strftime('%s'))\n    print('Received RPC request published %.2f seconds ago' % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties['content_type'])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {'app_id': 'Chapter 6 Listing 2 Consumer',\n                  'content_type': message.properties['content_type'],\n                  'correlation_id': message.properties['correlation_id'],\n                  'headers': {\n                      'first_publish': message.properties['timestamp']}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish('rpc-replies', message.properties['reply_to'])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n\n```\n\n## 交换器路由\n\n交换器间绑定，使用RPC方法Exchange.Bind。\n\n### 示例场景\n\n\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg)\n\n\n示例代码：\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tpc = rabbitpy.Exchange(channel, 'events',\n                                exchange_type='topic')\n        tpc.declare()\n        xch = rabbitpy.Exchange(channel, 'distributed-events',\n                                exchange_type='x-consistent-hash')\n        xch.declare()\n        xch.bind(foo, '#')\n```\n\n\n## 一致性哈希交换器\n\n用于消息队列的负载均衡，可以提升吞吐量\n\n### 示例场景\n\n\n示例代码：采用路由键的哈希值来分发消息\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash')\n        exchange.declare()\n```\n\n示例代码：header中的属性值作为哈希值\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, 'image-storage',\n                                     exchange_type='x-consistent-hash',\n                                     arguments={'hash-header': 'image-hash'})\n        exchange.declare()\n\n```\n\n示例代码：队列的创建与绑定\n```python\nimport rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for queue_num in range(4):\n            queue = rabbitpy.Queue (channel, 'server%s' % queue_num)\n            queue.declare()\n            queue.bind('image-storage', '10')\n```","slug":"rabbitmq消息路由","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxj60030ncufg8onrj9v","content":"<hr>\n<p>[toc]</p>\n<hr>\n<h2 id=\"direct交换器\"><a href=\"#direct交换器\" class=\"headerlink\" title=\"direct交换器\"></a>direct交换器</h2><hr>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>投递的消息有一个或者多个确定的目标。</li>\n<li>检查字符串是否相等，不允许使用模式匹配。</li>\n<li>绑定相同路由键的队列都能收到该路由键对应的消息。</li>\n<li>适用于RPC消息通信模式下的路由应答消息</li>\n</ul>\n<p>示例代码：Direct交换器</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'direct-example'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'direct'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"示例场景\"><a href=\"#示例场景\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>RPC worker消费图片实现面部识别，将结果发回给消息发布方。</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg\" alt></p>\n<ul>\n<li>客户端应用程序上传图像</li>\n<li>应用程序处理请求，用唯一ID标识远程请求并创建一条消息</li>\n<li>图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID</li>\n<li>消息路由到队列，</li>\n<li>消费者消费队列中的消息</li>\n<li>结果以RPC请求形式返回前端。</li>\n</ul>\n<p>注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。</p>\n<p>示例代码：RPC Publisher</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the channel and connection</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nexchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>DirectExchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">)</span>\nexchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the response queue that will automatically delete, is not durable and</span>\n<span class=\"token comment\" spellcheck=\"true\"># is exclusive to this publisher</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'response-queue-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresponse_queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                queue_name<span class=\"token punctuation\">,</span>\n                                auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                                exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># Declare the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Iterate through the images to send RPC requests for</span>\n<span class=\"token keyword\">for</span> img_id<span class=\"token punctuation\">,</span> filename <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>get_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Sending request for image #%s: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the message</span>\n    message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                               <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> utils<span class=\"token punctuation\">.</span>mime_type<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">:</span> queue_name<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                               opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Pubish the message</span>\n    message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'direct-rpc-requests'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'detect-faces'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Loop until there is a response message</span>\n    message <span class=\"token operator\">=</span> None\n    <span class=\"token keyword\">while</span> <span class=\"token operator\">not</span> message<span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> response_queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack the response message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Caculate how long it took from publish to response</span>\n    duration <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span>\n                time<span class=\"token punctuation\">.</span>mktime<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Facial detection RPC call for image %s total duration: %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> duration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display the image in the IPython notebook interface</span>\n    utils<span class=\"token punctuation\">.</span>display_image<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'RPC requests processed'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Close the channel and connection</span>\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：RPC worker</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> detect\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'rpc-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'direct-rpc-requests'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'detect-faces'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display how long it took for the message to get here</span>\n    duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> int<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%s'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Received RPC request published %.2f seconds ago'</span> <span class=\"token operator\">%</span> duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Write out the message body to a temp file for facial detection process</span>\n    temp_file <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>write_temp_file<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span>\n                                      message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Detect faces</span>\n    result_file <span class=\"token operator\">=</span> detect<span class=\"token punctuation\">.</span>faces<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Build response properties including the timestamp from the first publish</span>\n    properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'app_id'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Chapter 6 Listing 2 Consumer'</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                      <span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># The result file could just be the original image if nothing detected</span>\n    body <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the temp file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the result file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Publish the response response</span>\n    response <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">,</span> opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    response<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"fanout交换器\"><a href=\"#fanout交换器\" class=\"headerlink\" title=\"fanout交换器\"></a>fanout交换器</h2><h3 id=\"特点-1\"><a href=\"#特点-1\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。</li>\n<li>消息投递不需要检测路由键，性能更好</li>\n</ul>\n<p>示例代码</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                    <span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'fanout'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"示例场景-1\"><a href=\"#示例场景-1\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg\" alt></p>\n<p>示例程序：Publisher</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the channel and connection</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the response queue that will automatically delete, is not durable and</span>\n<span class=\"token comment\" spellcheck=\"true\"># is exclusive to this publisher</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'response-queue-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresponse_queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                queue_name<span class=\"token punctuation\">,</span>\n                                auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                                exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># Declare the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Iterate through the images to send RPC requests for</span>\n<span class=\"token keyword\">for</span> img_id<span class=\"token punctuation\">,</span> filename <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>get_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span> <span class=\"token string\">'Sending request for image #%s: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the message</span>\n    message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                               <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> utils<span class=\"token punctuation\">.</span>mime_type<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">:</span> queue_name<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                               opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Pubish the message</span>\n    message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Loop until there is a response message</span>\n    message <span class=\"token operator\">=</span> None\n    <span class=\"token keyword\">while</span> <span class=\"token operator\">not</span> message<span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> response_queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack the response message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Caculate how long it took from publish to response</span>\n    duration <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span>\n                time<span class=\"token punctuation\">.</span>mktime<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Facial detection RPC call for image %s total duration: %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> duration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display the image in the IPython notebook interface</span>\n    utils<span class=\"token punctuation\">.</span>display_image<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span> <span class=\"token string\">'RPC requests processed'</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Close the channel and connection</span>\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：detect worker</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> detect\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'rpc-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display how long it took for the message to get here</span>\n    duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> int<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%s'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Received RPC request published %.2f seconds ago'</span> <span class=\"token operator\">%</span> duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Write out the message body to a temp file for facial detection process</span>\n    temp_file <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>write_temp_file<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span>\n                                      message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Detect faces</span>\n    result_file <span class=\"token operator\">=</span> detect<span class=\"token punctuation\">.</span>faces<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Build response properties including the timestamp from the first publish</span>\n    properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'app_id'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Chapter 6 Listing 2 Consumer'</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                      <span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># The result file could just be the original image if nothing detected</span>\n    body <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the temp file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the result file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Publish the response response</span>\n    response <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span>\n    response<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：Hash Consumer</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> hashlib\n<span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'hashing-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'fanout-rpc-requests'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the hashing object</span>\n    hash_obj <span class=\"token operator\">=</span> hashlib<span class=\"token punctuation\">.</span>md5<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Print out the info, this might go into a database or log file</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Image with correlation-id of %s has a hash of %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n           hash_obj<span class=\"token punctuation\">.</span>hexdigest<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"topic交换器\"><a href=\"#topic交换器\" class=\"headerlink\" title=\"topic交换器\"></a>topic交换器</h2><h3 id=\"特点-2\"><a href=\"#特点-2\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。</li>\n</ul>\n<h3 id=\"示例场景-2\"><a href=\"#示例场景-2\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg\" alt></p>\n<h2 id=\"headers交换器\"><a href=\"#headers交换器\" class=\"headerlink\" title=\"headers交换器\"></a>headers交换器</h2><h3 id=\"特点-3\"><a href=\"#特点-3\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>使用消息属性中的headers属性匹配。</li>\n<li>queue.bind，x-match指定匹配策略，其他参数表示绑定值</li>\n<li>绑定策略可能会使得性能降低</li>\n</ul>\n<p>示例代码</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                     <span class=\"token string\">'headers-rpc-requests'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：publisher</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the channel and connection</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the response queue that will automatically delete, is not durable and</span>\n<span class=\"token comment\" spellcheck=\"true\"># is exclusive to this publisher</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'response-queue-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresponse_queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                                queue_name<span class=\"token punctuation\">,</span>\n                                auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                                exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># Declare the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the response queue</span>\n<span class=\"token keyword\">if</span> response_queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Response queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Iterate through the images to send RPC requests for</span>\n<span class=\"token keyword\">for</span> img_id<span class=\"token punctuation\">,</span> filename <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>utils<span class=\"token punctuation\">.</span>get_images<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Sending request for image #%s: %s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Create the message</span>\n    message <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span>\n                               utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                               <span class=\"token punctuation\">{</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> utils<span class=\"token punctuation\">.</span>mime_type<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">(</span>img_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'source'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'profile'</span><span class=\"token punctuation\">,</span>\n                                            <span class=\"token string\">'object'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'image'</span><span class=\"token punctuation\">,</span>\n                                            <span class=\"token string\">'action'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'new'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                                <span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">:</span> queue_name<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n                               opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Pubish the message</span>\n    message<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'headers-rpc-requests'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Loop until there is a response message</span>\n    message <span class=\"token operator\">=</span> None\n    <span class=\"token keyword\">while</span> <span class=\"token operator\">not</span> message<span class=\"token punctuation\">:</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        message <span class=\"token operator\">=</span> response_queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack the response message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Caculate how long it took from publish to response</span>\n    duration <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span>\n                time<span class=\"token punctuation\">.</span>mktime<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'headers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Facial detection RPC call for image %s total duration: %s'</span> <span class=\"token operator\">%</span>\n          <span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> duration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display the image in the IPython notebook interface</span>\n    utils<span class=\"token punctuation\">.</span>display_image<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'RPC requests processed'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Close the channel and connection</span>\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例程序：worker</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> rabbitpy\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> detect\n<span class=\"token keyword\">from</span> ch6 <span class=\"token keyword\">import</span> utils\n\n<span class=\"token comment\" spellcheck=\"true\"># Open the connection and the channel</span>\nconnection <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Create the worker queue</span>\nqueue_name <span class=\"token operator\">=</span> <span class=\"token string\">'rpc-worker-%s'</span> <span class=\"token operator\">%</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nqueue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> queue_name<span class=\"token punctuation\">,</span>\n                       auto_delete<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                       durable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                       exclusive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Declare the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue declared'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Bind the worker queue</span>\n<span class=\"token keyword\">if</span> queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'headers-rpc-requests'</span><span class=\"token punctuation\">,</span>\n              arguments<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'x-match'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'all'</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token string\">'source'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'profile'</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token string\">'object'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'image'</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token string\">'action'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'new'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Worker queue bound'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Consume messages from RabbitMQ</span>\n<span class=\"token keyword\">for</span> message <span class=\"token keyword\">in</span> queue<span class=\"token punctuation\">.</span>consume_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Display how long it took for the message to get here</span>\n    duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> int<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%s'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Received RPC request published %.2f seconds ago'</span> <span class=\"token operator\">%</span> duration<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Write out the message body to a temp file for facial detection process</span>\n    temp_file <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>write_temp_file<span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span>\n                                      message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Detect faces</span>\n    result_file <span class=\"token operator\">=</span> detect<span class=\"token punctuation\">.</span>faces<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Build response properties including the timestamp from the first publish</span>\n    properties <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'app_id'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Chapter 6 Listing 2 Consumer'</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'content_type'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'content_type'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'correlation_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                  <span class=\"token string\">'headers'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                      <span class=\"token string\">'first_publish'</span><span class=\"token punctuation\">:</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># The result file could just be the original image if nothing detected</span>\n    body <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>read_image<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the temp file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>temp_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Remove the result file</span>\n    os<span class=\"token punctuation\">.</span>unlink<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Publish the response response</span>\n    response <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Message<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">,</span> opinionated<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    response<span class=\"token punctuation\">.</span>publish<span class=\"token punctuation\">(</span><span class=\"token string\">'rpc-replies'</span><span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">.</span>properties<span class=\"token punctuation\">[</span><span class=\"token string\">'reply_to'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Acknowledge the delivery of the RPC request message</span>\n    message<span class=\"token punctuation\">.</span>ack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"交换器路由\"><a href=\"#交换器路由\" class=\"headerlink\" title=\"交换器路由\"></a>交换器路由</h2><p>交换器间绑定，使用RPC方法Exchange.Bind。</p>\n<h3 id=\"示例场景-3\"><a href=\"#示例场景-3\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg\" alt></p>\n<p>示例代码：</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        tpc <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'events'</span><span class=\"token punctuation\">,</span>\n                                exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'topic'</span><span class=\"token punctuation\">)</span>\n        tpc<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        xch <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'distributed-events'</span><span class=\"token punctuation\">,</span>\n                                exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'x-consistent-hash'</span><span class=\"token punctuation\">)</span>\n        xch<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        xch<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span>foo<span class=\"token punctuation\">,</span> <span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"一致性哈希交换器\"><a href=\"#一致性哈希交换器\" class=\"headerlink\" title=\"一致性哈希交换器\"></a>一致性哈希交换器</h2><p>用于消息队列的负载均衡，可以提升吞吐量</p>\n<h3 id=\"示例场景-4\"><a href=\"#示例场景-4\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>示例代码：采用路由键的哈希值来分发消息</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'image-storage'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'x-consistent-hash'</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：header中的属性值作为哈希值</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        exchange <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Exchange<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'image-storage'</span><span class=\"token punctuation\">,</span>\n                                     exchange_type<span class=\"token operator\">=</span><span class=\"token string\">'x-consistent-hash'</span><span class=\"token punctuation\">,</span>\n                                     arguments<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'hash-header'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'image-hash'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        exchange<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>示例代码：队列的创建与绑定</p>\n<pre class=\"line-numbers language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> rabbitpy\n\n<span class=\"token keyword\">with</span> rabbitpy<span class=\"token punctuation\">.</span>Connection<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> connection<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> channel<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> queue_num <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            queue <span class=\"token operator\">=</span> rabbitpy<span class=\"token punctuation\">.</span>Queue <span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> <span class=\"token string\">'server%s'</span> <span class=\"token operator\">%</span> queue_num<span class=\"token punctuation\">)</span>\n            queue<span class=\"token punctuation\">.</span>declare<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            queue<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token string\">'image-storage'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'10'</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<hr>\n<p>[toc]</p>\n<hr>\n<h2 id=\"direct交换器\"><a href=\"#direct交换器\" class=\"headerlink\" title=\"direct交换器\"></a>direct交换器</h2><hr>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>投递的消息有一个或者多个确定的目标。</li>\n<li>检查字符串是否相等，不允许使用模式匹配。</li>\n<li>绑定相同路由键的队列都能收到该路由键对应的消息。</li>\n<li>适用于RPC消息通信模式下的路由应答消息</li>\n</ul>\n<p>示例代码：Direct交换器</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;direct-example&#39;,\n                                     exchange_type=&#39;direct&#39;)\n        exchange.declare()</code></pre>\n<h3 id=\"示例场景\"><a href=\"#示例场景\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>RPC worker消费图片实现面部识别，将结果发回给消息发布方。</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg\" alt></p>\n<ul>\n<li>客户端应用程序上传图像</li>\n<li>应用程序处理请求，用唯一ID标识远程请求并创建一条消息</li>\n<li>图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID</li>\n<li>消息路由到队列，</li>\n<li>消费者消费队列中的消息</li>\n<li>结果以RPC请求形式返回前端。</li>\n</ul>\n<p>注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。</p>\n<p>示例代码：RPC Publisher</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\nexchange = rabbitpy.DirectExchange(channel, &#39;rpc-replies&#39;)\nexchange.declare()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = &#39;response-queue-%s&#39; % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print(&#39;Response queue declared&#39;)\n\n# Bind the response queue\nif response_queue.bind(&#39;rpc-replies&#39;, queue_name):\n    print(&#39;Response queue bound&#39;)\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print(&#39;Sending request for image #%s: %s&#39; % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {&#39;content_type&#39;: utils.mime_type(filename),\n                                &#39;correlation_id&#39;: str(img_id),\n                                &#39;reply_to&#39;: queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish(&#39;direct-rpc-requests&#39;, &#39;detect-faces&#39;)\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties[&#39;headers&#39;][&#39;first_publish&#39;]))\n\n    print(&#39;Facial detection RPC call for image %s total duration: %s&#39; %\n          (message.properties[&#39;correlation_id&#39;], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties[&#39;content_type&#39;])\n\nprint(&#39;RPC requests processed&#39;)\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n</code></pre>\n<p>示例代码：RPC worker</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;rpc-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;direct-rpc-requests&#39;, &#39;detect-faces&#39;):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties[&#39;timestamp&#39;].strftime(&#39;%s&#39;))\n    print(&#39;Received RPC request published %.2f seconds ago&#39; % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties[&#39;content_type&#39;])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {&#39;app_id&#39;: &#39;Chapter 6 Listing 2 Consumer&#39;,\n                  &#39;content_type&#39;: message.properties[&#39;content_type&#39;],\n                  &#39;correlation_id&#39;: message.properties[&#39;correlation_id&#39;],\n                  &#39;headers&#39;: {\n                      &#39;first_publish&#39;: message.properties[&#39;timestamp&#39;]}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish(&#39;rpc-replies&#39;, message.properties[&#39;reply_to&#39;])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<h2 id=\"fanout交换器\"><a href=\"#fanout交换器\" class=\"headerlink\" title=\"fanout交换器\"></a>fanout交换器</h2><h3 id=\"特点-1\"><a href=\"#特点-1\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。</li>\n<li>消息投递不需要检测路由键，性能更好</li>\n</ul>\n<p>示例代码</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                    &#39;fanout-rpc-requests&#39;,\n                                     exchange_type=&#39;fanout&#39;)\n        exchange.declare()</code></pre>\n<h3 id=\"示例场景-1\"><a href=\"#示例场景-1\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg\" alt></p>\n<p>示例程序：Publisher</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = &#39;response-queue-%s&#39; % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print(&#39;Response queue declared&#39;)\n\n# Bind the response queue\nif response_queue.bind(&#39;rpc-replies&#39;, queue_name):\n    print(&#39;Response queue bound&#39;)\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print &#39;Sending request for image #%s: %s&#39; % (img_id, filename)\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {&#39;content_type&#39;: utils.mime_type(filename),\n                                &#39;correlation_id&#39;: str(img_id),\n                                &#39;reply_to&#39;: queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish(&#39;fanout-rpc-requests&#39;)\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties[&#39;headers&#39;][&#39;first_publish&#39;]))\n\n    print(&#39;Facial detection RPC call for image %s total duration: %s&#39; %\n          (message.properties[&#39;correlation_id&#39;], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties[&#39;content_type&#39;])\n\nprint &#39;RPC requests processed&#39;\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n</code></pre>\n<p>示例程序：detect worker</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;rpc-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;fanout-rpc-requests&#39;):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties[&#39;timestamp&#39;].strftime(&#39;%s&#39;))\n    print(&#39;Received RPC request published %.2f seconds ago&#39; % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties[&#39;content_type&#39;])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {&#39;app_id&#39;: &#39;Chapter 6 Listing 2 Consumer&#39;,\n                  &#39;content_type&#39;: message.properties[&#39;content_type&#39;],\n                  &#39;correlation_id&#39;: message.properties[&#39;correlation_id&#39;],\n                  &#39;headers&#39;: {\n                      &#39;first_publish&#39;: message.properties[&#39;timestamp&#39;]}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties)\n    response.publish(&#39;rpc-replies&#39;, message.properties[&#39;reply_to&#39;])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<p>示例程序：Hash Consumer</p>\n<pre><code class=\"python\">import os\nimport hashlib\nimport rabbitpy\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;hashing-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;fanout-rpc-requests&#39;):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Create the hashing object\n    hash_obj = hashlib.md5(message.body)\n\n    # Print out the info, this might go into a database or log file\n    print(&#39;Image with correlation-id of %s has a hash of %s&#39; %\n          (message.properties[&#39;correlation_id&#39;],\n           hash_obj.hexdigest()))\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<h2 id=\"topic交换器\"><a href=\"#topic交换器\" class=\"headerlink\" title=\"topic交换器\"></a>topic交换器</h2><h3 id=\"特点-2\"><a href=\"#特点-2\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。</li>\n</ul>\n<h3 id=\"示例场景-2\"><a href=\"#示例场景-2\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg\" alt></p>\n<h2 id=\"headers交换器\"><a href=\"#headers交换器\" class=\"headerlink\" title=\"headers交换器\"></a>headers交换器</h2><h3 id=\"特点-3\"><a href=\"#特点-3\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>使用消息属性中的headers属性匹配。</li>\n<li>queue.bind，x-match指定匹配策略，其他参数表示绑定值</li>\n<li>绑定策略可能会使得性能降低</li>\n</ul>\n<p>示例代码</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel,\n                                     &#39;headers-rpc-requests&#39;,\n                                     exchange_type=&#39;headers&#39;)\n        exchange.declare()\n</code></pre>\n<p>示例程序：publisher</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import utils\n\n# Open the channel and connection\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the response queue that will automatically delete, is not durable and\n# is exclusive to this publisher\nqueue_name = &#39;response-queue-%s&#39; % os.getpid()\nresponse_queue = rabbitpy.Queue(channel,\n                                queue_name,\n                                auto_delete=True,\n                                durable=False,\n                                exclusive=True)\n# Declare the response queue\nif response_queue.declare():\n    print(&#39;Response queue declared&#39;)\n\n# Bind the response queue\nif response_queue.bind(&#39;rpc-replies&#39;, queue_name):\n    print(&#39;Response queue bound&#39;)\n\n# Iterate through the images to send RPC requests for\nfor img_id, filename in enumerate(utils.get_images()):\n\n    print(&#39;Sending request for image #%s: %s&#39; % (img_id, filename))\n\n    # Create the message\n    message = rabbitpy.Message(channel,\n                               utils.read_image(filename),\n                               {&#39;content_type&#39;: utils.mime_type(filename),\n                                &#39;correlation_id&#39;: str(img_id),\n                                &#39;headers&#39;: {&#39;source&#39;: &#39;profile&#39;,\n                                            &#39;object&#39;: &#39;image&#39;,\n                                            &#39;action&#39;: &#39;new&#39;},\n                                &#39;reply_to&#39;: queue_name},\n                               opinionated=True)\n\n    # Pubish the message\n    message.publish(&#39;headers-rpc-requests&#39;)\n\n    # Loop until there is a response message\n    message = None\n    while not message:\n        time.sleep(0.5)\n        message = response_queue.get()\n\n    # Ack the response message\n    message.ack()\n\n    # Caculate how long it took from publish to response\n    duration = (time.time() -\n                time.mktime(message.properties[&#39;headers&#39;][&#39;first_publish&#39;]))\n\n    print(&#39;Facial detection RPC call for image %s total duration: %s&#39; %\n          (message.properties[&#39;correlation_id&#39;], duration))\n\n    # Display the image in the IPython notebook interface\n    utils.display_image(message.body, message.properties[&#39;content_type&#39;])\n\nprint(&#39;RPC requests processed&#39;)\n\n# Close the channel and connection\nchannel.close()\nconnection.close()\n</code></pre>\n<p>示例程序：worker</p>\n<pre><code class=\"python\">import os\nimport rabbitpy\nimport time\nfrom ch6 import detect\nfrom ch6 import utils\n\n# Open the connection and the channel\nconnection = rabbitpy.Connection()\nchannel = connection.channel()\n\n# Create the worker queue\nqueue_name = &#39;rpc-worker-%s&#39; % os.getpid()\nqueue = rabbitpy.Queue(channel, queue_name,\n                       auto_delete=True,\n                       durable=False,\n                       exclusive=True)\n\n# Declare the worker queue\nif queue.declare():\n    print(&#39;Worker queue declared&#39;)\n\n# Bind the worker queue\nif queue.bind(&#39;headers-rpc-requests&#39;,\n              arguments={&#39;x-match&#39;: &#39;all&#39;,\n                         &#39;source&#39;: &#39;profile&#39;,\n                         &#39;object&#39;: &#39;image&#39;,\n                         &#39;action&#39;: &#39;new&#39;}):\n    print(&#39;Worker queue bound&#39;)\n\n# Consume messages from RabbitMQ\nfor message in queue.consume_messages():\n\n    # Display how long it took for the message to get here\n    duration = time.time() - int(message.properties[&#39;timestamp&#39;].strftime(&#39;%s&#39;))\n    print(&#39;Received RPC request published %.2f seconds ago&#39; % duration)\n\n    # Write out the message body to a temp file for facial detection process\n    temp_file = utils.write_temp_file(message.body,\n                                      message.properties[&#39;content_type&#39;])\n\n    # Detect faces\n    result_file = detect.faces(temp_file)\n\n    # Build response properties including the timestamp from the first publish\n    properties = {&#39;app_id&#39;: &#39;Chapter 6 Listing 2 Consumer&#39;,\n                  &#39;content_type&#39;: message.properties[&#39;content_type&#39;],\n                  &#39;correlation_id&#39;: message.properties[&#39;correlation_id&#39;],\n                  &#39;headers&#39;: {\n                      &#39;first_publish&#39;: message.properties[&#39;timestamp&#39;]}}\n\n    # The result file could just be the original image if nothing detected\n    body = utils.read_image(result_file)\n\n    # Remove the temp file\n    os.unlink(temp_file)\n\n    # Remove the result file\n    os.unlink(result_file)\n\n    # Publish the response response\n    response = rabbitpy.Message(channel, body, properties, opinionated=True)\n    response.publish(&#39;rpc-replies&#39;, message.properties[&#39;reply_to&#39;])\n\n    # Acknowledge the delivery of the RPC request message\n    message.ack()\n</code></pre>\n<h2 id=\"交换器路由\"><a href=\"#交换器路由\" class=\"headerlink\" title=\"交换器路由\"></a>交换器路由</h2><p>交换器间绑定，使用RPC方法Exchange.Bind。</p>\n<h3 id=\"示例场景-3\"><a href=\"#示例场景-3\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg\" alt></p>\n<p>示例代码：</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        tpc = rabbitpy.Exchange(channel, &#39;events&#39;,\n                                exchange_type=&#39;topic&#39;)\n        tpc.declare()\n        xch = rabbitpy.Exchange(channel, &#39;distributed-events&#39;,\n                                exchange_type=&#39;x-consistent-hash&#39;)\n        xch.declare()\n        xch.bind(foo, &#39;#&#39;)</code></pre>\n<h2 id=\"一致性哈希交换器\"><a href=\"#一致性哈希交换器\" class=\"headerlink\" title=\"一致性哈希交换器\"></a>一致性哈希交换器</h2><p>用于消息队列的负载均衡，可以提升吞吐量</p>\n<h3 id=\"示例场景-4\"><a href=\"#示例场景-4\" class=\"headerlink\" title=\"示例场景\"></a>示例场景</h3><p>示例代码：采用路由键的哈希值来分发消息</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;image-storage&#39;,\n                                     exchange_type=&#39;x-consistent-hash&#39;)\n        exchange.declare()</code></pre>\n<p>示例代码：header中的属性值作为哈希值</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        exchange = rabbitpy.Exchange(channel, &#39;image-storage&#39;,\n                                     exchange_type=&#39;x-consistent-hash&#39;,\n                                     arguments={&#39;hash-header&#39;: &#39;image-hash&#39;})\n        exchange.declare()\n</code></pre>\n<p>示例代码：队列的创建与绑定</p>\n<pre><code class=\"python\">import rabbitpy\n\nwith rabbitpy.Connection() as connection:\n    with connection.channel() as channel:\n        for queue_num in range(4):\n            queue = rabbitpy.Queue (channel, &#39;server%s&#39; % queue_num)\n            queue.declare()\n            queue.bind(&#39;image-storage&#39;, &#39;10&#39;)</code></pre>\n"},{"title":"rabbitmq集群","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:17:41.000Z","password":null,"summary":null,"_content":"\n## 集群概述\n\n------------\n\n### 集群节点类型\n\n- 磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。\n- 内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。\n\n**统计节点**\nrabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。\n\n## 集群设置\n\n**加入集群**\n\n```\n1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n\n```","source":"_posts/rabbitmq集群.md","raw":"---\ntitle: rabbitmq集群\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:17:41\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 集群概述\n\n------------\n\n### 集群节点类型\n\n- 磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。\n- 内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。\n\n**统计节点**\nrabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。\n\n## 集群设置\n\n**加入集群**\n\n```\n1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n\n```","slug":"rabbitmq集群","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxj80033ncuf97pzqe8g","content":"<h2 id=\"集群概述\"><a href=\"#集群概述\" class=\"headerlink\" title=\"集群概述\"></a>集群概述</h2><hr>\n<h3 id=\"集群节点类型\"><a href=\"#集群节点类型\" class=\"headerlink\" title=\"集群节点类型\"></a>集群节点类型</h3><ul>\n<li>磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。</li>\n<li>内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。</li>\n</ul>\n<p><strong>统计节点</strong><br>rabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。</p>\n<h2 id=\"集群设置\"><a href=\"#集群设置\" class=\"headerlink\" title=\"集群设置\"></a>集群设置</h2><p><strong>加入集群</strong></p>\n<pre><code>1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n</code></pre>","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"集群概述\"><a href=\"#集群概述\" class=\"headerlink\" title=\"集群概述\"></a>集群概述</h2><hr>\n<h3 id=\"集群节点类型\"><a href=\"#集群节点类型\" class=\"headerlink\" title=\"集群节点类型\"></a>集群节点类型</h3><ul>\n<li>磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。</li>\n<li>内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。</li>\n</ul>\n<p><strong>统计节点</strong><br>rabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。</p>\n<h2 id=\"集群设置\"><a href=\"#集群设置\" class=\"headerlink\" title=\"集群设置\"></a>集群设置</h2><p><strong>加入集群</strong></p>\n<pre><code>1、在第一节点上运行rabbitmq\n2、在第二节点上停止rabbitmq，并清除状态\nrabbitmqctl stop_app\nrabbitmqctl reset\n3、加入主节点，构成集群\nrabbitmqctl join_cluster rabbitmq@node1\n4、再次启动第二节点rabbitmq\nrabbitmqctl start_app\n\n\n</code></pre>"},{"title":"rabbitmq进阶","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-04-03T13:32:53.000Z","password":null,"summary":null,"_content":"\n## 消息传递\n\n**mandatory**\n\n`mandatory=true`，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 `Basic.Return `命令将消息返回给生产者，生产者通过调用 `channel.addReturnListener `添加监听器接收返回结果\n`mandatory=false`，上述情形下，RabbitMQ 将消息直接丢弃\n\n**immediate**\n\n`immediate=true`，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 `Basic.Return` 返回生产者\n**和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息**\n\n**备份交换器（Alternate Exchange）**\n\nAE可以将未被路由的消息存储到 RabbitMQ 中。简化了`mandatory`+`addReturnListener `的编程逻辑。\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"alternate-exchange\",\"myAe\");\n\n// 声明普通交换器（AE交换器作为备份交换器）\nchannel.exchangeDeclare(\"normalExchange\",\"direct\",true,false,args);\n// 声明AE交换器\nchannel.exchangeDeclare(\"myAe\",\"fanout\",true,false,null);\n\n// 普通队列 绑定 普通交换器\nchannel.queueBind(\"normalQueue\",\"normalExchange\",\"normalKey\");\n\n// 声明 未路由队列\nchannel.queueDeclare(\"unroutedQueue\",true,false,false,null);\n// 未路由队列 绑定 AE交换器\nchannel.queueBind(\"unroutedQueue\",\"myAe\",\"\");\n```\n\n特殊情况\n\n- 若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器和mandatory参数一起使用，该参数无效\n\n## 过期时间（TTL）\n\n**通过队列属性设置消息TTL**\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"x-message-ttl\",6000); // 单位毫秒\nchannel.queueDeclare(queueName,durable,exclusive,autoDelete,args);\n```\n\n- 不设置TTL：该消息不会过期\n- TTL为0：若直接可以投递到消费者，否则立刻被丢弃\n\n消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。\n\n**设置每条消息TTL**\n\n在 `channel.basicPublish` 方法中加入 expiration 参数，单位毫秒\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.deliveryMode(2);\nbuilder.expiration(\"60000\");\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(exchangeName,routingKey,mandatory,properties,\"ttlTestMessage\".getBytes());\n```\n\n消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。\n\n**设置队列的TTL**\n\n通过 `channel.queueDeclare` 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间\n\nRabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置\n\n## 死信队列\n\n当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列\n\n死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度\n\n绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX\n\n## 延迟队列\n\n消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费\n\n**场景：**\n\n订单超时支付，延时队列做异常处理；\n\n智能设备在指定时间进行工作，延时队列做指令推送；\n\n**用法：**\n\n- 每条消息设置为10秒过期时间\n- 通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中\n- 消费者订阅 queue.dlx 队列\n- 10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息\n\n## 优先级队列\n\n具有高优先级的队列有高的优先权，优先级高的消息优先被消费\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.priority(5);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(\"exchange_priority\",\"rk_priority\",properties,(\"message\").getBytes());\n```\n\n- 默认优先级为0，最高为队列设置的最大优先级\n- 如果Broker中有消息堆积，优先级高的消息可以被优先消费\n\n## RPC实现\n\n远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。\n\nRPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。\n\n```java\nString callbackQueueName = channel.queueDeclare().getQueue();\nBasicProperties props = new BasicProperties.Builder().replyTo(callbackQueueName).build();\nchannel.basicPublish(\"\",\"rpc_queue\",props,message.getBytes());\n```\n\nRPC 处理流程：\n\n- 客户端启动时，创建一个匿名的回调队列\n- 客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求\n- 请求被发送到 rpc_queue 队列中\n- RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列''; \n- 客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果\n\n## 持久化\n\n持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失\n\n持久化的各种情况\n\nRabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化\n\n- 若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。\n- 若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失\n- 若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡\n- 生产环境会设置镜像队列保证系统的高可用性\n  \n\n## 生产者确认\n\n默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。\n\n**事务机制**\n\n事务方法：\n\n- channel.txSelect： 用于将当前信道设置成事务模式\n- channel.txCommit：用于提交事务\n- channel.txRollback：用于事务回滚\n\n事务流程：\n\n- 客户端发送 Tx.Select，将信道置为事务模式\n- Broker回复 Tx.Select-Ok，确认已将信道置为事务模式\n- Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务\n- Broker 回复 Tx.Commit，确认事务提交\n\n事务问题：事务机制会耗尽 RabbitMQ 的性能\n\n**发送方确认机制**\n\n1. 生产者将信道设置成 confirm 模式\n2. 信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID\n3. 消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者\n\n发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。\n\n发送方确认机制的优势在于不一定需要同步确认：\n\n- 批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回\n- 异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。\n\n注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。\n\n## 消费端要点\n\n**消息分发**\n\n- 当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者\n- 但是这样会造成因为各机器性能不同而引起负载不均\n- 消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量\n- 一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果\n- Basic.Qos的使用对于拉模式消费方式无效\n\n**消息顺序性**\n\n顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的\n\n顺序性打破的情况：\n\n-  生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现\n- 启用 publiser confirm时，发生发生超时、中断，导致错序\n- 生产者设置了延迟队列，但是超时时间设置的不一样\n- 消息设置了优先级，消费端收到的消息必然不是顺序性的\n\n**弃用 QueueingConsumer**\n\n- 队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决\n- QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低\n- 同步调用 QueueingConsumer 会产生死锁\n\n## 消息传输保障\n\n**消息传输保障等级**\n\nAt most once：最多一次。消息可能丢失，但绝不会重复传输\nAt least once：最少一次。消息绝不会丢失，但可能重复传输\nExactly once：恰好一次。每条消息肯定会，有且传输一次\n最少一次：需要考虑 事务、mandatory、持久化处理、autoAck\n最多一次：无须考虑以上问题，随便发送与接收\n恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。\n\n去重一般是通过业务客户端引入GUID实现","source":"_posts/rabbitmq进阶.md","raw":"---\ntitle: rabbitmq进阶\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-04-03 21:32:53\npassword:\nsummary:\ntags:\n- rabbitmq\ncategories:\n- rabbitmq\n---\n\n## 消息传递\n\n**mandatory**\n\n`mandatory=true`，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 `Basic.Return `命令将消息返回给生产者，生产者通过调用 `channel.addReturnListener `添加监听器接收返回结果\n`mandatory=false`，上述情形下，RabbitMQ 将消息直接丢弃\n\n**immediate**\n\n`immediate=true`，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 `Basic.Return` 返回生产者\n**和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息**\n\n**备份交换器（Alternate Exchange）**\n\nAE可以将未被路由的消息存储到 RabbitMQ 中。简化了`mandatory`+`addReturnListener `的编程逻辑。\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"alternate-exchange\",\"myAe\");\n\n// 声明普通交换器（AE交换器作为备份交换器）\nchannel.exchangeDeclare(\"normalExchange\",\"direct\",true,false,args);\n// 声明AE交换器\nchannel.exchangeDeclare(\"myAe\",\"fanout\",true,false,null);\n\n// 普通队列 绑定 普通交换器\nchannel.queueBind(\"normalQueue\",\"normalExchange\",\"normalKey\");\n\n// 声明 未路由队列\nchannel.queueDeclare(\"unroutedQueue\",true,false,false,null);\n// 未路由队列 绑定 AE交换器\nchannel.queueBind(\"unroutedQueue\",\"myAe\",\"\");\n```\n\n特殊情况\n\n- 若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失\n- 若备份交换器和mandatory参数一起使用，该参数无效\n\n## 过期时间（TTL）\n\n**通过队列属性设置消息TTL**\n\n```java\nMap<String,Object> args = new HashMap<String,Object>();\nargs.put(\"x-message-ttl\",6000); // 单位毫秒\nchannel.queueDeclare(queueName,durable,exclusive,autoDelete,args);\n```\n\n- 不设置TTL：该消息不会过期\n- TTL为0：若直接可以投递到消费者，否则立刻被丢弃\n\n消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。\n\n**设置每条消息TTL**\n\n在 `channel.basicPublish` 方法中加入 expiration 参数，单位毫秒\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.deliveryMode(2);\nbuilder.expiration(\"60000\");\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(exchangeName,routingKey,mandatory,properties,\"ttlTestMessage\".getBytes());\n```\n\n消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。\n\n**设置队列的TTL**\n\n通过 `channel.queueDeclare` 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间\n\nRabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置\n\n## 死信队列\n\n当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列\n\n死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度\n\n绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX\n\n## 延迟队列\n\n消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费\n\n**场景：**\n\n订单超时支付，延时队列做异常处理；\n\n智能设备在指定时间进行工作，延时队列做指令推送；\n\n**用法：**\n\n- 每条消息设置为10秒过期时间\n- 通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中\n- 消费者订阅 queue.dlx 队列\n- 10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息\n\n## 优先级队列\n\n具有高优先级的队列有高的优先权，优先级高的消息优先被消费\n\n```java\nAMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.priority(5);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(\"exchange_priority\",\"rk_priority\",properties,(\"message\").getBytes());\n```\n\n- 默认优先级为0，最高为队列设置的最大优先级\n- 如果Broker中有消息堆积，优先级高的消息可以被优先消费\n\n## RPC实现\n\n远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。\n\nRPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。\n\n```java\nString callbackQueueName = channel.queueDeclare().getQueue();\nBasicProperties props = new BasicProperties.Builder().replyTo(callbackQueueName).build();\nchannel.basicPublish(\"\",\"rpc_queue\",props,message.getBytes());\n```\n\nRPC 处理流程：\n\n- 客户端启动时，创建一个匿名的回调队列\n- 客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求\n- 请求被发送到 rpc_queue 队列中\n- RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列''; \n- 客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果\n\n## 持久化\n\n持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失\n\n持久化的各种情况\n\nRabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化\n\n- 若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。\n- 若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失\n- 若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡\n- 生产环境会设置镜像队列保证系统的高可用性\n  \n\n## 生产者确认\n\n默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。\n\n**事务机制**\n\n事务方法：\n\n- channel.txSelect： 用于将当前信道设置成事务模式\n- channel.txCommit：用于提交事务\n- channel.txRollback：用于事务回滚\n\n事务流程：\n\n- 客户端发送 Tx.Select，将信道置为事务模式\n- Broker回复 Tx.Select-Ok，确认已将信道置为事务模式\n- Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务\n- Broker 回复 Tx.Commit，确认事务提交\n\n事务问题：事务机制会耗尽 RabbitMQ 的性能\n\n**发送方确认机制**\n\n1. 生产者将信道设置成 confirm 模式\n2. 信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID\n3. 消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者\n\n发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。\n\n发送方确认机制的优势在于不一定需要同步确认：\n\n- 批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回\n- 异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。\n\n注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。\n\n## 消费端要点\n\n**消息分发**\n\n- 当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者\n- 但是这样会造成因为各机器性能不同而引起负载不均\n- 消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量\n- 一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果\n- Basic.Qos的使用对于拉模式消费方式无效\n\n**消息顺序性**\n\n顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的\n\n顺序性打破的情况：\n\n-  生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现\n- 启用 publiser confirm时，发生发生超时、中断，导致错序\n- 生产者设置了延迟队列，但是超时时间设置的不一样\n- 消息设置了优先级，消费端收到的消息必然不是顺序性的\n\n**弃用 QueueingConsumer**\n\n- 队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决\n- QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低\n- 同步调用 QueueingConsumer 会产生死锁\n\n## 消息传输保障\n\n**消息传输保障等级**\n\nAt most once：最多一次。消息可能丢失，但绝不会重复传输\nAt least once：最少一次。消息绝不会丢失，但可能重复传输\nExactly once：恰好一次。每条消息肯定会，有且传输一次\n最少一次：需要考虑 事务、mandatory、持久化处理、autoAck\n最多一次：无须考虑以上问题，随便发送与接收\n恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。\n\n去重一般是通过业务客户端引入GUID实现","slug":"rabbitmq进阶","published":1,"updated":"2021-04-04T05:02:06.522Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxjb0038ncufov2efeuc","content":"<h2 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h2><p><strong>mandatory</strong></p>\n<p><code>mandatory=true</code>，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 <code>Basic.Return</code>命令将消息返回给生产者，生产者通过调用 <code>channel.addReturnListener</code>添加监听器接收返回结果<br><code>mandatory=false</code>，上述情形下，RabbitMQ 将消息直接丢弃</p>\n<p><strong>immediate</strong></p>\n<p><code>immediate=true</code>，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 <code>Basic.Return</code> 返回生产者<br><strong>和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息</strong></p>\n<p><strong>备份交换器（Alternate Exchange）</strong></p>\n<p>AE可以将未被路由的消息存储到 RabbitMQ 中。简化了<code>mandatory</code>+<code>addReturnListener</code>的编程逻辑。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span> args <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nargs<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"alternate-exchange\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"myAe\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">// 声明普通交换器（AE交换器作为备份交换器）</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">exchangeDeclare</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"normalExchange\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"direct\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>args<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 声明AE交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">exchangeDeclare</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"myAe\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"fanout\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">// 普通队列 绑定 普通交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueBind</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"normalQueue\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"normalExchange\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"normalKey\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\" spellcheck=\"true\">// 声明 未路由队列</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"unroutedQueue\"</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">// 未路由队列 绑定 AE交换器</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueBind</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"unroutedQueue\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"myAe\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>特殊情况</p>\n<ul>\n<li>若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器和mandatory参数一起使用，该参数无效</li>\n</ul>\n<h2 id=\"过期时间（TTL）\"><a href=\"#过期时间（TTL）\" class=\"headerlink\" title=\"过期时间（TTL）\"></a>过期时间（TTL）</h2><p><strong>通过队列属性设置消息TTL</strong></p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span> args <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span>Object<span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nargs<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"x-message-ttl\"</span><span class=\"token punctuation\">,</span><span class=\"token number\">6000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 单位毫秒</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span>queueName<span class=\"token punctuation\">,</span>durable<span class=\"token punctuation\">,</span>exclusive<span class=\"token punctuation\">,</span>autoDelete<span class=\"token punctuation\">,</span>args<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>不设置TTL：该消息不会过期</li>\n<li>TTL为0：若直接可以投递到消费者，否则立刻被丢弃</li>\n</ul>\n<p>消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。</p>\n<p><strong>设置每条消息TTL</strong></p>\n<p>在 <code>channel.basicPublish</code> 方法中加入 expiration 参数，单位毫秒</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder builder <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nbuilder<span class=\"token punctuation\">.</span><span class=\"token function\">deliveryMode</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nbuilder<span class=\"token punctuation\">.</span><span class=\"token function\">expiration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"60000\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nAMQP<span class=\"token punctuation\">.</span>BasicProperties properties <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span>exchangeName<span class=\"token punctuation\">,</span>routingKey<span class=\"token punctuation\">,</span>mandatory<span class=\"token punctuation\">,</span>properties<span class=\"token punctuation\">,</span><span class=\"token string\">\"ttlTestMessage\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。</p>\n<p><strong>设置队列的TTL</strong></p>\n<p>通过 <code>channel.queueDeclare</code> 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间</p>\n<p>RabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置</p>\n<h2 id=\"死信队列\"><a href=\"#死信队列\" class=\"headerlink\" title=\"死信队列\"></a>死信队列</h2><p>当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列</p>\n<p>死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度</p>\n<p>绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX</p>\n<h2 id=\"延迟队列\"><a href=\"#延迟队列\" class=\"headerlink\" title=\"延迟队列\"></a>延迟队列</h2><p>消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费</p>\n<p><strong>场景：</strong></p>\n<p>订单超时支付，延时队列做异常处理；</p>\n<p>智能设备在指定时间进行工作，延时队列做指令推送；</p>\n<p><strong>用法：</strong></p>\n<ul>\n<li>每条消息设置为10秒过期时间</li>\n<li>通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中</li>\n<li>消费者订阅 queue.dlx 队列</li>\n<li>10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息</li>\n</ul>\n<h2 id=\"优先级队列\"><a href=\"#优先级队列\" class=\"headerlink\" title=\"优先级队列\"></a>优先级队列</h2><p>具有高优先级的队列有高的优先权，优先级高的消息优先被消费</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder builder <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AMQP<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">.</span>Builder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nbuilder<span class=\"token punctuation\">.</span><span class=\"token function\">priority</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nAMQP<span class=\"token punctuation\">.</span>BasicProperties properties <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"exchange_priority\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"rk_priority\"</span><span class=\"token punctuation\">,</span>properties<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"message\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>默认优先级为0，最高为队列设置的最大优先级</li>\n<li>如果Broker中有消息堆积，优先级高的消息可以被优先消费</li>\n</ul>\n<h2 id=\"RPC实现\"><a href=\"#RPC实现\" class=\"headerlink\" title=\"RPC实现\"></a>RPC实现</h2><p>远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。</p>\n<p>RPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">String callbackQueueName <span class=\"token operator\">=</span> channel<span class=\"token punctuation\">.</span><span class=\"token function\">queueDeclare</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getQueue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nBasicProperties props <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">BasicProperties<span class=\"token punctuation\">.</span>Builder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">replyTo</span><span class=\"token punctuation\">(</span>callbackQueueName<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nchannel<span class=\"token punctuation\">.</span><span class=\"token function\">basicPublish</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"rpc_queue\"</span><span class=\"token punctuation\">,</span>props<span class=\"token punctuation\">,</span>message<span class=\"token punctuation\">.</span><span class=\"token function\">getBytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>RPC 处理流程：</p>\n<ul>\n<li>客户端启动时，创建一个匿名的回调队列</li>\n<li>客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求</li>\n<li>请求被发送到 rpc_queue 队列中</li>\n<li>RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列’’; </li>\n<li>客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果</li>\n</ul>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><p>持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失</p>\n<p>持久化的各种情况</p>\n<p>RabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化</p>\n<ul>\n<li>若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。</li>\n<li>若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失</li>\n<li>若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡</li>\n<li>生产环境会设置镜像队列保证系统的高可用性</li>\n</ul>\n<h2 id=\"生产者确认\"><a href=\"#生产者确认\" class=\"headerlink\" title=\"生产者确认\"></a>生产者确认</h2><p>默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。</p>\n<p><strong>事务机制</strong></p>\n<p>事务方法：</p>\n<ul>\n<li>channel.txSelect： 用于将当前信道设置成事务模式</li>\n<li>channel.txCommit：用于提交事务</li>\n<li>channel.txRollback：用于事务回滚</li>\n</ul>\n<p>事务流程：</p>\n<ul>\n<li>客户端发送 Tx.Select，将信道置为事务模式</li>\n<li>Broker回复 Tx.Select-Ok，确认已将信道置为事务模式</li>\n<li>Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务</li>\n<li>Broker 回复 Tx.Commit，确认事务提交</li>\n</ul>\n<p>事务问题：事务机制会耗尽 RabbitMQ 的性能</p>\n<p><strong>发送方确认机制</strong></p>\n<ol>\n<li>生产者将信道设置成 confirm 模式</li>\n<li>信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID</li>\n<li>消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者</li>\n</ol>\n<p>发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。</p>\n<p>发送方确认机制的优势在于不一定需要同步确认：</p>\n<ul>\n<li>批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回</li>\n<li>异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。</li>\n</ul>\n<p>注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。</p>\n<h2 id=\"消费端要点\"><a href=\"#消费端要点\" class=\"headerlink\" title=\"消费端要点\"></a>消费端要点</h2><p><strong>消息分发</strong></p>\n<ul>\n<li>当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者</li>\n<li>但是这样会造成因为各机器性能不同而引起负载不均</li>\n<li>消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量</li>\n<li>一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果</li>\n<li>Basic.Qos的使用对于拉模式消费方式无效</li>\n</ul>\n<p><strong>消息顺序性</strong></p>\n<p>顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的</p>\n<p>顺序性打破的情况：</p>\n<ul>\n<li>生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现</li>\n<li>启用 publiser confirm时，发生发生超时、中断，导致错序</li>\n<li>生产者设置了延迟队列，但是超时时间设置的不一样</li>\n<li>消息设置了优先级，消费端收到的消息必然不是顺序性的</li>\n</ul>\n<p><strong>弃用 QueueingConsumer</strong></p>\n<ul>\n<li>队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决</li>\n<li>QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低</li>\n<li>同步调用 QueueingConsumer 会产生死锁</li>\n</ul>\n<h2 id=\"消息传输保障\"><a href=\"#消息传输保障\" class=\"headerlink\" title=\"消息传输保障\"></a>消息传输保障</h2><p><strong>消息传输保障等级</strong></p>\n<p>At most once：最多一次。消息可能丢失，但绝不会重复传输<br>At least once：最少一次。消息绝不会丢失，但可能重复传输<br>Exactly once：恰好一次。每条消息肯定会，有且传输一次<br>最少一次：需要考虑 事务、mandatory、持久化处理、autoAck<br>最多一次：无须考虑以上问题，随便发送与接收<br>恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。</p>\n<p>去重一般是通过业务客户端引入GUID实现</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h2><p><strong>mandatory</strong></p>\n<p><code>mandatory=true</code>，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 <code>Basic.Return</code>命令将消息返回给生产者，生产者通过调用 <code>channel.addReturnListener</code>添加监听器接收返回结果<br><code>mandatory=false</code>，上述情形下，RabbitMQ 将消息直接丢弃</p>\n<p><strong>immediate</strong></p>\n<p><code>immediate=true</code>，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 <code>Basic.Return</code> 返回生产者<br><strong>和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息</strong></p>\n<p><strong>备份交换器（Alternate Exchange）</strong></p>\n<p>AE可以将未被路由的消息存储到 RabbitMQ 中。简化了<code>mandatory</code>+<code>addReturnListener</code>的编程逻辑。</p>\n<pre><code class=\"java\">Map&lt;String,Object&gt; args = new HashMap&lt;String,Object&gt;();\nargs.put(&quot;alternate-exchange&quot;,&quot;myAe&quot;);\n\n// 声明普通交换器（AE交换器作为备份交换器）\nchannel.exchangeDeclare(&quot;normalExchange&quot;,&quot;direct&quot;,true,false,args);\n// 声明AE交换器\nchannel.exchangeDeclare(&quot;myAe&quot;,&quot;fanout&quot;,true,false,null);\n\n// 普通队列 绑定 普通交换器\nchannel.queueBind(&quot;normalQueue&quot;,&quot;normalExchange&quot;,&quot;normalKey&quot;);\n\n// 声明 未路由队列\nchannel.queueDeclare(&quot;unroutedQueue&quot;,true,false,false,null);\n// 未路由队列 绑定 AE交换器\nchannel.queueBind(&quot;unroutedQueue&quot;,&quot;myAe&quot;,&quot;&quot;);</code></pre>\n<p>特殊情况</p>\n<ul>\n<li>若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li>\n<li>若备份交换器和mandatory参数一起使用，该参数无效</li>\n</ul>\n<h2 id=\"过期时间（TTL）\"><a href=\"#过期时间（TTL）\" class=\"headerlink\" title=\"过期时间（TTL）\"></a>过期时间（TTL）</h2><p><strong>通过队列属性设置消息TTL</strong></p>\n<pre><code class=\"java\">Map&lt;String,Object&gt; args = new HashMap&lt;String,Object&gt;();\nargs.put(&quot;x-message-ttl&quot;,6000); // 单位毫秒\nchannel.queueDeclare(queueName,durable,exclusive,autoDelete,args);</code></pre>\n<ul>\n<li>不设置TTL：该消息不会过期</li>\n<li>TTL为0：若直接可以投递到消费者，否则立刻被丢弃</li>\n</ul>\n<p>消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。</p>\n<p><strong>设置每条消息TTL</strong></p>\n<p>在 <code>channel.basicPublish</code> 方法中加入 expiration 参数，单位毫秒</p>\n<pre><code class=\"java\">AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.deliveryMode(2);\nbuilder.expiration(&quot;60000&quot;);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(exchangeName,routingKey,mandatory,properties,&quot;ttlTestMessage&quot;.getBytes());</code></pre>\n<p>消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。</p>\n<p><strong>设置队列的TTL</strong></p>\n<p>通过 <code>channel.queueDeclare</code> 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间</p>\n<p>RabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置</p>\n<h2 id=\"死信队列\"><a href=\"#死信队列\" class=\"headerlink\" title=\"死信队列\"></a>死信队列</h2><p>当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列</p>\n<p>死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度</p>\n<p>绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX</p>\n<h2 id=\"延迟队列\"><a href=\"#延迟队列\" class=\"headerlink\" title=\"延迟队列\"></a>延迟队列</h2><p>消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费</p>\n<p><strong>场景：</strong></p>\n<p>订单超时支付，延时队列做异常处理；</p>\n<p>智能设备在指定时间进行工作，延时队列做指令推送；</p>\n<p><strong>用法：</strong></p>\n<ul>\n<li>每条消息设置为10秒过期时间</li>\n<li>通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中</li>\n<li>消费者订阅 queue.dlx 队列</li>\n<li>10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息</li>\n</ul>\n<h2 id=\"优先级队列\"><a href=\"#优先级队列\" class=\"headerlink\" title=\"优先级队列\"></a>优先级队列</h2><p>具有高优先级的队列有高的优先权，优先级高的消息优先被消费</p>\n<pre><code class=\"java\">AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();\nbuilder.priority(5);\nAMQP.BasicProperties properties = builder.build();\nchannel.basicPublish(&quot;exchange_priority&quot;,&quot;rk_priority&quot;,properties,(&quot;message&quot;).getBytes());</code></pre>\n<ul>\n<li>默认优先级为0，最高为队列设置的最大优先级</li>\n<li>如果Broker中有消息堆积，优先级高的消息可以被优先消费</li>\n</ul>\n<h2 id=\"RPC实现\"><a href=\"#RPC实现\" class=\"headerlink\" title=\"RPC实现\"></a>RPC实现</h2><p>远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。</p>\n<p>RPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。</p>\n<pre><code class=\"java\">String callbackQueueName = channel.queueDeclare().getQueue();\nBasicProperties props = new BasicProperties.Builder().replyTo(callbackQueueName).build();\nchannel.basicPublish(&quot;&quot;,&quot;rpc_queue&quot;,props,message.getBytes());</code></pre>\n<p>RPC 处理流程：</p>\n<ul>\n<li>客户端启动时，创建一个匿名的回调队列</li>\n<li>客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求</li>\n<li>请求被发送到 rpc_queue 队列中</li>\n<li>RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列’’; </li>\n<li>客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果</li>\n</ul>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><p>持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失</p>\n<p>持久化的各种情况</p>\n<p>RabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化</p>\n<ul>\n<li>若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。</li>\n<li>若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失</li>\n<li>若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡</li>\n<li>生产环境会设置镜像队列保证系统的高可用性</li>\n</ul>\n<h2 id=\"生产者确认\"><a href=\"#生产者确认\" class=\"headerlink\" title=\"生产者确认\"></a>生产者确认</h2><p>默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。</p>\n<p><strong>事务机制</strong></p>\n<p>事务方法：</p>\n<ul>\n<li>channel.txSelect： 用于将当前信道设置成事务模式</li>\n<li>channel.txCommit：用于提交事务</li>\n<li>channel.txRollback：用于事务回滚</li>\n</ul>\n<p>事务流程：</p>\n<ul>\n<li>客户端发送 Tx.Select，将信道置为事务模式</li>\n<li>Broker回复 Tx.Select-Ok，确认已将信道置为事务模式</li>\n<li>Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务</li>\n<li>Broker 回复 Tx.Commit，确认事务提交</li>\n</ul>\n<p>事务问题：事务机制会耗尽 RabbitMQ 的性能</p>\n<p><strong>发送方确认机制</strong></p>\n<ol>\n<li>生产者将信道设置成 confirm 模式</li>\n<li>信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID</li>\n<li>消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者</li>\n</ol>\n<p>发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。</p>\n<p>发送方确认机制的优势在于不一定需要同步确认：</p>\n<ul>\n<li>批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回</li>\n<li>异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。</li>\n</ul>\n<p>注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。</p>\n<h2 id=\"消费端要点\"><a href=\"#消费端要点\" class=\"headerlink\" title=\"消费端要点\"></a>消费端要点</h2><p><strong>消息分发</strong></p>\n<ul>\n<li>当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者</li>\n<li>但是这样会造成因为各机器性能不同而引起负载不均</li>\n<li>消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量</li>\n<li>一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果</li>\n<li>Basic.Qos的使用对于拉模式消费方式无效</li>\n</ul>\n<p><strong>消息顺序性</strong></p>\n<p>顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的</p>\n<p>顺序性打破的情况：</p>\n<ul>\n<li>生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现</li>\n<li>启用 publiser confirm时，发生发生超时、中断，导致错序</li>\n<li>生产者设置了延迟队列，但是超时时间设置的不一样</li>\n<li>消息设置了优先级，消费端收到的消息必然不是顺序性的</li>\n</ul>\n<p><strong>弃用 QueueingConsumer</strong></p>\n<ul>\n<li>队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决</li>\n<li>QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低</li>\n<li>同步调用 QueueingConsumer 会产生死锁</li>\n</ul>\n<h2 id=\"消息传输保障\"><a href=\"#消息传输保障\" class=\"headerlink\" title=\"消息传输保障\"></a>消息传输保障</h2><p><strong>消息传输保障等级</strong></p>\n<p>At most once：最多一次。消息可能丢失，但绝不会重复传输<br>At least once：最少一次。消息绝不会丢失，但可能重复传输<br>Exactly once：恰好一次。每条消息肯定会，有且传输一次<br>最少一次：需要考虑 事务、mandatory、持久化处理、autoAck<br>最多一次：无须考虑以上问题，随便发送与接收<br>恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。</p>\n<p>去重一般是通过业务客户端引入GUID实现</p>\n"},{"title":"redis AOF机制","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:07:40.000Z","password":null,"summary":null,"_content":"\n先写内存，在写日志。\n1、命令执行成功才会被记录日志。\n2、避免对当前命令的阻塞。\n\n## 风险\n1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。\n2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续操作。\n3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。\n4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。\n\n## 日志写回策略与选择\n- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\n- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\n- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n\n**对比如下**：\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201022202948278-1557328450.jpg)\n\n**选择如下**：\n- 高性能，选择 No；\n- 高可靠性，选择 Always；\n- 允许数据丢失，同时性能较好，选择 Everysec。\n\n## 重写机制\n\n后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。\n\n**作用**\n1、避免日志文件过大。\n2、后台线程避免阻塞主线程\n\n**流程**\n一个拷贝，两处日志\n1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程\n2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区\n3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件","source":"_posts/redis-AOF机制.md","raw":"---\ntitle: redis AOF机制\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:07:40\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n先写内存，在写日志。\n1、命令执行成功才会被记录日志。\n2、避免对当前命令的阻塞。\n\n## 风险\n1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。\n2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续操作。\n3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。\n4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。\n\n## 日志写回策略与选择\n- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\n- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\n- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n\n**对比如下**：\n![](https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201022202948278-1557328450.jpg)\n\n**选择如下**：\n- 高性能，选择 No；\n- 高可靠性，选择 Always；\n- 允许数据丢失，同时性能较好，选择 Everysec。\n\n## 重写机制\n\n后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。\n\n**作用**\n1、避免日志文件过大。\n2、后台线程避免阻塞主线程\n\n**流程**\n一个拷贝，两处日志\n1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程\n2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区\n3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件","slug":"redis-AOF机制","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxje003bncuf7tr0yman","content":"<p>先写内存，在写日志。<br>1、命令执行成功才会被记录日志。<br>2、避免对当前命令的阻塞。</p>\n<h2 id=\"风险\"><a href=\"#风险\" class=\"headerlink\" title=\"风险\"></a>风险</h2><p>1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。<br>2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续操作。<br>3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。<br>4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。</p>\n<h2 id=\"日志写回策略与选择\"><a href=\"#日志写回策略与选择\" class=\"headerlink\" title=\"日志写回策略与选择\"></a>日志写回策略与选择</h2><ul>\n<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>\n<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>\n<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>\n</ul>\n<p><strong>对比如下</strong>：<br><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201022202948278-1557328450.jpg\" alt></p>\n<p><strong>选择如下</strong>：</p>\n<ul>\n<li>高性能，选择 No；</li>\n<li>高可靠性，选择 Always；</li>\n<li>允许数据丢失，同时性能较好，选择 Everysec。</li>\n</ul>\n<h2 id=\"重写机制\"><a href=\"#重写机制\" class=\"headerlink\" title=\"重写机制\"></a>重写机制</h2><p>后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。</p>\n<p><strong>作用</strong><br>1、避免日志文件过大。<br>2、后台线程避免阻塞主线程</p>\n<p><strong>流程</strong><br>一个拷贝，两处日志<br>1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程<br>2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区<br>3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>先写内存，在写日志。<br>1、命令执行成功才会被记录日志。<br>2、避免对当前命令的阻塞。</p>\n<h2 id=\"风险\"><a href=\"#风险\" class=\"headerlink\" title=\"风险\"></a>风险</h2><p>1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。<br>2、AOF写磁盘，当磁盘压力大，会导致写盘慢，阻塞后续操作。<br>3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。<br>4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。</p>\n<h2 id=\"日志写回策略与选择\"><a href=\"#日志写回策略与选择\" class=\"headerlink\" title=\"日志写回策略与选择\"></a>日志写回策略与选择</h2><ul>\n<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>\n<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>\n<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>\n</ul>\n<p><strong>对比如下</strong>：<br><img src=\"https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201022202948278-1557328450.jpg\" alt></p>\n<p><strong>选择如下</strong>：</p>\n<ul>\n<li>高性能，选择 No；</li>\n<li>高可靠性，选择 Always；</li>\n<li>允许数据丢失，同时性能较好，选择 Everysec。</li>\n</ul>\n<h2 id=\"重写机制\"><a href=\"#重写机制\" class=\"headerlink\" title=\"重写机制\"></a>重写机制</h2><p>后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。</p>\n<p><strong>作用</strong><br>1、避免日志文件过大。<br>2、后台线程避免阻塞主线程</p>\n<p><strong>流程</strong><br>一个拷贝，两处日志<br>1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程<br>2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区<br>3、拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件</p>\n"},{"title":"redis6.0","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-12-09T05:35:15.000Z","password":null,"summary":null,"_content":"\n## 多线程\n\n**问题**\n\n单个主线程处理网络请求的速度跟不上底层网络硬件的速度。\n\n**优化**\n\n多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。\n\n**具体流程**\n\n1、服务端和客户端建立 Socket 连接，并分配处理线程\n\n2、IO 线程读取并解析请求\n\n3、主线程执行请求操作\n\n4、IO 线程回写 Socket 和主线程清空全局队列\n\n相关配置：\n\n```\nio-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数\n```\n\n## 服务端协助的客户端缓存（Tracking）\n\n**问题**\n\n如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。\n\n### 普通模式\n\n实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。\n\n服务端对于记录的 key 只会报告一次 invalidate 消息\n\n只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息\n\n**设置命令**\n\n```\nCLIENT TRACKING ON|OFF\n```\n\n### 广播模式\n\n服务端会给客户端广播所有 key 的失效情况，不过，这样做了之后，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。\n\n**应用场景**\n\n我们会让客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。\n\n**区别**：\n\n在广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。\n\n## 细粒度的权限控制\n\n1、支持创建不同用户来使用 Redis\n\n```\nACL SETUSER normaluser on > abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” \n```\n\n2、支持以用户为粒度设置命令操作的访问权限\n\n![acl_cmd](acl_cmd.jpg)\n\n","source":"_posts/redis6-0.md","raw":"---\ntitle: redis6.0\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-12-09 13:35:15\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 多线程\n\n**问题**\n\n单个主线程处理网络请求的速度跟不上底层网络硬件的速度。\n\n**优化**\n\n多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。\n\n**具体流程**\n\n1、服务端和客户端建立 Socket 连接，并分配处理线程\n\n2、IO 线程读取并解析请求\n\n3、主线程执行请求操作\n\n4、IO 线程回写 Socket 和主线程清空全局队列\n\n相关配置：\n\n```\nio-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数\n```\n\n## 服务端协助的客户端缓存（Tracking）\n\n**问题**\n\n如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。\n\n### 普通模式\n\n实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。\n\n服务端对于记录的 key 只会报告一次 invalidate 消息\n\n只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息\n\n**设置命令**\n\n```\nCLIENT TRACKING ON|OFF\n```\n\n### 广播模式\n\n服务端会给客户端广播所有 key 的失效情况，不过，这样做了之后，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。\n\n**应用场景**\n\n我们会让客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。\n\n**区别**：\n\n在广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。\n\n## 细粒度的权限控制\n\n1、支持创建不同用户来使用 Redis\n\n```\nACL SETUSER normaluser on > abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” \n```\n\n2、支持以用户为粒度设置命令操作的访问权限\n\n![acl_cmd](acl_cmd.jpg)\n\n","slug":"redis6-0","published":1,"updated":"2021-04-01T23:01:49.986Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxjh003encufj0aacev6","content":"<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><p><strong>问题</strong></p>\n<p>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p>\n<p><strong>优化</strong></p>\n<p>多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p>\n<p><strong>具体流程</strong></p>\n<p>1、服务端和客户端建立 Socket 连接，并分配处理线程</p>\n<p>2、IO 线程读取并解析请求</p>\n<p>3、主线程执行请求操作</p>\n<p>4、IO 线程回写 Socket 和主线程清空全局队列</p>\n<p>相关配置：</p>\n<pre><code>io-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数</code></pre><h2 id=\"服务端协助的客户端缓存（Tracking）\"><a href=\"#服务端协助的客户端缓存（Tracking）\" class=\"headerlink\" title=\"服务端协助的客户端缓存（Tracking）\"></a>服务端协助的客户端缓存（Tracking）</h2><p><strong>问题</strong></p>\n<p>如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。</p>\n<h3 id=\"普通模式\"><a href=\"#普通模式\" class=\"headerlink\" title=\"普通模式\"></a>普通模式</h3><p>实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。</p>\n<p>服务端对于记录的 key 只会报告一次 invalidate 消息</p>\n<p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息</p>\n<p><strong>设置命令</strong></p>\n<pre><code>CLIENT TRACKING ON|OFF</code></pre><h3 id=\"广播模式\"><a href=\"#广播模式\" class=\"headerlink\" title=\"广播模式\"></a>广播模式</h3><p>服务端会给客户端广播所有 key 的失效情况，不过，这样做了之后，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p>\n<p><strong>应用场景</strong></p>\n<p>我们会让客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。</p>\n<p><strong>区别</strong>：</p>\n<p>在广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。</p>\n<h2 id=\"细粒度的权限控制\"><a href=\"#细粒度的权限控制\" class=\"headerlink\" title=\"细粒度的权限控制\"></a>细粒度的权限控制</h2><p>1、支持创建不同用户来使用 Redis</p>\n<pre><code>ACL SETUSER normaluser on &gt; abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” </code></pre><p>2、支持以用户为粒度设置命令操作的访问权限</p>\n<p><img src=\"acl_cmd.jpg\" alt=\"acl_cmd\"></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><p><strong>问题</strong></p>\n<p>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p>\n<p><strong>优化</strong></p>\n<p>多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p>\n<p><strong>具体流程</strong></p>\n<p>1、服务端和客户端建立 Socket 连接，并分配处理线程</p>\n<p>2、IO 线程读取并解析请求</p>\n<p>3、主线程执行请求操作</p>\n<p>4、IO 线程回写 Socket 和主线程清空全局队列</p>\n<p>相关配置：</p>\n<pre><code>io-threads-do-reads yes #启用多线程\nio-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数</code></pre><h2 id=\"服务端协助的客户端缓存（Tracking）\"><a href=\"#服务端协助的客户端缓存（Tracking）\" class=\"headerlink\" title=\"服务端协助的客户端缓存（Tracking）\"></a>服务端协助的客户端缓存（Tracking）</h2><p><strong>问题</strong></p>\n<p>如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。</p>\n<h3 id=\"普通模式\"><a href=\"#普通模式\" class=\"headerlink\" title=\"普通模式\"></a>普通模式</h3><p>实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。</p>\n<p>服务端对于记录的 key 只会报告一次 invalidate 消息</p>\n<p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息</p>\n<p><strong>设置命令</strong></p>\n<pre><code>CLIENT TRACKING ON|OFF</code></pre><h3 id=\"广播模式\"><a href=\"#广播模式\" class=\"headerlink\" title=\"广播模式\"></a>广播模式</h3><p>服务端会给客户端广播所有 key 的失效情况，不过，这样做了之后，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p>\n<p><strong>应用场景</strong></p>\n<p>我们会让客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。</p>\n<p><strong>区别</strong>：</p>\n<p>在广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。</p>\n<h2 id=\"细粒度的权限控制\"><a href=\"#细粒度的权限控制\" class=\"headerlink\" title=\"细粒度的权限控制\"></a>细粒度的权限控制</h2><p>1、支持创建不同用户来使用 Redis</p>\n<pre><code>ACL SETUSER normaluser on &gt; abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” </code></pre><p>2、支持以用户为粒度设置命令操作的访问权限</p>\n<p><img src=\"acl_cmd.jpg\" alt=\"acl_cmd\"></p>\n"},{"title":"redis事务","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-11-01T05:28:57.000Z","password":null,"summary":null,"_content":"\n## 事务实现\n\n### 基本命令\n\n- MULTI\n\n显式地表示一个事务的开启，把这些命令暂存到一个命令队列中\n\n- EXEC \n\n实际执行命令队列中的所有命令\n\n- DISCARD\n\n主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）\n\n- WATCH\n\n在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。\n\n### 异常分析\n\n1、客户端发送的操作命令中存在语法错误\n\n拒绝执行所有提交的命令操作，返回事务失败\n\n2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误\n\nRedis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）\n\n3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败\n\n- 如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。\n\n使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。\n\n- 如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。","source":"_posts/redis事务.md","raw":"---\ntitle: redis事务\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-11-01 13:28:57\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 事务实现\n\n### 基本命令\n\n- MULTI\n\n显式地表示一个事务的开启，把这些命令暂存到一个命令队列中\n\n- EXEC \n\n实际执行命令队列中的所有命令\n\n- DISCARD\n\n主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）\n\n- WATCH\n\n在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。\n\n### 异常分析\n\n1、客户端发送的操作命令中存在语法错误\n\n拒绝执行所有提交的命令操作，返回事务失败\n\n2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误\n\nRedis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）\n\n3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败\n\n- 如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。\n\n使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。\n\n- 如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。","slug":"redis事务","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxjk003hncufbbalas4u","content":"<h2 id=\"事务实现\"><a href=\"#事务实现\" class=\"headerlink\" title=\"事务实现\"></a>事务实现</h2><h3 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h3><ul>\n<li>MULTI</li>\n</ul>\n<p>显式地表示一个事务的开启，把这些命令暂存到一个命令队列中</p>\n<ul>\n<li>EXEC </li>\n</ul>\n<p>实际执行命令队列中的所有命令</p>\n<ul>\n<li>DISCARD</li>\n</ul>\n<p>主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）</p>\n<ul>\n<li>WATCH</li>\n</ul>\n<p>在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。</p>\n<h3 id=\"异常分析\"><a href=\"#异常分析\" class=\"headerlink\" title=\"异常分析\"></a>异常分析</h3><p>1、客户端发送的操作命令中存在语法错误</p>\n<p>拒绝执行所有提交的命令操作，返回事务失败</p>\n<p>2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误</p>\n<p>Redis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）</p>\n<p>3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败</p>\n<ul>\n<li>如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。</li>\n</ul>\n<p>使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。</p>\n<ul>\n<li>如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"事务实现\"><a href=\"#事务实现\" class=\"headerlink\" title=\"事务实现\"></a>事务实现</h2><h3 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h3><ul>\n<li>MULTI</li>\n</ul>\n<p>显式地表示一个事务的开启，把这些命令暂存到一个命令队列中</p>\n<ul>\n<li>EXEC </li>\n</ul>\n<p>实际执行命令队列中的所有命令</p>\n<ul>\n<li>DISCARD</li>\n</ul>\n<p>主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）</p>\n<ul>\n<li>WATCH</li>\n</ul>\n<p>在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。</p>\n<h3 id=\"异常分析\"><a href=\"#异常分析\" class=\"headerlink\" title=\"异常分析\"></a>异常分析</h3><p>1、客户端发送的操作命令中存在语法错误</p>\n<p>拒绝执行所有提交的命令操作，返回事务失败</p>\n<p>2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误</p>\n<p>Redis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）</p>\n<p>3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败</p>\n<ul>\n<li>如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。</li>\n</ul>\n<p>使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。</p>\n<ul>\n<li>如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。</li>\n</ul>\n"},{"title":"redis内存碎片","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-11-02T13:35:08.000Z","password":null,"summary":null,"_content":"","source":"_posts/redis内存碎片.md","raw":"---\ntitle: redis内存碎片\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-11-02 21:35:08\npassword:\nsummary:\ntags:\ncategories:\n---\n","slug":"redis内存碎片","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxjm003kncuf94sekoy5","content":"","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":""},{"title":"redis切片集群","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T12:32:35.000Z","password":null,"summary":null,"_content":"\n## 问题\n\n RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。\n\n## 切片集群机制\n\n- 一个切片集群共有 16384 个哈希槽，哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。\n- 映射方法：按照CRC16 算法计算一个 16 bit 的值；再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽\n- Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。\n- 客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端\n\n## 难点\n\n- 集群实例有新增或删除，Redis 需要重新分配哈希槽；\n- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。\n\n## 解决方法\n\n**重定向机制**，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。\n\n注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。","source":"_posts/redis切片集群.md","raw":"---\ntitle: redis切片集群\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 20:32:35\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 问题\n\n RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。\n\n## 切片集群机制\n\n- 一个切片集群共有 16384 个哈希槽，哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。\n- 映射方法：按照CRC16 算法计算一个 16 bit 的值；再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽\n- Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。\n- 客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端\n\n## 难点\n\n- 集群实例有新增或删除，Redis 需要重新分配哈希槽；\n- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。\n\n## 解决方法\n\n**重定向机制**，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。\n\n注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。","slug":"redis切片集群","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxjp003nncufst3p9i7i","content":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p> RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p>\n<h2 id=\"切片集群机制\"><a href=\"#切片集群机制\" class=\"headerlink\" title=\"切片集群机制\"></a>切片集群机制</h2><ul>\n<li>一个切片集群共有 16384 个哈希槽，哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</li>\n<li>映射方法：按照CRC16 算法计算一个 16 bit 的值；再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽</li>\n<li>Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。</li>\n<li>客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端</li>\n</ul>\n<h2 id=\"难点\"><a href=\"#难点\" class=\"headerlink\" title=\"难点\"></a>难点</h2><ul>\n<li>集群实例有新增或删除，Redis 需要重新分配哈希槽；</li>\n<li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li>\n</ul>\n<h2 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h2><p><strong>重定向机制</strong>，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。</p>\n<p>注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p> RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p>\n<h2 id=\"切片集群机制\"><a href=\"#切片集群机制\" class=\"headerlink\" title=\"切片集群机制\"></a>切片集群机制</h2><ul>\n<li>一个切片集群共有 16384 个哈希槽，哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</li>\n<li>映射方法：按照CRC16 算法计算一个 16 bit 的值；再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽</li>\n<li>Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。</li>\n<li>客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端</li>\n</ul>\n<h2 id=\"难点\"><a href=\"#难点\" class=\"headerlink\" title=\"难点\"></a>难点</h2><ul>\n<li>集群实例有新增或删除，Redis 需要重新分配哈希槽；</li>\n<li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li>\n</ul>\n<h2 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h2><p><strong>重定向机制</strong>，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。</p>\n<p>注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。</p>\n"},{"title":"redis主从同步","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-25T08:30:01.000Z","password":null,"summary":null,"_content":"\n[toc]\n\n主从库之间采用读写分离。\n读操作：主库、从库都可以接收；\n写操作：首先到主库执行，然后，主库将写操作同步给从库。\n![读写分离](duxiefenli.jpg)\n\n## CAP\n\nC - Consistent ，一致性\nA - Availability ，可用性\nP - Partition tolerance ，分区容忍性\n\n在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。\n\n一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。\n\n## 同步机制\n\n通过 `replicaof`（Redis 5.0 之前使用 `slaveof`）命令形成主库和从库的关系。\n\n1、主从库间建立连接、协商同步，为全量复制做准备。\n**从库和主库建立起连接，发送 psync 命令**，表示要进行数据同步，**主库确认回复**，FULLRESYNC响应表示第一次复制采用的全量复制。\npsync 命令包含了主库的 runID 和复制进度 offset 两个参数。\n\n2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。\n主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。\n从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。\n\n3、主库会把第二阶段执行过程中新收到的写命令(replication buffer中的修改操作)，再发送给从库。\n主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。\n\n![主从第一次同步](zhucongtongbu.jpg)\n\n### 无盘复制\n\n主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。\n所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。\n\n## 主从级联\n\n### 问题\n\n- 从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。\n\n- 传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。\n\n### 解决\n\n通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上\n\n![级联的“主-从-从”模式](master_slave_slave.jpg)\n\n\n\n## 网络闪断\n\n网络闪断后，主从库会采用增量复制的方式继续同步。\n\n### 增量复制机制\n\n- 主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区\n\n- repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。\n- 连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。\n- 库还未读取的操作被主库新写的操作覆盖，需要全量复制\n\n### 应对\n\n- repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了\n\n- 使用切片集群来分担单个主库的请求压力\n\n## 主从数据不一致\n\n根本原因：主从库间的命令复制是异步进行的\n\n直接原因：\n\n- 主从库间的网络可能会有传输延迟\n- 处理其它复杂度高的命令（例如集合操作命令）而阻塞同步\n- 主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致\n\n解决方法\n\n- 尽量保证主从库间的网络连接状况良好\n- 外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接\n\n## 读取数据过期\n\n### 过期策略\n\n定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；\n\n**惰性删除策略**：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。**在 3.2 版本后**，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。\n\n### 过期命令\n\n- EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；\n- **EXPIREAT 和 PEXPIREA**：它们会直接把数据的过期时间设置为具体的一个时间点\n\n当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在**当前时间的基础上加上数据的存活时间**，从库上数据的过期时间就会比主库上延后了\n\n### 解决\n\n- 使用 Redis 3.2 及以上版本和惰性删除策略\n- 在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据\n\n### 同步异常\n\n`protected-mode`：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。\n\n`cluster-node-timeout`:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。\n\n## 其他\n\n`slave-serve-stale-data `: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。\n\n`slave-read-only `：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。\n\n","source":"_posts/redis主从同步.md","raw":"---\ntitle: redis主从同步\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-25 16:30:01\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n[toc]\n\n主从库之间采用读写分离。\n读操作：主库、从库都可以接收；\n写操作：首先到主库执行，然后，主库将写操作同步给从库。\n![读写分离](duxiefenli.jpg)\n\n## CAP\n\nC - Consistent ，一致性\nA - Availability ，可用性\nP - Partition tolerance ，分区容忍性\n\n在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。\n\n一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。\n\n## 同步机制\n\n通过 `replicaof`（Redis 5.0 之前使用 `slaveof`）命令形成主库和从库的关系。\n\n1、主从库间建立连接、协商同步，为全量复制做准备。\n**从库和主库建立起连接，发送 psync 命令**，表示要进行数据同步，**主库确认回复**，FULLRESYNC响应表示第一次复制采用的全量复制。\npsync 命令包含了主库的 runID 和复制进度 offset 两个参数。\n\n2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。\n主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。\n从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。\n\n3、主库会把第二阶段执行过程中新收到的写命令(replication buffer中的修改操作)，再发送给从库。\n主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。\n\n![主从第一次同步](zhucongtongbu.jpg)\n\n### 无盘复制\n\n主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。\n所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。\n\n## 主从级联\n\n### 问题\n\n- 从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。\n\n- 传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。\n\n### 解决\n\n通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上\n\n![级联的“主-从-从”模式](master_slave_slave.jpg)\n\n\n\n## 网络闪断\n\n网络闪断后，主从库会采用增量复制的方式继续同步。\n\n### 增量复制机制\n\n- 主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区\n\n- repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。\n- 连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。\n- 库还未读取的操作被主库新写的操作覆盖，需要全量复制\n\n### 应对\n\n- repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了\n\n- 使用切片集群来分担单个主库的请求压力\n\n## 主从数据不一致\n\n根本原因：主从库间的命令复制是异步进行的\n\n直接原因：\n\n- 主从库间的网络可能会有传输延迟\n- 处理其它复杂度高的命令（例如集合操作命令）而阻塞同步\n- 主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致\n\n解决方法\n\n- 尽量保证主从库间的网络连接状况良好\n- 外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接\n\n## 读取数据过期\n\n### 过期策略\n\n定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；\n\n**惰性删除策略**：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。**在 3.2 版本后**，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。\n\n### 过期命令\n\n- EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；\n- **EXPIREAT 和 PEXPIREA**：它们会直接把数据的过期时间设置为具体的一个时间点\n\n当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在**当前时间的基础上加上数据的存活时间**，从库上数据的过期时间就会比主库上延后了\n\n### 解决\n\n- 使用 Redis 3.2 及以上版本和惰性删除策略\n- 在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据\n\n### 同步异常\n\n`protected-mode`：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。\n\n`cluster-node-timeout`:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。\n\n## 其他\n\n`slave-serve-stale-data `: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。\n\n`slave-read-only `：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。\n\n","slug":"redis主从同步","published":1,"updated":"2021-04-01T23:01:50.016Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxjt003qncufsd51ya48","content":"<p>[toc]</p>\n<p>主从库之间采用读写分离。<br>读操作：主库、从库都可以接收；<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。<br><img src=\"duxiefenli.jpg\" alt=\"读写分离\"></p>\n<h2 id=\"CAP\"><a href=\"#CAP\" class=\"headerlink\" title=\"CAP\"></a>CAP</h2><p>C - Consistent ，一致性<br>A - Availability ，可用性<br>P - Partition tolerance ，分区容忍性</p>\n<p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。</p>\n<p>一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。</p>\n<h2 id=\"同步机制\"><a href=\"#同步机制\" class=\"headerlink\" title=\"同步机制\"></a>同步机制</h2><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系。</p>\n<p>1、主从库间建立连接、协商同步，为全量复制做准备。<br><strong>从库和主库建立起连接，发送 psync 命令</strong>，表示要进行数据同步，<strong>主库确认回复</strong>，FULLRESYNC响应表示第一次复制采用的全量复制。<br>psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p>\n<p>2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。<br>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。<br>从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。</p>\n<p>3、主库会把第二阶段执行过程中新收到的写命令(replication buffer中的修改操作)，再发送给从库。<br>主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p>\n<p><img src=\"zhucongtongbu.jpg\" alt=\"主从第一次同步\"></p>\n<h3 id=\"无盘复制\"><a href=\"#无盘复制\" class=\"headerlink\" title=\"无盘复制\"></a>无盘复制</h3><p>主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。<br>所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。</p>\n<h2 id=\"主从级联\"><a href=\"#主从级联\" class=\"headerlink\" title=\"主从级联\"></a>主从级联</h2><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li><p>从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</p>\n</li>\n<li><p>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。</p>\n</li>\n</ul>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</p>\n<p><img src=\"master_slave_slave.jpg\" alt=\"级联的“主-从-从”模式\"></p>\n<h2 id=\"网络闪断\"><a href=\"#网络闪断\" class=\"headerlink\" title=\"网络闪断\"></a>网络闪断</h2><p>网络闪断后，主从库会采用增量复制的方式继续同步。</p>\n<h3 id=\"增量复制机制\"><a href=\"#增量复制机制\" class=\"headerlink\" title=\"增量复制机制\"></a>增量复制机制</h3><ul>\n<li><p>主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区</p>\n</li>\n<li><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。</p>\n</li>\n<li><p>连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。</p>\n</li>\n<li><p>库还未读取的操作被主库新写的操作覆盖，需要全量复制</p>\n</li>\n</ul>\n<h3 id=\"应对\"><a href=\"#应对\" class=\"headerlink\" title=\"应对\"></a>应对</h3><ul>\n<li><p>repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了</p>\n</li>\n<li><p>使用切片集群来分担单个主库的请求压力</p>\n</li>\n</ul>\n<h2 id=\"主从数据不一致\"><a href=\"#主从数据不一致\" class=\"headerlink\" title=\"主从数据不一致\"></a>主从数据不一致</h2><p>根本原因：主从库间的命令复制是异步进行的</p>\n<p>直接原因：</p>\n<ul>\n<li>主从库间的网络可能会有传输延迟</li>\n<li>处理其它复杂度高的命令（例如集合操作命令）而阻塞同步</li>\n<li>主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致</li>\n</ul>\n<p>解决方法</p>\n<ul>\n<li>尽量保证主从库间的网络连接状况良好</li>\n<li>外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接</li>\n</ul>\n<h2 id=\"读取数据过期\"><a href=\"#读取数据过期\" class=\"headerlink\" title=\"读取数据过期\"></a>读取数据过期</h2><h3 id=\"过期策略\"><a href=\"#过期策略\" class=\"headerlink\" title=\"过期策略\"></a>过期策略</h3><p>定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；</p>\n<p><strong>惰性删除策略</strong>：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。<strong>在 3.2 版本后</strong>，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。</p>\n<h3 id=\"过期命令\"><a href=\"#过期命令\" class=\"headerlink\" title=\"过期命令\"></a>过期命令</h3><ul>\n<li>EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li>\n<li><strong>EXPIREAT 和 PEXPIREA</strong>：它们会直接把数据的过期时间设置为具体的一个时间点</li>\n</ul>\n<p>当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在<strong>当前时间的基础上加上数据的存活时间</strong>，从库上数据的过期时间就会比主库上延后了</p>\n<h3 id=\"解决-1\"><a href=\"#解决-1\" class=\"headerlink\" title=\"解决\"></a>解决</h3><ul>\n<li>使用 Redis 3.2 及以上版本和惰性删除策略</li>\n<li>在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据</li>\n</ul>\n<h3 id=\"同步异常\"><a href=\"#同步异常\" class=\"headerlink\" title=\"同步异常\"></a>同步异常</h3><p><code>protected-mode</code>：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。</p>\n<p><code>cluster-node-timeout</code>:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p><code>slave-serve-stale-data</code>: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。</p>\n<p><code>slave-read-only</code>：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>[toc]</p>\n<p>主从库之间采用读写分离。<br>读操作：主库、从库都可以接收；<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。<br><img src=\"duxiefenli.jpg\" alt=\"读写分离\"></p>\n<h2 id=\"CAP\"><a href=\"#CAP\" class=\"headerlink\" title=\"CAP\"></a>CAP</h2><p>C - Consistent ，一致性<br>A - Availability ，可用性<br>P - Partition tolerance ，分区容忍性</p>\n<p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。</p>\n<p>一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。</p>\n<h2 id=\"同步机制\"><a href=\"#同步机制\" class=\"headerlink\" title=\"同步机制\"></a>同步机制</h2><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系。</p>\n<p>1、主从库间建立连接、协商同步，为全量复制做准备。<br><strong>从库和主库建立起连接，发送 psync 命令</strong>，表示要进行数据同步，<strong>主库确认回复</strong>，FULLRESYNC响应表示第一次复制采用的全量复制。<br>psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p>\n<p>2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。<br>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。<br>从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。</p>\n<p>3、主库会把第二阶段执行过程中新收到的写命令(replication buffer中的修改操作)，再发送给从库。<br>主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p>\n<p><img src=\"zhucongtongbu.jpg\" alt=\"主从第一次同步\"></p>\n<h3 id=\"无盘复制\"><a href=\"#无盘复制\" class=\"headerlink\" title=\"无盘复制\"></a>无盘复制</h3><p>主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。<br>所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。</p>\n<h2 id=\"主从级联\"><a href=\"#主从级联\" class=\"headerlink\" title=\"主从级联\"></a>主从级联</h2><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li><p>从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</p>\n</li>\n<li><p>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。</p>\n</li>\n</ul>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</p>\n<p><img src=\"master_slave_slave.jpg\" alt=\"级联的“主-从-从”模式\"></p>\n<h2 id=\"网络闪断\"><a href=\"#网络闪断\" class=\"headerlink\" title=\"网络闪断\"></a>网络闪断</h2><p>网络闪断后，主从库会采用增量复制的方式继续同步。</p>\n<h3 id=\"增量复制机制\"><a href=\"#增量复制机制\" class=\"headerlink\" title=\"增量复制机制\"></a>增量复制机制</h3><ul>\n<li><p>主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区</p>\n</li>\n<li><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。</p>\n</li>\n<li><p>连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。</p>\n</li>\n<li><p>库还未读取的操作被主库新写的操作覆盖，需要全量复制</p>\n</li>\n</ul>\n<h3 id=\"应对\"><a href=\"#应对\" class=\"headerlink\" title=\"应对\"></a>应对</h3><ul>\n<li><p>repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了</p>\n</li>\n<li><p>使用切片集群来分担单个主库的请求压力</p>\n</li>\n</ul>\n<h2 id=\"主从数据不一致\"><a href=\"#主从数据不一致\" class=\"headerlink\" title=\"主从数据不一致\"></a>主从数据不一致</h2><p>根本原因：主从库间的命令复制是异步进行的</p>\n<p>直接原因：</p>\n<ul>\n<li>主从库间的网络可能会有传输延迟</li>\n<li>处理其它复杂度高的命令（例如集合操作命令）而阻塞同步</li>\n<li>主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致</li>\n</ul>\n<p>解决方法</p>\n<ul>\n<li>尽量保证主从库间的网络连接状况良好</li>\n<li>外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接</li>\n</ul>\n<h2 id=\"读取数据过期\"><a href=\"#读取数据过期\" class=\"headerlink\" title=\"读取数据过期\"></a>读取数据过期</h2><h3 id=\"过期策略\"><a href=\"#过期策略\" class=\"headerlink\" title=\"过期策略\"></a>过期策略</h3><p>定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；</p>\n<p><strong>惰性删除策略</strong>：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。<strong>在 3.2 版本后</strong>，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。</p>\n<h3 id=\"过期命令\"><a href=\"#过期命令\" class=\"headerlink\" title=\"过期命令\"></a>过期命令</h3><ul>\n<li>EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li>\n<li><strong>EXPIREAT 和 PEXPIREA</strong>：它们会直接把数据的过期时间设置为具体的一个时间点</li>\n</ul>\n<p>当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在<strong>当前时间的基础上加上数据的存活时间</strong>，从库上数据的过期时间就会比主库上延后了</p>\n<h3 id=\"解决-1\"><a href=\"#解决-1\" class=\"headerlink\" title=\"解决\"></a>解决</h3><ul>\n<li>使用 Redis 3.2 及以上版本和惰性删除策略</li>\n<li>在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据</li>\n</ul>\n<h3 id=\"同步异常\"><a href=\"#同步异常\" class=\"headerlink\" title=\"同步异常\"></a>同步异常</h3><p><code>protected-mode</code>：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。</p>\n<p><code>cluster-node-timeout</code>:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p><code>slave-serve-stale-data</code>: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。</p>\n<p><code>slave-read-only</code>：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。</p>\n"},{"title":"redis分布式锁","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-29T15:52:36.000Z","password":null,"summary":null,"_content":"\n\n\n为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。\n\n## redis原子操作\n\n- 单命令操作（INCR/DECR）；\n- 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本\n\n## 分布式锁\n\n- 分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；\n\n- 共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。\n\n### 单个 Redis 节点的分布式锁\n\n- **SETNX key value**\n\nkey 不存在， key 会被创建。执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁。\n\n**可能风险：**\n\n  - 操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。\n  - 客户端 A 执行了 SETNX 命令加锁后，客户端 B 执行了 DEL 命令释放锁，客户端 A 的锁就被误释放\n\n+ SET key value [EX seconds | PX milliseconds]  [NX]\n\n### 多个 Redis 节点的高可靠分布式锁\n\n分布式锁算法 Redlock\n\n- 客户端获取当前时间。\n- 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n- 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n\n**加锁成功条件**\n\n- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；\n\n- 客户端获取锁的总耗时没有超过锁的有效时间。","source":"_posts/redis分布式锁.md","raw":"---\ntitle: redis分布式锁\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-29 23:52:36\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n\n\n为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。\n\n## redis原子操作\n\n- 单命令操作（INCR/DECR）；\n- 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本\n\n## 分布式锁\n\n- 分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；\n\n- 共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。\n\n### 单个 Redis 节点的分布式锁\n\n- **SETNX key value**\n\nkey 不存在， key 会被创建。执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁。\n\n**可能风险：**\n\n  - 操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。\n  - 客户端 A 执行了 SETNX 命令加锁后，客户端 B 执行了 DEL 命令释放锁，客户端 A 的锁就被误释放\n\n+ SET key value [EX seconds | PX milliseconds]  [NX]\n\n### 多个 Redis 节点的高可靠分布式锁\n\n分布式锁算法 Redlock\n\n- 客户端获取当前时间。\n- 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n- 一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n\n**加锁成功条件**\n\n- 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；\n\n- 客户端获取锁的总耗时没有超过锁的有效时间。","slug":"redis分布式锁","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxk7003tncufl656glnl","content":"<p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p>\n<h2 id=\"redis原子操作\"><a href=\"#redis原子操作\" class=\"headerlink\" title=\"redis原子操作\"></a>redis原子操作</h2><ul>\n<li>单命令操作（INCR/DECR）；</li>\n<li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本</li>\n</ul>\n<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><ul>\n<li><p>分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；</p>\n</li>\n<li><p>共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。</p>\n</li>\n</ul>\n<h3 id=\"单个-Redis-节点的分布式锁\"><a href=\"#单个-Redis-节点的分布式锁\" class=\"headerlink\" title=\"单个 Redis 节点的分布式锁\"></a>单个 Redis 节点的分布式锁</h3><ul>\n<li><strong>SETNX key value</strong></li>\n</ul>\n<p>key 不存在， key 会被创建。执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁。</p>\n<p><strong>可能风险：</strong></p>\n<ul>\n<li>操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</li>\n<li>客户端 A 执行了 SETNX 命令加锁后，客户端 B 执行了 DEL 命令释放锁，客户端 A 的锁就被误释放</li>\n</ul>\n<ul>\n<li>SET key value [EX seconds | PX milliseconds]  [NX]</li>\n</ul>\n<h3 id=\"多个-Redis-节点的高可靠分布式锁\"><a href=\"#多个-Redis-节点的高可靠分布式锁\" class=\"headerlink\" title=\"多个 Redis 节点的高可靠分布式锁\"></a>多个 Redis 节点的高可靠分布式锁</h3><p>分布式锁算法 Redlock</p>\n<ul>\n<li>客户端获取当前时间。</li>\n<li>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</li>\n<li>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</li>\n</ul>\n<p><strong>加锁成功条件</strong></p>\n<ul>\n<li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；</p>\n</li>\n<li><p>客户端获取锁的总耗时没有超过锁的有效时间。</p>\n</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p>\n<h2 id=\"redis原子操作\"><a href=\"#redis原子操作\" class=\"headerlink\" title=\"redis原子操作\"></a>redis原子操作</h2><ul>\n<li>单命令操作（INCR/DECR）；</li>\n<li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本</li>\n</ul>\n<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><ul>\n<li><p>分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；</p>\n</li>\n<li><p>共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。</p>\n</li>\n</ul>\n<h3 id=\"单个-Redis-节点的分布式锁\"><a href=\"#单个-Redis-节点的分布式锁\" class=\"headerlink\" title=\"单个 Redis 节点的分布式锁\"></a>单个 Redis 节点的分布式锁</h3><ul>\n<li><strong>SETNX key value</strong></li>\n</ul>\n<p>key 不存在， key 会被创建。执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁。</p>\n<p><strong>可能风险：</strong></p>\n<ul>\n<li>操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</li>\n<li>客户端 A 执行了 SETNX 命令加锁后，客户端 B 执行了 DEL 命令释放锁，客户端 A 的锁就被误释放</li>\n</ul>\n<ul>\n<li>SET key value [EX seconds | PX milliseconds]  [NX]</li>\n</ul>\n<h3 id=\"多个-Redis-节点的高可靠分布式锁\"><a href=\"#多个-Redis-节点的高可靠分布式锁\" class=\"headerlink\" title=\"多个 Redis 节点的高可靠分布式锁\"></a>多个 Redis 节点的高可靠分布式锁</h3><p>分布式锁算法 Redlock</p>\n<ul>\n<li>客户端获取当前时间。</li>\n<li>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</li>\n<li>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</li>\n</ul>\n<p><strong>加锁成功条件</strong></p>\n<ul>\n<li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；</p>\n</li>\n<li><p>客户端获取锁的总耗时没有超过锁的有效时间。</p>\n</li>\n</ul>\n"},{"title":"redis哨兵机制","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-25T13:16:39.000Z","password":null,"summary":null,"_content":"\n## 问题\n\n主库故障的相关问题：\n\n1、确定主库故障\n\n2、选择新的主库\n\n3、新主库信息通知\n\n## 基本功能\n\n### 监控\n\n- 哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。\n\n- 主库或从库对 PING 命令的响应超时了，哨兵会标记为“主观下线”。\n\n- 需有quorum 个实例判断主库为“主观下线”，才能判定主库为“客观下线”\n\n### 选主\n\n- 筛选当前在线从库，且网络连接状况较好；\n\n- 选择从库优先级最高的从库\n\n- 选择从库复制进度最快的\n\n- 选择从库 ID 号小的\n\n### 通知\n\n- 通知从库执行replicaof，与新主库同步\n- 通知客户端，像新主库请求\n\n**通知客户端**的实现方法\n\n1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。\n\n2、客户端需要支持主动去获取最新主从的地址进行访问。\n\n## 哨兵集群pub/sub\n\n**连接关系的实现**\n\n- 哨兵-哨兵：哨兵订阅主库上的“__sentinel__:hello”，实现哨兵连接信息的发布获取\n- 哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库\n- 哨兵-客户端：客户端订阅哨兵消息\n\n\n**哨兵Leader竞选 （总从切换）**\n\n1、拿到半数以上的赞成票；\n\n2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。","source":"_posts/redis哨兵机制.md","raw":"---\ntitle: redis哨兵机制\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-25 21:16:39\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 问题\n\n主库故障的相关问题：\n\n1、确定主库故障\n\n2、选择新的主库\n\n3、新主库信息通知\n\n## 基本功能\n\n### 监控\n\n- 哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。\n\n- 主库或从库对 PING 命令的响应超时了，哨兵会标记为“主观下线”。\n\n- 需有quorum 个实例判断主库为“主观下线”，才能判定主库为“客观下线”\n\n### 选主\n\n- 筛选当前在线从库，且网络连接状况较好；\n\n- 选择从库优先级最高的从库\n\n- 选择从库复制进度最快的\n\n- 选择从库 ID 号小的\n\n### 通知\n\n- 通知从库执行replicaof，与新主库同步\n- 通知客户端，像新主库请求\n\n**通知客户端**的实现方法\n\n1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。\n\n2、客户端需要支持主动去获取最新主从的地址进行访问。\n\n## 哨兵集群pub/sub\n\n**连接关系的实现**\n\n- 哨兵-哨兵：哨兵订阅主库上的“__sentinel__:hello”，实现哨兵连接信息的发布获取\n- 哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库\n- 哨兵-客户端：客户端订阅哨兵消息\n\n\n**哨兵Leader竞选 （总从切换）**\n\n1、拿到半数以上的赞成票；\n\n2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。","slug":"redis哨兵机制","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxkb003wncufffzf1l3c","content":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>主库故障的相关问题：</p>\n<p>1、确定主库故障</p>\n<p>2、选择新的主库</p>\n<p>3、新主库信息通知</p>\n<h2 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h2><h3 id=\"监控\"><a href=\"#监控\" class=\"headerlink\" title=\"监控\"></a>监控</h3><ul>\n<li><p>哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</p>\n</li>\n<li><p>主库或从库对 PING 命令的响应超时了，哨兵会标记为“主观下线”。</p>\n</li>\n<li><p>需有quorum 个实例判断主库为“主观下线”，才能判定主库为“客观下线”</p>\n</li>\n</ul>\n<h3 id=\"选主\"><a href=\"#选主\" class=\"headerlink\" title=\"选主\"></a>选主</h3><ul>\n<li><p>筛选当前在线从库，且网络连接状况较好；</p>\n</li>\n<li><p>选择从库优先级最高的从库</p>\n</li>\n<li><p>选择从库复制进度最快的</p>\n</li>\n<li><p>选择从库 ID 号小的</p>\n</li>\n</ul>\n<h3 id=\"通知\"><a href=\"#通知\" class=\"headerlink\" title=\"通知\"></a>通知</h3><ul>\n<li>通知从库执行replicaof，与新主库同步</li>\n<li>通知客户端，像新主库请求</li>\n</ul>\n<p><strong>通知客户端</strong>的实现方法</p>\n<p>1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。</p>\n<p>2、客户端需要支持主动去获取最新主从的地址进行访问。</p>\n<h2 id=\"哨兵集群pub-sub\"><a href=\"#哨兵集群pub-sub\" class=\"headerlink\" title=\"哨兵集群pub/sub\"></a>哨兵集群pub/sub</h2><p><strong>连接关系的实现</strong></p>\n<ul>\n<li>哨兵-哨兵：哨兵订阅主库上的“<strong>sentinel</strong>:hello”，实现哨兵连接信息的发布获取</li>\n<li>哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库</li>\n<li>哨兵-客户端：客户端订阅哨兵消息</li>\n</ul>\n<p><strong>哨兵Leader竞选 （总从切换）</strong></p>\n<p>1、拿到半数以上的赞成票；</p>\n<p>2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>主库故障的相关问题：</p>\n<p>1、确定主库故障</p>\n<p>2、选择新的主库</p>\n<p>3、新主库信息通知</p>\n<h2 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h2><h3 id=\"监控\"><a href=\"#监控\" class=\"headerlink\" title=\"监控\"></a>监控</h3><ul>\n<li><p>哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</p>\n</li>\n<li><p>主库或从库对 PING 命令的响应超时了，哨兵会标记为“主观下线”。</p>\n</li>\n<li><p>需有quorum 个实例判断主库为“主观下线”，才能判定主库为“客观下线”</p>\n</li>\n</ul>\n<h3 id=\"选主\"><a href=\"#选主\" class=\"headerlink\" title=\"选主\"></a>选主</h3><ul>\n<li><p>筛选当前在线从库，且网络连接状况较好；</p>\n</li>\n<li><p>选择从库优先级最高的从库</p>\n</li>\n<li><p>选择从库复制进度最快的</p>\n</li>\n<li><p>选择从库 ID 号小的</p>\n</li>\n</ul>\n<h3 id=\"通知\"><a href=\"#通知\" class=\"headerlink\" title=\"通知\"></a>通知</h3><ul>\n<li>通知从库执行replicaof，与新主库同步</li>\n<li>通知客户端，像新主库请求</li>\n</ul>\n<p><strong>通知客户端</strong>的实现方法</p>\n<p>1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。</p>\n<p>2、客户端需要支持主动去获取最新主从的地址进行访问。</p>\n<h2 id=\"哨兵集群pub-sub\"><a href=\"#哨兵集群pub-sub\" class=\"headerlink\" title=\"哨兵集群pub/sub\"></a>哨兵集群pub/sub</h2><p><strong>连接关系的实现</strong></p>\n<ul>\n<li>哨兵-哨兵：哨兵订阅主库上的“<strong>sentinel</strong>:hello”，实现哨兵连接信息的发布获取</li>\n<li>哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库</li>\n<li>哨兵-客户端：客户端订阅哨兵消息</li>\n</ul>\n<p><strong>哨兵Leader竞选 （总从切换）</strong></p>\n<p>1、拿到半数以上的赞成票；</p>\n<p>2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。</p>\n"},{"title":"redis变慢以及优化方法","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:42:19.000Z","password":null,"summary":null,"_content":"\n## 确定问题\n\n1、查看 Redis 的响应延迟。\n2、基于当前环境下的 Redis 基线性能做判断\n基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。\n\n\n## 问题定位\n\n1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。\n2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）\n3、检查是否使用了慢查询命令，KEYS *xxx\n\n\n## 优化\n1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。\n1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。\n\n2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数\n\n3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。","source":"_posts/redis变慢以及优化方法.md","raw":"---\ntitle: redis变慢以及优化方法\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:42:19\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 确定问题\n\n1、查看 Redis 的响应延迟。\n2、基于当前环境下的 Redis 基线性能做判断\n基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。\n\n\n## 问题定位\n\n1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。\n2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）\n3、检查是否使用了慢查询命令，KEYS *xxx\n\n\n## 优化\n1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。\n1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。\n\n2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数\n\n3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。","slug":"redis变慢以及优化方法","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxkf003zncufncrh6eud","content":"<h2 id=\"确定问题\"><a href=\"#确定问题\" class=\"headerlink\" title=\"确定问题\"></a>确定问题</h2><p>1、查看 Redis 的响应延迟。<br>2、基于当前环境下的 Redis 基线性能做判断<br>基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。</p>\n<h2 id=\"问题定位\"><a href=\"#问题定位\" class=\"headerlink\" title=\"问题定位\"></a>问题定位</h2><p>1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。<br>2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>3、检查是否使用了慢查询命令，KEYS *xxx</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。<br>1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p>\n<p>2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数</p>\n<p>3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"确定问题\"><a href=\"#确定问题\" class=\"headerlink\" title=\"确定问题\"></a>确定问题</h2><p>1、查看 Redis 的响应延迟。<br>2、基于当前环境下的 Redis 基线性能做判断<br>基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。</p>\n<h2 id=\"问题定位\"><a href=\"#问题定位\" class=\"headerlink\" title=\"问题定位\"></a>问题定位</h2><p>1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。<br>2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>3、检查是否使用了慢查询命令，KEYS *xxx</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。<br>1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p>\n<p>2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数</p>\n<p>3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。</p>\n"},{"title":"redis思维导图","top":true,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-08T00:06:00.000Z","password":null,"summary":"博客中redis相关思维导图。","_content":"\n![思维导图](redis.png)","source":"_posts/redis思维导图.md","raw":"---\ntitle: redis思维导图\ntop: true\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-08 08:06:00\npassword:\nsummary: 博客中redis相关思维导图。\ntags:\n- redis\ncategories:\n- redis\n---\n\n![思维导图](redis.png)","slug":"redis思维导图","published":1,"updated":"2021-04-02T13:22:25.489Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxki0042ncufn7i04ny0","content":"<p><img src=\"redis.png\" alt=\"思维导图\"></p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p><img src=\"redis.png\" alt=\"思维导图\"></p>\n"},{"title":"redis数据结构","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:44:02.000Z","password":null,"summary":null,"_content":"\n\n\n基本数据结构包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）\n\n| 基本数据结构 | 底层实现           |\n| ------------ | ------------------ |\n| string       | 动态字符串         |\n| List         | 双向链表、压缩列表 |\n| Hash         | 哈希表，压缩列表   |\n| Sorted Set   | 跳表，压缩列表     |\n| Set          | 哈希表、数组       |\n\nredis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。\n哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n冲突增多时，Redis 会对哈希表做渐进式 rehash操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries\n\n## RedisObject\n\n```c\nstruct RedisObject {\n    int4 type; // 4bits\n    int4 encoding; // 4bits\n    int24 lru; // 24bits\n    int32 refcount; // 4bytes\n    void *ptr; // 8bytes，64-bit system\n} robj;\n```\n\n不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr 指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。\n\n## 字符串\n\nRedis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。\n\n```c\nstruct SDS<T> {\n    T capacity; // 数组容量\n    T len; // 数组长度\n    byte flags; // 特殊标识位，不理睬它\n    byte[] content; // 数组内容\n}\n\nstruct SDS {\n    int8 capacity; // 1byte\n    int8 len; // 1byte\n    int8 flags; // 1byte\n    byte[] content; // 内联数组，长度为 capacity\n}\n```\n\nembstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。\n\n### 扩容策略\n\n字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。\n\n## 字典\n\n除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。\n\ndict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。\n\n```c\nstruct dict {\n    ...\n    dictht ht[2];\n}\nstruct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}\n```\n\nhashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。\n\n### 渐进式rehash\n\n大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis表示很难承受这样耗时的过程。\n\nRedis还会在定时任务中对字典进行主动搬迁。\n\n### 扩容条件\n\n当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。\n\n\n\n## 压缩列表\n压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。\n\n压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。\n\n```c\nstruct ziplist<T> {\n    int32 zlbytes; // 整个压缩列表占用字节数\n    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点\n    int16 zllength; // 元素个数\n    T[] entries; // 元素内容列表，挨个挨个紧凑存储\n    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF\n}\nstruct entry {\n    int<var> prevlen; // 前一个 entry 的字节长度\n    int<var> encoding; // 元素类型编码\n    optional byte[] content; // 元素内容\n}\n```\n\n\n\n## 跳表\n跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。\n\n## 复杂度\n\n各个数据结构的查找时间复杂度\n| 数据结构 | 复杂度  |\n| -------- | ------- |\n| 哈希表   | O(1)    |\n| 跳表     | O(logN) |\n| 双向链表 | O(N)    |\n| 压缩列表 | O(N)    |\n| 数组     | O(N)    |","source":"_posts/redis数据结构.md","raw":"---\ntitle: redis数据结构\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:44:02\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n\n\n基本数据结构包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）\n\n| 基本数据结构 | 底层实现           |\n| ------------ | ------------------ |\n| string       | 动态字符串         |\n| List         | 双向链表、压缩列表 |\n| Hash         | 哈希表，压缩列表   |\n| Sorted Set   | 跳表，压缩列表     |\n| Set          | 哈希表、数组       |\n\nredis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。\n哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n冲突增多时，Redis 会对哈希表做渐进式 rehash操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries\n\n## RedisObject\n\n```c\nstruct RedisObject {\n    int4 type; // 4bits\n    int4 encoding; // 4bits\n    int24 lru; // 24bits\n    int32 refcount; // 4bytes\n    void *ptr; // 8bytes，64-bit system\n} robj;\n```\n\n不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr 指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。\n\n## 字符串\n\nRedis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。\n\n```c\nstruct SDS<T> {\n    T capacity; // 数组容量\n    T len; // 数组长度\n    byte flags; // 特殊标识位，不理睬它\n    byte[] content; // 数组内容\n}\n\nstruct SDS {\n    int8 capacity; // 1byte\n    int8 len; // 1byte\n    int8 flags; // 1byte\n    byte[] content; // 内联数组，长度为 capacity\n}\n```\n\nembstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。\n\n### 扩容策略\n\n字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。\n\n## 字典\n\n除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。\n\ndict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。\n\n```c\nstruct dict {\n    ...\n    dictht ht[2];\n}\nstruct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}\n```\n\nhashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。\n\n### 渐进式rehash\n\n大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis表示很难承受这样耗时的过程。\n\nRedis还会在定时任务中对字典进行主动搬迁。\n\n### 扩容条件\n\n当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。\n\n\n\n## 压缩列表\n压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。\n\n压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。\n\n```c\nstruct ziplist<T> {\n    int32 zlbytes; // 整个压缩列表占用字节数\n    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点\n    int16 zllength; // 元素个数\n    T[] entries; // 元素内容列表，挨个挨个紧凑存储\n    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF\n}\nstruct entry {\n    int<var> prevlen; // 前一个 entry 的字节长度\n    int<var> encoding; // 元素类型编码\n    optional byte[] content; // 元素内容\n}\n```\n\n\n\n## 跳表\n跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。\n\n## 复杂度\n\n各个数据结构的查找时间复杂度\n| 数据结构 | 复杂度  |\n| -------- | ------- |\n| 哈希表   | O(1)    |\n| 跳表     | O(logN) |\n| 双向链表 | O(N)    |\n| 压缩列表 | O(N)    |\n| 数组     | O(N)    |","slug":"redis数据结构","published":1,"updated":"2021-04-01T23:01:50.077Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxkn0045ncufpusffnb8","content":"<p>基本数据结构包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）</p>\n<table>\n<thead>\n<tr>\n<th>基本数据结构</th>\n<th>底层实现</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>string</td>\n<td>动态字符串</td>\n</tr>\n<tr>\n<td>List</td>\n<td>双向链表、压缩列表</td>\n</tr>\n<tr>\n<td>Hash</td>\n<td>哈希表，压缩列表</td>\n</tr>\n<tr>\n<td>Sorted Set</td>\n<td>跳表，压缩列表</td>\n</tr>\n<tr>\n<td>Set</td>\n<td>哈希表、数组</td>\n</tr>\n</tbody></table>\n<p>redis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。<br>哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br>冲突增多时，Redis 会对哈希表做渐进式 rehash操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</p>\n<h2 id=\"RedisObject\"><a href=\"#RedisObject\" class=\"headerlink\" title=\"RedisObject\"></a>RedisObject</h2><pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> RedisObject <span class=\"token punctuation\">{</span>\n    int4 type<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 4bits</span>\n    int4 encoding<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 4bits</span>\n    int24 lru<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 24bits</span>\n    int32 refcount<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 4bytes</span>\n    <span class=\"token keyword\">void</span> <span class=\"token operator\">*</span>ptr<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 8bytes，64-bit system</span>\n<span class=\"token punctuation\">}</span> robj<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr 指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。</p>\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> SDS<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n    T capacity<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 数组容量</span>\n    T len<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 数组长度</span>\n    byte flags<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 特殊标识位，不理睬它</span>\n    byte<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> content<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 数组内容</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">struct</span> SDS <span class=\"token punctuation\">{</span>\n    int8 capacity<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 1byte</span>\n    int8 len<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 1byte</span>\n    int8 flags<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 1byte</span>\n    byte<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> content<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 内联数组，长度为 capacity</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。</p>\n<h3 id=\"扩容策略\"><a href=\"#扩容策略\" class=\"headerlink\" title=\"扩容策略\"></a>扩容策略</h3><p>字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。</p>\n<h2 id=\"字典\"><a href=\"#字典\" class=\"headerlink\" title=\"字典\"></a>字典</h2><p>除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。</p>\n<p>dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> dict <span class=\"token punctuation\">{</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n    dictht ht<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">struct</span> dictEntry <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">void</span><span class=\"token operator\">*</span> key<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">void</span><span class=\"token operator\">*</span> val<span class=\"token punctuation\">;</span>\n    dictEntry<span class=\"token operator\">*</span> next<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 链接下一个 entry</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">struct</span> dictht <span class=\"token punctuation\">{</span>\n    dictEntry<span class=\"token operator\">*</span><span class=\"token operator\">*</span> table<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 二维</span>\n    <span class=\"token keyword\">long</span> size<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 第一维数组的长度</span>\n    <span class=\"token keyword\">long</span> used<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// hash 表中的元素个数</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>hashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。</p>\n<h3 id=\"渐进式rehash\"><a href=\"#渐进式rehash\" class=\"headerlink\" title=\"渐进式rehash\"></a>渐进式rehash</h3><p>大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis表示很难承受这样耗时的过程。</p>\n<p>Redis还会在定时任务中对字典进行主动搬迁。</p>\n<h3 id=\"扩容条件\"><a href=\"#扩容条件\" class=\"headerlink\" title=\"扩容条件\"></a>扩容条件</h3><p>当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。</p>\n<h2 id=\"压缩列表\"><a href=\"#压缩列表\" class=\"headerlink\" title=\"压缩列表\"></a>压缩列表</h2><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p>\n<p>压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。</p>\n<pre class=\"line-numbers language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> ziplist<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n    int32 zlbytes<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 整个压缩列表占用字节数</span>\n    int32 zltail_offset<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点</span>\n    int16 zllength<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素个数</span>\n    T<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> entries<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素内容列表，挨个挨个紧凑存储</span>\n    int8 zlend<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 标志压缩列表的结束，值恒为 0xFF</span>\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">struct</span> entry <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">int</span><span class=\"token operator\">&lt;</span>var<span class=\"token operator\">></span> prevlen<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 前一个 entry 的字节长度</span>\n    <span class=\"token keyword\">int</span><span class=\"token operator\">&lt;</span>var<span class=\"token operator\">></span> encoding<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素类型编码</span>\n    optional byte<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> content<span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 元素内容</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"跳表\"><a href=\"#跳表\" class=\"headerlink\" title=\"跳表\"></a>跳表</h2><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。</p>\n<h2 id=\"复杂度\"><a href=\"#复杂度\" class=\"headerlink\" title=\"复杂度\"></a>复杂度</h2><p>各个数据结构的查找时间复杂度<br>| 数据结构 | 复杂度  |<br>| ——– | ——- |<br>| 哈希表   | O(1)    |<br>| 跳表     | O(logN) |<br>| 双向链表 | O(N)    |<br>| 压缩列表 | O(N)    |<br>| 数组     | O(N)    |</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>基本数据结构包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）</p>\n<table>\n<thead>\n<tr>\n<th>基本数据结构</th>\n<th>底层实现</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>string</td>\n<td>动态字符串</td>\n</tr>\n<tr>\n<td>List</td>\n<td>双向链表、压缩列表</td>\n</tr>\n<tr>\n<td>Hash</td>\n<td>哈希表，压缩列表</td>\n</tr>\n<tr>\n<td>Sorted Set</td>\n<td>跳表，压缩列表</td>\n</tr>\n<tr>\n<td>Set</td>\n<td>哈希表、数组</td>\n</tr>\n</tbody></table>\n<p>redis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。<br>哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br>冲突增多时，Redis 会对哈希表做渐进式 rehash操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</p>\n<h2 id=\"RedisObject\"><a href=\"#RedisObject\" class=\"headerlink\" title=\"RedisObject\"></a>RedisObject</h2><pre><code class=\"c\">struct RedisObject {\n    int4 type; // 4bits\n    int4 encoding; // 4bits\n    int24 lru; // 24bits\n    int32 refcount; // 4bytes\n    void *ptr; // 8bytes，64-bit system\n} robj;</code></pre>\n<p>不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr 指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。</p>\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。</p>\n<pre><code class=\"c\">struct SDS&lt;T&gt; {\n    T capacity; // 数组容量\n    T len; // 数组长度\n    byte flags; // 特殊标识位，不理睬它\n    byte[] content; // 数组内容\n}\n\nstruct SDS {\n    int8 capacity; // 1byte\n    int8 len; // 1byte\n    int8 flags; // 1byte\n    byte[] content; // 内联数组，长度为 capacity\n}</code></pre>\n<p>embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。</p>\n<h3 id=\"扩容策略\"><a href=\"#扩容策略\" class=\"headerlink\" title=\"扩容策略\"></a>扩容策略</h3><p>字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。</p>\n<h2 id=\"字典\"><a href=\"#字典\" class=\"headerlink\" title=\"字典\"></a>字典</h2><p>除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。</p>\n<p>dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。</p>\n<pre><code class=\"c\">struct dict {\n    ...\n    dictht ht[2];\n}\nstruct dictEntry {\n    void* key;\n    void* val;\n    dictEntry* next; // 链接下一个 entry\n}\nstruct dictht {\n    dictEntry** table; // 二维\n    long size; // 第一维数组的长度\n    long used; // hash 表中的元素个数\n    ...\n}</code></pre>\n<p>hashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。</p>\n<h3 id=\"渐进式rehash\"><a href=\"#渐进式rehash\" class=\"headerlink\" title=\"渐进式rehash\"></a>渐进式rehash</h3><p>大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis表示很难承受这样耗时的过程。</p>\n<p>Redis还会在定时任务中对字典进行主动搬迁。</p>\n<h3 id=\"扩容条件\"><a href=\"#扩容条件\" class=\"headerlink\" title=\"扩容条件\"></a>扩容条件</h3><p>当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。</p>\n<h2 id=\"压缩列表\"><a href=\"#压缩列表\" class=\"headerlink\" title=\"压缩列表\"></a>压缩列表</h2><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p>\n<p>压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。</p>\n<pre><code class=\"c\">struct ziplist&lt;T&gt; {\n    int32 zlbytes; // 整个压缩列表占用字节数\n    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点\n    int16 zllength; // 元素个数\n    T[] entries; // 元素内容列表，挨个挨个紧凑存储\n    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF\n}\nstruct entry {\n    int&lt;var&gt; prevlen; // 前一个 entry 的字节长度\n    int&lt;var&gt; encoding; // 元素类型编码\n    optional byte[] content; // 元素内容\n}</code></pre>\n<h2 id=\"跳表\"><a href=\"#跳表\" class=\"headerlink\" title=\"跳表\"></a>跳表</h2><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。</p>\n<h2 id=\"复杂度\"><a href=\"#复杂度\" class=\"headerlink\" title=\"复杂度\"></a>复杂度</h2><p>各个数据结构的查找时间复杂度<br>| 数据结构 | 复杂度  |<br>| ——– | ——- |<br>| 哈希表   | O(1)    |<br>| 跳表     | O(logN) |<br>| 双向链表 | O(N)    |<br>| 压缩列表 | O(N)    |<br>| 数组     | O(N)    |</p>\n"},{"title":"redis应用","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-10T13:22:09.000Z","password":null,"summary":null,"_content":"\n## 分布式锁\n\n实现：set lock:codehole true ex5 nx\n\n注意：不要用于较长任务，可能超时释放\n\n优化：设置value是一个随机值，保证不会被其他线程释放\n\n可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。\n\n## 延时队列\n\n实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。\n\n优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。\n\n## 用户一年的签到统计\n\n使用位图，1天的签到记录只需要占据一个位，一年365位。\n\n## 页面访问量\n\n简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。\n\n优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount\n\n## 数据去重\n\n场景：用户为看过的内容推荐去重；爬虫URL去重；\n\n实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis>4.0）bf.add/bf.exists。\n\n误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。\n\n原理：大型位数组和几个不一样的无偏hash函数。\n\n## 简单限流\n\n场景：限制用户行为在一定时间内的次数\n\n实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，**获取当前剩下行为总数**，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。\n\n缺点：不适合1min操作不超过100万次这种场景。\n\n## 漏斗限流\n\n实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。\n\n非常棒，被拒绝还提供了重试时间。\n\n## 附近的人\n\n实现：使用GeoHash.\n\n原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。\n\n注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。\n\n","source":"_posts/redis应用.md","raw":"---\ntitle: redis应用\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-10 21:22:09\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 分布式锁\n\n实现：set lock:codehole true ex5 nx\n\n注意：不要用于较长任务，可能超时释放\n\n优化：设置value是一个随机值，保证不会被其他线程释放\n\n可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。\n\n## 延时队列\n\n实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。\n\n优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。\n\n## 用户一年的签到统计\n\n使用位图，1天的签到记录只需要占据一个位，一年365位。\n\n## 页面访问量\n\n简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。\n\n优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount\n\n## 数据去重\n\n场景：用户为看过的内容推荐去重；爬虫URL去重；\n\n实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis>4.0）bf.add/bf.exists。\n\n误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。\n\n原理：大型位数组和几个不一样的无偏hash函数。\n\n## 简单限流\n\n场景：限制用户行为在一定时间内的次数\n\n实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，**获取当前剩下行为总数**，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。\n\n缺点：不适合1min操作不超过100万次这种场景。\n\n## 漏斗限流\n\n实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。\n\n非常棒，被拒绝还提供了重试时间。\n\n## 附近的人\n\n实现：使用GeoHash.\n\n原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。\n\n注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。\n\n","slug":"redis应用","published":1,"updated":"2021-04-01T23:01:50.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxkq0048ncufy68ljlkl","content":"<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><p>实现：set lock:codehole true ex5 nx</p>\n<p>注意：不要用于较长任务，可能超时释放</p>\n<p>优化：设置value是一个随机值，保证不会被其他线程释放</p>\n<p>可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。</p>\n<h2 id=\"延时队列\"><a href=\"#延时队列\" class=\"headerlink\" title=\"延时队列\"></a>延时队列</h2><p>实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。</p>\n<p>优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。</p>\n<h2 id=\"用户一年的签到统计\"><a href=\"#用户一年的签到统计\" class=\"headerlink\" title=\"用户一年的签到统计\"></a>用户一年的签到统计</h2><p>使用位图，1天的签到记录只需要占据一个位，一年365位。</p>\n<h2 id=\"页面访问量\"><a href=\"#页面访问量\" class=\"headerlink\" title=\"页面访问量\"></a>页面访问量</h2><p>简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。</p>\n<p>优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount</p>\n<h2 id=\"数据去重\"><a href=\"#数据去重\" class=\"headerlink\" title=\"数据去重\"></a>数据去重</h2><p>场景：用户为看过的内容推荐去重；爬虫URL去重；</p>\n<p>实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis&gt;4.0）bf.add/bf.exists。</p>\n<p>误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。</p>\n<p>原理：大型位数组和几个不一样的无偏hash函数。</p>\n<h2 id=\"简单限流\"><a href=\"#简单限流\" class=\"headerlink\" title=\"简单限流\"></a>简单限流</h2><p>场景：限制用户行为在一定时间内的次数</p>\n<p>实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，<strong>获取当前剩下行为总数</strong>，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。</p>\n<p>缺点：不适合1min操作不超过100万次这种场景。</p>\n<h2 id=\"漏斗限流\"><a href=\"#漏斗限流\" class=\"headerlink\" title=\"漏斗限流\"></a>漏斗限流</h2><p>实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。</p>\n<p>非常棒，被拒绝还提供了重试时间。</p>\n<h2 id=\"附近的人\"><a href=\"#附近的人\" class=\"headerlink\" title=\"附近的人\"></a>附近的人</h2><p>实现：使用GeoHash.</p>\n<p>原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。</p>\n<p>注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h2><p>实现：set lock:codehole true ex5 nx</p>\n<p>注意：不要用于较长任务，可能超时释放</p>\n<p>优化：设置value是一个随机值，保证不会被其他线程释放</p>\n<p>可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。</p>\n<h2 id=\"延时队列\"><a href=\"#延时队列\" class=\"headerlink\" title=\"延时队列\"></a>延时队列</h2><p>实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。</p>\n<p>优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。</p>\n<h2 id=\"用户一年的签到统计\"><a href=\"#用户一年的签到统计\" class=\"headerlink\" title=\"用户一年的签到统计\"></a>用户一年的签到统计</h2><p>使用位图，1天的签到记录只需要占据一个位，一年365位。</p>\n<h2 id=\"页面访问量\"><a href=\"#页面访问量\" class=\"headerlink\" title=\"页面访问量\"></a>页面访问量</h2><p>简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。</p>\n<p>优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount</p>\n<h2 id=\"数据去重\"><a href=\"#数据去重\" class=\"headerlink\" title=\"数据去重\"></a>数据去重</h2><p>场景：用户为看过的内容推荐去重；爬虫URL去重；</p>\n<p>实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis&gt;4.0）bf.add/bf.exists。</p>\n<p>误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。</p>\n<p>原理：大型位数组和几个不一样的无偏hash函数。</p>\n<h2 id=\"简单限流\"><a href=\"#简单限流\" class=\"headerlink\" title=\"简单限流\"></a>简单限流</h2><p>场景：限制用户行为在一定时间内的次数</p>\n<p>实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，<strong>获取当前剩下行为总数</strong>，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。</p>\n<p>缺点：不适合1min操作不超过100万次这种场景。</p>\n<h2 id=\"漏斗限流\"><a href=\"#漏斗限流\" class=\"headerlink\" title=\"漏斗限流\"></a>漏斗限流</h2><p>实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。</p>\n<p>非常棒，被拒绝还提供了重试时间。</p>\n<h2 id=\"附近的人\"><a href=\"#附近的人\" class=\"headerlink\" title=\"附近的人\"></a>附近的人</h2><p>实现：使用GeoHash.</p>\n<p>原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。</p>\n<p>注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。</p>\n"},{"title":"redis消息队列","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-11-02T13:35:36.000Z","password":null,"summary":null,"_content":"\n## 需求分析\n\n- 消息保序：消费者需要按照生产者发送消息的顺序来处理消息\n\n- 处理重复的消息：消费者避免多次处理重复的消息\n\n- 保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理\n\n## 基于List\n\n-  LPUSH \n\n把要发送的消息依次写入 List\n\n- BRPOP \n\n阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。\n\n- 消费者程序本身能对重复消息进行判断\n\n消息队列要能给每一个消息提供全局唯一的 ID 号消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。\n\n- BRPOPLPUSH\n\n让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存\n\n缺点：不支持消费组\n\n## 基于 Streams（Redis 5.0）\n\n![](stream.jpg)\n\nRedis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。\n\n每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。\n\n同一个消费组 (Consumer Group) 可以挂接多个消费者 (Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。\n\n消费者 (Consumer) 内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。\n\n- XADD：插入消息，保证有序，可以自动生成全局唯一 ID；\n- XREAD：用于读取消息，可以按 ID 读取数据；\n- XREADGROUP：按消费组形式读取消息\n- XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。\n\n## 缺点\n\n在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。\n\n","source":"_posts/redis消息队列.md","raw":"---\ntitle: redis消息队列\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-11-02 21:35:36\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 需求分析\n\n- 消息保序：消费者需要按照生产者发送消息的顺序来处理消息\n\n- 处理重复的消息：消费者避免多次处理重复的消息\n\n- 保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理\n\n## 基于List\n\n-  LPUSH \n\n把要发送的消息依次写入 List\n\n- BRPOP \n\n阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。\n\n- 消费者程序本身能对重复消息进行判断\n\n消息队列要能给每一个消息提供全局唯一的 ID 号消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。\n\n- BRPOPLPUSH\n\n让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存\n\n缺点：不支持消费组\n\n## 基于 Streams（Redis 5.0）\n\n![](stream.jpg)\n\nRedis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。\n\n每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。\n\n同一个消费组 (Consumer Group) 可以挂接多个消费者 (Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。\n\n消费者 (Consumer) 内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。\n\n- XADD：插入消息，保证有序，可以自动生成全局唯一 ID；\n- XREAD：用于读取消息，可以按 ID 读取数据；\n- XREADGROUP：按消费组形式读取消息\n- XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。\n\n## 缺点\n\n在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。\n\n","slug":"redis消息队列","published":1,"updated":"2021-04-01T23:01:50.077Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxkv004bncufntslqrsf","content":"<h2 id=\"需求分析\"><a href=\"#需求分析\" class=\"headerlink\" title=\"需求分析\"></a>需求分析</h2><ul>\n<li><p>消息保序：消费者需要按照生产者发送消息的顺序来处理消息</p>\n</li>\n<li><p>处理重复的消息：消费者避免多次处理重复的消息</p>\n</li>\n<li><p>保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理</p>\n</li>\n</ul>\n<h2 id=\"基于List\"><a href=\"#基于List\" class=\"headerlink\" title=\"基于List\"></a>基于List</h2><ul>\n<li>LPUSH </li>\n</ul>\n<p>把要发送的消息依次写入 List</p>\n<ul>\n<li>BRPOP </li>\n</ul>\n<p>阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。</p>\n<ul>\n<li>消费者程序本身能对重复消息进行判断</li>\n</ul>\n<p>消息队列要能给每一个消息提供全局唯一的 ID 号消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。</p>\n<ul>\n<li>BRPOPLPUSH</li>\n</ul>\n<p>让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存</p>\n<p>缺点：不支持消费组</p>\n<h2 id=\"基于-Streams（Redis-5-0）\"><a href=\"#基于-Streams（Redis-5-0）\" class=\"headerlink\" title=\"基于 Streams（Redis 5.0）\"></a>基于 Streams（Redis 5.0）</h2><p><img src=\"stream.jpg\" alt></p>\n<p>Redis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。</p>\n<p>每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。</p>\n<p>同一个消费组 (Consumer Group) 可以挂接多个消费者 (Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。</p>\n<p>消费者 (Consumer) 内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。</p>\n<ul>\n<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li>\n<li>XREAD：用于读取消息，可以按 ID 读取数据；</li>\n<li>XREADGROUP：按消费组形式读取消息</li>\n<li>XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"需求分析\"><a href=\"#需求分析\" class=\"headerlink\" title=\"需求分析\"></a>需求分析</h2><ul>\n<li><p>消息保序：消费者需要按照生产者发送消息的顺序来处理消息</p>\n</li>\n<li><p>处理重复的消息：消费者避免多次处理重复的消息</p>\n</li>\n<li><p>保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理</p>\n</li>\n</ul>\n<h2 id=\"基于List\"><a href=\"#基于List\" class=\"headerlink\" title=\"基于List\"></a>基于List</h2><ul>\n<li>LPUSH </li>\n</ul>\n<p>把要发送的消息依次写入 List</p>\n<ul>\n<li>BRPOP </li>\n</ul>\n<p>阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。</p>\n<ul>\n<li>消费者程序本身能对重复消息进行判断</li>\n</ul>\n<p>消息队列要能给每一个消息提供全局唯一的 ID 号消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。</p>\n<ul>\n<li>BRPOPLPUSH</li>\n</ul>\n<p>让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存</p>\n<p>缺点：不支持消费组</p>\n<h2 id=\"基于-Streams（Redis-5-0）\"><a href=\"#基于-Streams（Redis-5-0）\" class=\"headerlink\" title=\"基于 Streams（Redis 5.0）\"></a>基于 Streams（Redis 5.0）</h2><p><img src=\"stream.jpg\" alt></p>\n<p>Redis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。</p>\n<p>每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。</p>\n<p>同一个消费组 (Consumer Group) 可以挂接多个消费者 (Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。</p>\n<p>消费者 (Consumer) 内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。</p>\n<ul>\n<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li>\n<li>XREAD：用于读取消息，可以按 ID 读取数据；</li>\n<li>XREADGROUP：按消费组形式读取消息</li>\n<li>XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。</p>\n"},{"title":"redis缓存","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-27T12:04:59.000Z","password":null,"summary":null,"_content":"\n## redis缓存\n\n- 应用读取数据时，需要先读取 Redis；\n\n- 发生缓存缺失时，需要从数据库读取数据；\n\n- 发生缓存缺失时，还需要更新缓存。\n\nRedis也称为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。\n\n## 缓存分类\n\n- 只读缓存能加速读请求。\n\n- 读写缓存可以同时加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。\n\n### 只读缓存\n\n- 读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。\n- 写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。\n\n**优点**\n\n数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。\n\n**缺点**\n\n每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。\n\n### 读写缓存\n\n读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。\n\n#### 同步直写\n\n- 写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回\n- 需要在业务应用中使用事务实现\n\n**缺点**：降低缓存的访问性能\n\n**优点**：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存\n\n#### 异步直写\n\n- 所有写请求都先在缓存中处理。等到增改的数据要被从缓存中淘汰出来时，将它们写回后端数据库\n\n注意：Redis 本身不提供机制将淘汰数据写回数据库\n\n\n\n**Read/Write Throught策略**\n\n应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，\n\n**优点**\n\n对于应用层的使用非常友好，只需要操作缓存即可\n\n**缺点**\n\n需要缓存层支持和后端数据库的联动。\n\n**Write Back策略**\n\n写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。\n\n**优点**\n\n写操作飞快（只写缓存）\n\n**缺点**\n\n如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。\n\n## 缓存淘汰\n\n“八二原理”：80% 的请求实际只访问了 20% 的数据。\n\n**缓存大小设置**：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。\n\n- 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。\n- 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。\n\n**淘汰策略**\n\n- volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。\n-  volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。\n- volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。\n-  allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。\n- allkeys-random 跟上面一样，不过淘汰的策略是随机的 key\n\n**LRU**\n\nRedis 中，LRU 算法被做了简化。\n\n- Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。\n- Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。\n- 再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值\n\n**LFU**\n\n从两个维度来筛选并淘汰数据：\n\n- 数据的被访问次数\n\n- 数据访问的时效性，访问时间离当前时间的远近\n\n**计数规则**：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。\n\n**counter 值的衰减机制**\n\nLFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。\n\n## 缓存一致性\n\n### 原因1：更新操作失败\n\n只读缓存：无法保证删改数据库和删除缓存的原子性。\n\n- 先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。\n- 先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了\n\n**解决办法：重试机制**\n\n- 把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n- 如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n\n### 原因2：大量并发请求\n\n**先删缓存，后更数据库**\n\n![并发缓存不一致](buyizhi.jpg)\n\n**解决办法：延迟双删**\n\n在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。\n\n难点：sleep时间不好控制\n\n**先更数据库，后删缓存**\n\n![并发缓存不一致2](buyizhi2.jpg)\n\n其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。\n\n优点：不存在缓存缺失的问题，推荐！！\n\n**缓存更新替代删除**\n\n写+写并发时，必然会有数据不一致的情况。因此需要配合**分布式锁**使用。\n\n写+读并发时，先更数据库可能会有短时不一致。\n\n## 缓存异常\n\n### 缓存雪崩\n\n大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n**原因**\n\n- 缓存中有大量数据同时过期\n- Redis 缓存实例发生故障宕机了，无法处理请求\n\n**解决办法**\n\n- 原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数\n- 原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取\n- 原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n- 事前预防。建 Redis 缓存高可靠主从集群。\n\n### 缓存击穿\n\n某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。\n\n**解决办法**\n\n访问特别频繁的热点数据，不设置过期时间\n\n### 缓存穿透\n\n要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。\n\n**原因**\n\n- 业务层误操作：缓存中的数据和数据库中的数据被误删除了\n\n- 恶意攻击：专门访问数据库中没有的数据。\n\n**解决办法**\n\n- 针对穿透查询数据，缓存空值或缺省值。\n- 使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。\n- 前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库\n\n","source":"_posts/redis缓存.md","raw":"---\ntitle: redis缓存\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-27 20:04:59\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## redis缓存\n\n- 应用读取数据时，需要先读取 Redis；\n\n- 发生缓存缺失时，需要从数据库读取数据；\n\n- 发生缓存缺失时，还需要更新缓存。\n\nRedis也称为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。\n\n## 缓存分类\n\n- 只读缓存能加速读请求。\n\n- 读写缓存可以同时加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。\n\n### 只读缓存\n\n- 读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。\n- 写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。\n\n**优点**\n\n数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。\n\n**缺点**\n\n每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。\n\n### 读写缓存\n\n读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。\n\n#### 同步直写\n\n- 写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回\n- 需要在业务应用中使用事务实现\n\n**缺点**：降低缓存的访问性能\n\n**优点**：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存\n\n#### 异步直写\n\n- 所有写请求都先在缓存中处理。等到增改的数据要被从缓存中淘汰出来时，将它们写回后端数据库\n\n注意：Redis 本身不提供机制将淘汰数据写回数据库\n\n\n\n**Read/Write Throught策略**\n\n应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，\n\n**优点**\n\n对于应用层的使用非常友好，只需要操作缓存即可\n\n**缺点**\n\n需要缓存层支持和后端数据库的联动。\n\n**Write Back策略**\n\n写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。\n\n**优点**\n\n写操作飞快（只写缓存）\n\n**缺点**\n\n如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。\n\n## 缓存淘汰\n\n“八二原理”：80% 的请求实际只访问了 20% 的数据。\n\n**缓存大小设置**：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。\n\n- 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。\n- 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。\n\n**淘汰策略**\n\n- volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。\n-  volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。\n- volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。\n-  allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。\n- allkeys-random 跟上面一样，不过淘汰的策略是随机的 key\n\n**LRU**\n\nRedis 中，LRU 算法被做了简化。\n\n- Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。\n- Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。\n- 再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值\n\n**LFU**\n\n从两个维度来筛选并淘汰数据：\n\n- 数据的被访问次数\n\n- 数据访问的时效性，访问时间离当前时间的远近\n\n**计数规则**：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。\n\n**counter 值的衰减机制**\n\nLFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。\n\n## 缓存一致性\n\n### 原因1：更新操作失败\n\n只读缓存：无法保证删改数据库和删除缓存的原子性。\n\n- 先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。\n- 先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了\n\n**解决办法：重试机制**\n\n- 把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n- 如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n\n### 原因2：大量并发请求\n\n**先删缓存，后更数据库**\n\n![并发缓存不一致](buyizhi.jpg)\n\n**解决办法：延迟双删**\n\n在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。\n\n难点：sleep时间不好控制\n\n**先更数据库，后删缓存**\n\n![并发缓存不一致2](buyizhi2.jpg)\n\n其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。\n\n优点：不存在缓存缺失的问题，推荐！！\n\n**缓存更新替代删除**\n\n写+写并发时，必然会有数据不一致的情况。因此需要配合**分布式锁**使用。\n\n写+读并发时，先更数据库可能会有短时不一致。\n\n## 缓存异常\n\n### 缓存雪崩\n\n大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n**原因**\n\n- 缓存中有大量数据同时过期\n- Redis 缓存实例发生故障宕机了，无法处理请求\n\n**解决办法**\n\n- 原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数\n- 原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取\n- 原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n- 事前预防。建 Redis 缓存高可靠主从集群。\n\n### 缓存击穿\n\n某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。\n\n**解决办法**\n\n访问特别频繁的热点数据，不设置过期时间\n\n### 缓存穿透\n\n要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。\n\n**原因**\n\n- 业务层误操作：缓存中的数据和数据库中的数据被误删除了\n\n- 恶意攻击：专门访问数据库中没有的数据。\n\n**解决办法**\n\n- 针对穿透查询数据，缓存空值或缺省值。\n- 使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。\n- 前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库\n\n","slug":"redis缓存","published":1,"updated":"2021-04-01T23:01:50.097Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxl1004encuf8hjpead4","content":"<h2 id=\"redis缓存\"><a href=\"#redis缓存\" class=\"headerlink\" title=\"redis缓存\"></a>redis缓存</h2><ul>\n<li><p>应用读取数据时，需要先读取 Redis；</p>\n</li>\n<li><p>发生缓存缺失时，需要从数据库读取数据；</p>\n</li>\n<li><p>发生缓存缺失时，还需要更新缓存。</p>\n</li>\n</ul>\n<p>Redis也称为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p>\n<h2 id=\"缓存分类\"><a href=\"#缓存分类\" class=\"headerlink\" title=\"缓存分类\"></a>缓存分类</h2><ul>\n<li><p>只读缓存能加速读请求。</p>\n</li>\n<li><p>读写缓存可以同时加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。</p>\n</li>\n</ul>\n<h3 id=\"只读缓存\"><a href=\"#只读缓存\" class=\"headerlink\" title=\"只读缓存\"></a>只读缓存</h3><ul>\n<li>读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。</li>\n<li>写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p>数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。</p>\n<p><strong>缺点</strong></p>\n<p>每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p>\n<h3 id=\"读写缓存\"><a href=\"#读写缓存\" class=\"headerlink\" title=\"读写缓存\"></a>读写缓存</h3><p>读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。</p>\n<h4 id=\"同步直写\"><a href=\"#同步直写\" class=\"headerlink\" title=\"同步直写\"></a>同步直写</h4><ul>\n<li>写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回</li>\n<li>需要在业务应用中使用事务实现</li>\n</ul>\n<p><strong>缺点</strong>：降低缓存的访问性能</p>\n<p><strong>优点</strong>：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存</p>\n<h4 id=\"异步直写\"><a href=\"#异步直写\" class=\"headerlink\" title=\"异步直写\"></a>异步直写</h4><ul>\n<li>所有写请求都先在缓存中处理。等到增改的数据要被从缓存中淘汰出来时，将它们写回后端数据库</li>\n</ul>\n<p>注意：Redis 本身不提供机制将淘汰数据写回数据库</p>\n<p><strong>Read/Write Throught策略</strong></p>\n<p>应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，</p>\n<p><strong>优点</strong></p>\n<p>对于应用层的使用非常友好，只需要操作缓存即可</p>\n<p><strong>缺点</strong></p>\n<p>需要缓存层支持和后端数据库的联动。</p>\n<p><strong>Write Back策略</strong></p>\n<p>写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。</p>\n<p><strong>优点</strong></p>\n<p>写操作飞快（只写缓存）</p>\n<p><strong>缺点</strong></p>\n<p>如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。</p>\n<h2 id=\"缓存淘汰\"><a href=\"#缓存淘汰\" class=\"headerlink\" title=\"缓存淘汰\"></a>缓存淘汰</h2><p>“八二原理”：80% 的请求实际只访问了 20% 的数据。</p>\n<p><strong>缓存大小设置</strong>：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。</p>\n<ul>\n<li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。</li>\n<li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。</li>\n</ul>\n<p><strong>淘汰策略</strong></p>\n<ul>\n<li>volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。</li>\n<li>volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。</li>\n<li>volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。</li>\n<li>allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。</li>\n<li>allkeys-random 跟上面一样，不过淘汰的策略是随机的 key</li>\n</ul>\n<p><strong>LRU</strong></p>\n<p>Redis 中，LRU 算法被做了简化。</p>\n<ul>\n<li>Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。</li>\n<li>Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</li>\n<li>再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值</li>\n</ul>\n<p><strong>LFU</strong></p>\n<p>从两个维度来筛选并淘汰数据：</p>\n<ul>\n<li><p>数据的被访问次数</p>\n</li>\n<li><p>数据访问的时效性，访问时间离当前时间的远近</p>\n</li>\n</ul>\n<p><strong>计数规则</strong>：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</p>\n<p><strong>counter 值的衰减机制</strong></p>\n<p>LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</p>\n<h2 id=\"缓存一致性\"><a href=\"#缓存一致性\" class=\"headerlink\" title=\"缓存一致性\"></a>缓存一致性</h2><h3 id=\"原因1：更新操作失败\"><a href=\"#原因1：更新操作失败\" class=\"headerlink\" title=\"原因1：更新操作失败\"></a>原因1：更新操作失败</h3><p>只读缓存：无法保证删改数据库和删除缓存的原子性。</p>\n<ul>\n<li>先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。</li>\n<li>先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了</li>\n</ul>\n<p><strong>解决办法：重试机制</strong></p>\n<ul>\n<li>把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</li>\n<li>如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>\n</ul>\n<h3 id=\"原因2：大量并发请求\"><a href=\"#原因2：大量并发请求\" class=\"headerlink\" title=\"原因2：大量并发请求\"></a>原因2：大量并发请求</h3><p><strong>先删缓存，后更数据库</strong></p>\n<p><img src=\"buyizhi.jpg\" alt=\"并发缓存不一致\"></p>\n<p><strong>解决办法：延迟双删</strong></p>\n<p>在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。</p>\n<p>难点：sleep时间不好控制</p>\n<p><strong>先更数据库，后删缓存</strong></p>\n<p><img src=\"buyizhi2.jpg\" alt=\"并发缓存不一致2\"></p>\n<p>其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。</p>\n<p>优点：不存在缓存缺失的问题，推荐！！</p>\n<p><strong>缓存更新替代删除</strong></p>\n<p>写+写并发时，必然会有数据不一致的情况。因此需要配合<strong>分布式锁</strong>使用。</p>\n<p>写+读并发时，先更数据库可能会有短时不一致。</p>\n<h2 id=\"缓存异常\"><a href=\"#缓存异常\" class=\"headerlink\" title=\"缓存异常\"></a>缓存异常</h2><h3 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h3><p>大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li>缓存中有大量数据同时过期</li>\n<li>Redis 缓存实例发生故障宕机了，无法处理请求</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数</li>\n<li>原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取</li>\n<li>原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</li>\n<li>事前预防。建 Redis 缓存高可靠主从集群。</li>\n</ul>\n<h3 id=\"缓存击穿\"><a href=\"#缓存击穿\" class=\"headerlink\" title=\"缓存击穿\"></a>缓存击穿</h3><p>某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p>\n<p><strong>解决办法</strong></p>\n<p>访问特别频繁的热点数据，不设置过期时间</p>\n<h3 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h3><p>要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li><p>业务层误操作：缓存中的数据和数据库中的数据被误删除了</p>\n</li>\n<li><p>恶意攻击：专门访问数据库中没有的数据。</p>\n</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>针对穿透查询数据，缓存空值或缺省值。</li>\n<li>使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。</li>\n<li>前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</li>\n</ul>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"redis缓存\"><a href=\"#redis缓存\" class=\"headerlink\" title=\"redis缓存\"></a>redis缓存</h2><ul>\n<li><p>应用读取数据时，需要先读取 Redis；</p>\n</li>\n<li><p>发生缓存缺失时，需要从数据库读取数据；</p>\n</li>\n<li><p>发生缓存缺失时，还需要更新缓存。</p>\n</li>\n</ul>\n<p>Redis也称为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p>\n<h2 id=\"缓存分类\"><a href=\"#缓存分类\" class=\"headerlink\" title=\"缓存分类\"></a>缓存分类</h2><ul>\n<li><p>只读缓存能加速读请求。</p>\n</li>\n<li><p>读写缓存可以同时加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。</p>\n</li>\n</ul>\n<h3 id=\"只读缓存\"><a href=\"#只读缓存\" class=\"headerlink\" title=\"只读缓存\"></a>只读缓存</h3><ul>\n<li>读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。</li>\n<li>写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。</li>\n</ul>\n<p><strong>优点</strong></p>\n<p>数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。</p>\n<p><strong>缺点</strong></p>\n<p>每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p>\n<h3 id=\"读写缓存\"><a href=\"#读写缓存\" class=\"headerlink\" title=\"读写缓存\"></a>读写缓存</h3><p>读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。</p>\n<h4 id=\"同步直写\"><a href=\"#同步直写\" class=\"headerlink\" title=\"同步直写\"></a>同步直写</h4><ul>\n<li>写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回</li>\n<li>需要在业务应用中使用事务实现</li>\n</ul>\n<p><strong>缺点</strong>：降低缓存的访问性能</p>\n<p><strong>优点</strong>：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存</p>\n<h4 id=\"异步直写\"><a href=\"#异步直写\" class=\"headerlink\" title=\"异步直写\"></a>异步直写</h4><ul>\n<li>所有写请求都先在缓存中处理。等到增改的数据要被从缓存中淘汰出来时，将它们写回后端数据库</li>\n</ul>\n<p>注意：Redis 本身不提供机制将淘汰数据写回数据库</p>\n<p><strong>Read/Write Throught策略</strong></p>\n<p>应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，</p>\n<p><strong>优点</strong></p>\n<p>对于应用层的使用非常友好，只需要操作缓存即可</p>\n<p><strong>缺点</strong></p>\n<p>需要缓存层支持和后端数据库的联动。</p>\n<p><strong>Write Back策略</strong></p>\n<p>写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。</p>\n<p><strong>优点</strong></p>\n<p>写操作飞快（只写缓存）</p>\n<p><strong>缺点</strong></p>\n<p>如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。</p>\n<h2 id=\"缓存淘汰\"><a href=\"#缓存淘汰\" class=\"headerlink\" title=\"缓存淘汰\"></a>缓存淘汰</h2><p>“八二原理”：80% 的请求实际只访问了 20% 的数据。</p>\n<p><strong>缓存大小设置</strong>：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。</p>\n<ul>\n<li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。</li>\n<li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。</li>\n</ul>\n<p><strong>淘汰策略</strong></p>\n<ul>\n<li>volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。</li>\n<li>volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。</li>\n<li>volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。</li>\n<li>allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。</li>\n<li>allkeys-random 跟上面一样，不过淘汰的策略是随机的 key</li>\n</ul>\n<p><strong>LRU</strong></p>\n<p>Redis 中，LRU 算法被做了简化。</p>\n<ul>\n<li>Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。</li>\n<li>Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</li>\n<li>再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值</li>\n</ul>\n<p><strong>LFU</strong></p>\n<p>从两个维度来筛选并淘汰数据：</p>\n<ul>\n<li><p>数据的被访问次数</p>\n</li>\n<li><p>数据访问的时效性，访问时间离当前时间的远近</p>\n</li>\n</ul>\n<p><strong>计数规则</strong>：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</p>\n<p><strong>counter 值的衰减机制</strong></p>\n<p>LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</p>\n<h2 id=\"缓存一致性\"><a href=\"#缓存一致性\" class=\"headerlink\" title=\"缓存一致性\"></a>缓存一致性</h2><h3 id=\"原因1：更新操作失败\"><a href=\"#原因1：更新操作失败\" class=\"headerlink\" title=\"原因1：更新操作失败\"></a>原因1：更新操作失败</h3><p>只读缓存：无法保证删改数据库和删除缓存的原子性。</p>\n<ul>\n<li>先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。</li>\n<li>先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了</li>\n</ul>\n<p><strong>解决办法：重试机制</strong></p>\n<ul>\n<li>把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</li>\n<li>如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>\n</ul>\n<h3 id=\"原因2：大量并发请求\"><a href=\"#原因2：大量并发请求\" class=\"headerlink\" title=\"原因2：大量并发请求\"></a>原因2：大量并发请求</h3><p><strong>先删缓存，后更数据库</strong></p>\n<p><img src=\"buyizhi.jpg\" alt=\"并发缓存不一致\"></p>\n<p><strong>解决办法：延迟双删</strong></p>\n<p>在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。</p>\n<p>难点：sleep时间不好控制</p>\n<p><strong>先更数据库，后删缓存</strong></p>\n<p><img src=\"buyizhi2.jpg\" alt=\"并发缓存不一致2\"></p>\n<p>其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。</p>\n<p>优点：不存在缓存缺失的问题，推荐！！</p>\n<p><strong>缓存更新替代删除</strong></p>\n<p>写+写并发时，必然会有数据不一致的情况。因此需要配合<strong>分布式锁</strong>使用。</p>\n<p>写+读并发时，先更数据库可能会有短时不一致。</p>\n<h2 id=\"缓存异常\"><a href=\"#缓存异常\" class=\"headerlink\" title=\"缓存异常\"></a>缓存异常</h2><h3 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h3><p>大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li>缓存中有大量数据同时过期</li>\n<li>Redis 缓存实例发生故障宕机了，无法处理请求</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数</li>\n<li>原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取</li>\n<li>原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</li>\n<li>事前预防。建 Redis 缓存高可靠主从集群。</li>\n</ul>\n<h3 id=\"缓存击穿\"><a href=\"#缓存击穿\" class=\"headerlink\" title=\"缓存击穿\"></a>缓存击穿</h3><p>某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p>\n<p><strong>解决办法</strong></p>\n<p>访问特别频繁的热点数据，不设置过期时间</p>\n<h3 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h3><p>要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。</p>\n<p><strong>原因</strong></p>\n<ul>\n<li><p>业务层误操作：缓存中的数据和数据库中的数据被误删除了</p>\n</li>\n<li><p>恶意攻击：专门访问数据库中没有的数据。</p>\n</li>\n</ul>\n<p><strong>解决办法</strong></p>\n<ul>\n<li>针对穿透查询数据，缓存空值或缺省值。</li>\n<li>使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。</li>\n<li>前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</li>\n</ul>\n"},{"title":"redis网络IO模型","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T14:06:23.000Z","password":null,"summary":null,"_content":"\n## 单线程\n\nRedis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\n\n避免了多线程编程模式面临的共享资源的并发访问控制问题。\n\n## 多路复用机制\n\n一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n\n为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。","source":"_posts/redis网络IO模型.md","raw":"---\ntitle: redis网络IO模型\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 22:06:23\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## 单线程\n\nRedis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\n\n避免了多线程编程模式面临的共享资源的并发访问控制问题。\n\n## 多路复用机制\n\n一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n\n为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。","slug":"redis网络IO模型","published":1,"updated":"2021-04-01T23:01:50.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxl5004hncufe067efjc","content":"<h2 id=\"单线程\"><a href=\"#单线程\" class=\"headerlink\" title=\"单线程\"></a>单线程</h2><p>Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p>\n<p>避免了多线程编程模式面临的共享资源的并发访问控制问题。</p>\n<h2 id=\"多路复用机制\"><a href=\"#多路复用机制\" class=\"headerlink\" title=\"多路复用机制\"></a>多路复用机制</h2><p>一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p>\n<p>为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"单线程\"><a href=\"#单线程\" class=\"headerlink\" title=\"单线程\"></a>单线程</h2><p>Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p>\n<p>避免了多线程编程模式面临的共享资源的并发访问控制问题。</p>\n<h2 id=\"多路复用机制\"><a href=\"#多路复用机制\" class=\"headerlink\" title=\"多路复用机制\"></a>多路复用机制</h2><p>一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p>\n<p>为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>\n"},{"title":"redis阻塞及解决办法","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:39:01.000Z","password":null,"summary":null,"_content":"\n\n\n---\n\n## 阻塞分析\n\n### 客户端\n\n**复杂度高的增删改查操作**\n1、集合全量查询和聚合操作\n2、bigkey 删除\n3、清空数据库\n\n\n### 磁盘\n\n1、AOF 日志同步写\n\n### 主从节点\n\n1、从库接收 RDB 文件后、**清空数据库、加载 RDB 文件**；\n\n### 切片集群\n\n向其他实例传输哈希槽信息，数据迁移时遇到big key。\n\n### 小结\n\n关键路径：集合全量查询和聚合操作和从库加载 RDB 文件\n非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。\n\n## 解决方案\n\n### 异步的子线程机制\n\nRedis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。\n\n注：异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。\n\n### 分批读取\n集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算\n\n### 控制RBD大小\n从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。","source":"_posts/redis阻塞及解决办法.md","raw":"---\ntitle: redis阻塞及解决办法\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:39:01\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n\n\n---\n\n## 阻塞分析\n\n### 客户端\n\n**复杂度高的增删改查操作**\n1、集合全量查询和聚合操作\n2、bigkey 删除\n3、清空数据库\n\n\n### 磁盘\n\n1、AOF 日志同步写\n\n### 主从节点\n\n1、从库接收 RDB 文件后、**清空数据库、加载 RDB 文件**；\n\n### 切片集群\n\n向其他实例传输哈希槽信息，数据迁移时遇到big key。\n\n### 小结\n\n关键路径：集合全量查询和聚合操作和从库加载 RDB 文件\n非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。\n\n## 解决方案\n\n### 异步的子线程机制\n\nRedis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。\n\n注：异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。\n\n### 分批读取\n集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算\n\n### 控制RBD大小\n从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。","slug":"redis阻塞及解决办法","published":1,"updated":"2021-04-01T23:01:50.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxl8004kncufw6vz0jxu","content":"<hr>\n<h2 id=\"阻塞分析\"><a href=\"#阻塞分析\" class=\"headerlink\" title=\"阻塞分析\"></a>阻塞分析</h2><h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><p><strong>复杂度高的增删改查操作</strong><br>1、集合全量查询和聚合操作<br>2、bigkey 删除<br>3、清空数据库</p>\n<h3 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h3><p>1、AOF 日志同步写</p>\n<h3 id=\"主从节点\"><a href=\"#主从节点\" class=\"headerlink\" title=\"主从节点\"></a>主从节点</h3><p>1、从库接收 RDB 文件后、<strong>清空数据库、加载 RDB 文件</strong>；</p>\n<h3 id=\"切片集群\"><a href=\"#切片集群\" class=\"headerlink\" title=\"切片集群\"></a>切片集群</h3><p>向其他实例传输哈希槽信息，数据迁移时遇到big key。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>关键路径：集合全量查询和聚合操作和从库加载 RDB 文件<br>非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。</p>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"异步的子线程机制\"><a href=\"#异步的子线程机制\" class=\"headerlink\" title=\"异步的子线程机制\"></a>异步的子线程机制</h3><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</p>\n<p>注：异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>\n<h3 id=\"分批读取\"><a href=\"#分批读取\" class=\"headerlink\" title=\"分批读取\"></a>分批读取</h3><p>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算</p>\n<h3 id=\"控制RBD大小\"><a href=\"#控制RBD大小\" class=\"headerlink\" title=\"控制RBD大小\"></a>控制RBD大小</h3><p>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<hr>\n<h2 id=\"阻塞分析\"><a href=\"#阻塞分析\" class=\"headerlink\" title=\"阻塞分析\"></a>阻塞分析</h2><h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><p><strong>复杂度高的增删改查操作</strong><br>1、集合全量查询和聚合操作<br>2、bigkey 删除<br>3、清空数据库</p>\n<h3 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h3><p>1、AOF 日志同步写</p>\n<h3 id=\"主从节点\"><a href=\"#主从节点\" class=\"headerlink\" title=\"主从节点\"></a>主从节点</h3><p>1、从库接收 RDB 文件后、<strong>清空数据库、加载 RDB 文件</strong>；</p>\n<h3 id=\"切片集群\"><a href=\"#切片集群\" class=\"headerlink\" title=\"切片集群\"></a>切片集群</h3><p>向其他实例传输哈希槽信息，数据迁移时遇到big key。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>关键路径：集合全量查询和聚合操作和从库加载 RDB 文件<br>非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。</p>\n<h2 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h2><h3 id=\"异步的子线程机制\"><a href=\"#异步的子线程机制\" class=\"headerlink\" title=\"异步的子线程机制\"></a>异步的子线程机制</h3><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</p>\n<p>注：异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>\n<h3 id=\"分批读取\"><a href=\"#分批读取\" class=\"headerlink\" title=\"分批读取\"></a>分批读取</h3><p>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算</p>\n<h3 id=\"控制RBD大小\"><a href=\"#控制RBD大小\" class=\"headerlink\" title=\"控制RBD大小\"></a>控制RBD大小</h3><p>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</p>\n"},{"title":"事务","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-14T11:57:07.000Z","password":null,"summary":null,"_content":"\n## 事务\n\n事务就是一组原子性的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。\n\n### ACID\n\n- atomicity（原子性） ：要么全执行，要么全都不执行；\n- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；\n- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；\n- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。\n\nInnoDB 采用 redo log 机制来保证事务更新的一致性和持久性。\n\n### 并发事务可能存在的问题\n\n- 脏读：事务 A 读取了事务 B 当前更新的数据，但是事务 B 出现了回滚或未提交修改，事务 A 读到的数据就被称为 “脏数据”。通常情况下，使用 “脏数据” 会造成系统数据不一致，出现错误\n- 不可重复读：事务 A 在执行过程中多次读取同一数据，但是事务 B 在事务 A 的读取过程中对数据做了多次修改并提交，则会导致事务 A 多次读取的数据不一致，进而无法做出准确性判断\n- 幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n\n### 事务隔离级别\n\n- READ-UNCOMMITTED：，一个事务还没提交时，它做的变更就能被别的事务看到。\n- READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。\n- REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n- SERIALIZABLE：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n### 事务隔离的实现\n\n数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。\n\n“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n## 事务可见性分析（RR）\n\n这个事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为低水位，最大值加1记为高水位。活跃事务ID数组。\n\nrow trx_id<低水位：表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n\n低水位<row trx_id<高水位：在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。\n\nrow trx_id>高水位：由将来启动的事务生成的，是肯定不可见的；\n\n也可以从事务启动时间来看：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：\n\n1. 版本未提交，不可见；\n2. 版本已提交，但是是在视图创建后提交的，不可见；\n3. 版本已提交，而且是在视图创建前提交的，可见。\n\n注意：\n\n更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）\n\nselect * from t where id=1加上lock in share mode 或for update，也是当前读。\n\n## Redo log\n\nRedo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。\n\nRedo log 由两部分组成：\n\n- 内存中的重做日志缓冲（redo log buffer）\n- 重做日志文件（redo log file）\n\n每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：\n\n- 0：表示每次事务提交时都只是把redo log留在redo log buffer中;\n- 1：表示每次事务提交时都将redo log直接持久化到磁盘；\n- 2：表示每次事务提交时都只是把redo log写到page cache。\n  innodb_flush_log_at_trx_commit 参数的默认值是 1\n\n除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。\n\n## Binlog\n\n二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）\n\nBinlog 有以下几个作用：\n\n- 恢复：数据恢复时可以使用二进制日志\n- 复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步\n- 审计：可以通过二进制日志进行审计数据的变更操作\n\nsync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。\n\n- sync_binlog=0，表示每次提交事务都只write，不fsync\n- sync_binlog=1，表示每次提交事务都会执行fsync\n- sync_binlog=N(N>1)，表示每次提交事务都write，累积N个事务后才fsync\n\n**binlog格式**\n\n当binlog_format=statement时，binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用\n\n当binlog_format使用row格式的时候，binlog里面记录了真实删除行的主键id，这样binlog传到备库去的时候，就肯定会删除id=4的行，不会有主备删除不同行的问题，缺点是很占空间。而且利于恢复数据。\n\nmixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。\n\n## redolog和binlog区别\n\n- redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n\n- redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n\n- redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n## 数据库突然断电不丢数据\n\n只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。\n\n## 事务建议\n\n- 循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。\n- 优化事务里的语句顺序，减少锁时间。\n- 关注不同事务访问资源的顺序，避免死锁。\n- 创建事务之前，关注事务隔离级别。\n- 不在事务中混合使用存储引擎（MyISAM无法回滚）\n\n## 分布式事务\n\n分布式事务使用两阶段提交协议：\n第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；\n第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。\n\n### MySQL 自带的分布式事务\n\n```mysql\nxa start 'a','a_1'; //启动分支事务\nxa end 'a','a_1'; //结束分支事务\nxa prepare 'a','a_1'; //进入准备状态\nxa commit 'a','a_1';  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息\n```\n\n","source":"_posts/事务.md","raw":"---\ntitle: 事务\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-14 19:57:07\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 事务\n\n事务就是一组原子性的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。\n\n### ACID\n\n- atomicity（原子性） ：要么全执行，要么全都不执行；\n- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；\n- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；\n- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。\n\nInnoDB 采用 redo log 机制来保证事务更新的一致性和持久性。\n\n### 并发事务可能存在的问题\n\n- 脏读：事务 A 读取了事务 B 当前更新的数据，但是事务 B 出现了回滚或未提交修改，事务 A 读到的数据就被称为 “脏数据”。通常情况下，使用 “脏数据” 会造成系统数据不一致，出现错误\n- 不可重复读：事务 A 在执行过程中多次读取同一数据，但是事务 B 在事务 A 的读取过程中对数据做了多次修改并提交，则会导致事务 A 多次读取的数据不一致，进而无法做出准确性判断\n- 幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n\n### 事务隔离级别\n\n- READ-UNCOMMITTED：，一个事务还没提交时，它做的变更就能被别的事务看到。\n- READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。\n- REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n- SERIALIZABLE：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n### 事务隔离的实现\n\n数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。\n\n“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n## 事务可见性分析（RR）\n\n这个事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为低水位，最大值加1记为高水位。活跃事务ID数组。\n\nrow trx_id<低水位：表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n\n低水位<row trx_id<高水位：在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。\n\nrow trx_id>高水位：由将来启动的事务生成的，是肯定不可见的；\n\n也可以从事务启动时间来看：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：\n\n1. 版本未提交，不可见；\n2. 版本已提交，但是是在视图创建后提交的，不可见；\n3. 版本已提交，而且是在视图创建前提交的，可见。\n\n注意：\n\n更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）\n\nselect * from t where id=1加上lock in share mode 或for update，也是当前读。\n\n## Redo log\n\nRedo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。\n\nRedo log 由两部分组成：\n\n- 内存中的重做日志缓冲（redo log buffer）\n- 重做日志文件（redo log file）\n\n每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：\n\n- 0：表示每次事务提交时都只是把redo log留在redo log buffer中;\n- 1：表示每次事务提交时都将redo log直接持久化到磁盘；\n- 2：表示每次事务提交时都只是把redo log写到page cache。\n  innodb_flush_log_at_trx_commit 参数的默认值是 1\n\n除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。\n\n## Binlog\n\n二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）\n\nBinlog 有以下几个作用：\n\n- 恢复：数据恢复时可以使用二进制日志\n- 复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步\n- 审计：可以通过二进制日志进行审计数据的变更操作\n\nsync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。\n\n- sync_binlog=0，表示每次提交事务都只write，不fsync\n- sync_binlog=1，表示每次提交事务都会执行fsync\n- sync_binlog=N(N>1)，表示每次提交事务都write，累积N个事务后才fsync\n\n**binlog格式**\n\n当binlog_format=statement时，binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用\n\n当binlog_format使用row格式的时候，binlog里面记录了真实删除行的主键id，这样binlog传到备库去的时候，就肯定会删除id=4的行，不会有主备删除不同行的问题，缺点是很占空间。而且利于恢复数据。\n\nmixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。\n\n## redolog和binlog区别\n\n- redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n\n- redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n\n- redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n## 数据库突然断电不丢数据\n\n只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。\n\n## 事务建议\n\n- 循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。\n- 优化事务里的语句顺序，减少锁时间。\n- 关注不同事务访问资源的顺序，避免死锁。\n- 创建事务之前，关注事务隔离级别。\n- 不在事务中混合使用存储引擎（MyISAM无法回滚）\n\n## 分布式事务\n\n分布式事务使用两阶段提交协议：\n第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；\n第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。\n\n### MySQL 自带的分布式事务\n\n```mysql\nxa start 'a','a_1'; //启动分支事务\nxa end 'a','a_1'; //结束分支事务\nxa prepare 'a','a_1'; //进入准备状态\nxa commit 'a','a_1';  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息\n```\n\n","slug":"事务","published":1,"updated":"2021-04-01T23:01:50.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxld004nncuffa5vn6ql","content":"<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><p>事务就是一组原子性的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。</p>\n<h3 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h3><ul>\n<li>atomicity（原子性） ：要么全执行，要么全都不执行；</li>\n<li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li>\n<li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li>\n<li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li>\n</ul>\n<p>InnoDB 采用 redo log 机制来保证事务更新的一致性和持久性。</p>\n<h3 id=\"并发事务可能存在的问题\"><a href=\"#并发事务可能存在的问题\" class=\"headerlink\" title=\"并发事务可能存在的问题\"></a>并发事务可能存在的问题</h3><ul>\n<li>脏读：事务 A 读取了事务 B 当前更新的数据，但是事务 B 出现了回滚或未提交修改，事务 A 读到的数据就被称为 “脏数据”。通常情况下，使用 “脏数据” 会造成系统数据不一致，出现错误</li>\n<li>不可重复读：事务 A 在执行过程中多次读取同一数据，但是事务 B 在事务 A 的读取过程中对数据做了多次修改并提交，则会导致事务 A 多次读取的数据不一致，进而无法做出准确性判断</li>\n<li>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>\n</ul>\n<h3 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h3><ul>\n<li>READ-UNCOMMITTED：，一个事务还没提交时，它做的变更就能被别的事务看到。</li>\n<li>READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。</li>\n<li>REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li>\n<li>SERIALIZABLE：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>\n</ul>\n<h3 id=\"事务隔离的实现\"><a href=\"#事务隔离的实现\" class=\"headerlink\" title=\"事务隔离的实现\"></a>事务隔离的实现</h3><p>数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>\n<p>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</p>\n<p>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</p>\n<p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</p>\n<p>而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>\n<h2 id=\"事务可见性分析（RR）\"><a href=\"#事务可见性分析（RR）\" class=\"headerlink\" title=\"事务可见性分析（RR）\"></a>事务可见性分析（RR）</h2><p>这个事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为低水位，最大值加1记为高水位。活跃事务ID数组。</p>\n<p>row trx_id&lt;低水位：表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</p>\n<p>低水位&lt;row trx_id&lt;高水位：在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。</p>\n<p>row trx_id&gt;高水位：由将来启动的事务生成的，是肯定不可见的；</p>\n<p>也可以从事务启动时间来看：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p>\n<ol>\n<li>版本未提交，不可见；</li>\n<li>版本已提交，但是是在视图创建后提交的，不可见；</li>\n<li>版本已提交，而且是在视图创建前提交的，可见。</li>\n</ol>\n<p>注意：</p>\n<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</p>\n<p>select * from t where id=1加上lock in share mode 或for update，也是当前读。</p>\n<h2 id=\"Redo-log\"><a href=\"#Redo-log\" class=\"headerlink\" title=\"Redo log\"></a>Redo log</h2><p>Redo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。</p>\n<p>Redo log 由两部分组成：</p>\n<ul>\n<li>内存中的重做日志缓冲（redo log buffer）</li>\n<li>重做日志文件（redo log file）</li>\n</ul>\n<p>每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：</p>\n<ul>\n<li>0：表示每次事务提交时都只是把redo log留在redo log buffer中;</li>\n<li>1：表示每次事务提交时都将redo log直接持久化到磁盘；</li>\n<li>2：表示每次事务提交时都只是把redo log写到page cache。<br>innodb_flush_log_at_trx_commit 参数的默认值是 1</li>\n</ul>\n<p>除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。</p>\n<h2 id=\"Binlog\"><a href=\"#Binlog\" class=\"headerlink\" title=\"Binlog\"></a>Binlog</h2><p>二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）</p>\n<p>Binlog 有以下几个作用：</p>\n<ul>\n<li>恢复：数据恢复时可以使用二进制日志</li>\n<li>复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步</li>\n<li>审计：可以通过二进制日志进行审计数据的变更操作</li>\n</ul>\n<p>sync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。</p>\n<ul>\n<li>sync_binlog=0，表示每次提交事务都只write，不fsync</li>\n<li>sync_binlog=1，表示每次提交事务都会执行fsync</li>\n<li>sync_binlog=N(N&gt;1)，表示每次提交事务都write，累积N个事务后才fsync</li>\n</ul>\n<p><strong>binlog格式</strong></p>\n<p>当binlog_format=statement时，binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用</p>\n<p>当binlog_format使用row格式的时候，binlog里面记录了真实删除行的主键id，这样binlog传到备库去的时候，就肯定会删除id=4的行，不会有主备删除不同行的问题，缺点是很占空间。而且利于恢复数据。</p>\n<p>mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。</p>\n<h2 id=\"redolog和binlog区别\"><a href=\"#redolog和binlog区别\" class=\"headerlink\" title=\"redolog和binlog区别\"></a>redolog和binlog区别</h2><ul>\n<li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p>\n</li>\n<li><p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</p>\n</li>\n<li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>\n</li>\n</ul>\n<h2 id=\"数据库突然断电不丢数据\"><a href=\"#数据库突然断电不丢数据\" class=\"headerlink\" title=\"数据库突然断电不丢数据\"></a>数据库突然断电不丢数据</h2><p>只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。</p>\n<h2 id=\"事务建议\"><a href=\"#事务建议\" class=\"headerlink\" title=\"事务建议\"></a>事务建议</h2><ul>\n<li>循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。</li>\n<li>优化事务里的语句顺序，减少锁时间。</li>\n<li>关注不同事务访问资源的顺序，避免死锁。</li>\n<li>创建事务之前，关注事务隔离级别。</li>\n<li>不在事务中混合使用存储引擎（MyISAM无法回滚）</li>\n</ul>\n<h2 id=\"分布式事务\"><a href=\"#分布式事务\" class=\"headerlink\" title=\"分布式事务\"></a>分布式事务</h2><p>分布式事务使用两阶段提交协议：<br>第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；<br>第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。</p>\n<h3 id=\"MySQL-自带的分布式事务\"><a href=\"#MySQL-自带的分布式事务\" class=\"headerlink\" title=\"MySQL 自带的分布式事务\"></a>MySQL 自带的分布式事务</h3><pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">xa start 'a','a_1'; //启动分支事务\nxa end 'a','a_1'; //结束分支事务\nxa prepare 'a','a_1'; //进入准备状态\nxa commit 'a','a_1';  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><p>事务就是一组原子性的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。</p>\n<h3 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h3><ul>\n<li>atomicity（原子性） ：要么全执行，要么全都不执行；</li>\n<li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li>\n<li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li>\n<li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li>\n</ul>\n<p>InnoDB 采用 redo log 机制来保证事务更新的一致性和持久性。</p>\n<h3 id=\"并发事务可能存在的问题\"><a href=\"#并发事务可能存在的问题\" class=\"headerlink\" title=\"并发事务可能存在的问题\"></a>并发事务可能存在的问题</h3><ul>\n<li>脏读：事务 A 读取了事务 B 当前更新的数据，但是事务 B 出现了回滚或未提交修改，事务 A 读到的数据就被称为 “脏数据”。通常情况下，使用 “脏数据” 会造成系统数据不一致，出现错误</li>\n<li>不可重复读：事务 A 在执行过程中多次读取同一数据，但是事务 B 在事务 A 的读取过程中对数据做了多次修改并提交，则会导致事务 A 多次读取的数据不一致，进而无法做出准确性判断</li>\n<li>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>\n</ul>\n<h3 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h3><ul>\n<li>READ-UNCOMMITTED：，一个事务还没提交时，它做的变更就能被别的事务看到。</li>\n<li>READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。</li>\n<li>REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li>\n<li>SERIALIZABLE：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>\n</ul>\n<h3 id=\"事务隔离的实现\"><a href=\"#事务隔离的实现\" class=\"headerlink\" title=\"事务隔离的实现\"></a>事务隔离的实现</h3><p>数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>\n<p>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</p>\n<p>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</p>\n<p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</p>\n<p>而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>\n<h2 id=\"事务可见性分析（RR）\"><a href=\"#事务可见性分析（RR）\" class=\"headerlink\" title=\"事务可见性分析（RR）\"></a>事务可见性分析（RR）</h2><p>这个事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为低水位，最大值加1记为高水位。活跃事务ID数组。</p>\n<p>row trx_id&lt;低水位：表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</p>\n<p>低水位&lt;row trx_id&lt;高水位：在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。</p>\n<p>row trx_id&gt;高水位：由将来启动的事务生成的，是肯定不可见的；</p>\n<p>也可以从事务启动时间来看：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p>\n<ol>\n<li>版本未提交，不可见；</li>\n<li>版本已提交，但是是在视图创建后提交的，不可见；</li>\n<li>版本已提交，而且是在视图创建前提交的，可见。</li>\n</ol>\n<p>注意：</p>\n<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</p>\n<p>select * from t where id=1加上lock in share mode 或for update，也是当前读。</p>\n<h2 id=\"Redo-log\"><a href=\"#Redo-log\" class=\"headerlink\" title=\"Redo log\"></a>Redo log</h2><p>Redo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。</p>\n<p>Redo log 由两部分组成：</p>\n<ul>\n<li>内存中的重做日志缓冲（redo log buffer）</li>\n<li>重做日志文件（redo log file）</li>\n</ul>\n<p>每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：</p>\n<ul>\n<li>0：表示每次事务提交时都只是把redo log留在redo log buffer中;</li>\n<li>1：表示每次事务提交时都将redo log直接持久化到磁盘；</li>\n<li>2：表示每次事务提交时都只是把redo log写到page cache。<br>innodb_flush_log_at_trx_commit 参数的默认值是 1</li>\n</ul>\n<p>除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。</p>\n<h2 id=\"Binlog\"><a href=\"#Binlog\" class=\"headerlink\" title=\"Binlog\"></a>Binlog</h2><p>二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）</p>\n<p>Binlog 有以下几个作用：</p>\n<ul>\n<li>恢复：数据恢复时可以使用二进制日志</li>\n<li>复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步</li>\n<li>审计：可以通过二进制日志进行审计数据的变更操作</li>\n</ul>\n<p>sync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。</p>\n<ul>\n<li>sync_binlog=0，表示每次提交事务都只write，不fsync</li>\n<li>sync_binlog=1，表示每次提交事务都会执行fsync</li>\n<li>sync_binlog=N(N&gt;1)，表示每次提交事务都write，累积N个事务后才fsync</li>\n</ul>\n<p><strong>binlog格式</strong></p>\n<p>当binlog_format=statement时，binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用</p>\n<p>当binlog_format使用row格式的时候，binlog里面记录了真实删除行的主键id，这样binlog传到备库去的时候，就肯定会删除id=4的行，不会有主备删除不同行的问题，缺点是很占空间。而且利于恢复数据。</p>\n<p>mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。</p>\n<h2 id=\"redolog和binlog区别\"><a href=\"#redolog和binlog区别\" class=\"headerlink\" title=\"redolog和binlog区别\"></a>redolog和binlog区别</h2><ul>\n<li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p>\n</li>\n<li><p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</p>\n</li>\n<li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>\n</li>\n</ul>\n<h2 id=\"数据库突然断电不丢数据\"><a href=\"#数据库突然断电不丢数据\" class=\"headerlink\" title=\"数据库突然断电不丢数据\"></a>数据库突然断电不丢数据</h2><p>只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。</p>\n<h2 id=\"事务建议\"><a href=\"#事务建议\" class=\"headerlink\" title=\"事务建议\"></a>事务建议</h2><ul>\n<li>循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。</li>\n<li>优化事务里的语句顺序，减少锁时间。</li>\n<li>关注不同事务访问资源的顺序，避免死锁。</li>\n<li>创建事务之前，关注事务隔离级别。</li>\n<li>不在事务中混合使用存储引擎（MyISAM无法回滚）</li>\n</ul>\n<h2 id=\"分布式事务\"><a href=\"#分布式事务\" class=\"headerlink\" title=\"分布式事务\"></a>分布式事务</h2><p>分布式事务使用两阶段提交协议：<br>第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；<br>第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。</p>\n<h3 id=\"MySQL-自带的分布式事务\"><a href=\"#MySQL-自带的分布式事务\" class=\"headerlink\" title=\"MySQL 自带的分布式事务\"></a>MySQL 自带的分布式事务</h3><pre><code class=\"mysql\">xa start &#39;a&#39;,&#39;a_1&#39;; //启动分支事务\nxa end &#39;a&#39;,&#39;a_1&#39;; //结束分支事务\nxa prepare &#39;a&#39;,&#39;a_1&#39;; //进入准备状态\nxa commit &#39;a&#39;,&#39;a_1&#39;;  //提交分支事务\nxa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息</code></pre>\n"},{"title":"分库分表","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-15T11:41:26.000Z","password":null,"summary":null,"_content":"\n## 垂直拆分\n\n- 有多个业务，每个业务单独分到一个实例里面。\n- 在一个实例中有多个库，把这些库分别放到单独的实例中。\n- 在一个库中存在过多的表，把这些表拆分到多个库中。\n- 把字段过多的表拆分成多个表，每张表包含一部分字段。\n\n\n\n## 水平拆分\n\n把同一张表分为多张表结构相同的表，每张表里存储一部分数据。拆分的算法也比较多，常见的就是取模、范围、和全局表等。\n\n## 分库分表场景\n\n1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟\n\n2、不同库表之间性能相互影响\n\n","source":"_posts/分库分表.md","raw":"---\ntitle: 分库分表\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-15 19:41:26\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 垂直拆分\n\n- 有多个业务，每个业务单独分到一个实例里面。\n- 在一个实例中有多个库，把这些库分别放到单独的实例中。\n- 在一个库中存在过多的表，把这些表拆分到多个库中。\n- 把字段过多的表拆分成多个表，每张表包含一部分字段。\n\n\n\n## 水平拆分\n\n把同一张表分为多张表结构相同的表，每张表里存储一部分数据。拆分的算法也比较多，常见的就是取模、范围、和全局表等。\n\n## 分库分表场景\n\n1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟\n\n2、不同库表之间性能相互影响\n\n","slug":"分库分表","published":1,"updated":"2021-04-01T23:01:50.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxll004qncufspoqs1fq","content":"<h2 id=\"垂直拆分\"><a href=\"#垂直拆分\" class=\"headerlink\" title=\"垂直拆分\"></a>垂直拆分</h2><ul>\n<li>有多个业务，每个业务单独分到一个实例里面。</li>\n<li>在一个实例中有多个库，把这些库分别放到单独的实例中。</li>\n<li>在一个库中存在过多的表，把这些表拆分到多个库中。</li>\n<li>把字段过多的表拆分成多个表，每张表包含一部分字段。</li>\n</ul>\n<h2 id=\"水平拆分\"><a href=\"#水平拆分\" class=\"headerlink\" title=\"水平拆分\"></a>水平拆分</h2><p>把同一张表分为多张表结构相同的表，每张表里存储一部分数据。拆分的算法也比较多，常见的就是取模、范围、和全局表等。</p>\n<h2 id=\"分库分表场景\"><a href=\"#分库分表场景\" class=\"headerlink\" title=\"分库分表场景\"></a>分库分表场景</h2><p>1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟</p>\n<p>2、不同库表之间性能相互影响</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"垂直拆分\"><a href=\"#垂直拆分\" class=\"headerlink\" title=\"垂直拆分\"></a>垂直拆分</h2><ul>\n<li>有多个业务，每个业务单独分到一个实例里面。</li>\n<li>在一个实例中有多个库，把这些库分别放到单独的实例中。</li>\n<li>在一个库中存在过多的表，把这些表拆分到多个库中。</li>\n<li>把字段过多的表拆分成多个表，每张表包含一部分字段。</li>\n</ul>\n<h2 id=\"水平拆分\"><a href=\"#水平拆分\" class=\"headerlink\" title=\"水平拆分\"></a>水平拆分</h2><p>把同一张表分为多张表结构相同的表，每张表里存储一部分数据。拆分的算法也比较多，常见的就是取模、范围、和全局表等。</p>\n<h2 id=\"分库分表场景\"><a href=\"#分库分表场景\" class=\"headerlink\" title=\"分库分表场景\"></a>分库分表场景</h2><p>1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟</p>\n<p>2、不同库表之间性能相互影响</p>\n"},{"title":"分页查询优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T09:15:47.000Z","password":null,"summary":null,"_content":"\n## 自增且连续主键的分页查询\n\n避免前n条记录的读取[mysql manual][https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html]，可以采用：\n\n```mysql\nselect * from t1 where id >99000 limit 2;\n```\n\n要求主链连续且自增，否则很多时候不适用。\n\n## 非主键字段排序的分页查询\n\n可能不走索引\n\n```mysql\nselect * from t1 order by a limit 99000,2;\n```\n\n优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录\n\n```mysql\nselect * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;\n```\n\n","source":"_posts/分页查询优化.md","raw":"---\ntitle: 分页查询优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 17:15:47\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 自增且连续主键的分页查询\n\n避免前n条记录的读取[mysql manual][https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html]，可以采用：\n\n```mysql\nselect * from t1 where id >99000 limit 2;\n```\n\n要求主链连续且自增，否则很多时候不适用。\n\n## 非主键字段排序的分页查询\n\n可能不走索引\n\n```mysql\nselect * from t1 order by a limit 99000,2;\n```\n\n优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录\n\n```mysql\nselect * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;\n```\n\n","slug":"分页查询优化","published":1,"updated":"2021-04-01T23:01:50.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxlp004tncufzrmkbbx1","content":"<h2 id=\"自增且连续主键的分页查询\"><a href=\"#自增且连续主键的分页查询\" class=\"headerlink\" title=\"自增且连续主键的分页查询\"></a>自增且连续主键的分页查询</h2><p>避免前n条记录的读取[mysql manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html]，可以采用：\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html]，可以采用：</a></p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where id >99000 limit 2;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>要求主链连续且自增，否则很多时候不适用。</p>\n<h2 id=\"非主键字段排序的分页查询\"><a href=\"#非主键字段排序的分页查询\" class=\"headerlink\" title=\"非主键字段排序的分页查询\"></a>非主键字段排序的分页查询</h2><p>可能不走索引</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 order by a limit 99000,2;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"自增且连续主键的分页查询\"><a href=\"#自增且连续主键的分页查询\" class=\"headerlink\" title=\"自增且连续主键的分页查询\"></a>自增且连续主键的分页查询</h2><p>避免前n条记录的读取[mysql manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html]，可以采用：\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html]，可以采用：</a></p>\n<pre><code class=\"mysql\">select * from t1 where id &gt;99000 limit 2;</code></pre>\n<p>要求主链连续且自增，否则很多时候不适用。</p>\n<h2 id=\"非主键字段排序的分页查询\"><a href=\"#非主键字段排序的分页查询\" class=\"headerlink\" title=\"非主键字段排序的分页查询\"></a>非主键字段排序的分页查询</h2><p>可能不走索引</p>\n<pre><code class=\"mysql\">select * from t1 order by a limit 99000,2;</code></pre>\n<p>优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录</p>\n<pre><code class=\"mysql\">select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;</code></pre>\n"},{"title":"基于多CPU多核架构的redis性能优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-10-26T13:40:55.000Z","password":null,"summary":null,"_content":"\n## CPU架构\n\n- 一个 CPU 处理器中一般有多个物理核。\n- 每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。\n- 不同的物理核还会共享一个共同的三级缓存\n- 每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存\n- 不同处理器间通过总线连接\n\n## 问题\n\n1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）\n\n2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。\n\n3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。\n\n## 优化\n\n1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上\n2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。\n3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。\n\n注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。","source":"_posts/基于多CPU多核架构的redis性能优化.md","raw":"---\ntitle: 基于多CPU多核架构的redis性能优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-10-26 21:40:55\npassword:\nsummary:\ntags:\n- redis\ncategories:\n- redis\n---\n\n## CPU架构\n\n- 一个 CPU 处理器中一般有多个物理核。\n- 每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。\n- 不同的物理核还会共享一个共同的三级缓存\n- 每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存\n- 不同处理器间通过总线连接\n\n## 问题\n\n1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）\n\n2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。\n\n3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。\n\n## 优化\n\n1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上\n2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。\n3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。\n\n注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。","slug":"基于多CPU多核架构的redis性能优化","published":1,"updated":"2021-04-01T23:01:50.137Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxlt004wncufxqg6gibh","content":"<h2 id=\"CPU架构\"><a href=\"#CPU架构\" class=\"headerlink\" title=\"CPU架构\"></a>CPU架构</h2><ul>\n<li>一个 CPU 处理器中一般有多个物理核。</li>\n<li>每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。</li>\n<li>不同的物理核还会共享一个共同的三级缓存</li>\n<li>每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存</li>\n<li>不同处理器间通过总线连接</li>\n</ul>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）</p>\n<p>2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。</p>\n<p>3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上<br>2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。<br>3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。</p>\n<p>注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"CPU架构\"><a href=\"#CPU架构\" class=\"headerlink\" title=\"CPU架构\"></a>CPU架构</h2><ul>\n<li>一个 CPU 处理器中一般有多个物理核。</li>\n<li>每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。</li>\n<li>不同的物理核还会共享一个共同的三级缓存</li>\n<li>每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存</li>\n<li>不同处理器间通过总线连接</li>\n</ul>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）</p>\n<p>2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。</p>\n<p>3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上<br>2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。<br>3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。</p>\n<p>注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p>\n"},{"title":"十大经典排序算法整理汇总（附代码）","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2020-02-16T07:09:23.000Z","password":null,"summary":"本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。","_content":"\n## 前言\n\n本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。\n\n**本文并不会详细讲解每种排序算法的原理**，网上有很多很好的教程，大家可以自己去搜了看。\n\n最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 [LeetCode 912. 排序数组](https://leetcode-cn.com/problems/sort-an-array/ \"LeetCode 912. 排序数组\") 这道题。\n\n## 性质汇总\n\n> 如果发现表中有错误，请留言告知。\n\n|   算法  |   最好  |  最坏   |  平均   |  空间   |  稳定性   | 是否基于比较\n| --- | --- | --- | --- | --- | :---: | :---: |\n|  冒泡排序   |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|   选择排序  |  $O(n^2)$  |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\times$  | $\\checkmark$ |\n|   插入排序  |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|  快速排序   |  $O(n\\log n)$   |  $O(n^2)$   |  $O(n\\log n)$   |  $O(\\log n)$~$O(n)$   |  $\\times$   | $\\checkmark$ |\n|  归并排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(n)$  |  $\\checkmark$   | $\\checkmark$ |\n|   希尔排序  |  $O(n^{1.3})$   |   $O(n^2)$  |  $O(n\\log n)$~$O(n^2)$   |  $O(1)$   | $\\times$    | $\\checkmark$ |\n|  计数排序   |  $O(n+k)$   |   $O(n+k)$  |   $O(n+k)$  |  $O(n+k)$   |  $\\checkmark$   | $\\times$ |\n|   基数排序  |   $O(nk)$  |  $O(nk)$   |   $O(nk)$  |   $O(n+k)$  |  $\\checkmark$   | $\\times$ |\n|  桶排序   |   $O(n)$  |   $O(n)$  |   $O(n)$  |  $O(n+m)$   |  $\\checkmark$   | $\\times$ |\n|  堆排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(1)$  |  $\\times$   | $\\checkmark$ |\n\n\n\n> 如果表格显示有问题的话，还可以直接看下面的汇总图：\n\n![十大经典排序算法性质汇总](1.png)\n\n### 维基百科\n\n我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。\n\n**冒泡排序**  \n[https://en.wikipedia.org/wiki/Bubble_sort](https://en.wikipedia.org/wiki/Bubble_sort)\n\n**选择排序**  \n[https://en.wikipedia.org/wiki/Selection_sort](https://en.wikipedia.org/wiki/Selection_sort)\n\n**插入排序**  \n[https://en.wikipedia.org/wiki/Insertion_sort](https://en.wikipedia.org/wiki/Insertion_sort)\n\n**快速排序**  \n[https://en.wikipedia.org/wiki/Quicksort](https://en.wikipedia.org/wiki/Quicksort)\n\n**归并排序**  \n[https://en.wikipedia.org/wiki/Merge_sort](https://en.wikipedia.org/wiki/Merge_sort)\n\n**希尔排序**  \n[https://en.wikipedia.org/wiki/Shellsort](https://en.wikipedia.org/wiki/Shellsort)\n\n**计数排序**  \n[https://en.wikipedia.org/wiki/Counting_sort](https://en.wikipedia.org/wiki/Counting_sort)\n\n**基数排序**  \n[https://en.wikipedia.org/wiki/Radix_sort](https://en.wikipedia.org/wiki/Radix_sort)\n\n**桶排序**  \n[https://en.wikipedia.org/wiki/Bucket_sort](https://en.wikipedia.org/wiki/Bucket_sort)\n\n**堆排序**  \n[https://en.wikipedia.org/wiki/Heapsort](https://en.wikipedia.org/wiki/Heapsort)\n\n## 代码实现\n\n所有的排序算法接口都是相同的，也就是 `vector<int> xxxSort(vector<int>& nums)` 。只需要你传入一个 `vector<int>` 类型的数组，就能返回排序后的结果。\n\n运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。\n\n```cpp\nclass Solution {\npublic:\n    vector<int> sortArray(vector<int>& nums) {\n        return quickSort(nums);\n    }\n\n    // 冒泡排序（超时）\n    vector<int> bubbleSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = n-2; j >= i; --j) {\n                if (nums[j] > nums[j+1]) {\n                    swap(nums[j], nums[j+1]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 选择排序（超时）\n    vector<int> selectSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            int idx = i;\n            for (int j = i; j < n; ++j) {\n                if (nums[j] < nums[idx]) {\n                    idx = j;\n                }\n            }\n            swap(nums[i], nums[idx]);\n        }\n        return nums;\n    }\n\n    // 插入排序（超时）\n    vector<int> insertSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = i; j > 0 && nums[j] < nums[j-1]; --j) {\n                swap(nums[j], nums[j-1]);\n            }\n        }\n        return nums;\n    }\n\n    // 快速排序（24 ms）\n    void qSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return;\n        int m = l;\n        for (int i = l; i < r; ++i) {\n            if (nums[i] < nums[r]) {\n                swap(nums[m++], nums[i]);\n            }\n        }\n        swap(nums[m], nums[r]);\n        qSort(nums, l, m-1);\n        qSort(nums, m+1, r);\n    }\n\n    vector<int> quickSort(vector<int>& nums) {\n        int n = nums.size();\n        qSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序（192 ms）\n    vector<int> mSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return {nums[l]};\n        int m = l+(r-l)/2;\n        vector<int> lnums = mSort(nums, l, m);\n        vector<int> rnums = mSort(nums, m+1, r);\n        vector<int> res;\n        int i = 0, j = 0;\n        while (i <= m-l && j <= r-m-1) {\n            if (lnums[i] < rnums[j]) {\n                res.push_back(lnums[i++]);\n            } else {\n                res.push_back(rnums[j++]);\n            }\n        }\n        while (i <= m-l) {\n            res.push_back(lnums[i++]);\n        }\n        while (j <= r-m-1) {\n            res.push_back(rnums[j++]);\n        }\n        return res;\n    }\n\n    vector<int> mergeSort(vector<int>& nums) {\n        int n = nums.size();\n        nums = mSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序 + 非递归（80 ms）\n    vector<int> mergeSortNR(vector<int>& nums) {\n        int n = nums.size();\n        for (int len = 1; len < n; len <<= 1) {\n            for (int l = 0; l < n-len; l += 2*len) {\n                int m = l+len-1;\n                int r = min(n-1, l+2*len-1);\n                vector<int> res;\n                int i = l, j = m+1;\n                while (i <= m && j <= r) {\n                    if (nums[i] < nums[j]) {\n                        res.push_back(nums[i++]);\n                    } else {\n                        res.push_back(nums[j++]);\n                    }\n                }\n                while (i <= m) {\n                    res.push_back(nums[i++]);\n                }\n                while (j <= r) {\n                    res.push_back(nums[j++]);\n                }\n                for (int i = l; i <= r; ++i) {\n                    nums[i] = res[i-l];\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 希尔排序（40 ms）\n    vector<int> shellSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int gap = n/2; gap > 0; gap /= 2) {\n            for (int i = gap; i < n; ++i) {\n                for (int j = i; j-gap >= 0 && nums[j-gap] > nums[j]; j -= gap) {\n                    swap(nums[j-gap], nums[j]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 计数排序（32 ms）\n    vector<int> countSort(vector<int>& nums) {\n        int n = nums.size();\n        if (!n) return {};\n        int minv = *min_element(nums.begin(), nums.end());\n        int maxv = *max_element(nums.begin(), nums.end());\n        int m = maxv-minv+1;\n        vector<int> count(m, 0);\n        for (int i = 0; i < n; ++i) {\n            count[nums[i]-minv]++;\n        }\n        vector<int> res;\n        for (int i = 0; i < m; ++i) {\n            for (int j = 0; j < count[i]; ++j) {\n                res.push_back(i+minv);\n            }\n        }\n        return res;\n    }\n\n    // 基数排序（不适用于负数）\n    vector<int> radixSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int maxd = 0;\n        while (maxv > 0) {\n            maxv /= 10;\n            maxd++;\n        }\n        vector<int> count(10, 0), rank(n, 0);\n        int base = 1;\n        while (maxd > 0) {\n            count.assign(10, 0);\n            for (int i = 0; i < n; ++i) {\n                count[(nums[i]/base)%10]++;\n            }\n            for (int i = 1; i < 10; ++i) {\n                count[i] += count[i-1];\n            }\n            for (int i = n-1; i >= 0; --i) {\n                rank[--count[(nums[i]/base)%10]] = nums[i];\n            }\n            for (int i = 0; i < n; ++i) {\n                nums[i] = rank[i];\n            }\n            maxd--;\n            base *= 10;\n        }\n        return nums;\n    }\n\n    // 桶排序 (20 ms)\n    vector<int> bucketSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int minv = *min_element(nums.begin(), nums.end());\n        int bs = 1000;\n        int m = (maxv-minv)/bs+1;\n        vector<vector<int> > bucket(m);\n        for (int i = 0; i < n; ++i) {\n            bucket[(nums[i]-minv)/bs].push_back(nums[i]);\n        }\n        int idx = 0;\n        for (int i = 0; i < m; ++i) {\n            int sz = bucket[i].size();\n            bucket[i] = quickSort(bucket[i]);\n            for (int j = 0; j < sz; ++j) {\n                nums[idx++] = bucket[i][j];\n            }\n        }\n        return nums;\n    }\n\n    // 堆排序（32 ms）\n    void adjust(vector<int>& nums, int p, int s) {\n        while (2*p+1 < s) {\n            int c1 = 2*p+1;\n            int c2 = 2*p+2;\n            int c = (c2<s && nums[c2]>nums[c1]) ? c2 : c1;\n            if (nums[c] > nums[p]) swap(nums[c], nums[p]);\n            else break;\n            p = c;\n        }\n    }\n\n    vector<int> heapSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = n/2-1; i >= 0; --i) {\n            adjust(nums, i, n);\n        }\n        for (int i = n-1; i > 0; --i) {\n            swap(nums[0], nums[i]);\n            adjust(nums, 0, i);\n        }\n        return nums;\n    }\n};\n```","source":"_posts/sort-algorithms.md","raw":"---\ntitle: 十大经典排序算法整理汇总（附代码）\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2020-02-16 15:09:23\npassword:\nsummary: 本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。\ntags:\n- 算法\ncategories:\n- 算法\n---\n\n## 前言\n\n本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。\n\n**本文并不会详细讲解每种排序算法的原理**，网上有很多很好的教程，大家可以自己去搜了看。\n\n最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 [LeetCode 912. 排序数组](https://leetcode-cn.com/problems/sort-an-array/ \"LeetCode 912. 排序数组\") 这道题。\n\n## 性质汇总\n\n> 如果发现表中有错误，请留言告知。\n\n|   算法  |   最好  |  最坏   |  平均   |  空间   |  稳定性   | 是否基于比较\n| --- | --- | --- | --- | --- | :---: | :---: |\n|  冒泡排序   |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|   选择排序  |  $O(n^2)$  |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\times$  | $\\checkmark$ |\n|   插入排序  |  $O(n)$   |   $O(n^2)$  |  $O(n^2)$   |  $O(1)$   | $\\checkmark$  | $\\checkmark$ |\n|  快速排序   |  $O(n\\log n)$   |  $O(n^2)$   |  $O(n\\log n)$   |  $O(\\log n)$~$O(n)$   |  $\\times$   | $\\checkmark$ |\n|  归并排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(n)$  |  $\\checkmark$   | $\\checkmark$ |\n|   希尔排序  |  $O(n^{1.3})$   |   $O(n^2)$  |  $O(n\\log n)$~$O(n^2)$   |  $O(1)$   | $\\times$    | $\\checkmark$ |\n|  计数排序   |  $O(n+k)$   |   $O(n+k)$  |   $O(n+k)$  |  $O(n+k)$   |  $\\checkmark$   | $\\times$ |\n|   基数排序  |   $O(nk)$  |  $O(nk)$   |   $O(nk)$  |   $O(n+k)$  |  $\\checkmark$   | $\\times$ |\n|  桶排序   |   $O(n)$  |   $O(n)$  |   $O(n)$  |  $O(n+m)$   |  $\\checkmark$   | $\\times$ |\n|  堆排序   |  $O(n\\log n)$   |   $O(n\\log n)$  |  $O(n\\log n)$   |   $O(1)$  |  $\\times$   | $\\checkmark$ |\n\n\n\n> 如果表格显示有问题的话，还可以直接看下面的汇总图：\n\n![十大经典排序算法性质汇总](1.png)\n\n### 维基百科\n\n我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。\n\n**冒泡排序**  \n[https://en.wikipedia.org/wiki/Bubble_sort](https://en.wikipedia.org/wiki/Bubble_sort)\n\n**选择排序**  \n[https://en.wikipedia.org/wiki/Selection_sort](https://en.wikipedia.org/wiki/Selection_sort)\n\n**插入排序**  \n[https://en.wikipedia.org/wiki/Insertion_sort](https://en.wikipedia.org/wiki/Insertion_sort)\n\n**快速排序**  \n[https://en.wikipedia.org/wiki/Quicksort](https://en.wikipedia.org/wiki/Quicksort)\n\n**归并排序**  \n[https://en.wikipedia.org/wiki/Merge_sort](https://en.wikipedia.org/wiki/Merge_sort)\n\n**希尔排序**  \n[https://en.wikipedia.org/wiki/Shellsort](https://en.wikipedia.org/wiki/Shellsort)\n\n**计数排序**  \n[https://en.wikipedia.org/wiki/Counting_sort](https://en.wikipedia.org/wiki/Counting_sort)\n\n**基数排序**  \n[https://en.wikipedia.org/wiki/Radix_sort](https://en.wikipedia.org/wiki/Radix_sort)\n\n**桶排序**  \n[https://en.wikipedia.org/wiki/Bucket_sort](https://en.wikipedia.org/wiki/Bucket_sort)\n\n**堆排序**  \n[https://en.wikipedia.org/wiki/Heapsort](https://en.wikipedia.org/wiki/Heapsort)\n\n## 代码实现\n\n所有的排序算法接口都是相同的，也就是 `vector<int> xxxSort(vector<int>& nums)` 。只需要你传入一个 `vector<int>` 类型的数组，就能返回排序后的结果。\n\n运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。\n\n```cpp\nclass Solution {\npublic:\n    vector<int> sortArray(vector<int>& nums) {\n        return quickSort(nums);\n    }\n\n    // 冒泡排序（超时）\n    vector<int> bubbleSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = n-2; j >= i; --j) {\n                if (nums[j] > nums[j+1]) {\n                    swap(nums[j], nums[j+1]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 选择排序（超时）\n    vector<int> selectSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            int idx = i;\n            for (int j = i; j < n; ++j) {\n                if (nums[j] < nums[idx]) {\n                    idx = j;\n                }\n            }\n            swap(nums[i], nums[idx]);\n        }\n        return nums;\n    }\n\n    // 插入排序（超时）\n    vector<int> insertSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = 0; i < n; ++i) {\n            for (int j = i; j > 0 && nums[j] < nums[j-1]; --j) {\n                swap(nums[j], nums[j-1]);\n            }\n        }\n        return nums;\n    }\n\n    // 快速排序（24 ms）\n    void qSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return;\n        int m = l;\n        for (int i = l; i < r; ++i) {\n            if (nums[i] < nums[r]) {\n                swap(nums[m++], nums[i]);\n            }\n        }\n        swap(nums[m], nums[r]);\n        qSort(nums, l, m-1);\n        qSort(nums, m+1, r);\n    }\n\n    vector<int> quickSort(vector<int>& nums) {\n        int n = nums.size();\n        qSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序（192 ms）\n    vector<int> mSort(vector<int>& nums, int l, int r) {\n        if (l >= r) return {nums[l]};\n        int m = l+(r-l)/2;\n        vector<int> lnums = mSort(nums, l, m);\n        vector<int> rnums = mSort(nums, m+1, r);\n        vector<int> res;\n        int i = 0, j = 0;\n        while (i <= m-l && j <= r-m-1) {\n            if (lnums[i] < rnums[j]) {\n                res.push_back(lnums[i++]);\n            } else {\n                res.push_back(rnums[j++]);\n            }\n        }\n        while (i <= m-l) {\n            res.push_back(lnums[i++]);\n        }\n        while (j <= r-m-1) {\n            res.push_back(rnums[j++]);\n        }\n        return res;\n    }\n\n    vector<int> mergeSort(vector<int>& nums) {\n        int n = nums.size();\n        nums = mSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序 + 非递归（80 ms）\n    vector<int> mergeSortNR(vector<int>& nums) {\n        int n = nums.size();\n        for (int len = 1; len < n; len <<= 1) {\n            for (int l = 0; l < n-len; l += 2*len) {\n                int m = l+len-1;\n                int r = min(n-1, l+2*len-1);\n                vector<int> res;\n                int i = l, j = m+1;\n                while (i <= m && j <= r) {\n                    if (nums[i] < nums[j]) {\n                        res.push_back(nums[i++]);\n                    } else {\n                        res.push_back(nums[j++]);\n                    }\n                }\n                while (i <= m) {\n                    res.push_back(nums[i++]);\n                }\n                while (j <= r) {\n                    res.push_back(nums[j++]);\n                }\n                for (int i = l; i <= r; ++i) {\n                    nums[i] = res[i-l];\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 希尔排序（40 ms）\n    vector<int> shellSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int gap = n/2; gap > 0; gap /= 2) {\n            for (int i = gap; i < n; ++i) {\n                for (int j = i; j-gap >= 0 && nums[j-gap] > nums[j]; j -= gap) {\n                    swap(nums[j-gap], nums[j]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 计数排序（32 ms）\n    vector<int> countSort(vector<int>& nums) {\n        int n = nums.size();\n        if (!n) return {};\n        int minv = *min_element(nums.begin(), nums.end());\n        int maxv = *max_element(nums.begin(), nums.end());\n        int m = maxv-minv+1;\n        vector<int> count(m, 0);\n        for (int i = 0; i < n; ++i) {\n            count[nums[i]-minv]++;\n        }\n        vector<int> res;\n        for (int i = 0; i < m; ++i) {\n            for (int j = 0; j < count[i]; ++j) {\n                res.push_back(i+minv);\n            }\n        }\n        return res;\n    }\n\n    // 基数排序（不适用于负数）\n    vector<int> radixSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int maxd = 0;\n        while (maxv > 0) {\n            maxv /= 10;\n            maxd++;\n        }\n        vector<int> count(10, 0), rank(n, 0);\n        int base = 1;\n        while (maxd > 0) {\n            count.assign(10, 0);\n            for (int i = 0; i < n; ++i) {\n                count[(nums[i]/base)%10]++;\n            }\n            for (int i = 1; i < 10; ++i) {\n                count[i] += count[i-1];\n            }\n            for (int i = n-1; i >= 0; --i) {\n                rank[--count[(nums[i]/base)%10]] = nums[i];\n            }\n            for (int i = 0; i < n; ++i) {\n                nums[i] = rank[i];\n            }\n            maxd--;\n            base *= 10;\n        }\n        return nums;\n    }\n\n    // 桶排序 (20 ms)\n    vector<int> bucketSort(vector<int>& nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int minv = *min_element(nums.begin(), nums.end());\n        int bs = 1000;\n        int m = (maxv-minv)/bs+1;\n        vector<vector<int> > bucket(m);\n        for (int i = 0; i < n; ++i) {\n            bucket[(nums[i]-minv)/bs].push_back(nums[i]);\n        }\n        int idx = 0;\n        for (int i = 0; i < m; ++i) {\n            int sz = bucket[i].size();\n            bucket[i] = quickSort(bucket[i]);\n            for (int j = 0; j < sz; ++j) {\n                nums[idx++] = bucket[i][j];\n            }\n        }\n        return nums;\n    }\n\n    // 堆排序（32 ms）\n    void adjust(vector<int>& nums, int p, int s) {\n        while (2*p+1 < s) {\n            int c1 = 2*p+1;\n            int c2 = 2*p+2;\n            int c = (c2<s && nums[c2]>nums[c1]) ? c2 : c1;\n            if (nums[c] > nums[p]) swap(nums[c], nums[p]);\n            else break;\n            p = c;\n        }\n    }\n\n    vector<int> heapSort(vector<int>& nums) {\n        int n = nums.size();\n        for (int i = n/2-1; i >= 0; --i) {\n            adjust(nums, i, n);\n        }\n        for (int i = n-1; i > 0; --i) {\n            swap(nums[0], nums[i]);\n            adjust(nums, 0, i);\n        }\n        return nums;\n    }\n};\n```","slug":"sort-algorithms","published":1,"updated":"2021-04-01T23:01:50.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxly004zncuftkgk2cg1","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。</p>\n<p><strong>本文并不会详细讲解每种排序算法的原理</strong>，网上有很多很好的教程，大家可以自己去搜了看。</p>\n<p>最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 <a href=\"https://leetcode-cn.com/problems/sort-an-array/\" title=\"LeetCode 912. 排序数组\" target=\"_blank\" rel=\"noopener\">LeetCode 912. 排序数组</a> 这道题。</p>\n<h2 id=\"性质汇总\"><a href=\"#性质汇总\" class=\"headerlink\" title=\"性质汇总\"></a>性质汇总</h2><blockquote>\n<p>如果发现表中有错误，请留言告知。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>最好</th>\n<th>最坏</th>\n<th>平均</th>\n<th>空间</th>\n<th align=\"center\">稳定性</th>\n<th align=\"center\">是否基于比较</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>冒泡排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>选择排序</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>插入排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>快速排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(\\log n)$~$O(n)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>归并排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>希尔排序</td>\n<td>$O(n^{1.3})$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$~$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>计数排序</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>基数排序</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>桶排序</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n+m)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>堆排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>如果表格显示有问题的话，还可以直接看下面的汇总图：</p>\n</blockquote>\n<p><img src=\"1.png\" alt=\"十大经典排序算法性质汇总\"></p>\n<h3 id=\"维基百科\"><a href=\"#维基百科\" class=\"headerlink\" title=\"维基百科\"></a>维基百科</h3><p>我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。</p>\n<p><strong>冒泡排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bubble_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bubble_sort</a></p>\n<p><strong>选择排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Selection_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Selection_sort</a></p>\n<p><strong>插入排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Insertion_sort</a></p>\n<p><strong>快速排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Quicksort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Quicksort</a></p>\n<p><strong>归并排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Merge_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Merge_sort</a></p>\n<p><strong>希尔排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Shellsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Shellsort</a></p>\n<p><strong>计数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Counting_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Counting_sort</a></p>\n<p><strong>基数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Radix_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Radix_sort</a></p>\n<p><strong>桶排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bucket_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bucket_sort</a></p>\n<p><strong>堆排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Heapsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Heapsort</a></p>\n<h2 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>所有的排序算法接口都是相同的，也就是 <code>vector&lt;int&gt; xxxSort(vector&lt;int&gt;&amp; nums)</code> 。只需要你传入一个 <code>vector&lt;int&gt;</code> 类型的数组，就能返回排序后的结果。</p>\n<p>运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。</p>\n<pre class=\"line-numbers language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Solution</span> <span class=\"token punctuation\">{</span>\n<span class=\"token keyword\">public</span><span class=\"token operator\">:</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">sortArray</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> <span class=\"token function\">quickSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 冒泡排序（超时）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">bubbleSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> n<span class=\"token number\">-2</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">>=</span> i<span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 选择排序（超时）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">selectSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    idx <span class=\"token operator\">=</span> j<span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 插入排序（超时）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">insertSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token operator\">&amp;&amp;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 快速排序（24 ms）</span>\n    <span class=\"token keyword\">void</span> <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> l<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>l <span class=\"token operator\">>=</span> r<span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> r<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>r<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>m<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>r<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> l<span class=\"token punctuation\">,</span> m<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> m<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">quickSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">qSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 归并排序（192 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> l<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>l <span class=\"token operator\">>=</span> r<span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>nums<span class=\"token punctuation\">[</span>l<span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> l<span class=\"token operator\">+</span><span class=\"token punctuation\">(</span>r<span class=\"token operator\">-</span>l<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> lnums <span class=\"token operator\">=</span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> l<span class=\"token punctuation\">,</span> m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> rnums <span class=\"token operator\">=</span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> m<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> res<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> j <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m<span class=\"token operator\">-</span>l <span class=\"token operator\">&amp;&amp;</span> j <span class=\"token operator\">&lt;=</span> r<span class=\"token operator\">-</span>m<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>lnums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> rnums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>lnums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n                res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>rnums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m<span class=\"token operator\">-</span>l<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>lnums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>j <span class=\"token operator\">&lt;=</span> r<span class=\"token operator\">-</span>m<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>rnums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> res<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">mergeSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        nums <span class=\"token operator\">=</span> <span class=\"token function\">mSort</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 归并排序 + 非递归（80 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">mergeSortNR</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> len <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> len <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> len <span class=\"token operator\">&lt;&lt;=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> l <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> l <span class=\"token operator\">&lt;</span> n<span class=\"token operator\">-</span>len<span class=\"token punctuation\">;</span> l <span class=\"token operator\">+</span><span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>len<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> l<span class=\"token operator\">+</span>len<span class=\"token number\">-1</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">int</span> r <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span>n<span class=\"token number\">-1</span><span class=\"token punctuation\">,</span> l<span class=\"token operator\">+</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>len<span class=\"token number\">-1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> res<span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> l<span class=\"token punctuation\">,</span> j <span class=\"token operator\">=</span> m<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m <span class=\"token operator\">&amp;&amp;</span> j <span class=\"token operator\">&lt;=</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                        res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n                        res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span>\n                <span class=\"token punctuation\">}</span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;=</span> m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>j <span class=\"token operator\">&lt;=</span> r<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n                <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;=</span> r<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> res<span class=\"token punctuation\">[</span>i<span class=\"token operator\">-</span>l<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 希尔排序（40 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">shellSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> gap <span class=\"token operator\">=</span> n<span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span> gap <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> gap <span class=\"token operator\">/</span><span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> gap<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j<span class=\"token operator\">-</span>gap <span class=\"token operator\">>=</span> <span class=\"token number\">0</span> <span class=\"token operator\">&amp;&amp;</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">-</span>gap<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">-</span><span class=\"token operator\">=</span> gap<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>j<span class=\"token operator\">-</span>gap<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 计数排序（32 ms）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">countSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> minv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">min_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">max_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> maxv<span class=\"token operator\">-</span>minv<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            count<span class=\"token punctuation\">[</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">-</span>minv<span class=\"token punctuation\">]</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> res<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> m<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">&lt;</span> count<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                res<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>i<span class=\"token operator\">+</span>minv<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> res<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 基数排序（不适用于负数）</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">radixSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">max_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxd <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>maxv <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            maxv <span class=\"token operator\">/</span><span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n            maxd<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token function\">rank</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> base <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>maxd <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            count<span class=\"token punctuation\">.</span><span class=\"token function\">assign</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                count<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>base<span class=\"token punctuation\">)</span><span class=\"token operator\">%</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                count<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span><span class=\"token operator\">=</span> count<span class=\"token punctuation\">[</span>i<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                rank<span class=\"token punctuation\">[</span><span class=\"token operator\">--</span>count<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">/</span>base<span class=\"token punctuation\">)</span><span class=\"token operator\">%</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> rank<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            maxd<span class=\"token operator\">--</span><span class=\"token punctuation\">;</span>\n            base <span class=\"token operator\">*</span><span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 桶排序 (20 ms)</span>\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">bucketSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> maxv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">max_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> minv <span class=\"token operator\">=</span> <span class=\"token operator\">*</span><span class=\"token function\">min_element</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">.</span><span class=\"token function\">begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">end</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> bs <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>maxv<span class=\"token operator\">-</span>minv<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>bs<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        vector<span class=\"token operator\">&lt;</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token operator\">></span> <span class=\"token function\">bucket</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            bucket<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">-</span>minv<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>bs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> m<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">int</span> sz <span class=\"token operator\">=</span> bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token function\">quickSort</span><span class=\"token punctuation\">(</span>bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">&lt;</span> sz<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>j<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                nums<span class=\"token punctuation\">[</span>idx<span class=\"token operator\">++</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> bucket<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 堆排序（32 ms）</span>\n    <span class=\"token keyword\">void</span> <span class=\"token function\">adjust</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> p<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>p<span class=\"token operator\">+</span><span class=\"token number\">1</span> <span class=\"token operator\">&lt;</span> s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">int</span> c1 <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>p<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">int</span> c2 <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token operator\">*</span>p<span class=\"token operator\">+</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">int</span> c <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>c2<span class=\"token operator\">&lt;</span>s <span class=\"token operator\">&amp;&amp;</span> nums<span class=\"token punctuation\">[</span>c2<span class=\"token punctuation\">]</span><span class=\"token operator\">></span>nums<span class=\"token punctuation\">[</span>c1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">?</span> c2 <span class=\"token operator\">:</span> c1<span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>c<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>p<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span>c<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>p<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">else</span> <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n            p <span class=\"token operator\">=</span> c<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span> <span class=\"token function\">heapSort</span><span class=\"token punctuation\">(</span>vector<span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> nums<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> n<span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token function\">adjust</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> n<span class=\"token number\">-1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token function\">swap</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> nums<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token function\">adjust</span><span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> nums<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。</p>\n<p><strong>本文并不会详细讲解每种排序算法的原理</strong>，网上有很多很好的教程，大家可以自己去搜了看。</p>\n<p>最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 <a href=\"https://leetcode-cn.com/problems/sort-an-array/\" title=\"LeetCode 912. 排序数组\" target=\"_blank\" rel=\"noopener\">LeetCode 912. 排序数组</a> 这道题。</p>\n<h2 id=\"性质汇总\"><a href=\"#性质汇总\" class=\"headerlink\" title=\"性质汇总\"></a>性质汇总</h2><blockquote>\n<p>如果发现表中有错误，请留言告知。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>最好</th>\n<th>最坏</th>\n<th>平均</th>\n<th>空间</th>\n<th align=\"center\">稳定性</th>\n<th align=\"center\">是否基于比较</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>冒泡排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>选择排序</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>插入排序</td>\n<td>$O(n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>快速排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(\\log n)$~$O(n)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>归并排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>希尔排序</td>\n<td>$O(n^{1.3})$</td>\n<td>$O(n^2)$</td>\n<td>$O(n\\log n)$~$O(n^2)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n<tr>\n<td>计数排序</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>基数排序</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(nk)$</td>\n<td>$O(n+k)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>桶排序</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n)$</td>\n<td>$O(n+m)$</td>\n<td align=\"center\">$\\checkmark$</td>\n<td align=\"center\">$\\times$</td>\n</tr>\n<tr>\n<td>堆排序</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(n\\log n)$</td>\n<td>$O(1)$</td>\n<td align=\"center\">$\\times$</td>\n<td align=\"center\">$\\checkmark$</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>如果表格显示有问题的话，还可以直接看下面的汇总图：</p>\n</blockquote>\n<p><img src=\"1.png\" alt=\"十大经典排序算法性质汇总\"></p>\n<h3 id=\"维基百科\"><a href=\"#维基百科\" class=\"headerlink\" title=\"维基百科\"></a>维基百科</h3><p>我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。</p>\n<p><strong>冒泡排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bubble_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bubble_sort</a></p>\n<p><strong>选择排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Selection_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Selection_sort</a></p>\n<p><strong>插入排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Insertion_sort</a></p>\n<p><strong>快速排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Quicksort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Quicksort</a></p>\n<p><strong>归并排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Merge_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Merge_sort</a></p>\n<p><strong>希尔排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Shellsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Shellsort</a></p>\n<p><strong>计数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Counting_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Counting_sort</a></p>\n<p><strong>基数排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Radix_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Radix_sort</a></p>\n<p><strong>桶排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Bucket_sort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Bucket_sort</a></p>\n<p><strong>堆排序</strong><br><a href=\"https://en.wikipedia.org/wiki/Heapsort\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Heapsort</a></p>\n<h2 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>所有的排序算法接口都是相同的，也就是 <code>vector&lt;int&gt; xxxSort(vector&lt;int&gt;&amp; nums)</code> 。只需要你传入一个 <code>vector&lt;int&gt;</code> 类型的数组，就能返回排序后的结果。</p>\n<p>运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。</p>\n<pre><code class=\"cpp\">class Solution {\npublic:\n    vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) {\n        return quickSort(nums);\n    }\n\n    // 冒泡排序（超时）\n    vector&lt;int&gt; bubbleSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = 0; i &lt; n; ++i) {\n            for (int j = n-2; j &gt;= i; --j) {\n                if (nums[j] &gt; nums[j+1]) {\n                    swap(nums[j], nums[j+1]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 选择排序（超时）\n    vector&lt;int&gt; selectSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = 0; i &lt; n; ++i) {\n            int idx = i;\n            for (int j = i; j &lt; n; ++j) {\n                if (nums[j] &lt; nums[idx]) {\n                    idx = j;\n                }\n            }\n            swap(nums[i], nums[idx]);\n        }\n        return nums;\n    }\n\n    // 插入排序（超时）\n    vector&lt;int&gt; insertSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = 0; i &lt; n; ++i) {\n            for (int j = i; j &gt; 0 &amp;&amp; nums[j] &lt; nums[j-1]; --j) {\n                swap(nums[j], nums[j-1]);\n            }\n        }\n        return nums;\n    }\n\n    // 快速排序（24 ms）\n    void qSort(vector&lt;int&gt;&amp; nums, int l, int r) {\n        if (l &gt;= r) return;\n        int m = l;\n        for (int i = l; i &lt; r; ++i) {\n            if (nums[i] &lt; nums[r]) {\n                swap(nums[m++], nums[i]);\n            }\n        }\n        swap(nums[m], nums[r]);\n        qSort(nums, l, m-1);\n        qSort(nums, m+1, r);\n    }\n\n    vector&lt;int&gt; quickSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        qSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序（192 ms）\n    vector&lt;int&gt; mSort(vector&lt;int&gt;&amp; nums, int l, int r) {\n        if (l &gt;= r) return {nums[l]};\n        int m = l+(r-l)/2;\n        vector&lt;int&gt; lnums = mSort(nums, l, m);\n        vector&lt;int&gt; rnums = mSort(nums, m+1, r);\n        vector&lt;int&gt; res;\n        int i = 0, j = 0;\n        while (i &lt;= m-l &amp;&amp; j &lt;= r-m-1) {\n            if (lnums[i] &lt; rnums[j]) {\n                res.push_back(lnums[i++]);\n            } else {\n                res.push_back(rnums[j++]);\n            }\n        }\n        while (i &lt;= m-l) {\n            res.push_back(lnums[i++]);\n        }\n        while (j &lt;= r-m-1) {\n            res.push_back(rnums[j++]);\n        }\n        return res;\n    }\n\n    vector&lt;int&gt; mergeSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        nums = mSort(nums, 0, n-1);\n        return nums;\n    }\n\n    // 归并排序 + 非递归（80 ms）\n    vector&lt;int&gt; mergeSortNR(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int len = 1; len &lt; n; len &lt;&lt;= 1) {\n            for (int l = 0; l &lt; n-len; l += 2*len) {\n                int m = l+len-1;\n                int r = min(n-1, l+2*len-1);\n                vector&lt;int&gt; res;\n                int i = l, j = m+1;\n                while (i &lt;= m &amp;&amp; j &lt;= r) {\n                    if (nums[i] &lt; nums[j]) {\n                        res.push_back(nums[i++]);\n                    } else {\n                        res.push_back(nums[j++]);\n                    }\n                }\n                while (i &lt;= m) {\n                    res.push_back(nums[i++]);\n                }\n                while (j &lt;= r) {\n                    res.push_back(nums[j++]);\n                }\n                for (int i = l; i &lt;= r; ++i) {\n                    nums[i] = res[i-l];\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 希尔排序（40 ms）\n    vector&lt;int&gt; shellSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int gap = n/2; gap &gt; 0; gap /= 2) {\n            for (int i = gap; i &lt; n; ++i) {\n                for (int j = i; j-gap &gt;= 0 &amp;&amp; nums[j-gap] &gt; nums[j]; j -= gap) {\n                    swap(nums[j-gap], nums[j]);\n                }\n            }\n        }\n        return nums;\n    }\n\n    // 计数排序（32 ms）\n    vector&lt;int&gt; countSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        if (!n) return {};\n        int minv = *min_element(nums.begin(), nums.end());\n        int maxv = *max_element(nums.begin(), nums.end());\n        int m = maxv-minv+1;\n        vector&lt;int&gt; count(m, 0);\n        for (int i = 0; i &lt; n; ++i) {\n            count[nums[i]-minv]++;\n        }\n        vector&lt;int&gt; res;\n        for (int i = 0; i &lt; m; ++i) {\n            for (int j = 0; j &lt; count[i]; ++j) {\n                res.push_back(i+minv);\n            }\n        }\n        return res;\n    }\n\n    // 基数排序（不适用于负数）\n    vector&lt;int&gt; radixSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int maxd = 0;\n        while (maxv &gt; 0) {\n            maxv /= 10;\n            maxd++;\n        }\n        vector&lt;int&gt; count(10, 0), rank(n, 0);\n        int base = 1;\n        while (maxd &gt; 0) {\n            count.assign(10, 0);\n            for (int i = 0; i &lt; n; ++i) {\n                count[(nums[i]/base)%10]++;\n            }\n            for (int i = 1; i &lt; 10; ++i) {\n                count[i] += count[i-1];\n            }\n            for (int i = n-1; i &gt;= 0; --i) {\n                rank[--count[(nums[i]/base)%10]] = nums[i];\n            }\n            for (int i = 0; i &lt; n; ++i) {\n                nums[i] = rank[i];\n            }\n            maxd--;\n            base *= 10;\n        }\n        return nums;\n    }\n\n    // 桶排序 (20 ms)\n    vector&lt;int&gt; bucketSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        int maxv = *max_element(nums.begin(), nums.end());\n        int minv = *min_element(nums.begin(), nums.end());\n        int bs = 1000;\n        int m = (maxv-minv)/bs+1;\n        vector&lt;vector&lt;int&gt; &gt; bucket(m);\n        for (int i = 0; i &lt; n; ++i) {\n            bucket[(nums[i]-minv)/bs].push_back(nums[i]);\n        }\n        int idx = 0;\n        for (int i = 0; i &lt; m; ++i) {\n            int sz = bucket[i].size();\n            bucket[i] = quickSort(bucket[i]);\n            for (int j = 0; j &lt; sz; ++j) {\n                nums[idx++] = bucket[i][j];\n            }\n        }\n        return nums;\n    }\n\n    // 堆排序（32 ms）\n    void adjust(vector&lt;int&gt;&amp; nums, int p, int s) {\n        while (2*p+1 &lt; s) {\n            int c1 = 2*p+1;\n            int c2 = 2*p+2;\n            int c = (c2&lt;s &amp;&amp; nums[c2]&gt;nums[c1]) ? c2 : c1;\n            if (nums[c] &gt; nums[p]) swap(nums[c], nums[p]);\n            else break;\n            p = c;\n        }\n    }\n\n    vector&lt;int&gt; heapSort(vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        for (int i = n/2-1; i &gt;= 0; --i) {\n            adjust(nums, i, n);\n        }\n        for (int i = n-1; i &gt; 0; --i) {\n            swap(nums[0], nums[i]);\n            adjust(nums, 0, i);\n        }\n        return nums;\n    }\n};</code></pre>\n"},{"title":"慢查询定位与分析","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-11T13:58:12.000Z","password":null,"summary":null,"_content":"\n## 定位慢sql\n\n1、查看慢查询日志确定已经执行完的慢查询\n\n```mysql\nmysql> set global slow_query_log = on;\nmysql> set global long_query_time = 1;\nmysql> show global variables like \"datadir\";\nmysql> show global variables like \"slow_query_log_file\";\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);\n```\n\n可以看到查询时间、表锁时间、扫描行数Rows_examined。\n\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。\n\n2、show processlist 查看正在执行的慢查询\n\n```mysql\nmysql> show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`\n```\n\n可以看到执行时间和SQL语句\n\n## 分析慢查询\n\n1、使用 explain 分析慢查询\n\n获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：\n\n- select_type 查询类型：显示本行是简单还是复杂查询\n\n- type 本次查询的表连接类型\n\n- key 实际选择的索引\n\n- rows 预计需要扫描的行数，对 InnoDB 来说，这个值是估值，并不一定准确\n\n- Extra 附加信息\n\n其中\n\n| select_type          | 含义                                                        |\n| :------------------- | ----------------------------------------------------------- |\n| SIMPLE               | 简单查询(不使用关联查询或子查询)                            |\n| PRIMARY              | 如果包含关联查询或者子查询，则最外层的查询部分标记为primary |\n| UNION                | 联合查询中第二个及后面的查询                                |\n| DEPENDENT UNION      | 满足依赖外部的关联查询中第二个及以后的查询                  |\n| UNION RESULT         | 联合查询的结果                                              |\n| SUBQUERY             | 子查询中的第一个查询                                        |\n| DEPENDENT SUBQUERY   | 子查询中的第一个查询，并且依赖外部查询                      |\n| DERIVED              | 用到派生表的查询                                            |\n| MATERIALIZED         | 被物化的子查询                                              |\n| UNCACHEABLE SUBQUERY | 一个子查询的结果不能被缓存，必须重新评估外层查询的每一行    |\n| UNCACHEABLE UNION    | 关联查询第二个或后面的语句属于不可缓存的子查询              |\n\n| type            | 含义                                     |\n| :-------------- | :--------------------------------------- |\n| system          | 查询对象表只有一行数据,且只能用于        |\n| const           | 基于主键或唯一索引查询，最多返回一条结果 |\n| eq_ref          | 表连接时基于主键或非                     |\n| ref             | 基于普通索引的等值查询，或者表间等值连接 |\n| fulltext        | 全文检索                                 |\n| ref_or_null     | 表连接类型是                             |\n| index_merge     | 利用多个索引                             |\n| unique_subquery | 子查询中使用唯一索引                     |\n| index_subquery  | 子查询中使用普通索引                     |\n| range           | 利用索引进行范围查询                     |\n| index           | 全索引扫描                               |\n| ALL             | 全表扫描                                 |\n\n| Extra                                | 解释                                                         |\n| :----------------------------------- | :----------------------------------------------------------- |\n| Using filesort                       | 将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序 |\n| Using temporary                      | 需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时 |\n| Using index                          | 使用覆盖索引                                                 |\n| Using where                          | 使用 where 语句来处理结果                                    |\n| Impossible WHERE                     | 对 where 子句判断的结果总是 false 而不能选择任何数据         |\n| Using join buffer (BlockNested Loop) | 关联查询中，被驱动表的关联字段没索引                         |\n| Using index condition                | 先条件过滤索引，再查数据                                     |\n| Select tables optimized away         | 使用某些聚合函数（比如 max、min）来访问存在索引的某个字段    |\n\n2、show profile\n\n了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节\n\n```mysql\nmysql> select @@have_profiling;\nmysql> select @@profiling;\nmysql> set profiling=1;\nmysql> select * from t1 where b=1000;\nmysql> show profiles;  /*获取query id*/\nmysql> show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)\n```\n\n3、trace\n\n使用 trace 查看优化器如何选择执行计划\n\n```mysql\nmysql> set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;\n/* optimizer_trace=\"enabled=on\" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql> select * from t1 where a >900 and b > 910 order by a;\nmysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n\n```\n\nTRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。\n\n也可以看number_of_tmp_files中判断是否使用了临时文件。\n\n","source":"_posts/慢查询定位与分析.md","raw":"---\ntitle: 慢查询定位与分析\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-11 21:58:12\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 定位慢sql\n\n1、查看慢查询日志确定已经执行完的慢查询\n\n```mysql\nmysql> set global slow_query_log = on;\nmysql> set global long_query_time = 1;\nmysql> show global variables like \"datadir\";\nmysql> show global variables like \"slow_query_log_file\";\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);\n```\n\n可以看到查询时间、表锁时间、扫描行数Rows_examined。\n\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。\n\n2、show processlist 查看正在执行的慢查询\n\n```mysql\nmysql> show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`\n```\n\n可以看到执行时间和SQL语句\n\n## 分析慢查询\n\n1、使用 explain 分析慢查询\n\n获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：\n\n- select_type 查询类型：显示本行是简单还是复杂查询\n\n- type 本次查询的表连接类型\n\n- key 实际选择的索引\n\n- rows 预计需要扫描的行数，对 InnoDB 来说，这个值是估值，并不一定准确\n\n- Extra 附加信息\n\n其中\n\n| select_type          | 含义                                                        |\n| :------------------- | ----------------------------------------------------------- |\n| SIMPLE               | 简单查询(不使用关联查询或子查询)                            |\n| PRIMARY              | 如果包含关联查询或者子查询，则最外层的查询部分标记为primary |\n| UNION                | 联合查询中第二个及后面的查询                                |\n| DEPENDENT UNION      | 满足依赖外部的关联查询中第二个及以后的查询                  |\n| UNION RESULT         | 联合查询的结果                                              |\n| SUBQUERY             | 子查询中的第一个查询                                        |\n| DEPENDENT SUBQUERY   | 子查询中的第一个查询，并且依赖外部查询                      |\n| DERIVED              | 用到派生表的查询                                            |\n| MATERIALIZED         | 被物化的子查询                                              |\n| UNCACHEABLE SUBQUERY | 一个子查询的结果不能被缓存，必须重新评估外层查询的每一行    |\n| UNCACHEABLE UNION    | 关联查询第二个或后面的语句属于不可缓存的子查询              |\n\n| type            | 含义                                     |\n| :-------------- | :--------------------------------------- |\n| system          | 查询对象表只有一行数据,且只能用于        |\n| const           | 基于主键或唯一索引查询，最多返回一条结果 |\n| eq_ref          | 表连接时基于主键或非                     |\n| ref             | 基于普通索引的等值查询，或者表间等值连接 |\n| fulltext        | 全文检索                                 |\n| ref_or_null     | 表连接类型是                             |\n| index_merge     | 利用多个索引                             |\n| unique_subquery | 子查询中使用唯一索引                     |\n| index_subquery  | 子查询中使用普通索引                     |\n| range           | 利用索引进行范围查询                     |\n| index           | 全索引扫描                               |\n| ALL             | 全表扫描                                 |\n\n| Extra                                | 解释                                                         |\n| :----------------------------------- | :----------------------------------------------------------- |\n| Using filesort                       | 将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序 |\n| Using temporary                      | 需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时 |\n| Using index                          | 使用覆盖索引                                                 |\n| Using where                          | 使用 where 语句来处理结果                                    |\n| Impossible WHERE                     | 对 where 子句判断的结果总是 false 而不能选择任何数据         |\n| Using join buffer (BlockNested Loop) | 关联查询中，被驱动表的关联字段没索引                         |\n| Using index condition                | 先条件过滤索引，再查数据                                     |\n| Select tables optimized away         | 使用某些聚合函数（比如 max、min）来访问存在索引的某个字段    |\n\n2、show profile\n\n了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节\n\n```mysql\nmysql> select @@have_profiling;\nmysql> select @@profiling;\nmysql> set profiling=1;\nmysql> select * from t1 where b=1000;\nmysql> show profiles;  /*获取query id*/\nmysql> show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)\n```\n\n3、trace\n\n使用 trace 查看优化器如何选择执行计划\n\n```mysql\nmysql> set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;\n/* optimizer_trace=\"enabled=on\" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql> select * from t1 where a >900 and b > 910 order by a;\nmysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n\n```\n\nTRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。\n\n也可以看number_of_tmp_files中判断是否使用了临时文件。\n\n","slug":"慢查询定位与分析","published":1,"updated":"2021-04-01T23:01:50.177Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxm40052ncuf97exk8s4","content":"<h2 id=\"定位慢sql\"><a href=\"#定位慢sql\" class=\"headerlink\" title=\"定位慢sql\"></a>定位慢sql</h2><p>1、查看慢查询日志确定已经执行完的慢查询</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> set global slow_query_log = on;\nmysql> set global long_query_time = 1;\nmysql> show global variables like \"datadir\";\nmysql> show global variables like \"slow_query_log_file\";\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>可以看到查询时间、表锁时间、扫描行数Rows_examined。</p>\n<p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p>\n<p>2、show processlist 查看正在执行的慢查询</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>可以看到执行时间和SQL语句</p>\n<h2 id=\"分析慢查询\"><a href=\"#分析慢查询\" class=\"headerlink\" title=\"分析慢查询\"></a>分析慢查询</h2><p>1、使用 explain 分析慢查询</p>\n<p>获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：</p>\n<ul>\n<li><p>select_type 查询类型：显示本行是简单还是复杂查询</p>\n</li>\n<li><p>type 本次查询的表连接类型</p>\n</li>\n<li><p>key 实际选择的索引</p>\n</li>\n<li><p>rows 预计需要扫描的行数，对 InnoDB 来说，这个值是估值，并不一定准确</p>\n</li>\n<li><p>Extra 附加信息</p>\n</li>\n</ul>\n<p>其中</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">select_type</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">SIMPLE</td>\n<td>简单查询(不使用关联查询或子查询)</td>\n</tr>\n<tr>\n<td align=\"left\">PRIMARY</td>\n<td>如果包含关联查询或者子查询，则最外层的查询部分标记为primary</td>\n</tr>\n<tr>\n<td align=\"left\">UNION</td>\n<td>联合查询中第二个及后面的查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT UNION</td>\n<td>满足依赖外部的关联查询中第二个及以后的查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNION RESULT</td>\n<td>联合查询的结果</td>\n</tr>\n<tr>\n<td align=\"left\">SUBQUERY</td>\n<td>子查询中的第一个查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT SUBQUERY</td>\n<td>子查询中的第一个查询，并且依赖外部查询</td>\n</tr>\n<tr>\n<td align=\"left\">DERIVED</td>\n<td>用到派生表的查询</td>\n</tr>\n<tr>\n<td align=\"left\">MATERIALIZED</td>\n<td>被物化的子查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE SUBQUERY</td>\n<td>一个子查询的结果不能被缓存，必须重新评估外层查询的每一行</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE UNION</td>\n<td>关联查询第二个或后面的语句属于不可缓存的子查询</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">type</th>\n<th align=\"left\">含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">system</td>\n<td align=\"left\">查询对象表只有一行数据,且只能用于</td>\n</tr>\n<tr>\n<td align=\"left\">const</td>\n<td align=\"left\">基于主键或唯一索引查询，最多返回一条结果</td>\n</tr>\n<tr>\n<td align=\"left\">eq_ref</td>\n<td align=\"left\">表连接时基于主键或非</td>\n</tr>\n<tr>\n<td align=\"left\">ref</td>\n<td align=\"left\">基于普通索引的等值查询，或者表间等值连接</td>\n</tr>\n<tr>\n<td align=\"left\">fulltext</td>\n<td align=\"left\">全文检索</td>\n</tr>\n<tr>\n<td align=\"left\">ref_or_null</td>\n<td align=\"left\">表连接类型是</td>\n</tr>\n<tr>\n<td align=\"left\">index_merge</td>\n<td align=\"left\">利用多个索引</td>\n</tr>\n<tr>\n<td align=\"left\">unique_subquery</td>\n<td align=\"left\">子查询中使用唯一索引</td>\n</tr>\n<tr>\n<td align=\"left\">index_subquery</td>\n<td align=\"left\">子查询中使用普通索引</td>\n</tr>\n<tr>\n<td align=\"left\">range</td>\n<td align=\"left\">利用索引进行范围查询</td>\n</tr>\n<tr>\n<td align=\"left\">index</td>\n<td align=\"left\">全索引扫描</td>\n</tr>\n<tr>\n<td align=\"left\">ALL</td>\n<td align=\"left\">全表扫描</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Extra</th>\n<th align=\"left\">解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Using filesort</td>\n<td align=\"left\">将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序</td>\n</tr>\n<tr>\n<td align=\"left\">Using temporary</td>\n<td align=\"left\">需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时</td>\n</tr>\n<tr>\n<td align=\"left\">Using index</td>\n<td align=\"left\">使用覆盖索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using where</td>\n<td align=\"left\">使用 where 语句来处理结果</td>\n</tr>\n<tr>\n<td align=\"left\">Impossible WHERE</td>\n<td align=\"left\">对 where 子句判断的结果总是 false 而不能选择任何数据</td>\n</tr>\n<tr>\n<td align=\"left\">Using join buffer (BlockNested Loop)</td>\n<td align=\"left\">关联查询中，被驱动表的关联字段没索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using index condition</td>\n<td align=\"left\">先条件过滤索引，再查数据</td>\n</tr>\n<tr>\n<td align=\"left\">Select tables optimized away</td>\n<td align=\"left\">使用某些聚合函数（比如 max、min）来访问存在索引的某个字段</td>\n</tr>\n</tbody></table>\n<p>2、show profile</p>\n<p>了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> select @@have_profiling;\nmysql> select @@profiling;\nmysql> set profiling=1;\nmysql> select * from t1 where b=1000;\nmysql> show profiles;  /*获取query id*/\nmysql> show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>3、trace</p>\n<p>使用 trace 查看优化器如何选择执行计划</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">mysql> set session optimizer_trace=\"enabled=on\",end_markers_in_json=on;\n/* optimizer_trace=\"enabled=on\" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql> select * from t1 where a >900 and b > 910 order by a;\nmysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>TRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。</p>\n<p>也可以看number_of_tmp_files中判断是否使用了临时文件。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"定位慢sql\"><a href=\"#定位慢sql\" class=\"headerlink\" title=\"定位慢sql\"></a>定位慢sql</h2><p>1、查看慢查询日志确定已经执行完的慢查询</p>\n<pre><code class=\"mysql\">mysql&gt; set global slow_query_log = on;\nmysql&gt; set global long_query_time = 1;\nmysql&gt; show global variables like &quot;datadir&quot;;\nmysql&gt; show global variables like &quot;slow_query_log_file&quot;;\n\n[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.log\nTime: 2019-05-21T09:15:06.255554+08:00\nUser@Host: root[root] @ localhost [] Id: 8591152\nQuery_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0\nSET timestamp=1558401306;\nselect sleep(10);</code></pre>\n<p>可以看到查询时间、表锁时间、扫描行数Rows_examined。</p>\n<p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p>\n<p>2、show processlist 查看正在执行的慢查询</p>\n<pre><code class=\"mysql\">mysql&gt; show processlist\\G`\n\n`*************************** 10. row ***************************`\n`Id: 7651833`\n`User: one`\n`Host: 192.168.1.251:52154`\n`db: ops`\n`Command: Query`\n`Time: 3`\n`State: User sleep`\n`Info: select sleep(10)`\n`......`\n`10 rows in set (0.00 sec)`</code></pre>\n<p>可以看到执行时间和SQL语句</p>\n<h2 id=\"分析慢查询\"><a href=\"#分析慢查询\" class=\"headerlink\" title=\"分析慢查询\"></a>分析慢查询</h2><p>1、使用 explain 分析慢查询</p>\n<p>获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：</p>\n<ul>\n<li><p>select_type 查询类型：显示本行是简单还是复杂查询</p>\n</li>\n<li><p>type 本次查询的表连接类型</p>\n</li>\n<li><p>key 实际选择的索引</p>\n</li>\n<li><p>rows 预计需要扫描的行数，对 InnoDB 来说，这个值是估值，并不一定准确</p>\n</li>\n<li><p>Extra 附加信息</p>\n</li>\n</ul>\n<p>其中</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">select_type</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">SIMPLE</td>\n<td>简单查询(不使用关联查询或子查询)</td>\n</tr>\n<tr>\n<td align=\"left\">PRIMARY</td>\n<td>如果包含关联查询或者子查询，则最外层的查询部分标记为primary</td>\n</tr>\n<tr>\n<td align=\"left\">UNION</td>\n<td>联合查询中第二个及后面的查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT UNION</td>\n<td>满足依赖外部的关联查询中第二个及以后的查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNION RESULT</td>\n<td>联合查询的结果</td>\n</tr>\n<tr>\n<td align=\"left\">SUBQUERY</td>\n<td>子查询中的第一个查询</td>\n</tr>\n<tr>\n<td align=\"left\">DEPENDENT SUBQUERY</td>\n<td>子查询中的第一个查询，并且依赖外部查询</td>\n</tr>\n<tr>\n<td align=\"left\">DERIVED</td>\n<td>用到派生表的查询</td>\n</tr>\n<tr>\n<td align=\"left\">MATERIALIZED</td>\n<td>被物化的子查询</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE SUBQUERY</td>\n<td>一个子查询的结果不能被缓存，必须重新评估外层查询的每一行</td>\n</tr>\n<tr>\n<td align=\"left\">UNCACHEABLE UNION</td>\n<td>关联查询第二个或后面的语句属于不可缓存的子查询</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">type</th>\n<th align=\"left\">含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">system</td>\n<td align=\"left\">查询对象表只有一行数据,且只能用于</td>\n</tr>\n<tr>\n<td align=\"left\">const</td>\n<td align=\"left\">基于主键或唯一索引查询，最多返回一条结果</td>\n</tr>\n<tr>\n<td align=\"left\">eq_ref</td>\n<td align=\"left\">表连接时基于主键或非</td>\n</tr>\n<tr>\n<td align=\"left\">ref</td>\n<td align=\"left\">基于普通索引的等值查询，或者表间等值连接</td>\n</tr>\n<tr>\n<td align=\"left\">fulltext</td>\n<td align=\"left\">全文检索</td>\n</tr>\n<tr>\n<td align=\"left\">ref_or_null</td>\n<td align=\"left\">表连接类型是</td>\n</tr>\n<tr>\n<td align=\"left\">index_merge</td>\n<td align=\"left\">利用多个索引</td>\n</tr>\n<tr>\n<td align=\"left\">unique_subquery</td>\n<td align=\"left\">子查询中使用唯一索引</td>\n</tr>\n<tr>\n<td align=\"left\">index_subquery</td>\n<td align=\"left\">子查询中使用普通索引</td>\n</tr>\n<tr>\n<td align=\"left\">range</td>\n<td align=\"left\">利用索引进行范围查询</td>\n</tr>\n<tr>\n<td align=\"left\">index</td>\n<td align=\"left\">全索引扫描</td>\n</tr>\n<tr>\n<td align=\"left\">ALL</td>\n<td align=\"left\">全表扫描</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Extra</th>\n<th align=\"left\">解释</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Using filesort</td>\n<td align=\"left\">将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序</td>\n</tr>\n<tr>\n<td align=\"left\">Using temporary</td>\n<td align=\"left\">需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时</td>\n</tr>\n<tr>\n<td align=\"left\">Using index</td>\n<td align=\"left\">使用覆盖索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using where</td>\n<td align=\"left\">使用 where 语句来处理结果</td>\n</tr>\n<tr>\n<td align=\"left\">Impossible WHERE</td>\n<td align=\"left\">对 where 子句判断的结果总是 false 而不能选择任何数据</td>\n</tr>\n<tr>\n<td align=\"left\">Using join buffer (BlockNested Loop)</td>\n<td align=\"left\">关联查询中，被驱动表的关联字段没索引</td>\n</tr>\n<tr>\n<td align=\"left\">Using index condition</td>\n<td align=\"left\">先条件过滤索引，再查数据</td>\n</tr>\n<tr>\n<td align=\"left\">Select tables optimized away</td>\n<td align=\"left\">使用某些聚合函数（比如 max、min）来访问存在索引的某个字段</td>\n</tr>\n</tbody></table>\n<p>2、show profile</p>\n<p>了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节</p>\n<pre><code class=\"mysql\">mysql&gt; select @@have_profiling;\nmysql&gt; select @@profiling;\nmysql&gt; set profiling=1;\nmysql&gt; select * from t1 where b=1000;\nmysql&gt; show profiles;  /*获取query id*/\nmysql&gt; show profile for query 1;\n\n+----------------------+----------+\n| Status | Duration |\n+----------------------+----------+\n| starting | 0.000115 |\n| checking permissions | 0.000013 |\n| Opening tables | 0.000027 |\n| init | 0.000035 |\n| System lock | 0.000017 |\n| optimizing | 0.000016 |\n| statistics | 0.000025 |\n| preparing | 0.000020 |\n| executing | 0.000006 |\n| Sending data | 0.000294 |\n| end | 0.000009 |\n| query end | 0.000012 |\n| closing tables | 0.000011 |\n| freeing items | 0.000024 |\n| cleaning up | 0.000016 |\n+----------------------+----------+\n15 rows in set, 1 warning (0.00 sec)</code></pre>\n<p>3、trace</p>\n<p>使用 trace 查看优化器如何选择执行计划</p>\n<pre><code class=\"mysql\">mysql&gt; set session optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;\n/* optimizer_trace=&quot;enabled=on&quot; 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */\nmysql&gt; select * from t1 where a &gt;900 and b &gt; 910 order by a;\nmysql&gt; SELECT * FROM information_schema.OPTIMIZER_TRACE\\G;\n</code></pre>\n<p>TRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。</p>\n<p>也可以看number_of_tmp_files中判断是否使用了临时文件。</p>\n"},{"title":"基础架构","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-21T07:01:22.000Z","password":null,"summary":null,"_content":"\nMySQL可以分为Server层和存储引擎层两部分。\n\nServer层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。\n\n存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。\n\n**连接器**\n\n连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n\n尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：\n\n1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2. 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n**查询缓存**\n\nMySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。\n\n建议不要使用查询缓存。\n\n**分析器**\n\n词法分析和语法分析。\n\n**优化器**\n\n确定语句的执行方案。\n\n**执行器**\n\n开始执行语句。\n\n","source":"_posts/基础架构.md","raw":"---\ntitle: 基础架构\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-21 15:01:22\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\nMySQL可以分为Server层和存储引擎层两部分。\n\nServer层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。\n\n存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。\n\n**连接器**\n\n连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n\n尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：\n\n1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2. 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n**查询缓存**\n\nMySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。\n\n建议不要使用查询缓存。\n\n**分析器**\n\n词法分析和语法分析。\n\n**优化器**\n\n确定语句的执行方案。\n\n**执行器**\n\n开始执行语句。\n\n","slug":"基础架构","published":1,"updated":"2021-04-01T23:01:50.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxm90057ncuf7c22ny0x","content":"<p>MySQL可以分为Server层和存储引擎层两部分。</p>\n<p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。</p>\n<p>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。</p>\n<p><strong>连接器</strong></p>\n<p>连接器负责跟客户端建立连接、获取权限、维持和管理连接。</p>\n<p>尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：</p>\n<ol>\n<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>\n<li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>\n</ol>\n<p><strong>查询缓存</strong></p>\n<p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。</p>\n<p>建议不要使用查询缓存。</p>\n<p><strong>分析器</strong></p>\n<p>词法分析和语法分析。</p>\n<p><strong>优化器</strong></p>\n<p>确定语句的执行方案。</p>\n<p><strong>执行器</strong></p>\n<p>开始执行语句。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>MySQL可以分为Server层和存储引擎层两部分。</p>\n<p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。</p>\n<p>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。</p>\n<p><strong>连接器</strong></p>\n<p>连接器负责跟客户端建立连接、获取权限、维持和管理连接。</p>\n<p>尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：</p>\n<ol>\n<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>\n<li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>\n</ol>\n<p><strong>查询缓存</strong></p>\n<p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。</p>\n<p>建议不要使用查询缓存。</p>\n<p><strong>分析器</strong></p>\n<p>词法分析和语法分析。</p>\n<p><strong>优化器</strong></p>\n<p>确定语句的执行方案。</p>\n<p><strong>执行器</strong></p>\n<p>开始执行语句。</p>\n"},{"title":"批量数据导入优化","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T03:53:46.000Z","password":null,"summary":null,"_content":"\n插入行所需的时间由以下因素决定([mysql manual][https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html])\n\n- 连接：30%\n- 向服务器发送查询：20%\n- 解析查询：20%\n- 插入行：10% * 行的大小\n- 插入索引：10% * 索引数\n- 结束：10%\n\n## 一次插入多行的值\n\n有大批量导入时，推荐一条insert语句插入多行数据。\n\n原因：减少服务器通信时间\n\n## 关闭自动提交\n\nAutocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。\n\n原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。\n\n## 参数调整\n\ninnodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略\n\n- 0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；\n- 1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；\n- 2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。\n\nsync_binlog：控制binlog的刷盘时机\n\n- 0：二进制日志从不同步到磁盘，依赖OS刷盘机制；\n- 1：二进制日志每次提交都会刷盘；\n- n(n>1) : 每n次提交落盘一次。\n\ninnodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。","source":"_posts/批量数据导入优化.md","raw":"---\ntitle: 批量数据导入优化\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 11:53:46\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n插入行所需的时间由以下因素决定([mysql manual][https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html])\n\n- 连接：30%\n- 向服务器发送查询：20%\n- 解析查询：20%\n- 插入行：10% * 行的大小\n- 插入索引：10% * 索引数\n- 结束：10%\n\n## 一次插入多行的值\n\n有大批量导入时，推荐一条insert语句插入多行数据。\n\n原因：减少服务器通信时间\n\n## 关闭自动提交\n\nAutocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。\n\n原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。\n\n## 参数调整\n\ninnodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略\n\n- 0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；\n- 1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；\n- 2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。\n\nsync_binlog：控制binlog的刷盘时机\n\n- 0：二进制日志从不同步到磁盘，依赖OS刷盘机制；\n- 1：二进制日志每次提交都会刷盘；\n- n(n>1) : 每n次提交落盘一次。\n\ninnodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。","slug":"批量数据导入优化","published":1,"updated":"2021-04-01T23:01:50.177Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxmb005ancufvbxcq63k","content":"<p>插入行所需的时间由以下因素决定([mysql manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html]\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html]</a>)</p>\n<ul>\n<li>连接：30%</li>\n<li>向服务器发送查询：20%</li>\n<li>解析查询：20%</li>\n<li>插入行：10% * 行的大小</li>\n<li>插入索引：10% * 索引数</li>\n<li>结束：10%</li>\n</ul>\n<h2 id=\"一次插入多行的值\"><a href=\"#一次插入多行的值\" class=\"headerlink\" title=\"一次插入多行的值\"></a>一次插入多行的值</h2><p>有大批量导入时，推荐一条insert语句插入多行数据。</p>\n<p>原因：减少服务器通信时间</p>\n<h2 id=\"关闭自动提交\"><a href=\"#关闭自动提交\" class=\"headerlink\" title=\"关闭自动提交\"></a>关闭自动提交</h2><p>Autocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。</p>\n<p>原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。</p>\n<h2 id=\"参数调整\"><a href=\"#参数调整\" class=\"headerlink\" title=\"参数调整\"></a>参数调整</h2><p>innodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略</p>\n<ul>\n<li>0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。</li>\n</ul>\n<p>sync_binlog：控制binlog的刷盘时机</p>\n<ul>\n<li>0：二进制日志从不同步到磁盘，依赖OS刷盘机制；</li>\n<li>1：二进制日志每次提交都会刷盘；</li>\n<li>n(n&gt;1) : 每n次提交落盘一次。</li>\n</ul>\n<p>innodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>插入行所需的时间由以下因素决定([mysql manual][<a href=\"https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html]\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html]</a>)</p>\n<ul>\n<li>连接：30%</li>\n<li>向服务器发送查询：20%</li>\n<li>解析查询：20%</li>\n<li>插入行：10% * 行的大小</li>\n<li>插入索引：10% * 索引数</li>\n<li>结束：10%</li>\n</ul>\n<h2 id=\"一次插入多行的值\"><a href=\"#一次插入多行的值\" class=\"headerlink\" title=\"一次插入多行的值\"></a>一次插入多行的值</h2><p>有大批量导入时，推荐一条insert语句插入多行数据。</p>\n<p>原因：减少服务器通信时间</p>\n<h2 id=\"关闭自动提交\"><a href=\"#关闭自动提交\" class=\"headerlink\" title=\"关闭自动提交\"></a>关闭自动提交</h2><p>Autocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。</p>\n<p>原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。</p>\n<h2 id=\"参数调整\"><a href=\"#参数调整\" class=\"headerlink\" title=\"参数调整\"></a>参数调整</h2><p>innodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略</p>\n<ul>\n<li>0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；</li>\n<li>2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。</li>\n</ul>\n<p>sync_binlog：控制binlog的刷盘时机</p>\n<ul>\n<li>0：二进制日志从不同步到磁盘，依赖OS刷盘机制；</li>\n<li>1：二进制日志每次提交都会刷盘；</li>\n<li>n(n&gt;1) : 每n次提交落盘一次。</li>\n</ul>\n<p>innodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。</p>\n"},{"title":"数据恢复","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-21T12:27:16.000Z","password":null,"summary":null,"_content":"\n## delete误删行\n\nFlashback工具通过闪回把数据恢复回来。\n\nFlashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和 binlog_row_image=FULL。\n\n恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数\n据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。\n用truncate /drop table和drop database命令删除的数据记录的binlog还是**statement格式**。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。\n\n## truncate /drop误删库/表\n\n需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。\n\n1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；\n2. 用备份恢复出一个临时库；\n3. 从日志备份里面，取出凌晨0点之后的日志；\n4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。\n\n说明：\n\n跳过误操作方法：\n\n如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；\n如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。\n\n## 预防\n\n### 搭建延迟复制备库\n\n延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。\n\n只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。\n\n### 账号分离\n\n我们只给业务开发同学DML权限，而不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。\n即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。\n\n### 制定操作规范\n\n在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。\n改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表","source":"_posts/数据恢复.md","raw":"---\ntitle: 数据恢复\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-21 20:27:16\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## delete误删行\n\nFlashback工具通过闪回把数据恢复回来。\n\nFlashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和 binlog_row_image=FULL。\n\n恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数\n据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。\n用truncate /drop table和drop database命令删除的数据记录的binlog还是**statement格式**。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。\n\n## truncate /drop误删库/表\n\n需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。\n\n1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；\n2. 用备份恢复出一个临时库；\n3. 从日志备份里面，取出凌晨0点之后的日志；\n4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。\n\n说明：\n\n跳过误操作方法：\n\n如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；\n如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。\n\n## 预防\n\n### 搭建延迟复制备库\n\n延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。\n\n只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。\n\n### 账号分离\n\n我们只给业务开发同学DML权限，而不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。\n即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。\n\n### 制定操作规范\n\n在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。\n改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表","slug":"数据恢复","published":1,"updated":"2021-04-01T23:01:50.177Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxme005dncuf4251i3po","content":"<h2 id=\"delete误删行\"><a href=\"#delete误删行\" class=\"headerlink\" title=\"delete误删行\"></a>delete误删行</h2><p>Flashback工具通过闪回把数据恢复回来。</p>\n<p>Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和 binlog_row_image=FULL。</p>\n<p>恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数<br>据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。<br>用truncate /drop table和drop database命令删除的数据记录的binlog还是<strong>statement格式</strong>。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。</p>\n<h2 id=\"truncate-drop误删库-表\"><a href=\"#truncate-drop误删库-表\" class=\"headerlink\" title=\"truncate /drop误删库/表\"></a>truncate /drop误删库/表</h2><p>需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。</p>\n<ol>\n<li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</li>\n<li>用备份恢复出一个临时库；</li>\n<li>从日志备份里面，取出凌晨0点之后的日志；</li>\n<li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li>\n</ol>\n<p>说明：</p>\n<p>跳过误操作方法：</p>\n<p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；<br>如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。</p>\n<h2 id=\"预防\"><a href=\"#预防\" class=\"headerlink\" title=\"预防\"></a>预防</h2><h3 id=\"搭建延迟复制备库\"><a href=\"#搭建延迟复制备库\" class=\"headerlink\" title=\"搭建延迟复制备库\"></a>搭建延迟复制备库</h3><p>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</p>\n<p>只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。</p>\n<h3 id=\"账号分离\"><a href=\"#账号分离\" class=\"headerlink\" title=\"账号分离\"></a>账号分离</h3><p>我们只给业务开发同学DML权限，而不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。<br>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</p>\n<h3 id=\"制定操作规范\"><a href=\"#制定操作规范\" class=\"headerlink\" title=\"制定操作规范\"></a>制定操作规范</h3><p>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。<br>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"delete误删行\"><a href=\"#delete误删行\" class=\"headerlink\" title=\"delete误删行\"></a>delete误删行</h2><p>Flashback工具通过闪回把数据恢复回来。</p>\n<p>Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和 binlog_row_image=FULL。</p>\n<p>恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数<br>据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。<br>用truncate /drop table和drop database命令删除的数据记录的binlog还是<strong>statement格式</strong>。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。</p>\n<h2 id=\"truncate-drop误删库-表\"><a href=\"#truncate-drop误删库-表\" class=\"headerlink\" title=\"truncate /drop误删库/表\"></a>truncate /drop误删库/表</h2><p>需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。</p>\n<ol>\n<li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</li>\n<li>用备份恢复出一个临时库；</li>\n<li>从日志备份里面，取出凌晨0点之后的日志；</li>\n<li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li>\n</ol>\n<p>说明：</p>\n<p>跳过误操作方法：</p>\n<p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；<br>如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。</p>\n<h2 id=\"预防\"><a href=\"#预防\" class=\"headerlink\" title=\"预防\"></a>预防</h2><h3 id=\"搭建延迟复制备库\"><a href=\"#搭建延迟复制备库\" class=\"headerlink\" title=\"搭建延迟复制备库\"></a>搭建延迟复制备库</h3><p>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</p>\n<p>只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。</p>\n<h3 id=\"账号分离\"><a href=\"#账号分离\" class=\"headerlink\" title=\"账号分离\"></a>账号分离</h3><p>我们只给业务开发同学DML权限，而不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。<br>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</p>\n<h3 id=\"制定操作规范\"><a href=\"#制定操作规范\" class=\"headerlink\" title=\"制定操作规范\"></a>制定操作规范</h3><p>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。<br>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表</p>\n"},{"title":"索引","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T14:06:54.000Z","password":null,"summary":null,"_content":"\n## 数据结构\n\n### B 树\n\nB 树每个节点都包含 key 值和 data 值，因此如果 data 比较大时，每一页存储的 key 会比较少；当数据比较多时，有“要经历多层节点才能查询在叶子节点的数据”的问题。\n\n### B+ 树\n\n- 所有叶子节点中包含了全部关键字的信息\n- 各叶子节点用指针进行连接\n- 非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。\n- B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”\n\n## 索引\n\n### 聚集索引\n\n实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。\n\nInnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。\n\n### 辅助索引\n\nInnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。\n\n当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。\n\n### 覆盖索引\n\n辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。\n\n### 使用\n\n- 数据检索\n- 聚合函数（max/count）\n- 排序\n- 避免回表（覆盖索引）\n- 关联查询\n\n### 普通索引和唯一索引\n\n**Insert Buffer**：对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。如果在，则直接插入；如果不在，则先放入 Insert Buffer 中，然后再以一定频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge 操作。**要求不是唯一索引**\n\n意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。\n\n**Change Buffer**：Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update**操作**都进行缓存。**要求不是唯一索引**\n\n参数：\n\n- innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。\n  \n- innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。\n\n原因：唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。\n\n**Change Buffer**适用场景：\n\n对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时changebuffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。\n\n**区别**\n\n1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。\n\n2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。\n\n3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。\n\n4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。\n\n**选择**\n\n1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引\n\n2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。\n\n### 联合索引\n\n对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。\n\n使用：\n\n- where 条件中，经常同时出现的列放在联合索引中。\n- 把选择性最大的列放在联合索引的最左边。\n\n联合索引应用：\n\n```mysql\n/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;\n```\n\n### 前缀索引\n\n当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。\n\n根据“索引选择性”（Index Selectivity）确定前缀长度。\n\n**其他方式**\n\n第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。\n\n第二种方式是使用hash字段。不支持范围查询。\n\n### 最左前缀\n\n不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。\n\n### 主键\n\n如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。\n\n### 优化器索引选择\n\n`show index from t`可以看到索引的Cardinality，即索引中不重复记录数量的预估值。\n\nCardinality 统计信息的更新时机：\n\n- 表中 1/16 的数据已经发生过变化\n- 表中数据发生变化次数超过 2000000000\n\n**统计方法**\n\n随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数\n\n**问题**\n\n通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。\n\n**应对**\n\n```mysql\nanalyze table t13;//更新统计信息\n```\n\n**问题**\n\n如果单次选取的数据量过大，可能也会导致“选错”索引\n\n```mysql\nselect a from t13 where a>70000 limit 1000;//走了主键索引\n```\n\n**应对**\n\nforce index 来强制走索引\n\n```mysql\nselect a from t13 force index(idx_a) where a>70000 limit 1000;\n```\n\n**其他应对**\n\n1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n\n2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n\n","source":"_posts/索引.md","raw":"---\ntitle: 索引\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 22:06:54\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 数据结构\n\n### B 树\n\nB 树每个节点都包含 key 值和 data 值，因此如果 data 比较大时，每一页存储的 key 会比较少；当数据比较多时，有“要经历多层节点才能查询在叶子节点的数据”的问题。\n\n### B+ 树\n\n- 所有叶子节点中包含了全部关键字的信息\n- 各叶子节点用指针进行连接\n- 非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。\n- B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”\n\n## 索引\n\n### 聚集索引\n\n实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。\n\nInnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。\n\n### 辅助索引\n\nInnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。\n\n当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。\n\n### 覆盖索引\n\n辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。\n\n### 使用\n\n- 数据检索\n- 聚合函数（max/count）\n- 排序\n- 避免回表（覆盖索引）\n- 关联查询\n\n### 普通索引和唯一索引\n\n**Insert Buffer**：对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。如果在，则直接插入；如果不在，则先放入 Insert Buffer 中，然后再以一定频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge 操作。**要求不是唯一索引**\n\n意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。\n\n**Change Buffer**：Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update**操作**都进行缓存。**要求不是唯一索引**\n\n参数：\n\n- innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。\n  \n- innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。\n\n原因：唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。\n\n**Change Buffer**适用场景：\n\n对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时changebuffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。\n\n**区别**\n\n1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。\n\n2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。\n\n3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。\n\n4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。\n\n**选择**\n\n1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引\n\n2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。\n\n### 联合索引\n\n对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。\n\n使用：\n\n- where 条件中，经常同时出现的列放在联合索引中。\n- 把选择性最大的列放在联合索引的最左边。\n\n联合索引应用：\n\n```mysql\n/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;\n```\n\n### 前缀索引\n\n当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。\n\n根据“索引选择性”（Index Selectivity）确定前缀长度。\n\n**其他方式**\n\n第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。\n\n第二种方式是使用hash字段。不支持范围查询。\n\n### 最左前缀\n\n不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。\n\n### 主键\n\n如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。\n\n### 优化器索引选择\n\n`show index from t`可以看到索引的Cardinality，即索引中不重复记录数量的预估值。\n\nCardinality 统计信息的更新时机：\n\n- 表中 1/16 的数据已经发生过变化\n- 表中数据发生变化次数超过 2000000000\n\n**统计方法**\n\n随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数\n\n**问题**\n\n通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。\n\n**应对**\n\n```mysql\nanalyze table t13;//更新统计信息\n```\n\n**问题**\n\n如果单次选取的数据量过大，可能也会导致“选错”索引\n\n```mysql\nselect a from t13 where a>70000 limit 1000;//走了主键索引\n```\n\n**应对**\n\nforce index 来强制走索引\n\n```mysql\nselect a from t13 force index(idx_a) where a>70000 limit 1000;\n```\n\n**其他应对**\n\n1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n\n2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n\n","slug":"索引","published":1,"updated":"2021-04-01T23:01:50.177Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxmi005gncufbta0twu6","content":"<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><h3 id=\"B-树\"><a href=\"#B-树\" class=\"headerlink\" title=\"B 树\"></a>B 树</h3><p>B 树每个节点都包含 key 值和 data 值，因此如果 data 比较大时，每一页存储的 key 会比较少；当数据比较多时，有“要经历多层节点才能查询在叶子节点的数据”的问题。</p>\n<h3 id=\"B-树-1\"><a href=\"#B-树-1\" class=\"headerlink\" title=\"B+ 树\"></a>B+ 树</h3><ul>\n<li>所有叶子节点中包含了全部关键字的信息</li>\n<li>各叶子节点用指针进行连接</li>\n<li>非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。</li>\n<li>B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”</li>\n</ul>\n<h2 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h2><h3 id=\"聚集索引\"><a href=\"#聚集索引\" class=\"headerlink\" title=\"聚集索引\"></a>聚集索引</h3><p>实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。</p>\n<p>InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。</p>\n<h3 id=\"辅助索引\"><a href=\"#辅助索引\" class=\"headerlink\" title=\"辅助索引\"></a>辅助索引</h3><p>InnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。</p>\n<p>当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。</p>\n<h3 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h3><p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><ul>\n<li>数据检索</li>\n<li>聚合函数（max/count）</li>\n<li>排序</li>\n<li>避免回表（覆盖索引）</li>\n<li>关联查询</li>\n</ul>\n<h3 id=\"普通索引和唯一索引\"><a href=\"#普通索引和唯一索引\" class=\"headerlink\" title=\"普通索引和唯一索引\"></a>普通索引和唯一索引</h3><p><strong>Insert Buffer</strong>：对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。如果在，则直接插入；如果不在，则先放入 Insert Buffer 中，然后再以一定频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge 操作。<strong>要求不是唯一索引</strong></p>\n<p>意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。</p>\n<p><strong>Change Buffer</strong>：Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update<strong>操作</strong>都进行缓存。<strong>要求不是唯一索引</strong></p>\n<p>参数：</p>\n<ul>\n<li><p>innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。</p>\n</li>\n<li><p>innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。</p>\n</li>\n</ul>\n<p>原因：唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。</p>\n<p><strong>Change Buffer</strong>适用场景：</p>\n<p>对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时changebuffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</p>\n<p><strong>区别</strong></p>\n<p>1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。</p>\n<p>2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。</p>\n<p>3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。</p>\n<p>4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。</p>\n<p><strong>选择</strong></p>\n<p>1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引</p>\n<p>2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。</p>\n<h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a>联合索引</h3><p>对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。</p>\n<p>使用：</p>\n<ul>\n<li>where 条件中，经常同时出现的列放在联合索引中。</li>\n<li>把选择性最大的列放在联合索引的最左边。</li>\n</ul>\n<p>联合索引应用：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h3><p>当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。</p>\n<p>根据“索引选择性”（Index Selectivity）确定前缀长度。</p>\n<p><strong>其他方式</strong></p>\n<p>第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。</p>\n<p>第二种方式是使用hash字段。不支持范围查询。</p>\n<h3 id=\"最左前缀\"><a href=\"#最左前缀\" class=\"headerlink\" title=\"最左前缀\"></a>最左前缀</h3><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p>\n<h3 id=\"主键\"><a href=\"#主键\" class=\"headerlink\" title=\"主键\"></a>主键</h3><p>如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。</p>\n<h3 id=\"优化器索引选择\"><a href=\"#优化器索引选择\" class=\"headerlink\" title=\"优化器索引选择\"></a>优化器索引选择</h3><p><code>show index from t</code>可以看到索引的Cardinality，即索引中不重复记录数量的预估值。</p>\n<p>Cardinality 统计信息的更新时机：</p>\n<ul>\n<li>表中 1/16 的数据已经发生过变化</li>\n<li>表中数据发生变化次数超过 2000000000</li>\n</ul>\n<p><strong>统计方法</strong></p>\n<p>随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数</p>\n<p><strong>问题</strong></p>\n<p>通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。</p>\n<p><strong>应对</strong></p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">analyze table t13;//更新统计信息<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>问题</strong></p>\n<p>如果单次选取的数据量过大，可能也会导致“选错”索引</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select a from t13 where a>70000 limit 1000;//走了主键索引<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>应对</strong></p>\n<p>force index 来强制走索引</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select a from t13 force index(idx_a) where a>70000 limit 1000;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>其他应对</strong></p>\n<p>1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p>\n<p>2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><h3 id=\"B-树\"><a href=\"#B-树\" class=\"headerlink\" title=\"B 树\"></a>B 树</h3><p>B 树每个节点都包含 key 值和 data 值，因此如果 data 比较大时，每一页存储的 key 会比较少；当数据比较多时，有“要经历多层节点才能查询在叶子节点的数据”的问题。</p>\n<h3 id=\"B-树-1\"><a href=\"#B-树-1\" class=\"headerlink\" title=\"B+ 树\"></a>B+ 树</h3><ul>\n<li>所有叶子节点中包含了全部关键字的信息</li>\n<li>各叶子节点用指针进行连接</li>\n<li>非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。</li>\n<li>B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”</li>\n</ul>\n<h2 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h2><h3 id=\"聚集索引\"><a href=\"#聚集索引\" class=\"headerlink\" title=\"聚集索引\"></a>聚集索引</h3><p>实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。</p>\n<p>InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。</p>\n<h3 id=\"辅助索引\"><a href=\"#辅助索引\" class=\"headerlink\" title=\"辅助索引\"></a>辅助索引</h3><p>InnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。</p>\n<p>当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。</p>\n<h3 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h3><p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><ul>\n<li>数据检索</li>\n<li>聚合函数（max/count）</li>\n<li>排序</li>\n<li>避免回表（覆盖索引）</li>\n<li>关联查询</li>\n</ul>\n<h3 id=\"普通索引和唯一索引\"><a href=\"#普通索引和唯一索引\" class=\"headerlink\" title=\"普通索引和唯一索引\"></a>普通索引和唯一索引</h3><p><strong>Insert Buffer</strong>：对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。如果在，则直接插入；如果不在，则先放入 Insert Buffer 中，然后再以一定频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge 操作。<strong>要求不是唯一索引</strong></p>\n<p>意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。</p>\n<p><strong>Change Buffer</strong>：Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update<strong>操作</strong>都进行缓存。<strong>要求不是唯一索引</strong></p>\n<p>参数：</p>\n<ul>\n<li><p>innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。</p>\n</li>\n<li><p>innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。</p>\n</li>\n</ul>\n<p>原因：唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。</p>\n<p><strong>Change Buffer</strong>适用场景：</p>\n<p>对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时changebuffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</p>\n<p><strong>区别</strong></p>\n<p>1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。</p>\n<p>2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。</p>\n<p>3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。</p>\n<p>4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。</p>\n<p><strong>选择</strong></p>\n<p>1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引</p>\n<p>2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。</p>\n<h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a>联合索引</h3><p>对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。</p>\n<p>使用：</p>\n<ul>\n<li>where 条件中，经常同时出现的列放在联合索引中。</li>\n<li>把选择性最大的列放在联合索引的最左边。</li>\n</ul>\n<p>联合索引应用：</p>\n<pre><code class=\"mysql\">/*使用完整联合索引*/\nselect * from t11 where a=1 and b=1 and c=1;\nselect * from t11 where c=1 and b=1 and a=1;\nselect * from t11 where a=2 and b in (1,2) and c=2;\nselect * from t11 where a=1 and b=2 order by c;\nselect * from t11 where a=1 order by b,c;\nselect a,b,c from t11 order by a,b,c;\n/*使用部分联合索引idx_a_b_c*/\nselect * from t11 where a=1 and b=1;\nselect * from t11 where a=1 and c=1;//索引a\nselect * from t11 where a=2 and b in (3,4) order by c; //索引ab\n/*覆盖索引,不需要回表查询聚集索引中的记录*/\nselect b,c from t11 where a=3;\nselect c from t11 where a=1 and b=1 ;\nselect id from t11 where a=1 and b=1 and c=1;\n/*不能使用联合索引*/\nselect * from t11 where b=1; //联合索引最左匹配\nselect * from t11 order by b;</code></pre>\n<h3 id=\"前缀索引\"><a href=\"#前缀索引\" class=\"headerlink\" title=\"前缀索引\"></a>前缀索引</h3><p>当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。</p>\n<p>根据“索引选择性”（Index Selectivity）确定前缀长度。</p>\n<p><strong>其他方式</strong></p>\n<p>第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。</p>\n<p>第二种方式是使用hash字段。不支持范围查询。</p>\n<h3 id=\"最左前缀\"><a href=\"#最左前缀\" class=\"headerlink\" title=\"最左前缀\"></a>最左前缀</h3><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p>\n<h3 id=\"主键\"><a href=\"#主键\" class=\"headerlink\" title=\"主键\"></a>主键</h3><p>如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。</p>\n<h3 id=\"优化器索引选择\"><a href=\"#优化器索引选择\" class=\"headerlink\" title=\"优化器索引选择\"></a>优化器索引选择</h3><p><code>show index from t</code>可以看到索引的Cardinality，即索引中不重复记录数量的预估值。</p>\n<p>Cardinality 统计信息的更新时机：</p>\n<ul>\n<li>表中 1/16 的数据已经发生过变化</li>\n<li>表中数据发生变化次数超过 2000000000</li>\n</ul>\n<p><strong>统计方法</strong></p>\n<p>随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数</p>\n<p><strong>问题</strong></p>\n<p>通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。</p>\n<p><strong>应对</strong></p>\n<pre><code class=\"mysql\">analyze table t13;//更新统计信息</code></pre>\n<p><strong>问题</strong></p>\n<p>如果单次选取的数据量过大，可能也会导致“选错”索引</p>\n<pre><code class=\"mysql\">select a from t13 where a&gt;70000 limit 1000;//走了主键索引</code></pre>\n<p><strong>应对</strong></p>\n<p>force index 来强制走索引</p>\n<pre><code class=\"mysql\">select a from t13 force index(idx_a) where a&gt;70000 limit 1000;</code></pre>\n<p><strong>其他应对</strong></p>\n<p>1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p>\n<p>2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p>\n"},{"title":"读写分离","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-15T11:27:16.000Z","password":null,"summary":null,"_content":"\n## 主从复制\n\n### 异步复制\n\n在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（这里不会管从库是否已经收到了事务的 binlog），从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中。\n\n### 半同步复制\n\n在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，**从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功**，从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中\n\n## 主从切换\n\n### 可靠性优先策略\n\n1. 判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则\n持续重试这一步；\n2. 把主库A改成只读状态，即把readonly设置为true；\n3. 判断备库B的seconds_behind_master的值，直到这个值变成0为止；\n4. 把备库B改成可读写状态，也就是把readonly 设置为false；\n5. 把业务请求切到备库B。\n\n如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。\n\n### 可用性优先策略\n\n不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。可能出现不一致的数据。\n\n设置binlog_format=row，会出现duplicate key error并停止；\n\n使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了\n\n## 备库并行复制策略\n\n### 按库并行\n\n用于决定分发策略的hash表里，key就是数据库名。如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n\n### MariaDB的并行复制策略\n\n利用redo log组提交(group commit)特性：\n1. 能够在同一组里提交的事务，一定不会修改同一行；\n2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n实现方法\n\n1. 在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；\n2. commit_id直接写到binlog里面；\n3. 传到备库应用的时候，相同commit_id的事务分发到多个worker执行；\n4. 这一组全部执行完成后，coordinator再去取下一批。\n\n### MySQL 5.7.22的新增并行复制策略\n\n基于WRITESET的并行复制。\n\n参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可以并行的策略。\n2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。\n3. WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n## 主从延迟\n\n可能原因：\n\n- 大表 DDL\n- 大事务\n- 主库 DML 并发大\n- 从库配置差\n\n判断主从延迟：\n\n1、判断 Seconds_Behind_Master 是否等于 0。\n\n2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。\n\n3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。\n\n## 主备切换\n\n**基于位点的主备切换**\n\n考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。\n一种做法是，主动跳过一个事务。另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos\n```\n\n**基于GTID的主备切换**\n\nGTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1\n```\n\n主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:\n1. 实例B指定主库A’，基于主备协议建立连接。\n2. 实例B把set_b发给主库A’。\n3. 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的\n集合，判断A’本地是否包含了这个差集需要的所有binlog事务。\na. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；\nb. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；\n4. 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。\n\n## 过期读\n\n问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更\n新之前的状态。\n\n**强制走主库方案**\n\n1. 对于必须要拿到最新结果的请求，强制将其发到主库上\n2. 对于可以读到旧数据的请求，才将其发到从库上。\n\n**sleep方案**\n\n大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条select sleep(1)命令。\n\n以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。\n\n**缺点**\n\n1. 如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；\n2. 如果延迟超过1秒，还是会出现过期读。\n\n**判断主备无延迟方案**\n\n第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。\n\n第二种方法，对比位点确保主备无延迟（show slave status）：\nMaster_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；\nRelay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。\n如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和\nExec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成\n\n第三种方法，对比GTID集合确保主备无延迟（show slave status）：\n\nAuto_Position=1 ，表示这对主备关系使用了GTID协议。\nRetrieved_Gtid_Set，是备库收到的所有日志的GTID集合；\nExecuted_Gtid_Set，是备库所有已经执行完成的GTID集合。\n\n缺点：仍可能过期读。备库收到的日志都执行完成了。但是，从binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n**配合semi-sync方案**\n\n引入半同步复制,配合前面关于位点的判断。\n\n在一主多从场景中,如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。\n\n在持续延迟的情况下，可能出现过度等待的问题。\n\n**等主库位点方案**\n\n1. trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行select master_pos_wait(File, Position, 1)；\n4. 如果返回值是>=0的正整数，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n**等GTID方案**\n\n1. trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；\n4. 如果返回值是0，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n","source":"_posts/读写分离.md","raw":"---\ntitle: 读写分离\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-15 19:27:16\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 主从复制\n\n### 异步复制\n\n在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（这里不会管从库是否已经收到了事务的 binlog），从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中。\n\n### 半同步复制\n\n在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，**从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功**，从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中\n\n## 主从切换\n\n### 可靠性优先策略\n\n1. 判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则\n持续重试这一步；\n2. 把主库A改成只读状态，即把readonly设置为true；\n3. 判断备库B的seconds_behind_master的值，直到这个值变成0为止；\n4. 把备库B改成可读写状态，也就是把readonly 设置为false；\n5. 把业务请求切到备库B。\n\n如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。\n\n### 可用性优先策略\n\n不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。可能出现不一致的数据。\n\n设置binlog_format=row，会出现duplicate key error并停止；\n\n使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了\n\n## 备库并行复制策略\n\n### 按库并行\n\n用于决定分发策略的hash表里，key就是数据库名。如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n\n### MariaDB的并行复制策略\n\n利用redo log组提交(group commit)特性：\n1. 能够在同一组里提交的事务，一定不会修改同一行；\n2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n实现方法\n\n1. 在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；\n2. commit_id直接写到binlog里面；\n3. 传到备库应用的时候，相同commit_id的事务分发到多个worker执行；\n4. 这一组全部执行完成后，coordinator再去取下一批。\n\n### MySQL 5.7.22的新增并行复制策略\n\n基于WRITESET的并行复制。\n\n参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可以并行的策略。\n2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。\n3. WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n## 主从延迟\n\n可能原因：\n\n- 大表 DDL\n- 大事务\n- 主库 DML 并发大\n- 从库配置差\n\n判断主从延迟：\n\n1、判断 Seconds_Behind_Master 是否等于 0。\n\n2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。\n\n3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。\n\n## 主备切换\n\n**基于位点的主备切换**\n\n考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。\n一种做法是，主动跳过一个事务。另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos\n```\n\n**基于GTID的主备切换**\n\nGTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。\n\n```mysql\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1\n```\n\n主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:\n1. 实例B指定主库A’，基于主备协议建立连接。\n2. 实例B把set_b发给主库A’。\n3. 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的\n集合，判断A’本地是否包含了这个差集需要的所有binlog事务。\na. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；\nb. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；\n4. 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。\n\n## 过期读\n\n问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更\n新之前的状态。\n\n**强制走主库方案**\n\n1. 对于必须要拿到最新结果的请求，强制将其发到主库上\n2. 对于可以读到旧数据的请求，才将其发到从库上。\n\n**sleep方案**\n\n大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条select sleep(1)命令。\n\n以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。\n\n**缺点**\n\n1. 如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；\n2. 如果延迟超过1秒，还是会出现过期读。\n\n**判断主备无延迟方案**\n\n第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。\n\n第二种方法，对比位点确保主备无延迟（show slave status）：\nMaster_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；\nRelay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。\n如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和\nExec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成\n\n第三种方法，对比GTID集合确保主备无延迟（show slave status）：\n\nAuto_Position=1 ，表示这对主备关系使用了GTID协议。\nRetrieved_Gtid_Set，是备库收到的所有日志的GTID集合；\nExecuted_Gtid_Set，是备库所有已经执行完成的GTID集合。\n\n缺点：仍可能过期读。备库收到的日志都执行完成了。但是，从binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n**配合semi-sync方案**\n\n引入半同步复制,配合前面关于位点的判断。\n\n在一主多从场景中,如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。\n\n在持续延迟的情况下，可能出现过度等待的问题。\n\n**等主库位点方案**\n\n1. trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行select master_pos_wait(File, Position, 1)；\n4. 如果返回值是>=0的正整数，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n**等GTID方案**\n\n1. trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；\n4. 如果返回值是0，则在这个从库执行查询语句；\n5. 否则，到主库执行查询语句。\n\n等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。\n\n","slug":"读写分离","published":1,"updated":"2021-04-01T23:01:50.197Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxmn005jncufwy77zn0q","content":"<h2 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h2><h3 id=\"异步复制\"><a href=\"#异步复制\" class=\"headerlink\" title=\"异步复制\"></a>异步复制</h3><p>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（这里不会管从库是否已经收到了事务的 binlog），从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中。</p>\n<h3 id=\"半同步复制\"><a href=\"#半同步复制\" class=\"headerlink\" title=\"半同步复制\"></a>半同步复制</h3><p>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，<strong>从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功</strong>，从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中</p>\n<h2 id=\"主从切换\"><a href=\"#主从切换\" class=\"headerlink\" title=\"主从切换\"></a>主从切换</h2><h3 id=\"可靠性优先策略\"><a href=\"#可靠性优先策略\" class=\"headerlink\" title=\"可靠性优先策略\"></a>可靠性优先策略</h3><ol>\n<li>判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则<br>持续重试这一步；</li>\n<li>把主库A改成只读状态，即把readonly设置为true；</li>\n<li>判断备库B的seconds_behind_master的值，直到这个值变成0为止；</li>\n<li>把备库B改成可读写状态，也就是把readonly 设置为false；</li>\n<li>把业务请求切到备库B。</li>\n</ol>\n<p>如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。</p>\n<h3 id=\"可用性优先策略\"><a href=\"#可用性优先策略\" class=\"headerlink\" title=\"可用性优先策略\"></a>可用性优先策略</h3><p>不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。可能出现不一致的数据。</p>\n<p>设置binlog_format=row，会出现duplicate key error并停止；</p>\n<p>使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了</p>\n<h2 id=\"备库并行复制策略\"><a href=\"#备库并行复制策略\" class=\"headerlink\" title=\"备库并行复制策略\"></a>备库并行复制策略</h2><h3 id=\"按库并行\"><a href=\"#按库并行\" class=\"headerlink\" title=\"按库并行\"></a>按库并行</h3><p>用于决定分发策略的hash表里，key就是数据库名。如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。</p>\n<h3 id=\"MariaDB的并行复制策略\"><a href=\"#MariaDB的并行复制策略\" class=\"headerlink\" title=\"MariaDB的并行复制策略\"></a>MariaDB的并行复制策略</h3><p>利用redo log组提交(group commit)特性：</p>\n<ol>\n<li>能够在同一组里提交的事务，一定不会修改同一行；</li>\n<li>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</li>\n</ol>\n<p>实现方法</p>\n<ol>\n<li>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；</li>\n<li>commit_id直接写到binlog里面；</li>\n<li>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；</li>\n<li>这一组全部执行完成后，coordinator再去取下一批。</li>\n</ol>\n<h3 id=\"MySQL-5-7-22的新增并行复制策略\"><a href=\"#MySQL-5-7-22的新增并行复制策略\" class=\"headerlink\" title=\"MySQL 5.7.22的新增并行复制策略\"></a>MySQL 5.7.22的新增并行复制策略</h3><p>基于WRITESET的并行复制。</p>\n<p>参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。</p>\n<ol>\n<li>COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可以并行的策略。</li>\n<li>WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。</li>\n<li>WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li>\n</ol>\n<h2 id=\"主从延迟\"><a href=\"#主从延迟\" class=\"headerlink\" title=\"主从延迟\"></a>主从延迟</h2><p>可能原因：</p>\n<ul>\n<li>大表 DDL</li>\n<li>大事务</li>\n<li>主库 DML 并发大</li>\n<li>从库配置差</li>\n</ul>\n<p>判断主从延迟：</p>\n<p>1、判断 Seconds_Behind_Master 是否等于 0。</p>\n<p>2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。</p>\n<p>3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。</p>\n<h2 id=\"主备切换\"><a href=\"#主备切换\" class=\"headerlink\" title=\"主备切换\"></a>主备切换</h2><p><strong>基于位点的主备切换</strong></p>\n<p>考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。<br>一种做法是，主动跳过一个事务。另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>基于GTID的主备切换</strong></p>\n<p>GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:</p>\n<ol>\n<li>实例B指定主库A’，基于主备协议建立连接。</li>\n<li>实例B把set_b发给主库A’。</li>\n<li>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的<br>集合，判断A’本地是否包含了这个差集需要的所有binlog事务。<br>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；<br>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</li>\n<li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。</li>\n</ol>\n<h2 id=\"过期读\"><a href=\"#过期读\" class=\"headerlink\" title=\"过期读\"></a>过期读</h2><p>问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更<br>新之前的状态。</p>\n<p><strong>强制走主库方案</strong></p>\n<ol>\n<li>对于必须要拿到最新结果的请求，强制将其发到主库上</li>\n<li>对于可以读到旧数据的请求，才将其发到从库上。</li>\n</ol>\n<p><strong>sleep方案</strong></p>\n<p>大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条select sleep(1)命令。</p>\n<p>以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。</p>\n<p><strong>缺点</strong></p>\n<ol>\n<li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</li>\n<li>如果延迟超过1秒，还是会出现过期读。</li>\n</ol>\n<p><strong>判断主备无延迟方案</strong></p>\n<p>第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。</p>\n<p>第二种方法，对比位点确保主备无延迟（show slave status）：<br>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；<br>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。<br>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和<br>Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成</p>\n<p>第三种方法，对比GTID集合确保主备无延迟（show slave status）：</p>\n<p>Auto_Position=1 ，表示这对主备关系使用了GTID协议。<br>Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；<br>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。</p>\n<p>缺点：仍可能过期读。备库收到的日志都执行完成了。但是，从binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p>\n<p><strong>配合semi-sync方案</strong></p>\n<p>引入半同步复制,配合前面关于位点的判断。</p>\n<p>在一主多从场景中,如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</p>\n<p>在持续延迟的情况下，可能出现过度等待的问题。</p>\n<p><strong>等主库位点方案</strong></p>\n<ol>\n<li>trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行select master_pos_wait(File, Position, 1)；</li>\n<li>如果返回值是&gt;=0的正整数，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n<p><strong>等GTID方案</strong></p>\n<ol>\n<li>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；</li>\n<li>如果返回值是0，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h2><h3 id=\"异步复制\"><a href=\"#异步复制\" class=\"headerlink\" title=\"异步复制\"></a>异步复制</h3><p>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（这里不会管从库是否已经收到了事务的 binlog），从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中。</p>\n<h3 id=\"半同步复制\"><a href=\"#半同步复制\" class=\"headerlink\" title=\"半同步复制\"></a>半同步复制</h3><p>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中，主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，<strong>从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功</strong>，从库的 SQL 线程负责读取它的 relay log 里的信息并应用到从库数据库中</p>\n<h2 id=\"主从切换\"><a href=\"#主从切换\" class=\"headerlink\" title=\"主从切换\"></a>主从切换</h2><h3 id=\"可靠性优先策略\"><a href=\"#可靠性优先策略\" class=\"headerlink\" title=\"可靠性优先策略\"></a>可靠性优先策略</h3><ol>\n<li>判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则<br>持续重试这一步；</li>\n<li>把主库A改成只读状态，即把readonly设置为true；</li>\n<li>判断备库B的seconds_behind_master的值，直到这个值变成0为止；</li>\n<li>把备库B改成可读写状态，也就是把readonly 设置为false；</li>\n<li>把业务请求切到备库B。</li>\n</ol>\n<p>如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。</p>\n<h3 id=\"可用性优先策略\"><a href=\"#可用性优先策略\" class=\"headerlink\" title=\"可用性优先策略\"></a>可用性优先策略</h3><p>不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。可能出现不一致的数据。</p>\n<p>设置binlog_format=row，会出现duplicate key error并停止；</p>\n<p>使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了</p>\n<h2 id=\"备库并行复制策略\"><a href=\"#备库并行复制策略\" class=\"headerlink\" title=\"备库并行复制策略\"></a>备库并行复制策略</h2><h3 id=\"按库并行\"><a href=\"#按库并行\" class=\"headerlink\" title=\"按库并行\"></a>按库并行</h3><p>用于决定分发策略的hash表里，key就是数据库名。如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。</p>\n<h3 id=\"MariaDB的并行复制策略\"><a href=\"#MariaDB的并行复制策略\" class=\"headerlink\" title=\"MariaDB的并行复制策略\"></a>MariaDB的并行复制策略</h3><p>利用redo log组提交(group commit)特性：</p>\n<ol>\n<li>能够在同一组里提交的事务，一定不会修改同一行；</li>\n<li>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</li>\n</ol>\n<p>实现方法</p>\n<ol>\n<li>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；</li>\n<li>commit_id直接写到binlog里面；</li>\n<li>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；</li>\n<li>这一组全部执行完成后，coordinator再去取下一批。</li>\n</ol>\n<h3 id=\"MySQL-5-7-22的新增并行复制策略\"><a href=\"#MySQL-5-7-22的新增并行复制策略\" class=\"headerlink\" title=\"MySQL 5.7.22的新增并行复制策略\"></a>MySQL 5.7.22的新增并行复制策略</h3><p>基于WRITESET的并行复制。</p>\n<p>参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。</p>\n<ol>\n<li>COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可以并行的策略。</li>\n<li>WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。</li>\n<li>WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li>\n</ol>\n<h2 id=\"主从延迟\"><a href=\"#主从延迟\" class=\"headerlink\" title=\"主从延迟\"></a>主从延迟</h2><p>可能原因：</p>\n<ul>\n<li>大表 DDL</li>\n<li>大事务</li>\n<li>主库 DML 并发大</li>\n<li>从库配置差</li>\n</ul>\n<p>判断主从延迟：</p>\n<p>1、判断 Seconds_Behind_Master 是否等于 0。</p>\n<p>2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。</p>\n<p>3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。</p>\n<h2 id=\"主备切换\"><a href=\"#主备切换\" class=\"headerlink\" title=\"主备切换\"></a>主备切换</h2><p><strong>基于位点的主备切换</strong></p>\n<p>考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。<br>一种做法是，主动跳过一个事务。另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。</p>\n<pre><code class=\"mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos</code></pre>\n<p><strong>基于GTID的主备切换</strong></p>\n<p>GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。</p>\n<pre><code class=\"mysql\">CHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1</code></pre>\n<p>主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:</p>\n<ol>\n<li>实例B指定主库A’，基于主备协议建立连接。</li>\n<li>实例B把set_b发给主库A’。</li>\n<li>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的<br>集合，判断A’本地是否包含了这个差集需要的所有binlog事务。<br>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；<br>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</li>\n<li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。</li>\n</ol>\n<h2 id=\"过期读\"><a href=\"#过期读\" class=\"headerlink\" title=\"过期读\"></a>过期读</h2><p>问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更<br>新之前的状态。</p>\n<p><strong>强制走主库方案</strong></p>\n<ol>\n<li>对于必须要拿到最新结果的请求，强制将其发到主库上</li>\n<li>对于可以读到旧数据的请求，才将其发到从库上。</li>\n</ol>\n<p><strong>sleep方案</strong></p>\n<p>大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条select sleep(1)命令。</p>\n<p>以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。</p>\n<p><strong>缺点</strong></p>\n<ol>\n<li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</li>\n<li>如果延迟超过1秒，还是会出现过期读。</li>\n</ol>\n<p><strong>判断主备无延迟方案</strong></p>\n<p>第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。</p>\n<p>第二种方法，对比位点确保主备无延迟（show slave status）：<br>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；<br>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。<br>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和<br>Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成</p>\n<p>第三种方法，对比GTID集合确保主备无延迟（show slave status）：</p>\n<p>Auto_Position=1 ，表示这对主备关系使用了GTID协议。<br>Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；<br>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。</p>\n<p>缺点：仍可能过期读。备库收到的日志都执行完成了。但是，从binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p>\n<p><strong>配合semi-sync方案</strong></p>\n<p>引入半同步复制,配合前面关于位点的判断。</p>\n<p>在一主多从场景中,如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</p>\n<p>在持续延迟的情况下，可能出现过度等待的问题。</p>\n<p><strong>等主库位点方案</strong></p>\n<ol>\n<li>trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行select master_pos_wait(File, Position, 1)；</li>\n<li>如果返回值是&gt;=0的正整数，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n<p><strong>等GTID方案</strong></p>\n<ol>\n<li>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</li>\n<li>选定一个从库执行查询语句；</li>\n<li>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；</li>\n<li>如果返回值是0，则在这个从库执行查询语句；</li>\n<li>否则，到主库执行查询语句。</li>\n</ol>\n<p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>\n"},{"title":"索引失效","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-13T03:07:49.000Z","password":null,"summary":null,"_content":"\n## 函数操作\n\n对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。\n\n```mysql\nselect * from t1 where date(c) ='2019-05-21';\n```\n\n优化：改成范围查询\n\n```mysql\nselect * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';\n```\n\n## 隐式转换\n\n操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */\n```\n\n实际会做函数操作：\n\n```mysql\nselect user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; \n```\n\n优化：类型统一\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字\n```\n\n## 模糊查询\n\n通配符在前面\n\n```mysql\nselect * from t1 where a like '%1111%';\n```\n\n优化:模糊查询必须包含条件字段前面的值\n\n```mysql\nselect * from t1 where a like '1111%';\n```\n\n## 范围查询\n\n范围查询数据量太多，需要回表，因此不走索引。\n\n```mysql\nselect * from t1 where b>=1 and b <=2000;\n```\n\n优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）\n\n```\nselect * from t1 where b>=1 and b <=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b>=1 and b <=1000 |\n|        2 | 0.00605625 | select * from t1 where b>=1 and b <=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n## 计算操作\n\n即使是简单的计算\n\n```mysql\nexplain select * from t1 where b-1 =1000;\n```\n\n优化：将计算操作放在等号后面\n\n```mysql\nexplain select * from t1 where b =1000 + 1;\n```\n\n\n\n\n\n","source":"_posts/索引失效.md","raw":"---\ntitle: 索引失效\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-13 11:07:49\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n## 函数操作\n\n对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。\n\n```mysql\nselect * from t1 where date(c) ='2019-05-21';\n```\n\n优化：改成范围查询\n\n```mysql\nselect * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';\n```\n\n## 隐式转换\n\n操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */\n```\n\n实际会做函数操作：\n\n```mysql\nselect user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; \n```\n\n优化：类型统一\n\n```mysql\nselect user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字\n```\n\n## 模糊查询\n\n通配符在前面\n\n```mysql\nselect * from t1 where a like '%1111%';\n```\n\n优化:模糊查询必须包含条件字段前面的值\n\n```mysql\nselect * from t1 where a like '1111%';\n```\n\n## 范围查询\n\n范围查询数据量太多，需要回表，因此不走索引。\n\n```mysql\nselect * from t1 where b>=1 and b <=2000;\n```\n\n优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）\n\n```\nselect * from t1 where b>=1 and b <=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b>=1 and b <=1000 |\n|        2 | 0.00605625 | select * from t1 where b>=1 and b <=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n## 计算操作\n\n即使是简单的计算\n\n```mysql\nexplain select * from t1 where b-1 =1000;\n```\n\n优化：将计算操作放在等号后面\n\n```mysql\nexplain select * from t1 where b =1000 + 1;\n```\n\n\n\n\n\n","slug":"索引失效","published":1,"updated":"2021-04-01T23:01:50.177Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxmr005mncufkehin407","content":"<h2 id=\"函数操作\"><a href=\"#函数操作\" class=\"headerlink\" title=\"函数操作\"></a>函数操作</h2><p>对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where date(c) ='2019-05-21';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：改成范围查询</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"隐式转换\"><a href=\"#隐式转换\" class=\"headerlink\" title=\"隐式转换\"></a>隐式转换</h2><p>操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>实际会做函数操作：</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：类型统一</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"模糊查询\"><a href=\"#模糊查询\" class=\"headerlink\" title=\"模糊查询\"></a>模糊查询</h2><p>通配符在前面</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where a like '%1111%';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化:模糊查询必须包含条件字段前面的值</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where a like '1111%';<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"范围查询\"><a href=\"#范围查询\" class=\"headerlink\" title=\"范围查询\"></a>范围查询</h2><p>范围查询数据量太多，需要回表，因此不走索引。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">select * from t1 where b>=1 and b <=2000;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）</p>\n<pre><code>select * from t1 where b&gt;=1 and b &lt;=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b&gt;=1 and b &lt;=1000 |\n|        2 | 0.00605625 | select * from t1 where b&gt;=1 and b &lt;=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)</code></pre><h2 id=\"计算操作\"><a href=\"#计算操作\" class=\"headerlink\" title=\"计算操作\"></a>计算操作</h2><p>即使是简单的计算</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">explain select * from t1 where b-1 =1000;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>优化：将计算操作放在等号后面</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">explain select * from t1 where b =1000 + 1;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<h2 id=\"函数操作\"><a href=\"#函数操作\" class=\"headerlink\" title=\"函数操作\"></a>函数操作</h2><p>对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。</p>\n<pre><code class=\"mysql\">select * from t1 where date(c) =&#39;2019-05-21&#39;;</code></pre>\n<p>优化：改成范围查询</p>\n<pre><code class=\"mysql\">select * from t1 where c&gt;=&#39;2019-05-21 00:00:00&#39; and c&lt;=&#39;2019-05-21 23:59:59&#39;;</code></pre>\n<h2 id=\"隐式转换\"><a href=\"#隐式转换\" class=\"headerlink\" title=\"隐式转换\"></a>隐式转换</h2><p>操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。</p>\n<pre><code class=\"mysql\">select user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */</code></pre>\n<p>实际会做函数操作：</p>\n<pre><code class=\"mysql\">select user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; </code></pre>\n<p>优化：类型统一</p>\n<pre><code class=\"mysql\">select user_name,tele_phone from user_info where tele_phone =&#39;11111111111&#39;;//字符串转数字</code></pre>\n<h2 id=\"模糊查询\"><a href=\"#模糊查询\" class=\"headerlink\" title=\"模糊查询\"></a>模糊查询</h2><p>通配符在前面</p>\n<pre><code class=\"mysql\">select * from t1 where a like &#39;%1111%&#39;;</code></pre>\n<p>优化:模糊查询必须包含条件字段前面的值</p>\n<pre><code class=\"mysql\">select * from t1 where a like &#39;1111%&#39;;</code></pre>\n<h2 id=\"范围查询\"><a href=\"#范围查询\" class=\"headerlink\" title=\"范围查询\"></a>范围查询</h2><p>范围查询数据量太多，需要回表，因此不走索引。</p>\n<pre><code class=\"mysql\">select * from t1 where b&gt;=1 and b &lt;=2000;</code></pre>\n<p>优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）</p>\n<pre><code>select * from t1 where b&gt;=1 and b &lt;=1000;\n\n show profiles;\n+----------+------------+------------------------------------------+\n| Query_ID | Duration   | Query                                    |\n+----------+------------+------------------------------------------+\n|        1 | 0.00534775 | select * from t1 where b&gt;=1 and b &lt;=1000 |\n|        2 | 0.00605625 | select * from t1 where b&gt;=1 and b &lt;=2000 |\n+----------+------------+------------------------------------------+\n2 rows in set, 1 warning (0.00 sec)</code></pre><h2 id=\"计算操作\"><a href=\"#计算操作\" class=\"headerlink\" title=\"计算操作\"></a>计算操作</h2><p>即使是简单的计算</p>\n<pre><code class=\"mysql\">explain select * from t1 where b-1 =1000;</code></pre>\n<p>优化：将计算操作放在等号后面</p>\n<pre><code class=\"mysql\">explain select * from t1 where b =1000 + 1;</code></pre>\n"},{"title":"锁","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-03-14T03:14:09.000Z","password":null,"summary":null,"_content":"\n锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。\n\n## 全局锁\n\nMySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。\n\n```mysql\nFLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;\n```\n\n当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。\n\n场景\n\n一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。\n\nmysqldump 包含一个参数 --single-transaction，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。\n\n## 表级锁\n\n表级锁有两种：表锁和元数据锁。\n\n### 表锁\n\n场景\n\n1. 事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；\n2. 事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。\n\n```mysql\nlock tables t14 read;\nlock tables t14 write;\n```\n\n表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。\n\n### 元数据锁\n\nMDL不需要显式使用，在访问一个表的时候会被自动加上。\n\nMDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。\n\n对开发而言尽量避免慢查询，事务要及时提交，避免大事务。\n\n对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。\n\n在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。\n\n```mysql\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n```\n\n## 行锁\n\nInnoDB后来居上：\n\n- InnoDB 支持事务：适合在并发条件下要求数据一致的场景。\n- InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。\n\n### 两阶段锁\n\n行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。因此：\n\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n\n### 行锁\n\n两种类型的行锁：\n\n- 共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；\n- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。\n\n共享锁（S）：select * from table_name where … lock in share mode;\n排他锁（X）：select * from table_name where … for update(当前读)。\n\n### 行锁算法\n\nRecord Lock：单个记录上的索引加锁。\nGap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。\nNext-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。\n\n### 加锁规则\n\n5.x系列<=5.7.24，8.0系列 <=8.0.13\n\n1. 原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。\n2. 原则2：查找过程中访问到的对象才会加锁。\n3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。\n4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。\n5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n### 事务隔离级别\n\nRead uncommitted（读未提交）: 在该隔离级别，所有事务都可以看到其它未提交事务的执行结果。可能会出现\n脏读。\n**Read Committed（读已提交，简称： RC）**：一个事务只能看见已经提交事务所做的改变。因为同一事务的其它\n实例在该实例处理期间可能会有新的 commit，**所以可能出现幻读**。\n**Repeatable Read（可重复读，简称：RR）**：这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在\n并发读取数据时，会看到同样的数据行。消除了脏读、不可重复读，**默认也不会出现幻读**。\n**Serializable（串行）**：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。\n\n脏读：读取未提交的事务。\n幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n#### 非索引字段查询（RC）\n\n如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。\n\n#### 唯一索引查询（RC）\n\n如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。\n\n#### 非唯一索引查询（RC）\n\n如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。\n\n#### 非索引字段查询（RR）\n\nRR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）\n\n#### 唯一索引查询（RR）\n\n如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。\n\n以唯一索引为条件的当前读，不会有 GAP 锁。\n\n#### 非唯一索引查询(RR)\n\n新增GAP锁+对应数据的X锁\n\n## 悲观锁\n\n当我们要对数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制\n\n优点：利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳\n缺点：一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量\n\n悲观锁的适用场景：写入操作比较频繁的场景\n\n## 乐观锁\n\n乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。\n\n优点：由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高\n缺点：锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈\n\n乐观锁的适用场景：读取操作比较频繁的场景\n\n## 锁定位\n\n1、show processlist，查看state\n\n## 死锁\n\n死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。\n\n**“唯一键”引起的死锁**\n\n会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。\n\n之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。\n\n**解决方法**\n\n1. 检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；\n2. 等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。\n\n方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。\n\n**降低死锁概率**\n\n1. 更新 SQL 的 where 条件尽量用索引；\n2. 基于 primary 或 unique key 更新数据；\n3. 减少范围更新，尤其非主键、非唯一索引上的范围更新；\n4. 加锁顺序一致，尽可能一次性锁定所有需要行；\n5. 将 RR 隔离级别调整为 RC 隔离级别。\n\n**分析死锁**\n\n```mysql\nSHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息\n```\n\n另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。\n\nINNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。\n\nINNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。\n\nINNODB_LOCK_WAITS记录了事务的锁等待状态。","source":"_posts/锁.md","raw":"---\ntitle: 锁\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-03-14 11:14:09\npassword:\nsummary:\ntags:\n- mysql\ncategories:\n- mysql\n---\n\n锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。\n\n## 全局锁\n\nMySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。\n\n```mysql\nFLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;\n```\n\n当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。\n\n场景\n\n一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。\n\nmysqldump 包含一个参数 --single-transaction，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。\n\n## 表级锁\n\n表级锁有两种：表锁和元数据锁。\n\n### 表锁\n\n场景\n\n1. 事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；\n2. 事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。\n\n```mysql\nlock tables t14 read;\nlock tables t14 write;\n```\n\n表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。\n\n### 元数据锁\n\nMDL不需要显式使用，在访问一个表的时候会被自动加上。\n\nMDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。\n\n对开发而言尽量避免慢查询，事务要及时提交，避免大事务。\n\n对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。\n\n在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。\n\n```mysql\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n```\n\n## 行锁\n\nInnoDB后来居上：\n\n- InnoDB 支持事务：适合在并发条件下要求数据一致的场景。\n- InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。\n\n### 两阶段锁\n\n行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。因此：\n\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n\n### 行锁\n\n两种类型的行锁：\n\n- 共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；\n- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。\n\n共享锁（S）：select * from table_name where … lock in share mode;\n排他锁（X）：select * from table_name where … for update(当前读)。\n\n### 行锁算法\n\nRecord Lock：单个记录上的索引加锁。\nGap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。\nNext-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。\n\n### 加锁规则\n\n5.x系列<=5.7.24，8.0系列 <=8.0.13\n\n1. 原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。\n2. 原则2：查找过程中访问到的对象才会加锁。\n3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。\n4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。\n5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n### 事务隔离级别\n\nRead uncommitted（读未提交）: 在该隔离级别，所有事务都可以看到其它未提交事务的执行结果。可能会出现\n脏读。\n**Read Committed（读已提交，简称： RC）**：一个事务只能看见已经提交事务所做的改变。因为同一事务的其它\n实例在该实例处理期间可能会有新的 commit，**所以可能出现幻读**。\n**Repeatable Read（可重复读，简称：RR）**：这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在\n并发读取数据时，会看到同样的数据行。消除了脏读、不可重复读，**默认也不会出现幻读**。\n**Serializable（串行）**：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。\n\n脏读：读取未提交的事务。\n幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n#### 非索引字段查询（RC）\n\n如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。\n\n#### 唯一索引查询（RC）\n\n如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。\n\n#### 非唯一索引查询（RC）\n\n如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。\n\n#### 非索引字段查询（RR）\n\nRR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）\n\n#### 唯一索引查询（RR）\n\n如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。\n\n以唯一索引为条件的当前读，不会有 GAP 锁。\n\n#### 非唯一索引查询(RR)\n\n新增GAP锁+对应数据的X锁\n\n## 悲观锁\n\n当我们要对数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制\n\n优点：利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳\n缺点：一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量\n\n悲观锁的适用场景：写入操作比较频繁的场景\n\n## 乐观锁\n\n乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。\n\n优点：由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高\n缺点：锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈\n\n乐观锁的适用场景：读取操作比较频繁的场景\n\n## 锁定位\n\n1、show processlist，查看state\n\n## 死锁\n\n死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。\n\n**“唯一键”引起的死锁**\n\n会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。\n\n之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。\n\n**解决方法**\n\n1. 检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；\n2. 等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。\n\n方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。\n\n**降低死锁概率**\n\n1. 更新 SQL 的 where 条件尽量用索引；\n2. 基于 primary 或 unique key 更新数据；\n3. 减少范围更新，尤其非主键、非唯一索引上的范围更新；\n4. 加锁顺序一致，尽可能一次性锁定所有需要行；\n5. 将 RR 隔离级别调整为 RC 隔离级别。\n\n**分析死锁**\n\n```mysql\nSHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息\n```\n\n另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。\n\nINNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。\n\nINNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。\n\nINNODB_LOCK_WAITS记录了事务的锁等待状态。","slug":"锁","published":1,"updated":"2021-04-01T23:01:50.197Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckn8tqxmt005pncufke16uxzu","content":"<p>锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。</p>\n<h2 id=\"全局锁\"><a href=\"#全局锁\" class=\"headerlink\" title=\"全局锁\"></a>全局锁</h2><p>MySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">FLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。</p>\n<p>场景</p>\n<p>一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。</p>\n<p>mysqldump 包含一个参数 –single-transaction，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。</p>\n<h2 id=\"表级锁\"><a href=\"#表级锁\" class=\"headerlink\" title=\"表级锁\"></a>表级锁</h2><p>表级锁有两种：表锁和元数据锁。</p>\n<h3 id=\"表锁\"><a href=\"#表锁\" class=\"headerlink\" title=\"表锁\"></a>表锁</h3><p>场景</p>\n<ol>\n<li>事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；</li>\n<li>事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。</li>\n</ol>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">lock tables t14 read;\nlock tables t14 write;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。</p>\n<h3 id=\"元数据锁\"><a href=\"#元数据锁\" class=\"headerlink\" title=\"元数据锁\"></a>元数据锁</h3><p>MDL不需要显式使用，在访问一个表的时候会被自动加上。</p>\n<p>MDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。</p>\n<p>对开发而言尽量避免慢查询，事务要及时提交，避免大事务。</p>\n<p>对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。</p>\n<p>在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。</p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">ALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h2 id=\"行锁\"><a href=\"#行锁\" class=\"headerlink\" title=\"行锁\"></a>行锁</h2><p>InnoDB后来居上：</p>\n<ul>\n<li>InnoDB 支持事务：适合在并发条件下要求数据一致的场景。</li>\n<li>InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。</li>\n</ul>\n<h3 id=\"两阶段锁\"><a href=\"#两阶段锁\" class=\"headerlink\" title=\"两阶段锁\"></a>两阶段锁</h3><p>行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。因此：</p>\n<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>\n<h3 id=\"行锁-1\"><a href=\"#行锁-1\" class=\"headerlink\" title=\"行锁\"></a>行锁</h3><p>两种类型的行锁：</p>\n<ul>\n<li>共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；</li>\n<li>排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。</li>\n</ul>\n<p>共享锁（S）：select <em> from table_name where … lock in share mode;<br>排他锁（X）：select </em> from table_name where … for update(当前读)。</p>\n<h3 id=\"行锁算法\"><a href=\"#行锁算法\" class=\"headerlink\" title=\"行锁算法\"></a>行锁算法</h3><p>Record Lock：单个记录上的索引加锁。<br>Gap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。<br>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。</p>\n<h3 id=\"加锁规则\"><a href=\"#加锁规则\" class=\"headerlink\" title=\"加锁规则\"></a>加锁规则</h3><p>5.x系列&lt;=5.7.24，8.0系列 &lt;=8.0.13</p>\n<ol>\n<li>原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。</li>\n<li>原则2：查找过程中访问到的对象才会加锁。</li>\n<li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li>\n<li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li>\n<li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>\n</ol>\n<h3 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h3><p>Read uncommitted（读未提交）: 在该隔离级别，所有事务都可以看到其它未提交事务的执行结果。可能会出现<br>脏读。<br><strong>Read Committed（读已提交，简称： RC）</strong>：一个事务只能看见已经提交事务所做的改变。因为同一事务的其它<br>实例在该实例处理期间可能会有新的 commit，<strong>所以可能出现幻读</strong>。<br><strong>Repeatable Read（可重复读，简称：RR）</strong>：这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在<br>并发读取数据时，会看到同样的数据行。消除了脏读、不可重复读，<strong>默认也不会出现幻读</strong>。<br><strong>Serializable（串行）</strong>：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。</p>\n<p>脏读：读取未提交的事务。<br>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p>\n<h4 id=\"非索引字段查询（RC）\"><a href=\"#非索引字段查询（RC）\" class=\"headerlink\" title=\"非索引字段查询（RC）\"></a>非索引字段查询（RC）</h4><p>如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。</p>\n<h4 id=\"唯一索引查询（RC）\"><a href=\"#唯一索引查询（RC）\" class=\"headerlink\" title=\"唯一索引查询（RC）\"></a>唯一索引查询（RC）</h4><p>如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。</p>\n<h4 id=\"非唯一索引查询（RC）\"><a href=\"#非唯一索引查询（RC）\" class=\"headerlink\" title=\"非唯一索引查询（RC）\"></a>非唯一索引查询（RC）</h4><p>如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。</p>\n<h4 id=\"非索引字段查询（RR）\"><a href=\"#非索引字段查询（RR）\" class=\"headerlink\" title=\"非索引字段查询（RR）\"></a>非索引字段查询（RR）</h4><p>RR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）</p>\n<h4 id=\"唯一索引查询（RR）\"><a href=\"#唯一索引查询（RR）\" class=\"headerlink\" title=\"唯一索引查询（RR）\"></a>唯一索引查询（RR）</h4><p>如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。</p>\n<p>以唯一索引为条件的当前读，不会有 GAP 锁。</p>\n<h4 id=\"非唯一索引查询-RR\"><a href=\"#非唯一索引查询-RR\" class=\"headerlink\" title=\"非唯一索引查询(RR)\"></a>非唯一索引查询(RR)</h4><p>新增GAP锁+对应数据的X锁</p>\n<h2 id=\"悲观锁\"><a href=\"#悲观锁\" class=\"headerlink\" title=\"悲观锁\"></a>悲观锁</h2><p>当我们要对数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制</p>\n<p>优点：利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳<br>缺点：一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量</p>\n<p>悲观锁的适用场景：写入操作比较频繁的场景</p>\n<h2 id=\"乐观锁\"><a href=\"#乐观锁\" class=\"headerlink\" title=\"乐观锁\"></a>乐观锁</h2><p>乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。</p>\n<p>优点：由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高<br>缺点：锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈</p>\n<p>乐观锁的适用场景：读取操作比较频繁的场景</p>\n<h2 id=\"锁定位\"><a href=\"#锁定位\" class=\"headerlink\" title=\"锁定位\"></a>锁定位</h2><p>1、show processlist，查看state</p>\n<h2 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h2><p>死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。</p>\n<p><strong>“唯一键”引起的死锁</strong></p>\n<p>会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。</p>\n<p>之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。</p>\n<p><strong>解决方法</strong></p>\n<ol>\n<li>检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；</li>\n<li>等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。</li>\n</ol>\n<p>方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。</p>\n<p><strong>降低死锁概率</strong></p>\n<ol>\n<li>更新 SQL 的 where 条件尽量用索引；</li>\n<li>基于 primary 或 unique key 更新数据；</li>\n<li>减少范围更新，尤其非主键、非唯一索引上的范围更新；</li>\n<li>加锁顺序一致，尽可能一次性锁定所有需要行；</li>\n<li>将 RR 隔离级别调整为 RC 隔离级别。</li>\n</ol>\n<p><strong>分析死锁</strong></p>\n<pre class=\"line-numbers language-mysql\"><code class=\"language-mysql\">SHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。</p>\n<p>INNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。</p>\n<p>INNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。</p>\n<p>INNODB_LOCK_WAITS记录了事务的锁等待状态。</p>\n","site":{"data":{"musics":[{"name":"夜曲","artist":"周杰伦","url":"/medias/music/yequ.mp3","cover":"/medias/music/avatars/yequ.jpg"},{"name":"一路向北","artist":"周杰伦","url":"/medias/music/yiluxiangbei.mp3","cover":"/medias/music/avatars/yiluxiangbei.jpg"},{"name":"来自天堂的魔鬼","artist":"邓紫棋","url":"/medias/music/tiantangdemogui.mp3","cover":"/medias/music/avatars/tiantangdemogui.jpg"},{"name":"倒数","artist":"邓紫棋","url":"/medias/music/daoshu.mp3","cover":"/medias/music/avatars/daoshu.jpg"}],"friends":[{"name":"博客园","url":"https://www.cnblogs.com/hainingwyx/","title":"访问主页","introduction":"hainingwyx博客园主页","avatar":"https://www.cnblogs.com/images/logo.svg?v=R9M0WmLAIPVydmdzE2keuvnjl-bPR7_35oHqtiBzGsM"}]}},"excerpt":"","more":"<p>锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。</p>\n<h2 id=\"全局锁\"><a href=\"#全局锁\" class=\"headerlink\" title=\"全局锁\"></a>全局锁</h2><p>MySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。</p>\n<pre><code class=\"mysql\">FLUSH TABLES WITH READ LOCK;\nUNLOCK TABLES;</code></pre>\n<p>当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。</p>\n<p>场景</p>\n<p>一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。</p>\n<p>mysqldump 包含一个参数 –single-transaction，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。</p>\n<h2 id=\"表级锁\"><a href=\"#表级锁\" class=\"headerlink\" title=\"表级锁\"></a>表级锁</h2><p>表级锁有两种：表锁和元数据锁。</p>\n<h3 id=\"表锁\"><a href=\"#表锁\" class=\"headerlink\" title=\"表锁\"></a>表锁</h3><p>场景</p>\n<ol>\n<li>事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；</li>\n<li>事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。</li>\n</ol>\n<pre><code class=\"mysql\">lock tables t14 read;\nlock tables t14 write;</code></pre>\n<p>表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。</p>\n<h3 id=\"元数据锁\"><a href=\"#元数据锁\" class=\"headerlink\" title=\"元数据锁\"></a>元数据锁</h3><p>MDL不需要显式使用，在访问一个表的时候会被自动加上。</p>\n<p>MDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。</p>\n<p>对开发而言尽量避免慢查询，事务要及时提交，避免大事务。</p>\n<p>对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。</p>\n<p>在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。</p>\n<pre><code class=\"mysql\">ALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...</code></pre>\n<h2 id=\"行锁\"><a href=\"#行锁\" class=\"headerlink\" title=\"行锁\"></a>行锁</h2><p>InnoDB后来居上：</p>\n<ul>\n<li>InnoDB 支持事务：适合在并发条件下要求数据一致的场景。</li>\n<li>InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。</li>\n</ul>\n<h3 id=\"两阶段锁\"><a href=\"#两阶段锁\" class=\"headerlink\" title=\"两阶段锁\"></a>两阶段锁</h3><p>行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。因此：</p>\n<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>\n<h3 id=\"行锁-1\"><a href=\"#行锁-1\" class=\"headerlink\" title=\"行锁\"></a>行锁</h3><p>两种类型的行锁：</p>\n<ul>\n<li>共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；</li>\n<li>排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。</li>\n</ul>\n<p>共享锁（S）：select <em> from table_name where … lock in share mode;<br>排他锁（X）：select </em> from table_name where … for update(当前读)。</p>\n<h3 id=\"行锁算法\"><a href=\"#行锁算法\" class=\"headerlink\" title=\"行锁算法\"></a>行锁算法</h3><p>Record Lock：单个记录上的索引加锁。<br>Gap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。<br>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。</p>\n<h3 id=\"加锁规则\"><a href=\"#加锁规则\" class=\"headerlink\" title=\"加锁规则\"></a>加锁规则</h3><p>5.x系列&lt;=5.7.24，8.0系列 &lt;=8.0.13</p>\n<ol>\n<li>原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。</li>\n<li>原则2：查找过程中访问到的对象才会加锁。</li>\n<li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li>\n<li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li>\n<li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>\n</ol>\n<h3 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h3><p>Read uncommitted（读未提交）: 在该隔离级别，所有事务都可以看到其它未提交事务的执行结果。可能会出现<br>脏读。<br><strong>Read Committed（读已提交，简称： RC）</strong>：一个事务只能看见已经提交事务所做的改变。因为同一事务的其它<br>实例在该实例处理期间可能会有新的 commit，<strong>所以可能出现幻读</strong>。<br><strong>Repeatable Read（可重复读，简称：RR）</strong>：这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在<br>并发读取数据时，会看到同样的数据行。消除了脏读、不可重复读，<strong>默认也不会出现幻读</strong>。<br><strong>Serializable（串行）</strong>：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。</p>\n<p>脏读：读取未提交的事务。<br>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p>\n<h4 id=\"非索引字段查询（RC）\"><a href=\"#非索引字段查询（RC）\" class=\"headerlink\" title=\"非索引字段查询（RC）\"></a>非索引字段查询（RC）</h4><p>如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。</p>\n<h4 id=\"唯一索引查询（RC）\"><a href=\"#唯一索引查询（RC）\" class=\"headerlink\" title=\"唯一索引查询（RC）\"></a>唯一索引查询（RC）</h4><p>如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。</p>\n<h4 id=\"非唯一索引查询（RC）\"><a href=\"#非唯一索引查询（RC）\" class=\"headerlink\" title=\"非唯一索引查询（RC）\"></a>非唯一索引查询（RC）</h4><p>如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。</p>\n<h4 id=\"非索引字段查询（RR）\"><a href=\"#非索引字段查询（RR）\" class=\"headerlink\" title=\"非索引字段查询（RR）\"></a>非索引字段查询（RR）</h4><p>RR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）</p>\n<h4 id=\"唯一索引查询（RR）\"><a href=\"#唯一索引查询（RR）\" class=\"headerlink\" title=\"唯一索引查询（RR）\"></a>唯一索引查询（RR）</h4><p>如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。</p>\n<p>以唯一索引为条件的当前读，不会有 GAP 锁。</p>\n<h4 id=\"非唯一索引查询-RR\"><a href=\"#非唯一索引查询-RR\" class=\"headerlink\" title=\"非唯一索引查询(RR)\"></a>非唯一索引查询(RR)</h4><p>新增GAP锁+对应数据的X锁</p>\n<h2 id=\"悲观锁\"><a href=\"#悲观锁\" class=\"headerlink\" title=\"悲观锁\"></a>悲观锁</h2><p>当我们要对数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制</p>\n<p>优点：利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳<br>缺点：一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量</p>\n<p>悲观锁的适用场景：写入操作比较频繁的场景</p>\n<h2 id=\"乐观锁\"><a href=\"#乐观锁\" class=\"headerlink\" title=\"乐观锁\"></a>乐观锁</h2><p>乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。</p>\n<p>优点：由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高<br>缺点：锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈</p>\n<p>乐观锁的适用场景：读取操作比较频繁的场景</p>\n<h2 id=\"锁定位\"><a href=\"#锁定位\" class=\"headerlink\" title=\"锁定位\"></a>锁定位</h2><p>1、show processlist，查看state</p>\n<h2 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h2><p>死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。</p>\n<p><strong>“唯一键”引起的死锁</strong></p>\n<p>会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。</p>\n<p>之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。</p>\n<p><strong>解决方法</strong></p>\n<ol>\n<li>检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；</li>\n<li>等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。</li>\n</ol>\n<p>方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。</p>\n<p><strong>降低死锁概率</strong></p>\n<ol>\n<li>更新 SQL 的 where 条件尽量用索引；</li>\n<li>基于 primary 或 unique key 更新数据；</li>\n<li>减少范围更新，尤其非主键、非唯一索引上的范围更新；</li>\n<li>加锁顺序一致，尽可能一次性锁定所有需要行；</li>\n<li>将 RR 隔离级别调整为 RC 隔离级别。</li>\n</ol>\n<p><strong>分析死锁</strong></p>\n<pre><code class=\"mysql\">SHOW FULL PROCESSLIST; //State字段，waiting for ... lock\nshow engine innodb status\\G; //查看最后一次死锁信息</code></pre>\n<p>另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。</p>\n<p>INNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。</p>\n<p>INNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。</p>\n<p>INNODB_LOCK_WAITS记录了事务的锁等待状态。</p>\n"}],"PostAsset":[{"_id":"source/_posts/redis主从同步/duxiefenli.jpg","slug":"duxiefenli.jpg","post":"ckn8tqxjt003qncufsd51ya48","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/transport.jpg","slug":"transport.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka认证/compare.jpg","slug":"compare.jpg","post":"ckn8tqxgo001incufg0inc3ip","modified":1,"renderable":0},{"_id":"source/_posts/KafkaAdminClient/yuanli.jpg","slug":"yuanli.jpg","post":"ckn8tqws20002ncufjk01u37y","modified":1,"renderable":0},{"_id":"source/_posts/kafka思维导图/kafka.png","slug":"kafka.png","post":"ckn8tqwsj000bncufimld3qw2","modified":1,"renderable":0},{"_id":"source/_posts/Kafka控制器/Failover.jpg","slug":"Failover.jpg","post":"ckn8tqwsb0005ncufbcw0yt9l","modified":1,"renderable":0},{"_id":"source/_posts/Kafka控制器/data.jpg","slug":"data.jpg","post":"ckn8tqwsb0005ncufbcw0yt9l","modified":1,"renderable":0},{"_id":"source/_posts/Kafka控制器/zookeeper.jpg","slug":"zookeeper.jpg","post":"ckn8tqwsb0005ncufbcw0yt9l","modified":1,"renderable":0},{"_id":"source/_posts/kafka-Broker请求处理/reactor.jpg","slug":"reactor.jpg","post":"ckn8tqwsu000incufq7oohd7z","modified":1,"renderable":0},{"_id":"source/_posts/kafka-Broker请求处理/work.jpg","slug":"work.jpg","post":"ckn8tqwsu000incufq7oohd7z","modified":1,"renderable":0},{"_id":"source/_posts/rabbitmq思维导图/rabbitmq.png","slug":"rabbitmq.png","post":"ckn8tqxi0001wncufr7j49qj5","modified":1,"renderable":0},{"_id":"source/_posts/kafka集群配置/atoconfig.png","post":"ckn8tqxi4001zncufk2qe9pny","slug":"atoconfig.png","modified":1,"renderable":1},{"_id":"source/_posts/rabbitmq概念/moxin.png","post":"ckn8tqxi80024ncufxl19csvf","slug":"moxin.png","modified":1,"renderable":1},{"_id":"source/_posts/redis6-0/acl_cmd.jpg","slug":"acl_cmd.jpg","post":"ckn8tqxjh003encufj0aacev6","modified":1,"renderable":0},{"_id":"source/_posts/redis思维导图/redis.png","slug":"redis.png","post":"ckn8tqxki0042ncufn7i04ny0","modified":1,"renderable":0},{"_id":"source/_posts/redis消息队列/stream.jpg","post":"ckn8tqxkv004bncufntslqrsf","slug":"stream.jpg","modified":1,"renderable":1},{"_id":"source/_posts/redis主从同步/master_slave_slave.jpg","slug":"master_slave_slave.jpg","post":"ckn8tqxjt003qncufsd51ya48","modified":1,"renderable":0},{"_id":"source/_posts/redis主从同步/zhucongtongbu.jpg","slug":"zhucongtongbu.jpg","post":"ckn8tqxjt003qncufsd51ya48","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/bad.jpg","slug":"bad.jpg","post":"ckn8tqxib0028ncufh44tkbai","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/good.jpg","slug":"good.jpg","post":"ckn8tqxib0028ncufh44tkbai","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/water.jpg","slug":"water.jpg","post":"ckn8tqxib0028ncufh44tkbai","modified":1,"renderable":0},{"_id":"source/_posts/kafka高水位和Leader-Epoch/watertime.jpg","slug":"watertime.jpg","post":"ckn8tqxib0028ncufh44tkbai","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/compare.jpg","slug":"compare.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/comsumedown.jpg","slug":"comsumedown.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/groups_shell.png","post":"ckn8tqxgh001bncufekvo8dmw","slug":"groups_shell.png","modified":1,"renderable":1},{"_id":"source/_posts/kafka消费者/leavegroup.jpg","slug":"leavegroup.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/newadd.jpg","slug":"newadd.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/plan1.jpg","slug":"plan1.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/plan2.jpg","slug":"plan2.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/kafka消费者/state.jpeg","post":"ckn8tqxgh001bncufekvo8dmw","slug":"state.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/kafka消费者/stragey.jpg","slug":"stragey.jpg","post":"ckn8tqxgh001bncufekvo8dmw","modified":1,"renderable":0},{"_id":"source/_posts/sort-algorithms/1.png","post":"ckn8tqxly004zncuftkgk2cg1","slug":"1.png","modified":1,"renderable":1},{"_id":"source/_posts/redis缓存/buyizhi.jpg","slug":"buyizhi.jpg","post":"ckn8tqxl1004encuf8hjpead4","modified":1,"renderable":0},{"_id":"source/_posts/redis缓存/buyizhi2.jpg","slug":"buyizhi2.jpg","post":"ckn8tqxl1004encuf8hjpead4","modified":1,"renderable":0}],"PostCategory":[{"post_id":"ckn8tqwsd0006ncufkou3y1s4","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqwsp000encuf0odvvpnv"},{"post_id":"ckn8tqwrq0001ncufrcjt05it","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqwsx000jncufjunn923g"},{"post_id":"ckn8tqwsg0007ncuf5eiiqd86","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqwt2000mncufor9676pz"},{"post_id":"ckn8tqwsj000bncufimld3qw2","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwt7000pncuflpmp45xv"},{"post_id":"ckn8tqws20002ncufjk01u37y","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwta000sncufe8500m9d"},{"post_id":"ckn8tqwsn000dncuf2vqirlxg","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqwtd000vncuf11cijpyz"},{"post_id":"ckn8tqwsu000incufq7oohd7z","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwtf000yncufzbjg2l0c"},{"post_id":"ckn8tqwsb0005ncufbcw0yt9l","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwth0010ncuffkr7n3sw"},{"post_id":"ckn8tqwsz000lncuftxw4v7et","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwti0012ncufcwqx2dnc"},{"post_id":"ckn8tqwt5000oncuf5boda6ub","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwtj0014ncufinwgwnoi"},{"post_id":"ckn8tqwt9000rncuflb0abd41","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwtl0016ncufawu98i4u"},{"post_id":"ckn8tqwtb000uncuf7m41c13z","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwtn0018ncufeuu7ti4v"},{"post_id":"ckn8tqwte000xncufud02ada5","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqwtn0019ncufplgm3xpg"},{"post_id":"ckn8tqxgg001ancufi0mv8wae","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxgn001gncuffk1vgdzv"},{"post_id":"ckn8tqxgh001bncufekvo8dmw","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxgp001jncufv4q6q1gl"},{"post_id":"ckn8tqxgj001dncufnlvfhqh5","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxgq001lncufdwrb1ffr"},{"post_id":"ckn8tqxgl001fncufwc1pct05","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxgs001nncufuo5h3xf2"},{"post_id":"ckn8tqxgo001incufg0inc3ip","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxgs001oncufjvk70ru3"},{"post_id":"ckn8tqxhh001rncufuncuq2rs","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxi50020ncufaxjmqub6"},{"post_id":"ckn8tqxhk001tncuf9ukaylqa","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxi90025ncuf5ekpylo8"},{"post_id":"ckn8tqxi4001zncufk2qe9pny","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxie002ancufrnbk6fy8"},{"post_id":"ckn8tqxib0028ncufh44tkbai","category_id":"ckn8tqwsh0008ncuf73e35nud","_id":"ckn8tqxim002hncufk3w1y8r6"},{"post_id":"ckn8tqxi0001wncufr7j49qj5","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxiq002kncufkqqvldfg"},{"post_id":"ckn8tqxid0029ncuffezyhggb","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxit002nncufe3aby38y"},{"post_id":"ckn8tqxih002encufq5pxzox2","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxiw002qncufebkbhfoo"},{"post_id":"ckn8tqxi80024ncufxl19csvf","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxiz002tncufth26bjeo"},{"post_id":"ckn8tqxij002gncufhkjn9tyv","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxj5002yncufklcmbcdu"},{"post_id":"ckn8tqxio002jncufbqmlpy9j","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxj70031ncuf819djp5s"},{"post_id":"ckn8tqxis002mncufhf7b10v3","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxja0035ncuf9jxm4eh4"},{"post_id":"ckn8tqxiy002sncuf7wpmkd5s","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxjd0039ncufsykh5u85"},{"post_id":"ckn8tqxj60030ncufg8onrj9v","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxjf003cncufpxh83jyv"},{"post_id":"ckn8tqxiv002pncufbk5llwbn","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxjj003fncufbh6oj45l"},{"post_id":"ckn8tqxiv002pncufbk5llwbn","category_id":"ckn8tqxj4002xncuffxrgxq9r","_id":"ckn8tqxjl003incuf592d6rq8"},{"post_id":"ckn8tqxj80033ncuf97pzqe8g","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxjo003lncuf7ue68wcm"},{"post_id":"ckn8tqxjb0038ncufov2efeuc","category_id":"ckn8tqxi70022ncufr31mvab9","_id":"ckn8tqxjr003oncufsrgbu8cj"},{"post_id":"ckn8tqxj2002wncuf0wrnruh6","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxk5003rncuf0foug8g4"},{"post_id":"ckn8tqxje003bncuf7tr0yman","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxka003uncufpfhy1d8a"},{"post_id":"ckn8tqxjh003encufj0aacev6","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxke003xncufsltdnfyf"},{"post_id":"ckn8tqxjk003hncufbbalas4u","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxkh0040ncufl3xgvsp7"},{"post_id":"ckn8tqxjp003nncufst3p9i7i","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxkl0043ncufp67j3evt"},{"post_id":"ckn8tqxjt003qncufsd51ya48","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxkp0046ncufmwo1v60i"},{"post_id":"ckn8tqxk7003tncufl656glnl","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxks0049ncufz99cp7iw"},{"post_id":"ckn8tqxkb003wncufffzf1l3c","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxkx004cncufhsdovsn9"},{"post_id":"ckn8tqxkf003zncufncrh6eud","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxl3004fncufzzszp9p9"},{"post_id":"ckn8tqxki0042ncufn7i04ny0","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxl7004incuf5yvwkdyn"},{"post_id":"ckn8tqxkn0045ncufpusffnb8","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxlb004lncufosh32wlf"},{"post_id":"ckn8tqxkq0048ncufy68ljlkl","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxlh004oncufcx2ea5bg"},{"post_id":"ckn8tqxkv004bncufntslqrsf","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxln004rncufotlu9ude"},{"post_id":"ckn8tqxl1004encuf8hjpead4","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxlr004uncufvmae9s1t"},{"post_id":"ckn8tqxl5004hncufe067efjc","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxlw004xncufm9zngaj6"},{"post_id":"ckn8tqxl8004kncufw6vz0jxu","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxm20050ncufadpyyrex"},{"post_id":"ckn8tqxld004nncuffa5vn6ql","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxm60053ncufuj5mzf3h"},{"post_id":"ckn8tqxll004qncufspoqs1fq","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxma0058ncufxg3atsge"},{"post_id":"ckn8tqxlp004tncufzrmkbbx1","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmd005bncufpjktcvpf"},{"post_id":"ckn8tqxlt004wncufxqg6gibh","category_id":"ckn8tqxja0036ncufqkyzd15y","_id":"ckn8tqxmh005encuf7qel86g3"},{"post_id":"ckn8tqxm40052ncuf97exk8s4","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmm005hncufmyiei5e0"},{"post_id":"ckn8tqxm90057ncuf7c22ny0x","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmq005kncufu2d4a7ub"},{"post_id":"ckn8tqxmb005ancufvbxcq63k","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxms005nncuff4lfkjx7"},{"post_id":"ckn8tqxly004zncuftkgk2cg1","category_id":"ckn8tqxm70054ncufrnagd167","_id":"ckn8tqxmu005qncufvf1cut8q"},{"post_id":"ckn8tqxme005dncuf4251i3po","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmv005sncufvu4p5ok5"},{"post_id":"ckn8tqxmi005gncufbta0twu6","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmw005uncufdsxqbnti"},{"post_id":"ckn8tqxmn005jncufwy77zn0q","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmx005wncufrqoa4a5o"},{"post_id":"ckn8tqxmr005mncufkehin407","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmy005yncuf01berjk6"},{"post_id":"ckn8tqxmt005pncufke16uxzu","category_id":"ckn8tqws80003ncufd8z44tlo","_id":"ckn8tqxmz005zncuftc4yiffk"}],"PostTag":[{"post_id":"ckn8tqwsd0006ncufkou3y1s4","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqwsj000ancuf4dupomz0"},{"post_id":"ckn8tqwrq0001ncufrcjt05it","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqwsm000cncuf7bq1b4ed"},{"post_id":"ckn8tqwsg0007ncuf5eiiqd86","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqwsu000hncufm1zuwa6v"},{"post_id":"ckn8tqwsj000bncufimld3qw2","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwsy000kncufksvdaj24"},{"post_id":"ckn8tqws20002ncufjk01u37y","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwt4000nncufu0lkzpck"},{"post_id":"ckn8tqwsn000dncuf2vqirlxg","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqwt8000qncufdjeny52f"},{"post_id":"ckn8tqwsu000incufq7oohd7z","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwtb000tncufmjndurzh"},{"post_id":"ckn8tqwsb0005ncufbcw0yt9l","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwte000wncufzu6pm1gx"},{"post_id":"ckn8tqwsz000lncuftxw4v7et","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwtg000zncufet64taqp"},{"post_id":"ckn8tqwt5000oncuf5boda6ub","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwti0011ncufkl1jbk38"},{"post_id":"ckn8tqwt9000rncuflb0abd41","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwtj0013ncufesdwrtqr"},{"post_id":"ckn8tqwtb000uncuf7m41c13z","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwtl0015ncufc1zsljpf"},{"post_id":"ckn8tqwte000xncufud02ada5","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqwtm0017ncufbnrdcn05"},{"post_id":"ckn8tqxgg001ancufi0mv8wae","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxgj001cncuf12k6wu4r"},{"post_id":"ckn8tqxgh001bncufekvo8dmw","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxgl001encufqwgznm8x"},{"post_id":"ckn8tqxgj001dncufnlvfhqh5","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxgn001hncuf3cln08z3"},{"post_id":"ckn8tqxgl001fncufwc1pct05","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxgq001kncufwp3x1i0o"},{"post_id":"ckn8tqxgo001incufg0inc3ip","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxgr001mncufdvm5m8al"},{"post_id":"ckn8tqxhh001rncufuncuq2rs","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxhz001vncufp499uypg"},{"post_id":"ckn8tqxhk001tncuf9ukaylqa","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxi3001yncufh4trq42u"},{"post_id":"ckn8tqxi4001zncufk2qe9pny","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxib0027ncuf6r4akigy"},{"post_id":"ckn8tqxib0028ncufh44tkbai","tag_id":"ckn8tqwsh0009ncufnh2zapgm","_id":"ckn8tqxig002dncufh1s1b0wa"},{"post_id":"ckn8tqxi0001wncufr7j49qj5","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxij002fncuf4yao8lj1"},{"post_id":"ckn8tqxid0029ncuffezyhggb","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxin002incuftqd8hv20"},{"post_id":"ckn8tqxih002encufq5pxzox2","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxir002lncufxegn96xs"},{"post_id":"ckn8tqxi80024ncufxl19csvf","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxiu002oncufls58b6wk"},{"post_id":"ckn8tqxij002gncufhkjn9tyv","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxix002rncufxyspojfn"},{"post_id":"ckn8tqxio002jncufbqmlpy9j","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxj1002vncuf2r6tde2k"},{"post_id":"ckn8tqxis002mncufhf7b10v3","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxj5002zncuf5heoaxwv"},{"post_id":"ckn8tqxiy002sncuf7wpmkd5s","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxj80032ncufq4nsfk29"},{"post_id":"ckn8tqxj60030ncufg8onrj9v","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxjb0037ncufd8b99stq"},{"post_id":"ckn8tqxiv002pncufbk5llwbn","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxjd003ancufyszqfcfd"},{"post_id":"ckn8tqxiv002pncufbk5llwbn","tag_id":"ckn8tqxj0002uncufkzohae58","_id":"ckn8tqxjh003dncufafq32sxz"},{"post_id":"ckn8tqxj80033ncuf97pzqe8g","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxjk003gncufnuh2zfty"},{"post_id":"ckn8tqxjb0038ncufov2efeuc","tag_id":"ckn8tqxi80023ncufc1tt218k","_id":"ckn8tqxjm003jncufrlgijl85"},{"post_id":"ckn8tqxj2002wncuf0wrnruh6","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxjp003mncufokofy57b"},{"post_id":"ckn8tqxje003bncuf7tr0yman","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxjt003pncufav3yovau"},{"post_id":"ckn8tqxjh003encufj0aacev6","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxk6003sncufyrswrznn"},{"post_id":"ckn8tqxjk003hncufbbalas4u","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxkb003vncufhp70qerc"},{"post_id":"ckn8tqxjp003nncufst3p9i7i","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxkf003yncuf7hxyfs8y"},{"post_id":"ckn8tqxjt003qncufsd51ya48","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxki0041ncuf5pqscr9i"},{"post_id":"ckn8tqxk7003tncufl656glnl","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxkm0044ncufdssqiga7"},{"post_id":"ckn8tqxkb003wncufffzf1l3c","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxkq0047ncuflhexjnek"},{"post_id":"ckn8tqxkf003zncufncrh6eud","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxku004ancufl34o894k"},{"post_id":"ckn8tqxki0042ncufn7i04ny0","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxl0004dncufevos2v21"},{"post_id":"ckn8tqxkn0045ncufpusffnb8","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxl4004gncufdij7ecb7"},{"post_id":"ckn8tqxkq0048ncufy68ljlkl","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxl8004jncufutk0m6af"},{"post_id":"ckn8tqxkv004bncufntslqrsf","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxlc004mncufaf4zhg29"},{"post_id":"ckn8tqxl1004encuf8hjpead4","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxlk004pncuflp6igy83"},{"post_id":"ckn8tqxl5004hncufe067efjc","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxlo004sncufa8f2ygit"},{"post_id":"ckn8tqxl8004kncufw6vz0jxu","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxls004vncufskm5kvb0"},{"post_id":"ckn8tqxld004nncuffa5vn6ql","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxly004yncufgdb9apd7"},{"post_id":"ckn8tqxll004qncufspoqs1fq","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxm30051ncufoyowp0m8"},{"post_id":"ckn8tqxlp004tncufzrmkbbx1","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxm80056ncufhjrzrf0o"},{"post_id":"ckn8tqxlt004wncufxqg6gibh","tag_id":"ckn8tqxj90034ncuf16568kjm","_id":"ckn8tqxmb0059ncufn1iu9cxl"},{"post_id":"ckn8tqxm40052ncuf97exk8s4","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmd005cncufw0cr3r9w"},{"post_id":"ckn8tqxm90057ncuf7c22ny0x","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmh005fncufsxptha14"},{"post_id":"ckn8tqxmb005ancufvbxcq63k","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmn005incufavhai9je"},{"post_id":"ckn8tqxly004zncuftkgk2cg1","tag_id":"ckn8tqxm80055ncufif2jtfww","_id":"ckn8tqxmq005lncuf9ylb1gel"},{"post_id":"ckn8tqxme005dncuf4251i3po","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmt005oncufh4mrz554"},{"post_id":"ckn8tqxmi005gncufbta0twu6","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmv005rncuf3yrvp000"},{"post_id":"ckn8tqxmn005jncufwy77zn0q","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmw005tncufar3vgxun"},{"post_id":"ckn8tqxmr005mncufkehin407","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmx005vncufxtil2js5"},{"post_id":"ckn8tqxmt005pncufke16uxzu","tag_id":"ckn8tqwsa0004ncufkuwd3p46","_id":"ckn8tqxmy005xncuffxoq61xz"}],"Tag":[{"name":"mysql","_id":"ckn8tqwsa0004ncufkuwd3p46"},{"name":"kafka","_id":"ckn8tqwsh0009ncufnh2zapgm"},{"name":"rabbitmq","_id":"ckn8tqxi80023ncufc1tt218k"},{"name":"面试","_id":"ckn8tqxj0002uncufkzohae58"},{"name":"redis","_id":"ckn8tqxj90034ncuf16568kjm"},{"name":"算法","_id":"ckn8tqxm80055ncufif2jtfww"}]}}