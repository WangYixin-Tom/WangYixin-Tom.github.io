<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>研发效能</title>
      <link href="/2021/08/15/yanfa/"/>
      <url>/2021/08/15/yanfa/</url>
      
        <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>更高效、更高质量、更可靠、可持续地交付更优的业务价值</p><ul><li>更高效：价值的流动过程必须高效顺畅，阻力越小越好。</li><li>更高质量：如果质量不行，流动越快，死的也会越快。</li><li>更可靠：安全性和合规性要保障好。</li><li>可持续：输出不能时断时续，小步快跑才是正道，不要憋大招。</li><li>更优的业务价值：这是从需求层面来说的，你的交付物是不是真正解决了用户的本质问题。比如：“女生减肥不是本质问题，女生爱美才是”。</li></ul><p>我们引出<strong>持续开发，持续集成，持续测试，持续交付和持续运维</strong>的理念，它们是研发效能落地的必要实践。与此同时，我们还需要从<strong>流动速度，长期质量，客户价值以及数据驱动</strong>四个维度来对研发效能进行有效的度量。</p><h2 id="需求及作用"><a href="#需求及作用" class="headerlink" title="需求及作用"></a>需求及作用</h2><p>1、<strong>很多企业存在大量重复造轮子</strong></p><p>就像“中台“概念一样，现在很多大企业的产品线非常广，其中存在大量重复的轮子，如果我们关注业务上的重复轮子，那么就是业务中台；如果我们关注数据建设上的重复轮子，那么就是数据中台；如果我们关注研发效能建设上的重复轮子，那就是研效平台，其实研效平台在某种程度上也可以称之为”研发效能中台“，其目标是实现企业级跨产品跨项目的研发能力复用，避免原来每条产品线都在做研发效能所必须的”0到1“，没人有精力去关注更有价值的”1到n“。现代化的研效平台会统一来打造组织级别通用研发能力的最佳实践平台。</p><p>2、<strong>toC产品已经趋向饱和</strong></p><p>现在toC已经逐渐走向红海，同时研发的规模也比以往任何时候都要大，是时候要勒紧裤腰带过日子了，当开源（开源节流中的开源）遇到瓶颈了，节流就应该发挥作用。这个节流就是研发效能的提升，同样的资源，同样的时间来获得更多的产出</p><p>3、<strong>部分企业存在谷仓困局</strong></p><p>研发各个环节内部可能已经做了优化，但是跨环节的协作可能就会有大量的流转与沟通成本，从而影响全局效率。基于流程优化，打破各个环节看不见的墙，去除不必要的等待，提升价值流动速度正是研发效能在流程优化层面试图解决的一大类问题。</p><h2 id="研发效能方向"><a href="#研发效能方向" class="headerlink" title="研发效能方向"></a>研发效能方向</h2><p>考虑到</p><ul><li>软件架构本身的复杂度提升（微服务，服务网格等）</li><li>软件规模的不断增长（集群规模，数据规模等）</li><li>研发团队人员规模不断扩大引发沟通协作难度增长</li></ul><p><strong>我们能做的不是提升研发效能的绝对值，而是尽可能减缓研发效能恶化的程度，使其下降的不至于太快，努力保持现状就是成功。</strong></p><h2 id="当前存在问题"><a href="#当前存在问题" class="headerlink" title="当前存在问题"></a>当前存在问题</h2><ul><li><strong>迷信单点局部能力，忽略全局优化和拉通的重要性</strong></li><li><strong>具有普适性的通用研发效能工具其实没有专属工具来的好用</strong></li><li><strong>用“伪”工程实践和“面子工程”来滥竽充数</strong></li><li><strong>忽略研发效能工具体系的长尾效应</strong></li><li><strong>盲目跟风</strong></li><li><strong>迷信外部专家</strong></li><li><strong>研效度量的罪与罚</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一致性哈希</title>
      <link href="/2021/07/12/c-hash/"/>
      <url>/2021/07/12/c-hash/</url>
      
        <content type="html"><![CDATA[<h2 id="Hash取模"><a href="#Hash取模" class="headerlink" title="Hash取模"></a><strong>Hash取模</strong></h2><p><strong>缺点</strong></p><ul><li>节点出现宕机，哈希需要重新调整，数据迁移较多，缓存场景会出现缓存击穿，甚至缓存雪崩</li><li>节点扩容，哈希需要重新调整，问题同上</li></ul><h2 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h2><p><strong>基本思想</strong></p><p>固定N，避免了N的变动</p><ul><li>Karger的一致性哈希算法将N设置为2^32，形成了一个0~(2^32-1）的哈希环，也就是相当于普通Hash取模时N=2^32。</li><li>将服务器结点也作为一种key分发到哈希环上，顺时针方法实现结点对哈希环shard的归属</li><li>引入虚拟节点，解决一致性哈希的数据倾斜</li></ul><p><strong>增加节点</strong></p><p>部分数据需要迁移到新增节点和其虚拟节点上</p><p><strong>删除节点</strong></p><p>删除节点及其虚拟节点，顺时针迁移到下一个实体结点或者虚拟结点。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>Redis cluster 拥有固定的16384个slot，slot是虚拟的且被分布到各个master中，当key 映射到某个master 负责slot时，就由对应的master为key 提供服务。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/92742908" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/92742908</a></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux优化方法</title>
      <link href="/2021/07/08/linux-youhua/"/>
      <url>/2021/07/08/linux-youhua/</url>
      
        <content type="html"><![CDATA[<h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><h3 id="高cpu占用率的进程和线程"><a href="#高cpu占用率的进程和线程" class="headerlink" title="高cpu占用率的进程和线程"></a>高cpu占用率的进程和线程</h3><pre class="line-numbers language-shell"><code class="language-shell">top                 # 查看高CPU进程top -H -p pid        # 查看高CPU线程<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="CPU占用资源低但是系统响应速度很慢可能是什么问题"><a href="#CPU占用资源低但是系统响应速度很慢可能是什么问题" class="headerlink" title="CPU占用资源低但是系统响应速度很慢可能是什么问题"></a>CPU占用资源低但是系统响应速度很慢可能是什么问题</h3><p>等待磁盘I/O完成的进程过多，导致进程队列长度过大，但是cpu运行的进程却很少，这样就体现到负载过大了，cpu使用率低。</p><p>负载就是cpu在一段时间内正在处理以及等待cpu处理的进程数之和的统计信息，也就是cpu使用队列的长度统计信息，这个数字越小越好</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker必知必会</title>
      <link href="/2021/07/07/interview-docker/"/>
      <url>/2021/07/07/interview-docker/</url>
      
        <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="什么是容器"><a href="#什么是容器" class="headerlink" title="什么是容器"></a>什么是容器</h3><p>容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。</p><h2 id="必要性"><a href="#必要性" class="headerlink" title="必要性"></a>必要性</h2><p><strong>容器使软件具备了超强的可移植能力</strong>。</p><p>Docker 解决了环境配置问题，可以简化应用部署。它是一种虚拟化技术，对进程进行隔离，被隔离的进程独立于宿主操作系统和其它隔离的进程</p><h3 id="vs虚拟机"><a href="#vs虚拟机" class="headerlink" title="vs虚拟机"></a><strong>vs虚拟机</strong></h3><p>虚拟机也是一种虚拟化技术，通过模拟硬件，并在硬件上安装操作系统来实现。容器在 Host 操作系统的用户空间中运行，与操作系统的其他进程隔离。</p><p><img src="docker_vm.png" alt></p><h4 id="启动速度"><a href="#启动速度" class="headerlink" title="启动速度"></a>启动速度</h4><p>虚拟机需要先启动虚拟机的操作系统，再启动应用，速度慢；</p><p>Docker 相当于启动宿主操作系统上的一个进程，不需要启动整个操作系统。</p><h4 id="占用资源"><a href="#占用资源" class="headerlink" title="占用资源"></a>占用资源</h4><p>虚拟机是一个完整的操作系统，需要占用大量的磁盘、内存和 CPU 资源，一台机器只能开启几十个的虚拟机。</p><p>Docker 只是一个进程，只需要将应用以及相关的组件打包，在运行时占用很少的资源，一台机器可以开启成千上万个 Docker。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>除了启动速度快以及占用资源少之外，Docker 具有以下优势：</p><p><strong>更容易迁移</strong></p><p>提供一致性的运行环境。已经打包好的应用可以在不同的机器上进行迁移，而不用担心环境变化导致无法运行。</p><p><strong>更容易维护</strong></p><p>使用分层技术和镜像，使得应用可以更容易复用重复的部分。复用程度越高，维护工作也越容易。</p><p><strong>更容易扩展</strong></p><p>可以使用基础镜像进一步扩展得到新的镜像，并且官方和开源社区提供了大量的镜像，通过扩展这些镜像可以非常容易得到我们想要的镜像。</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p><strong>持续集成</strong></p><p>持续集成指的是频繁地将代码集成到主干上，这样能够更快地发现错误。</p><p>Docker 具有轻量级以及隔离性的特点，在将代码集成到一个 Docker 中不会对其它 Docker 产生影响。</p><p><strong>提供可伸缩的云服务</strong></p><p>根据应用的负载情况，可以很容易地增加或者减少 Docker。</p><p><strong>搭建微服务架构</strong></p><p>Docker 轻量级的特点使得它很适合用于部署、维护、组合微服务。</p><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><pre class="line-numbers language-shell"><code class="language-shell">FROM指定 base 镜像。MAINTAINER设置镜像的作者，可以是任意字符串。COPY将文件从build context复制到镜像。ADD与 COPY 类似，从 build context 复制文件到镜像。如果 src 是归档文件（tar, zip等），文件会被自动解压到 dest。ENV设置环境变量，环境变量可被后面的指令使用。EXPOSE指定容器中的进程会监听某个端口，Docker可以将该端口暴露出来。VOLUME将文件或目录声明为 volumeWORKDIR为后面的 RUN, CMD, ENTRYPOINT, ADD 或 COPY 指令设置镜像中的当前工作目录。RUN在容器中运行指定的命令。CMD容器启动时运行指定的命令。Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效。CMD 可以被 docker run 之后的参数替换。ENTRYPOINT设置容器启动时运行的命令。Dockerfile 中可以有多个 ENTRYPOINT 指令，但只有最后一个生效。CMD 或 docker run 之后的参数会被当做参数传递给 ENTRYPOINT。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="RUN、CMD和ENTRYPOINT区别"><a href="#RUN、CMD和ENTRYPOINT区别" class="headerlink" title="RUN、CMD和ENTRYPOINT区别"></a>RUN、CMD和ENTRYPOINT区别</h3><ol><li>RUN 执行命令并创建新的镜像层，常用于安装软件包。</li><li>CMD 设置容器启动后默认执行的命令及其参数，此命令会在容器启动且 docker run 没有指定其他命令时运行。如果 docker run 指定了其他命令，CMD 指定的默认命令将被忽略。如果 Dockerfile 中有多个 CMD 指令，只有最后一个 CMD 有效。</li><li>ENTRYPOINT 配置容器启动时运行的命令。 ENTRYPOINT 指令可让容器以应用程序或者服务的形式运行。ENTRYPOINT 不会被忽略，一定会被执行，即使运行 docker run 时指定了其他命令。</li></ol><h3 id="解释一下dockerfile的ONBUILD指令？"><a href="#解释一下dockerfile的ONBUILD指令？" class="headerlink" title="解释一下dockerfile的ONBUILD指令？"></a>解释一下dockerfile的ONBUILD指令？</h3><p>当镜像用作另一个镜像构建的基础时，向镜像添加将在稍后执行的触发指令。</p><p>如果要构建将用作构建其他镜像的基础的镜像，这将非常有用。</p><h3 id="构建docker镜像应该遵循哪些原则"><a href="#构建docker镜像应该遵循哪些原则" class="headerlink" title="构建docker镜像应该遵循哪些原则"></a>构建docker镜像应该遵循哪些原则</h3><ul><li>尽量选取满足需求但较小的基础系统镜像。</li><li>使用RUN指令时候，尽量把多个RUN指令合并为一个，通常做法是使用&amp;&amp;符号；COPY、ADD和RUN语句会向镜像中添加新层</li><li>清理编译生成文件、安装包的缓存等临时文件。</li><li>通过multi-stage方法减少一些不必要使用的环境来减小镜像;</li><li>安装各个软件时候要指定准确的版本号，并避免引入不需要的依赖。</li><li>从安全的角度考虑，应用尽量使用系统的库和依赖。</li><li>使用dockerfile创建镜像时候要添加.dockerignore文件或使用干净的工作目录。</li></ul><h3 id="如何控制容器占用系统资源（CPU，内存）的份额"><a href="#如何控制容器占用系统资源（CPU，内存）的份额" class="headerlink" title="如何控制容器占用系统资源（CPU，内存）的份额"></a>如何控制容器占用系统资源（CPU，内存）的份额</h3><p>docker create命令创建容器或使用docker run 创建并运行容器的时候，可以使用-c|-cpu-shares[=0]参数来调整同期使用CPU的权重，使用-m|-memory参数来调整容器使用内存的大小。</p><h3 id="如何停止所有正在运行的容器？"><a href="#如何停止所有正在运行的容器？" class="headerlink" title="如何停止所有正在运行的容器？"></a>如何停止所有正在运行的容器？</h3><p>使用<code>docker kill $(sudo docker ps -q)</code></p><h3 id="如何清理批量后台停止的容器？"><a href="#如何清理批量后台停止的容器？" class="headerlink" title="如何清理批量后台停止的容器？"></a>如何清理批量后台停止的容器？</h3><p>使用<code>docker rm $（sudo docker ps -a -q）</code></p><h3 id="批量删除所有已经退出的容器"><a href="#批量删除所有已经退出的容器" class="headerlink" title="批量删除所有已经退出的容器"></a>批量删除所有已经退出的容器</h3><p><code>docker rm -v $(docker ps -aq -f status=exited)</code></p><h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2><ul><li>可将 Docker 镜像看着只读模板，通过它可以创建 Docker 容器。</li><li>Docker 容器就是 Docker 镜像的运行实例。</li></ul><p>镜像包含着容器运行时所需要的代码以及其它组件，它是一种分层结构，每一层都是只读的（read-only layers）。构建镜像时，会一层一层构建，前一层是后一层的基础。镜像的这种分层存储结构很适合镜像的复用以及定制。</p><p>构建容器时，通过在镜像的基础上添加一个可写层（writable layer），用来保存着容器运行过程中的修改。</p><h3 id="base镜像"><a href="#base镜像" class="headerlink" title="base镜像"></a><strong>base镜像</strong></h3><p>用户空间的文件系统是 rootfs，包含我们熟悉的 /dev，/proc， /bin 等目录。</p><p>对于 base 镜像来说，底层直接用 Host 的 kernel，自己只需要提供 rootfs 就行了。</p><p><strong>base 镜像提供的是最小安装的 Linux 发行版</strong>。不同 Linux 发行版的区别主要就是 rootfs。</p><p>Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。</p><h3 id="分层"><a href="#分层" class="headerlink" title="分层"></a>分层</h3><p>新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。最大的一个好处就是共享资源</p><p>所有对容器的改动，无论添加、删除、还是修改文件，都只会发生在容器层中。</p><p>只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。</p><h3 id="镜像的缓存特性"><a href="#镜像的缓存特性" class="headerlink" title="镜像的缓存特性"></a>镜像的缓存特性</h3><p>Docker 会缓存已有镜像的镜像层，构建新镜像时，如果某镜像层已经存在，就直接使用，无需重新创建。</p><h3 id="多阶段构建"><a href="#多阶段构建" class="headerlink" title="多阶段构建"></a>多阶段构建</h3><p> <code>Dockerfile</code> 中使用多个 FROM 语句。每个 FROM 指令都可以使用不同的基础镜像，并表示开始一个新的构建阶段。你可以很方便的将一个阶段的文件复制到另外一个阶段，在最终的镜像中保留下你需要的内容即可。</p><pre><code>COPY --from=build-env /go/src/app/app-server /usr/local/bin/app-server</code></pre><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><h3 id="attach-与-exec-主要区别"><a href="#attach-与-exec-主要区别" class="headerlink" title="attach 与 exec 主要区别"></a>attach 与 exec 主要区别</h3><ol><li>attach 直接进入容器 <strong>启动命令</strong>的终端，不会启动新的进程。</li><li>exec 则是在容器中打开新的终端，并且可以启动新的进程。</li></ol><blockquote><p>在终端中查看启动命令的输出，用 attach；其他情况使用 exec。</p><p>只是为了查看启动命令的输出，可以使用 <code>docker logs</code> 命令</p></blockquote><h3 id="底层技术"><a href="#底层技术" class="headerlink" title="底层技术"></a>底层技术</h3><ul><li>cgroup （Control Group）实现资源限额，通过 cgroup 可以设置进程使用 CPU、内存 和 IO 资源的限额。 </li><li>namespace 实现资源隔离。</li></ul><p><strong>六种 namespace</strong></p><ul><li>Mount namespace 让容器看上去拥有整个文件系统。</li><li>UTS namespace 让容器有自己的 hostname。</li><li>IPC namespace 让容器拥有自己的共享内存和信号量来实现进程间通信</li><li>PID namespace：容器拥有自己独立的一套 PID</li><li>Network namespace 让容器拥有自己独立的网卡、IP、路由等资源。</li><li>User namespace 让容器能够管理自己的用户</li></ul><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><h3 id="原生网络-单个-host-上的容器网络"><a href="#原生网络-单个-host-上的容器网络" class="headerlink" title="原生网络/单个 host 上的容器网络"></a>原生网络/单个 host 上的容器网络</h3><p>none 网络：什么都没有的网络。挂在这个网络下的容器除了 lo，没有其他任何网卡。</p><p>host 网络：容器共享 Docker host 的网络栈，容器的网络配置与 host 完全一样。性能好，牺牲一些灵活性要考虑端口冲突问题。</p><p>bridge 网络：veth pair，一段挂在网桥 <code>docker0</code> 上，通信需要使用同一网络下的网卡</p><h3 id="user-defined-网络驱动"><a href="#user-defined-网络驱动" class="headerlink" title="user-defined 网络驱动"></a>user-defined 网络驱动</h3><p>bridge：需要创建网桥。创建容器，可基于网桥所在网络指定IP。跨容器通信需要使用同一网桥下的网络。</p><p>overlay ：</p><p>macvlan：</p><h3 id="容器间通信"><a href="#容器间通信" class="headerlink" title="容器间通信"></a>容器间通信</h3><ul><li>IP：使用同一网桥下的网络</li><li>DNS：docker daemon 实现了一个内嵌的 DNS server，使容器可以直接通过“容器名”通信。<strong>只能在 user-defined 网络中使用</strong>。默认的 bridge 网络是无法使用 DNS 的。</li><li>joined容器：两个或多个容器共享一个网络栈，共享网卡和配置信息，joined 容器之间可以通过 127.0.0.1 直接通信，适合web server 与 app server容器。</li></ul><h3 id="容器访问外部世界"><a href="#容器访问外部世界" class="headerlink" title="容器访问外部世界"></a>容器访问外部世界</h3><p><strong>容器默认就能访问外网</strong>。如果网桥 <code>docker0</code> 收到来自 172.17.0.0/16 网段的外出包，把它交给 MASQUERADE 处理。而 MASQUERADE 的处理方式是将包的源地址替换成 host 的地址发送出去，<strong>即做了一次网络地址转换（NAT）</strong></p><h3 id="外部世界如何访问容器"><a href="#外部世界如何访问容器" class="headerlink" title="外部世界如何访问容器"></a>外部世界如何访问容器</h3><p>docker 可将容器对外提供服务的端口映射到 host 的某个端口，外网通过该端口访问容器。容器启动时通过<code>-p</code>参数映射端口。docker-proxy 监听，某一个端口并转发给容器。</p><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><h3 id="storage-driver"><a href="#storage-driver" class="headerlink" title="storage driver"></a>storage driver</h3><p>管理的镜像层和容器层，对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。</p><h3 id="Data-Volume"><a href="#Data-Volume" class="headerlink" title="Data Volume"></a>Data Volume</h3><p>Docker Host 文件系统中的目录或文件，能够直接被 mount 到容器的文件系统中。Data Volume 是目录或文件，而非没有格式化的磁盘（块设备）。容器可以读写 volume 中的数据。volume 数据可以被永久的保存，即使使用它的容器已经销毁。</p><p><strong>bind mount</strong><br>将 host 上已存在的目录或文件 mount 到容器，可设置为只读，默认为读写权限<br><strong>用途</strong>：源代码/数据备份，删除容器后还会保留，支持单个文件<br><strong>缺点</strong>：移植性弱，与 host path 绑定</p><p><strong>docker managed volume</strong><br>原有数据复制到 volume，移植性强，无需指定 host 目录，不支持单个文件，无控制权限</p><h3 id="数据共享"><a href="#数据共享" class="headerlink" title="数据共享"></a>数据共享</h3><p><strong>容器与 host 共享数据</strong></p><ul><li><p>bind mount</p></li><li><p>docker managed volume</p></li><li><p>docker cp </p></li></ul><p><strong>容器之间共享数据</strong></p><ul><li>bind mount多个容器</li><li>volume container（专门为其他容器提供 volume 的容器）：容器与 host 的解耦</li><li>data-packed volume container：将数据打包到镜像中，然后通过 docker managed volume 共享，不依赖 host 提供数据，具有很强的移植性，非常适合只使用静态数据的场景</li></ul>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>攻击技术</title>
      <link href="/2021/06/30/attack/"/>
      <url>/2021/06/30/attack/</url>
      
        <content type="html"><![CDATA[<h2 id="XSS-跨站脚本攻击"><a href="#XSS-跨站脚本攻击" class="headerlink" title="XSS 跨站脚本攻击"></a>XSS 跨站脚本攻击</h2><p><strong>原理</strong></p><ul><li>恶意攻击者将代码通过网站注入到其他用户浏览器中的攻击方式。</li><li>攻击者会把恶意JavaScript 代码作为普通数据放入到网站数据库中；</li><li>其他用户在获取和展示数据的过程中，运行JavaScript 代码；</li><li>JavaScript 代码执行恶意代码（调用恶意请求，发送数据到攻击者等等）。</li></ul><p><strong>防御</strong></p><p>根本的解决方法：<strong>从输入到输出都需要过滤、转义。</strong></p><ol><li><p><strong>对重要的 cookie设置 httpOnly,</strong> 防止客户端通过document.cookie读取 cookie，此 HTTP头由服务端设置。</p></li><li><p><strong>关键字符过滤</strong>，从而避免 HTML 和 Jascript 代码的运行。</p></li></ol><h2 id="CSRF-跨站请求伪造"><a href="#CSRF-跨站请求伪造" class="headerlink" title="CSRF 跨站请求伪造"></a>CSRF 跨站请求伪造</h2><p>恶意攻击者在用户不知情的情况下，使用用户的身份来操作</p><p><strong>原理</strong></p><ul><li>黑客创建一个请求网站A 类的URL 的Web 页面，放在恶意网站B 中，这个文件包含了一个创建用户的表单。这个表单加载完毕就会立即进行提交。</li><li>黑客把这个恶意Web 页面的URL 发送至超级管理员，诱导超级管理员打开这个Web 页面。</li></ul><p><strong>防御</strong></p><p><strong>token 校验</strong></p><p>最常用的一种是通过token去校验请求是否合法：</p><p>在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。</p><p><strong>检查 Referer 首部字段</strong></p><p>用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。</p><p><strong>输入验证码</strong></p><p>因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入验证码可以让用户知道自己正在做的操作。</p><h2 id="SQL注入攻击"><a href="#SQL注入攻击" class="headerlink" title="SQL注入攻击"></a>SQL注入攻击</h2><p>SQL 注入漏洞: 攻击者直接对网站数据库执行任意SQL语句，在无需用户权限的情况下即可实现对数据的访问、修改甚至是删除。</p><p><strong>防御</strong></p><p>注意避免拼接字符串</p><p>部分ORM框架自带防御</p><h2 id="拒绝服务攻击"><a href="#拒绝服务攻击" class="headerlink" title="拒绝服务攻击"></a>拒绝服务攻击</h2><p>拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，在短时间内发起大量请求，耗尽服务器的资源，无法响应正常的访问，造成网站实质下线。</p><p>分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。</p><h3 id="防护措施"><a href="#防护措施" class="headerlink" title="防护措施"></a>防护措施</h3><h4 id="HTTP-请求的拦截"><a href="#HTTP-请求的拦截" class="headerlink" title="HTTP 请求的拦截"></a>HTTP 请求的拦截</h4><p>恶意请求都是从某个 IP 段发出的，那么把这个 IP 段封掉就行了。或者，它们的 User Agent 字段有特征（包含某个特定的词语），那就把带有这个词语的请求拦截。<strong>可以使用本机防火墙或者Web服务器拦截</strong>。</p><h4 id="带宽扩容"><a href="#带宽扩容" class="headerlink" title="带宽扩容"></a>带宽扩容</h4><p>正的 DDOS 攻击是没有特征的，它的请求看上去跟正常请求一样，而且来自不同的 IP 地址，所以没法拦截。</p><h4 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h4><p>网站的静态内容分发到多个服务器，用户就近访问，提高速度。因此，CDN 也是带宽扩容的一种方法，可以用来防御 DDOS 攻击。</p><p>网站内容存放在源服务器，CDN 上面是内容的缓存。用户只允许访问 CDN，如果内容不在 CDN 上，CDN 再向源服务器发出请求。这样的话，只要 CDN 够大，就可以抵御很大的攻击。不过，这种方法有一个前提，网站的大部分内容必须可以静态缓存。对于动态内容为主的网站（比如论坛），就要想别的办法，尽量减少用户对动态数据的请求。</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>1、降低SYN timeout时间，使得主机尽快释放半连接的占用<br>2、采用SYN cookie设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文<br>3、使用防火墙或者代理设备，缓冲SYN洪泛攻击</p>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统必知必会</title>
      <link href="/2021/06/30/interview-os/"/>
      <url>/2021/06/30/interview-os/</url>
      
        <content type="html"><![CDATA[<h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><p>操作系统是管理计算机硬件与软件资源的程序，本质上是运行在计算机上的软件程序 ，为用户提供一个与系统交互的操作界面 ，</p><p>分内核与外壳，外壳理解成围绕着内核的应用程序，而内核就是能操作硬件的程序。</p><h3 id="32位系统进程可分配内存"><a href="#32位系统进程可分配内存" class="headerlink" title="32位系统进程可分配内存"></a>32位系统进程可分配内存</h3><p>创建一个进程时，操作系统会为该进程分配一个 4GB 大小的虚拟进程地址空间。 </p><p>在 32 位的操作系统中，一个指针长度是 4 字节 ， 2的32次方个地址寻址能力是从 0x00000000~0xFFFFFFFF ，即为 4GB 。</p><h3 id="32位64位操作系统的区别？"><a href="#32位64位操作系统的区别？" class="headerlink" title="32位64位操作系统的区别？"></a>32位64位操作系统的区别？</h3><ul><li>32位处理器一次只能处理32位，4个字节；而64位处理器一次就能处理64位，8个字节。</li><li>传统32位处理器的寻址空间最大为4GB，而64位的处理器在理论上则可以达到1800万TB。</li><li>最大内存容量、数据传输和处理速度、数值精度等指标也成倍增加，CPU的处理能力得到大幅提升</li></ul><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><h3 id="零拷贝-1"><a href="#零拷贝-1" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域，通常用于网络传输文件。</p><blockquote><p>零拷贝并非真的是完全没有数据拷贝的过程，只不过是减少用户态和内核态的切换次数以及CPU拷贝的次数。</p></blockquote><h3 id="DMA拷贝"><a href="#DMA拷贝" class="headerlink" title="DMA拷贝"></a><strong>DMA</strong>拷贝</h3><p>主板上的独立芯片，通过它来进行内存和IO设备的数据传输，从而减少CPU的等待时间。</p><h3 id="传统IO"><a href="#传统IO" class="headerlink" title="传统IO"></a>传统IO</h3><p>传统的IO<code>read+write</code>方式会产生2次DMA拷贝+2次CPU拷贝，4次上下文切换。</p><p><img src="%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png" alt></p><h3 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap + write"></a>mmap + write</h3><p><code>mmap+write</code>方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件的传输。</p><p><img src="mmap-write.png" alt></p><h3 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h3><p><code>sendfile</code>方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。</p><p><img src="senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png" alt></p><h3 id="sendfile-DMA-gather"><a href="#sendfile-DMA-gather" class="headerlink" title="sendfile+DMA gather"></a>sendfile+DMA gather</h3><p><code>sendfile+DMA gather</code>方式产生2次DMA拷贝，没有CPU拷贝，而且也只有2次上下文切换。依赖新的硬件设备支持。</p><p><img src="senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt></p><h3 id="PageCache有什么用"><a href="#PageCache有什么用" class="headerlink" title="PageCache有什么用"></a>PageCache有什么用</h3><p>内核缓冲区，即磁盘高速缓存（PageCache）</p><ul><li>通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。用 PageCache 来缓存最近被访问的数据。</li></ul><blockquote><p>针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致热点小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。</p></blockquote><h3 id="大文件的传输"><a href="#大文件的传输" class="headerlink" title="大文件的传输"></a>大文件的传输</h3><ul><li>内核向磁盘发起读请求，但是可以<strong>不等待数据就位就可以返回</strong>，于是进程此时可以处理其他任务；</li><li>当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的<strong>通知</strong>，再去处理数据；</li><li>绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O</li></ul><h2 id="用户态内核态"><a href="#用户态内核态" class="headerlink" title="用户态内核态"></a>用户态内核态</h2><h3 id="内核态和用户态"><a href="#内核态和用户态" class="headerlink" title="内核态和用户态"></a>内核态和用户态</h3><p>为了限制不同程序的访问能力，划分了用户态和内核态两个权限等级。</p><ul><li>用户态只能访问受限的资源，如果需要特殊权限，可以通过系统调用获取相应的资源；</li><li>内核态可以访问所有的 CPU 指令和所有的内存空间、I/O 空间和硬件设备。</li></ul><p>所有用户程序都运行在用户态，一些内核态的操作需要进行系统调用，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。</p><h3 id="为什么要有内核态和用户态"><a href="#为什么要有内核态和用户态" class="headerlink" title="为什么要有内核态和用户态"></a>为什么要有内核态和用户态</h3><ul><li>安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；</li><li>封装性：用户程序不需要实现更加底层的代码；</li><li>利于调度：便于操作系统统一调度。</li></ul><h3 id="什么时候进入内核态"><a href="#什么时候进入内核态" class="headerlink" title="什么时候进入内核态"></a>什么时候进入内核态</h3><p>用户态切换到内核态的3种方式</p><p><strong>a. 系统调用</strong></p><p><strong>通过系统调用申请使用内核态服务程序完成工作</strong>，比如<code>fork()</code>，本质通过中断来实现。</p><p><strong>b. 异常</strong></p><p>用户态下的程序，发生了某些不可知的异常，会切换到处理此异常的内核程序，也就转到了内核态，比如缺页异常。</p><p><strong>c. 外围设备的中断</strong></p><p><strong>当外围设备完成用户请求的操作后，会发出相应的中断信号</strong>，程序转而去执行中断处理程序。</p><blockquote><p>内核态-&gt;用户态：执行一条特权指令，修改PSW的标志位为用户态</p></blockquote><h3 id="为什么用户态切换到内核态代价大"><a href="#为什么用户态切换到内核态代价大" class="headerlink" title="为什么用户态切换到内核态代价大"></a>为什么用户态切换到内核态代价大</h3><p>当发生用户态到内核态的切换时，会发生如下过程（本质上是从“用户程序”切换到“内核程序”）</p><ul><li>设置处理器至内核态。</li><li>保存当前寄存器（栈指针、程序计数器、通用寄存器）。</li><li>将栈指针设置指向内核栈地址。</li><li>将程序计数器设置为一个事先约定的地址上，该地址上存放的是系统调用处理程序的起始地址。</li></ul><p>而之后从内核态返回用户态时，又会进行类似的工作。</p><h3 id="内核空间和用户空间"><a href="#内核空间和用户空间" class="headerlink" title="内核空间和用户空间"></a>内核空间和用户空间</h3><p>内核空间总是驻留在内存中，它是<strong>为操作系统的内核保留的</strong>。按访问权限可以分为</p><ul><li>进程私有：每个进程都有单独的<strong>内核栈</strong>、<strong>页表</strong>、<strong>task 结构以及 mem_map 结构</strong>等。</li><li>进程共享：包括<strong>物理存储器、内核数据和内核代码区域</strong>。</li></ul><p>用户进程都有一个单独的用户空间，处于用户态的进程不能访问内核空间中的数据，需要通过系统调用，切换到内核态。用户空间包括：</p><ul><li>运行时栈：<strong>由编译器自动释放，存放函数的参数值，局部变量和方法返回值等</strong>。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈顶，调用结束后调用信息会被弹出弹出并释放掉内存。栈区是从高地址位向低地址位增长的。</li><li>运行时堆：<strong>用于存放进程运行中被动态分配的内存段</strong>。由开发人员申请分配和释放。堆是从低地址位向高地址位增长，采用链式存储结构。</li><li>代码段：<strong>存放 CPU 可以执行的机器指令。通常代码区是共享的，即其它执行程序可调用它。</strong></li><li>未初始化的数据段：<strong>存放未初始化的全局变量</strong>。</li><li>已初始化的数据段：<strong>存放已初始化的全局变量</strong>，包括静态全局变量、静态局部变量以及常量。</li><li>内存映射区域：<strong>例如将动态库，共享内存等虚拟空间的内存映射到物理空间的内存</strong>，一般是 mmap 函数所分配的虚拟内存空间。</li></ul><h3 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h3><p><strong>系统调用是操作系统对程序员提供的接口</strong>。根据进程访问资源的特点，分为用户态和系统态。用户程序运行在用户态，通过系统调用使用系统态提供的功能。</p><p>系统调用按功能分为：设备管理、文件管理、进程控制、进程通信、内存管理。</p><h3 id="系统调用和中断的关系"><a href="#系统调用和中断的关系" class="headerlink" title="系统调用和中断的关系"></a>系统调用和中断的关系</h3><p>系统调用：通过系统调用使用内核态的子功能。</p><p>中断：一个硬件或软件发出请求，要求CPU暂停当前工作，处理更加重要的事情。</p><ul><li><p>都是CPU停止掉当前用户态上下文，保存工作现场，然后陷入到内核态继续工作。</p></li><li><p>区别是系统调用是切换到同进程的内核态上下文，而软中断是切换到了另外一个内核进程ksoftirqd上。</p></li></ul><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><h3 id="内存管理主要是做什么"><a href="#内存管理主要是做什么" class="headerlink" title="内存管理主要是做什么"></a><strong>内存管理主要是做什么</strong></h3><ul><li>负责内存的分配与回收</li><li>地址转换，将逻辑地址转换成物理地址</li></ul><h3 id="常见的内存管理机制"><a href="#常见的内存管理机制" class="headerlink" title="常见的内存管理机制"></a>常见的内存管理机制</h3><p>连续分配管理，如<strong>块式管理</strong> 。非连续分配管理如<strong>页式管理</strong> 、<strong>段式管理</strong>。</p><ol><li><strong>块式管理</strong> ： 将内存分为几个固定大小的块，每个块中只包含一个进程。每个块中可能存在浪费。</li><li><strong>页式管理</strong> ：把<strong>主存分为大小相等且固定的一页一页的形式</strong>，页无实际意义，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。通过<strong>页表对应逻辑地址和物理地址。</strong></li><li><strong>段式管理</strong> ：把主存分为一段段的，每一段的空间又要比一页的空间小很多 。段有实际意义的，每个段定义了一组逻辑信息，例如，有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 通过<strong>段表对应逻辑地址和物理地址</strong>。</li><li><strong>段页式管理机制</strong>结合了段式管理和页式管理的优点。把主存先分成若干段，每个段又分成若干页。</li></ol><h4 id="请求分页存储管理"><a href="#请求分页存储管理" class="headerlink" title="请求分页存储管理"></a>请求分页存储管理</h4><p>基本分页思想</p><ul><li>我们将逻辑地址空间和内存地址空间划分为<strong>等大</strong>的页。每次调入调出都以页为单位，逻辑地址空间的某一个页经过页表转化到物理空间的某一页。<strong>运行某个程序时需一次性地调入程序所占用的所有页面</strong></li></ul><p>请求分页只修改了页面的调度：</p><p><strong>运行某个程序时，需要哪一页调入哪一页（请求调页），由于内存大小有限，因此在调入新的一页时，可能空间不够，此时需要先选择一页调出（页面置换）</strong></p><h4 id="请求分页存储和基本分页存储的区别"><a href="#请求分页存储和基本分页存储的区别" class="headerlink" title="请求分页存储和基本分页存储的区别"></a>请求分页存储和基本分页存储的区别</h4><ul><li>请求分页是虚拟存储中的概念，基本分页是传统存储中的概念</li><li>请求分页在运行作业时不需要将全部的页面调入内存</li><li>请求分页有“请求调页”，“页面置换”，基本分页没有</li></ul><h4 id="请求分页存储虚实地址转换"><a href="#请求分页存储虚实地址转换" class="headerlink" title="请求分页存储虚实地址转换"></a>请求分页存储虚实地址转换</h4><ul><li>程序请求访问某一页</li><li>判断页号是否大于页表寄存器中的页表长度，从而判断是否产生越界中断</li><li>索引快表，若快表命中<ul><li>修改该页表项的访问位和修改位</li><li>根据快表形成物理地址</li></ul></li><li>索引快表，若快表没有命中<ul><li>索引慢表，若慢表命中: 页表项复制到快表中，修改访问位和修改位，形成物理地</li><li>索引慢表，若没有命中<br>说明该页还没有调入内存，产生缺页中断，请求外存调入页面。<br>1.产生缺页中断<br>2.从外存中找到该页面<br>3.检查内存是否已满，如果不满直接调入页面，如果内存已满需要根据页面置换算法选择一页换出后，再调入页面<br>4.调入后要修改页面，同时将页表项复制到快表中，从头开始继续访问快表<br>5.快表一定命中，成功得到物理地址</li></ul></li></ul><h4 id="分页和分段区别？"><a href="#分页和分段区别？" class="headerlink" title="分页和分段区别？"></a><strong>分页和分段区别？</strong></h4><ol><li>共同点：<ul><li>都是为了提高内存利用率，较少内存碎片。</li><li>页和段都是离散存储的，所以两者都是离散分配内存的方式。每个页和段中的内存是连续的。</li><li><strong>都需要访问两次内存</strong>：第一次访问内存中的段表或者页表得到物理地址，第二次根据物理地址访问内存中的数据</li></ul></li><li>区别：<ul><li><strong>页的大小是固定的，由操作系统决定；段的大小不固定，取决于我们当前运行的程序。</strong></li><li><strong>分页对用户不可见，完全由硬件决定，分段是用户可见的。</strong>（分页中是粗暴地将所有的程序划分成等大的页，程序员没办法决定，但是分段是按照程序员的编程逻辑来的，程序员可以决定）</li><li>分页仅仅是为了满足操作系统内存管理的需求，而<strong>段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要</strong>。</li></ul></li></ol><h4 id="地址转换最多-最少访问内存次数？"><a href="#地址转换最多-最少访问内存次数？" class="headerlink" title="地址转换最多/最少访问内存次数？"></a>地址转换最多/最少访问内存次数？</h4><p><strong>页式存储，2次：</strong></p><p>第一次，<strong>访问内存中的页表</strong>，利用逻辑地址中的页号查找到页帧号，与逻辑地址中的页内偏移拼接形成物理地址；</p><p>第二次：得到物理地址后，再一次访问内存，存取指令或者数据。</p><p>段式存储，2次（同上）</p><p><strong>段页式存储，3次：</strong></p><p>第一次：访问内存中的段表查到<strong>页表的起始地址</strong></p><p>第二次：访问内存中的页表找到<strong>页帧号</strong>，<strong>形成物理地址</strong></p><p>第三次：得到<strong>物理地址后，再一次访问内存</strong>，存取指令或者数据</p><p><strong>快表</strong></p><p><img src="tlb.jpeg" alt></p><p>TLB（translation lookaside buffer），旁路快表缓冲，页表缓冲。快表用来存放当前访问的若干页表项</p><ul><li><p>当CPU收到应用程序发来的虚拟地址后，首先到TLB中查找相应的页表数据</p></li><li><p>若快表命中，则可直接得到页帧号，与页内偏移拼接成物理地址后访问内存，进行指令或者数据的存取。（只需访问一次内存）</p></li><li><p>若快表不命中，则需去内存中访问页表，形成物理地址后，再一次访问内存进行指令或者数据的存取。（需要访问两次内存）</p></li></ul><h3 id="内存分配方式一般有哪些"><a href="#内存分配方式一般有哪些" class="headerlink" title="内存分配方式一般有哪些"></a>内存分配方式一般有哪些</h3><p> （1）静态：是在程序编译时就已经分配好的，在整个运行期间都存在，如全局变量、常量。</p><p> （2）栈式分配：由编译器自动分配释放 ，存放函数参数、局部变量等，函数执行结束后自动释放。</p><p> （3）堆式分配：一般由程序员分配释放，若程序员不释放，程序结束时可由 OS 自动回收。</p><h3 id="内存碎片如何产生的？"><a href="#内存碎片如何产生的？" class="headerlink" title="内存碎片如何产生的？"></a>内存碎片如何产生的？</h3><ul><li>内部碎片，当一个进程不能完全使用分给它的固定大小的内存区域时就产生了内部碎片，通常内部碎片难以完全避免；</li><li>外部碎片，未分配的连续内存区域太小，不能满足进程的内存分配请求。</li></ul><ol><li>普遍采用的段页式内存分配方式通过页表机制，使段内的页可以不必连续处于同一内存区域，从而减少了外部碎片</li><li>同一页内仍然可能存在少量的内部碎片，只是一页的内存空间本就较小，从而使可能存在的内部碎片也较少。</li></ol><h3 id="虚拟内存，常驻内存，共享内存"><a href="#虚拟内存，常驻内存，共享内存" class="headerlink" title="虚拟内存，常驻内存，共享内存"></a>虚拟内存，常驻内存，共享内存</h3><p>虚拟内存（VIRT）：进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据，文件映射区以及堆空间和栈等</p><p>常驻内存（RES）：进程当前使用的内存大小，包括使用中的堆空间和分配的栈空间，包含其他进程的共享内存。（除去内核使用的部分，所有的进程都需要分配物理内存页给它们的代码、数据和堆栈。）</p><p>共享内存（SHARE）：进程会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，在内存中实际只会加载一份。</p><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><h4 id="什么是虚拟内存"><a href="#什么是虚拟内存" class="headerlink" title="什么是虚拟内存"></a><strong>什么是虚拟内存</strong></h4><ul><li>每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页通过页表被映射到物理内存；</li><li>不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。</li><li>对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。</li></ul><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li><strong>地址空间</strong>：提供更大的地址空间，并且地址空间是连续的，使得程序编写、链接更加简单</li><li><strong>进程隔离</strong>：不同进程的虚拟地址之间没有关系，所以一个进程的操作不会对其它进程造成影响</li><li><strong>提高物理内存利用率</strong>：直接映射磁盘上的文件到虚拟地址空间，内存吃紧的时候又可以将这部分内存清空掉。</li></ul><h4 id="局部性原理"><a href="#局部性原理" class="headerlink" title="局部性原理"></a>局部性原理</h4><ol><li><strong>时间局部性</strong> ：如果程序中的某条指令一旦执行，不久后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。</li><li><strong>空间局部性</strong> ：程序访问了某个存储单元，其附近的存储单元也将被访问</li></ol><h4 id="MMU作用"><a href="#MMU作用" class="headerlink" title="MMU作用"></a>MMU作用</h4><p>内存管理单元，负责<strong>虚拟地址映射为物理地址</strong>。页表存储着页（逻辑地址）和页框（物理内存空间）的映射表。</p><h4 id="逻辑地址和物理地址"><a href="#逻辑地址和物理地址" class="headerlink" title="逻辑地址和物理地址"></a>逻辑地址和物理地址</h4><ul><li>逻辑地址是相对地址，是在编译链接后指明的地址，编程一般只有可能和逻辑地址打交道。</li><li>物理地址是在内存中的实际地址，是装入后指明的位置</li></ul><h3 id="缺页中断"><a href="#缺页中断" class="headerlink" title="缺页中断"></a>缺页中断</h3><p><strong>概念</strong></p><p>当程序访问一个<strong>映射到地址空间却实际并未加载到物理内存</strong>的页时， 硬件向软件发出的一次中断（或异常）就是一个缺页中断或叫页错误（page fault）。</p><blockquote><p>缺页中断是一种特殊的中断，它与一般的中断的区别是：</p><p>（1）缺页中断是在指令执行期间，发现所要访问的指令或数据不在内存时产生和处理的。</p><p>（2）可能产生多次缺页中断。</p></blockquote><p><strong>Major/Minor page fault区别</strong></p><p>发生缺页中断时，对应的数据还存在于磁盘上，即major page fault；</p><p>发生缺页中断时，对应的数据已经载到了Page Cache中，即minor page fault。</p><p><strong>如何查看进程发生缺页中断的次数？</strong></p><p>用<code>ps -o majflt,minflt -C program</code>命令查看</p><p><strong>tcp服务器的系统发生大量缺页中断，可能的原因是什么</strong></p><p>可能是mmap了大文件导致的，或者内存不够用了被频繁换入换出。</p><h4 id="页面置换算法的作用"><a href="#页面置换算法的作用" class="headerlink" title="页面置换算法的作用?"></a><strong>页面置换算法的作用?</strong></h4><p>当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在选择一个页面将其移出内存，为即将调入的页面让出空间。</p><h4 id="常见的页面置换算法有哪些"><a href="#常见的页面置换算法有哪些" class="headerlink" title="常见的页面置换算法有哪些?"></a>常见的页面置换算法有哪些?</h4><ul><li><strong>FIFO （先进先出）</strong> : 置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；</li><li><strong>LRU （最近未使用）</strong> ：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。</li><li><strong>最不经常使用算法</strong>NFU：置换出访问次数最少的页面</li></ul><h3 id="堆和栈的区别"><a href="#堆和栈的区别" class="headerlink" title="堆和栈的区别"></a>堆和栈的区别</h3><ul><li><p><strong>申请方式</strong></p><p> 栈：由系统自动分配；</p><p> 堆：程序员自己申请</p></li><li><p><strong>申请效率的比较</strong></p><p>栈：速度较快。</p><p>堆：一般速度比较慢，而且容易产生内存碎片。</p></li><li><p><strong>堆和栈中的存储内容</strong></p><p>栈：下一条指令的地址，函数的各个参数，函数中的局部变量。 </p><p>堆：堆中的具体内容由程序员安排。</p></li></ul><h2 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h2><h3 id="进程实体的组成"><a href="#进程实体的组成" class="headerlink" title="进程实体的组成"></a>进程实体的组成</h3><ul><li>PCB：面向操作系统，<strong>PCB 是进程存在的唯一标志</strong>，当进程被创建时，操作系统为其创建 PCB，当进程结束时，会回收其 PCB。包含进程描述信息（进程标识符PID，用户标识符UID），进程控制和管理信息（进程当前状态）、资源分配清单（正在使用<strong>文件</strong>、内存区域、IO设备）、寄存器的值（PSW、PC）等</li><li>程序段：程序的代码（指令序列）</li><li>数据段：运行过程中产生的各种数据（如：程序中定义的变量）</li></ul><h3 id="进程线程区别"><a href="#进程线程区别" class="headerlink" title="进程线程区别"></a>进程线程区别</h3><ul><li>进程是<strong>操作系统分配资源的最小单元，线程是操作系统调度的最小单元</strong>。</li><li>不同进程有自己的独立地址空间，同一进程的线程共享所属进程的虚拟地址空间；</li><li>线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信的方式进行</li><li>一个程序至少有一个进程，一个进程至少有一个线程；</li><li><strong>线程的上下文切换只需要保存线程的运行时数据，比如线程的id、寄存器中的值、栈数据</strong>。进程上下文要保存<strong>页表、文件描述符表、信号控制数据和进程信息、数据段、堆</strong>等数据。</li><li>多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮</li></ul><h3 id="为什么进程切换开销大"><a href="#为什么进程切换开销大" class="headerlink" title="为什么进程切换开销大"></a>为什么进程切换开销大</h3><p><strong>线程的上下文切换只需要保存线程的运行时数据，比如线程的id、寄存器中的值、栈数据</strong>。进程上下文要保存<strong>页表、文件描述符表、信号控制数据和进程信息、数据段、堆</strong>等数据。</p><p>进程的上下文的切换会扰乱处理器的缓存机制。处理器中已经缓存的内存地址都作废了，页表缓冲会被全部刷新。</p><h3 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a><strong>进程间通信</strong></h3><p>进程拥有独立的内存地址空间，导致了进程之间无法利用直接的内存映射进行进程间通信。</p><h4 id="1-信号"><a href="#1-信号" class="headerlink" title="1.信号"></a>1.信号</h4><p>在软件层次上对中断机制的模拟。信号是异步的。<strong>唯一的异步通信机制</strong>。</p><h4 id="2-信号量"><a href="#2-信号量" class="headerlink" title="2.信号量"></a>2.信号量</h4><p>一个计数器，常用来处理进程或线程同步的问题，特别是对临界资源的访问同步问题。</p><p>临界资源：某一时刻只能由一个进程或线程操作的资源，当信号量的值大于或等于0时，表示可以供并发进程访问的临界资源数，当小于0时，表示正在等待使用临界资源的进程数。</p><blockquote><p>由于信号量只能进行等待和发送信号，即<code>P(sv)</code>和<code>V(sv)</code>：</p><ul><li><code>P(sv)</code>：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行</li><li><code>V(sv)</code>：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1.</li></ul><p>PV操作都为原子操作（因为它需要保护临界资源）；在临界区之前执行P（mutex），在临界区之后执行V（mutex）；P、V操作必须成对出现。</p></blockquote><h4 id="3-消息队列"><a href="#3-消息队列" class="headerlink" title="3.消息队列"></a>3.消息队列</h4><p>消息队列是存放在内核中的消息链表，与管道不同的是，消息队列存放在内核中，只有在系统重启时才能删除一个消息队列，消息队列的大小受限制的。</p><h4 id="4-共享内存"><a href="#4-共享内存" class="headerlink" title="4.共享内存"></a>4.共享内存</h4><p><strong>共享内存就是分配一块能被其他进程访问的内存。</strong>共享内存是最快的IPC形式。</p><p>共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。</p><p><strong>不同进程间是如何实现共享内存的</strong></p><ul><li>每个进程都有属于自己的进程控制块（PCB）和地址空间，</li><li>通过内存管理单元进行管理。两个不同的虚拟地址通过页表映射到物理空间的同一区域。</li><li>这样当一个进程进行写操作，另一个进程读操作就可以实现进程间通信。</li></ul><blockquote><p>确保一个进程在写的时候不能被读，使用信号量来实现同步与互斥。</p></blockquote><h4 id="5-管道"><a href="#5-管道" class="headerlink" title="5.管道"></a>5.管道</h4><p>半双工通信方式；只用于有亲缘关系（父子或兄弟进程）的进程间的通信；</p><p><strong>管道通信怎么实现</strong></p><p>内核管理的一个环形的缓冲区。</p><ul><li>管道的一端连接一个进程的输出。会向管道中放入信息。</li><li>管道的另一端连接一个进程的输入，这个进程取出信息。</li><li>当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。</li><li>当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。</li><li>当两个进程都终结的时候，管道也自动消失。</li></ul><p><strong>管道需要进入内核态吗？</strong></p><p>每个进程各自有不同的地址空间，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程A把数据从用户空间拷到内核缓冲区，进程B再从内核缓冲区把数据读走。</p><h4 id="6-命名管道"><a href="#6-命名管道" class="headerlink" title="6.命名管道"></a>6.命名管道</h4><p>命名管道是服务器进程和一个或多个客户进程之间通信的单向或双向管道。半双工。</p><p>不同于匿名管道的是：</p><ul><li><p>命名管道可以在<strong>不相关的进程之间使用</strong>，服务器建立命名管道时给它指定一个名字，任何进程都可以通过该名字打开管道的另一端，根据给定的权限和服务器进程通信。</p></li><li><p>命名管道是个<strong>设备文件，存储在文件系统中</strong>，没有亲缘关系的进程也可以访问，但是它要按照<strong>先进先出</strong>的原则读取数据。</p></li></ul><h4 id="7-套接字"><a href="#7-套接字" class="headerlink" title="7.套接字"></a>7.套接字</h4><p><strong>可用于不同主机间的进程通信。</strong></p><h3 id="线程间的通信"><a href="#线程间的通信" class="headerlink" title="线程间的通信"></a>线程间的通信</h3><h4 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h4><ul><li>只有拥有互斥对象的线程才能访问互斥资源。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；</li><li>当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源。</li></ul><h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>控制同一时刻访问此资源的最大线程数量。</p><ul><li>信号量对象保存了<strong>最大资源计数</strong>和<strong>当前可用资源计数</strong></li><li>每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，将当前可用资源数加1。</li><li>如果信号量的取值只能为0或1，那么信号量就成为了互斥量</li></ul><h4 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h4><p>一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。</p><h3 id="临界区和临界资源"><a href="#临界区和临界资源" class="headerlink" title="临界区和临界资源"></a>临界区和临界资源</h3><p><strong>临界资源</strong></p><p>临界资源是一次仅允许一个进程使用的共享资源。各进程采取互斥的方式，实现共享的资源称作临界资源。</p><p><strong>临界区</strong><br>访问临界资源的代码称为临界区，每次只允许一个进程进入临界区，进入后，不允许其他进程进入。</p><p><strong>互斥量和临界区有什么区别？</strong></p><p>互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。</p><p>创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。</p><h3 id="线程的共享资源和私有资源"><a href="#线程的共享资源和私有资源" class="headerlink" title="线程的共享资源和私有资源"></a>线程的共享资源和私有资源</h3><p>线程共享包括：<strong>进程代码段、进程的公有数据（全局堆、全局变量，静态变量）、进程打开的文件描述符、信号处理器/信号处理函数、进程ID与进程组ID</strong>。</p><p> 私有资源：线程上下文（所属线程的栈区、<em>局部堆</em>、程序计数器、错误返回码、信号屏蔽码）</p><blockquote><p>全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。</p><p>为了保证对象的内存分配过程中的线程安全性，HotSpot虚拟机提供了一种叫做TLAB，Thread Local Allocation Buffer的技术。<br>在线程初始化时，虚拟机会为每个线程分配一块TLAB空间，只给当前线程使用，当需要分配内存时，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。<br>所以，“堆是线程共享的内存区域”这句话并不完全正确，因为TLAB是堆内存的一部分，他在读取上确实是线程共享的，但是在内存分配上，是线程独享的。</p></blockquote><h3 id="进程状态转换"><a href="#进程状态转换" class="headerlink" title="进程状态转换"></a>进程状态转换</h3><p><img src="process.png" alt></p><h3 id="线程有哪些状态"><a href="#线程有哪些状态" class="headerlink" title="线程有哪些状态"></a>线程有哪些状态</h3><p>新建：新建线程对象，未调用 start 方法<br>可运行：调用 start 方法。等待获取 CPU 的使用权<br>运行中：线程获取了 CPU 的使用权，执行程序代码<br>阻塞：线程因为某种原因放弃了 CPU 的使用权，暂时停止运行</p><ul><li>等待阻塞：调用wait/join后，进入该状态。放弃了 CPU 的使用权，直到notify方法唤起。</li><li>计时等待：调用Thread.sleep进入该状态，随后由计时器触发，再进入可运行状态。</li><li>同步阻塞：线程要进入临界区的时候，会发生</li></ul><p>死亡：线程已经执行完毕。主线程 main 方法结束或因异常退出；子线程 run 方法结束或因异常退出</p><h3 id="wait和block的区别？"><a href="#wait和block的区别？" class="headerlink" title="wait和block的区别？"></a>wait和block的区别？</h3><p>wait的线程被唤醒后其实会进入block的状态去抢锁。</p><p>因为wait是在同步代码块中运行的，所以被唤醒后会要去抢锁，抢到锁才会进入就绪状态。</p><h3 id="fork函数的底层实现原理"><a href="#fork函数的底层实现原理" class="headerlink" title="fork函数的底层实现原理"></a>fork函数的底层实现原理</h3><ol><li><p>分配新的内存块和内核数据结构给子进程</p></li><li><p>将父进程部分数据结构内容拷贝至子进程：进程pcb、 程序体，即代码段数据段等、用户栈、内核栈、虚拟内存池、页表。当父子进程有一个想要修改数据或者堆栈时，两个进程真正分裂。</p></li><li><p>添加子进程到系统进程列表当中</p></li><li><p>fork返回，开始调度器调度</p></li></ol><h3 id="fork之后的父子进程同时读取一个文件"><a href="#fork之后的父子进程同时读取一个文件" class="headerlink" title="fork之后的父子进程同时读取一个文件"></a>fork之后的父子进程同时读取一个文件</h3><ul><li><strong>fork之前open</strong>：由于父子进程是以共享的方式控制已经打开文件的，因此对文件的操作也是相互影响的，因此读写文件的位置也会发生相应的改变。</li><li>如果是非父子进程或者fork之后open，则会存在相互覆盖的情况</li><li>如果用O_APPEND标志打开一个文件，每次对这种具有填写标志的文件执行写操作时，每次写的数据都添加到文件的当前尾端处。</li></ul><h3 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h3><ul><li>切换新的页表，然后使用新的虚拟地址空间</li><li>切换内核栈，加入新的内容（PCB控制块，资源相关），硬件上下文切换</li></ul><h3 id="线程切换"><a href="#线程切换" class="headerlink" title="线程切换"></a>线程切换</h3><p>线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。 </p><h3 id="进程的调度算法"><a href="#进程的调度算法" class="headerlink" title="进程的调度算法"></a>进程的调度算法</h3><p><strong>批处理系统</strong></p><ul><li>先到先服务（FCFS） : 按照请求的顺序进行调度。非抢占式，无饥饿问题；对短进程不利。</li><li>短作业优先（SJF） : 按估计运行时间最短的顺序进行调度。非抢占式，可能导致饥饿问题；对长进程不利。</li><li>最短剩余时间优先 （SRTN）：按剩余运行时间的顺序进行调度，最短作业优先的<strong>抢占式版本</strong>。可能导致饥饿问题，对长进程不利。</li><li>最高响应比优先：响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。</li></ul><p><strong>交互式系统</strong></p><p>交互式系统有大量的用户交互操作，调度算法的目标是快速响应。</p><ul><li><p><strong>时间片轮转调度算法</strong> ：将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），无饥饿问题，为短进程提供好的响应时间；</p><p>若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。</p></li><li><p><strong>优先级调度</strong> ： 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</p></li><li><p><strong>多级反馈队列调度算法</strong> ：设置多个就绪队列1、2、3…，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片但还未执行完，则会被移到下一队列。抢占式（时间片用完时），可能会出现饥饿问题</p></li></ul><h3 id="抢占式非抢占式的区别"><a href="#抢占式非抢占式的区别" class="headerlink" title="抢占式非抢占式的区别"></a>抢占式非抢占式的区别</h3><ul><li>抢占式：更高优先级的任务出现时，执行优先级更高的进程。</li><li>非抢占式：高优先级的进程不能中止低优先级的进程，抢占CPU运行。</li><li>饥饿：抢占式，低优先级的进程必须等待很长时间，并且可能会饿死。 </li><li>调度开销：抢占式有进程调度的开销，非抢占式没有</li></ul><h3 id="CFS-完全公平调度算法"><a href="#CFS-完全公平调度算法" class="headerlink" title="CFS 完全公平调度算法"></a>CFS 完全公平调度算法</h3><ul><li>给每一个进程安排一个虚拟时钟，vruntime。</li><li>如果一个进程得以执行，随着时间的增长，其vruntime将不断增大。没有得到执行的进程vruntime不变。</li><li>而调度器总是选择vruntime最小的那个进程来执行。</li></ul><blockquote><p>CFS的思想就是让每个调度实体（没有组调度的情形下就是进程）的vruntime互相追赶，而每个调度实体的vruntime增加速度不同，权重越大的增加的越慢，这样就能获得更多的cpu执行时间。</p><p>nice值越小, 进程的权重越大，实际运行时间越长。</p></blockquote><p><strong>几个过程</strong></p><ul><li>创建新进程：设置新进程的vruntime值，将新进程加入红黑树中，判断是否需要抢占当前进程</li><li>进程唤醒：调整睡眠进程的vruntime值， 将睡眠进程加入红黑树中，判断是否需要抢占当前进程</li><li>进程的调度： 进程调度时，把当前进程加入红黑树中， 从红黑树中挑选出下一个要运行的进程</li><li>时钟周期中断： 更新当前运行进程的vruntime值，并判断是否需要抢占当前进程</li></ul><h3 id="程序计数器的作用"><a href="#程序计数器的作用" class="headerlink" title="程序计数器的作用"></a><strong>程序计数器的作用</strong></h3><p>为了保证进程能执行下去，需要确定下一条指令的地址。</p><ul><li>在程序开始执行前，必须将它的起始地址，即程序的第一条指令所在的内存单元地址送入程序计数器。</li><li>当执行指令时， 处理器将自动修改程序计数器的内容，即每执行一条指令程序计数器增加一个量，以便保持的总是将要执行的下一条指令的地址。</li></ul><h3 id="并发、并行、异步的区别？"><a href="#并发、并行、异步的区别？" class="headerlink" title="并发、并行、异步的区别？"></a>并发、并行、异步的区别？</h3><p>并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行；</p><p>并行：多个程序同时执行的</p><p>异步：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事</p><h3 id="可以用kill-9-关闭进程吗"><a href="#可以用kill-9-关闭进程吗" class="headerlink" title="可以用kill -9 关闭进程吗"></a>可以用kill -9 关闭进程吗</h3><p>kill可将指定的信息送至程序。预设的信息为<code>SIGTERM(15)</code>，可将指定程序终止。若仍无法终止该程序，可使用<code>SIGKILL(9)</code>信息尝试强制删除程序。</p><ul><li>由于kill -9 属于暴力删除，相当于突然断电。</li><li>迫使进程在运行时突然终止，进程在结束后不能自我清理。可能导致系统资源无法正常释放，不推荐。 </li></ul><h3 id="kill是靠什么来通信的"><a href="#kill是靠什么来通信的" class="headerlink" title="kill是靠什么来通信的"></a>kill是靠什么来通信的</h3><p>信号。</p><ul><li>ctrl + c，会发送<code>SIGINT</code>的信号，等同于<code>kill -2(interrupt)</code></li><li>ctrl + z，会发送<code>SIGTSTP</code>的信号</li></ul><h3 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h3><p>当多个进程共享同一块数据时，每个进程要修改的时候才拷贝到自己的地址空间。</p><h3 id="什么是僵尸进程？大量的僵尸进程如何处理"><a href="#什么是僵尸进程？大量的僵尸进程如何处理" class="headerlink" title="什么是僵尸进程？大量的僵尸进程如何处理"></a>什么是僵尸进程？大量的僵尸进程如何处理</h3><p><strong>what</strong></p><p>父进程使用 fork 创建子进程，如果子进程退出，而父进程并没有调用 wait 或 waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。</p><p><strong>危害</strong></p><p><strong>进程号就会一直被占用</strong>，进程号有限的，可能导致系统不能产生新的进程</p><p><strong>处理</strong></p><p>父进程kill。僵尸进程变成孤儿进程，被 init 进程接管，init 进程会 <code>wait()</code>这些孤儿进程，释放它们占用的系统进程表中的资源。</p><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁</p><h4 id="必要条件"><a href="#必要条件" class="headerlink" title="必要条件"></a>必要条件</h4><ul><li><strong>互斥</strong>：同一时刻，一个资源只能被一个进程使用；</li><li><strong>占有并等待</strong>：已经占有了某个资源的进程可以请求并等待新的资源。</li><li><strong>非抢占</strong>：已经分配给一个进程的资源不能被强制性抢占，只能由占有进程自愿释放；</li><li><strong>循环等待</strong>：若干进程之间形成一种环形等待关系，该环路中的每个进程都在等待下一个进程所占有的资源。</li></ul><h4 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h4><p><strong>引入银行家算法</strong></p><p>当进程提出资源分配请求时，先判断满足本次请求会不会导致系统不安全状态。如果是，拒绝分配资源并阻塞进程；否则分配资源。<br><strong>安全状态</strong></p><p>如果能够找到某种顺序，使得给每个进程分配所有需要的资源后，能够依次顺利执行，结束并释放资源。</p><h4 id="死锁解除"><a href="#死锁解除" class="headerlink" title="死锁解除"></a>死锁解除</h4><ul><li>利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。（要求系统保持进程的历史信息，设置还原点）；</li><li>利用杀死进程。</li></ul><h3 id="中断发生了什么"><a href="#中断发生了什么" class="headerlink" title="中断发生了什么"></a>中断发生了什么</h3><ul><li>执行完每个指令后，CPU都要检查当前是否有外部中断信号。</li><li>如果检测到外部中断信号，则需要保护被中断进程的CPU环境（如<strong>程序状态字PSW、程序计数器、各种通用寄存器</strong>）。</li><li>根据中断信号类型转入相应的中断处理程序。</li><li>恢复进程的CPU环境并退出中断，返回原进程继续往下执行。</li></ul><h3 id="进程的异常控制流：陷阱、中断、异常和信号"><a href="#进程的异常控制流：陷阱、中断、异常和信号" class="headerlink" title="进程的异常控制流：陷阱、中断、异常和信号"></a>进程的异常控制流：陷阱、中断、异常和信号</h3><ul><li><p>陷阱是<strong>有意</strong>造成的异常，是执行一条指令的结果。陷阱的主要作用是实现<strong>系统调用</strong>。</p></li><li><p>中断由处理器<strong>外部</strong>的<strong>硬件</strong>产生，也无法预测发生时机。中断独立于当前程序，因此中断是异步事件。</p></li><li><p>异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。</p></li><li><p>信号是一种更高层的软件形式的异常，用来通知进程发生了某种系统事件。</p></li></ul><h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><h3 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h3><p>内核为了管理打开的文件所创建的索引，用于指代被打开的文件，对文件所有 I/O 操作的系统调用都需要通过文件描述符。</p><h3 id="软链接和硬链接"><a href="#软链接和硬链接" class="headerlink" title="软链接和硬链接"></a>软链接和硬链接</h3><p><strong>硬链接</strong><br>和源文件共享同一个inode节点，通过这个inode节点来访问文件数据。</p><p>文件系统会维护一个引用计数，只要有文件指向这个区块，它就不会从硬盘上消失。只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。</p><p><strong>创建方法</strong>：<code>ln [源文件] [链接文件.hard]</code></p><p><strong>软链接（符号链接）：</strong><br>类似windows的快捷方式，给文件创建一个快速的访问路径，它依赖于原文件。当原文件出现问题后，该链接不可用。</p><p><strong>创建方法</strong>：<code>ln -s [源文件] [链接文件.soft]</code></p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>删除源文件后硬链接还可以访问源文件数据，软链接失效。</p><p>原因：硬链接与源文件共用同一个inode，删除源文件后只是减少了inode的一个链接数，硬链接文件还可以继续访问源文件数据。而软链接是通过源文件路径来访问数据，但是源文件已经删除，所以路径访问不到，无法获取源文件数据。</p><blockquote><p>删除一个文件，文件并不会立即删除，而是先删除了目录项中的文件名信息，并使inode的链接数减一，只有链接数为0时文件才会删除</p></blockquote><h2 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h2><p>IO多路复用是指单个进程/线程就可以同时处理多个IO请求。</p><p>实现原理：用户将想要监视的文件描述符添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时，函数就会返回，然后该进程可以进行相应的读/写操作。</p><h3 id="select"><a href="#select" class="headerlink" title="select"></a><strong>select</strong></h3><ul><li>Socket 是文件描述符，线程盯的所有的 Socket，都放在文件描述符集合 fd_set 中，调用 select 函数来监听文件描述符集合是否有变化。</li><li>一旦有变化，依次查看每个文件描述符。发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。</li></ul><blockquote><p> Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式。因而能够同时盯的项目数量由 FD_SETSIZE 限制  </p></blockquote><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a><strong>epoll</strong></h3><p><strong>epoll的使用过程</strong>:</p><ul><li>调用<code>epoll_create()</code>函数创建一个epoll对象</li><li>调用<code>epoll_ctl()</code>函数将监控的文件描述符进行处理</li><li>调用<code>epoll_wait()</code>函数，等待就绪的文件描述符</li></ul><p>通过注册 callback 函数的方式，文件描述符变化时，会主动通知。  </p><ul><li>epoll_create 创建一个 epoll 对象，对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，保存这个 epoll要监听的所有 Socket  </li><li>epoll_ctl 将新的文件描述符通过epoll_ctl添加到红黑树中，由红黑树这个数据结构来管理所有需要监视的文件描述符</li><li>将新的文件描述符通过epoll_ctl添加到红黑树中，由红黑树这个数据结构来管理所有需要监视的文件描述符。  </li></ul><p><strong>使用场景</strong></p><p>高并发</p><p><strong>优点</strong></p><ul><li>文件描述符的个数无上限（只要内存足够大）。将新的文件描述符通过epoll_ctl添加到红黑树中，由红黑树这个数据结构来管理所有需要监视的文件描述符</li><li>通知文件描述符已经就绪的方式：每一个文件描述符都会与网卡绑定，当文件描述符就绪时，就会触发网卡去将对应的就绪的文件描述符回调，然后将其添加到队列（双向列表）之中</li><li>维护就绪队列：当调用函数<code>epoll_wait()</code>函数时，若该队列之中有元素就会被取走，这样的操作时间复杂度是<code>O(1)</code>;</li></ul><h3 id="select-poll-epoll三者的区别？"><a href="#select-poll-epoll三者的区别？" class="headerlink" title="select/poll/epoll三者的区别？"></a>select/poll/epoll三者的区别？</h3><ul><li><code>select</code>：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，<strong>开销大</strong>），由内核根据就绪状态修改该集合的内容。（缺点2）<strong>集合大小有限制</strong>，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：<strong>轮询的方式效率较低</strong>），当文件描述符的数量增加时，效率会线性下降；</li><li><code>poll</code>：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；</li><li><code>epoll</code>：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高；文件描述符就绪时，采用回调机制，避免了轮询；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。</li></ul><p>总结，区别主要在于：</p><ul><li>一个线程/进程所能打开的最大连接数</li><li>文件描述符传递方式（是否复制）</li><li>水平触发 or 边缘触发</li><li>查询就绪的描述符时的效率（是否轮询）</li></ul><h3 id="什么时候使用select-poll-epoll？"><a href="#什么时候使用select-poll-epoll？" class="headerlink" title="什么时候使用select/poll/epoll？"></a>什么时候使用select/poll/epoll？</h3><p>当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；</p><p>但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。</p><h3 id="水平、边缘触发"><a href="#水平、边缘触发" class="headerlink" title="水平、边缘触发"></a>水平、边缘触发</h3><p> <strong>水平触发（lt）</strong></p><p>只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知。</p><p>select，poll就属于水平触发。</p><p><strong>边缘触发（et）</strong></p><p>当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）</p><p>epoll支持水平触发和边缘触发。</p><p><strong>区别</strong></p><p>边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。</p><h3 id="常见IO模型"><a href="#常见IO模型" class="headerlink" title="常见IO模型"></a>常见IO模型</h3><ul><li>同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；</li><li>同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；</li><li>IO多路复用：是指单个进程/线程就可以同时处理多个IO请求。</li><li>异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="shell命令运行原理"><a href="#shell命令运行原理" class="headerlink" title="shell命令运行原理"></a>shell命令运行原理</h3><h4 id="什么是shell"><a href="#什么是shell" class="headerlink" title="什么是shell"></a>什么是shell</h4><p>Linux系统的shell作为操作系统的外壳，为用户提供使用操作系统的接口。</p><p>shell是用户和Linux内核之间的接口程序，如果把Linux内核想象成一个球体的中心，shell就是围绕内核的外层。当从shell或其他程序向Linux传递命令时，内核会做出相应的反应。</p><p>shell是一个命令语言解释器，它拥有自己内建的shell命令集，shell也能被系统中其他应用程序所调用。用户在提示符下输入的命令都由shell先解释然后传给Linux核心。</p><h4 id="内部命令和外部命令"><a href="#内部命令和外部命令" class="headerlink" title="内部命令和外部命令"></a>内部命令和外部命令</h4><p>cd，pwd这些内置命令是属于Shell的一部分，当Shell一运行起来就随Shell加载入内存，因此，当我们在命令行上输入这些命令就可以像调用函数一样直接使用，效率非常高。</p><p>而如ls，cat这些外部命令却不是如此，当我们在命令行输入cat，当前的Shell会fork一个子进程，然后调用exec载入这个命令的可执行文件，比如bin/cat，因此效率上稍微低了点。</p><h4 id="命令分析过程"><a href="#命令分析过程" class="headerlink" title="命令分析过程"></a>命令分析过程</h4><p>1、首先，检查用户输入的命令是否是内部命令，如果不是在检查是否是一个应用程序；<br>2、shell在搜索路径或者环境变量中寻找这些应用程序；<br>3、如果键入命令不是一个内部命令并且没有在搜索路径中查找到可执行文件，那么将会显示一条错误信息；<br>4、如果能够成功找到可执行文件，那么该内部命令或者应用程序将会被分解为系统调用传给Linux内核，然后内核在完成相应的工作</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/83398714" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/83398714</a></p><p><a href="https://www.cnblogs.com/javaguide/p/operating-system.html" target="_blank" rel="noopener">https://www.cnblogs.com/javaguide/p/operating-system.html</a></p>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP和HTTPS</title>
      <link href="/2021/06/30/interview-http/"/>
      <url>/2021/06/30/interview-http/</url>
      
        <content type="html"><![CDATA[<h2 id="报文"><a href="#报文" class="headerlink" title="报文"></a>报文</h2><h3 id="请求报文"><a href="#请求报文" class="headerlink" title="请求报文"></a>请求报文</h3><ul><li>请求行：请求方法、请求地址和协议及版本，以CRLF结束。</li><li>请求Header：拥有若干个报文属。 </li><li>空行，分隔首部和请求体</li><li>请求体。</li></ul><h3 id="POST和PUT的区别"><a href="#POST和PUT的区别" class="headerlink" title="POST和PUT的区别"></a>POST和PUT的区别</h3><p>在HTTP规范中，POST是非幂等的，PUT是幂等的</p><h3 id="GET与POST的区别？"><a href="#GET与POST的区别？" class="headerlink" title="GET与POST的区别？"></a>GET与POST的区别？</h3><ol><li>GET是幂等的，POST不是幂等的；</li><li>GET一般用于从服务器获取资源，而POST一般是改变服务器上的资源；</li><li>GET请求的数据附在URL之后，参数有长度限制；POST请求的数据在请求体中，参数无长度限制；</li><li>GET请求可被缓存、收藏、保留到历史记录，参数暴露在URL中。POST不会被保存，安全性相对较高，参数在body中；</li><li>GET只允许ASCII字符，POST对数据类型没有要求；</li><li>GET的长度有限制（操作系统或者浏览器的限制），而POST数据大小无限制</li><li>GET产生一个TCP数据包；POST一般产生两个TCP数据包。POST，浏览器先发送header，服务器响应100 continue，浏览器再发送body，服务器响应200</li></ol><blockquote><p>并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。</p><p> GET 加 request body，POST 带url参数，不同服务器的处理方式也是不同的，有些服务器支持有些不支持，所以，虽然GET可以带 request body，不能保证一定能被接收到。</p></blockquote><h3 id="post里面传的都是表单吗？"><a href="#post里面传的都是表单吗？" class="headerlink" title="post里面传的都是表单吗？"></a>post里面传的都是表单吗？</h3><p>contentType用于表明发送数据流的类型</p><p>常用的Content-Type：text/html，  image/png，application/x-www-form-urlencoded， multipart/form-data， application/json等。</p><h3 id="断点续传的原理是什么"><a href="#断点续传的原理是什么" class="headerlink" title="断点续传的原理是什么"></a>断点续传的原理是什么</h3><p>范围请求，首部字段<code>Range</code>来指定资源的byte范围。</p><h3 id="一个-url-分为哪几部分，各个部分的含义是什么"><a href="#一个-url-分为哪几部分，各个部分的含义是什么" class="headerlink" title="一个 url 分为哪几部分，各个部分的含义是什么"></a>一个 url 分为哪几部分，各个部分的含义是什么</h3><p>统一资源定位符（URL）用于完整地描述资源的地址。</p><p>URL的一般格式为（带方括号的为可选项）：<code>protocol://hostname[:port]/path/[;parameters][?query]#fragment</code> </p><p>URL由三部分组成： 协议类型 ，主机名 和 路径及文件名 。</p><p>1、protocol：指定使用的传输协议。 </p><p>2、hostname：是指存放资源的服务器主机名或 IP 地址。</p><p>3、port：省略时，使用默认端口。</p><p>4、path：表示主机上的一个目录或文件地址。</p><p>5、;parameters：指定特殊参数的可选项。<br>6、?query：可选，可有多个参数。<br>7、fragment，信息片断，用于指定网络资源中的片断。</p><h3 id="百分号（URL）编码"><a href="#百分号（URL）编码" class="headerlink" title="百分号（URL）编码"></a>百分号（URL）编码</h3><p>URL规定只能使用英文字母、数字和某些标点符号。如果 URL 中有其他字符，就必须编码后使用。</p><p><strong>百分号编码与 Base64 异同</strong></p><p><strong>相同点</strong>：它们都是用给定的ASCII 码（可打印字符）去表示更广范围数据的方法。</p><p><strong>区别</strong>：百分号编码是针对超出 URI 合法字符范围外的字符做编码，而 Base64 是针对二进制数据做编码；一个是对文本的编码，一个是对二进制数据的编码。</p><h3 id="HTTP怎么实现分包？"><a href="#HTTP怎么实现分包？" class="headerlink" title="HTTP怎么实现分包？"></a>HTTP怎么实现分包？</h3><p>用\r\n\r\n来分割消息头和消息体，消息头中有Content-Length来告知消息体有多大，如果没有该字段就表示无消息体</p><h3 id="响应报文"><a href="#响应报文" class="headerlink" title="响应报文"></a>响应报文</h3><ul><li>协议版本、状态码以及描述</li><li>响应头</li><li>空行：分隔响应头和响应体</li><li>响应体</li></ul><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><h3 id="什么是HTTP"><a href="#什么是HTTP" class="headerlink" title="什么是HTTP"></a>什么是HTTP</h3><p>Hyper Text Transfer Protocol（超文本传输协议），服务器传输超文本到本地浏览器。</p><p>HTTP是属于TCP上层的协议，基于请求/响应模式的，是无状态的协议。</p><h3 id="HTTP为什么基于TCP？"><a href="#HTTP为什么基于TCP？" class="headerlink" title="HTTP为什么基于TCP？"></a>HTTP为什么基于TCP？</h3><p>http协议只定义了应用层的东西，需要基于TCP实现消息可靠性</p><h3 id="http1-0-1-1-2-0-的区别"><a href="#http1-0-1-1-2-0-的区别" class="headerlink" title="http1.0/1.1/2.0 的区别"></a>http1.0/1.1/2.0 的区别</h3><h4 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP 1.1"></a>HTTP 1.1</h4><ul><li><p>支持长连接，一个TCP连接上可以传送多个HTTP请求和响应，在HTTP1.1中默认开启keep-alive</p></li><li><p>请求和响应都应支持Host头域，且请求消息中如果没有Host域会报告一个错误（400 Bad Request）。</p></li><li><p>引入了更多的缓存控制策略，例如If-Match， If-None-Match。</p></li><li><p>引入了range头域，它允许只请求资源的某个部分，支持断点续传。</p></li></ul><h4 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h4><p>多路复用：请求与响应以二进制帧的形式交错进行，只需建立一次连接，即一轮三次握手，实现多路复用</p><p>压缩消息头：将原来每次都要携带的大量 key value在两端建立一个索引表，对相同的头只发送索引表中的索引。</p><p>服务端推送：HTTP2.0中服务器会主动将资源推送给客户端。</p><h3 id="HTTP2-0的多路复用和HTTP1-1中的长连接复用区别"><a href="#HTTP2-0的多路复用和HTTP1-1中的长连接复用区别" class="headerlink" title="HTTP2.0的多路复用和HTTP1.1中的长连接复用区别"></a>HTTP2.0的多路复用和HTTP1.1中的长连接复用区别</h3><ul><li>HTTP/1.0 每一个请求都要建立一个连接；</li><li>HTTP/1.1 默认是 keep-alive 的，即tcp连接可以复用，不用每次都要重新建立和断开 TCP 连接，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞。</li><li>HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行</li></ul><h3 id="浏览器对同一-Host-建立-TCP-连接到数量有没有限制？"><a href="#浏览器对同一-Host-建立-TCP-连接到数量有没有限制？" class="headerlink" title="浏览器对同一 Host 建立 TCP 连接到数量有没有限制？"></a>浏览器对同一 Host 建立 TCP 连接到数量有没有限制？</h3><p>Chrome 最多允许对同一个 Host 建立六个 TCP 连接，不同的浏览器有一些区别。</p><h3 id="HTTP如何保持长连接？"><a href="#HTTP如何保持长连接？" class="headerlink" title="HTTP如何保持长连接？"></a>HTTP如何保持长连接？</h3><ul><li>浏览器发起请求，HTTP版本号为1.1。</li><li>服务器收到请求，在响应的头中也增加keep-alive。同时不会关闭已建立的tcp连接。</li><li>浏览器收到服务器的响应头中包含keep-alive，不关闭tcp连接。并用该tcp连接再发送请求。</li></ul><p>减少了TCP的三次握手和四次挥手</p><h3 id="HTTP缓存机制"><a href="#HTTP缓存机制" class="headerlink" title="HTTP缓存机制"></a>HTTP缓存机制</h3><p>HTTP缓存主要分强制缓存和对比缓存</p><ul><li>强制缓存：Cache-Control，Exipres（HTTP1.0），浏览器直接读本地缓存，不会再跟服务器端交互，状态码200。</li><li>对比缓存：Last-Modified / If-Modified-Since， Etag / If-None-Match，每次请求需要让服务器判断一下资源是否更新过，从而决定浏览器是否使用缓存，如果是，则返回304，否则重新完整响应。</li></ul><h3 id="重定向和转发"><a href="#重定向和转发" class="headerlink" title="重定向和转发"></a>重定向和转发</h3><ul><li>重定向：返回3xx状态码+location响应头；浏览器跳转到location所在的URL。重定向是在客户端进行跳转。URL会改变。</li><li>转发：直接获取要转发的URL地址并返回。转发是在服务端进行跳转。URL不会改变。</li></ul><h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><h3 id="什么是-https"><a href="#什么是-https" class="headerlink" title="什么是 https"></a>什么是 https</h3><p>https 是 http + ssl，对 http 通信内容进行加密，是HTTP的安全版</p><p>Https的作用：</p><ul><li>内容加密建立一个信息安全通道，来保证数据传输的安全；</li><li>身份认证确认网站的真实性</li></ul><h3 id="什么是SSL"><a href="#什么是SSL" class="headerlink" title="什么是SSL"></a>什么是SSL</h3><p>Secure Socket Layer，创建安全的Internet通信，用于加密浏览器和服务器之间的通信。</p><h3 id="HTTP和HTTPS区别？"><a href="#HTTP和HTTPS区别？" class="headerlink" title="HTTP和HTTPS区别？"></a>HTTP和HTTPS区别？</h3><ol><li>端口不同：HTTP使用的80端口，HTTPS使用443端口；</li><li>HTTP信息是明文传输，HTTPS运行在SSL之上，添加了加密和认证机制，更加安全；</li><li>HTTPS由于加密解密会带来更大的CPU和内存开销；</li><li>HTTPS通信需要证书，一般需要向CA购买</li><li>HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。</li></ol><h3 id="Https的连接过程？"><a href="#Https的连接过程？" class="headerlink" title="Https的连接过程？"></a>Https的连接过程？</h3><p><img src="https.png" alt></p><h4 id="证书验证阶段"><a href="#证书验证阶段" class="headerlink" title="证书验证阶段"></a>证书验证阶段</h4><ul><li>浏览器发起请求，请求携带了浏览器支持的加密算法和哈希算法</li><li>服务器接收到请求之后，选择浏览器支持的加密算法和哈希算法，会返回证书，包括公钥</li><li>浏览器接收到证书之后，会检验证书是否合法（网站的网址、网站的公钥、证书的有效期），不合法的话，会弹出告警提示</li></ul><h4 id="数据传输阶段"><a href="#数据传输阶段" class="headerlink" title="数据传输阶段"></a>数据传输阶段</h4><p>证书验证合法之后</p><ul><li>浏览器会生成一个随机数，使用公钥进行加密，发送给服务端</li><li>服务器收到浏览器发来的加密随机数，使用私钥进行解密，得到随机数</li><li>解析成功之后，使用随机数为秘钥的对称加密算法进行加密传输</li></ul><h3 id="https为什么要采用对称和非对称加密结合的方式"><a href="#https为什么要采用对称和非对称加密结合的方式" class="headerlink" title="https为什么要采用对称和非对称加密结合的方式"></a>https为什么要采用对称和非对称加密结合的方式</h3><p>非对称加密在性能上较差，对称加密安全性较差。</p><p>非对称加密主要用于传输秘钥，真正数据通信都是通过对称加密进行的。  </p><h3 id="什么是中间人攻击"><a href="#什么是中间人攻击" class="headerlink" title="什么是中间人攻击"></a>什么是中间人攻击</h3><p>与通讯的两端分别创建独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方直接对话。</p><p>中间人拦截客户端请求，然后向客户端提供自己的公钥，再向服务端请求公钥。</p><h3 id="https-是如何防止中间人攻击的"><a href="#https-是如何防止中间人攻击的" class="headerlink" title="https 是如何防止中间人攻击的"></a>https 是如何防止中间人攻击的</h3><p>https证书，证明就需要权威第三方机构CA来公正。</p><h3 id="浏览器是如何确保CA证书的合法性？"><a href="#浏览器是如何确保CA证书的合法性？" class="headerlink" title="浏览器是如何确保CA证书的合法性？"></a>浏览器是如何确保CA证书的合法性？</h3><p><strong>证书包含什么信息？</strong></p><p>颁发机构、公钥、公司信息、域名、有效期、指纹</p><p><strong>浏览器如何验证证书的合法性？</strong></p><ul><li>验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；</li><li>判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，利用本地根证书完成来源验证；</li><li>判断证书是否被篡改。需要与CA服务器进行校验；</li><li>判断证书是否已吊销。</li></ul><h3 id="https可以抓包吗"><a href="#https可以抓包吗" class="headerlink" title="https可以抓包吗"></a>https可以抓包吗</h3><p>常规下抓到的包是加密状态，无法直接查看。</p><p><strong>模拟中间人抓包</strong></p><ul><li>抓包工具生成一个证书，用户需要手动把证书安装到客户端中。</li><li>客户端发起请求到抓包工具，然后抓包工具再转发请求到服务器</li><li>把服务器返回的结果在控制台输出后再返回给客户端，从而完成整个请求的闭环。</li></ul><h3 id="输入-xxx-com，怎么变成-https-www-xxx-com-的？"><a href="#输入-xxx-com，怎么变成-https-www-xxx-com-的？" class="headerlink" title="输入 xxx.com，怎么变成 https://www.xxx.com 的？"></a>输入 xxx.com，怎么变成 <a href="https://www.xxx.com" target="_blank" rel="noopener">https://www.xxx.com</a> 的？</h3><p>302跳转，服务器把所有的HTTP流量跳转到HTTPS。</p><h3 id="什么是对称加密、非对称加密？区别是什么？"><a href="#什么是对称加密、非对称加密？区别是什么？" class="headerlink" title="什么是对称加密、非对称加密？区别是什么？"></a>什么是对称加密、非对称加密？区别是什么？</h3><ul><li>对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4</li><li>非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。私钥加密的信息，只有公钥才能解密  如：RSA</li><li>区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高  </li></ul><p><strong>数字证书</strong>  </p><p>鉴别别人给你的公钥是对的。  包括公钥、证书的所有者 、CA签名、颁发者、签名算法。</p><h3 id="数字签名、报文摘要的原理"><a href="#数字签名、报文摘要的原理" class="headerlink" title="数字签名、报文摘要的原理"></a>数字签名、报文摘要的原理</h3><ul><li>发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。</li><li>摘要算法：MD5、SHA</li></ul><p><strong>签名算法</strong></p><p>一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值得出原来的信息内容。在把信息发送出去时，把这个 Hash 值加密后，作为一个签名和信息一起发出去。 </p><p> CA 用自己的私钥给外卖网站的公钥签名，就相当于给外卖网站背书，形成了外卖网站的证书。</p><h2 id="Session和Cookie"><a href="#Session和Cookie" class="headerlink" title="Session和Cookie"></a>Session和Cookie</h2><h3 id="Session与Cookie的区别？"><a href="#Session与Cookie的区别？" class="headerlink" title="Session与Cookie的区别？"></a>Session与Cookie的区别？</h3><p>Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案</p><p>Cookie保存在客户端本地，客户端请求时会将Cookie一起提交；</p><p>Session保存在服务端，检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie</p><p><strong>cookie用途</strong></p><p>保存用户相关信息，下次再访问您的站点时，应用程序就可以检索以前保存的信息。</p><h3 id="服务端怎么设置cookie"><a href="#服务端怎么设置cookie" class="headerlink" title="服务端怎么设置cookie"></a><strong>服务端怎么设置cookie</strong></h3><p>HTTP响应，Set-Cookie中设置cookie</p><h3 id="cookie关闭浏览器重新打开就没了吗？"><a href="#cookie关闭浏览器重新打开就没了吗？" class="headerlink" title="cookie关闭浏览器重新打开就没了吗？"></a>cookie关闭浏览器重新打开就没了吗？</h3><p>cookie生命周期默认为浏览器会话期间，驻留内存，关闭浏览器cookie就没了</p><h3 id="浏览器禁用cookie怎么办"><a href="#浏览器禁用cookie怎么办" class="headerlink" title="浏览器禁用cookie怎么办"></a>浏览器禁用cookie怎么办</h3><p><strong>URL重写</strong></p><p>判断前端是否禁用了cookie，如果禁用了cookie，在url后带上jsessionid。</p><h3 id="cookie包含哪几项内容"><a href="#cookie包含哪几项内容" class="headerlink" title="cookie包含哪几项内容"></a>cookie包含哪几项内容</h3><ul><li>Expire：cookie失效日期。</li><li>Domain和Path：限制 cookie 能被哪些 URL 访问。即请求的URL是Domain或其子域、且URL的路径是Path或子路径，则都可以访问该cookie</li><li>Size：Cookie的大小</li><li>Secure：Secure选项用来设置cookie只在确保安全的请求中（HTTPS）才会发送。</li><li>httpOnly：这个选项用来设置cookie是否能通过 js 去访问。<strong>带httpOnly选项时，客户端则无法通过js代码去访问cookie。</strong></li></ul><blockquote><p>http/1.1协议中Expires已经由 Max age 选项代替。</p></blockquote><h3 id="Cookie防劫持"><a href="#Cookie防劫持" class="headerlink" title="Cookie防劫持?"></a>Cookie防劫持?</h3><p>基于XSS攻击，窃取Cookie信息，并冒充他人身份。</p><ul><li>给Cookie添加HttpOnly属性， document.cookie无法获取到该Cookie值.</li><li>在cookie中添加校验信息， 这个校验信息和当前用户外置环境有些关系，比如ip、agent有关，当cookie被人劫持了，在服务器端校验的时候， 发现校验值发生了变化， 要求重新登录</li><li>cookie中session id的定时更换</li></ul><h2 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h2><h3 id="常见状态码"><a href="#常见状态码" class="headerlink" title="常见状态码"></a>常见状态码</h3><ol><li>1xx消息 这一类型的状态码，代表请求已被接受，需要继续处理</li><li>2xx状态码：操作成功。200 OK，201状态码英文名称是Created，该状态码表示已创建。</li><li>3xx状态码：重定向。</li><li>4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden；404 Not Found；405 方法禁用，禁用请求中指定的方法。</li><li>5xx状态码：服务端错误。500服务器内部错误；501服务不可用； 502 Bad Gateway：请求未完成，服务器从上游服务器收到一个无效的响应。 </li></ol><p><code>502</code>并不是指网关（例如nginx）本身出了问题，而是从上游接收响应出了问题，比如由于上游服务自身超时导致不能产生响应数据，或者上游不按照协议约定来返回数据导致网关不能正常解析。</p><p><code>504</code>，<code>Gateway Timeout</code>，网关超时。它表示网关没有从上游及时获取响应数据。原因在于超过了<code>nginx</code>自身的超时时间</p><p>304 Not Modified：客户端有缓冲的文件并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。</p><h3 id="301和302区别"><a href="#301和302区别" class="headerlink" title="301和302区别"></a>301和302区别</h3><ul><li>301 永久重定向；302暂时重定向</li><li>都表示重定向，自动跳转到一个新的URL地址</li><li>301表示旧地址已经被永久地移除了（这个资源不可访问了），搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。</li></ul><h3 id="发生502，应该先查看什么"><a href="#发生502，应该先查看什么" class="headerlink" title="发生502，应该先查看什么"></a>发生502，应该先查看什么</h3><p>502错误最通常的出现情况就是后端主机宕机。</p><p>1、查看后台进程数是否够用，确定是否是因为高并发导致的</p><p>2、查看程序执行时间是否超过Nginx等待时间，应用日志。可能是数据库死锁导致的。</p><p>3、查看Nginx日志</p><h3 id="发生500应该先查看什么"><a href="#发生500应该先查看什么" class="headerlink" title="发生500应该先查看什么"></a>发生500应该先查看什么</h3><p>先看看服务的进程还在不在，然后查看日志，从日志里面找原因。</p><h3 id="为什么重定向？"><a href="#为什么重定向？" class="headerlink" title="为什么重定向？"></a>为什么重定向？</h3><p><strong>域名别称</strong>：需要为资源设定不同的名称。其重定向到那个实际的URL</p><p><strong>保持链接有效</strong>：重构 Web 站点，不想旧链接失效。</p><p><strong>对于耗时请求的临时响应</strong><br>一些请求的处理会需要比较长的时间，链接到一个页面，表示请求的操作已经被列入计划，并且最终会通知用户操作的进展情况。</p><h3 id="从输入网址到获得页面的过程？"><a href="#从输入网址到获得页面的过程？" class="headerlink" title="从输入网址到获得页面的过程？"></a>从输入网址到获得页面的过程？</h3><ol><li>浏览器查询 DNS，获取域名对应的IP地址<ul><li>浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询。</li><li>如果本地域名服务器并未缓存该网址映射关系，迭代查询根 DNS 、顶级域名服务器、权威DNS服务器；</li></ul></li><li>浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；</li><li>TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；</li><li>服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；</li><li>浏览器解析并渲染视图；</li></ol>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python多线程同步</title>
      <link href="/2021/06/26/python-thread/"/>
      <url>/2021/06/26/python-thread/</url>
      
        <content type="html"><![CDATA[<h2 id="Condition相关函数"><a href="#Condition相关函数" class="headerlink" title="Condition相关函数"></a>Condition相关函数</h2><p><strong>acquire()</strong> — 线程锁，注意线程条件变量Condition中的所有相关函数使用必须在<strong>acquire()</strong> <strong>/release()</strong> 内部操作；</p><p><strong>release()</strong> — 释放锁；</p><p><strong>wait(timeout)</strong> — 线程挂起(阻塞状态)，直到收到一个notify通知或者超时才会被唤醒继续运行（超时参数默认不设置，可选填，类型是浮点数，单位是秒）。wait()必须在已获得Lock前提下才能调用，否则会触发RuntimeError；</p><p><strong>notify(n=1)</strong> — 通知其他线程，那些挂起的线程接到这个通知之后会开始运行，缺省参数，默认是通知一个正等待通知的线程,最多则唤醒n个等待的线程。notify()必须在已获得Lock前提下才能调用，否则会触发RuntimeError，notify()不会主动释放Lock；</p><p><strong>notifyAll()</strong> — 如果wait状态线程比较多，notifyAll的作用就是通知所有线程；</p><h2 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h2><h3 id="两个线程交替打印1-10"><a href="#两个线程交替打印1-10" class="headerlink" title="两个线程交替打印1-10"></a>两个线程交替打印1-10</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> threadingx <span class="token operator">=</span> <span class="token number">0</span>con <span class="token operator">=</span> threading<span class="token punctuation">.</span>Condition<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">print_num</span><span class="token punctuation">(</span>mode<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> x    con<span class="token punctuation">.</span>acquire<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> x <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> x <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> mode<span class="token punctuation">:</span>            con<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>get_ident<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>        x <span class="token operator">+=</span> <span class="token number">1</span>        con<span class="token punctuation">.</span>notify<span class="token punctuation">(</span><span class="token punctuation">)</span>    con<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    t1 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>print_num<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    t2 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>print_num<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="三个线程同时启动，优先级相同，分别打印A、B、C，保证打印顺序为ABC。"><a href="#三个线程同时启动，优先级相同，分别打印A、B、C，保证打印顺序为ABC。" class="headerlink" title="三个线程同时启动，优先级相同，分别打印A、B、C，保证打印顺序为ABC。"></a>三个线程同时启动，优先级相同，分别打印A、B、C，保证打印顺序为ABC。</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> threadingx <span class="token operator">=</span> <span class="token number">0</span>flag <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">]</span>con <span class="token operator">=</span> threading<span class="token punctuation">.</span>Condition<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">print_char</span><span class="token punctuation">(</span>to_print<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> flag    <span class="token keyword">global</span> x    con<span class="token punctuation">.</span>acquire<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> flag<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token operator">!=</span> to_print<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># print(flag[x]+'!='+to_print)</span>        con<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>flag<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span>    x <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token comment" spellcheck="true"># 需要通知所有其他线程</span>    con<span class="token punctuation">.</span>notifyAll<span class="token punctuation">(</span><span class="token punctuation">)</span>    con<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    t1 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>print_char<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    t2 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>print_char<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'B'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    t3 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>print_char<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'C'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    t3<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    t3<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Paxos与Raft</title>
      <link href="/2021/06/25/paxos-yu-raft/"/>
      <url>/2021/06/25/paxos-yu-raft/</url>
      
        <content type="html"><![CDATA[<h2 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h2><p>解决了一致性问题。</p><blockquote><p>在一个分布式系统中，每个 proposer都可以提出一个 value，consensus 算法就是用来从这些 values 里选定一个最终 value。如果没有 value 被提出来，那么就没有 value 被选中；如果有1个 value 被选中，那么所有的 process 都应该被通知到。</p></blockquote><h3 id="Paxos-例子说明"><a href="#Paxos-例子说明" class="headerlink" title="Paxos 例子说明"></a>Paxos 例子说明</h3><ul><li>无人竞争，超过半数即可通过提案</li><li>先后竞争，先到先得，回复当前选择；同时竞争，先到先得，视后到者身份不同，可能有回复，可能无回复</li></ul><h2 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h2><p>Raft 是一种为了管理复制日志的一致性算法。</p><p><strong>一致性</strong><br>一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。</p><p><strong>管理日志</strong><br>一致性算法是从复制状态机的背景下提出的，复制状态机通常都是<code>基于复制日志</code>实现的，这个日志可以理解为一个指令。</p><h3 id="领导人选举"><a href="#领导人选举" class="headerlink" title="领导人选举"></a>领导人选举</h3><p>Raft 通过选举一个领导人，然后给予他全部的管理复制日志的责任来实现一致性。</p><p>每个 server 都可能会在 3 个身份之间切换：领导者、候选者、跟随者</p><p>所有服务器初始化的时候，都是 <code>跟随者</code>，这个时候需要一个 <code>领导者</code>，所有人都变成 <code>候选者</code>，直到有人成功当选 <code>领导者</code>。</p><p>领导者也有宕机的时候，宕机后引发新的 <code>选举</code>，所以，整个集群在选举和正常运行之间切换</p><p>每一个 server 最多在一个任期内投出一张选票（有任期号约束），先到先得。</p><p>一旦成功，立即成为领导人，然后广播所有服务器停止投票阻止新得领导产生。</p><h3 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h3><p>客户端发送日志给领导者，随后领导者将日志复制到其他的服务器。如果跟随者故障，领导者将会尝试重试。直到所有的跟随者都成功存储了所有日志。</p><p><strong>步骤</strong></p><ol><li>客户端提交</li><li>复制数据到所有跟随者</li><li>跟随者回复 <code>确认收到</code></li><li>领导者回复客户端和所有跟随者 <code>确认提交</code>。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2PC与3PC</title>
      <link href="/2021/06/23/2pc-yu-3pc/"/>
      <url>/2021/06/23/2pc-yu-3pc/</url>
      
        <content type="html"><![CDATA[<h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h2><p>二阶段提交就是将事务的提交过程分成了两个阶段来进行处理。</p><h3 id="阶段一"><a href="#阶段一" class="headerlink" title="阶段一"></a>阶段一</h3><ul><li><p>事务询问<br>协调者向所有的参与者询问，是否准备好了执行事务，并开始等待各参与者的响应。</p></li><li><p>执行事务<br>各参与者节点执行事务操作，并将 Undo 和 Redo 信息记入事务日志中</p></li><li><p>各参与者向协调者反馈事务询问的响应<br>如果参与者成功执行了事务操作，那么就反馈给协调者 Yes 响应，表示事务可以执行；如果参与者没有成功执行事务，就返回 No 给协调者，表示事务不可以执行。</p></li></ul><h3 id="阶段二"><a href="#阶段二" class="headerlink" title="阶段二"></a>阶段二</h3><p>根据阶段一的投票结果执行两种操作：执行事务提交or中断事务。</p><p>执行事务提交：</p><ol><li>发送提交请求：协调者向所有参与者发出 commit 请求。</li><li>事务提交：参与者收到 commit 请求后，会正式执行事务提交操作，并在完成提交之后释放整个事务执行期间占用的事务资源。</li><li>反馈事务提交结果：参与者在完成事务提交之后，向协调者发送 Ack 信息。</li><li>协调者接收到所有参与者反馈的 Ack 信息后，完成事务。</li></ol><p>中断事务：</p><ol><li>发送回滚请求：协调者向所有参与者发出 Rollback 请求。</li><li>事务回滚：参与者接收到 Rollback 请求后，会利用其在阶段一种记录的 Undo 信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。</li><li>反馈事务回滚结果：参与者在完成事务回滚之后，想协调者发送 Ack 信息。</li><li>中断事务：协调者接收到所有参与者反馈的 Ack 信息后，完成事务中断。</li></ol><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：原理简单，实现方便<br>缺点：同步阻塞，单点问题，数据不一致，过于保守</p><p><strong>同步阻塞：</strong></p><p>在二阶段提交的过程中，所有的节点都在等待其他节点的响应，无法进行其他操作。这种同步阻塞极大的限制了分布式系统的性能。</p><p><strong>单点问题：</strong></p><p>协调者在整个二阶段提交过程中很重要，如果协调者在提交阶段出现问题，那么整个流程将无法运转，更重要的是：其他参与者将会处于一直锁定事务资源的状态中，而无法继续完成事务操作。</p><p><strong>数据不一致：</strong></p><p>假设当协调者向所有的参与者发送 commit请求之后，发生了局部网络异常或者是协调者在尚未发送完所有 commit 请求之前自身发生了崩溃，导致最终只有部分参与者收到了 commit 请求。这将导致严重的数据不一致问题。</p><p><strong>过于保守：</strong></p><p>如果在二阶段提交的提交询问阶段中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的化，这时协调者只能依靠其自身的超时机制来判断是否需要中断事务，显然，这种策略过于保守。换句话说，<strong>二阶段提交协议没有设计较为完善的容错机制，任意一个节点是失败都会导致整个事务的失败</strong></p><h2 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h2><p>三阶段提交，是 2PC 的改进版，其将 2PC 的 “提交事务请求” 过程一分为二。</p><h3 id="阶段一：CanCommit"><a href="#阶段一：CanCommit" class="headerlink" title="阶段一：CanCommit"></a>阶段一：CanCommit</h3><ol><li>务询问：协调者向所有的参与者发送一个包含事务内容的 canCommit 请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。</li><li>各参与者向协调者反馈事务询问的响应：参与者接收来自协调者的 canCommit 请求，如果参与者认为自己可以顺利执行事务，就返回 Yes，否则反馈 No 响应。</li></ol><h3 id="阶段二：PreCommit"><a href="#阶段二：PreCommit" class="headerlink" title="阶段二：PreCommit"></a>阶段二：PreCommit</h3><p>协调者在得到所有参与者的响应之后，会根据结果执行2种操作：执行事务预提交，或者中断事务。</p><p><strong>执行事务预提交</strong></p><ul><li>发送预提交请求：协调者向所有参与者节点发出 preCommit 的请求，并进入 prepared 状态。</li><li>事务预提交：参与者受到 preCommit 请求后，会执行事务操作，对应 2PC 中的 “执行事务”，也会 Undo 和 Redo 信息记录到事务日志中。</li><li>各参与者向协调者反馈事务执行的结果：如果参与者成功执行了事务，就反馈 Ack 响应，同时等待指令：提交（commit） 或终止（abor）。</li></ul><p><strong>中断事务</strong></p><ul><li>发送中断请求：协调者向所有参与者节点发出 abort 请求 。</li><li>中断事务：参与者如果收到 abort 请求或者超时了，都会中断事务。</li></ul><h3 id="阶段三：do-Commit"><a href="#阶段三：do-Commit" class="headerlink" title="阶段三：do Commit"></a>阶段三：do Commit</h3><p>该阶段做真正的提交，同样也会出现两种情况：</p><p><strong>执行提交</strong></p><ul><li>发送提交请求：进入这一阶段，如果协调者正常工作，并且接收到了所有协调者的 Ack 响应，那么协调者将从 “预提交” 状态变为 “提交” 状态，并向所有的参与者发送 doCommit 请求 。</li><li>事务提交：参与者收到 doCommit 请求后，会正式执行事务提交操作，并在完成之后释放在整个事务执行期间占用的事务资源。</li><li>反馈事务提交结果：参与者完成事务提交后，向协调者发送 Ack 消息。</li><li>完成事务：协调者接收到所有参与者反馈的 Ack 消息后，完成事务。</li></ul><p><strong>中断事务</strong></p><p>假设有任何参与者反馈了 no  响应，或者超时了，就中断事务。</p><ul><li>发送中断请求：协调者向所有的参与者节点发送 abort 请求。</li><li>事务回滚：参与者接收到 abort 请求后，会利用其在二阶段记录的 undo 信息来执行事务回滚操作，并在完成回滚之后释放整个事务执行期间占用的资源。</li><li>反馈事务回滚结果：参与者在完成事务回滚之后，向协调者发送 Ack 消息。</li></ul><blockquote><p>一旦进入阶段三，可能会出现 2 种故障：</p><ul><li><p>协调者出现问题</p></li><li><p>协调者和参与者之间的网络故障</p><p>出现了任一种情况，最终都会导致参与者无法收到 doCommit 请求或者 abort 请求，针对这种情况，参与者都会在等待超时之后，继续进行事务提交。</p></li></ul></blockquote><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong></p><p>减少了参与者的阻塞范围（第一个阶段是不阻塞的），并且能够在单点故障后继续达成一致（2PC 在提交阶段会出现此问题，而 3PC 会根据协调者的状态进行回滚或者提交）。</p><p><strong>缺点</strong></p><p>如果参与者收到了 preCommit 消息后，出现了网络分区，那么参与者等待超时后，都会进行事务的提交，这必然会出现事务不一致的问题。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>oceanbase了解</title>
      <link href="/2021/06/23/oceanbase/"/>
      <url>/2021/06/23/oceanbase/</url>
      
        <content type="html"><![CDATA[<p>透明可扩展的企业级数据库</p><h2 id="透明可扩展"><a href="#透明可扩展" class="headerlink" title="透明可扩展"></a>透明可扩展</h2><p><strong>企业级数据库面临的问题</strong></p><p><strong>企业级数据库是一个面向单机设计的数据库，没有解决可扩展性的问题。</strong>这跟企业数据库的技术有关，也跟企业级数据库的商业模式有关。</p><p>如果容量不足怎么办？可以采用垂直扩展的方式。通过不断扩展容量，虽然稳定性也能做得还不错，但是成本的<strong>代价会变得非常的高。</strong></p><p><strong>云数据库 != 透明可扩展</strong></p><p>数据库的模式采用的是存储计算分离的方式，解决了存储可扩展的问题，但是没有解决更关键的问题，那就是事务与 SQL 可扩展的问题。</p><p><strong>分库分表 != 透明可扩展</strong></p><p>分库分表的方案从理论上讲就永远不可能实现全区索引这个功能。另外整个分库分表方案往往会在上面架一层中间件，通过中间件做简单的 SQL 转发、路由、聚合，以及一些比较基础的数据查询功能。</p><p>它不支持很多功能，包括全局快照——跨多台机器的全局快照，包括复杂查询——跨服务器的复杂查询，跨服务器的写入操作，也包括一个很重要的能力——带容错能力的分布式事务。</p><p>很多中间件是支持分布式事务的，但是中间件支持的分布式事务是不带容错能力的分布式事务。当服务器出现故障的时候，整个事务会被夯住，需要人肉去做容错。这种方案跟真正的分布式数据库里带容错的分布式事务是两个方案，有本质的差别。</p><p><strong>透明可扩展的企业级数据库</strong></p><p>透明可扩展的企业级分布式数据库需要具备一些基本的属性：</p><ol><li>它需要像传统企业级数据库一样，无需业务修改，按需扩容</li><li>核心能力可扩展，包括存储，事务和 SQL。其中这里面存储可扩展是最容易实现的，事务可扩展是最难做到的，SQL 可扩展是工作量最大的。</li><li>持续可用，保持稳定：整个系统需要是持续可用的，不管服务器发生了什么故障，都必须做到系统稳定，整个系统对外体现一个持续稳定的输出，保证业务的连续性。</li><li>具备企业级数据库功能</li><li>通过核心业务和 benchmark 证明</li></ol><h2 id="透明可扩展的理论基础"><a href="#透明可扩展的理论基础" class="headerlink" title="透明可扩展的理论基础"></a>透明可扩展的理论基础</h2><p>事务是一个非常古老的概念，必须遵循 ACID 特性。</p><p><strong>两阶段提交协议</strong>本身并不复杂。当我们需要把多台机器连起来做协调的时候，所有机器都叫做参与者，然后其中有一台机器会选出来做协调者。当要进行事务提交的时候，协调者先给所有的参与者发送 prepare 消息，如果所有的参与者都 prepare 成功，最终协调者认为整个事务可以提交了，然后再发出 commit 消息，让每一个参与者都提交事务。如果其中某个参与者因为各种情况比如资源不足最后没法提交事务，整个事务提交失败，协调者给参与者发送回滚消息。</p><p>这个协议看起来很简单，但没有考虑容错。假设协调者出现了故障，整个数据就会被 hung 住，即使是参与者出现故障，那参与者所在的那台机器也会被 hung 住。在一个高并发的系统里只要有一台机器被 hung 住，就意味着客户端被 hung 住。客户端被 hung 住就意味着整个系统被 hung 住。所以一台机器故障最终会导致整个集群的不可服务。</p><p><strong>分布式事务：Paxos + 2PC</strong></p><ul><li>中间件 XA：依赖数据库</li></ul><p>其中的一种方案就是中间件 XA。中间件 XA 是一种分布式事务的实践方法， XA 的本质是把协调者跟参与者的状态持久化到数据库里，由数据库来支持容错，所以中间件是无状态的。但是我们自己是分布式事务数据库的设计者，不可能再把状态持久化到另外一个分布式数据库里来支持容错。</p><ul><li>NOSQL 系统：回避一致性与分布式事务</li></ul><p>另外一个思路是 NOSQL 系统中的 CAP 理论。CAP 三者不可兼得。在一个需要考虑容错的系统设计里面，P（分区容错）是不可选择的，一定会出现网络分区的情况。C（一致性）跟 A（可用性）二者只能取其一，要么要一致性，要么要可用性。</p><p>其实 NOSQL 系统从理论上就已经比较“巧妙”的回避了一致性分布式问题。分布式事务的问题就不处理了，或者根本就不支持分布式事务。</p><p><strong>云时代的架构选择：采用 Paxos + 2PC</strong></p><p> Paxos + 2PC 的论文。但是这个协议从理论走向工程实践，经过了十多年的时间。<br><strong>CAP 与 Paxos</strong></p><p>CAP 理论告诉我们，要么强一致，要么高可用。Paxos 却能同时实现强一致和高可用，那么 Paxos 协议是不是违背了 CAP 理论呢？我认为其实是没有违背的，本质在于 Paxos 里的高可用跟 CAP 里的可用性是两个不同的概念。</p><ul><li><p>Paxos 是从系统整体的角度来看的，哪怕出现单个节点故障的时候，只要多数派能够快速恢复使得整个系统继续服务，它就是高可用的。</p></li><li><p>但是 CAP 理论是从故障节点的角度来看的，当单个节点出现故障的时候，这个故障的节点能不能在有限的时间被访问到，这是 CAP 理论里可用性的意思。</p></li></ul><p><strong>Raft or Paxos</strong></p><p>Paxos 协议有一个很大的设计假设，它要求支持多个投票，也就是数据库里的多条日志之间是可以乱序提交的，可以并行处理的。但是 raft 协议的做了一个约束，数据库的多个投票多条日志一定要按照顺序执行，只能前一个日志被确认了才能确认后一个日志。</p><p><strong>这种简化使得 Paxos 协议走进了千家万户。</strong>但是有得必有失，他把这个约束变得更简单了以后，导致了两个问题，第一个问题是并发能力变得更差了。以前支持并发的提交，现在只能支持一个结束以后再来下一个，所以它的性能变差了。</p><p>第二个是可用性的问题。如果采用 Paxos 协议，当一台机器新上线的时候很快就能提供服务了，因为不需要等前面的数据确认它就能提供服务，但是如果使用的是 raft 协议，需要等前面的所有日志确认以后才能提供服务，所以说 raft 协议存在可用性的风险。在某些场景尤其是异地部署和比较差的网络环境下是有风险的。</p><p><strong>自动负载均衡</strong></p><p>有了分区表，把整个数据打散成很多数据分片以后，我们接下来要做的一件事就是把这些数据分片均匀的分布到整个后台的分布式集群里，这个过程我们称为<strong>自动负载均衡。</strong></p><p>负载均衡里有一点想特别强调一下，就是复制的方式。复制的方式有两种：一种方式叫逻辑复制，一种方式叫物理复制。</p><p>顾名思义，逻辑复制相当于把数据一行一行读出来再写，这叫逻辑复制。物理复制，就是直接拷贝最终的数据文件或者是数据块。物理复制的性能很好，但是实现难度却很高。按照以往经验来看，物理复制的性能可以做到逻辑复制的 5 到 10 倍。</p><p>在大部分的分布式存储系统里面，负载均衡都实现了自动化。但是目前绝大部分的分布式数据库的负载均衡都是人肉负载均衡</p><p>分布式数据库里的自动负载均衡实现难度很大。因为分布式数据库里面临的负载均衡本质上是一个多因子负载均衡的问题，它需要考虑两种负载，一种负载叫做计算负载，主要考虑的是 CPU 跟内存。另外一种负载叫存储负载，主要考虑的是磁盘的占用量。</p><p>当计算负载比较高的时候，存储负载可能是比较低的。相反，当存储负载比较高的时候，计算负载又是比较低的。而且我们会发现计算存储的资源配比跟业务实际的计算存储负载是不一致的。同时，存储的迁移耗时很长。</p><p><strong>分区容错</strong></p><p>当我们有了分区表，假设已经把负载自动均衡到所有的机器后，下面我们要考虑的就是如何做容错的问题。容错分为两种情况，一种是分区自身发生的故障如何容错，还有一种情况是外部的用户请求如何动态的处理故障。</p><p><strong>主备切换不杀事务</strong></p><p>当发生主备切换的时候，需要做到新的事务在新的分区里开启，老的事务还需要动态地由原来的主分区一行一行迁移到新的主分区，整个过程需要做到事务的在线迁移。大家可以想象这是一个分布式场景的并发处理问题，它的难点在于怎么做多机的并发问题以及如何做异常的处理。</p><p><strong>分区分裂不杀事务</strong></p><p>分区分裂是我们内部的一个操作，这样的一个操作是不能杀事务的。如果杀事务用户就会感知到，感知到后台做了一些操作。而且数据库的事务可能是一个执行非常长的一个事务，有的甚至执行一到两天。我们需要做到新的事务在新的分区里执行，老的事务还能动态的一行一行迁移到新的分区里，整个过程需要做到对用户透明，这是其中最大的难点。</p><p><strong>全链路请求容错</strong></p><p>全链路的请求容错，难点在于请求涉及的环节特别多。从应用过来一个请求，首先会到一个叫 Proxy 的代理服务器，Proxy 再请求后端的分布式数据库的集群，整个过程是一台机器请求另外一台机器，一台机器再请求另外一台机器，任何一个过程都可能会发生故障。</p><p>在发生故障的时候都需要做到读写请求的重试，但是重试其实是一个很危险的操作。AWS 之前曾经因为重试产生了重试风暴导致大面积的故障。重试可能会产生连锁反应。原来用户发了一个请求，最后重试变成了一百个请求，整个系统就崩溃了，而且永远不可恢复，只能把用户的请求停掉，最后才能恢复。</p><p>重试也要做的，但是我们追求一点，就是需要做到任务级的重试。一个请求可能涉及的数据量很大，这个过程中会处理很多的数据分片，某一个数据分片出现故障的时候只重试这一个数据分片。整个请求的链路涉及到 Proxy 到数据库，当 Proxy 跟数据库做动态调整或者在线升级的时候，我们需要做到将它上面正在进行的请求动态的迁移到其他还能够工作的机器上。这是这件事情的难点，它需要做动态，但不能杀事务。</p><p>异常处理也有一个比较大的难点——是半死不活。当请求一个磁盘，它一会好一会不好，网络时好时坏。如何处理这种半死不活的状况。这个情况在大规模系统里面叫 hung 住。hung 住比失败要可怕得多。</p><p><strong>企业级查询优化器</strong></p><p>企业级数据库里有一个很重要的功能叫优化器。优化器在企业级数据库里面都是基于代价来实现的。因为优化器带来的问题特别多，我这里面只提两个问题。</p><p>第一个是大小账号的问题，很多人在互联网公司都经历过，比如一张表格有很多的用户，有的用户数据量很大，有的数据量很小。假设一个企业级数据库，同样一条 SQL 进来的时候，能够动态的判断请求的用户是哪个，并且可以根据统计信息来选择执行计划。如果请求的是大账号，就选择一个全表扫描的执行计划，如果小账号选择一个索引回表的执行计划来达到最优。</p><p>数据库后台调整的时候，特别让人害怕的一点就是数据库后台调整以后执行计划变了，使得原来执行很快的执行计划变得很慢，这个时候该怎么办呢？在企业级数据库里，有执行计划演进这样的一个功能。</p><p>当有调整的时候也会生成新的执行计划，但是新的执行计划并不会立刻生效，而是把流量一点一点从老的执行计划切到新的执行计划，等到最终内部验证了整个新的执行计划的性能没有回退以后，我们再用新的执行计划完全替代老的执行计划。这是企业级数据库里面优化器的一些基本的功能。</p><p>分布式数据库相比企业级数据库又多了一个问题，主要是并行优化的问题。假设一个单机数据库，以 Oracle 为例，优化器的实现会把整个优化分成两个阶段，第一个阶段叫串行优化，不会考虑一些分布式的问题，也不会考虑网络开销的问题。第二个阶段它会对第一个阶段串行优化结果里部分的算子做局部的并行化。所以大家可以想象，分成了这两个阶段以后，它的搜索空间并不是那么的全面，有一些应该搜索的这样的一些执行计划就被忽略掉了。</p><p>但是如果是一个分布式数据库，我们一开始就应该考虑并行优化器，一开始就应该考虑所有的单机的开销以及分布式的开销，直接搜索全部的空间，然后生成一个涉及全部开销的并行执行计划，最终才可能达到一个最优。</p><h2 id="OceanBase-的业务实践"><a href="#OceanBase-的业务实践" class="headerlink" title="OceanBase 的业务实践"></a>OceanBase 的业务实践</h2><p>OceanBase 是一个工业级的 share-nothing 透明可扩展的分布式架构，可以无限扩展。</p><p>OceanBase 可以给用户提供全局一致的数据库视图，并且能够支持跨服务器任意的复杂查询。</p><p>ceanBase 对 MySQL 全兼容，还支持部分 Oracle 版本的兼容。</p><ul><li><strong>交易支付透明拆分</strong></li></ul><p>原来交易支付是按照 UserID 拆分成 N 份的，后来发现容量不够，要拆分成 M*N 份。以前做拆分都是中间件跟业务一起来改造，每一次拆分都需要技术部门几百人的开发花费一年的时候来完成改造。导致一方面耗时耗力，另外一方面技术风险非常高。</p><p><strong>OceanBase 的解决方案：</strong></p><p>OceanBase 解决的方案就是使用 OceanBase 分区表实现透明拆分。通过 OceanBase 分区表在数据库底层实现拆分，业务完全没有感知，也基本上不需要任何的改造。</p><ul><li><strong>会员系统全局索引</strong></li></ul><p>公司的核心系统，它存储了用户的重要信息。一个用户的信息是多维度的，除了根据 userID 还可能根据用户名，邮箱手机号码等进行查询。</p><p>本质上就是全局索引的需求，但是我们都知道分库分表的方案是不支持全局索引的，带来的问题就是单机数据库只能垂直扩展，没有办法做到水平扩展。</p><p><strong>OceanBase 的解决方案：</strong></p><p>OceanBase 的解决方案就是 OceanBase 分区表 + 强一致的全局索引，通过这样的方案在数据库底层实现可扩展，而且对用户透明。</p><ul><li><strong>结算系统小机下移</strong></li></ul><p>外部业务相比蚂蚁的业务对透明可扩展的要求更高，在蚂蚁内部我们有非常强大的 DBA ，有很强大的开发能力可以改造，但是在外部客户基本上是不能改造的。某金融机构有大量批处理场景，有多张大表关联的复杂计算，并且涉及到大量的数据更新。批处理意味着每一次处理的数据量很大，而且有很多张大表要做关联，经常要做一些比较复杂的查询，并且更新量也比较大。业务的痛点在于传统的集中式数据库，单点出现了瓶颈，并且小型机的成本很高。如果扩容只能扩容成大型机，成本就变得不可接受。</p><p><strong>OceanBase 的解决方案：</strong></p><p>OceanBase 的解决方案就是透明可扩展的 OceanBase，通过 OceanBase 的 HTAP 场景的并行处理能力，使得处理时间相比现有的时间缩短了一半，并且 TCO 得到了大幅度的降低。通过 OceanBase 迁移服务（又名 OMS）进行平滑迁移实现了可灰度可回滚。过去金融行业进行业务迁移都是停机迁移，OceanBase 做到了在线迁移并且可灰度可回滚在金融行业是一件非常了不起的事情。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/70676722" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/70676722</a></p>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CAP和BASE理论</title>
      <link href="/2021/06/23/cap-he-base-li-lun/"/>
      <url>/2021/06/23/cap-he-base-li-lun/</url>
      
        <content type="html"><![CDATA[<h2 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h2><p>一个分布式系统不可能同时满足一致性（C:Consistency)，可用性（A: Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的2个。</p><p><strong>一致性</strong>，指数据在多个副本之间能够保持一致的特性（严格的一致性）。</p><p><strong>可用性</strong>，指系统提供的服务必须一直处于可用的状态，每次请求总能在<strong>有限时间内返回结果</strong>。</p><p><strong>分区容错性</strong>，分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。</p><h3 id="为什么只能3选2"><a href="#为什么只能3选2" class="headerlink" title="为什么只能3选2"></a>为什么只能3选2</h3><p>整个系统由两个节点配合组成，之间通过网络通信，当节点 A 进行更新数据库操作的时候，需要同时更新节点 B 的数据库（这是一个原子的操作）。</p><p>当节点 A,B 出现了网络分区，</p><ul><li>当节点A更新的时候，节点B也要更新</li><li>必须保证两个节点都是可用的。</li></ul><p>显然无法满足，A节点无法连上B节点。如果一定要满足一致性，就必须放弃可用性，等待网络恢复。</p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>放弃P：将所有数据放到一个分布式节点上，放弃P，也放弃了系统的扩展性</p><p>放弃A：收到影响的服务需要等待一定时间，在此期间服务不可用</p><p>放弃C：放弃数据的强一致性，保留最终一致性。虽然无法保证实时的一致性，但是数据最终会达到一个一致的状态。</p><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><p><strong>BASE：</strong>全称：Basically Available(基本可用)，Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的缩写</p><p><strong>核心思想：</strong>即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</p><h3 id="基本可用"><a href="#基本可用" class="headerlink" title="基本可用"></a>基本可用</h3><p>出现了不可预知的故障，损失部分可用性，如：</p><ul><li>响应时间上的损失：正常情况下的搜索引擎 0.5 秒即返回给用户结果，出现故障后，查询结果响应时间增加到了1-2秒。</li><li>功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单，但是到了大促期间，为了保护购物系统的稳定性，</li></ul><h3 id="软状态"><a href="#软状态" class="headerlink" title="软状态"></a>软状态</h3><p>软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本之间数据同步存在一定延时。</p><h3 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h3><p>系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问最终都能够获取到最新的值。</p><p><strong>最终一致性分为 5 种：</strong></p><p><strong>1. 因果一致性（Causal consistency）</strong></p><p>如果进程 A 在更新完某个数据后通知了进程 B，那么进程B 之后对该数据的访问和修改都是基于 A 更新后的值。于此同时，和进程A 无因果关系的进程C 的数据访问则没有这样的限制。</p><p><strong>2. 读己之所写（Read your writes）</strong></p><p>这种就很简单了，进程A 更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。</p><p><strong>3. 会话一致性（Session consistency）</strong></p><p>会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</p><p><strong>4. 单调读一致性（Monotonic read consistency）</strong></p><p>单调读一致性是指如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。</p><p><strong>5. 单调写一致性（Monotonic write consistency）</strong></p><p>指一个系统要能够保证来自同一个节点的写操作被顺序的执行。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>BASE 理论面向的是大型高可用可扩展的分布式系统，和传统事务的 ACID 是<strong>相反的</strong>，它完全不同于 ACID 的强一致性模型，而是<strong>通过牺牲强一致性</strong>来获得可用性，并允许数据在一段时间是不一致的。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构必知必会</title>
      <link href="/2021/06/09/interview-structure/"/>
      <url>/2021/06/09/interview-structure/</url>
      
        <content type="html"><![CDATA[<h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><p><strong>主要作用</strong></p><p>加快查找速度。时间复杂度可以近似看成O（1）</p><p><strong>缺点</strong></p><p>1.<strong>当更多的数插入时，哈希表冲突的可能性就更大。</strong>对于冲突，哈希表通常有两种解决方案：第一种是线性探索，相当于在冲突的地方后建立一个单链表，这种情况下，插入和查找以及删除操作消耗的时间会达到O(n)，且该哈希表需要更多的空间进行储存。第二种方法是开放寻址，他不需要更多的空间，但是在最坏的情况下（例如所有输入数据都被map到了一个index上）的时间复杂度也会达到O(n)。</p><p>2.在决定建立哈希表之前，最好可以估计输入的数据的size。否则，<strong>resize哈希表的过程将会是一个非常消耗时间的过程。</strong>例如，如果现在你的哈希表的长度是100，但是现在有第101个数要插入。这时，不仅哈希表的长度可能要扩展到150，且扩展之后所有的数都需要重新rehash。</p><p>3.<strong>哈希表中的元素是没有被排序的。</strong></p><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><h3 id="二叉查找树（BST）"><a href="#二叉查找树（BST）" class="headerlink" title="二叉查找树（BST）"></a>二叉查找树（BST）</h3><ul><li>若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</li><li>若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</li><li>任意节点的左、右子树也分别为二叉查找树。</li><li>没有键值相等的节点（no duplicate nodes）</li></ul><p><strong>缺点</strong></p><p>二叉查找树近似退化为一条链表，这样的二叉查找树的查找时间复杂度顿时变成了<code>O(n)</code></p><h3 id="平衡二叉树（AVL）"><a href="#平衡二叉树（AVL）" class="headerlink" title="平衡二叉树（AVL）"></a><strong>平衡二叉树</strong>（AVL）</h3><p>解决二叉查找树退化成链表。</p><p>平衡树具有如下特点：</p><p>1、具有二叉查找树的全部特性。</p><p>2、每个节点的左子树和右子树的高度差&lt;=1。</p><h4 id="怎么插入节点？"><a href="#怎么插入节点？" class="headerlink" title="怎么插入节点？"></a>怎么插入节点？</h4><p>比较大小，定位到叶子节点，根据大小插入到叶子节点的左子节点或者右子节点。</p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>因为平衡树要求<strong>每个节点的左子树和右子树的高度差至多等于1</strong>，为了维护绝对平衡，几乎每次插入删除都要进行旋转操作；删除节点的时候，需要维护从被删除节点到根节点这几个节点的平衡，旋转的时间复杂度是O（logn）。</p><h3 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a><strong>红黑树</strong></h3><p>解决平衡二叉树插入、删除频繁的场景。</p><p>红黑树虽然本质上是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)</p><h4 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h4><p>红黑树是每个节点都<strong>带有颜色属性的二叉查找树</strong>，颜色或红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求：</p><p>1、节点是红色或黑色</p><p>2、根节点是黑色的</p><p>3、每个叶节点是黑色的，且为nil</p><p>4、每个红色节点的两个子节点都是黑色</p><p>5、从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点</p><h4 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h4><p>与平衡树不同的是，红黑树在插入、删除等操作，<strong>不会像平衡树那样，频繁着破坏红黑树的规则，所以不需要频繁着调整</strong>，这也是我们为什么大多数情况下使用红黑树的原因。</p><p>不过，如果你要说，单单在查找方面的效率的话，平衡树比红黑树快。</p><p>所以，我们也可以说，<strong>红黑树是一种不大严格的平衡树</strong>。也可以说是一个折中方案。</p><h4 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h4><ul><li>首先以二叉查找树的方法增加节点并标记它为红色。</li><li>设为红色节点后，可能会导致出现两个连续红色节点的冲突，可以通过中心着色和树旋转来调整。 下面要进行什么操作取决于其他临近节点的颜色。</li></ul><h4 id="维持平衡"><a href="#维持平衡" class="headerlink" title="维持平衡"></a>维持平衡</h4><p>当在对红黑树进行插入和删除等操作时，对树做了修改可能会破坏红黑树的性质。</p><p>为了继续保持红黑树的性质，可以通过对结点进行<strong>重新着色</strong>，以及对树进行相关的<strong>旋转操作</strong>，即通过修改树中某些结点的颜色及指针结构，来达到对红黑树进行插入或删除结点等操作后继续保持它的性质或平衡的目的</p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>适合排序，查找的场景。</p><ul><li>容器的基本组成，如Java中的HashMap/TreeMap</li><li>Linux内核的完全公平调度器（CFS）：CFS 背后的主要想法是维护为任务提供处理器时间方面的平衡。任务存储在<strong>以时间为顺序的</strong>红黑树中（由 <code>sched_entity</code> 对象表示），对处理器需求最多的任务 （最低虚拟执行时vruntime）存储在树的左側，处理器需求最少的任务（最高虚拟执行时）存储在树的右側。 为了公平。调度器然后选取红黑树最左端的节点调度为下一个以便<strong>保持公平性。</strong></li><li>Linux中epoll机制的实现：epoll 通过 socket 句柄来作为 key，把 socket 保存在红黑树中。如 图2 所示，每个节点中的数字代表着 socket 句柄。把监听的 socket 保存在红黑树中的目的是，为了在修改监听 socket 的读写事件时，能够通过 socket 句柄快速找到对应的 socket 对象。</li><li>内存管理与红黑树：Linux内存管理模块使用红黑树来提升虚拟内存的查找速度。<code>vm_area_struct</code>是描述进程地址空间的基本管理单元，一个进程往往需要多个<code>vm_area_struct</code>来描述它的用户空间虚拟地址，需要使用「链表」和「红黑树」来组织各个<code>vm_area_struct</code>。</li></ul><h4 id="为什么平衡性好"><a href="#为什么平衡性好" class="headerlink" title="为什么平衡性好"></a>为什么平衡性好</h4><p>首先红黑树是不符合AVL树的平衡条件的，即每个节点的左子树和右子树的高度最多差1的二叉查找树。但是提出了为节点增加颜色，红黑是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决，而AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高！</p><h4 id="红黑树和哈希表比较"><a href="#红黑树和哈希表比较" class="headerlink" title="红黑树和哈希表比较"></a>红黑树和哈希表比较</h4><ol><li>红黑树是有序的，Hash是无序的</li><li><strong>时间复杂度上</strong>，红黑树的插入、删除、查找性能都是<code>O(logN)</code>而哈希表的插入、删除、查找性能理论上都是<code>O(1)</code>，他是相对于稳定的，最差情况下都是高效的。哈希表的插入删除操作的理论上时间复杂度是常数时间的，这有个前提就是哈希表不发生数据碰撞。<strong>在发生碰撞的最坏的情况下，哈希表的插入和删除时间复杂度最坏能达到<code>O(n)</code>。</strong></li><li>红黑树占用的内存更小（仅需要为其存在的节点分配内存），而Hash事先应该分配足够的内存存储散列表,即使有些槽可能弃用</li></ol><h3 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h3><p>又叫字典树、前缀树（Prefix Tree）、单词查找树 或 键树，是一种多叉树结构。</p><h4 id="基本性质"><a href="#基本性质" class="headerlink" title="基本性质"></a>基本性质</h4><ul><li>根节点不包含字符，除根节点外的每一个子节点都包含一个字符。</li><li>从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。</li><li>每个节点的所有子节点包含的字符互不相同。</li></ul><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p><strong>优点</strong></p><ul><li>插入和查询的效率很高，都为O(m)，其中 m 是待插入/查询的字符串的长度。</li><li>Trie树不用求 hash 值，对短字符串有更快的速度。通常，求hash值也是需要遍历字符串的。</li><li>Trie树可以对关键字按字典序排序。</li></ul><p><strong>缺点</strong></p><ul><li>空间消耗比较大。</li></ul><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>字符串检索、词频统计、字符串排序、前缀匹配</p><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><ul><li><p>跳表是可以实现二分查找的有序链表；</p></li><li><p>每个元素插入时随机生成它的level；</p></li><li><p>最底层包含所有的元素；</p></li><li><p>如果一个元素出现在level(x)，那么它肯定出现在x以下的level中；</p></li><li><p>每个索引节点包含两个指针，一个向下，一个向右；（笔记目前看过的各种跳表源码实现包括Redis 的zset 都没有向下的指针，那怎么从二级索引跳到一级索引呢？留个悬念，看源码吧，文末有跳表实现源码）</p></li><li><p>跳表查询、插入、删除的时间复杂度为O(log n)，与平衡二叉树接近；</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多阶段构建</title>
      <link href="/2021/06/07/docker-multistage/"/>
      <url>/2021/06/07/docker-multistage/</url>
      
        <content type="html"><![CDATA[<h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>　在构建镜像过程中，我们可能只需要某些镜像的产物，比如在运行一个go程序需要先go程序包编译后才运行，如果在一个镜像里面完成，先要经过安装编译环境，程序编译完再安装运行环境，最后运行程序，这样的镜像体积往往比较大，不利于我们使用。而真正我们需要的镜像是只有程序包和运行环境，编译环境的构建在运行容器时候是不需要的，所以Docker提供了一种解决方案就是multi-stage（多阶段构建）。</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>Docker允许多个镜像的构建可以使用同一个Dockerfile，每个镜像构建过程可以称之为一个stage，简单理解就是一个FROM指令到下一个FROM指令，而每个stage可使用上一个stage过程的产物或环境（其实还支持其他镜像的），这样一来，最终所得镜像体积相对较小。</p><p>不仅如此多阶段构建同样可以很方便地将多个彼此依赖的项目通过一个Dockerfile就可轻松构建出期望的容器镜像，而不用担心镜像太大、项目环境依赖等问题。</p><p>通过上述介绍，我们可以在第一个stage将go程序编译得到编译后程序包，然后在第二个stage中直接拷贝编译好的go程序包到运行环境中，最后的镜像中就只有程序包和运行环境。以下作为示例：</p><pre><code>FROM golang:1.7.3WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/html  COPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latest  RUN apk --no-cache add ca-certificatesWORKDIR /root/# ！！！COPY --from=0 /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;]</code></pre><p>在以上Dockerfile中存在两个FROM指令，也就是两个stage，第一个stage用于构建产物，而在第二个stage中使用COPY –from=0 意思将第一个stage中的/go/src/github.com/alexellis/href-counter/app拷贝到.目录，第二个stage仅仅相当于执行copy就有了构建产物，不用在安装编译环境，镜像会很缩小。 </p><h3 id="命名stage"><a href="#命名stage" class="headerlink" title="命名stage"></a>命名stage</h3><p>默认情况下，stage未命名，可以通过整数来引用它们，第一个stage表示0，第二个表1以此类推。 但是，当有多个stage时候，这样会显得麻烦，Docker提供AS 语法可以为stage命名：</p><pre><code>FROM golang:1.7.3 as builder</code></pre><p>然后在另一个stage中使用：</p><pre><code>COPY --from=builder /go/src/github.com/alexellis/href-counter/app .</code></pre><h2 id="构建镜像建议"><a href="#构建镜像建议" class="headerlink" title="构建镜像建议"></a>构建镜像建议</h2><ol><li>基础镜像尽量选择比体积较小的镜像，如每个官方发行的alpine镜像。虽然这版本镜像比较小，但是与之带来的是利用该类镜像运行的容器中排错的命令很少;</li><li>使用RUN指令时候，尽量把多个RUN指令合并为一个，通常做法是使用&amp;&amp;符号;</li><li>通过multi-stage方法减少一些不必要使用的环境来减小镜像;</li><li>安装完成软件同时删除一些不需要的文件或目录； </li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/wdliu/p/10469257.html" target="_blank" rel="noopener">https://www.cnblogs.com/wdliu/p/10469257.html</a></p>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3. 无重复字符的最长子串</title>
      <link href="/2021/06/05/3-wu-chong-fu-zi-fu-de-zui-chang-zi-chuan/"/>
      <url>/2021/06/05/3-wu-chong-fu-zi-fu-de-zui-chang-zi-chuan/</url>
      
        <content type="html"><![CDATA[<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>给定一个字符串，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><p> <strong>示例 1:</strong></p><pre><code>输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。</code></pre><pre><code>输入: s = &quot;&quot;输出: 0</code></pre><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/</a></p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>使用集合保存已经遍历的字符。</p><p>从头开始遍历，遇上遍历过的（判断是否存在于集合中），先计算子串长度并更新最长子串，然后从集合中移除相关元素，同时更新字符串的起始位移和当前字符串的长度。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">lengthOfLongestSubstring</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: int        """</span>        strs <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>        count <span class="token operator">=</span> <span class="token number">0</span>        left <span class="token operator">=</span> <span class="token number">0</span>        maxcount <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">not</span> <span class="token keyword">in</span> strs<span class="token punctuation">:</span>                strs<span class="token punctuation">.</span>add<span class="token punctuation">(</span>s<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                count <span class="token operator">=</span> count <span class="token operator">+</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                maxcount <span class="token operator">=</span> max<span class="token punctuation">(</span>maxcount<span class="token punctuation">,</span> count<span class="token punctuation">)</span>                <span class="token keyword">while</span> s<span class="token punctuation">[</span>left<span class="token punctuation">]</span> <span class="token operator">!=</span> s<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>                    strs<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>s<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span>                    left <span class="token operator">+=</span> <span class="token number">1</span>                    count <span class="token operator">=</span> count <span class="token operator">-</span><span class="token number">1</span>                left <span class="token operator">=</span> left <span class="token operator">+</span> <span class="token number">1</span>        maxcount <span class="token operator">=</span> max<span class="token punctuation">(</span>maxcount<span class="token punctuation">,</span> count<span class="token punctuation">)</span>        <span class="token keyword">return</span> maxcount<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>53最大自序和</title>
      <link href="/2021/06/05/53-zui-da-zi-xu-he/"/>
      <url>/2021/06/05/53-zui-da-zi-xu-he/</url>
      
        <content type="html"><![CDATA[<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>给定一个整数数组 <code>nums</code> ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p><p><strong>示例 1：</strong></p><pre><code>输入：nums = [-2,1,-3,4,-1,2,1,-5,4]输出：6解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：nums = [1]输出：1</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：nums = [0]输出：0</code></pre><p><strong>示例 4：</strong></p><pre><code>输入：nums = [-1]输出：-1</code></pre><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="https://leetcode-cn.com/problems/maximum-subarray/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/maximum-subarray/</a></p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>直接的思路是动态： $f(i)$ 代表以第$$i$$个数结尾的「连续子数组的最大和」</p><p>$$<br>f(i)=max\{f(i−1)+nums[i],nums[i]\}<br>$$</p><p>这个需要空间复杂度$O(n)$</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">maxSubArray</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :rtype: int        """</span>        dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        max_v <span class="token operator">=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        dp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> max<span class="token punctuation">(</span>dp<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token operator">+</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">></span> max_v<span class="token punctuation">:</span>                max_v <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> max_v<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>改进方法：依据动态的思想：每个数字遍历的时候，当前结尾的sum值依据前一个值是否大于0，然后更新最大值。初始最大sum为num第0个元素。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">maxSubArray</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :rtype: int        """</span>        max_sum <span class="token operator">=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        cur_sum <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> num <span class="token keyword">in</span> nums<span class="token punctuation">:</span>            <span class="token keyword">if</span> cur_sum <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>                cur_sum <span class="token operator">+=</span> num            <span class="token keyword">else</span><span class="token punctuation">:</span>                cur_sum <span class="token operator">=</span> num            max_sum <span class="token operator">=</span> max<span class="token punctuation">(</span>cur_sum<span class="token punctuation">,</span> max_sum<span class="token punctuation">)</span>        <span class="token keyword">return</span> max_sum<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>215数组中的第K个最大元素</title>
      <link href="/2021/06/05/215-shu-zu-zhong-de-di-k-ge-zui-da-yuan-su/"/>
      <url>/2021/06/05/215-shu-zu-zhong-de-di-k-ge-zui-da-yuan-su/</url>
      
        <content type="html"><![CDATA[<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。</p><p><strong>示例 1:</strong></p><pre><code>输入: [3,2,1,5,6,4] 和 k = 2输出: 5</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: [3,2,3,1,2,4,5,5,6] 和 k = 4输出: 4</code></pre><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array" target="_blank" rel="noopener">https://leetcode-cn.com/problems/kth-largest-element-in-an-array</a></p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>使用类似快排的思想：</p><p>1、随机选择一个数字后，分解成排序的2部分，返回随机数所在位置</p><p>2、根据随机数所在位置，循环分区，直到成功获取。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> random<span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findKthLargest</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type k: int        :rtype: int        """</span>        left <span class="token operator">=</span> <span class="token number">0</span>        right <span class="token operator">=</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token number">1</span>         k <span class="token operator">=</span> k<span class="token number">-1</span>        pos <span class="token operator">=</span> self<span class="token punctuation">.</span>partion<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> k<span class="token punctuation">,</span> left<span class="token punctuation">,</span> right<span class="token punctuation">)</span>        <span class="token keyword">while</span> pos <span class="token operator">!=</span> k<span class="token punctuation">:</span>            <span class="token keyword">if</span> pos <span class="token operator">></span> k<span class="token punctuation">:</span>                right <span class="token operator">=</span> pos                pos <span class="token operator">=</span> self<span class="token punctuation">.</span>partion<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> k<span class="token punctuation">,</span> left<span class="token punctuation">,</span> right<span class="token number">-1</span><span class="token punctuation">)</span>            <span class="token keyword">elif</span> pos <span class="token operator">&lt;</span> k<span class="token punctuation">:</span>                left <span class="token operator">=</span> pos                pos <span class="token operator">=</span> self<span class="token punctuation">.</span>partion<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> k<span class="token operator">-</span><span class="token punctuation">(</span>left<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> left<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> right<span class="token punctuation">)</span>        <span class="token keyword">return</span> nums<span class="token punctuation">[</span>k<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">partion</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> a<span class="token punctuation">,</span> k<span class="token punctuation">,</span> left<span class="token punctuation">,</span> right<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        降序排列        """</span>        pos <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>left<span class="token punctuation">,</span> right<span class="token punctuation">)</span>         a<span class="token punctuation">[</span>pos<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>right<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>pos<span class="token punctuation">]</span>        i<span class="token punctuation">,</span> j <span class="token operator">=</span> left<span class="token punctuation">,</span> left        <span class="token keyword">while</span> j <span class="token operator">&lt;</span> right<span class="token punctuation">:</span>            <span class="token keyword">if</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">>=</span> a<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span>                a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span>                i <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>            j <span class="token operator">=</span> j <span class="token operator">+</span> <span class="token number">1</span>        a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>right<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> i<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>121买卖股票最佳时机</title>
      <link href="/2021/06/03/121-mai-mai-gu-piao-zui-jia-shi-ji/"/>
      <url>/2021/06/03/121-mai-mai-gu-piao-zui-jia-shi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。</p><p>你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。</p><p>返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。</p><p><strong>示例 1：</strong></p><pre><code>输入：[7,1,5,3,6,4]输出：5</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：prices = [7,6,4,3,1]输出：0</code></pre><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>每天遍历过去的时候，如果发现是最低的，那就假设当天买进，一般情况下，每天都计算按照之前最低买进的计算最大利润。</p><p>复杂度<code>O(n)</code></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">maxProfit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prices<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type prices: List[int]        :rtype: int        """</span>        min_p <span class="token operator">=</span> prices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        max_pro <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> p <span class="token keyword">in</span> prices<span class="token punctuation">:</span>            <span class="token keyword">if</span> p <span class="token operator">&lt;</span> min_p<span class="token punctuation">:</span>                min_p <span class="token operator">=</span> p            <span class="token keyword">elif</span> p <span class="token operator">-</span> min_p <span class="token operator">></span> max_pro<span class="token punctuation">:</span>                max_pro <span class="token operator">=</span> p <span class="token operator">-</span> min_p        <span class="token keyword">return</span> max_pro<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最长公共子序列</title>
      <link href="/2021/05/31/zui-chang-gong-gong-zi-xu-lie/"/>
      <url>/2021/05/31/zui-chang-gong-gong-zi-xu-lie/</url>
      
        <content type="html"><![CDATA[<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>给定两个字符串str1和str2，输出两个字符串的最长公共子序列。如果最长公共子序列为空，则返回”-1”。目前给出的数据，仅仅会存在一个最长的公共子序列</p><h2 id="示例1"><a href="#示例1" class="headerlink" title="示例1"></a>示例1</h2><p>输入：</p><pre><code>&quot;1A2C3D4B56&quot;,&quot;B1D23A456A&quot;</code></pre><p>返回值：</p><pre><code>&quot;123456&quot;</code></pre><h2 id="示例2"><a href="#示例2" class="headerlink" title="示例2"></a>示例2</h2><p>输入：</p><pre><code>&quot;abc&quot;,&quot;def&quot;</code></pre><p>返回值：</p><pre><code>&quot;-1&quot;</code></pre><h2 id="示例3"><a href="#示例3" class="headerlink" title="示例3"></a>示例3</h2><p>输入：</p><pre><code>&quot;abc&quot;,&quot;abc&quot;</code></pre><p>返回值：</p><pre><code>&quot;abc&quot;</code></pre><h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><p>如果单纯求长度就行，难点在于找到递推公式：</p><p><code>dp[i][j]</code>表示<code>s1[i]</code>和<code>s2[j]</code>中的最长子串长度，显然如果<code>s1[i]==s2[j]</code>，则有，<code>dp[i][j] = dp[i-1][j-1] + 1</code></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">LCS</span><span class="token punctuation">(</span>self <span class="token punctuation">,</span> s1 <span class="token punctuation">,</span> s2 <span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># write code here</span>        len1<span class="token punctuation">,</span> len2 <span class="token operator">=</span> len<span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>s2<span class="token punctuation">)</span>        dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len2<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len1<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len1<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len2<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> s1<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">==</span> s2<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token punctuation">:</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token comment" spellcheck="true"># pay attention!!!</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> max<span class="token punctuation">(</span>dp<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> dp<span class="token punctuation">[</span>len1<span class="token punctuation">]</span><span class="token punctuation">[</span>len2<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果需要返回最长子序列，建议画个dp图，找规律：</p><p>1、需要从右下往左上走</p><p>2、对于<code>dp[i][j]=k</code> ，必须要找到满足：<code>dp[i-1][j]&lt;k</code>和<code>dp[i][j-1]&lt;k</code></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">LCS</span><span class="token punctuation">(</span>self <span class="token punctuation">,</span> s1 <span class="token punctuation">,</span> s2 <span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># write code here</span>        len1<span class="token punctuation">,</span> len2 <span class="token operator">=</span> len<span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>s2<span class="token punctuation">)</span>        dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len2<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len1<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len1<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len2<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> s1<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">==</span> s2<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token punctuation">:</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token comment" spellcheck="true"># pay attention!!!</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> max<span class="token punctuation">(</span>dp<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        maxlen <span class="token operator">=</span> dp<span class="token punctuation">[</span>len1<span class="token punctuation">]</span><span class="token punctuation">[</span>len2<span class="token punctuation">]</span>        <span class="token keyword">if</span> maxlen <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>        count <span class="token operator">=</span> maxlen        _str <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        i<span class="token punctuation">,</span>j <span class="token operator">=</span> len1<span class="token punctuation">,</span> len2        <span class="token keyword">while</span> i<span class="token operator">>=</span><span class="token number">1</span> <span class="token operator">and</span> j<span class="token operator">>=</span><span class="token number">1</span> <span class="token operator">and</span> count<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">while</span>  j<span class="token operator">></span><span class="token number">0</span> <span class="token operator">and</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> count<span class="token punctuation">:</span>                j <span class="token operator">-=</span> <span class="token number">1</span>            <span class="token keyword">while</span> i<span class="token operator">></span><span class="token number">0</span> <span class="token operator">and</span> dp<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">>=</span> count<span class="token punctuation">:</span>                i <span class="token operator">-=</span> <span class="token number">1</span>            _str<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s1<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            j <span class="token operator">-=</span> <span class="token number">1</span>            i <span class="token operator">-=</span> <span class="token number">1</span>            count <span class="token operator">-=</span> <span class="token number">1</span>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>_str<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://leetcode-cn.com/problems/longest-common-subsequence" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-common-subsequence</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最长公共子串</title>
      <link href="/2021/05/30/zui-chang-gong-gong-zi-chuan/"/>
      <url>/2021/05/30/zui-chang-gong-gong-zi-chuan/</url>
      
        <content type="html"><![CDATA[<p>思路：动态规划。</p><p><code>dp[i][j]</code>标识str1[i]和str[j]结尾的最长公共子串，递推关系如下：</p><ul><li>若<code>str1[i] == str2[j]</code>，则<code>dp[i][j] = dp[i-1][j-1] + 1</code></li><li>否则，<code>dp[i][j] = 0</code></li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">LCS</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>str1 <span class="token punctuation">,</span> str2 <span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># write code here</span>        len1<span class="token punctuation">,</span> len2<span class="token operator">=</span> len<span class="token punctuation">(</span>str1<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>str2<span class="token punctuation">)</span>        dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len2<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len1<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len1<span class="token punctuation">)</span><span class="token punctuation">:</span>            dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">if</span> str1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> str2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>len2<span class="token punctuation">)</span><span class="token punctuation">:</span>            dp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">if</span> str1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> str2<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span>        maxlen <span class="token operator">=</span> <span class="token number">0</span>        pos <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>len1<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len2<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> str1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> str2<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>                    <span class="token keyword">if</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> maxlen<span class="token punctuation">:</span>                        maxlen <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span>                        pos <span class="token operator">=</span> i                <span class="token keyword">else</span><span class="token punctuation">:</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">return</span> str1<span class="token punctuation">[</span>pos<span class="token operator">-</span>maxlen<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span>pos<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>场景头脑风暴</title>
      <link href="/2021/05/24/interview-changjin/"/>
      <url>/2021/05/24/interview-changjin/</url>
      
        <content type="html"><![CDATA[<h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>一个很长的二进制向量 （位数组）、一系列随机函数 (哈希)、空间效率和查询效率高，但是有一定的误判率（哈希表是精确匹配）</p><p><strong>基本原理</strong></p><p>首先将位数组进行初始化，将里面每个位都设置位0。对于集合里面的每一个元素，将元素依次通过3个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。查询W元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。反之，如果3个点都为1，则该元素可能存在集合中。</p><p><strong>问题</strong></p><p>此处不能判断该元素是否一定存在集合中，可能存在一定的误判率。</p><p><strong>1、100G 的手机号文件，找到重复的手机号，将重复手机号放入另一个文件。PC 机内存1G</strong></p><p>按照手机前三位分成1000 个文件，然后hashmap 或者bitmap 进行重复校验</p><p><strong>2、1G大小的一个文件中找出出现频率最高的100个数</strong></p><p>（1）此处1G文件远远大于1M内存，分治法，先hash映射把大文件分成很多个小文件，具体操作如下：读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件(记为f0，f1，…，f4999)中，这样每个文件大概是200k左右（每个相同的词一定被映射到了同一文件中）<br>（2）对于每个文件fi，都用hash_map做词和出现频率的统计，取出频率大的前100个词（怎么取？topK问题，建立一个100个节点的最小堆），把这100个词和出现频率再单独存入一个文件<br>（3）根据上述处理，我们又得到了5000个文件，归并文件取出top100（Top K 问题，比较最大的前100个频数）</p><p><strong>3、海量日志数据，提取出某日访问百度次数最多的那个IP。</strong></p><p>分而治之+Hash<br>1.IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理；<br>2.可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址；<br>3.对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；<br>4.可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP</p><p><strong>4、统计最热门的10个查询串，要求使用的内存不能超过1G，搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。</strong></p><p>第一步、先对这批海量数据预处理，在O（N）的时间内用Hash表完成统计;<br>第二步、借助堆这个数据结构，找出Top K，时间复杂度为N’logK。<br>即，借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别 和根元素进行对比所以，我们最终的时间复杂度是：O（N） + N’*O（logK），（N为1000万，N’为300万）。</p><p><strong>5、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？</strong></p><p>2读1写：可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。</p><p>遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0，a1，…，a999）中。这样每个小文件的大约为300M。</p><p>遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0，b1，…，b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0，a1vsb1，…，a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的 url即可。</p><p>求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。</p><hr><p>优化：布隆过滤器</p><p>如果允许有一定的错误率，可以使用 Bloom filter，4G 内存大概可以表示 340 亿 bit。将其中一个文件中的 url 使用 Bloom filter 映射为这 340 亿 bit，然后挨个读取另外一个文件的 url，检查是否与 Bloom filter，如果是，那么该 url 应该是共同的 url（注意会有一定的错误率）</p><p><strong>6、2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。</strong></p><p>采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看 bitmap，把对应位是01的整数输出即可。</p><p><strong>7、给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？</strong></p><p>申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。</p><p><strong>8、大日志中获取到指定时间段的数据</strong></p><p>与传统的二分搜索不一样，日志文件中的每一条日志长度都是不一样的，我们使用<code>mid = start + (end - start) / 2</code>得到mid时，并不直接指向一行的行首。所以我们需要找到<code>mid</code>所在行的行首。</p><p><strong>9、海量数据如何排序</strong></p><p><strong>外部排序</strong></p><ul><li>海量数据拆分成多个文件</li><li>每个文件使用快速排序等方法做局部排序</li><li><strong>多路归并方法</strong>将所有拆分节点的部分排序结果整合成最终的排序结果</li></ul><p>如果不进行额外处理，<strong>合并节点仍然无法将所有数据读入内存中。可以使用小顶堆</strong>：</p><ul><li>从这 k 个文件分别读取一个最小的数据到小顶堆中。</li><li>将堆顶数据移出堆并写入合并节点的最终结果文件中。</li><li>确定刚才从堆中移除的数据属于哪个拆分节点，并从该拆分节点再读入一个数据。</li></ul><p><strong>优化</strong></p><p>每次读取一批数据，避免频繁读写磁盘</p><p><strong>BitMap</strong></p><p>待排序的数据是整数，或者其它范围比较小的数据时，可以使用 BitMap 对其进行排序。标记后，从头遍历比特数组就能得到一个排序的整数序列。</p><p>这种方法<strong>只能处理数据不重复的情况</strong>，如果数据重复，就要将<strong>比特数组转换成整数数组用于计数</strong></p><p><strong>10、100亿数据找中位数</strong></p><blockquote><p>（1）划分映射区域，一个有符号的32位整数的取值范围是[-2^31， 2^31-1]，总共有4294967296个取值，因此我们将它划分成100000组，即43000个数映射到一个组，将a1的区间[-2^31，-2^31+43000)，a2的区间[-2^31+43000，-2^31+86000)……一直到a100000的区间；（这是组数与项数的一个平衡问题）；</p><p>（2）区间统计计数；</p><p>（3）累加区间统计计数，计算50亿所在区间，前一个区间的累计数量;</p><p>（4）区间以单个映射计数，确定第50亿个数</p></blockquote><p>11、10000个IP，快速查找某IP是否存在，使用什么数据结构?</p><blockquote><p>使用BitMap，需要使用32位。</p></blockquote><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><h3 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a><strong>银行家算法</strong></h3><p>我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。<br>为保证资金的安全，银行家规定:</p><ul><li>当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客</li><li>顾客可以分期贷款，但贷款的总数不能超过最大需求量</li><li>当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款</li><li>当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金</li></ul><h3 id="哲学家吃饭问题怎么解决？"><a href="#哲学家吃饭问题怎么解决？" class="headerlink" title="哲学家吃饭问题怎么解决？"></a>哲学家吃饭问题怎么解决？</h3><blockquote><p>五个哲学家共用一张圆桌，分别坐在周围的五张椅子上，在桌子上有五只碗和五只筷子，他们的生活方式是交替地进行思考和进餐。平时，一个哲学家进行思考，饥饿时便试图取用其左右最靠近他的筷子，只有在他拿到两只筷子时才能进餐。进餐毕，放下筷子继续思考。</p></blockquote><p>可以用一个信号量表示筷子，由这<strong>五个信号量构成信号量数组</strong>。下面是死锁的解决：</p><p><strong>策略一</strong>：至多只允许四个哲学家同时进餐，以保证至少有一个哲学家能够进餐，最终总会释放出他所使用过的两支筷子，从而可使更多的哲学家进餐。定义信号量count，只允许4个哲学家同时进餐，这样就能保证至少有一个哲学家可以就餐。</p><p><strong>策略二</strong>：仅当哲学家的<strong>左右两支筷子都可用</strong>时，才允许他拿起筷子进餐。利用信号量的保护机制实现，思想是通过记录型信号量mutex对取左侧和右侧筷子的操作进行保护，使之成为一个原子操作，这样可以防止死锁的出现。</p><p><strong>策略三</strong>：规定奇数号的哲学家先拿起<strong>他左边</strong>的筷子，然后再去拿他右边的筷子；而偶数号的哲学家则先拿起<strong>他右边</strong>的筷子，然后再去拿他左边的筷子。</p><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><h3 id="单点登录"><a href="#单点登录" class="headerlink" title="单点登录"></a>单点登录</h3><p>单点登录就是<strong>在多个系统中，用户只需一次登录，各个系统即可感知该用户已经登录。</strong></p><p><strong>Session不共享问题</strong></p><blockquote><ul><li>SSO系统生成一个token，并将用户信息存到Redis中，并设置过期时间</li><li>其他系统请求SSO系统进行登录，得到SSO返回的token，写到Cookie中</li><li>每次请求时，Cookie都会带上，拦截器得到token，判断是否已经登录</li></ul></blockquote><p>针对Cookie存在<strong>跨域问题</strong>，有几种解决方案：</p><ol><li>服务端将Cookie写到客户端后，客户端对Cookie进行解析，将Token解析出来，此后请求都把这个Token带上就行了</li><li>多个域名共享Cookie，在写到客户端的时候设置Cookie的domain。</li><li>将Token保存在SessionStroage中（不依赖Cookie就没有跨域的问题了）</li></ol><p><strong>中心认证服务（Central Authentication Service）原理</strong></p><ul><li>用户想要访问系统A<code>www.java3y.com</code>受限的资源，系统A<code>www.java3y.com</code>发现用户并没有登录，于是<strong>重定向到sso认证中心，并将自己的地址作为参数</strong>。</li><li>sso认证中心发现用户未登录，将用户引导至登录页面，用户进行输入用户名和密码进行登录，用户与认证中心建立<strong>全局会话（生成一份Token，写到Cookie中，保存在浏览器上）</strong></li><li>认证中心<strong>重定向回系统A</strong>，并把Token携带过去给系统A</li><li>系统A去sso认证中心验证这个Token是否正确，如果正确，则系统A和用户建立局部会话（<strong>创建Session</strong>）。到此，系统A和用户已经是登录状态了。</li><li>此时，用户想要访问系统B<code>www.java4y.com</code>受限的资源，系统B<code>www.java4y.com</code>发现用户并没有登录，于是<strong>重定向到sso认证中心，并将自己的地址作为参数</strong>，这次系统B<strong>重定向</strong>到认证中心<code>www.sso.com</code>是可以带上Cookie的。</li><li>认证中心<strong>根据带过来的Cookie</strong>发现已经与用户建立了全局会话了，认证中心<strong>重定向回系统B</strong>，并把Token携带过去给系统B</li><li>系统B去sso认证中心验证这个Token是否正确，如果正确，则系统B和用户建立局部会话（<strong>创建Session</strong>）。到此，系统B和用户已经是登录状态了。</li></ul><h3 id="JWT"><a href="#JWT" class="headerlink" title="JWT"></a>JWT</h3><h4 id="令牌结构"><a href="#令牌结构" class="headerlink" title="令牌结构"></a><strong>令牌结构</strong></h4><p>由三部分组成，这些部分由点分隔</p><ul><li>Header：包括令牌的类型（即JWT）和所使用的签名算法（SHA256或者RSA）</li><li>Payload：有关实体（通常是用户）和其他数据的声明<ul><li>注册声明：提供一组有用的可互操作的权利要求。其中一些是： iss（JWT的签发者）， exp（expires，到期时间）， sub（主题）， aud（JWT接收者），iat（issued at，签发时间）等</li><li>公开声明：一般添加用户的相关信息或其他业务需要的必要信息。不建议添加敏感信息，因为该部分在客户端可解密。</li><li>私有声明：提供者和消费者所共同定义的声明，一般不建议存放敏感信息</li></ul></li><li>Signature：Signature生成需要base64编码之后的Header，base64编码之后的Payload，密钥（secret），Header需要指定签字的算法。</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>无法在使用过程中废止某个 token，或者更改 token 的权限。一旦 JWT 签发了，<strong>在到期之前就会始终有效</strong>。</li><li>JWT 本身包含了认证信息，<strong>一旦泄露，任何人都可以获得该令牌的所有权限</strong>。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。</li><li>为了减少盗用，<strong>JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输</strong>。</li></ul><h4 id="用户登出，如何设置token无效？"><a href="#用户登出，如何设置token无效？" class="headerlink" title="用户登出，如何设置token无效？"></a>用户登出，如何设置token无效？</h4><p>JWT是无状态的，用户登出设置token无效就已经违背了JWT的设计原则，但是在实际应用场景中，这种功能是需要的，那该如何实现呢？提供几种思路：</p><ul><li>用户登出，浏览器端丢弃token</li><li>使用redis数据库，用户登出，从redis中删除对应的token，请求访问时，需要从redis库中取出对应的token，若没有，则表明已经登出</li></ul><blockquote><p>为了保持数据的一致性，每一次认证都需要从redis中取出对应的token，每一次都以redis中的token为准。</p></blockquote><h4 id="使用redis，两个不同的设备，一个设备登出，另外一个设备如何处理？"><a href="#使用redis，两个不同的设备，一个设备登出，另外一个设备如何处理？" class="headerlink" title="使用redis，两个不同的设备，一个设备登出，另外一个设备如何处理？"></a>使用redis，两个不同的设备，一个设备登出，另外一个设备如何处理？</h4><p>每一个设备与用户生成唯一的key，保存在redis中，即设备1的用户登出，只删除对应的token，设备2的token仍然存在</p><h3 id="OAuth"><a href="#OAuth" class="headerlink" title="OAuth"></a>OAuth</h3><p>所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。</p><p><strong>OAuth 2.0 规定了四种获得令牌的流程。</strong></p><ul><li>授权码（authorization-code）</li></ul><p><strong>指的是第三方应用先申请一个授权码，然后再用该码获取令牌。</strong></p><blockquote><ol><li>A 网站让用户跳转到 GitHub。</li><li>GitHub 要求用户登录，然后询问”A 网站要求获得 xx 权限，你是否同意？”</li><li>用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。</li><li>A 网站使用授权码，向 GitHub 请求令牌。</li><li>GitHub 返回令牌.</li><li>A 网站使用令牌，向 GitHub 请求用户数据。</li></ol></blockquote><ul><li>隐藏式</li><li>密码式</li><li>客户端凭证</li></ul><h3 id="验证码登录"><a href="#验证码登录" class="headerlink" title="验证码登录"></a>验证码登录</h3><p>验证码是由服务端产生，以图片的形式展示在客户端或页面</p><p>用户端的用户根据图片识别验证码，并进行注册提交</p><p>提交的验证码在服务层进行校验，如果校验成功，则用户注册成功并登陆</p><h3 id="限流器"><a href="#限流器" class="headerlink" title="限流器"></a>限流器</h3><h4 id="令牌桶"><a href="#令牌桶" class="headerlink" title="令牌桶"></a>令牌桶</h4><p>假设允许的请求速率为<code>r</code>次每秒，那么每过<code>1/r</code>秒就会向桶里面添加一个令牌。桶的最大大小是<code>b</code>。当请求到来时，检查桶内令牌数是否足够，如果足够，令牌数减少，请求通过。不够的话就会触发拒绝策略。</p><p>如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。令牌桶在保持整体上的请求速率的同时，允许某种程度的突发传输。</p><ul><li>限制调用的平均速率的同时还允许一定程度的突发调用</li></ul><h4 id="漏斗桶"><a href="#漏斗桶" class="headerlink" title="漏斗桶"></a>漏斗桶</h4><p>漏斗桶控制请求必须在最大某个速率被消费，就像一个漏斗一样，入水量可大可小，但是最大速率只能到某一量值，不会像令牌桶一样，会有小的尖峰。</p><p>主要实现方式是通过一个 FIFO 队列实现，这个队列是一个有界队列，大小为<code>b</code>，如果请求堆积满了队列，就会触发丢弃策略。假设允许的请求速率为<code>r</code>次每秒，那么这个队列中的请求，就会以这个速率进行消费。</p><ul><li>能够限制请求调用的速率</li></ul><blockquote><p><strong>漏桶</strong></p><p>漏桶的出水速度是恒定的，那么意味着如果瞬时大流量的话，将有大部分请求被丢弃掉</p><p><strong>令牌桶</strong></p><p>生成令牌的速度是恒定的，而请求去拿令牌是没有速度限制的。这意味，面对瞬时大流量，该算法可以在短时间内请求拿到大量令牌，而且拿令牌的过程并不是消耗很大的事情。</p></blockquote><h4 id="滑动日志"><a href="#滑动日志" class="headerlink" title="滑动日志"></a>滑动日志</h4><p>缓存通过的请求与对应的时间戳，缓存集合为<code>B</code>。每当有请求到来时，从<code>B</code>中删除掉<code>n</code>秒前的所有请求，查看集合是否满了，如果没满，则通过请求，并放入集合，如果满了就触发拒绝策略。</p><h4 id="固定时间窗口"><a href="#固定时间窗口" class="headerlink" title="固定时间窗口"></a>固定时间窗口</h4><p>每隔<code>n</code>秒将计数器重置为<code>b</code>。请求到来时，如果计数器值足够，则扣除并请求通过，不够则触发拒绝策略。实现简单，适用于一些要求不严格的场景，不精细。</p><ul><li><code>突刺现象</code>：如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能眼巴巴的把请求拒绝</li></ul><h3 id="短连接生成转换设计"><a href="#短连接生成转换设计" class="headerlink" title="短连接生成转换设计"></a>短连接生成转换设计</h3><p>通过发号策略，给每一个过来的长地址，发一个号即可，小型系统直接用mysql的自增索引就搞定了。大型应用，可以考虑各种分布式key-value系统做发号器。不停的自增就行了。</p><p>第一个使用这个服务的人得到的短地址是 <a href="http://xx.xx/0" target="_blank" rel="noopener">http://xx.xx/0</a> ，第二个是 <a href="http://xx.xx/1" target="_blank" rel="noopener">http://xx.xx/1</a> ，第11个是 <a href="http://xx.xx/a" target="_blank" rel="noopener">http://xx.xx/a</a> ，依次往后，相当于<strong>实现了一个62进制的自增字段</strong>即可。<br><strong>如何保证同一个长地址，每次转出来都是一样的短地址</strong></p><p>用key-value存储，保存最近生成的长对短的一个对应关系。注意不保存全量的长对短的关系，而只保存最近的。比如采用一小时过期的机制来实现LRU淘汰。</p><blockquote><ul><li>在这个最近表中查看一下，看长地址有没有对应的短地址，有就直接返回，并且将这个key-value对的过期时间<strong>再延长成一小时</strong></li><li>如果没有，就通过发号器生成一个短地址，并且将这个“最近”表中，过期时间为1小时<br>所以当一个地址被频繁使用，那么它会一直在这个key-value表中，总能返回当初生成那个短地址，不会出现重复的问题。如果它使用并不频繁，那么长对短的key会过期，LRU机制自动就会淘汰掉它。<br>当然，这不能保证100%的同一个长地址一定能转出同一个短地址，比如你拿一个生僻的url，每间隔1小时来转一次，你会得到不同的短地址。</li></ul></blockquote><p><strong>保证发号器的大并发高可用</strong></p><p>我们可以实现1000个逻辑发号器，分别发尾号为0到999的号。每发一个号，每个发号器加1000，而不是加1。这些发号器独立工作，互不干扰即可。</p><h3 id="RPC框架设计"><a href="#RPC框架设计" class="headerlink" title="RPC框架设计"></a>RPC框架设计</h3><h4 id="网络IO模型"><a href="#网络IO模型" class="headerlink" title="网络IO模型"></a>网络IO模型</h4><p>最被广泛使用的是多路 I/O 复用，Linux 系统中的 select、epoll 等系统调用都是支持多路 I/O 复用模型的</p><h4 id="序列化方式"><a href="#序列化方式" class="headerlink" title="序列化方式"></a>序列化方式</h4><ul><li>性能要求不高，在传输数据占用带宽不大的场景下可以使用 JSON 作为序列化协议；</li><li>性能要求比较高，那么使用 Thrift 或者 Protobuf 都可以。而 Thrift 提供了配套的 RPC 框架，所以想要一体化的解决方案，你可以优先考虑 Thrift；</li><li>在一些存储的场景下，比如说你的缓存中存储的数据占用空间较大，那么你可以考虑使用 Protobuf 替换 JSON 作为存储数据的序列化方式。</li></ul><h4 id="TCP相关"><a href="#TCP相关" class="headerlink" title="TCP相关"></a>TCP相关</h4><p>开启 tcp_nodelay，这个参数关闭了 Nagle算法</p><h4 id="服务寻址"><a href="#服务寻址" class="headerlink" title="服务寻址"></a><strong>服务寻址</strong></h4><ul><li>服务提供者启动后<strong>主动向服务中心注册机器ip、端口以及提供的服务列表</strong>。</li><li>服务消费者启动时向<strong>服务中心获取服务提供方地址列表，可实现软负载均衡和Failover</strong>。</li><li><strong>提供者需要定时向注册中心发送心跳</strong>，一段时间未收到来自提供者的心跳后，认为提供者已经停止服务，从注册中心上摘取掉对应的服务等等。</li></ul><p><strong>1）服务注册</strong></p><p>首先需要把服务注册到服务中心。其实就是在注册中心进行一个登记，注册中心存储了该服务的IP、端口、调用方式(协议、序列化方式等。在zookeeper中，进行服务注册，实际上就是在zookeeper中创建了一个znode节点，该节点存储了上面所说的服务信息。</p><p><strong>2）服务发现</strong></p><p>服务消费者在第一次调用服务时，会通过注册中心找到相应的服务的IP地址列表，并缓存到本地，以供后续使用。当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从IP列表中取一个服务提供者的服务器调用服务。</p><h2 id="逻辑题"><a href="#逻辑题" class="headerlink" title="逻辑题"></a>逻辑题</h2><p>1、很多根绳子，每一根都不一样且粗细不均匀，每根绳子从头烧到尾都是60分钟烧完，怎么用绳子去测量15分钟的时间</p><pre><code>取出三条绳子。1、同时点燃“第一根的两头”和“第二根的一头”，第一根烧完时间过了“30分钟”；2、第一根烧完后马上点燃第二根的另一头，到第二根烧完时间又过了“15分钟”；</code></pre><p>2、1000杯水，其中一杯有毒，用老鼠试毒，老鼠24h才会死，需要多少只才能找出这杯有毒的水（可以稀释）</p><pre><code>将1000杯水编号(1-1000)，将其转化为2进制码，取10只小白鼠（为什么是10只，因为其1000的2进制码长度是10位），给10只小白鼠编号1-10，第一只小白鼠喝第一位2进制码为1的（1000杯中2进制码第一位为1的都要喝），第二只小白鼠喝第二位2进制为1的（1000杯中2进制码第二位的都要喝）以此类推一直到第10只小白鼠喝完，然后1小时后看那几只小白鼠会死，死掉的小白鼠用1表示，未死的用0表示整理出10位2进制码</code></pre><p>3、10个箱子，每个箱子100跟金条，每个1两，一个贪官，在其中一个箱子里面，每根都磨去了一钱，只能称一次，哪个箱子被磨去了一钱。</p><pre><code>第一箱子拿1块，第二箱子拿2块，第n箱子拿n块，然后放在一起称，看看缺了几钱，缺了n钱就说明是第n个箱子。</code></pre><p>4、有八个球，只能称两次（天平称）只有一个球最重谁能找出？</p><blockquote><p>8个球分成3份，分别是2个球，3个球，3个球</p><p>3个球和3个球称，如果一样重的话，那证明重的球在那一份2个球的，两边各放一个，重的球就可以找到了。</p></blockquote><p>5、回到扑克牌的这个主题，要求把一堆乱序的扑克牌进行 排序 ，如果要极致地压榨性能，应该怎么做？时间复杂度能达到多少？</p><blockquote><p>扑克牌本身规律8个1，8个2…</p></blockquote><p>6、假设现在有1-100号乘客顺序登机，正常情况下1号乘客需要坐1号位置，以此类推，大家顺序入座。假设现在1号乘客随机选择了一个座位坐下，2-100号乘客优先看自己的座位是否被占，自己座位被占的情况下会从剩下的座位中随机选一个坐下，否则坐自己的座位； 那么这种情况下，100号乘客可以做到100号位置的概率会是多少?</p><blockquote><p>等价于这个描述：2-99号乘客登机后如果发现1号疯子坐在本属于自己的位子上，就会请疯子离开，然后疯子再随机找个空座。这样到100号登机时，2-99号都在自己座位上，1号疯子在自己座位上和100号乘客座位上概率相同，所以是1/2。</p><p>假设疯子坐到了第2号位置上，第二个人因此根据题目随机坐到1和3-100位置上，如果2号把疯子赶走后疯子再随机坐到1和3-100位置上，对于第3号人没有任何区别。从3号的角度看都是有一个坐在2号座位上的人，还有一个随机找座位的“疯子”</p></blockquote><p>7、河里的水是无限的，现在有两个水桶分别是5L、6L，问如何从河里取3L水?</p><blockquote><p>解1<br>设：A为5L 。B为6L。<br>解：<br>（1）5L的装满，全倒向6L中；此时B中有5L水（空1L）.<br>（2）5L的再装满，再倒向6L中，此时只能倒入1L；此时A剩有4L水.<br>（3）把B中的的水全倒掉，把A中的4L倒入B中；此时B中有4L水（空2L），A为空.<br>（4）把A装满，倒向B，只能倒入2L，A中还剩3L.</p></blockquote><p>8、64匹马，8个赛道，找出跑得最快的4匹马</p><blockquote><p>1、全部马分为8组，每组8匹，每组各跑一次，然后淘汰掉每组的后四名</p><p>2、8组，取每组第一名进行一次比赛，然后淘汰最后四名所在组的所有马，产生了总冠军</p><p>3、第一名组取前3名，第二名组取前3名，第三名组取前2名，第四名组第一名暂时不比。</p><p>4、如果出现第1，2是二三组的第一名，那么第四组第一名需要加赛一场。</p></blockquote><p>10、A B C D E 海盗，他们要瓜分 100 个金币。A B C D E，轮流提议，提议的人需要获得半票及以上，不然就会被杀死，下一个继续提议，你是 A 会怎么分配？</p><blockquote><p>反推方案：</p><p>D E 时， 100，0</p><p>C D E 时， 99，0，1</p><p>B C D E时，99，0，1，0</p><p>ABCDE时，98，0，1，0，1</p></blockquote><p>11、小明离家有50米，每走一米吃一个苹果，起点有100个苹果，每次最多背50个苹果，请问最多可以拿回家多少苹果？</p><ul><li>每走1m，消耗3个苹果，可以走16米，抛弃2个苹果</li><li>一直走，剩16个苹果</li></ul><blockquote><p>从A地往B运送3000L汽油，两地相距1000KM，一辆汽车最多可装载1000L汽油，每行驶1KM耗油1L，请问从B地最多可以得到多少L汽油？ </p><ul><li>每走1km，消耗5升油，可以走200米</li><li>每走1km，消耗3升油，可以走333米，抛弃剩下的1L，</li><li>一直走就行，最后剩533L油</li></ul></blockquote><p>12、圆形湖中间一只鸭，岸边一只老虎，鸭的速度为s，老虎速度为4s，湖半径为r，鸭子到岸边即可安全逃脱，问什么情况下鸭子能顺利逃脱？</p><blockquote><p>我们暂且假定它就在一个半径为R/4的小圆上围绕圆心游走，只要经过一段时间追赶，鸭子一定会游到这样一个位置，它和老虎在同一条直径上，但位置在圆心的两边。</p><p>此时鸭子立即改为沿半径方向往岸边P点游，显然，它离岸边的距离为3R/4，它登岸需要的时间是3R/4V；而老虎到P点的距离正好是半圆，即Rπ，老虎需要的时间是Rπ/4V。因为π=3.14&gt;3，所以 鸭子先上岸。</p></blockquote><p>13、抛硬币，先抛到正面的赢，第一个抛的人赢的概率</p><blockquote><p>1/2 +1/8 + …，等比数列求和，答案2/3</p></blockquote><p>14、23枚硬币，有10个正面朝上。现在蒙住你的眼睛，如何将硬币分为两堆，保证两堆硬币中，正面朝上的硬币数相同。 </p><blockquote><p>先将硬币分为两组，A组10个，B组13个，假设此时B组有x个朝上，那么A组有10-x个朝上。再将A组每个硬币翻转，此时A组有<code>(10-(10-x))=x</code>枚硬币朝上，和B组朝上的硬币数相等。</p></blockquote><p>15.有两个技巧相当的赌徒 A 和 B（即两人赌博胜率各为0.5），现在设定这样的获胜规则：</p><ol><li>A只要赢了2局或以上就获</li><li>B要赢3局或以上才能获胜。</li></ol><p>问双方胜率各为多少？</p><blockquote><p> <code>1/4+2/8+3/16=11/16</code>，另一方获胜5/16</p></blockquote><p>16、在岛上有100只老虎和1只羊，老虎可以吃草，但他们更愿意吃羊。老虎吃羊会变成羊。问羊会不会被吃？</p><blockquote><pre class="line-numbers language-undefined"><code class="language-undefined">1. 1 只老虎，肯定吃;2. 2 只老虎肯定不吃，否则就被另一只吃了;3. 3 只老虎，如果一只老虎吃掉了羊，这样问题就转换为 2 只老虎和 1 只羊的情况，显然另外两种老虎不敢轻举妄动，所以羊会被吃；4. 4 只老虎，如果某一只老虎吃了羊，问题转化为 3 只老虎和 1 只羊的问题，它肯定会被接下来的某一只吃掉，然后其他两只只能等着，所以 4 只老虎，大家都不敢吃羊；我们就可以发现如果老虎数目是奇数，那么羊肯定被吃，如果是偶数，那么羊肯定不会被吃。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></blockquote><p>17、两个人数数字，1~30，最少说一个，最多说三个，怎么保证第一个人一定输或者一定赢</p><blockquote><p>4个时，先说是输的，即4n+4的状态。即谁处于这个状态就是输的</p><p>先说的30需要将对方转换到4n+4的状态，即先说2个，剩28，后面根据对方说的数字补充4-x即可。</p></blockquote><p>18、Rand5 实现 Rand7</p><blockquote><p>rand5 *5 + rand5=rand25，小于等于21时对7求余数</p></blockquote><p>19、有n个灯泡，按环状摆放，0为关，1为开，单次操作能改变相邻三个灯泡的状态。能否将所有灯泡全亮？</p><blockquote><p>如果给100个灯泡编号0～99 ，顺序往下走，如果灯是亮的就不管，灭的就按下后面灯泡使这个灯亮。</p><p>98号灯是灭的，看99号灯是灭还是亮。如果99号灯是灭的，那就再按一下99号灯的开关，这样全环只有一个灭的灯（0号灯）；如果99号灯是亮的，这样只有98号灯是灭的。总之，全环只有一个灯是灭的。</p><p>第二阶段，将那个灭的灯标记为0号灯，后面的灯依次按顺序排序，每3个一组，中间的那个灯按开关，整个循环跑完，所有的灯都灭了。</p><p>第三阶段，每个灯泡的开关都按一遍。以上步骤就可以使最后的灯泡全亮。</p></blockquote><p>20、两个球，100层楼，每个球在一定高度扔下去会碎，怎么用最少的次数判断几层楼会把球摔碎？</p><blockquote><p>动态规划</p><p>找到子问题。做如下的分析，假设f{n}表示从第n层楼扔下鸡蛋，没有摔碎的最少尝试次数。第一个鸡蛋，可能的落下位置(1，n)，第一个鸡蛋从第i层扔下，有两个情况：</p><ul><li>碎了，第二个鸡蛋，需要从第一层开始试验，有i-1次机会</li><li>没碎，两个鸡蛋，还有n-i层。这个就是子问题了f{n-i} 所以，当第一个鸡蛋，由第i个位置落下的时候，要尝试的次数为1 + max(i - 1， f{n - i})，那么对于每一个i，尝试次数最少的，就是f{n}的值。状态转移方程如下： f{n} = min(1 + max(i - 1， f{n - 1}) ) 其中: i的范围为(1， n)， f{1} = 1 。</li></ul><p>数学推导</p><p>假设最少尝试次数为x，那么，第一个鸡蛋必须要从第x层扔下，如果碎了，前面还有x - 1层楼可以尝试，如果没碎，后面还有x-1次机会。如果没碎，第一个鸡蛋，第二次就可以从x +（x - 1）层进行尝试，为什么是加上x - 1，因为，当此时，第一个鸡蛋碎了，第二个鸡蛋还有可以从x+1 到 x + (x - 1) - 1层进行尝试，有x - 2次。如果还没碎，那第一个鸡蛋，第三次从 x + (x - 1) + (x - 2)层尝试。碎或者没碎，都有x - 3次尝试机会，依次类推。那么，x次的最少尝试，可以确定的最高的楼层是多少呢？ x + (x - 1) + (x - 2) + … + 1 = x(x+1) / 2 那反过来问，当最高楼层是100层，最少需要多少次呢？x(x+1)/2 &gt;= 100， 得到x&gt;=14，最少要尝试14次。</p></blockquote><p>20、十层楼，每层楼有一颗钻石，大小不一，电梯从下往上，每层楼可以打开电梯门查看，但是只能拿走一颗，且不能交换，请问有什么方法可以拿到最大的</p><blockquote><p>37%法则：先放弃前 37%（就是1/e）的钻石，此后选择比前 37% 都大的第一颗钻石。</p></blockquote><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><h3 id="哈希函数的冲突如何避免？"><a href="#哈希函数的冲突如何避免？" class="headerlink" title="哈希函数的冲突如何避免？"></a>哈希函数的冲突如何避免？</h3><p>双哈希或者多哈希</p><h3 id="直播视频卡住了，分析原因"><a href="#直播视频卡住了，分析原因" class="headerlink" title="直播视频卡住了，分析原因"></a>直播视频卡住了，分析原因</h3><ul><li>帧率太低 如果主播端手机性能较差，或者有很占 CPU 的后台程序在运行，可能导致视频的帧率太低。</li><li>上传阻塞 主播的手机在推流时会源源不断地产生音视频数据，但如果手机的上传网速太小，那么产生的音视频数据都会被堆积在主播的手机里传不出去，上传阻塞会导致全部观众的观看体验都很卡顿。</li><li>下行不佳 就是观众的下载带宽跟不上或者网络很波动</li></ul><h3 id="线程池的核心线程数大小如何确定"><a href="#线程池的核心线程数大小如何确定" class="headerlink" title="线程池的核心线程数大小如何确定"></a>线程池的核心线程数大小如何确定</h3><ul><li>计算密集型为N（N为CPU总核数）+1，IO密集型为2N。</li></ul><p>$N_{threads}=N_{cpu}<em>U_{cpu}</em>(1+W/C)，W等待时间，C计算时间$</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html</a></p><p><a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html</a></p><p><a href="http://www.ruanyifeng.com/blog/2019/04/oauth_design.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2019/04/oauth_design.html</a></p>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络必知必会</title>
      <link href="/2021/05/20/interview-network/"/>
      <url>/2021/05/20/interview-network/</url>
      
        <content type="html"><![CDATA[<h2 id="计算机网络体系结构"><a href="#计算机网络体系结构" class="headerlink" title="计算机网络体系结构"></a>计算机网络体系结构</h2><p><img src="stru.png" alt></p><p><img src="mode.png" alt></p><h3 id="OSI-7层"><a href="#OSI-7层" class="headerlink" title="OSI 7层"></a>OSI 7层</h3><p>物理层：通过网线、光缆等这种物理方式将电脑连接起来。发送高低电平（电信号）</p><p>数据链路层：定义了电信号的分组方式。MAC地址的封装和解封装。</p><p>网路层：引入网络地址用来区分不同的广播域/子网，ip的封装和解封装</p><p>传输层：建立端口到端口的通信，接受到的数据进行分段处理，再进行组装</p><p>会话层：建立和断开客户端与服务端连接</p><p>表示层：数据格式转换。如编码、数据格式转换、加密解密、压缩解压</p><p>应用层：规定应用程序的数据格式</p><h3 id="四层网络"><a href="#四层网络" class="headerlink" title="四层网络"></a>四层网络</h3><ul><li>链路层：负责封装和解封装MAC地址，发送和接受ARP/RARP报文等。</li><li>网络层：负责路由以及把分组报文发送给目标网络或主机。</li><li>传输层：负责对报文进行分组和重组，并以TCP或UDP协议格式封装报文。</li><li>应用层：负责向用户提供应用程序，比如HTTP、FTP、Telnet、DNS、SMTP等。</li></ul><h3 id="为什么要分层？"><a href="#为什么要分层？" class="headerlink" title="为什么要分层？"></a>为什么要分层？</h3><p>1、易于实现、标准化、各层独立，就可以把大问题分割成多个小问题，利于实现；</p><p>2、灵活性好：如果某一层发生变化，只要接口不变，不会影响其他层；</p><p>3、分层后，用户只关心用到的应用层，其他层用户可以复用；</p><ul><li>应用层：常见协议：<ul><li>FTP（21端口）：文件传输协议</li><li>SSH（22端口）：远程登陆</li><li>TELNET（23端口）：远程登录</li><li>SMTP（25端口）：发送邮件</li><li>POP3（110端口）：接收邮件</li><li>HTTP（80端口）：超文本传输协议</li><li>DNS（53端口）：运行在UDP上，域名解析服务</li><li>DHCP</li></ul></li><li>传输层：TCP/UDP</li><li>网络层：IP、NAT、RIP、ICMP</li><li>链路层：VLAN、STP</li></ul><h3 id="为什么需要IP？MAC？"><a href="#为什么需要IP？MAC？" class="headerlink" title="为什么需要IP？MAC？"></a>为什么需要IP？MAC？</h3><p><strong>需要 IP 地址</strong></p><p>如果我们只用 MAC 地址，路由器需要记住每个 MAC 地址所在的子网是哪一个，因此需要极大的内存</p><p><strong>需要Mac地址</strong></p><p>需要用 MAC 地址来区分不同的设备。</p><h3 id="TCP和IP的区别"><a href="#TCP和IP的区别" class="headerlink" title="TCP和IP的区别"></a>TCP和IP的区别</h3><p>IP协议：规定了数据传输时的基本单元和格式，定义了数据包的递交办法和路由选择。</p><p>TCP协议：提供了可靠的数据流传输服务。</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><h4 id="四层负载均衡"><a href="#四层负载均衡" class="headerlink" title="四层负载均衡"></a><strong>四层负载均衡</strong></h4><p>工作于OSI模型的传输层，它主要处理消息的传递，而不管消息的内容。<strong>四层负载均衡只针对由上游服务发送和接收的网络包，而并不检查包内的具体内容是什么。</strong></p><p>通过报文中的<strong>目标地址和端口</strong>，再加上负载均衡模式，选择内部服务器，即<strong>转发</strong>，只需要一个连接。</p><h4 id="七层负载均衡"><a href="#七层负载均衡" class="headerlink" title="七层负载均衡"></a><strong>七层负载均衡</strong></h4><p>通过报文中的应用层内容（比如url、参数、cookie、header等），再加上负载均衡模式，选择内部服务器。</p><p>主作于OSI模型的应用层，终止网络传输并读取消息中的内容。它可以基于消息中内容（比如URL或者cookie中的信息）来做出负载均衡的决定。七层负载均衡器建立一个新的TCP连接来选择上游服务（或者再利用一个已经存在的TCP连接，通过 HTTP keepalives 的方式）并向这个服务发出请求</p><h4 id="https怎么实现负载均衡"><a href="#https怎么实现负载均衡" class="headerlink" title="https怎么实现负载均衡"></a><strong>https怎么实现负载均衡</strong></h4><p>7层：nginx安装ssl证书，用户请求 –https–&gt; nginx –http–&gt; 应用</p><p>4层：用户请求–https-&gt; 4层负载 –https-&gt; 应用</p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a><strong>应用场景</strong></h4><ul><li>四层负载均衡SYN攻击（DOS/DDOS攻击）都会被转发到后端的服务器上；七层负载均衡SYN攻击在负载均衡设备上截止，不会影响后台服务器的正常运行</li><li>七层负载均衡，主要应用于HTTP协议，即网站。</li></ul><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>性能：4层要比7层快，因为7层代理需要解析数据包的具体内容，需要消耗额外的cpu</p><p>灵活性：4层代理不知道请求的具体内容。 7层代理可以根据请求内容（url，参数，cookie，请求头）实现动态代理、风控、审计</p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>现代机器cpu性能都很好，4层代理并没有明显的性能优势，而7层代理在业务层面优势明显，所以一般直接选择7层代理</p><h4 id="nginx的轮询算法"><a href="#nginx的轮询算法" class="headerlink" title="nginx的轮询算法"></a>nginx的轮询算法</h4><ul><li>轮询算法</li><li>权重轮询</li><li>随机均衡</li><li>响应速度均衡：负载均衡向后端服务器发出一个探测请求，那个回应速度最快就使用哪个</li><li>最少连接数</li><li>处理能力均衡：把请求分配给处理负荷最轻的服务器，适用于第七层负载均衡</li></ul><h2 id="网络设备"><a href="#网络设备" class="headerlink" title="网络设备"></a>网络设备</h2><h3 id="集线器"><a href="#集线器" class="headerlink" title="集线器"></a>集线器</h3><p>工作在OSI物理层，集线器的基本功能是信息分发，它把一个port接收的全部信号向全部port分发出去。</p><h3 id="交换机的工作原理"><a href="#交换机的工作原理" class="headerlink" title="交换机的工作原理"></a>交换机的工作原理</h3><p>工作在OSI数据链路层，依据MAC地址进行数据转发。</p><ul><li>取得目标MAC地址后，查找交换机中存储的地址对比表（MAC地址相应的port），将数据包送到相应port。</li><li>目的MAC若不存在，广播到全部的port。接收port回应后，把新的MAC地址加入入内部地址表中。  </li></ul><h3 id="网桥"><a href="#网桥" class="headerlink" title="网桥"></a>网桥</h3><p>工作在OSI数据链路层，能够看成是一个二层路由器。</p><p>网桥可有效的将两个局域网连起来，依据MAC地址来转发帧。</p><h3 id="路由器的工作原理"><a href="#路由器的工作原理" class="headerlink" title="路由器的工作原理"></a>路由器的工作原理</h3><p>工作在OSI网络层。可以连接多个网络或网段，依据IP进行寻址转发数据包。</p><h2 id="报文头部"><a href="#报文头部" class="headerlink" title="报文头部"></a>报文头部</h2><h3 id="网络包的格式"><a href="#网络包的格式" class="headerlink" title="网络包的格式"></a>网络包的格式</h3><p>MAC头+IP头+TCP头+HTTP头+HTTP正文</p><h3 id="IP报文"><a href="#IP报文" class="headerlink" title="IP报文"></a>IP报文</h3><p><img src="ip.jpg" alt></p><p>（1）版本号：IP协议的版本。<br>（2）头部长度：4位最大为0xF，注意该字段表示单位是字（4字节）<br>（3）服务类型<br>（4）总长度: 指整个IP数据报的长度，IP数据报的最大长度为65535字节。由于MTU的限制，长度超过MTU的数据报都将被分片传输。</p><p><strong>下来的3个字段则描述如何实现分片:</strong><br>（5）标识：唯一地标识主机发送的每一个数据报，其初始值是随机的，每发送一个数据报其值就加1。同一个数据报的所有分片都具有相同的标识值<br>（6） 标志: 位1保留，位2表禁止分片（DF），若设置了此位，IP模块将不对数据报进行分片；位3标识更多分片（MF），除了数据报的最后一个分片，其他分片都要把它设置为1<br>（7） 位偏移：分片相对原始IP数据报数据部分的偏移。</p><p>（8） 生存时间：数据报到达目的地之前允许经过的路由器跳数。<br>（9） 协议： 区分IP协议上的上层协议。ICMP为1，TCP为6，UDP为17<br>（10） 头部校验和： 由发送端填充接收端对其使用CRC算法校验，检查IP数据报头部在传输过程中是否损坏<br>（11） 源IP地址和目的IP地址：表示数据报的发送端和接收端。一般情况下这两个地址在整个数据报传递过程中保持不变。</p><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><p><img src="baowen.jpg" alt></p><ul><li>源端口号和目标端口号，各16bit</li><li>包的序号（seq）：32 bits</li><li>确认序号（ack）：32 bits</li><li>状态位：例如 SYN 发起连接，ACK 回复，RST 重新连接，FIN 结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</li><li>窗口大小：接收窗口的大小，16 bits</li></ul><h3 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h3><p><img src="udp_header.png" alt="UDP头"></p><ul><li><p>源端口和目的端口</p></li><li><p>报文长度：16 bits，指示UDP报文的总长度。最小8 bytes，只有首部，没有数据。最大值为65535 bytes。</p></li><li><p>校验和</p></li></ul><h3 id="TCP和UDP报文区别"><a href="#TCP和UDP报文区别" class="headerlink" title="TCP和UDP报文区别"></a>TCP和UDP报文区别</h3><p>TCP首部开销（20字节），UDP首部开销（8字节）</p><p>UDP 包 <code>MTU1500 - IP头(20) - UDP头(8) = 1472(Bytes)</code><br>TCP 包 <code>MSS=MTU1500 - IP头(20) - TCP头(20) = 1460 (Bytes)</code></p><blockquote><p> Maximum Transmit Unit，数据链路层最大传输单元</p><p>Maximum Segment Size ，网络层最大分段大小</p></blockquote><h3 id="TCP校验怎么实现？"><a href="#TCP校验怎么实现？" class="headerlink" title="TCP校验怎么实现？"></a>TCP校验怎么实现？</h3><ul><li><p>首如果总长度为奇数个字节，则在最后增添一个位都为0的字节。</p></li><li><p>校验和字段置为0（否则就陷入鸡生蛋还是蛋生鸡的问题）。</p></li><li><p>反码相加法累加所有的16位字。</p></li><li><p>计算结果取反，作为TCP的校验和。</p><p><strong>如果接收方比对校验和与发送方一致，数据不一定传输成功。</strong></p></li></ul><h3 id="如果网络层不分片怎么做？"><a href="#如果网络层不分片怎么做？" class="headerlink" title="如果网络层不分片怎么做？"></a>如果网络层不分片怎么做？</h3><ul><li><strong>IP头的DF置为1</strong></li><li>链路上有台路由器由于各种原因MTU变小了</li><li>IP消息到这台路由器了，路由器发现消息长度大于自己的MTU，且消息设置DF不让分片。就把消息丢弃，同时返回一个ICMP错误给发送端，并带上自己的MTU。</li></ul><h2 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h2><h3 id="什么是ARP协议-？"><a href="#什么是ARP协议-？" class="headerlink" title="什么是ARP协议 ？"></a>什么是ARP协议 ？</h3><p>Address Resolution Protocol</p><ul><li><strong>ARP协议完成了IP地址与物理地址的映射</strong>。每一个主机都设有一个 ARP 高速缓存，有所在的局域网上的各主机、路由器的 IP 地址到MAC地址的映射表。</li><li>当检查自己的ARP高速缓存中有没有目的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，发起一个ARP请求的广播包（ARP 请求会带上源 IP 地址到MAC地址的映射）</li><li>收到ARP请求的主机检查IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。</li><li>源主机收到响应数据包，添加目的主机的IP地址与MAC地址的映射，再进行数据传送。源主机没有收到响应，表示ARP查询失败。</li></ul><blockquote><p> 如果目的主机和源主机不在同一个局域网，通过 ARP 某个路由器的MAC地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。</p></blockquote><h3 id="IPv4怎么缓解地址不够？"><a href="#IPv4怎么缓解地址不够？" class="headerlink" title="IPv4怎么缓解地址不够？"></a>IPv4怎么缓解地址不够？</h3><p>NAT。使用少量的公有IP地址代表较多的私有IP地址。</p><h3 id="什么是NAT-？"><a href="#什么是NAT-？" class="headerlink" title="什么是NAT ？"></a>什么是NAT ？</h3><p>Network Address Translation， 网络地址转换，用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址。</p><h3 id="IPv6和IPv4区别？"><a href="#IPv6和IPv4区别？" class="headerlink" title="IPv6和IPv4区别？"></a>IPv6和IPv4区别？</h3><p><strong>地址长度不同</strong></p><p>IPv4的地址是32位，而IPv6的地址是128位的。</p><p><strong>地址的表示方法</strong></p><p>IPv4地址是以十进制表示。 IPv6地址是以十六进制表示。</p><p><strong>IPv6 相比 IPv4 的首部改进</strong>：</p><ul><li>取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。</li><li>取消了分片/重组相关字段。 分片与重组是耗时的过程， IPv6 不允许在中间路由器进行分片与重组，只能在源与目标主机分片重组，大大提高了路由器转发的速度。</li><li>取消选项字段。 选项字段不再是标准 IP 首部的一部分了。</li></ul><h3 id="IP分片和重组"><a href="#IP分片和重组" class="headerlink" title="IP分片和重组"></a>IP分片和重组</h3><p>包长度大于链路上物理设备的mtu时，会根据一定的方式进行切割，从而使报文得以发送出去。</p><p>把一份IP数据报文分片以后，只有到达IP报文传送的下一站才进行重新组装。</p><p>第三位标志用于指出当前分段后面是否还有更多的分段，如果此位置0，表示当前分段是数据报的最后一个分段。 </p><h3 id="IP寻址过程"><a href="#IP寻址过程" class="headerlink" title="IP寻址过程"></a>IP寻址过程</h3><p><strong>一、在同一个局域网内的两台主机</strong></p><ol><li>A开始只知道B的IP地址 并不知道B的mac地址，A发送ARP广播</li><li>交换机收到ARP广播后，将它转发到所有端口，并记录源MAC地址</li><li>B收到ARP请求，发现和自己IP匹配，发送ARP响应</li><li>交换机收到B的响应，转发到A端口，同时保存B的MAC地址</li><li>A收到回复后 ，得知B的mac地址 ，保存到本地ARP高速缓存，发送数据包</li></ol><p><strong>一、不在同一个局域网内的两台主机</strong></p><ol><li>先会 ARP 广播请求 网关 的 MAC 地址 </li><li>A 得到网关的 MAC 地址后，以它为数据帧的目标 MAC 地址进行封装数据，并发送出去</li><li>Router1 收到该帧后，检查该帧的目标 IP ，查路由表，下一跳地址是 routerB ，数据重新封装，将源地址改为router1 MAC 地址，目标 MAC 地址改为 router2  MAC 址址，并发送给 router2</li><li>routerN 发现目标 IP 就在自己的直连网段，于是查看 ARP 缓存，如果找到该 IP 的 MAC 地址，则以该 MAC 地址封装数据发送出去，如果在 ARP 缓存没找到，则发出 ARP 广播，请求该 IP 的 MAC 地址，得到对应的 MAC 地址后，再发送给主机 B</li></ol><p>1，由于 B 的 IP 地址并没有和 A 在一个网段，所以当 A 向 B 发送数据时， A 并不会直接把数据给 B ，而是交给自己的网关，所以 A 首先会 ARP 广播请求 网关 的 MAC 地址 A 得到网关的 MAC 地址后，以它为数据帧的目标 MAC 地址进行封装数据，并发送出去</p><h3 id="路由器怎么转发"><a href="#路由器怎么转发" class="headerlink" title="路由器怎么转发"></a>路由器怎么转发</h3><ul><li>路由器收到一个数据包后，会检查其目的IP地址，然后依据最长匹配原则查找路由表；</li><li>如果查找到匹配的路由表项之后，路由器会根据该表项所指示的出接口信息和下一跳信息将数据包转发出去；</li><li>如果没有找到，会查找是否<strong>有缺省路由</strong>，找到的话会依据出接口信息和下一跳信息将数据包转发出去；</li><li>如果都没有找到，<strong>数据包会被丢弃</strong>；</li></ul><h3 id="什么是ICMP协议，它的作用是什么？"><a href="#什么是ICMP协议，它的作用是什么？" class="headerlink" title="什么是ICMP协议，它的作用是什么？"></a>什么是ICMP协议，它的作用是什么？</h3><p><strong>互联网控制报文协议</strong>。用在主机、路由器之间传递控制消息，控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。</p><p>ICMP 主要的功能包括：确认 IP 包是否成功送达、 IP 包被废弃的原因等。</p><p>ICMP 包头的类型字段，大致可以分为两大类：</p><ul><li>查询报文：用于诊断的查询消息</li><li>差错报文：通知出错原因的错误消息</li></ul><h3 id="Ping的过程以及原理"><a href="#Ping的过程以及原理" class="headerlink" title="Ping的过程以及原理"></a>Ping的过程以及原理</h3><p> <strong>使用ICMP查询报文</strong></p><ul><li>源主机首先会构建一个 <strong>ICMP 回送请求消息</strong>数据包</li><li>交给 IP 层。IP 层将设置目的地址，源地址，协议字段。</li><li>加入 <code>MAC</code> 头。如果没有，则需要发送 <code>ARP</code> 协议查询 MAC 地址。</li><li>主机 <code>B</code> 收到后，检查 MAC 地址，如符合，则接收，否则就丢弃。</li><li>提取IP 层，交给 ICMP 协议。</li><li>主机 <code>B</code> 构建一个 ICMP 回送响应消息数据包。</li><li>源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。</li></ul><h3 id="traceroute命令用处"><a href="#traceroute命令用处" class="headerlink" title="traceroute命令用处"></a>traceroute命令用处</h3><p>诊断网络问题。定位从源主机到目标主机之间经过了哪些路由器，以及到达各个路由器的耗时。</p><p><strong>原理</strong></p><p>从源主机向目标主机发送IP数据报，并按顺序将TTL设置为从1开始递增的数字，导致第N个节点丢弃数据报并返回出错信息。源主机根据接收到的错误信息，确定到达目标主机路径上的所有节点的IP，以及对应的耗时。</p><h3 id="什么是RIP"><a href="#什么是RIP" class="headerlink" title="什么是RIP?"></a>什么是RIP?</h3><p>Routing Information Protocol， 距离矢量路由协议，每个路由器维护一张表，记录该路由器到其它网络的”跳数“。</p><p>路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。</p><p><strong>缺点</strong></p><ul><li>最大距离为15，限制了网络的规模；</li><li>当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器</li></ul><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p><img src="woshou.jpg" alt></p><ul><li>一客户端和服务端都处于 CLOSED 状态。服务端主动监听某个端口，处于 LISTEN 状态。</li><li>客户端主动发起连接 SYN，序列号是X，处于 SYN-SENT 状态。</li><li>服务端ACK 客户端的 SYN，ack的值为X+1，并且同时发送 SYN，序列号为Y，之后处于 SYN-RCVD 状态。</li><li>客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，处于 ESTABLISHED 状态，因为它一发一收成功了。</li><li>服务端收到 ACK 后，处于 ESTABLISHED 状态，因为它也一发一收了。</li></ul><h3 id="客户端发送的SYN丢失"><a href="#客户端发送的SYN丢失" class="headerlink" title="客户端发送的SYN丢失"></a>客户端发送的SYN丢失</h3><p>触发<strong>重传机制</strong>，重传的次数是由 tcp_syn_retries 决定。超过重传次数会返回错误。</p><h3 id="为什么不是2次"><a href="#为什么不是2次" class="headerlink" title="为什么不是2次"></a>为什么不是2次</h3><ul><li><p>服务器端的应答包不知道能不能到达客户端。服务器端不能认为连接是建立好了，应答包可能会丢，会绕弯路，或者客户端已经挂了。</p></li><li><p>如果仅是两次连接。可能出现<strong>已失效的连接请求报文段又传到了服务器端</strong>：</p><ul><li>客户端发起连接，由于网络情况不好，服务器端延时很长时间后收到报文。客户端将此报文认定为失效的报文，因为中间可能已经建立连接并断开。</li><li>服务器端收到报文后，会向客户端发起连接。此时两次握手完毕。</li><li>服务器端会认为已经建立了连接可以通信，服务器端会一直等到客户端发送的连接请求，而客户端对失效的报文回复自然不会处理。会陷入服务器端忙等的僵局，造成资源的浪费。</li></ul></li></ul><h3 id="为什么不是4次"><a href="#为什么不是4次" class="headerlink" title="为什么不是4次"></a>为什么不是4次</h3><p>可以。但是会降低传输的效率。</p><p>四次握手是指：第二次握手时服务器端只发送ACK和acknowledge number；</p><p>而服务器端的SYN和初始序列号在第三次握手时发送。</p><p>出于优化目的，四次握手中的二、三可以合并。</p><h3 id="第三次握手中，ACK丢失会怎样？"><a href="#第三次握手中，ACK丢失会怎样？" class="headerlink" title="第三次握手中，ACK丢失会怎样？"></a>第三次握手中，ACK丢失会怎样？</h3><p>服务器：<br>由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。</p><p>客户端：  </p><ol><li>如果客户端向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态  </li><li>在服务器进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。</li></ol><h3 id="初始序列号是什么？"><a href="#初始序列号是什么？" class="headerlink" title="初始序列号是什么？"></a>初始序列号是什么？</h3><p>TCP连接的一方A，随机选择一个32位的序列号作为发送数据的初始序列号，以该序列号为原点，对要传送的数据进行编号，以便另一方B可以确认什么样的数据编号是合法的；</p><p>同时A还可以确认B收到的每一个字节，如果A收到了B的确认编号是2001，就说明编号为1001-2000的数据已经被B成功接受。</p><h3 id="序列号是随机取的吗？为什么？"><a href="#序列号是随机取的吗？为什么？" class="headerlink" title="序列号是随机取的吗？为什么？"></a>序列号是随机取的吗？为什么？</h3><p>1）攻击维度</p><p>如果TCP每次连接都使用固定初始序列号，黑客可以很方便模拟任何IP与服务器建立连接。</p><p>2）TCP连接稳定维度</p><p>假设客户端与服务器连接状况不好，那么之前交互的报文很可能在连接已断但是还没到server。</p><p>如果初始序列号是固定的，那很可能在新连接建立后，上次连接通信的报文才到达，这就全乱了。</p><h3 id="accept-connect-listen对应三次握手什么阶段"><a href="#accept-connect-listen对应三次握手什么阶段" class="headerlink" title="accept connect listen对应三次握手什么阶段"></a>accept connect listen对应三次握手什么阶段</h3><ul><li>当服务端调用 listen 函数进行监听。  这个时候客户端就可以发起连接</li><li>客户端可以通过 connect 函数发起连接。指明要连接的 IP 地址和端口号，三次握手。  内核会给客户端分配一个临时的端口。</li><li>一旦握手成功，服务端的 accept就会返回另一个 Socket。  </li></ul><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p><img src="huishou.jpg" alt></p><ul><li><p>客户端进程发出连接释放报文FIN，序列号为seq=p，并且停止发送数据。客户端进入FIN-WAIT-1。 </p></li><li><p>服务器收到后，发出确认报文ACK，ack=p+1，此时，服务端就进入了CLOSE-WAIT。TCP服务器通知高层的应用进程，客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。</p></li><li><p>客户端收到Ack后，此时，客户端就进入FIN-WAIT-2状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。</p></li><li><p>服务器将最后的数据发送完毕后，就向客户端发送连接释放报文FIN，ack=p+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=q，此时，服务器就进入了LAST-ACK状态，等待客户端的确认。</p></li><li><p>客户端收到服务器的连接释放报文后，必须发出确认ACK，ack=q+1，此时，客户端就进入了TIME-WAIT状态。此时TCP连接还没有释放，必须经过2MSL的时间后，才进入CLOSED状态。</p></li><li><p>服务器只要收到了客户端发出的确认，立即进入CLOSED状态。</p></li></ul><h3 id="服务器的ACK丢失，会怎样？"><a href="#服务器的ACK丢失，会怎样？" class="headerlink" title="服务器的ACK丢失，会怎样？"></a>服务器的ACK丢失，会怎样？</h3><p>客户端没有收到ACK确认，会重新发送FIN请求。</p><h3 id="TIME-WAIT意义是什么？"><a href="#TIME-WAIT意义是什么？" class="headerlink" title="TIME_WAIT意义是什么？"></a>TIME_WAIT意义是什么？</h3><p>第四次挥手时，客户端ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果服务器没有收到ACK，就会重发FIN，如果客户端在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL。</p><p>MSL（Maximum Segment Lifetime），指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。</p><h3 id="2MSL作用"><a href="#2MSL作用" class="headerlink" title="2MSL作用"></a>2MSL作用</h3><ul><li><p>确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。</p></li><li><p>等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。</p></li></ul><p>超过了 2MSL ，依然没有收到FIN 的 ACK，重发 FIN，A 发送 RST，B 就知道 A 早就跑了。</p><h3 id="建立连接是三次握手，关闭连接四次挥手？"><a href="#建立连接是三次握手，关闭连接四次挥手？" class="headerlink" title="建立连接是三次握手，关闭连接四次挥手？"></a>建立连接是三次握手，关闭连接四次挥手？</h3><ul><li>建立连接时， 服务器收到SYN报文后，把ACK和SYN放在一个报文里发送给客户端。</li><li>关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据，自己也未必全部数据都发送给对方了，所以需要等到数据发完之后再发FIN，断开服务器到客户端的数据传送。</li></ul><h3 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h3><ul><li>TCP设有一个保活计时器。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时</li><li>若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</li></ul><h3 id="服务端出现大量close-wait原因"><a href="#服务端出现大量close-wait原因" class="headerlink" title="服务端出现大量close_wait原因"></a>服务端出现大量close_wait原因</h3><p>服务端程序忘记主动关闭连接，这个资源会一直被程序占着。</p><p>会导致to many open files。</p><h3 id="服务器保持了大量TIME-WAIT状态"><a href="#服务器保持了大量TIME-WAIT状态" class="headerlink" title="服务器保持了大量TIME_WAIT状态"></a>服务器保持了大量TIME_WAIT状态</h3><p>一些爬虫服务器或者WEB服务器上经常会遇到这个问题，在完成一个爬取任务之后，发起主动关闭连接，进入TIME_WAIT的状态，2MSL时间之后，彻底关闭回收资源。</p><p>解决方法：优化系统参数</p><pre><code>#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭 net.ipv4.tcp_tw_reuse = 1 #表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 net.ipv4.tcp_tw_recycle = 1 </code></pre><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><h3 id="TCP如何实现流量控制？"><a href="#TCP如何实现流量控制？" class="headerlink" title="TCP如何实现流量控制？"></a>TCP如何实现流量控制？</h3><p><img src="huadong.png" alt="滑动窗口"></p><p>使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。</p><ul><li>接收方会维护一个接收窗口 ，接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。</li><li>发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。</li><li>发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。</li></ul><h3 id="什么是零窗口？"><a href="#什么是零窗口？" class="headerlink" title="什么是零窗口？"></a>什么是零窗口？</h3><ul><li>如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据。</li><li>启动一个持续计时器，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。</li><li>如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。</li></ul><h3 id="TCP的拥塞控制是怎么实现的？"><a href="#TCP的拥塞控制是怎么实现的？" class="headerlink" title="TCP的拥塞控制是怎么实现的？"></a>TCP的拥塞控制是怎么实现的？</h3><p>拥塞控制主要由四个算法组成：<strong>慢启动、拥塞避免、快重传 、快恢复</strong></p><ol><li><p>慢启动：刚开始发送数据时，先把拥塞窗口设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍</p></li><li><p>拥塞避免：当拥塞窗口的大小达到慢开始门限时，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.  </p></li></ol><blockquote><p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。<strong>（这是不使用快重传的情况）</strong></p></blockquote><ol start="3"><li>快重传：接收方在收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认。发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</li><li>快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。 </li></ol><p><strong>为什么需要3次重复确认？</strong></p><p>主要的考虑还是要区分丢包和乱序。两次duplicated ACK时一定是乱序造成的，三次duplicated ACK时很可能是丢包造成的！四次duplicated ACK更可能是丢包造成的！但是这样的响应策略太慢。丢包肯定会造成三次duplicated ACK!综上是选择收到三个重复确认时窗口减半效果最好。</p><h3 id="慢启动对HTTP有什么影响？HTTP如何解决这种影响？"><a href="#慢启动对HTTP有什么影响？HTTP如何解决这种影响？" class="headerlink" title="慢启动对HTTP有什么影响？HTTP如何解决这种影响？"></a>慢启动对HTTP有什么影响？HTTP如何解决这种影响？</h3><ul><li>建立TCP连接都经历慢启动。</li><li>如果HTTP是短连接，有可能还没有经历完TCP慢启动，这个TCP连接就断开了。</li><li>为了提升性能，我们可以开启HTTP的持久连接也就是后面要说的keepalive。</li></ul><h3 id="HTTP对TCP的缺点做了那些改进？"><a href="#HTTP对TCP的缺点做了那些改进？" class="headerlink" title="HTTP对TCP的缺点做了那些改进？"></a>HTTP对TCP的缺点做了那些改进？</h3><p>最常见的影响HTTP性能的包括：</p><ul><li>TCP连接建立，三次握手</li><li>TCP慢启动</li><li>TCP延迟确认</li><li>Nagle算法</li></ul><blockquote><ul><li><p>HTTP的keep alive，实现连接复用</p></li><li><p>我们可以关闭或者调整TCP延迟确认。</p></li><li><p>可以在操作系统上禁用或者在HTTP程序中设置TCP_NODELAY来禁用Nagle算法</p></li></ul></blockquote><h3 id="TCP如何最大利用带宽？"><a href="#TCP如何最大利用带宽？" class="headerlink" title="TCP如何最大利用带宽？"></a>TCP如何最大利用带宽？</h3><p>TCP速率受到三个因素影响</p><ul><li>窗口：滑动窗口大小</li><li>带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。</li><li>RTT：表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样</li></ul><h2 id="TCP与UDP"><a href="#TCP与UDP" class="headerlink" title="TCP与UDP"></a>TCP与UDP</h2><h3 id="TCP与UDP的区别"><a href="#TCP与UDP的区别" class="headerlink" title="TCP与UDP的区别"></a>TCP与UDP的区别</h3><ol><li>TCP是面向连接的，UDP是无连接的；</li><li>TCP是可靠的，UDP不可靠；</li><li>TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；</li><li>TCP是面向字节流的，UDP是面向报文的；</li><li>TCP有拥塞控制机制，UDP没有。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天。</li><li>TCP首部开销（20字节）比UDP首部开销（8字节）要大</li></ol><blockquote><p>1：UDP发送数据之前不需要建立连接</p><p>2：UDP接收方收到报文后，不需要给出任何确认</p><p>4：面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。</p></blockquote><h3 id="什么时候选择TCP，什么时候选UDP？"><a href="#什么时候选择TCP，什么时候选UDP？" class="headerlink" title="什么时候选择TCP，什么时候选UDP？"></a>什么时候选择TCP，什么时候选UDP？</h3><p>对某些实时性要求比较高的情况，选择UDP，比如游戏，媒体通信，实时视频流（直播），即使出现传输错误也可以容忍；</p><p>其它大部分情况下，HTTP都是用TCP，因为要求传输的内容可靠，不出现丢失</p><h3 id="TCP报文确认机制"><a href="#TCP报文确认机制" class="headerlink" title="TCP报文确认机制"></a>TCP报文确认机制</h3><ul><li>为了保证顺序性，每一个包都有一个 ID。</li><li>在建立连接的时候，确定起始的 ID ，然后按照 ID 一个个发送。</li><li>为了保证不丢包，对于发送的包都要进行应答。</li><li>应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答</li></ul><h3 id="TCP发数据过程中必须按顺序接收吗"><a href="#TCP发数据过程中必须按顺序接收吗" class="headerlink" title="TCP发数据过程中必须按顺序接收吗"></a>TCP发数据过程中必须按顺序接收吗</h3><p>TCP报文段作为IP数据来传输，在IP数据报的到达可能会失序，因此TCP报文段的到达也存在失序的可能。</p><p>TCP将对收到的数据进行重新排列，确保顺序正确后再交给应用层。</p><h3 id="TCP发送窗口过大会怎么样？"><a href="#TCP发送窗口过大会怎么样？" class="headerlink" title="TCP发送窗口过大会怎么样？"></a>TCP发送窗口过大会怎么样？</h3><p>接收端缓存溢出或者网络拥塞</p><h3 id="为什么会发生网络卡顿现象？"><a href="#为什么会发生网络卡顿现象？" class="headerlink" title="为什么会发生网络卡顿现象？"></a>为什么会发生网络卡顿现象？</h3><p>丢包。需要超时重传，慢开始门限减半，然后执行拥塞避免算法。</p><blockquote><p>当拥塞窗口的大小达到慢开始门限时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS. </p></blockquote><h3 id="TCP粘包"><a href="#TCP粘包" class="headerlink" title="TCP粘包"></a>TCP粘包</h3><h4 id="什么是TCP粘包问题？"><a href="#什么是TCP粘包问题？" class="headerlink" title="什么是TCP粘包问题？"></a>什么是TCP粘包问题？</h4><p>发送方包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾。</p><h4 id="造成TCP粘包的原因"><a href="#造成TCP粘包的原因" class="headerlink" title="造成TCP粘包的原因"></a>造成TCP粘包的原因</h4><p>（1）发送方原因</p><p>TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：</p><ul><li><p>只有上一个分组得到确认，才会发送下一个分组</p></li><li><p>收集多个小分组，在一个确认到来时一起发送</p></li></ul><p>（2）接收方原因</p><p>TCP接收到数据包时，应用层并不会立即处理。</p><p>数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。</p><p>如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。</p><h4 id="什么时候需要处理粘包现象？"><a href="#什么时候需要处理粘包现象？" class="headerlink" title="什么时候需要处理粘包现象？"></a>什么时候需要处理粘包现象？</h4><ul><li>如果发送方发送的多组数据本来就是同一块数据的不同部分，比如一个文件的多个部分，不需要处理粘包</li><li>如果多个分组毫不相干，甚至是并列关系，需要处理粘包</li></ul><h4 id="如何处理粘包现象？"><a href="#如何处理粘包现象？" class="headerlink" title="如何处理粘包现象？"></a>如何处理粘包现象？</h4><p>（1）发送方</p><p>通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭。</p><p>（2）接收方应用层</p><p>应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。</p><p>解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据。</p><h3 id="TCP-半包"><a href="#TCP-半包" class="headerlink" title="TCP 半包"></a>TCP 半包</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><ul><li>MSS/MTU限制</li><li>程序写入数据的字节大小大于套接字发送缓冲区的大小</li></ul><h4 id="应用层解决"><a href="#应用层解决" class="headerlink" title="应用层解决"></a>应用层解决</h4><p>（1）在包尾增加分割符，比如回车换行符进行分割。<br>（2）消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格<br>（3）将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段。</p><h4 id="UDP会不会产生粘包问题呢？"><a href="#UDP会不会产生粘包问题呢？" class="headerlink" title="UDP会不会产生粘包问题呢？"></a>UDP会不会产生粘包问题呢？</h4><p>TCP采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的。</p><p>UDP面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。</p><h3 id="HTTP可以使用UDP吗？"><a href="#HTTP可以使用UDP吗？" class="headerlink" title="HTTP可以使用UDP吗？"></a>HTTP可以使用UDP吗？</h3><p>不可以，HTTP需要基于可靠的传输协议，而UDP不可靠</p><h3 id="UDP协议应用"><a href="#UDP协议应用" class="headerlink" title="UDP协议应用"></a>UDP协议应用</h3><ul><li>DHCP。一般的获取 IP 地址都是内网请求，而且一次获取不到IP 又没事，过一会儿还有机会。</li><li>PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。  </li></ul><h3 id="如何在应用层保证udp可靠传输"><a href="#如何在应用层保证udp可靠传输" class="headerlink" title="如何在应用层保证udp可靠传输"></a>如何在应用层保证udp可靠传输</h3><p>最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理时：</p><ul><li>1、实现确认机制，确保数据发送到对端</li><li>2、实现发送和接收缓冲区，主要是用户超时重传。</li></ul><h3 id="面向连接和无连接的区别"><a href="#面向连接和无连接的区别" class="headerlink" title="面向连接和无连接的区别"></a>面向连接和无连接的区别</h3><p>面向连接的协议会先建立连接。例如，TCP 会三次握手，而 UDP 不会。</p><p>建立连接，是为了建立一定的数据结构来维护双方交互的状态。</p><h3 id="TCP如何保证传输的可靠性"><a href="#TCP如何保证传输的可靠性" class="headerlink" title="TCP如何保证传输的可靠性"></a>TCP如何保证传输的可靠性</h3><ol><li>数据包校验：如果接收方检测到校验和有差错，则TCP段会被直接丢弃。</li><li>对失序数据包重新排序（TCP报文具有序列号）</li><li>丢弃重复数据</li><li>应答机制：接收方收到数据之后，会发送一个确认；</li><li>超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；或者是快速重传；</li><li>流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出</li><li>拥塞控制：当网络拥塞时，减少数据的发送</li></ol><h3 id="TCP-keepalive实现原理"><a href="#TCP-keepalive实现原理" class="headerlink" title="TCP keepalive实现原理"></a>TCP keepalive实现原理</h3><p>可以检测死连接，TCP会在空闲了一定时间后发送数据给对方。</p><ol><li>如果主机可达，对方就会响应ACK应答。</li><li>如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。</li><li>如果可达，但应用程序崩溃，对方就发FIN消息。</li><li>如果对方主机不响应ack/rst，继续发送直到超时，就撤消连接。默认二个小时。</li></ol><h3 id="TCP的延迟ACK机制？"><a href="#TCP的延迟ACK机制？" class="headerlink" title="TCP的延迟ACK机制？"></a>TCP的延迟ACK机制？</h3><p>接收方在收到数据后，并不会立即回复ACK，而是延迟一定时间。</p><ul><li>ACK是可以合并的，如果连续收到两个TCP包，只要回复最终的ACK就可以了，降低网络流量。</li><li>如果接收方有数据要发送，在发送数据的TCP数据包里，带上ACK信息。可以避免ACK以一个单独的TCP包发送，减少网络流量。</li></ul><h3 id="对于tcp来说，服务端断电和进程挂掉有什么区别？"><a href="#对于tcp来说，服务端断电和进程挂掉有什么区别？" class="headerlink" title="对于tcp来说，服务端断电和进程挂掉有什么区别？"></a>对于tcp来说，服务端断电和进程挂掉有什么区别？</h3><p><strong>服务进程crash</strong>：服务端会发送RST报文</p><p><strong>进程结束：</strong>服务端发送FIN报文</p><p><strong>主机关机</strong>：init进程会给所有进程发送SIGTERM信号，等待一段时间，然后再给所有仍在运行的进程发送SIGKILL信号。同进程结束。</p><p><strong>主机宕机</strong>：服务器始终不能应答</p><p><strong>主机宕机后重启</strong>：收到不存在连接的报文，响应RST。</p><h3 id="单机最大tcp连接数"><a href="#单机最大tcp连接数" class="headerlink" title="单机最大tcp连接数"></a>单机最大tcp连接数</h3><p>系统用一个4四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}。</p><p>client最大tcp连接数：1-65535</p><p>server最大tcp连接数：客户端ip数×客户端port数。在实际环境中，受到内存和允许的文件描述符个数限制。</p><h3 id="SYN泛洪攻击"><a href="#SYN泛洪攻击" class="headerlink" title="SYN泛洪攻击"></a>SYN泛洪攻击</h3><p>攻击端利用伪造的IP地址向被攻击端发出三次握手请求，而被攻击端发出的响应报文将永远发送不到目的地。</p><p>被攻击端在等待关闭这个连接的过程中消耗了资源，如果有成千上万的这种连接，主机资源将被耗尽，从而达到攻击的目的。</p><p><strong>解决方法</strong></p><p>1、降低SYN timeout时间，使得主机尽快释放半连接的占用<br>2、采用SYN cookie设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文<br>3、使用防火墙或者代理设备，缓冲SYN洪泛攻击</p><h3 id="MSL、TTL和RTT的区别"><a href="#MSL、TTL和RTT的区别" class="headerlink" title="MSL、TTL和RTT的区别"></a>MSL、TTL和RTT的区别</h3><ul><li>MSL ，Maximum Segment Lifetime，报文最大生存时间，报文在网络上存在的最长时间，超过这个时间报文将被丢弃。</li><li>ip头中有一个TTL， time to live，一个ip数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。</li><li>RTT，round-trip time，客户端到服务器往返所花时间</li></ul><h3 id="多久没收到会丢失重传，往返时间怎么预估"><a href="#多久没收到会丢失重传，往返时间怎么预估" class="headerlink" title="多久没收到会丢失重传，往返时间怎么预估"></a>多久没收到会丢失重传，往返时间怎么预估</h3><p>每个数据包都有相应的计时器，一旦超过 RTO 而没有收到 ACK，就重发该数据包。</p><ul><li>估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。</li></ul><h3 id="TCP和UDP可以同时监听相同的端口吗"><a href="#TCP和UDP可以同时监听相同的端口吗" class="headerlink" title="TCP和UDP可以同时监听相同的端口吗"></a>TCP和UDP可以同时监听相同的端口吗</h3><p>可以。linux是以协议、ip、端口来绑定端口的，所以不同协议相同的ip和端口也是可以绑定成功的。</p><h2 id="QUIC"><a href="#QUIC" class="headerlink" title="QUIC"></a>QUIC</h2><h3 id="自定义连接机制"><a href="#自定义连接机制" class="headerlink" title="自定义连接机制"></a>自定义连接机制</h3><p>QUIC 维护连接，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化的时候，只要 ID 不变，就不需要重新建立连接。</p><p>避免了当手机信号不稳定或者在 WIFI 和移动网络切换时，导致重连，从而进行再次的三次握手。</p><h3 id="自定义重传机制"><a href="#自定义重传机制" class="headerlink" title="自定义重传机制"></a>自定义重传机制</h3><p>QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。</p><p>发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。</p><h3 id="无阻塞的多路复用"><a href="#无阻塞的多路复用" class="headerlink" title="无阻塞的多路复用"></a>无阻塞的多路复用</h3><p>同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。</p><p>一个连接上的多个 stream 之间没有依赖。</p><p>假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。</p><h3 id="自定义流量控制"><a href="#自定义流量控制" class="headerlink" title="自定义流量控制"></a>自定义流量控制</h3><h2 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h2><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><h4 id="解析流程"><a href="#解析流程" class="headerlink" title="解析流程"></a>解析流程</h4><p>从客户端到本地DNS服务器属于递归查询，而DNS服务器之间是迭代查询。</p><ul><li>客户端会发出 DNS 请求，发给本地域名服务器。本地 DNS 由你的网络服务商，如电信、移动等自动分配。</li><li>本地 DNS 收到来自客户端的请求。如果能找到 ，它直接就返回 IP 地址。如果没有，本地 DNS 请求根域名服务器。根域名服务器是最高层次的，全球共有 13 套。</li><li>根 DNS 收到来自本地 DNS 的请求，发现后缀是 <strong>.com</strong>，返回对应顶级域名服务器的地址</li><li>本地 DNS 请求<strong>顶级域名服务器</strong>，顶级域名服务器负责管理二级域名，比如163.com。顶级域名服务器返回对应的权威 DNS 服务器的地址</li><li>本地 DNS 请求权威 DNS 服务器，权限 DNS 服务器返回 IP 地址到本地 DNS。</li><li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li></ul><h4 id="如果dns解析得到ip地址之后请求超时，那么会重新解析吗"><a href="#如果dns解析得到ip地址之后请求超时，那么会重新解析吗" class="headerlink" title="如果dns解析得到ip地址之后请求超时，那么会重新解析吗"></a>如果dns解析得到ip地址之后请求超时，那么会重新解析吗</h4><p>浏览器得到了域名对应的 IP 地址，并将 IP 地址缓存起来。不需要重新解析</p><h4 id="DNS使用TCP协议还是UDP协议"><a href="#DNS使用TCP协议还是UDP协议" class="headerlink" title="DNS使用TCP协议还是UDP协议"></a>DNS使用TCP协议还是UDP协议</h4><p><strong>区域传送时使用TCP</strong><br>辅域名服务器会定时向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。 TCP保证了数据的准确性。 </p><p><strong>域名解析时使用UDP协议</strong><br>客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快。</p><p>DNS 查询选择 UDP 或者 TCP 两种不同协议时的主要原因：</p><ul><li>UDP 协议<ul><li>DNS 查询的数据包较小；</li><li>UDP 协议的额外开销小、有着更好的性能表现；</li></ul></li><li>TCP 协议<ul><li>导致 DNS 响应经常超过 MTU 造成数据的分片和丢失，需要依靠可靠的 TCP 协议完成数据的传输；</li><li>数据不断增加，TCP 协议头以及三次握手带来的额外开销比例逐渐降低；</li></ul></li></ul><h4 id="根DNS服务器如何承受并发"><a href="#根DNS服务器如何承受并发" class="headerlink" title="根DNS服务器如何承受并发"></a>根DNS服务器如何承受并发</h4><p>先访问DNS缓存、本地DNS服务器。同时有13台根DNS服务器作负载均衡。</p><p>根DNS服务器只存储一级域名的映射，实际不做域名的解析。</p><h4 id="DNS劫持是什么"><a href="#DNS劫持是什么" class="headerlink" title="DNS劫持是什么"></a>DNS劫持是什么</h4><p>域名劫持，DNS重定向。DNS查询没有得到正确的解析，以致引导user访问到恶意的网站，从而窃取用户隐私，或者进行某些恶意的操作。</p><h4 id="DNS的防范劫持"><a href="#DNS的防范劫持" class="headerlink" title="DNS的防范劫持"></a>DNS的防范劫持</h4><ul><li>开启防火墙等，防止恶意软件，木马病毒感染计算机</li><li>改变路由器默认密码，防止攻击者修改路由器的DNS配置指向恶意的DNS服务器</li></ul><h4 id="DNS缺点"><a href="#DNS缺点" class="headerlink" title="DNS缺点"></a>DNS缺点</h4><p> <strong>域名缓存问题</strong>：直接返回缓存数据。上次进行的缓存，不一定是这次离最近的地方，可能会绕远路。</p><p><strong>解析延迟</strong>：DNS的查询过程需要递归遍历多个DNS服务器，才能获得最终结果。可能会带来一定的延时。</p><p><strong>域名转发问题</strong>：如果是A运营商将解析的请求转发给B运营商，B去权威DNS服务器查询的话，权威服务器会认为你是B运营商的，就返回了B运营商的网站地址，结果每次都会跨运营商。</p><p><strong>出口NAT问题</strong>：做了网络地址转化后，没法通过地址来判断客户到底是哪个运营商，极有可能误判运营商，导致跨运营商访问。</p><h3 id="HTTPDNS"><a href="#HTTPDNS" class="headerlink" title="HTTPDNS"></a>HTTPDNS</h3><p>HTTPDNS使用HTTP与DNS服务器交互，代替传统的基于UDP的DNS协议，域名解析请求直接发送到HTTPDNS服务端，从而绕过运营商的Local DNS</p><h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><p><strong>防止域名劫持</strong></p><p>由于 HttpDns 是通过 IP 直接请求 HTTP 获取服务器 A 记录地址，不存在向本地运营商询问 domain 解析过程，所以从根本避免了劫持问题。</p><p><strong>精准调度</strong></p><p>HTTPDNS能够直接获取到用户的IP地址，从而实现精确定位与导流</p><p><strong>用户连接失败率下降</strong></p><p>通过算法降低以往失败率过高的服务器排序。</p><h3 id="FTP"><a href="#FTP" class="headerlink" title="FTP"></a>FTP</h3><p>文件传输协议（File Transfer Protocol，FTP）是用于在网络上进行文件传输的一套标准协议， 使用 TCP 传输，为数据传输提供可靠保证。</p><h4 id="Port模式"><a href="#Port模式" class="headerlink" title="Port模式"></a><strong>Port模式</strong></h4><ul><li>FTP 客户端首先和服务器的TCP 21端口建立连接，用来发送命令</li><li>客户端需要接收数据的时候在这个通道上发送PORT命令。告知服务端接收端口。服务器端使用TCP 20端口向客户端端口发送连接请求，建立一条数据链路来传送数据。</li></ul><h4 id="Passive模式"><a href="#Passive模式" class="headerlink" title="Passive模式"></a><strong>Passive模式</strong></h4><ul><li>客户端向服务器的FTP端口发送连接请求，服务器接受连接，建立一条命令链路。</li><li>服务器在命令链路上用PASV命令告诉客户端端口号。于是客户端向服务器的端口发送连接请求，建立一条数据链路来传送数据。</li></ul><h3 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h3><p>用于计算机之间的加密登录。采用了公钥加密。</p><p>整个过程是这样的：</p><p>（1）远程主机收到用户的登录请求，把自己的公钥发给用户。</p><p>（2）用户使用这个公钥，将登录密码加密后，发送回来。</p><p>（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。</p><p>如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。</p><h4 id="中间人攻击"><a href="#中间人攻击" class="headerlink" title="中间人攻击"></a>中间人攻击</h4><p><strong>口令登录</strong></p><p>确认host主机的真实性：首次连接确认公钥指纹。</p><p><strong>公钥登录</strong></p><p>不需要输入密码。</p><ol><li>是用户将自己的公钥储存在远程主机上。</li><li>登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。</li><li>远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell。</li></ol><h2 id="路由协议"><a href="#路由协议" class="headerlink" title="路由协议"></a>路由协议</h2><p>路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；</p><p>动态路由主流算法有两种，距离矢量算法和链路状态算法。BGP 协议和OSPF 协议。</p><h2 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h2><h3 id="DES加密算法"><a href="#DES加密算法" class="headerlink" title="DES加密算法"></a>DES加密算法</h3><p>DES（Data Encryption Standard）数据加密标准算法，是对称性加密算法。</p><p><strong>工作原理</strong></p><p>当需要加密的时候就用key对data加密，生成密码形式的data作为输出结果</p><p>解密就需要再利用key对data进行解密获得原文密码作为输出。</p><h3 id="MD5加密算法"><a href="#MD5加密算法" class="headerlink" title="MD5加密算法"></a>MD5加密算法</h3><p>Message-Digest-Algorithm 信息摘要算法第五代。Hash算法一代，是一种单向加密算法，可以将输入的信息加密转换为128位固定长度的散列值，一般用于检验数据传输过程中的完整性。</p><p><strong>优势：</strong></p><ul><li>防篡改，在传输过程中一旦被串改，那么计算出的MD5值一定不同。</li><li>计算速度快。加密速度快，不需要秘钥。</li></ul><p><strong>缺点:</strong></p><ul><li>仍然存在两种不同数据会发生碰撞。</li><li>MD5的安全性：直接MD5存入数据库，若数据库被破解，通过MD5反查会查到密码，需要随机盐值的配合。</li></ul><h3 id="SHA1加密算法"><a href="#SHA1加密算法" class="headerlink" title="SHA1加密算法"></a>SHA1加密算法</h3><p>SHA-1是一种数据加密算法，该算法的思想是取一串输入码，并把它们转化为长度较短、位数固定的输出序列即散列值的过程。</p><h3 id="RSA加密算法"><a href="#RSA加密算法" class="headerlink" title="RSA加密算法"></a>RSA加密算法</h3><p>RSA是一种非对称加密算法。</p><p>目前最有影响力的公钥加密算法，将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，因此可以将乘积作为加密公钥，而两个大素数组合成私钥。 公钥加密，私钥解密。</p><h3 id="为什么密码加盐"><a href="#为什么密码加盐" class="headerlink" title="为什么密码加盐"></a>为什么密码加盐</h3><p>Salt 可以是任意字母、数字、或是字母或数字的组合，但必须是随机产生的，每个用户的 Salt 都不一样，用户注册的时候，数据库中存入 MD5（明文密码 + Salt）。</p><p>即便数据库泄露了，但是由于密码都是加了 Salt 之后的散列，数据字典已经无法直接匹配，明文密码被破解出来的概率也大大降低</p><h2 id="为什么网络中会发生丢包？"><a href="#为什么网络中会发生丢包？" class="headerlink" title="为什么网络中会发生丢包？"></a>为什么网络中会发生丢包？</h2><p><strong>物理线路故障</strong></p><p><strong>设备故障</strong>：如网卡是坏的，交换机的某个端口出现了物理故障，光模块等。接收到的分组校验出错</p><p><strong>网络拥塞</strong>：分组在网络中超出最大存活时间、路由器接收分组数量达到上限后，会丢弃多余分组</p><h2 id="小端和大端字节序，这个对什么产生影响，做什么事情会出现问题"><a href="#小端和大端字节序，这个对什么产生影响，做什么事情会出现问题" class="headerlink" title="小端和大端字节序，这个对什么产生影响，做什么事情会出现问题"></a>小端和大端字节序，这个对什么产生影响，做什么事情会出现问题</h2><ul><li><strong>大端字节序</strong>：高位字节在前，低位字节在后，这是人类读写数值的方法。</li><li><strong>小端字节序</strong>：低位字节在前，高位字节在后</li></ul><p>计算机一般先处理低位字节，效率比较高，因为计算都是从低位开始的。</p><p>人类还是习惯大端字节序。所以，其他的场合几乎都是大端字节序，比如网络传输和文件储存。</p><h2 id="传一个字符串，定义为大端和小端一样吗？如果传一个数字有影响吗？"><a href="#传一个字符串，定义为大端和小端一样吗？如果传一个数字有影响吗？" class="headerlink" title="传一个字符串，定义为大端和小端一样吗？如果传一个数字有影响吗？"></a>传一个字符串，定义为大端和小端一样吗？如果传一个数字有影响吗？</h2><p>大小端是面向多字节类型定义的，比如2字节、4字节、8字节整型、长整型、浮点型等，单字节的字符串一般不用考虑。</p><h2 id="网卡接收数据流程"><a href="#网卡接收数据流程" class="headerlink" title="网卡接收数据流程"></a>网卡接收数据流程</h2><ul><li><strong>1：</strong> 数据包从外面网络进入物理网卡。如果目的地址不是该网卡（且该网卡没有开启混杂模式）该包会被网卡丢弃。</li><li><strong>2：</strong> 网卡将数据包通过DMA的方式写入到指定的内存地址，该地址由网卡驱动分配并初始化。</li><li><strong>3：</strong> 网卡通过硬件中断通知CPU，告诉它有数据来了</li><li><strong>4：</strong> CPU根据中断表，调用中断函数，中断函数会调用网卡驱动程序中相应的函数</li><li><strong>5：</strong> 先禁用网卡的中断，表示驱动程序已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知CPU了，这样可以提高效率，避免CPU不停的被中断。</li><li><strong>6：</strong> 启动软中断。硬件中断处理函数返回。（由于硬中断处理程序执行的过程中不能被中断，所以如果它执行时间过长，会导致CPU没法响应其它硬件的中断，于是内核引入软中断，耗时的部分移到软中断处理函数里面来慢慢处理。）</li><li><strong>7：</strong> 内核中的ksoftirqd进程专门负责软中断的处理，读取写到内存中的数据包。</li><li><strong>8：</strong> 调用协议栈相应的函数，将数据包交给协议栈处理。</li><li>8.1：进入网络层，如果目的IP是本地IP，发送到传输层</li><li>8.2：根据IP和端口找对应的socket，通知socket数据包已经准备好，如果没有找到相应的socket，那么该数据包将会被丢弃。</li><li>8.3：应用层一般有两种方式接收数据，一种是recvfrom函数阻塞在那里等着数据来，这种情况下当socket收到通知后，recvfrom就会被唤醒，然后读取接收队列的数据；另一种是通过epoll或者select监听相应的socket，当收到通知后，再调用recvfrom函数去读取接收队列的数据。</li><li><strong>9：</strong> 待内存中的所有数据包被处理完成后（即poll函数执行完成），启用网卡的硬中断，这样下次网卡再收到数据的时候就会通知CPU</li></ul><h2 id="WebSocket-和-HTTP-的区别"><a href="#WebSocket-和-HTTP-的区别" class="headerlink" title="WebSocket 和 HTTP 的区别"></a>WebSocket 和 HTTP 的区别</h2><ul><li>http 协议必须要有客户端发起，然后服务器返回结果。</li><li>为了解决客户端发起多个 http 请求轮训问题， webSocket 协议下客服端和浏览器可以同时发送信息。降低了服务器压力，减少了部分多余信息。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/weixin_41047704/article/details/85340311" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41047704/article/details/85340311</a></p><p><a href="https://blog.csdn.net/gdutxiaoxu/article/details/107393249" target="_blank" rel="noopener">https://blog.csdn.net/gdutxiaoxu/article/details/107393249</a></p><p><a href="https://blog.csdn.net/weixin_38035852/article/details/81667160" target="_blank" rel="noopener">https://blog.csdn.net/weixin_38035852/article/details/81667160</a></p>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flask</title>
      <link href="/2021/04/22/flask-mian-shi/"/>
      <url>/2021/04/22/flask-mian-shi/</url>
      
        <content type="html"><![CDATA[<h1 id="Flask框架"><a href="#Flask框架" class="headerlink" title="Flask框架"></a>Flask框架</h1><h2 id="WEB框架"><a href="#WEB框架" class="headerlink" title="WEB框架"></a>WEB框架</h2><p>它们接收 HTTP 请求，然后分发任务，并生成 HTML，然后返回包含 HTML 的 HTTP 应答。</p><h2 id="应用启动过程"><a href="#应用启动过程" class="headerlink" title="应用启动过程"></a>应用启动过程</h2><ul><li><p><code>run</code> 方法启动了 Flask 应用</p></li><li><p><code>run</code> 方法调用werkzeug 的 <code>run_simple</code> 方法，启动了服务器 <code>BaseWSGIServer</code>。在调用 run_simple 时，Flask 对象把自己 <code>self</code> 作为参数传进去了，在收到请求的时候，就知道调用谁的 <code>__call__</code> 方法。</p></li></ul><h2 id="请求处理过程"><a href="#请求处理过程" class="headerlink" title="请求处理过程"></a>请求处理过程</h2><ul><li><p>默认使用 <code>WSGIRequestHandler</code>类来作为 request handler，在接收到请求时这个类在被 <code>BaseWSGIServer</code> 调用时，会执行<code>execute</code>函数</p></li><li><p><code>execute</code>函数中，把 <code>environ</code> 和 <code>start_response</code> 传入，调用 <code>app</code>的<code>__call__</code> 。</p></li><li><p><code>app</code>的<code>__call__</code>中，调用了 <code>wsgi_app</code>方法（为了中间件）。</p></li></ul><blockquote><p>该方法最终返回的<code>response(environ, start_response)</code>中的response 是<code>werkzueg.response</code> 类的一个实例，是可调用的对象，负责生成最终的可遍历的响应体，并调用 <code>start_response</code> 形成响应头</p></blockquote><ul><li><p><code>wsgi_app</code>方法中 调用 <code>request_context(environ)</code>函数建立了一个 <code>RequestContext</code> <strong>请求上下文对象</strong></p><ul><li><code>RequestContext</code>初始化根据传入的 <code>environ</code> 创建一个 <code>werkzeug.Request</code> 的实例</li></ul></li><li><p>把请求上下文 <code>RequestContext</code>，调用<code>push</code>，压入<code>_request_ctx_stack</code> 栈。（这些操作是为了 flask 在处理多个请求的时候不会混淆）。</p><ul><li><code>_request_ctx_stack</code> 是一个 <code>LocalStack</code> 类的实例，通过<strong>Local实现线程隔离</strong>，隔离是使用了<code>get_ident</code>,属性被保存到每个线程id对应的字典中了。</li></ul></li><li><p><code>wsgi_app</code>方法中 调用  <code>full_dispatch_request</code>方法<strong>请求分发</strong>，开始实际的请求处理过程，这个过程中会生成 <code>response</code>对象来返回给服务器。</p><ul><li><p>调用 <code>try_trigger_before_first_request_functions</code> 方法尝试调用 <code>before_first_request</code> 列表中的函数，只会执行一次</p></li><li><p>调用 <code>preprocess_request</code> 方法，调用 <code>before_request_funcs</code> 列表中所有的方法。（可以检测用户是否登录，未登录使用<code>abort</code>返回错误，则后续不会分发）</p></li><li><p>调用 <code>dispatch_request</code> 方法进行业务请求分发。</p><ul><li><code>_request_ctx_stack.top.request</code>获取请求上下文</li><li>获取请求上下文在的<code>rule</code></li><li>调用 <code>view_functions</code> 中相应的<strong>视图函数</strong>（<code>rule.endpoint</code> 作为键值）并把参数值传入（<code>**req.view_args</code>），视图函数就是开发人员写的API接口了。视图函数的返回值或者错误处理视图函数的返回值会作为<code>rv</code>返回给<code>full_dispatch_request</code>。</li></ul><ul><li>调用<code>finalize_request</code>根据 <code>rv</code> 生成响应<ul><li>调用<code>make_response</code> 方法会查看 rv 是否是要求的返回值类型，否则生成正确的返回类型。</li><li>调用<code>process_response</code> 方法，实现<code>after_request</code>方法的调用</li><li>返回<code>response</code></li></ul></li></ul></li></ul></li></ul><ul><li><p>如果当中出错，就生成相应的错误信息。</p></li><li><p>把<strong>请求上下文</strong>出栈。</p></li></ul><h2 id="视图函数注册"><a href="#视图函数注册" class="headerlink" title="视图函数注册"></a>视图函数注册</h2><p>在程序加载业务代码时，用修饰器 <code>route</code>注册视图函数，并实现 URL 到视图函数的映射。在<code>route</code> 方法中，调用了<code>add_url_rule</code>方法。主要流程如下：</p><ul><li>准备好一个视图函数所支持的 HTTP 方法</li><li>通过 <code>url_rule_class</code> 创建一个 <code>rule</code> 对象，并把这个对象添加到自己的 <code>url_map</code></li></ul><blockquote><p><code>rule</code> 对象是一个保存合法的（Flask 应用所支持的） URL、方法、<code>endpoint</code>（在 <code>**options</code> 中） 及它们的对应关系的数据结构</p><p> <code>url_map</code> 是保存<code>rule</code> 对象的集合</p></blockquote><ul><li><code>view_functions</code>中加入<code>endpoint</code>、视图函数的映射关系</li></ul><p>在 Flask 应用收到请求时，这些被绑定到 url_map 上的 Rule 会被查看，来找到它们对应的视图函数。在 <code>dispatch_request</code> 方法中，从 <code>_request_ctx_stack.top.request</code> 得到 <code>rule</code> 并从这个 <code>rule</code> 找到 <code>endpoint</code>，最终找到用来处理该请求的正确的视图函数的。</p><h2 id="请求的过程总结"><a href="#请求的过程总结" class="headerlink" title="请求的过程总结"></a>请求的过程总结</h2><ul><li><p>在请求发出之前，Flask 注册好了所有的视图函数和 URL映射，服务器在自己身上注册了 Flask 应用。</p></li><li><p>请求到达服务器，服务器准备好 environ 和 make_response 函数，然后调用了自己身上注册的 Flask 应用。</p></li><li><p>通过 <code>__call__</code>中转到 wsgi_app 的方法。它首先通过 environ 创建了请求上下文，并将它推入栈，使得 flask 在处理当前请求的过程中都可以访问到这个请求上下文。</p></li><li><p><code>full_dispatch_request</code>中开始处理这个请求，依次调用 <code>before_first_request_funcs</code> <code>before_request_funcs view_functions</code>中的函数，并最终通过 <code>finalize_request</code> 生成一个 <code>response</code>对象，调用<code>after_request_funcs</code>进行 response 生成后的后处理。</p></li><li><p>Flask 调用这个 response 对象，最终调用了 make_response 函数，并返回了一个可遍历的响应内容。</p></li><li><p>服务器发送响应。</p></li></ul><h2 id="Flask-和-werkzeug关系"><a href="#Flask-和-werkzeug关系" class="headerlink" title="Flask 和 werkzeug关系"></a>Flask 和 werkzeug关系</h2><p>Flask 和 werkzeug 是强耦合的，一些非常细节的工作，其实都是 werkzeug 库完成的：</p><ul><li><p>封装 Response 和 Request 类型供 Flask 使用，在实际开发中，我们在请求和响应对象上的操作，调用的其实是 werkzeug 的方法。</p></li><li><p>实现 URL到视图函数的映射，并且能把 URL中的参数传给该视图函数。我们看到了 Flask 的 url_map 属性并且看到了它如何绑定视图函数和错误处理函数，但是具体的映射规则的实现，和在响应过程中的 URL解析，都是由 werkzeug 完成的。</p></li><li><p>通过 _request_ctx_stack 对 Flask 实现线程保护。</p></li></ul><h2 id="默认session处理机制"><a href="#默认session处理机制" class="headerlink" title="默认session处理机制?"></a>默认session处理机制?</h2><p>flask的session是基于cookie的会话保持。<strong>简单的原理</strong>即：</p><p>当客户端进行第一次请求时，客户端的HTTP request（cookie为空）到服务端，服务端创建session，视图函数中填写session，请求结束时，session内容填写入response的cookie中并返回给客户端，客户端的cookie中便保存了用户的数据。</p><p>当同一客户端再次请求时， 客户端的HTTP request中cookie已经携带数据，视图函数根据cookie中值做相应操作（如已经携带用户名和密码就可以直接登陆）。</p><p><strong>请求第一次来时，session是什么时候生成的？存放在哪里？</strong></p><ul><li><p>客户端的请求进来时，会生成RequestContext对象。其中定义了session，且初值为None。</p></li><li><p>在ctx.push()函数中，所有和 session 有关的调用，都转发到 <code>session_interface</code> 的方法调用上，而默认的 <code>session_inerface</code>为<code>SecureCookieSessionInterface()</code></p><ul><li>执行<code>SecureCookieSessionInterface.open_session()</code>来生成默认session对象<ul><li>获取session签名的算法</li><li>获取<em>request.cookies</em>，请求第一次来时，<strong>request.cookies为空</strong>，即返回<code>SecureCookieSession</code>,session就是一个特殊的字典</li></ul></li></ul></li></ul><p><strong>当请求第二次来时，session生成的是什么？</strong></p><p><strong>request.cookies不为空</strong>，, 获取cookie的有效时长，如果cookie依然有效，通过与写入时同样的签名算法将cookie中的值解密出来并写入字典并返回中，若cookie已经失效，则仍然返回’空字典’。</p><p><strong>特殊的SecureCookieSession字典有那些功能？如何实现的？</strong></p><p><code>permanent</code>（flask 插件会用到这个变量）、<code>modified</code>（表明实例是否被更新过，如果更新过就要重新计算并设置 cookie，因为计算过程比较贵，所以如果对象没有被修改，就直接跳过）</p><p><code>SecureCookieSession</code> 是基于 <code>CallbackDict</code> 实现的，这个类可以指定一个函数作为 on_update 参数，每次有字典操作的时候（<code>__setitem__</code>、<code>__delitem__</code>、clear、popitem、update、pop、setdefault）会调用这个函数。<br><strong>session什么时候写入cookie中？session的生命周期？</strong></p><p><code>process_response</code>判断session是否为空，如果不为空，则执行<code>save_session()</code>，其中通过<code>response.set_cookie</code>将session写入。这样便完成session的写入response工作，并由response返回至客户端。</p><h2 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h2><h3 id="flask上下文种类"><a href="#flask上下文种类" class="headerlink" title="flask上下文种类"></a><strong>flask上下文种类</strong></h3><p>current_app、g 是应用上下文。 request、session 是请求上下文。</p><h3 id="为什么要用上下文"><a href="#为什么要用上下文" class="headerlink" title="为什么要用上下文"></a>为什么要用上下文</h3><p>flask从客户端获取到请求时，要让视图函数能访问一些对象，这样才能处理请求。例如请求对象就是一个很好的例子。要让视图函数访问请求对象，一个显而易见的方法就是将其作为参数传入视图函数，不过这回导致程序中的每个视图函数都增加一个参数，为了避免大量可有可无才参数把视图函数弄得一团糟，flask使用上下文临时把某些对象变为全局可访问（只是当前线程的全局可访问）。</p><h3 id="请求上下文和应用上下文两者区别"><a href="#请求上下文和应用上下文两者区别" class="headerlink" title="请求上下文和应用上下文两者区别"></a><strong>请求上下文和应用上下文两者区别</strong></h3><p>请求上下文:保存了客户端和服务器交互的数据。request处理http请求，session  处理用户信息。LocalStack用来存储请求上下文</p><p>应用上下文:flask 应用程序运行过程中，保存一些配置信息，比如程序名、数据库连接、应用信息等。</p><p>g 用来存储开发者自定义的一些数据，不用通过传参的方式获取参数了。current_app 当前激活程序的程序实例。LocalStack用来存储应用上下文。</p><h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a><strong>生命周期</strong></h3><ul><li>current_app的生命周期最长，只要当前程序实例还在运行，都不会失效。</li><li>Request和g的生命周期为一次请求期间，当请求处理完成后，生命周期也就完结了</li><li>Session就是传统意义上的session了。只要它还未失效（用户未关闭浏览器、没有超过设定的失效时间），那么不同的请求会共用同样的session。</li></ul><h3 id="为什么上下文需要放在栈中？"><a href="#为什么上下文需要放在栈中？" class="headerlink" title="为什么上下文需要放在栈中？"></a><strong>为什么上下文需要放在栈中？</strong></h3><p>1.应用上下文：</p><p>Flask底层是基于werkzeug，werkzeug是可以包含多个app的，所以这时候用一个栈来保存，如果你在使用app1，那么app1应该是要在栈的顶部，如果用完了app1那么app应该从栈中删除，方便其他代码使用下面的app。</p><p>2.请求上下文：</p><p>如果在写测试代码，或者离线脚本的时候，我们有时候可能需要创建多个请求上下文，这时候就需要存放到一个栈中了。使用哪个请求上下文的时候，就把对应的请求上下文放到栈的顶部，用完了就要把这个请求上下文从栈中移除掉。</p><h3 id="上下文管理流程"><a href="#上下文管理流程" class="headerlink" title="上下文管理流程?"></a>上下文管理流程?</h3><p>每次有请求过来的时候，flask 会先创建当前线程或者进程需要处理的两个重要上下文对象，把它们保存到隔离的栈里面，这样视图函数进行处理的时候就能直接从栈上获取这些信息。</p><p>1.请求到来时，将session和request封装到ctx对象中；</p><p>2.对session作补充；</p><p>3.将包含了request和session的ctx对象放到一个容器中（每一个请求都会根据线程/协程加一个惟一标识）；</p><p>4.视图函数使用的时候须要根据当前线程或协程的惟一标识，获取ctx对象，再取ctx对象中取request和session（视图函数使用的时候，须要根据当前线程获取数据。）</p><p>5.请求结束时，根据当前线程/协程的惟一标记，将这个容器上的数据移除。</p><h3 id="为什么要把-request-context-和-application-context-分开？每个请求不是都同时拥有这两个上下文信息吗？"><a href="#为什么要把-request-context-和-application-context-分开？每个请求不是都同时拥有这两个上下文信息吗？" class="headerlink" title="为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？"></a>为什么要把 request context 和 application context 分开？每个请求不是都同时拥有这两个上下文信息吗？</h3><p>虽然在实际运行中，每个请求对应一个 request context 和一个 application context，但是在测试或者 python shell 中运行的时候，用户可以单独创建 request context 或者 application context，这种灵活度方便用户的不同的使用场景</p><h3 id="为什么Local对象中的stack-维护成一个列表？"><a href="#为什么Local对象中的stack-维护成一个列表？" class="headerlink" title="为什么Local对象中的stack 维护成一个列表？"></a>为什么Local对象中的stack 维护成一个列表？</h3><p>测试的时候可以添加多个上下文，另外一个原因是 flask 可以<a href="http://flask.pocoo.org/docs/0.12/patterns/appdispatch/#combining-applications" target="_blank" rel="noopener">多个 application 同时运行</a></p><h3 id="Flask中多app应用是怎么完成？"><a href="#Flask中多app应用是怎么完成？" class="headerlink" title="Flask中多app应用是怎么完成？"></a>Flask中多app应用是怎么完成？</h3><p>请求进来时，可以根据URL的不同，交给不同的APP处理。</p><p>使用Flask类建立不一样的app对象，而后借助DispatcherMiddleware类来实现。</p><h3 id="Local对象和threading-local对象的区别"><a href="#Local对象和threading-local对象的区别" class="headerlink" title="Local对象和threading.local对象的区别"></a>Local对象和threading.local对象的区别</h3><p>Thread Local 则是一种特殊的对象，它的“状态”对线程隔离 —— 也就是说每个线程对一个 Thread Local 对象的修改都不会影响其他线程。原理也非常简单，只要以线程的 ID 来保存多份状态字典即可。</p><p>werkzeug.local.Local和threading.local<strong>区别</strong>如下：</p><p>（1）werkzeug使用了自定义的<code>__storage__</code>保存不同线程下的状态</p><p>（2）werkzeug提供了释放本地线程的release_local方法</p><p>（3）werkzeug通过get_ident函数来获得线程标识符</p><h4 id="为什么造轮子"><a href="#为什么造轮子" class="headerlink" title="为什么造轮子"></a><strong>为什么造轮子</strong></h4><p>WSGI不保证每个请求必须由一个线程来处理，如果WSGI服务器不是每个线程派发一个请求，而是每个协程派发一个请求，thread local变量可能会造成请求间数据相互干扰，因为一个线程中存在多个请求。</p><h4 id="除-了Local"><a href="#除-了Local" class="headerlink" title="除 了Local"></a>除 了Local</h4><p>Werkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。</p><p>LocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。</p><p>LocalProxy用于代理Local对象和LocalStack对象，而所谓代理就是作为中间的代理人来处理所有针对被代理对象的操作。LocalStack无法再动态更新了，而使用Proxy实现了动态更新。重载了绝大多数操作符，以便在调用LocalProxy的相应操作时，通过<code>_get_current_object</code> method来获取真正代理的对象，然后再进行相应操作</p><h2 id="蓝图"><a href="#蓝图" class="headerlink" title="蓝图"></a>蓝图</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul><li><p>将不同的功能模块化，构建大型应用</p></li><li><p>优化项目结构</p></li><li><p>增强可读性,易于维护</p></li></ul><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><ul><li>新增了一个xxx.py的文件，实例化Blueprint应用</li><li>xxx.py编写视图函数，使用Blueprint应用示例设置路由</li><li>run.py中，注册蓝图示例</li></ul><h2 id="如何在Flask中访问会话"><a href="#如何在Flask中访问会话" class="headerlink" title="如何在Flask中访问会话?"></a>如何在Flask中访问会话?</h2><p>用户第一次请求后，将产生的状态信息保存在session中，这时可以把session当做一个容器，它保存了正在使用的所有用户的状态信息；这段状态信息分配了一个唯一的标识符用来标识用户的身份，将其保存在响应对象的cookie中；当第二次请求时，解析cookie中的标识符，拿到标识符后去session找到对应的用户的信息。</p><p>在flask中，如果我们想要获取session信息，直接通过flask的session获取就可以了，这是因为session是一个代理对象，代理当前请求上下文的session属性。</p><h2 id="wsgi"><a href="#wsgi" class="headerlink" title="wsgi"></a>wsgi</h2><p>Web服务器和Web应用程序或框架之间的一种简单而通用的接口。描述了web server如何与web application交互、web application如何处理请求。</p><p><strong>应用程序端</strong></p><p>WSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了<code>__call__</code> 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。</p><h2 id="Werkzeug"><a href="#Werkzeug" class="headerlink" title="Werkzeug"></a>Werkzeug</h2><p>HTTP 和 WSGI 相关的工具集，可以用来编写 web 框架，可以直接使用它提供的一些帮助函数。</p><p>werkzeug 提供了 python web WSGI 开发相关的功能：</p><ul><li><p>路由处理：如何根据请求 URL 找到对应的视图函数</p></li><li><p>request 和 response 封装: 提供更好的方式处理request和生成response对象</p></li><li><p>自带的 WSGI server: 测试环境运行WSGI应用</p></li></ul><h2 id="RESTful"><a href="#RESTful" class="headerlink" title="RESTful"></a>RESTful</h2><p>REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。</p><p>（1）每一个URI代表一种资源；</p><p>（2）客户端和服务器之间，传递这种资源的某种表现层；</p><p>（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。</p><p>“资源”是一种信息实体，它可以有多种外在表现形式。<strong>我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。</strong></p><p>所有的状态都保存在服务器端。因此，<strong>如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。</strong></p><h2 id="安全漏洞"><a href="#安全漏洞" class="headerlink" title="安全漏洞"></a>安全漏洞</h2><h3 id="XSS-跨站脚本攻击"><a href="#XSS-跨站脚本攻击" class="headerlink" title="XSS 跨站脚本攻击"></a>XSS 跨站脚本攻击</h3><p><strong>原理</strong></p><ul><li>恶意攻击者将代码通过网站注入到其他用户浏览器中的攻击方式。</li><li>攻击者会把恶意JavaScript 代码作为普通数据放入到网站数据库中；</li><li>其他用户在获取和展示数据的过程中，运行JavaScript 代码；</li><li>JavaScript 代码执行恶意代码（调用恶意请求，发送数据到攻击者等等）。</li></ul><p><strong>防御</strong></p><p>根本的解决方法：<strong>从输入到输出都需要过滤、转义。</strong></p><ol><li><p>对输入内容的特定字符进行编码，例如表示 html标记的 &lt; &gt; 等符号。</p></li><li><p>对重要的 cookie设置 httpOnly, 防止客户端通过document.cookie读取 cookie，此 HTTP头由服务端设置。</p></li><li><p>将不可信的值输出 URL参数之前，进行 URLEncode操作，而对于从 URL参数中获取值一定要进行格式检测（比如你需要的时URL，就判读是否满足URL格式）。</p></li><li><p>不要使用 Eval来解析并运行不确定的数据或代码，对于 JSON解析请使用 JSON.parse() 方法。</p></li><li><p>后端接口也应该要做到关键字符过滤的问题。</p></li></ol><h3 id="CSRF-跨站请求伪造"><a href="#CSRF-跨站请求伪造" class="headerlink" title="CSRF 跨站请求伪造"></a>CSRF 跨站请求伪造</h3><p>恶意攻击者在用户不知情的情况下，使用用户的身份来操作</p><p><strong>原理</strong></p><ul><li>黑客创建一个请求网站A 类的URL 的Web 页面，放在恶意网站B 中，这个文件包含了一个创建用户的表单。这个表单加载完毕就会立即进行提交。</li><li>黑客把这个恶意Web 页面的URL 发送至超级管理员，诱导超级管理员打开这个Web 页面。</li></ul><p><strong>防御：token 校验</strong></p><p>最常用的一种是通过token去校验请求是否合法：</p><h5 id="校验原理"><a href="#校验原理" class="headerlink" title="校验原理:"></a>校验原理:</h5><ol><li>后端生成 token，并存在 session 中。</li><li>用户请求成功后，后端将 token 发送到客户端，发送方式主要是为以下两种：</li></ol><p>（1）服务端将 token 渲染到 html 中。 也就是通过一个 dom 结点保存 token 信息，客户端就可以通过 dom 操作获取到该 token 内容。（同源策略会限制脚本 API 操作）</p><p>（2）服务端将 token 设置到 cookie 中。 客户端从 cookie 中获取（同源策略限制 cookie 操作）</p><ol start="3"><li>客户端在获取到 token 后，在下一次进行比较关键的请求操作时，将 token 发送到服务端。</li></ol><p>发送 token 到服务端的方式主要包括两种：</p><ul><li>在请求头中将获取到的 token 设置到 cookie 中。</li><li>将 token 放到请求参数中。</li></ul><ol start="4"><li>服务端在接收到请求后，会从请求头中取出 token，并和 session 中的 token 进行比较，一致则表示身份验证通过，再返回相应的信息；否则，则校验不通过。</li></ol><h3 id="SQL注入攻击"><a href="#SQL注入攻击" class="headerlink" title="SQL注入攻击"></a>SQL注入攻击</h3><p>SQL 注入漏洞: 攻击者直接对网站数据库执行任意SQL语句，在无需用户权限的情况下即可实现对数据的访问、修改甚至是删除。</p><p><strong>防御</strong></p><p>注意避免拼接字符串</p><p>部分ORM框架自带防御</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://juejin.im/post/6844903533238566925#heading-10" target="_blank" rel="noopener">https://juejin.im/post/6844903533238566925#heading-10</a></p><p><a href="http://www.pythondoc.com/flask/appcontext.html" target="_blank" rel="noopener">http://www.pythondoc.com/flask/appcontext.html</a></p><p><a href="http://www.pythondoc.com/flask/reqcontext.html" target="_blank" rel="noopener">http://www.pythondoc.com/flask/reqcontext.html</a></p><p><a href="https://cizixs.com/2017/01/12/flask-insight-routing/" target="_blank" rel="noopener">https://cizixs.com/2017/01/12/flask-insight-routing/</a></p><p><a href="https://www.cnblogs.com/kendrick/p/7649772.html" target="_blank" rel="noopener">https://www.cnblogs.com/kendrick/p/7649772.html</a></p><p><a href="https://www.cnblogs.com/panlq/p/13266426.html" target="_blank" rel="noopener">https://www.cnblogs.com/panlq/p/13266426.html</a></p>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python必知必会</title>
      <link href="/2021/04/13/interview-python/"/>
      <url>/2021/04/13/interview-python/</url>
      
        <content type="html"><![CDATA[<h2 id="语言特性"><a href="#语言特性" class="headerlink" title="语言特性"></a>语言特性</h2><p>解释型语言。Python不需要在运行之前进行编译。</p><p>动态语言，不需要声明变量的类型，动态增加类方法。</p><p>适合面向对象的编程，允许类的定义和继承。</p><h2 id="python2和python3区别"><a href="#python2和python3区别" class="headerlink" title="python2和python3区别"></a>python2和python3区别</h2><ul><li>Python2 的默认编码是 ascii，Python 3 默认编码 UTF-8，不需要在文件顶部写 <code># coding=utf-8</code>。</li><li>python2默认是按照相对路径导入模块和包，python3默认则是按照绝对路径导入</li><li>Python3里只有新式类；Python2里面继承object的是新式类，没有写父类的是经典类，多重继承的属性搜索顺序不一样，新式类是采用广度优先搜索，旧式类采用深度优先搜索。</li></ul><ul><li>Python3，新增了关键字 nonlcoal，支持嵌套函数中，变量声明为非局部变量。</li><li>python3提供注解，但是解释器<strong>并不会</strong>因为这些注解而提供额外的校验，没有任何的类型检查工作。也就是说，这些类型注解加不加，对你的代码来说<strong>没有任何影响</strong>，好处是易懂。</li></ul><ul><li>在Python2 中，字符串有两个类型， unicode和 str，前者表示文本字符串，后者表示字节序列，python2 会自动将字符串转换为合适编码的字节字符串（utf-8/gbk…），<code>decode(&#39;utf-8&#39;)</code>之后转换为unicode，可以显示指定字符串类型为unicode类型；Python3  str 表示字符串，byte 表示字节序列，字符串默认是Unicode，不能显示指定u”xx”，转换字节序列需要<code>encode(&#39;utf-8&#39;)</code>。</li><li>True 和 False 在 Python2 中是全局变量，分别对应 1 和 0，可以指向其它对象。 Python3  True 和 False 变为关键字，不允许再被重新赋值。</li><li>在Python2中，3/2是整数，在Python 3中浮点数，如果相除还想得到整数，就需要改成//相除。</li><li>原来在py2里，4字节以内的整数类型为int，超过就是long，而py3里没有long类型，只有int，而带来的问题是，大量整数计算时，py3要比py2占用更多内存，计算也明显更慢。</li><li>py3里dict没有<code>has_key()</code>方法，统一使用in表达式</li></ul><ul><li>Python 2中print/exec是特殊语句，Python 3中print/exec是函数，需要加上括号。</li><li>python2 range返回列表，python3 range中返回可迭代对象，节约内存。</li><li>Python 2 map、zip、filter函数返回list，Python3返回迭代器。</li><li>python2中的raw_input/input函数，python3中改名为input函数，危险的input被删掉了</li></ul><h2 id="python2和3代码如何兼容"><a href="#python2和3代码如何兼容" class="headerlink" title="python2和3代码如何兼容"></a>python2和3代码如何兼容</h2><ul><li><p>使用 2to3 工具（python自带的转换工具）对代码检查</p><p>查看输出信息，并修正相关问题。</p></li><li><p>使用python -3执行python程序</p><p>程序在运行时会在控制台上将python2和python3不一致，同时2to3无法处理的问题提示出来</p></li><li><p><code>from __future__ import</code>在python2使用python的未来特性了</p></li><li><p>import问题</p><p>python3中“少”了很多python2的包，在大多情况下这些包之是改了个名字而已。我们可以在import的时候捕获ImportError，重新import。</p></li><li><p>使用python3的方式写程序</p><p>python2中print是关键字，到了python3中print变成了函数。</p></li><li><p>检查当前运行的python版本</p><p>有时候你或许必须为python2和python3写不同的代码，可以先获取版本。</p></li><li><p>使用six</p><p>six 提供了一些简单的工具用来封装 Python 2 和 Python 3 之间的差异性。支持3向2的兼容。</p></li></ul><h2 id="Python基础"><a href="#Python基础" class="headerlink" title="Python基础"></a>Python基础</h2><h3 id="import机制"><a href="#import机制" class="headerlink" title="import机制"></a>import机制</h3><ul><li>当 import 一个模块时首先会在sys.modules列表中查找是否已经加载了此模块，如果加载了则只是将模块的名字加入到正在调用 import 的模块的 Local 名字空间中。如果没有加载则从 sys.path 目录中按照模块名称查找模块文件，模块可以是py、pyc、pyd，找到后将模块载入内存，并加到 sys.modules 中，并将名称导入到当前的 Local 名字空间。</li><li>包导入的过程和模块的基本一致，只是导入包的时候会执行此包目录下的<code>__init__.py</code> 而不是模块里面的语句了。另外，如果只是单纯的导入包，而包的<code>__init__.py</code>中又没有明确的其他初始化操作，那么此包下面的模块是不会自动导入的。</li></ul><blockquote><p>搜索路径查找模块：</p><ol><li>py 所在文件的目录</li><li>PYTHONPATH 中的目录</li><li>python安装目录，UNIX下，默认路径一般为/usr/local/lib/python/</li><li>3.x 中.pth 文件内容</li></ol></blockquote><h3 id="可变数据类型和不可变数据类型"><a href="#可变数据类型和不可变数据类型" class="headerlink" title="可变数据类型和不可变数据类型"></a>可变数据类型和不可变数据类型</h3><p>可变数据类型（引用类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址不发生改变。</p><p>不可变数据类型（值类型）：当该数据类型对应的变量值发生了变化时，对应的内存地址发生了改变。</p><p>可变数据类型：list和dict；</p><p>不可变数据类型：int、float、string和tuple、bytes。</p><h3 id="array-与内置list-有什么区别"><a href="#array-与内置list-有什么区别" class="headerlink" title="array 与内置list 有什么区别"></a>array 与内置list 有什么区别</h3><p>array 是数组, 数组是只能够保存一种类型, 初始化的时候就决定了数据类型.</p><p>而list 里面 几乎可以放任意类型</p><h3 id="扁平序列"><a href="#扁平序列" class="headerlink" title="扁平序列"></a>扁平序列</h3><p>存放的都是原子级元素，此时存放的是值而不会是引用。</p><p>常见的扁平序列包括：str，bytes，bytearray, memoryview, array.array等。</p><h3 id="python2中xrange和range的区别"><a href="#python2中xrange和range的区别" class="headerlink" title="python2中xrange和range的区别"></a>python2中xrange和range的区别</h3><p><code>range()</code>返回的是一个list对象，而xrange返回的是一个可迭代对象。</p><p><code>xrange()</code>则不会直接生成一个list，而是每次调用返回其中的一个值，内存空间使用极少。因而性能非常好。</p><h3 id="变量的作用域-查找顺序"><a href="#变量的作用域-查找顺序" class="headerlink" title="变量的作用域/查找顺序"></a>变量的作用域/查找顺序</h3><p>函数作用域的LEGB顺序</p><p>L：local ，局部作用域；</p><p>E：enclosing，嵌套的父级函数的局部作用域；</p><p>G：global ，全局变量；</p><p>B：build-in， 系统固定模块里面的变量。</p><p>Python除了def/class/lambda 外，其他如: if/elif/else/ try/except for/while并不能改变其作用域。</p><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><p><code>reduce()</code> 函数会对参数序列中元素进行累积。</p><p>先对数据集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据做函数运算。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># 两数相加</span>   <span class="token keyword">return</span> x <span class="token operator">+</span> yreduce<span class="token punctuation">(</span>add<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 计算列表和：1+2+3+4+5</span>reduce<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> x<span class="token operator">+</span>y<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 使用 lambda 匿名函数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>filter()</code> 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。</p><p>序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">is_odd</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">return</span> n <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">1</span>newlist <span class="token operator">=</span> filter<span class="token punctuation">(</span>is_odd<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>newlist<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>map()</code> 会根据提供的函数对指定序列做映射。</p><p>序列中的每一个元素调用 函数，返回包含每次函数返回值的新列表（python2），python3是会返回可迭代对象的。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">square</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># 计算平方数</span>   <span class="token keyword">return</span> x <span class="token operator">**</span> <span class="token number">2</span>map<span class="token punctuation">(</span>square<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 计算列表各个元素的平方</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>repr()</code>函数将对象转化为供解释器读取的形式</p><pre class="line-numbers language-python"><code class="language-python">dict1 <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'runoob'</span><span class="token punctuation">:</span> <span class="token string">'runoob.com'</span><span class="token punctuation">,</span> <span class="token string">'google'</span><span class="token punctuation">:</span> <span class="token string">'google.com'</span><span class="token punctuation">}</span><span class="token punctuation">;</span>repr<span class="token punctuation">(</span>dict1<span class="token punctuation">)</span>str<span class="token punctuation">(</span>dict1<span class="token punctuation">)</span><span class="token string">"{'google': 'google.com', 'runoob': 'runoob.com'}"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>vars()</code>函数返回对象object的属性和属性值的字典对象。</p><pre><code>class Runoob:   a = 1print(vars(Runoob)){&#39;a&#39;: 1, &#39;__module__&#39;: &#39;__main__&#39;, &#39;__doc__&#39;: None}</code></pre><p><strong>ord</strong></p><p>一个长度为1的字符串作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。</p><h4 id="dir"><a href="#dir" class="headerlink" title="dir"></a>dir</h4><p>不带参数时，返回当前范围内的变量、方法和定义的类型列表；</p><p>带参数时，返回参数的属性、方法列表。</p><p>如果参数包含方法<code>__dir__()</code>，该方法将被调用。</p><h4 id="isinstance"><a href="#isinstance" class="headerlink" title="isinstance"></a><strong>isinstance</strong></h4><p><code>isinstance()</code>判断一个对象是否是一个已知的类型，<code>type()</code>查看一个类型或变量的类型。</p><p><code>type()</code>不会认为子类是一种父类类型。<code>isinstance()</code>会认为子类是一种父类类型。</p><h4 id="raw-input、input"><a href="#raw-input、input" class="headerlink" title="raw_input、input"></a>raw_input、input</h4><p>1、在 Python2.x 中<code>raw_input()</code>和<code>input()</code>，两个函数都存在，其中区别为:</p><ul><li><code>raw_input()</code>将所有输入作为字符串看待，返回字符串类型。</li><li><code>input()</code> 只能接收“数字”的输入，它返回所输入的数字的类型。</li></ul><p>2、在 Python3.x 中 仅保留了<code>input()</code> 函数，将所有输入作为字符串处理，并返回字符串类型。</p><h4 id="sort-sorted"><a href="#sort-sorted" class="headerlink" title="sort sorted"></a>sort sorted</h4><p><strong>区别</strong></p><p>对于一个无序的列表a，调用<code>a.sort()</code>，对a进行排序后返回None，<code>sort()</code>函数修改待排序的列表内容。</p><p>而对于同样一个无序的列表a，调用<code>sorted(a)</code>，对a进行排序后返回一个新的列表，而对a不产生影响。</p><h3 id="魔法方法"><a href="#魔法方法" class="headerlink" title="魔法方法"></a>魔法方法</h3><p>在特殊的情况下被Python所调用的方法。</p><p><code>__init__</code>构造器，当一个实例被创建的时候用于初始化的方法。</p><p><code>__new__</code>实例化对象调用的第一个方法，用来创造一个类的实例的，取下cls参数，把其他参数传给<code>__init__</code>.</p><p><code>__slot__</code>:让解释器在元组中存储实例属性，而不用字典，告诉解释器：“这个类中的所有实例属性都在这儿了！”</p><p><code>__call__</code>让一个类的实例像函数一样被调用</p><p><code>__getitem__</code>定义获取容器中指定元素的行为，相当于<code>self[key]</code></p><p><code>__getattr__</code>定义当用户试图访问一个不存在属性的时候的行为</p><p><code>__setattr__</code>定义当一个属性被设置的时候的行为</p><p><code>__getattribute___</code>定义当一个属性被访问的时候的行为</p><p><code>__del__</code>删除对象执行的方法</p><p><code>__str__</code>强调可读性，面向用户，在<code>print()</code>或者<code>str()</code>函数调用的时候才会被调用；</p><p><code>__repr__</code>强调标准性，面向开发者。</p><p>%s调用<code>__str__</code>方法，而%r调用<code>__repr__</code>方法</p><p><code>__repr__</code>在表示类时，是一级的，如果只定义它，那么<code>__str__</code> = <code>__repr__</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Callable</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">return</span> a <span class="token operator">+</span> bfunc <span class="token operator">=</span> Callable<span class="token punctuation">(</span><span class="token punctuation">)</span> result <span class="token operator">=</span> func<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 像函数一样调用</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="读取obj-field时-发生了什么"><a href="#读取obj-field时-发生了什么" class="headerlink" title="读取obj.field时, 发生了什么?"></a>读取obj.field时, 发生了什么?</h3><ol><li>如果定义了<code>__getattribute__</code>，访问该方法获取属性值。逐级查找父类的<code>__getattribute__</code></li><li>对应描述符<code>__get__()</code>方法</li><li>如果obj 实例有这个属性, 返回. </li><li>非数据描述符<code>__get__()</code></li><li>如果obj 的class 有这个属性, 返回. 逐级查找父类的属性</li><li>执行<code>obj.__getattr__</code>方法.逐级查找父类的<code>__getattr__</code>方法</li></ol><h3 id="new-amp-init区别"><a href="#new-amp-init区别" class="headerlink" title="new &amp; init区别"></a>new &amp; init区别</h3><p>1、<code>__new__</code>有参数cls，代表当前类，从而产生一个实例；<code>__new__</code>必须要有返回值，返回实例化出来的实例，可以return父类（<code>super(当前类名, cls)</code>）<code>__new__</code>出来的实例，或object的<code>__new__</code>出来的实例</p><p>2、<code>__init__</code>有参数self，完成一些初始化的动作，<code>__init__</code>不需要返回值</p><p>3、如果<code>__new__</code>创建的是当前类的实例，会自动调用<code>__init__</code>（return语句里面调用的<code>__new__</code>函数的第一个参数是cls，保证是当前类实例）；如果<code>__new__</code>返回一个已经存在的实例，<code>__init__</code>不会被调用。</p><p>4、如果我们在<code>__new__</code>函数中不返回任何对象，则<code>__init__</code>函数也不会被调用。</p><blockquote><p>Python的旧类中实际上并没有<code>__new__</code>方法。因为旧类中的<code>__init__</code>实际上起构造器的作用</p></blockquote><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>避免转义，给字符串加r表示原始字符串。</p><h3 id="is-和-区别"><a href="#is-和-区别" class="headerlink" title="is 和 ==区别"></a>is 和 ==区别</h3><p>is：比较俩对象是否为同一个实例对象，是否指向同一个内存地址。</p><p>== ： 比较的两个对象的内容/值是否相等，默认会调用对象的<code>eq()</code>方法</p><h3 id="set去重"><a href="#set去重" class="headerlink" title="set去重"></a>set去重</h3><p>set的去重是通过两个函数<code>__hash__</code>和<code>__eq__</code>结合实现的。</p><p>1、当两个变量的哈希值不相同时，就认为这两个变量是不同的</p><p>2、当两个变量哈希值一样时，调用<code>__eq__</code>方法，当返回值为True时认为这两个变量是同一个。返回FALSE时，不去重。</p><h3 id="list切片"><a href="#list切片" class="headerlink" title="list切片"></a>list切片</h3><p>索引操作本身基于<code>__getitem__</code>和<code>__setitem__</code></p><p>python向<code>__getitem__</code>传入了一个<code>slice</code>的对象，这个类有start, stop, step三个属性，缺省值都是None。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span>x <span class="token operator">=</span> a <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># x = a.__getitem__(slice( 1, 5, None))</span>a <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># a.__setitem__(slice(1, 3, None), [ 10, 11, 12 ])</span><span class="token keyword">del</span> a <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># a.__delitem__(slice(1, 4, None))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="三元算子"><a href="#三元算子" class="headerlink" title="三元算子"></a>三元算子</h3><p><code>[on true] if [expression] else [on false]</code></p><h3 id="pass"><a href="#pass" class="headerlink" title="pass"></a>pass</h3><p>1、一般作为占位符或者创建占位程序，pass语句不会执行任何操作</p><p>2、保证格式、语义完整 </p><h3 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h3><p>创建匿名函数的一个特殊语法，即用即仍，</p><p>1.一般用来给filter，map这样的函数式编程服务</p><p>2.作为回调函数</p><h3 id="迭代器和生成器"><a href="#迭代器和生成器" class="headerlink" title="迭代器和生成器"></a>迭代器和生成器</h3><h4 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h4><p><strong>迭代器协议</strong>： <code>__iter__()</code> 返回一个特殊的迭代器对象， 这个迭代器对象实现了 <code>__next__()</code> 并通过 <code>StopIteration</code> 异常，标识迭代的完成。</p><p><strong>迭代器对象</strong>：实现了迭代器协议的对象/被<code>next()</code>函数调用并不断返回下一个值的对象称为迭代器。</p><p><strong>例子</strong></p><p>Python的内置工具（如for循环，sum，min，max函数等）使用迭代器协议访问对象</p><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p><strong>使用了 yield 的函数被称为生成器</strong>。<strong>只要把一个列表生成式的<code>[]</code>改成<code>()</code>，就创建了一个生成器</strong></p><p>生成器是一种特殊的迭代器，生成器自动实现了“迭代器协议”。</p><p>好处：不用占用很多内存，只需要在用的时候计算元素的值就行了。</p><p>生成器在迭代的过程中可以改变当前迭代值，而修改普通迭代器的当前迭代值往往会发生异常，影响程序的执行。</p><p><strong>yield</strong></p><p>yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator。</p><p>它和普通函数不同，生成一个 generator 看起来像函数调用，<strong>但不会执行任何函数代码，直到对其调用</strong> <code>next()</code>（在 for 循环中会自动调用 <code>next()</code>）才开始执行。虽然执行流程仍按函数的流程执行，<strong>但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行</strong>。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。</p><p><strong>激活</strong></p><ul><li>除了 next，还可以使用 send 激活生成器，两者可以交替使用。</li><li>第一次当生成器处于 started 状态时，只能 send(None)，否则会报错</li></ul><h4 id="可迭代对象"><a href="#可迭代对象" class="headerlink" title="可迭代对象"></a>可迭代对象</h4><p>实现<code>__iter__</code>方法的对象。可迭代对象包含文件对象、序列（字符串、列表、元组、集合）、字典。</p><h4 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> Iterable<span class="token punctuation">,</span> Iterator<span class="token keyword">from</span> inspect <span class="token keyword">import</span> isgeneratorisinstance<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Iterable<span class="token punctuation">)</span>isinstance<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Iterator<span class="token punctuation">)</span>isgenerator<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>装饰器本质上是一个<strong>Python函数或者类</strong>，让其他函数在不做任何代码变动，从而增加额外功能，装饰器的返回值也是一个函数对象。</p><p>场景：<strong>插入日志</strong>、性能测试、<strong>事务处理</strong>、缓存、<strong>权限校验、异常处理</strong>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> functools<span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>a <span class="token operator">+</span> b<span class="token punctuation">)</span>add  <span class="token operator">=</span> functools<span class="token punctuation">.</span>partial<span class="token punctuation">(</span>add<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 输出：3</span>add<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>经过partial包装之后，a参数的值被固定为了1，新的add对象（注意此处add已经是一个可调用对象）只需要接收一个参数即可。</p><p><strong>把原函数的部分参数固定了初始值，新的调用只需要传递其它参数。</strong></p><p><code>@functools.wraps(func)</code>底层逻辑，就是把wrapped函数的属性拷贝到wrapper函数中。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">outer</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>  @functools<span class="token punctuation">.</span>wraps<span class="token punctuation">(</span>func<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">inner</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"before..."</span><span class="token punctuation">)</span>     func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>     <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"after..."</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> inner@outer<span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""  求和运算  """</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>a <span class="token operator">+</span> b<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>1、原函数为add。</p><p>2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。</p><p>3、执行outer函数时，加载inner函数，此时会直接执行<code>functools.wraps(func)</code>返回一个可调用对象，即partial对象。</p><p>4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。</p><p>5、把add指向inner函数。</p><p>6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。</p><p> <strong>总结</strong></p><p>1）functools.wraps 旨在消除装饰器对原函数造成的影响，即对原函数的相关属性进行拷贝。</p><p>2）wraps内部通过partial对象和update_wrapper函数实现。</p><p>3）partial是一个类，通过实现<code>__new__</code>，<strong>自定义实例化对象过程，使得对象内部保留原函数和固定参数</strong>，通过实现<code>__call__</code>，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。</p><h4 id="类装饰器"><a href="#类装饰器" class="headerlink" title="类装饰器"></a><strong>类装饰器</strong></h4><p>类装饰器具有<strong>灵活度大、高内聚、封装性</strong>等优点。</p><p>依靠<code>__call__</code>方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Foo</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> func<span class="token punctuation">)</span><span class="token punctuation">:</span>     self<span class="token punctuation">.</span>_func <span class="token operator">=</span> func<span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'class decorator runing'</span><span class="token punctuation">)</span>   self<span class="token punctuation">.</span>_func<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'class decorator ending'</span><span class="token punctuation">)</span>@Foo<span class="token keyword">def</span> <span class="token function">bar</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'bar'</span><span class="token punctuation">)</span>bar<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="动态属性property"><a href="#动态属性property" class="headerlink" title="动态属性property"></a>动态属性property</h3><p>让方法像属性一样使用.</p><p>大量的@property修饰的方法在同一个类，这是不符合设计原则的，代码的分离性和可读性大大降低。建议使用属性描述符。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     self<span class="token punctuation">.</span>_x <span class="token operator">=</span> None  @property  <span class="token keyword">def</span> <span class="token function">x</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token triple-quoted-string string">"""I'm the 'x' property."""</span>     <span class="token keyword">return</span> self<span class="token punctuation">.</span>_x  @x<span class="token punctuation">.</span>setter  <span class="token keyword">def</span> <span class="token function">x</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>value<span class="token punctuation">,</span>numbers<span class="token punctuation">.</span>Integral<span class="token punctuation">)</span><span class="token punctuation">:</span>         self<span class="token punctuation">.</span>_x <span class="token operator">=</span> value  @x<span class="token punctuation">.</span>deleter  <span class="token keyword">def</span> <span class="token function">x</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">del</span> self<span class="token punctuation">.</span>_x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用property装饰后，x不再是一个函数，而是property类的一个实例。所以第二个函数可以使用 x.setter 来装饰，本质是调用property.setter 来产生一个新的 property实例赋值给第二个x。</p><p>第一个 x和第二个 x 是两个不同 property实例。但他们都属于同一个描述符类（property），当赋值时，就会进入 <code>property.__set__</code>，取值时，就会进入 <code>property.__get__</code>。</p><h3 id="参数类型"><a href="#参数类型" class="headerlink" title="参数类型"></a>参数类型</h3><p><strong>位置参数：</strong>传参数时，按照顺序，依次传值。</p><p><strong>默认参数：</strong>参数提供默认值。默认参数一定要指向不变对象。</p><p><strong>可变参数：</strong>可变参数就是传入的参数个数是可变的。特征：*args</p><p><strong>关键字参数：</strong>允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。特征：**kw</p><p><strong>命名关键字参数：</strong>如果要限制关键字参数的名字，就可以用命名关键字参数。特征：命名关键字参数需要一个特殊分隔符<code>*</code>，而后面的参数被视为命名关键字参数。如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要特殊分隔符了</p><p>参数定义的<strong>顺序</strong>必须是：位置参数–&gt;默认参数–&gt;可变参数–&gt;命名关键字参数–&gt;关键字参数</p><h3 id="zip"><a href="#zip" class="headerlink" title="zip"></a>zip</h3><p>拉链函数， 将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表迭代器。</p><p>如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>list<span class="token punctuation">(</span>zip<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="and-和or"><a href="#and-和or" class="headerlink" title="and 和or"></a>and 和or</h3><p> 在不加括号时候, and优先级大于or </p><p>x or y：x为真是x, x为假是y </p><p>x and y ： x为真就是y, x为假就是x</p><pre class="line-numbers language-python"><code class="language-python">v <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">and</span> <span class="token number">2</span> <span class="token operator">or</span> <span class="token number">3</span> <span class="token operator">and</span> <span class="token number">4</span> <span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="for-循环"><a href="#for-循环" class="headerlink" title="for 循环"></a>for 循环</h3><p><strong>通过调用<code>iter()</code>方法执行（字符串，元组，字典，集合，文件）对象内部的<code>__iter__</code>方法，获取一个迭代器，然后使用迭代器协议去实现循环访问，</strong>当元素循环完时，会触发StopIteration异常，for循环会捕捉到这种异常，终止迭代</p><h3 id="深拷贝和浅拷贝"><a href="#深拷贝和浅拷贝" class="headerlink" title="深拷贝和浅拷贝"></a>深拷贝和浅拷贝</h3><p>浅拷贝：在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素地址的拷贝。也就是说新的容器中指向了旧的元素（ 新瓶装旧酒 ）。</p><p>深拷贝：在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。（ 新瓶装新酒 ）。</p><p>1、复制不可变数据类型， copy /deepcopy，都指向原地址对象</p><p>2、复制的值是可变对象</p><p><strong>浅拷贝copy有两种情况：</strong></p><p>复制对象中包含的非可变数据类型：改变值，会开辟新的内存，有新的引用。原来值的改变并不会影响浅复制的值。</p><p>复制对象中包含的可变数据类型：改变原来的值，会影响浅复制的值。</p><p><strong>深拷贝deepcopy</strong></p><p>完全复制独立，包括内层列表和字典</p><h3 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a>参数传递</h3><p><strong>值传递：</strong>实参把值传递给形参，形参的改变不影响实参值。</p><p><strong>引用传递（地址传递）：</strong>把实参地址传递形参，形参值的改变会影响实参的值。</p><ul><li>函数中修改字典某一个键值对是有效的</li><li>函数中交换两个字典并无法生效</li></ul><p>因此不是严格意义上的引用传递，而是<strong>基于引用地址的值传递</strong>，传递的是对象地址的拷贝。</p><h3 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h3><p><strong>高阶函数</strong>：函数为入参，或者函数作为返回结果。</p><p><strong>闭包</strong>：在外函数中定义了内函数，内函数里使用了外函数的临时变量，并且外函数的返回值是内函数的引用。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">timer</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">wrapper</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>     start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>     func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#此处拿到了被装饰的函数func</span>     time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#模拟耗时操作</span>     long <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start      <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'共耗时{long}秒。'</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> wrapper <span class="token comment" spellcheck="true">#返回内层函数的引用</span>@timer<span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token operator">+</span>b<span class="token punctuation">)</span>add<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#正常调用add</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>模块加载</strong></p><ul><li>遇到@，执行timer函数，传入add函数 </li><li>生成<code>timer.&lt;locals&gt;.wrapper</code>函数并命名为add，其实是覆盖了原同名函数 </li><li>调用<code>add(1, 2)</code></li><li>去执行<code>timer.&lt;locals&gt;.wrapper(1, 2)</code></li><li>wrapper内部持有原add函数引用<code>(func)</code>，调用<code>func(1, 2)</code></li><li>继续执行完wrapper函数</li></ul><p><strong>带参数的装饰器</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">auth</span><span class="token punctuation">(</span>permission<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">_auth</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">wrapper</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"验证权限[{permission}]..."</span><span class="token punctuation">)</span>       func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>       <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"执行完毕..."</span><span class="token punctuation">)</span>     <span class="token keyword">return</span> wrapper  <span class="token keyword">return</span> _auth@auth<span class="token punctuation">(</span><span class="token string">"add"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""  求和运算  """</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>a <span class="token operator">+</span> b<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>真正调用的是装饰后生成的新函数。</p><p>为了消除装饰器对原函数的影响，需要伪装成原函数，拥有原函数的属性。可以利用functools：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">auth</span><span class="token punctuation">(</span>permission<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">_auth</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>     @functools<span class="token punctuation">.</span>wraps<span class="token punctuation">(</span>func<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 注意此处</span>     <span class="token keyword">def</span> <span class="token function">wrapper</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"验证权限[{permission}]..."</span><span class="token punctuation">)</span>       func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>       <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"执行完毕..."</span><span class="token punctuation">)</span>     <span class="token keyword">return</span> wrapper  <span class="token keyword">return</span> _auth@auth<span class="token punctuation">(</span><span class="token string">"add"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""  求和运算  """</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>a <span class="token operator">+</span> b<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="特殊例子"><a href="#特殊例子" class="headerlink" title="特殊例子"></a>特殊例子</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">multi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token keyword">lambda</span> x <span class="token punctuation">:</span> i<span class="token operator">*</span>x <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>m<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token keyword">for</span> m <span class="token keyword">in</span> multi<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [9,9,9,9]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>闭包的延迟绑定导致的，在<strong>闭包中的变量是在内部函数被调用的时候被查找的</strong>，最后函数被调用的时候，for循环已经完成， i 的值最后是3，因此每一个返回值的i都是3，所以最后的结果是[9,9,9,9]</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># [0, 3, 6, 9]</span><span class="token keyword">def</span> <span class="token function">multipliers</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">yield</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> i <span class="token operator">*</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="上下文管理"><a href="#上下文管理" class="headerlink" title="上下文管理"></a>上下文管理</h3><p>在一个类里，实现了<code>__enter__</code>和<code>__exit__</code>的方法，这个类的实例就是一个上下文管理器。</p><p><strong>基本使用语法</strong></p><pre class="line-numbers language-pyt"><code class="language-pyt">with EXPR as VAR:    BLOCK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>为什么要使用上下文管理器？</strong></p><p>一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接；处理异常；</p><p><strong>使用contextlib</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> contextlib@contextlib<span class="token punctuation">.</span>contextmanager<span class="token keyword">def</span> <span class="token function">open_func</span><span class="token punctuation">(</span>file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># __enter__方法</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'open file:'</span><span class="token punctuation">,</span> file_name<span class="token punctuation">,</span> <span class="token string">'in __enter__'</span><span class="token punctuation">)</span>    file_handler <span class="token operator">=</span> open<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">yield</span> file_handler    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> exc<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># deal with exception</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'the exception was thrown'</span><span class="token punctuation">)</span>    <span class="token keyword">finally</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'close file:'</span><span class="token punctuation">,</span> file_name<span class="token punctuation">,</span> <span class="token string">'in __exit__'</span><span class="token punctuation">)</span>        file_handler<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span><span class="token keyword">with</span> open_func<span class="token punctuation">(</span><span class="token string">'/Users/MING/mytest.txt'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_in<span class="token punctuation">:</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> file_in<span class="token punctuation">:</span>        <span class="token number">1</span><span class="token operator">/</span><span class="token number">0</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h3><h4 id="编码类型"><a href="#编码类型" class="headerlink" title="编码类型"></a>编码类型</h4><ul><li>ascii ：一个字节表示一个字符，最多只能表示 256 个符号，是针对英语字符与二进制位之间的关系的统一规定。</li><li>unicode：将世界上所有的符号都纳入其中，每一个符号都给予一个独一无二的编码，用于解决乱码问题。只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。</li><li>utf-8：互联网上使用最广的一种 Unicode 的实现方式，完成了统一的编码方式。UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。一般来说，<strong>英文字符1个字节、 欧洲字符2个字节， 中文字符3个字节</strong><ul><li>对于单字节的符号，字节的第一位设为<code>0</code>，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。</li><li>对于<code>n</code>字节的符号（<code>n &gt; 1</code>），第一个字节的前<code>n</code>位都设为<code>1</code>，第<code>n + 1</code>位设为<code>0</code>，后面字节的前两位一律设为<code>10</code>。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。</li></ul></li><li>gbk：英文字符1个字节，中文字符两个字节</li></ul><p>在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。</p><p>python2 的默认编码方式为ASCII码，python3默认的文件编码是UTF-8</p><blockquote><p>Python的字符串类型是<code>str</code>，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把<code>str</code>变为以字节为单位的<code>bytes</code>。</p><p>如果我们从网络或磁盘上读取了字节流，那么读到的数据就是<code>bytes</code>。要把<code>bytes</code>变为<code>str</code>，就需要用<code>decode()</code>方法；</p><p>如果要在网络上传输，或者保存到磁盘上，就需要把<code>str</code>变为以字节为单位的<code>bytes</code></p><p><code>len()</code>函数计算的是<code>str</code>的字符数，如果换成<code>bytes</code>，<code>len()</code>函数就计算字节数</p><p>如果没有特殊业务要求，请牢记仅使用<code>UTF-8</code>编码</p></blockquote><h4 id="unicode、utf-8和utf-16的区别"><a href="#unicode、utf-8和utf-16的区别" class="headerlink" title="unicode、utf-8和utf-16的区别"></a>unicode、utf-8和utf-16的区别</h4><p>Unicode 是字符集，UTF-8 是编码规则</p><ul><li>字符集：为每一个字符分配一个唯一的 ID（学名为码位 / 码点 / Code Point）</li><li>编码规则：将「码位」转换为字节序列的规则（编码/解码 可以理解为 加密/解密 的过程）</li></ul><p>广义的 Unicode 是一个标准，定义了一个字符集以及一系列的编码规则，即 Unicode 字符集和 UTF-8、UTF-16、UTF-32 等等编码……</p><p>Unicode 字符集为每一个字符分配一个码位，例如「知」的码位是 30693，记作 U+77E5（30693 的十六进制为 0x77E5）。</p><p>UTF-8 顾名思义，是一套以 8 位为一个编码单位的可变长编码。会将一个码位编码为 1 到 4 个字节。</p><p>utf-16是用两个字节来编码所有的字符。</p><h3 id="pickling和unpickling？"><a href="#pickling和unpickling？" class="headerlink" title="pickling和unpickling？"></a>pickling和unpickling？</h3><p>模块 pickle 实现了对一个 Python 对象结构的二进制序列化和反序列化。</p><p> “pickling” 是将 Python 对象及转化为一个字节流的过程</p><p>“unpickling” 将字节流转化回一个对象层次结构。</p><p>Pickle 协议和 JSON 间有着本质的<strong>不同</strong>：</p><ul><li>JSON 是一个文本序列化格式，而 pickle 是一个二进制序列化格式；</li><li>JSON 是我们可以直观阅读的，而 pickle 不是；</li><li>JSON在Python之外广泛使用，而pickle则是Python专用的；</li><li>JSON 只能表示 Python 内置类型的子集，不能表示自定义的类；但 pickle 可以表示大量的 Python 数据类型。</li></ul><h3 id="说一下namedtuple的用法和作用"><a href="#说一下namedtuple的用法和作用" class="headerlink" title="说一下namedtuple的用法和作用"></a>说一下<code>namedtuple</code>的用法和作用</h3><p>只有属性没有方法的类，用于组织数据，称为<strong>数据类</strong>。</p><p>在Python中可以用<code>namedtuple</code>（命名元组）来替代这种类。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> namedtupleCard <span class="token operator">=</span> namedtuple<span class="token punctuation">(</span><span class="token string">'Card'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'suite'</span><span class="token punctuation">,</span> <span class="token string">'face'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>card1 <span class="token operator">=</span> Card<span class="token punctuation">(</span><span class="token string">'红桃'</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">)</span>card2 <span class="token operator">=</span> Card<span class="token punctuation">(</span><span class="token string">'草花'</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'{card1.suite}{card1.face}'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'{card2.suite}{card2.face}'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>命名元组与普通元组一样是不可变容器，</strong>一旦将数据存储在<code>namedtuple</code>的顶层属性中，数据就不能再修改了，</p><p>对象上的所有属性都遵循“一次写入，多次读取”的原则。</p><p>和普通元组不同的是，命名元组中的数据有访问名称，可以<strong>通过名称而不是索引来获取保存的数据</strong></p><p><strong>命名元组的本质就是一个类，所以它还可以作为父类创建子类。</strong></p><p>除此之外，命名元组内置了一系列的方法，例如，可以通过<code>_asdict</code>方法将命名元组处理成字典，也可以通过<code>_replace</code>方法创建命名元组对象的浅拷贝。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyCard</span><span class="token punctuation">(</span>Card<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">show</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        faces <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'2'</span><span class="token punctuation">,</span> <span class="token string">'3'</span><span class="token punctuation">,</span> <span class="token string">'4'</span><span class="token punctuation">,</span> <span class="token string">'5'</span><span class="token punctuation">,</span> <span class="token string">'6'</span><span class="token punctuation">,</span> <span class="token string">'7'</span><span class="token punctuation">,</span> <span class="token string">'8'</span><span class="token punctuation">,</span> <span class="token string">'9'</span><span class="token punctuation">,</span> <span class="token string">'10'</span><span class="token punctuation">,</span> <span class="token string">'J'</span><span class="token punctuation">,</span> <span class="token string">'Q'</span><span class="token punctuation">,</span> <span class="token string">'K'</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> f<span class="token string">'{self.suite}{faces[self.face]}'</span><span class="token keyword">print</span><span class="token punctuation">(</span>Card<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># &lt;class '__main__.Card'></span>card3 <span class="token operator">=</span> MyCard<span class="token punctuation">(</span><span class="token string">'方块'</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>card3<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 方块Q</span><span class="token keyword">print</span><span class="token punctuation">(</span>dict<span class="token punctuation">(</span>card1<span class="token punctuation">.</span>_asdict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># {'suite': '红桃', 'face': 13}</span><span class="token keyword">print</span><span class="token punctuation">(</span>card2<span class="token punctuation">.</span>_replace<span class="token punctuation">(</span>suite<span class="token operator">=</span><span class="token string">'方块'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Card(suite='方块', face=5)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h2><p>继承：将多个类的共同属性和方法封装到一个父类下面，然后在用这些类来继承这个类的属性和方法</p><p>封装：将有共同的属性和方法封装到同一个类下面</p><p>多态：Python天生是支持多态的。指的是基类的同一个方法在不同的派生类中有着不同的功能</p><h3 id="新式类和经典类"><a href="#新式类和经典类" class="headerlink" title="新式类和经典类"></a>新式类和经典类</h3><p>Python3里只有新式类；Python2里面继承object的是新式类，没有写父类的是经典类</p><p><strong>区别</strong></p><ul><li>新式类 保持class与type的统一，对新式类的实例执行<code>a.__class__</code>与<code>type(a)</code>的结果是一致的</li><li>旧式类的<code>type(a)</code>返回instance。</li><li>多重继承的属性搜索顺序不一样，新式类是采用广度优先搜索，旧式类采用深度优先搜索。</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">foo1</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span> <span class="token string">"A"</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">foo2</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">foo1</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span> <span class="token string">"C"</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">pass</span>d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>d<span class="token punctuation">.</span>foo1<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>缺点：</strong>经典类的查找顺序是深度优先的规则，在访问<code>d.foo1()</code>的时候,D-&gt;B-&gt;A,找到了<code>foo1()</code>,调用A的<code>foo1()</code>，导致C重写的<code>foo1()</code>被绕过</p><h3 id="类方法、类实例方法、静态方法"><a href="#类方法、类实例方法、静态方法" class="headerlink" title="类方法、类实例方法、静态方法"></a>类方法、类实例方法、静态方法</h3><ul><li><p>类方法: 是类对象的方法，使用 @classmethod 进行装饰，形参有cls，表示类对象</p></li><li><p>类实例方法: 是类实例化对象的方法，形参为self，指代对象本身;</p></li><li><p>静态方法: 是一个任意函数，使用 @staticmethod 进行装饰</p><blockquote><p>实例方法只能通过实例对象调用；</p><p>类方法和静态方法可以通过类对象或者实例对象调用，</p><p>使用实例对象调用的类方法或静态方法，最终通过类对象调用。</p></blockquote></li></ul><h3 id="如何判断是函数还是方法？"><a href="#如何判断是函数还是方法？" class="headerlink" title="如何判断是函数还是方法？"></a>如何判断是函数还是方法？</h3><p>如果是以函数的形式定义或者是静态方法，一定是函数</p><p>如果是类方法，一定是方法。</p><p>实例方法是方法，如果类直接调用实例方法，则是函数（直接调用运行是有问题的）。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> types <span class="token keyword">import</span> MethodType<span class="token punctuation">,</span>FunctionType<span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>obj<span class="token punctuation">.</span>func<span class="token punctuation">,</span> FunctionType<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>obj<span class="token punctuation">.</span>func<span class="token punctuation">,</span> MethodType<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="接口类与抽象类"><a href="#接口类与抽象类" class="headerlink" title="接口类与抽象类"></a>接口类与抽象类</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Operate_database</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 接口类1</span>    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sql<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> NotImplementedError    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sql<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> NotImplementedError<span class="token keyword">from</span> abc <span class="token keyword">import</span> ABCMeta<span class="token punctuation">,</span>abstractmethod<span class="token keyword">class</span> <span class="token class-name">Operate_database</span><span class="token punctuation">(</span>metaclass<span class="token operator">=</span>ABCMeta<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 接口类2</span>    @abstractmethod    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sql<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    @abstractmethod    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sql<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> Python 原生仅支持抽象类，不支持接口类，abc模块就是用来实现抽象类的。</p><p>若是类中所有的方法都没有实现，则认为这是一个接口，</p><p>若是有部分方法实现，则认为这是一个抽象类。</p><p>抽象类和接口类都仅用于被继承，不能被实例化.</p><h3 id="描述符"><a href="#描述符" class="headerlink" title="描述符"></a>描述符</h3><ul><li>一个实现了<code>__get__()</code>、<code>__set__()</code>、<code>__delete__()</code>其中至少一个方法的类就是一个描述符。</li><li>只实现了<code>__get__()</code>的称作非数据描述符</li><li>实现了<code>__get__()</code>和<code>__set__()</code>方法的称作数据描述符。</li></ul><p><code>__get__</code>： 用于访问属性。它返回属性的值，若属性不存在、不合法等都可以抛出对应的异常。</p><p><code>__set__</code>：将在属性分配操作中调用。</p><p><code>__delete__</code>：控制删除操作。</p><p>描述符的作用和优势，以弥补Python动态类型的缺点。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Score</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     self<span class="token punctuation">.</span>_score <span class="token operator">=</span> default  <span class="token keyword">def</span> <span class="token function">__set__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> instance<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">if</span> <span class="token operator">not</span> isinstance<span class="token punctuation">(</span>value<span class="token punctuation">,</span> int<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">raise</span> TypeError<span class="token punctuation">(</span><span class="token string">'Score must be integer'</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> value <span class="token operator">&lt;=</span> <span class="token number">100</span><span class="token punctuation">:</span>       <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Valid value must be in [0, 100]'</span><span class="token punctuation">)</span>     self<span class="token punctuation">.</span>_score <span class="token operator">=</span> value  <span class="token keyword">def</span> <span class="token function">__get__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> instance<span class="token punctuation">,</span> owner<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">return</span> self<span class="token punctuation">.</span>_score  <span class="token keyword">def</span> <span class="token function">__delete__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">del</span> self<span class="token punctuation">.</span>_score    <span class="token keyword">class</span> <span class="token class-name">Student</span><span class="token punctuation">:</span>  math <span class="token operator">=</span> Score<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  chinese <span class="token operator">=</span> Score<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  english <span class="token operator">=</span> Score<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> math<span class="token punctuation">,</span> chinese<span class="token punctuation">,</span> english<span class="token punctuation">)</span><span class="token punctuation">:</span>     self<span class="token punctuation">.</span>name <span class="token operator">=</span> name     self<span class="token punctuation">.</span>math <span class="token operator">=</span> math     self<span class="token punctuation">.</span>chinese <span class="token operator">=</span> chinese     self<span class="token punctuation">.</span>english <span class="token operator">=</span> english<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>staticmethod</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Test</span><span class="token punctuation">:</span>  @staticmethod  <span class="token keyword">def</span> <span class="token function">myfunc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 上下两种写法等价</span><span class="token keyword">class</span> <span class="token class-name">Test</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">myfunc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 重点：这就是描述符的体现</span>  <span class="token comment" spellcheck="true"># 每调用一次，它都会经过描述符类的 __get__</span>  myfunc <span class="token operator">=</span> staticmethod<span class="token punctuation">(</span>myfunc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>classmethod</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">classmethod</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> f<span class="token punctuation">)</span><span class="token punctuation">:</span>     self<span class="token punctuation">.</span>f <span class="token operator">=</span> f  <span class="token keyword">def</span> <span class="token function">__get__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> instance<span class="token punctuation">,</span> owner<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"in classmethod __get__"</span><span class="token punctuation">)</span>     <span class="token keyword">def</span> <span class="token function">newfunc</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">return</span> self<span class="token punctuation">.</span>f<span class="token punctuation">(</span>owner<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span>     <span class="token keyword">return</span> newfunc<span class="token keyword">class</span> <span class="token class-name">Test</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">myfunc</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 重点：这就是描述符的体现</span>  myfunc <span class="token operator">=</span> classmethod<span class="token punctuation">(</span>myfunc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="元类"><a href="#元类" class="headerlink" title="元类"></a>元类</h3><p><strong>元类是用来创建类的类。</strong></p><p>如果类属性中定义了<code>__metaclass__</code>，则在创建类的时候用元类来创建；</p><p>如果没有则向其父类查找<code>__metaclass__</code>。</p><p>如果都没有，则用<code>type()</code>创建类。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># metaclass是类的模板，所以必须从`type`类型派生：</span><span class="token keyword">class</span> <span class="token class-name">ListMetaclass</span><span class="token punctuation">(</span>type<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> name<span class="token punctuation">,</span> bases<span class="token punctuation">,</span> attrs<span class="token punctuation">)</span><span class="token punctuation">:</span>        attrs<span class="token punctuation">[</span><span class="token string">'add'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">lambda</span> self<span class="token punctuation">,</span> value<span class="token punctuation">:</span> self<span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>        <span class="token keyword">return</span> type<span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> name<span class="token punctuation">,</span> bases<span class="token punctuation">,</span> attrs<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">(</span>list<span class="token punctuation">,</span> metaclass<span class="token operator">=</span>ListMetaclass<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>传入关键字参数<code>metaclass</code>时，指示Python解释器在创建<code>MyList</code>时，要通过<code>ListMetaclass.__new__()</code>来创建</p><p>在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。</p><p><code>__new__()</code>方法接收到的参数依次是：</p><ol><li>当前准备创建的类的对象；</li><li>类的名字；</li><li>类继承的父类集合；</li><li>类的方法集合。</li></ol><p><strong>元类作用</strong></p><ul><li>拦截类的创建</li><li>修改类</li><li>返回修改后的类</li></ul><p><strong>应用场景</strong></p><p>ORM：所有的类都只能动态定义，因为只有使用者才能根据表的结构定义出对应的类来。</p><blockquote><p>元类中的<code>__call__</code>会在你每次实例化的时候调用, 其实和<code>Foo.__new__</code>是一样的, 如果你的Foo定义了<code>__new__</code>, 元类中的<code>__call__</code>便不会执行</p><p>元类中的<code>__new__</code>会在加载类的时候执行一次，在创建类的时候会调用类的<code>__new__</code>或者元类的<code>__call__</code></p></blockquote><h2 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h2><p>字典的查询、添加、删除的平均时间复杂度都是<code>O(1)</code>。因为字典是通过哈希表来实现的.</p><ul><li><p>计算key的hash值<code>hash(key)</code>，再和mask做与操作【mask=字典最小长度（DictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的enteies哈希表中的下标位置</p></li><li><p>若index下标位置已经被占用，则会判断enteies的key是否与要插入的key是否相等</p><ul><li><p>如果key相等就表示key已存在，则更新value值</p></li><li><p>如果key不相等，就表示hash冲突，则会继续向下寻找空位置，一直到找到剩余空位为止。</p></li></ul></li></ul><h3 id="开放寻址法"><a href="#开放寻址法" class="headerlink" title="开放寻址法"></a><strong>开放寻址法</strong></h3><p>开放寻址法中，所有的元素都存放在散列表里，当产生哈希冲突时，通过一个探测函数计算出下一个候选位置，如果下一个获选位置还是有冲突，不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。</p><blockquote><p>开放寻址法中解决冲突的方法有：线行探查法、平方探查法、双散列函数探查法</p></blockquote><p>采用哈希表，dict的哈希表里每个slot都是一个自定义的entry结构：</p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token punctuation">{</span>   Py_ssize_t me_hash<span class="token punctuation">;</span>   PyObject <span class="token operator">*</span>me_key<span class="token punctuation">;</span>   PyObject <span class="token operator">*</span>me_value<span class="token punctuation">;</span><span class="token punctuation">}</span> PyDictEntry<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每个entry有三种状态Active, Unused, Dummy。</p><ul><li><p>Unused:me_key == me_value == NULL，即未使用的空闲状态。</p></li><li><p>Active:me_key != NULL, me_value != NULL，即该entry已被占用</p></li><li><p>Dummy:me_key == dummy, me_value == NULL。</p></li></ul><p><strong>为什么entry有Dummy状态呢？</strong></p><p>用开放寻址法中，<strong>遇到哈希冲突时会找到下一个合适的位置，</strong>例如ABC构成了探测链，查找元素时如果hash值相同，那么也是<strong>顺着这条探测链不断往后找</strong>，当删除探测链中的某个元素时，如果直接把B从哈希表中移除，即变成Unused状态，那么C就不可能再找到了，因此需要Dummy保证探测链的连续性。</p><p>dict对象的定义为：</p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">struct</span> _dictobject <span class="token punctuation">{</span>  PyObject _HEAD  Py_ssize_t ma_fill<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">/* # Active + # Dummy */</span>  Py_ssize_t ma_used<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">/* # Active */</span>  Py_ssize_t ma_mask<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//slot -1</span>  PyDictEntry <span class="token operator">*</span>ma_table<span class="token punctuation">;</span>  PyDictEntry <span class="token operator">*</span><span class="token punctuation">(</span><span class="token operator">*</span>ma_lookup<span class="token punctuation">)</span><span class="token punctuation">(</span>PyDictObject <span class="token operator">*</span>mp<span class="token punctuation">,</span> PyObject <span class="token operator">*</span>key<span class="token punctuation">,</span> <span class="token keyword">long</span> hash<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 搜索函数指针</span>  PyDictEntry ma_smalltable<span class="token punctuation">[</span>PyDict_MINSIZE<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//默认的slot</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="dict对象的创建"><a href="#dict对象的创建" class="headerlink" title="dict对象的创建"></a><strong>dict对象的创建</strong></h3><p>dict对象的创建很简单，先看看缓冲的对象池里有没有可用对象，如果有就直接用，没有就从堆上申请。</p><h3 id="dict对象的插入"><a href="#dict对象的插入" class="headerlink" title="dict对象的插入"></a><strong>dict对象的插入</strong></h3><p>如果不存在key-value则插入，存在则覆盖。</p><ul><li>生成Hash</li><li>如果可用的entry&lt;0，字典扩容</li><li>基于key、hash，查找可用哈希位置，以便于存储<ul><li>字典中是否有空余的值，或者如果找到了满足 hash 值与 key 相同的,就将 value 设置为找到的值</li></ul></li><li>保存key、Hash、value值</li></ul><h3 id="dict对象的删除"><a href="#dict对象的删除" class="headerlink" title="dict对象的删除"></a><strong>dict对象的删除</strong></h3><p>算出哈希值，找到entry，将其从Active转换成Dummy，并调整table的容量。</p><p><strong>注意</strong></p><p>（1） dict的key 或者 set的值都必须是可hash的不可变对象，都是可hash的</p><p>（2）当发现内存空间中的“空”只有1/3时，便会触发扩容操作。</p><h3 id="OrderedDict实现"><a href="#OrderedDict实现" class="headerlink" title="OrderedDict实现"></a>OrderedDict实现</h3><p>使用了双向循环链表+哈希的方法</p><ol><li>哈希用来快速获取LinkNode，从而获取value，也支持快速定位</li><li>双向链表可以快速删除一个元素，使用哈希可以实现基于key快速查找</li><li>循环链表可以使得处理变得更加简单，不需要保存dummy的head和tail，以快速获取收尾节点。只需要保存实际的head，通过head.prev来快速定位尾结点。</li></ol><h2 id="整数"><a href="#整数" class="headerlink" title="整数"></a>整数</h2><h3 id="小整数对象池"><a href="#小整数对象池" class="headerlink" title="小整数对象池"></a>小整数对象池</h3><p>Python使用<strong>小整数对象池</strong>small_ints缓存了[-5，257）之间的整数，该范围内的整数在Python系统中是共享的，值相同就属于同一个对象。</p><p>对于同一个代码块中值不在<code>small_ints</code>缓存范围内的整数，如果同一个代码块中已经存在一个值与其相同的整数对象，那么就直接引用该对象，否则创建新的<code>int</code>对象。</p><h3 id="整型不会溢出原理"><a href="#整型不会溢出原理" class="headerlink" title="整型不会溢出原理"></a>整型不会溢出原理</h3><p>1、用动态的可变长的结构，显然，数组的形式能够胜任</p><pre class="line-numbers language-c"><code class="language-c"><span class="token punctuation">[</span>longintrepr<span class="token punctuation">.</span>h<span class="token punctuation">]</span><span class="token keyword">struct</span> _longobject <span class="token punctuation">{</span>    PyObject_VAR_HEAD    <span class="token keyword">int</span> <span class="token operator">*</span>ob_digit<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2、保存形式：数组中每个int存放它的上限（2^31 - 1），这样表示大数时，数组长度更短，更省空间。但是，空间确实是更省了，但操作会代码麻烦，比方大数做乘积操作，由于元素之间存在乘法溢出问题，所以只保存 <code>15</code>位，这样元素之间的乘积就可以只用 <code>int</code> 类型保存即可, 对乘积结果做位移操作就能得到尾部和进位 <code>carry</code>了</p><h2 id="字符串-1"><a href="#字符串-1" class="headerlink" title="字符串"></a>字符串</h2><p>Python解释器中使用了 intern（字符串驻留）的技术来提高字符串效率，值同样的字符串对象仅仅会保存一份，放在一个字符串储蓄池中，是共用的。</p><p><strong>简单原理</strong></p><p>维护一个字符串存储池，这个池子是一个字典结构</p><p>如果字符串已经存在于池子中，直接返回之前创建好的字符串对象，</p><p>如果不存在，则构造一个字符串对象并加入到池子中去。</p><blockquote><p>在shell中，并非全部的字符串都会采用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。不能超过20个字符。因为如果超过xx个字符的话，解释器认为这个字符串不常用，不用放入字符串池中。</p><p>字符串拼接时，运行时拼接，不会intern；例如”hell” + “o”在编译时完成拼接的才会intern</p></blockquote><h3 id="字符串不等"><a href="#字符串不等" class="headerlink" title="字符串不等"></a>字符串不等</h3><p><strong>字符串打印出来看着一样，但是判断却是False</strong>？</p><p>如果两个字符串末尾有其他符号，比如回车‘\n’，print的时候无法发现的</p><p><strong>==判断是 True ，is 判断却是 False?<em>**</em></strong></p><p>字符串来自不同的内存块，内存地址不一样</p><p><strong>is判断是False，用id判断却是True</strong></p><pre class="line-numbers language-python"><code class="language-python">In <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span> foo<span class="token punctuation">.</span>bar <span class="token keyword">is</span> Foo<span class="token punctuation">.</span>barOut<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean">False</span>In <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">:</span> id<span class="token punctuation">(</span>foo<span class="token punctuation">.</span>bar<span class="token punctuation">)</span> <span class="token operator">==</span> id<span class="token punctuation">(</span>Foo<span class="token punctuation">.</span>bar<span class="token punctuation">)</span>Out<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>foo.bar本身并不是简单的名字，而是表达式的计算结果，是一个 method object，method object只是一个临时的中间变量而已，对临时的中间变量做id是没有意义的。</p><p>只有你能保证对象不会被销毁的前提下，你才能用 id 来比较两个对象。</p><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="不同列表表达式的区别"><a href="#不同列表表达式的区别" class="headerlink" title="不同列表表达式的区别"></a>不同列表表达式的区别</h3><p>a = a <em> 10<br>b </em>= 10</p><p>不同的操作，乘法操作会调用 <code>list_repeat()</code> ；<code>*=</code> 会调用 <code>list_inplace_repeat()</code></p><p><code>list_repeat</code> 需要多少空间就申请多少空间，<code>list_inplace_repeat()</code>会申请比所需的空间还要大点的内存</p><h2 id="堆-栈"><a href="#堆-栈" class="headerlink" title="堆 栈"></a>堆 栈</h2><p>在Python中，变量也称为：对象的引用。变量存储的就是对象的地址。</p><p><strong>变量位于：栈内存。</strong></p><p><strong>对象位于：堆内存。</strong></p><p>内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。</p><p><strong>代码区：</strong>程序中的代码数据、二进制数据、方法数据等等程序运行需要的预加载数据。</p><p><strong>静态数据区：</strong>存储<strong>全局变量、静态变量</strong>。</p><p><strong>栈区：</strong>存储变量。存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。</p><p><strong>堆区</strong>：对象真实数据。</p><h2 id="内存回收机制"><a href="#内存回收机制" class="headerlink" title="内存回收机制"></a>内存回收机制</h2><p>python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略。</p><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a><strong>引用计数法</strong></h3><p><strong>原理：</strong>每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数加1，每当该对象的引用失效时，计数减1，一旦对象的引用计数为0，该对象立即被回收，占用的内存空间将被释放。</p><p><strong>缺点：</strong>不能解决对象的循环引用</p><h3 id="标记清除"><a href="#标记清除" class="headerlink" title="标记清除"></a>标记清除</h3><p>解决容器对象可能产生的循环引用问题。（只有容器对象才会产生循环引用的情况，比如列表、字典、用户自定义类的对象、元组等）</p><p><strong>A）标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达</strong>；</p><p>B）清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。</p><h3 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h3><p>标记清除时，应用程序会被暂停，为了减少应用程序暂停的时间。</p><p><strong>对象存在时间越长，越可能不是垃圾，应该越少去收集</strong>。</p><p>给对象定义了三种世代，每一个新生对象在0代中，如果它在一轮gc扫描中活了下来，那么它将被移至1代，在那里他将较少的被扫描，如果它又活过了一轮gc，它又将被移至2代，在那里它被扫描的次数将会更少。</p><h3 id="gc的扫描在什么时候会被触发呢"><a href="#gc的扫描在什么时候会被触发呢" class="headerlink" title="gc的扫描在什么时候会被触发呢?"></a><strong>gc的扫描在什么时候会被触发呢</strong>?</h3><p>年轻代链表的总数达到上限时。</p><p>当某一世代的扫描被触发的时候，比该世代年轻的世代也会被扫描。</p><h3 id="调优手段"><a href="#调优手段" class="headerlink" title="调优手段"></a><strong>调优手段</strong></h3><p>1.手动垃圾回收</p><p>2.调高垃圾回收阈值</p><p>3.避免循环引用</p><h3 id="退出Python时，是否释放全部内存？"><a href="#退出Python时，是否释放全部内存？" class="headerlink" title="退出Python时，是否释放全部内存？"></a>退出Python时，是否释放全部内存？</h3><p>进程退出的时候，资源最终都会释放掉，这是操作系统负责的。</p><p>如果是一段程序运行结束之后：</p><ol><li>CPython会通过引用计数立即释放引用数量为0的对象（其它版本解释器并不保证）；循环引用的对象会在下一次GC时释放，除非有两个对象都带有<code>__del__</code>析构函数，且直接或间接循环引用。这种情况下，所有循环引用的对象都无法被释放。原因在于无法确定<code>__del__</code>的执行顺序。</li><li>全局引用的对象无法被回收，但也不只是模块中直接或间接保存的对象，还包括未退出的线程使用的对象，解释器缓存的小整数和字符串，还有C模块里间接引用的对象等等。</li><li>C扩展直接通过malloc分配的内存自然无法通过gc来回收，但一般如果存在没有被回收的内存说明是有内存泄漏的，这属于实现的bug</li></ol><h2 id="线程和进程"><a href="#线程和进程" class="headerlink" title="线程和进程"></a>线程和进程</h2><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。在Python中，进程适合计算密集型任务。</p><h4 id="进程间的通信（IPC）"><a href="#进程间的通信（IPC）" class="headerlink" title="进程间的通信（IPC）"></a>进程间的通信（IPC）</h4><p><strong>1）管道（Pipe</strong>）：通过<code>send()</code>和<code>recv()</code>来发送和接受信息，适合父子进程关系或者两个子进程之间。 </p><p>2）<strong>有名管道（FIFO）</strong>：有名管道也是半双工的通信方式。 将自己注册到文件系统里一个文件，通过读写这个文件进行通信。允许在没有亲缘关系的进程之间使用。要求读写双方必须同时打开才可以继续进行读写操作，否则打开操作会堵塞直到对方也打开。</p><p>3）<strong>信号量（Semaphore）</strong>：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 创建子进程时将信号量my_semaphore作为参数传入子进程任务函数，子进程中使用semaphore.acquire() 尝试获取信号量，semaphore.release()尝试 释放信号量。</p><p><strong>4）队列（Queue）</strong>。 使用get/put在父子进程关系或者两个子进程之间通信。</p><p>5）<strong>信号 （signal）</strong>：用于通知接收进程某个事件已经发生，可以设置信号处理函数。 </p><p>6）共享内存（shared memory）：操作系统负责将同一份物理地址的内存映射到多个进程的不同的虚拟地址空间中。进而每个进程都可以操作这份内存。需要在进程访问时做好并发控制，比如使用信号量。 python标准库mmap，apache开源的pyarrow都是。</p><p>7）套接字（socket）：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。 </p><p><strong>8）文件</strong> </p><p>（1）仅进程同步不涉及数据传输，可以使用信号、信号量；<br>（2）若进程间需要传递少量数据，可以使用管道、有名管道、队列；<br>（3）若进程间需要传递大量数据，最佳方式是使用共享内存，推荐使用pyarrow，这样减少数据拷贝、传输的时间内存代价；<br>（4）跨主机的进程间通信（RPC）可以使用socket通信。</p><p><strong>共享变量</strong></p><p>使用 Process 定义的多进程之间（父子或者兄弟）共享变量可以直接使用 multiprocessing 下的 Value，Array，Queue 等，如果要共享 list，dict，可以使用强大的 Manager 模块。</p><h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>线程是cpu调度执行的最小单位，依赖进程存在，一个进程至少有一个线程。在python中，线程适合IO密集型任务。</p><p>同一个进程下的线程共享程序的内存空间<strong>（如代码段，全局变量，堆等）</strong></p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>继承Thread，重写run方法，通过start方法开线程</p><p>将要执行的方法作为参数传给Thread的构造方法</p><h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h4><p>线程有五种状态:创建、就绪、运行、阻塞、死亡。 </p><ul><li><p>调用start方法时，线程就会进入就绪状态。 </p></li><li><p>在线程得到cpu时间片时进入运行状态。 </p></li><li><p><strong>线程调用yield方法可以让出cpu时间回到就绪状态</strong>。 </p></li><li><p>线程运行时可能<strong>由于IO、调用sleep、wait、join方法或者无法获得同步锁等原因进入阻塞</strong>状态。 </p></li><li><p>当线程获得到等待的资源资源或者引起阻塞的条件得到满足时，会从阻塞状态进入就绪状态。 </p></li><li><p>当线程的run方法执行结束时，线程就进入死亡状态。</p></li></ul><h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h4><p>多个线程同时对一个公共资源（如全局变量）进行操作的情况，为了避免发生混乱。<code>threading.lock</code>，<code>acquire()</code>方法上锁，<code>release()</code>方法解锁</p><p>可重入锁：为了支持在同一线程中多次请求同一资源，python提供了threading.RLock。重入锁必须由获取它的同一个线程释放，同时要求解锁次数应与加锁次数相同，才能用于另一个线程。</p><h4 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h4><p>阻塞线程直到子线程全部结束。</p><h4 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h4><p>不重要线程。主线程会等所有‘重要’线程结束后才结束。</p><h4 id="线程池的工作原理"><a href="#线程池的工作原理" class="headerlink" title="线程池的工作原理"></a>线程池的工作原理</h4><p>减少线程本身创建和销毁造成的开销，属于典型的空间换时间操作。</p><p>创建和释放线程涉及到大量的系统底层操作，开销较大，如果变成预创建和借还操作，将大大减少底层开销。</p><ul><li>在应用程序启动后，线程池创建一定数量的线程，放入空闲队列中。这些线程最开始都处于阻塞状态，不会消耗CPU，占用少量的内存。</li><li>当任务到来后，从队列中取出一个空闲线程，把任务派发到这个线程中运行，并将标记为已占用。</li><li>当线程池中所有的线程都被占用后，可以选择自动创建一定数量的新线程，用于处理更多的任务，也可以选择让任务排队等待直到有空闲的线程可用。</li><li>在任务执行完毕后，线程并不退出结束，而是继续保持在池中等待下一次的任务。</li><li>当系统比较空闲时，大部分线程长时间处于闲置状态时，线程池可以自动销毁一部分线程，回收系统资源。</li></ul><p>线程池组成部分：</p><ol><li>线程池管理器：用于创建并管理线程池。</li><li>工作线程和线程队列：线程池中实际执行的线程以及保存这些线程的容器。</li><li>任务接口：将线程执行的任务抽象出来，形成任务接口，确保线程池与具体的任务无关。</li><li>任务队列：线程池中保存等待被执行的任务的容器。</li></ol><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><p>协程是一种用户态的轻量级线程，用户自己来编写调度逻辑的。</p><p>协程拥有自己的寄存器上下文和栈。协程的切换都在用户空间内进行，不需要进行系统调用。对CPU来说，协程其实是单线程，所以CPU不用去考虑怎么调度、切换上下文，这就省去了CPU的切换开销，所以协程在一定程度上又好于多线程</p><p>协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，基本没有内核切换的开销，可以不加锁的访问全局变量，上下文的切换非常快。</p><blockquote><p>不管是进程还是线程，每次阻塞、切换都需要陷入系统调用，先让CPU跑操作系统的调度程序，然后再由调度程序决定该跑哪一个进程/线程。</p><hr><p>协程又称微线程，属于用户级线程。 gevent 就是一种协程实现方式，除了 gevent 还有 asyncio。用户级线程就是在一个内核调度实体上映射出来的多个用户线程，用户线程的创建、调度和销毁完全由用户程序控制, 对内核调度透明：内核一旦将 cpu 分配给了线程，该 cpu 的使用权就归该线程所有，线程可以再次按照比如时间片轮转等常规调度算法分配给每个微线程，从而实现更大的并发自由度，但所有的微线程只能在该 cpu 上运行，无法做到并行。</p><p>把协程看作这些映射出来的“微线程”。用户程序控制的协程需要解决线程的挂起和唤醒、现场保护等问题，然而区别于线程的是协程不需要处理锁和同步问题，因为多个协程是在一个用户级线程内进行的，但需要处理因为单个协程阻塞导致整个线程（进程）阻塞的问题。</p></blockquote><h4 id="greenlet"><a href="#greenlet" class="headerlink" title="greenlet"></a>greenlet</h4><p>创建协程对象的方法其实有两个参数 <code>greenlet(run=None, parent=None)</code>。参数 run 就是其要调用的方法；参数 parent 定义了该协程对象的父协程，也就是说，greenlet 协程之间是可以有父子关系的。如果不设或设为空，则其父协程就是程序默认的”main”主协程。这个”main”协程不需要用户创建，它所对应的方法就是主程序，而所有用户创建的协程都是其子孙。</p><p>在子协程执行完毕后，会自动返回父协程。</p><h4 id="eventlet"><a href="#eventlet" class="headerlink" title="eventlet"></a>eventlet</h4><p>eventlet 在 Greenlet 的基础上实现了自己的 GreenThread，实际上就是 greenlet 类的扩展封装，而与 Greenlet 的不同是，Eventlet 实现了自己调度器称为 Hub，Hub 类似于 Tornado 的 IOLoop，是单实例的。在 Hub 中有一个 event loop，根据不同的事件来切换到对应的 GreenThread。</p><h4 id="gevent"><a href="#gevent" class="headerlink" title="gevent"></a>gevent</h4><p>gevent 是基于 libev(Linux 上 epoll）和 greenlet 实现的 <strong>Python 网络库</strong>。libev 是一个事件循环器：向 libev 注册感兴趣的事件，比如 socket 可读事件，libev 会对所注册的事件的源进行管理，并在事件发生时触发相应的程序。也就是说 libev 提供了指定文件描述符事件发生时调用回调函数的机制。</p><h4 id="asyncio"><a href="#asyncio" class="headerlink" title="asyncio"></a>asyncio</h4><p> Python 3.4 试验性引入的异步 I/O 框架，提供了基于协程做异步 I/O 编写单线程并发代码的基础设施。其核心组件有事件循环（Event Loop）、协程 (Coroutine）、任务(Task)、未来对象(Future) 以及其他一些扩充和辅助性质的模块。</p><blockquote><p>定义好的协程并不能直接使用，需要将其包装成为了一个任务（task 对象），然后放到事件循环中才能被执行。所谓 task 对象是 Future 类的一个子类，保存了协程运行后的状态，用于未来获取协程的结果。</p></blockquote><p><strong>使用步骤</strong></p><ul><li>定义协程函数</li><li>封装成 task（非必须，直接将协程放到事件循环中，事件循环会自动完成这一操作）</li><li>获取事件循环</li><li>将 task 放到事件循环中执行。</li></ul><p><strong>协程函数</strong></p><p>如果协程函数调用了阻塞操作，那么其他协程和主线程将被阻塞。这意味着协程函数逻辑要么使用用非阻塞功能，要么同步调用的功能时间很短，否则无法发挥协程的并发优势。</p><p>比如request请求url就是同步调用，无法真正实现并发。幸运的是aio库中有对应的异步实现：aiohttp。</p><p><strong>如何利用多核CPU呢？</strong></p><p>最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。</p><p>每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，所以在python中，多进程的执行效率优于多线程</p><p><strong>常用模块</strong></p><p>greenlet：提供了切换任务的快捷方式，但是遇到io无法自动切换任务，需要手动切换</p><p>gevent：开启协程任务并切换的模块，遇到io自动切换任务。</p><p>asyncio：<code>@asyncio.coroutine</code>装饰器的函数称为协程函数。</p><p><code>yield from</code>语法用于将一个生成器部分操作委托给另一个生成器。</p><p><code>async</code>/<code>await</code>：<code>@asyncio.coroutine</code>和<code>yield from</code>的语法糖</p><p><strong>缺点</strong></p><ul><li><p>无法利用多核资源：协程的本质是个单线程</p></li><li><p>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序</p></li></ul><p><strong>协程主要使用场景</strong></p><p>网络请求，比如爬虫，大量使用 aiohttp</p><p>文件读取， aiofile</p><p>web 框架， aiohttp， fastapi</p><p>数据库查询， asyncpg, databases</p><p><strong>协程优于线程</strong></p><ul><li>python 线程调度方式是，每执行 100 个字节码或者遇到阻塞就停止当前线程，然后进行一个系统调用，让 os 内核选出下一个线程。但是协程只会在阻塞的时候，切换到下一个协程。因此线程的切换存在很多是无效的切换，当线程数量越大，这种因为调度策略的先天不足带来的性能损耗就越大。</li><li>线程需要进行系统调用，协程不需要。系统调用需要进入内核态，无效的调度会让这部分开销显得更大</li><li>协程可以自主调度，而线程只能决定合适退出，但是下一个线程是谁则依赖于操作系统。</li></ul><h3 id="僵尸进程和孤儿进程"><a href="#僵尸进程和孤儿进程" class="headerlink" title="僵尸进程和孤儿进程"></a>僵尸进程和孤儿进程</h3><p>孤儿进程： <strong>父进程退出，子进程还在运行的这些子进程都是孤儿进程，</strong>孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。</p><p>僵尸进程： 进程使用fork 创建子进程<strong>，如果子进程退出，而父进程并没有调用wait 获取子进程的状态信息</strong>，那么子进程的进程描述符仍然保存在系统中，这些进程是僵尸进程。</p><p>避免僵尸进程的方法：</p><p>1.用<code>wait()</code>函数使父进程阻塞，这个<code>wait()</code>操作就负责回收子进程，这样也不会产生僵尸进程。但这样做有个致命的问题，wait是阻塞的，如果进行wait，主进程就什么都做不了。</p><p>2.使用信号量，子进程退出时向父进程发送SIGCHILD信号，在signal handler 中调用waitpid，这样父进程不用阻塞</p><p>3.fork 两次用孙子进程去完成子进程的任务，孙子进程刚产生，它的父亲就退出了，成了孤儿进程，由init收养</p><h2 id="Global-Interpreter-Lock"><a href="#Global-Interpreter-Lock" class="headerlink" title="Global Interpreter Lock"></a>Global Interpreter Lock</h2><p>Python 默认的解释器是 CPython，<strong>GIL 是存在于 CPython 解释器中的</strong>。</p><p> <strong>CPython 解释器的内存管理</strong>不是线程安全的。执行 Python 字节码时，引入了为了保护访问 Python 对象而阻止多个线程执行的一把互斥锁GIL。某个线程想要执行，必须先拿到GIL锁，并且在一个python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。</p><p><strong>因此，同一时刻，只有一个线程在运行，其它线程只能等待，即使是多核CPU</strong>，<strong>也没办法让多个线程「并行」地同时执行代码，只能是交替执行</strong>，因为多线程涉及到上线文切换、锁机制处理（获取锁，释放锁等），所以，多线程执行不快反慢。</p><p>尽管存在 GIL，但 python 多线程仍然不是线程安全的，对于共享状态的场合仍然需要借助锁同步。</p><p>常见的 Python 解释器：IPython（基于Cython）、Jython（Python 代码编译成 Java 字节码，依赖 Java 平台，不存在 GIL）、IronPython（ .Net 平台下的 Python 解释器，Python 代码编译成 .Net 字节码，不存在 GIL）</p><h3 id="GIL原理"><a href="#GIL原理" class="headerlink" title="GIL原理"></a>GIL原理</h3><p>python 的线程就是 C 语言的 pthread，它是通过操作系统调度算法调度执行的。</p><p>Python 2.x 的代码执行是基于 opcode 数量的调度方式，简单来说就是每执行一定数量的字节码，或遇到系统 IO 时，会强制释放 GIL，然后触发一次操作系统的线程调度。</p><p> Python 3.x 基于固定时间的调度方式，就是每执行固定时间的字节码，或遇到系统 IO 时，强制释放 GIL，触发系统的线程调度。</p><h3 id="为什么会有GIL"><a href="#为什么会有GIL" class="headerlink" title="为什么会有GIL"></a>为什么会有GIL</h3><p>90年代单核 CPU 还是主流，多线程的应用场景也不多，大部分时候还是以单线程的方式运行，单线程不要涉及线程的上下文切换，效率反而比多线程更高（在多核环境下，不适用此规则），设计一个全局锁是<strong>那个时代保护多线程资源一致性最简单经济的设计方案</strong>。</p><p>多核心时代来临，当大家试图去拆分和去除 GIL 的时候，发现大量库的代码和开发者已经重度依赖 GIL（默认认为 Python内部对象是线程安全的，无需在开发时额外加锁），所以这个去除 GIL 的任务变得复杂且难以实现。</p><blockquote><p>CPython 解释器在创建变量时，首先会分配内存，然后对该变量的引用进行计数，这称为 引用计数。如果变量的引用数变为 0，这个变量就会从内存中释放掉。而当多个线程内共享一个变量时，CPython 锁定引用计数的关键就在于使用了 GIL，它会谨慎地控制线程的执行情况，无论同时存在多少个线程，解释器每次只允许一个线程进行操作。</p></blockquote><h3 id="GIL的实现是线程不安全-为什么"><a href="#GIL的实现是线程不安全-为什么" class="headerlink" title="GIL的实现是线程不安全?为什么?"></a>GIL的实现是线程不安全?为什么?</h3><p>单核情况下:</p><p><img src="gil.png" alt></p><blockquote><ol><li>到第5步的时候，可能这个时候python正好切换了一次GIL(据说python2.7中，每100条指令会切换一次GIL),执行的时间到了，被要求释放GIL,这个时候thead 1的count=0并没有得到执行，而是挂起状态，count=0这个上下文关系被存到寄存器中.</li><li>然后到第6步，这个时候thead 2开始执行，然后就变成了count = 1,返回给count，这个时候count=1.</li><li>然后再回到thead 1，这个时候由于上下文关系，thead 1拿到的寄存器中的count = 0，经过计算，得到count = 1，经过第13步的操作就覆盖了原来的count = 1的值，所以这个时候count依然是count = 1，所以这个数据并没有保护起来。</li></ol></blockquote><p>python2.x和3.x都是在执行IO操作的时候，强制释放GIL，使其他线程有机会执行程序。</p><h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h3 id="python为什么慢"><a href="#python为什么慢" class="headerlink" title="python为什么慢"></a>python为什么慢</h3><ul><li><p>GIL</p><p>无论同时存在多少个线程，解释器每次只允许一个线程进行操作。</p></li><li><p>解释型语言而不是编译型语言</p><p>Python 都会解释字节码并本地执行。.NET 和 Java 都是 JIT 编译的，JIT 会允许在运行时进行优化，缺点是启动慢。</p></li><li><p>动态类型的语言</p><p>类型比较和类型转换消耗的资源是比较多的，每次读取、写入或引用变量时都会检查变量的类型</p></li></ul><h3 id="lru-cache装饰器"><a href="#lru-cache装饰器" class="headerlink" title="lru_cache装饰器"></a>lru_cache装饰器</h3><p>为函数提供缓存功能。在下次以相同参数调用时直接返回上一次的结果，要求参数可hash。</p><h3 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h3><p>Python 标准库提供了同一分析接口的两种不同实现：</p><ol><li>建议使用 <a href="https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile" target="_blank" rel="noopener"><code>cProfile</code></a> ；这是一个 C 扩展插件，因为其合理的运行开销，所以适合于分析长时间运行的程序。</li><li><a href="https://docs.python.org/zh-cn/3/library/profile.html#module-profile" target="_blank" rel="noopener"><code>profile</code></a> 是一个纯 Python 模块（<a href="https://docs.python.org/zh-cn/3/library/profile.html#module-cProfile" target="_blank" rel="noopener"><code>cProfile</code></a> 就是模拟其接口的 C 语言实现），但它会显著增加配置程序的开销。如果你正在尝试以某种方式扩展分析器，则使用此模块可能会更容易完成任务</li></ol><p>支持输出：调用次数、在指定函数中消耗的总时间（不包括调用子函数的时间）、指定的函数及其所有子函数（从调用到退出）消耗的累积时间、函数运行一次的平均时间</p><h3 id="加速python运行"><a href="#加速python运行" class="headerlink" title="加速python运行"></a>加速python运行</h3><ol><li><p>优化代码和算法</p><ul><li>避免全局变量</li><li>避免模块和函数属性访问：对于频繁访问的变量<code>sqrt</code>，通过将其改为局部变量可以加速运行。</li><li>避免类内属性访问：通过将需要频繁访问的类内属性赋值给一个局部变量，可以提升代码运行速度。</li><li>避免数据复制：交换值时不使用中间变量、避免无意义的数据复制、字符串拼接用join而不是+</li><li>利用if条件的短路特性</li><li>使用numba.jit</li><li>循环优化： 用for循环代替while循环、使用隐式for循环代替显式for循环</li><li>选择合适的数据结构：如果有频繁的新增、删除操作，新增、删除的元素数量又很多时，list的效率不高。此时，应该考虑使用collections.deque。</li></ul></li><li><p>使用 PyPy</p><p>PyPy通过使用一种 Just-in-time（JIT，即时编译）技术来实现的。CPython 使用解释来执行代码，虽然这一做法提供了很大的灵活性，但速度也变得慢了下来。使用 JIT，你的代码是在运行程序时即时编译的。它结合了 Ahead-of-time（AOT，提前编译）技术的速度优势（由 C 和 C++ 等语言使用）和解释的灵活性。另一个优点是 JIT 编译器可以在运行时不断优化代码。代码运行的时间越长，它就会变得越优化。</p></li><li><p>使用线程</p></li><li><p>使用 Asyncio</p></li><li><p>同时使用多个处理器</p></li></ol><p>使用多个进程，使用分布式方案等。</p><h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><h3 id="使用装饰器"><a href="#使用装饰器" class="headerlink" title="使用装饰器"></a><strong>使用装饰器</strong></h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">singleton</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>  instances <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>  <span class="token keyword">def</span> <span class="token function">wrapper</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">if</span> cls <span class="token operator">not</span> <span class="token keyword">in</span> instances<span class="token punctuation">:</span>       instances<span class="token punctuation">[</span>cls<span class="token punctuation">]</span> <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>     <span class="token keyword">return</span> instances<span class="token punctuation">[</span>cls<span class="token punctuation">]</span>  <span class="token keyword">return</span> wrapper@singleton<span class="token keyword">class</span> <span class="token class-name">Foo</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">pass</span>foo1 <span class="token operator">=</span> Foo<span class="token punctuation">(</span><span class="token punctuation">)</span>foo2 <span class="token operator">=</span> Foo<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>foo1 <span class="token keyword">is</span> foo2<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用new"><a href="#使用new" class="headerlink" title="使用new"></a>使用new</h3><p>New 是真正创建实例对象的方法，所以重写基类的new 方法，以此保证创建对象的时候只生成一个实例。</p><p>但是以上的方法在多线程中会有线程安全问题，当有多个线程同时去初始化对象时，就很可能同时判断__instance is None，从而进入初始化instance的代码中。所以需要用<strong>互斥锁</strong>来解决这个问题。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token string">'_instance'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       cls<span class="token punctuation">.</span>_instance <span class="token operator">=</span> super<span class="token punctuation">(</span>Singleton<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>     <span class="token keyword">return</span> cls<span class="token punctuation">.</span>_instance<span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  __instance <span class="token operator">=</span> None  <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">if</span> cls<span class="token punctuation">.</span>__instance <span class="token keyword">is</span> None<span class="token punctuation">:</span>       cls<span class="token punctuation">.</span>__instance <span class="token operator">=</span> super<span class="token punctuation">(</span>Singleton<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>     <span class="token keyword">return</span> cls<span class="token punctuation">.</span>__instance<span class="token keyword">class</span> <span class="token class-name">Foo</span><span class="token punctuation">(</span>Singleton<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">pass</span>foo1 <span class="token operator">=</span> Foo<span class="token punctuation">(</span><span class="token punctuation">)</span>foo2 <span class="token operator">=</span> Foo<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>foo1 <span class="token keyword">is</span> foo2<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="用装饰器实现同步锁"><a href="#用装饰器实现同步锁" class="headerlink" title="用装饰器实现同步锁"></a>用装饰器实现同步锁</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">make_synchronized</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">import</span> threading    func<span class="token punctuation">.</span>__lock__ <span class="token operator">=</span> threading<span class="token punctuation">.</span>Lock<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">synced_func</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> func<span class="token punctuation">.</span>__lock__<span class="token punctuation">:</span>            <span class="token keyword">return</span> func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token keyword">return</span> synced_func<span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    __instance <span class="token operator">=</span> None    @make_synchronized    <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token operator">not</span> cls<span class="token punctuation">.</span>__instance<span class="token punctuation">:</span>            cls<span class="token punctuation">.</span>__instance <span class="token operator">=</span> object<span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">)</span>        <span class="token keyword">return</span> cls<span class="token punctuation">.</span>__instance<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="双重检查线程安全单例模式"><a href="#双重检查线程安全单例模式" class="headerlink" title="双重检查线程安全单例模式"></a>双重检查线程安全单例模式</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SingletonSample</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    _instanceLock <span class="token operator">=</span> threading<span class="token punctuation">.</span>Lock<span class="token punctuation">(</span><span class="token punctuation">)</span>    @classmethod    <span class="token keyword">def</span> <span class="token function">get_instance</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 初次检查，避免锁竞争</span>        <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token string">"_instance"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">with</span> cls<span class="token punctuation">.</span>_instanceLock<span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 获取到锁后再次判断，避免重复创建</span>                <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token string">"_instance"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    cls<span class="token punctuation">.</span>_instance <span class="token operator">=</span> super<span class="token punctuation">(</span>SingletonSample<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">)</span>                    <span class="token keyword">print</span> cls<span class="token punctuation">.</span>_instance        <span class="token keyword">return</span> cls<span class="token punctuation">.</span>_instance<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="classmethod"><a href="#classmethod" class="headerlink" title="classmethod"></a>classmethod</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> threading<span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>     _instance_lock <span class="token operator">=</span> threading<span class="token punctuation">.</span>Lock<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            @classmethod    <span class="token keyword">def</span> <span class="token function">instance</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> Singleton<span class="token punctuation">.</span>_instance_lock<span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 加锁</span>            <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>Singleton<span class="token punctuation">,</span> <span class="token string">'_instance'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                Singleton<span class="token punctuation">.</span>_instance <span class="token operator">=</span> Singleton<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>            <span class="token keyword">return</span> Singleton<span class="token punctuation">.</span>_instance<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="元类-1"><a href="#元类-1" class="headerlink" title="元类"></a>元类</h3><p>元类是用于创建类对象的类，类对象创建实例对象时一定要调用call方法，因此在调用call时候保证始终只创建一个实例即可，type是python的元类</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span>type<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token string">'_instance'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            cls<span class="token punctuation">.</span>_instance <span class="token operator">=</span> super<span class="token punctuation">(</span>Singleton<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>__call__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token keyword">return</span> cls<span class="token punctuation">.</span>_instance<span class="token comment" spellcheck="true"># Python2</span><span class="token keyword">class</span> <span class="token class-name">Foo</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    __metaclass__ <span class="token operator">=</span> Singleton<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="线程安全–元类"><a href="#线程安全–元类" class="headerlink" title="线程安全–元类"></a>线程安全–元类</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> threading<span class="token keyword">class</span> <span class="token class-name">MetaSingleton</span><span class="token punctuation">(</span>type<span class="token punctuation">)</span><span class="token punctuation">:</span>    _instance_lock <span class="token operator">=</span> threading<span class="token punctuation">.</span>Lock<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token string">'_instance'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">with</span> MetaSingleton<span class="token punctuation">.</span>_instance_lock<span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token operator">not</span> hasattr<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token string">'_instance'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    cls<span class="token punctuation">.</span>_instance <span class="token operator">=</span> super<span class="token punctuation">(</span>MetaSingleton<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>__call__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token keyword">return</span> cls<span class="token punctuation">.</span>_instance<span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span>metaclass<span class="token operator">=</span>MetaSingleton<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="select-poll和epoll"><a href="#select-poll和epoll" class="headerlink" title="select,poll和epoll"></a>select,poll和epoll</h2><p> select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 </p><h2 id="docker和virtualenv技术具体有什么不同？"><a href="#docker和virtualenv技术具体有什么不同？" class="headerlink" title="docker和virtualenv技术具体有什么不同？"></a>docker和virtualenv技术具体有什么不同？</h2><ul><li>virtualenv是python的版本和库管理器，virtualenv虚拟python运行环境</li><li>docker是虚拟化整个系统环境工具，docker不仅可以跑python，还可以跑其他的需要进程环境隔离的程序。</li></ul><p>环境的特点有二：</p><ul><li>Python版本固定。即使系统的Python升级了，虚拟环境中的仍然不受影响，保留开发状态。</li><li>所有Python软件包，都只在这个环境生效。一旦退出，则回到用户+系统的默认环境中。</li></ul><p>这两个特点，由两个小手段实现。</p><ul><li>改变当前Shell的<code>PATH</code>。</li><li>改变Python运行时的<code>sys.path</code>。</li></ul><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis必知必会</title>
      <link href="/2021/04/12/interview-redis/"/>
      <url>/2021/04/12/interview-redis/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h3><p>Redis（Remote Dictionary Server） 是一个使用 C 语言编写的，<strong>开源的高性能非关系型（NoSQL）的键值对数据库</strong>。</p><p>Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、Hash、有序集合。</p><p> Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应<strong>用于缓存方向</strong>，每秒可以处理超过10万次读写操作。</p><h3 id="Redis有哪些优缺点"><a href="#Redis有哪些优缺点" class="headerlink" title="Redis有哪些优缺点"></a>Redis有哪些优缺点</h3><p><strong>优点</strong></p><blockquote><p><strong>读写性能优异，</strong> Redis能读的速度是110000次/s，写的速度是81000次/s。<br><strong>数据结构丰富</strong>，支持string、hash、set、zset、list等数据结构。<br><strong>支持数据持久化</strong>，支持AOF和RDB两种持久化方式。<br><strong>支持事务</strong>，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。<br><strong>支持主从复制</strong>，主机会自动将数据同步到从机，支持读写分离。</p></blockquote><p><strong>缺点</strong></p><blockquote><p>数据库<strong>容量受到物理内存的限制</strong>，不能用作海量数据的高性能读写，适合的场景主要局限在较小数据量的高性能操作和运算上。<br>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后会引入数据不一致的问题。</p></blockquote><h3 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h3><p>一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。</p><p>另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p><p><strong>IO多路复用模型</strong></p><p>Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流– select/epoll 机制。</p><ol><li>允许同时存在多个监听套接字和已连接套接字。</li><li>内核会一直监听这些套接字上的连接请求或数据请求。select/epoll 一旦监测到文件描述符上有请求到达时，就会触发相应的事件。</li><li>这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。</li></ol><p>redis不会阻塞在某一个特定的客户端请求处理上。Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="Redis有哪些数据类型"><a href="#Redis有哪些数据类型" class="headerlink" title="Redis有哪些数据类型"></a>Redis有哪些数据类型</h3><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash.</p><table><thead><tr><th>数据类型</th><th>可存储的值</th><th>操作</th><th>应用场景</th></tr></thead><tbody><tr><td>STRING</td><td>字符串、整数或者浮点数</td><td>对整个字符串或者字符串的其中一部分执行操作</td><td>整数和浮点数自增减操作；键值对缓存</td></tr><tr><td>LIST</td><td>列表</td><td>从两端压入或者弹出元素;对单个或者多个元素进行修剪，只保留一个范围内的元素</td><td>存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据</td></tr><tr><td>SET</td><td>无序集合</td><td>添加、获取、移除单个元素;检查一个元素是否存在于集合中;计算交集、并集、差集</td><td>可以把两个人的粉丝列表整一个交集</td></tr><tr><td>HASH</td><td>包含键值对的无序散列表</td><td>添加、获取、移除单个键值对;获取所有键值对;检查某个键是否存在</td><td>结构化的数据，比如一个对象</td></tr><tr><td>ZSET</td><td>有序集合</td><td>添加、获取、删除元素;根据分值范围或者成员来获取元素;计算一个键的排名</td><td>去重但可以排序，如获取排名前几名的用户</td></tr></tbody></table><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p><strong>数据结构</strong></p><p>Redis 的字符串叫着SDS，Simple Dynamic String。它的结构是一个带长度信息的字节数组。</p><ul><li>embstr ：将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。</li><li>raw ：需要两次 malloc，两个对象头在内存地址上一般是不连续的。</li></ul><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><ul><li>内部包含两个 dictht，通常情况下只有一个 hashtable 是有值的。</li><li>每个dictht包括，哈希表数组，同时包含数组长度和可用元素的个数。</li><li>数组中的每一个元素dictEntry组成包括， key、value、下一个元素的指针</li></ul><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">struct</span> dict <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    dictht ht<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//哈希表</span><span class="token punctuation">}</span><span class="token keyword">struct</span> dictht <span class="token punctuation">{</span>    dictEntry<span class="token operator">*</span><span class="token operator">*</span> table<span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 二维</span>    <span class="token keyword">long</span> size<span class="token punctuation">;</span>             <span class="token comment" spellcheck="true">// 第一维数组的长度</span>    <span class="token keyword">long</span> used<span class="token punctuation">;</span>             <span class="token comment" spellcheck="true">// hash 表中的元素个数</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token keyword">struct</span> dictEntry <span class="token punctuation">{</span>    <span class="token keyword">void</span><span class="token operator">*</span> key<span class="token punctuation">;</span>    <span class="token keyword">void</span><span class="token operator">*</span> val<span class="token punctuation">;</span>    dictEntry<span class="token operator">*</span> next<span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 链接下一个 entry</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="hash-冲突"><a href="#hash-冲突" class="headerlink" title="hash 冲突"></a>hash 冲突</h4><p>使用<strong>链地址法</strong>解决哈希冲突。哈希表节点的next指针指向下一个哈希表节点，通过单向链表解决哈希冲突。为了速度考虑，总是将新节点添加到链表的表头位置。</p><h4 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h4><ol><li>为字典的 <code>ht[1]</code> 哈希表分配空间，初始默认hash长度为4，当元素个数与hash表长度一致时，就发生扩容，hash长度变为原来的二倍</li><li>将保存在 <code>ht[0]</code> 中的所有键值对 rehash 到 <code>ht[1]</code> 上面</li><li>当 <code>ht[0]</code> 包含的所有键值对都迁移到了 <code>ht[1]</code> 之后 （<code>ht[0]</code> 变为空表）， 释放 <code>ht[0]</code> ， 将 <code>ht[1]</code> 设置为 <code>ht[0]</code> ， 并在 <code>ht[1]</code> 新创建一个空白哈希表， 为下一次 rehash 做准备</li></ol><h4 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a><strong>渐进式rehash</strong></h4><ol><li>为 <code>ht[1]</code> 分配空间， 让字典同时持有 <code>ht[0]</code> 和 <code>ht[1]</code> 两个哈希表。</li><li>在字典中维持一个索引计数器变量 <code>rehashidx</code> ， 并将它的值设置为 <code>0</code> ， 表示 rehash 工作正式开始。</li><li>在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 <code>ht[0]</code> 哈希表在 <code>rehashidx</code> 索引上的所有键值对 rehash 到 <code>ht[1]</code> ， 当 rehash 工作完成之后， 程序将 <code>rehashidx</code> 属性的值增一。</li><li>随着字典操作的不断执行， 最终在某个时间点上， <code>ht[0]</code> 的所有键值对都会被 rehash 至 <code>ht[1]</code> ， 这时程序将 <code>rehashidx</code> 属性的值设为 <code>-1</code> ， 表示 rehash 操作已完成。</li></ol><h4 id="负载因子"><a href="#负载因子" class="headerlink" title="负载因子"></a>负载因子</h4><p>Redis中，<code>loader_factor</code>：<code>哈希表中键值对数量 / 哈希表长度</code>。</p><ul><li>服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ；</li><li>服务器目前正在执行BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ；</li></ul><p>根据 BGSAVE 命令或 BGREWRITEAOF 命令是否正在执行， 服务器执行扩展操作所需的负载因子并不相同， 这是因为在执行BGSAVE 命令或BGREWRITEAOF 命令的过程中， Redis 需要创建当前服务器进程的子进程，而大多数操作系统都采用<strong>写时复制（copy-on-write）</strong>技术来优化子进程的使用效率， 所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子， 从而尽可能地避免在子进程存在期间进行哈希表扩展操作， 这可以避免不必要的内存写入操作，最大限度地节约内存。</p><h3 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h3><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。跳表的查找复杂度就是 <code>O(logN)</code></p><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>跳表是一种可以进行<strong>二分</strong>查找的<strong>有序链表</strong>。</p><p>跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。</p><p>跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。</p><h4 id="跳表怎么增加节点"><a href="#跳表怎么增加节点" class="headerlink" title="跳表怎么增加节点"></a>跳表怎么增加节点</h4><ul><li>根据投硬币的方式，决定新元素要占据的层数</li><li>然后，找到这个元素在下面两层的前置节点。</li><li>接着，就是链表的插入元素操作了</li></ul><h4 id="跳表怎么删除节点"><a href="#跳表怎么删除节点" class="headerlink" title="跳表怎么删除节点"></a>跳表怎么删除节点</h4><ul><li>找到各层中包含元素x的节点。</li><li>使用标准的链表删除元素的方法删除即可。</li></ul><h4 id="Redis中的skiplist和经典有何不同"><a href="#Redis中的skiplist和经典有何不同" class="headerlink" title="Redis中的skiplist和经典有何不同"></a>Redis中的skiplist和经典有何不同</h4><ul><li>score允许重复，即skiplist的key允许重复。经典skiplist中是不允许的。</li><li>在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。</li><li>第1层链表是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。</li><li>redis的跳表维护了span字段，可以快速计算出节点的rank或者获取指定rank的节点。</li></ul><h4 id="为什么Redis选择使用跳表而不是红黑树来实现有序集合？"><a href="#为什么Redis选择使用跳表而不是红黑树来实现有序集合？" class="headerlink" title="为什么Redis选择使用跳表而不是红黑树来实现有序集合？"></a>为什么Redis选择使用跳表而不是红黑树来实现有序集合？</h4><p>首先，我们来分析下Redis的有序集合支持的操作：</p><p>1）插入元素</p><p>2）删除元素</p><p>3）查找元素</p><p>4）有序输出所有元素</p><p>5）<strong>查找区间内所有元素</strong></p><p>其中，前4项红黑树都可以完成，且时间复杂度与跳表一致。</p><p>但是，查找区间内所有元素，红黑树的效率就没有跳表高了。</p><p><strong>在跳表中，要查找区间的元素，我们只要定位到两个区间端点在最低层级的位置，然后按顺序遍历元素就可以了，非常高效。</strong></p><p><strong>而红黑树只能定位到端点后，再从首位置开始每次都要查找后继节点，相对来说是比较耗时的。</strong></p><p>redis的跳表维护了span字段，可以快速计算出节点的rank或者获取指定rank的节点</p><p>此外，跳表实现起来很容易且易读，红黑树实现起来相对困难，所以Redis选择使用跳表来实现有序集合。</p><blockquote><p>span 表示当前节点在当前层到达下一个节点的距离。后续查找节点的时候，每层会获取一个节点，这些节点的span加起来，就是节点的rank。</p></blockquote><h3 id="BitMaps"><a href="#BitMaps" class="headerlink" title="BitMaps"></a>BitMaps</h3><p>BitMaps是在字符串类型上定义的位操作。可用于用户签到、应用访问统计等场景。</p><h3 id="Hyperloglog"><a href="#Hyperloglog" class="headerlink" title="Hyperloglog"></a>Hyperloglog</h3><p>Hyperloglog 提供了一种不太精确的基数统计方法，用来统计一个集合中不重复的元素个数，比如统计网站的UV，或者应用的日活、月活，存在一定的误差。</p><h3 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h3><p>适用于位置信息服务（Location-Based Service，LBS）的应用。</p><p><strong>实现原理</strong></p><p>GEO 类型的底层数据结构就是用 Sorted Set 来实现的。Sorted Set 元素的权重分数是一个浮点数（float 类型），而一组经纬度包含的是经度和纬度两个值。因此需要对一组经纬度进行 GeoHash 编码，基本原理就是<code>二分区间，区间编码</code>，经纬度编码需要交叉组合成一个数。</p><h3 id="Streams（5-0）"><a href="#Streams（5-0）" class="headerlink" title="Streams（5.0）"></a>Streams（5.0）</h3><p>Streams 是 Redis 专门为消息队列设计的数据类型。</p><ul><li><p>对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。</p></li><li><p>Streams支持消费组。消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。</p></li><li><p>Streams 会自动使用内部队列（ PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams消息已经处理完成</p></li></ul><h3 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h3><h4 id="总结一"><a href="#总结一" class="headerlink" title="总结一"></a>总结一</h4><p><strong>计数器</strong></p><p>可以对 String 进行自增自减运算，从而实现计数器功能。</p><p><strong>缓存</strong></p><p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。</p><p><strong>会话缓存</strong></p><p>统一存储多台应用服务器的会话信息。</p><p><strong>全页缓存</strong></p><p>Redis还提供很简便的全页缓存平台。Magento、WordPress提供一个插件来使用Redis作为全页缓存后端</p><p><strong>查找表</strong></p><p>例如 DNS 记录就很适合使用 Redis 进行存储。</p><p><strong>消息队列</strong></p><p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。</p><p><strong>其它</strong></p><p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。</p><p>ZSet 可以实现有序性操作，从而<strong>实现排行榜</strong>等功能。</p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="what？"><a href="#what？" class="headerlink" title="what？"></a>what？</h3><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了，内存数据丢失。</p><h3 id="持久化机制？各自的优缺点？"><a href="#持久化机制？各自的优缺点？" class="headerlink" title="持久化机制？各自的优缺点？"></a>持久化机制？各自的优缺点？</h3><p>Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制。</p><h4 id="RDB（Redis-DataBase）"><a href="#RDB（Redis-DataBase）" class="headerlink" title="RDB（Redis DataBase）"></a><strong>RDB（Redis DataBase）</strong></h4><ul><li>主进程fork出子进程，共享主线程的所有内存数据</li><li>子进程读取主线程的内存数据，并把它们写入 RDB 文件</li><li>如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件</li></ul><p>借助了操作系统提供的<strong>写时复制技术</strong>（Copy-On-Write），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。</p><p><strong>优点</strong></p><ul><li>性能最大化，<strong>fork 子进程来完成写操作</strong>，主进程不会进行任何 IO 操作，保证了 redis 的高性能</li><li>比 AOF 的启动效率更高。</li></ul><p><strong>缺点</strong></p><p>如果两次持久化之间 发生故障，会导致数据丢失。</p><h4 id="AOF持久化（Append-Only-File）"><a href="#AOF持久化（Append-Only-File）" class="headerlink" title="AOF持久化（Append Only File）"></a><strong>AOF持久化（Append Only File）</strong></h4><p>执行命令后，将Redis执行的每次写命令记录到单独的日志文件中。写后日志，避免了命令的检查，并且不阻塞当前的写操作。但是可能会给下一个操作带来阻塞风险，因为AOF日志在主线程中运行。</p><p>当重启Redis，利用持久化日志，恢复数据。</p><p><strong>优点：</strong></p><ul><li>支持每进行一次命令操作就记录到 aof 文件中一次。</li></ul><p><strong>缺点：</strong></p><ul><li>AOF 文件比 RDB 文件大，且恢复速度慢。</li></ul><h3 id="AOF重写流程"><a href="#AOF重写流程" class="headerlink" title="AOF重写流程"></a>AOF重写流程</h3><ul><li>主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程</li><li>新操作写到正在使用的 AOF 日志的缓冲区（因为可能记录了最新操作）</li><li>新操作写到正在使用的 重写日志的缓冲区（重写日志也不会丢失最新的操作）。</li><li>拷贝数据的所有操作记录重写完成后，重写日志记录缓冲区的最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时可以用新的 AOF 文件替代旧文件了。</li></ul><blockquote><p>AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；</p><p>然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。</p><p>而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p></blockquote><h3 id="如何选择合适的持久化方式"><a href="#如何选择合适的持久化方式" class="headerlink" title="如何选择合适的持久化方式"></a>如何选择合适的持久化方式</h3><ul><li>数据不能丢失时，内存快照和 AOF 的混合使用；</li><li>如果允许分钟级别的数据丢失，只使用 RDB；</li><li>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</li></ul><h3 id="aof-和-rdb-哪个效率好"><a href="#aof-和-rdb-哪个效率好" class="headerlink" title="aof 和 rdb 哪个效率好"></a>aof 和 rdb 哪个效率好</h3><ul><li>RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。</li><li>因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。</li></ul><h2 id="过期键的删除策略"><a href="#过期键的删除策略" class="headerlink" title="过期键的删除策略"></a>过期键的删除策略</h2><h3 id="Redis的过期键的删除策略"><a href="#Redis的过期键的删除策略" class="headerlink" title="Redis的过期键的删除策略"></a>Redis的过期键的删除策略</h3><p><strong>惰性过期：</strong>只有当访问一个key时，才会判断它是否已过期，过期则清除。该策略可以节省CPU资源，极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。<br><strong>定期过期：</strong>每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。<br><strong>Redis中同时使用了惰性过期和定期过期两种过期策略。</strong></p><h3 id="Redis-key的过期时间和永久有效分别怎么设置？"><a href="#Redis-key的过期时间和永久有效分别怎么设置？" class="headerlink" title="Redis key的过期时间和永久有效分别怎么设置？"></a>Redis key的过期时间和永久有效分别怎么设置？</h3><p>EXPIRE和PERSIST命令。</p><h2 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h2><h3 id="MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据"><a href="#MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据" class="headerlink" title="MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据"></a>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</h3><p>redis内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。</p><h3 id="Redis的内存淘汰策略有哪些"><a href="#Redis的内存淘汰策略有哪些" class="headerlink" title="Redis的内存淘汰策略有哪些"></a>Redis的内存淘汰策略有哪些</h3><p><strong>全局选择性移除</strong></p><ul><li><p>allkeys-lru：移除最近最少使用的key。</p></li><li><p>allkeys-lfu：所有键根据数据的被访问次数和访问时效性，进行移除</p></li></ul><ul><li>allkeys-random：随机移除某个key。</li></ul><p><strong>设置过期时间的键空间选择性移除</strong></p><ul><li><p>volatile-lru：在设置了过期时间的键中，移除最近最少使用的key。</p></li><li><p>volatile-lfu：在设置了过期时间的键中，根据数据的被访问次数和访问时效性，进行移除</p></li><li><p>volatile-random：在设置了过期时间的键中，随机移除某个key。</p></li><li><p>volatile-ttl：在设置了过期时间的键中，有更早过期时间的key优先移除。</p></li></ul><h3 id="Redis的内存用完了会发生什么？"><a href="#Redis的内存用完了会发生什么？" class="headerlink" title="Redis的内存用完了会发生什么？"></a>Redis的内存用完了会发生什么？</h3><p>如果配置了内存淘汰机制，会冲刷掉旧的内容。否则Redis的写命令会返回错误信息。</p><h3 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a><strong>LRU</strong></h3><p>Redis 中，LRU 算法被做了简化。</p><ul><li>Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。</li><li>Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</li><li>再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值</li></ul><h3 id="Redis如何做内存优化？"><a href="#Redis如何做内存优化？" class="headerlink" title="Redis如何做内存优化？"></a>Redis如何做内存优化？</h3><p>利用Hash、list、sorted set、set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起</p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="what？-1"><a href="#what？-1" class="headerlink" title="what？"></a>what？</h3><p>事务是一个单独的隔离操作,事务中的所有命令都会序列化、按顺序地执行。</p><p>事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p><h3 id="Redis事务的三个阶段"><a href="#Redis事务的三个阶段" class="headerlink" title="Redis事务的三个阶段"></a>Redis事务的三个阶段</h3><ol><li>事务开始 MULTI</li><li>命令入队</li><li>事务执行 EXEC</li></ol><p>事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队。</p><h3 id="Redis事务相关命令"><a href="#Redis事务相关命令" class="headerlink" title="Redis事务相关命令"></a>Redis事务相关命令</h3><p><strong>WATCH 命令是一个乐观锁</strong>，可以为 Redis 事务提供CAS。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。<br><strong>MULTI命令用于开启一个事务</strong>。 MULTI执行之后，客户端可向服务器发送任意多条命令，这些命令会被放到一个队列中，当EXEC被调用时，队列中的命令才会被执行。<br><strong>EXEC：执行所有事务块内的命令</strong>。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。<br>通过调用<strong>DISCARD</strong>，客户端可以<strong>清空事务队列，并放弃执行事务</strong>。<br><strong>UNWATCH命令可以取消watch对所有key的监控</strong>。</p><h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><ul><li><p>原子性（Atomicity）<br>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p></li><li><p><strong>一致性（Consistency）</strong><br>事务前后数据的完整性必须保持一致。</p></li><li><p><strong>隔离性（Isolation）</strong><br>多个事务并发执行时，一个事务的执行不应影响其他事务的执行</p></li><li><p>持久性（Durability）<br>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响</p></li></ul><p>Redis的事务具备<strong>一致性和隔离性</strong>。</p><h3 id="Redis事务支持隔离性吗"><a href="#Redis事务支持隔离性吗" class="headerlink" title="Redis事务支持隔离性吗"></a>Redis事务支持隔离性吗</h3><p>支持。Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。</p><h3 id="Redis事务保证原子性吗，支持回滚吗"><a href="#Redis事务保证原子性吗，支持回滚吗" class="headerlink" title="Redis事务保证原子性吗，支持回滚吗"></a>Redis事务保证原子性吗，支持回滚吗</h3><p>单条命令是原子性执行的，但事务不保证原子性，且没有回滚。</p><blockquote><p>如果事务中的命令出现错误，那么所有的命令都不会执行</p><p>如果事务中出现运行错误，那么正确的命令会被执行。</p></blockquote><h3 id="Redis事务其他实现"><a href="#Redis事务其他实现" class="headerlink" title="Redis事务其他实现"></a>Redis事务其他实现</h3><ul><li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行</li></ul><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h3><p><strong>监控</strong></p><ul><li>哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</li><li>主库或从库对 PING 命令的响应超时了，哨兵会标记为主观下线。</li><li>需有quorum 个实例判断主库为主观下线，才能判定主库为客观下线</li></ul><p><strong>选主</strong></p><ul><li>筛选当前在线从库，且网络连接状况较好；</li><li>选择从库<strong>优先级最高</strong>的从库</li><li>选择从库<strong>复制进度最快的</strong></li><li>选择<strong>从库 ID 号小</strong>的</li></ul><p><strong>通知</strong></p><ul><li>通知从库执行replicaof，与新主库同步</li><li>通知客户端，向新主库请求</li></ul><p><strong>通知客户端</strong>的实现方法</p><p>1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。</p><p>2、客户端需要支持主动去获取最新主从的地址进行访问。</p><h3 id="集群模式的工作原理？-key-如何寻址的？"><a href="#集群模式的工作原理？-key-如何寻址的？" class="headerlink" title="集群模式的工作原理？ key 如何寻址的？"></a>集群模式的工作原理？ key 如何寻址的？</h3><p><strong>简介</strong></p><ul><li><p>Redis Cluster是一种服务端Sharding技术。</p></li><li><p>每个key通过CRC16校验后对16384取模来决定放置哪个槽。每个节点存储一定哈希槽的数据，默认分配了16384 个槽位</p></li><li><p>读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点</p></li></ul><p><strong>节点间的内部通信机制</strong></p><p>redis 节点间采用 gossip 协议进行通信。</p><p><strong>分布式寻址算法</strong></p><ul><li>hash 算法（大量缓存重建）</li><li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li><li>redis cluster 的 哈希槽算法（其实也是一致性哈希算法）</li></ul><p><strong>优点</strong></p><ul><li>无中心架构，支持动态扩容，对业务透明</li><li>具备Sentinel的监控和自动Failover能力</li><li>高性能，客户端直连redis服务，免去了proxy代理的损耗</li></ul><p><strong>缺点</strong></p><ul><li>只能使用0号数据库</li><li>不支持批量操作（pipeline管道操作）</li></ul><h3 id="Redis-主从架构"><a href="#Redis-主从架构" class="headerlink" title="Redis 主从架构"></a>Redis 主从架构</h3><p><strong>主从复制原理</strong></p><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系。</p><ol><li><p>主从库间建立连接、协商同步，为全量复制做准备。</p><p>从库和主库建立起连接，发送 psync 命令，表示要进行数据同步。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p><p>主库确认回复，FULLRESYNC响应表示第一次复制采用的全量复制。</p></li><li><p>主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。</p><p>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。</p><p>从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。</p></li><li><p>主库会把第二阶段执行过程中新收到的写命令（replication buffer中的修改操作），再发送给从库。<br>主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p></li></ol><p><strong>缺点</strong></p><p>可能会造成master节点压力太大，使用主从从结构来解决</p><h3 id="增量复制机制"><a href="#增量复制机制" class="headerlink" title="增量复制机制"></a>增量复制机制</h3><ul><li>主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区</li><li>repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。</li><li>连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。</li><li>库还未读取的操作被主库新写的操作覆盖，需要全量复制</li></ul><h3 id="主从集群切换数据丢失"><a href="#主从集群切换数据丢失" class="headerlink" title="主从集群切换数据丢失"></a>主从集群切换数据丢失</h3><p><strong>通过配置控制同步时间</strong></p><p>min-slaves-max-lag、min-slaves-to-write：要求至少有1个slave，数据复制和同步延迟不能超过10秒；如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么master就会拒绝接收任何请求。</p><h3 id="集群模式下key怎么保证在一个节点上？"><a href="#集群模式下key怎么保证在一个节点上？" class="headerlink" title="集群模式下key怎么保证在一个节点上？"></a>集群模式下key怎么保证在一个节点上？</h3><p>分布在一个节点上，可能是需要对这些key做聚合处理。</p><p>基于redis cluster分片机制，key 进行规划和使用 hash tag 特性。在开源 Redis 中，花括号{}表示 hash tag，这个两个花括号中间的字符才会进行 CRC16 散列计算。Crc16 散列函数返回的是一个 14bit 的整数，当中间字符只有数字的时候，CRC16计算的位置就可控了。</p><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><h3 id="Redis是单线程的，如何提高多核CPU的利用率？"><a href="#Redis是单线程的，如何提高多核CPU的利用率？" class="headerlink" title="Redis是单线程的，如何提高多核CPU的利用率？"></a>Redis是单线程的，如何提高多核CPU的利用率？</h3><ul><li>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用。</li><li>把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上</li><li>把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。</li></ul><h3 id="为什么要做Redis分区？"><a href="#为什么要做Redis分区？" class="headerlink" title="为什么要做Redis分区？"></a>为什么要做Redis分区？</h3><p>分区可以让Redis管理更大的内存。</p><p>RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p><h3 id="Redis分区有什么缺点？"><a href="#Redis分区有什么缺点？" class="headerlink" title="Redis分区有什么缺点？"></a>Redis分区有什么缺点？</h3><ul><li>涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例。</li><li>同时操作多个key，则不能使用Redis事务.</li></ul><h2 id="分布式问题"><a href="#分布式问题" class="headerlink" title="分布式问题"></a>分布式问题</h2><h3 id="Redis实现分布式锁"><a href="#Redis实现分布式锁" class="headerlink" title="Redis实现分布式锁"></a>Redis实现分布式锁</h3><p><strong>加锁</strong></p><ul><li><p><code>SET key value [EX seconds | PX milliseconds]  [NX]</code></p></li><li><p>key 不存在， key 会被创建。</p></li><li><p>Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。</p></li><li><p>过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p></li></ul><p><strong>解锁</strong></p><p>执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。</p><p><strong>缺点</strong></p><ul><li>它获取锁的方式简单粗暴，<strong>获取不到锁直接不断尝试获取锁</strong>，比较消耗性能。</li><li>即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。</li><li>Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如<strong>，锁过期问题</strong>。</li></ul><p><strong>优点</strong></p><p> Redis 的性能很高，可以支撑高并发的获取、释放锁操作</p><h3 id="Zookeeper-实现"><a href="#Zookeeper-实现" class="headerlink" title="Zookeeper 实现"></a>Zookeeper 实现</h3><ul><li>使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。</li><li>创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。</li><li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。</li><li>如果当前线程创建的节点不是所有节点序号最小的节点，则<strong>对节点序号的前一个节点添加一个事件监听</strong>。</li></ul><p><strong>优点</strong></p><ul><li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</li><li>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</li></ul><p><strong>缺点</strong></p><p>如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</p><h3 id="分布式Redis是前期做还是后期规模上来了再做好？为什么？"><a href="#分布式Redis是前期做还是后期规模上来了再做好？为什么？" class="headerlink" title="分布式Redis是前期做还是后期规模上来了再做好？为什么？"></a>分布式Redis是前期做还是后期规模上来了再做好？为什么？</h3><p>一开始就多设置几个Redis实例，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是<strong>仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）</strong>。</p><h3 id="什么是-RedLock"><a href="#什么是-RedLock" class="headerlink" title="什么是 RedLock"></a>什么是 RedLock</h3><p>分布式锁算法 Redlock</p><ul><li><p>客户端获取当前时间。</p></li><li><p>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p></li><li><p>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</p></li><li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功</p></li><li><p>别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</p></li></ul><p><strong>缺点</strong></p><p>无法保证加锁的过程一定正确</p><h2 id="缓存异常"><a href="#缓存异常" class="headerlink" title="缓存异常"></a>缓存异常</h2><p><a href="https://wangyixin-tom.github.io/2020/10/27/redis-huan-cun">https://wangyixin-tom.github.io/2020/10/27/redis-huan-cun</a></p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存</p><p><strong>解决方案</strong></p><ul><li>统计出频率较高的热数据，直接写个缓存刷新页面，上线时手工操作一下；</li></ul><h3 id="缓存热点key过期"><a href="#缓存热点key过期" class="headerlink" title="缓存热点key过期"></a><strong>缓存热点key</strong>过期</h3><p>一般都会从后端DB加载数据并回设到缓存，大并发的请求可能会瞬间把后端DB压垮。</p><p><strong>解决方案</strong></p><p><strong>对缓存查询加锁</strong>：如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；</p><p>其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询</p><h3 id="热key怎么解决？"><a href="#热key怎么解决？" class="headerlink" title="热key怎么解决？"></a>热key怎么解决？</h3><h4 id="怎么发现热key"><a href="#怎么发现热key" class="headerlink" title="怎么发现热key"></a>怎么发现热key</h4><p><strong>方法一:预估哪些是热key</strong><br>比如某商品在做秒杀，那这个商品的key就可以判断出是热key。缺点很明显，并非所有业务都能预估出哪些key是热key。<br><strong>方法二:在客户端进行收集</strong><br>这个方式就是在操作redis之前，加入一行代码进行数据统计。缺点就是对客户端代码造成入侵。<br><strong>方法三:在Proxy层做收集</strong><br>可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。</p><p><strong>方法四:用redis自带命令</strong><br>monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。</p><h4 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h4><ul><li>利用二级缓存</li></ul><p>在你发现热key以后，把热key加载到系统的JVM中。针对这种热key请求，会直接从jvm中取，而不会走到redis层。</p><ul><li>备份热key</li></ul><p>我们把这个key，在多个redis上都存一份，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。</p><h2 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h2><h3 id="Redis与Memcached的区别"><a href="#Redis与Memcached的区别" class="headerlink" title="Redis与Memcached的区别"></a>Redis与Memcached的区别</h3><p>(1) memcached所有的值均是简单的字符串，redis支持更为丰富的数据类型</p><p>(2) redis的速度比memcached快很多</p><p>(3) redis可以持久化数据</p><h3 id="如何保证缓存与数据库双写时的数据一致性？"><a href="#如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="如何保证缓存与数据库双写时的数据一致性？"></a>如何保证缓存与数据库双写时的数据一致性？</h3><p>先更新数据库，然后再删除缓存。</p><h3 id="Redis常见性能问题和解决方案？"><a href="#Redis常见性能问题和解决方案？" class="headerlink" title="Redis常见性能问题和解决方案？"></a>Redis常见性能问题和解决方案？</h3><ul><li><p>Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。</p></li><li><p>如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。</p></li><li><p>为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。</p></li><li><p>尽量避免在压力较大的主库上增加从库</p></li></ul><h3 id="一个字符串类型的值能存储最大容量是多少？"><a href="#一个字符串类型的值能存储最大容量是多少？" class="headerlink" title="一个字符串类型的值能存储最大容量是多少？"></a>一个字符串类型的值能存储最大容量是多少？</h3><p>512M</p><h3 id="Redis如何做大量数据插入？"><a href="#Redis如何做大量数据插入？" class="headerlink" title="Redis如何做大量数据插入？"></a>Redis如何做大量数据插入？</h3><p>pipe mode的新模式用于执行大量数据插入工作。</p><h3 id="Lua脚本是如何保证操作的原子性的"><a href="#Lua脚本是如何保证操作的原子性的" class="headerlink" title="Lua脚本是如何保证操作的原子性的"></a>Lua脚本是如何保证操作的原子性的</h3><p>Redis使用同一个Lua解释器来执行所有命令，同时，Redis保证以一种原子性的方式来执行脚本：当lua脚本在执行的时候，不会有其他脚本和命令同时执行，这种语义类似于 MULTI/EXEC。</p><p>从别的客户端的视角来看，一个lua脚本要么不可见，要么已经执行完。</p><h3 id="找出Redis里面有10w个key是以某个固定的已知的前缀开头的"><a href="#找出Redis里面有10w个key是以某个固定的已知的前缀开头的" class="headerlink" title="找出Redis里面有10w个key是以某个固定的已知的前缀开头的"></a>找出Redis里面有10w个key是以某个固定的已知的前缀开头的</h3><p>使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</p><h3 id="redis数据统计，在高并发下的问题？"><a href="#redis数据统计，在高并发下的问题？" class="headerlink" title="redis数据统计，在高并发下的问题？"></a>redis数据统计，在高并发下的问题？</h3><p>Set 集合的交差并的计算复杂度很高，如果数据量很大的情况下，可能会造成Redis的阻塞。</p><p>那么如何规避阻塞呢？建议如下：</p><ol><li>在 Redis 集群中选一个从库专门负责聚合统计，这样就不会阻塞主库和其他的从库了</li><li>将数据交给客户端，由客户端进行聚合统计。</li></ol><h3 id="big-key如何优化"><a href="#big-key如何优化" class="headerlink" title="big key如何优化"></a>big key如何优化</h3><ol><li>优化big key的原则就是string减少字符串长度，list、hash、set、zset等拆分减少成员数</li><li>以hash类型举例来说，对于field过多的场景，可以根据field进行hash取模，生成一个新的key，例如原来的hash_key:{filed1:value, filed2:value, filed3:value …}，可以hash取模后形成如下key:value形式<br>hash_key:mod1:{filed1:value}<br>hash_key:mod2:{filed2:value}<br>hash_key:mod3:{filed3:value}<br>取模后，将原先单个key分成多个key，每个key filed个数为原先的1/N</li></ol><h3 id="big-key-删除"><a href="#big-key-删除" class="headerlink" title="big key 删除"></a>big key 删除</h3><p>1、异步的键值对删除操作是 Redis 4.0 后提供的功能。</p><p>2、之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令（sscan、hscan、zscan）读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p><h3 id="redis怎么防止超买"><a href="#redis怎么防止超买" class="headerlink" title="redis怎么防止超买"></a>redis怎么防止超买</h3><ul><li>先检查 库存是否充足</li><li>DECR或者INCR，设置一个键值对存放被抢购数量，每次一个用户进来就将该值加一进行判断，如果小于抢购的商品数量则抢购成功，否则失败。</li><li>如果超过数字，需要恢复库存，其他人可以买剩下的较少数量物品</li></ul><p>最好使用lua脚本实现</p><p>或者使用事务机制</p><h3 id="mget和pipeline区别"><a href="#mget和pipeline区别" class="headerlink" title="mget和pipeline区别"></a>mget和pipeline区别</h3><ul><li>mget和pipeline都是多命令一起执行，只有一次往返的网络IO</li><li>mget在集群下可以并行去获取，pipeline还是串行</li></ul><h3 id="使用Redis做过异步队列吗，是如何实现的"><a href="#使用Redis做过异步队列吗，是如何实现的" class="headerlink" title="使用Redis做过异步队列吗，是如何实现的"></a>使用Redis做过异步队列吗，是如何实现的</h3><p>使用list类型保存数据信息，rpush生产消息，</p><p>使用blpop消费消息, 在没有信息的时候，会一直阻塞，直到信息的到来。</p><p>redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。</p><h3 id="Redis如何实现延时队列"><a href="#Redis如何实现延时队列" class="headerlink" title="Redis如何实现延时队列"></a>Redis如何实现延时队列</h3><p>使用sortedset，使用时间戳做score, 消息内容作为key，调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。</p><h3 id="如何实现分页"><a href="#如何实现分页" class="headerlink" title="如何实现分页"></a>如何实现分页</h3><p>SortedSet的添加元素指令<code>ZADD key score member [[score,member]…]</code>会给每个添加的元素member绑定一个用于排序的值score，SortedSet就会根据score值的大小对元素进行排序。</p><p>SortedSet中的指令<code>ZREVRANGE key start stop</code>又可以返回指定区间内的成员，可以用来做分页</p><h3 id="Redis回收进程如何工作的？"><a href="#Redis回收进程如何工作的？" class="headerlink" title="Redis回收进程如何工作的？"></a>Redis回收进程如何工作的？</h3><p>Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。</p><h3 id="RDB持久化内存分析"><a href="#RDB持久化内存分析" class="headerlink" title="RDB持久化内存分析"></a>RDB持久化内存分析</h3><blockquote><p>使用 4GB 内存云主机运行 Redis，Redis 数据库的数据量 2GB，我们使用了 RDB 做持久化保证，写读比例差不多在 8:2 左右。</p></blockquote><p>redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和</p><p>如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。</p><p>如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。</p><h3 id="商品秒杀实现过程"><a href="#商品秒杀实现过程" class="headerlink" title="商品秒杀实现过程"></a>商品秒杀实现过程</h3><p><strong>分析</strong></p><p>秒杀活动可以分为3个阶段：</p><p><strong>秒杀前：</strong>用户不断刷新商品详情页，页面请求达到瞬时峰值。</p><p><strong>秒杀开始：</strong>用户点击秒杀按钮，下单请求达到瞬时峰值。</p><p><strong>秒杀后：</strong>一部分成功下单的用户不断刷新订单或者产生退单操作，大部分用户继续刷新商品详情页等待退单机会。消费者提交订单，一般做法是利用数据库的行级锁，只有抢到锁的请求可以进行库存查询和下单操作。但是在高并发的情况下，数据库无法承担如此大的请求，往往会使整个服务blocked，在消费者看来就是服务器宕机。</p><p><strong>实施</strong></p><p>1、<strong>利用浏览器缓存和CDN抗压静态页面流量</strong></p><p>秒杀前，用户不断刷新商品详情页，造成大量的页面请求。</p><p>2、<strong>利用读写分离Redis缓存拦截流量</strong></p><p>CDN是第一级流量拦截，第二级流量拦截我们使用支持读写分离的Redis。</p><p>3、<strong>利用主从版Redis缓存加速库存扣量</strong></p><p>成功参与下单后，进入下层服务，开始进行订单信息校验，库存扣量。为了避免直接访问数据库，我们使用主从版Redis来进行库存扣量，主从版Redis提供10万级别的QPS。使用Redis来优化库存查询，提前拦截秒杀失败的请求，将大大提高系统的整体吞吐量。通过数据控制模块提前将库存存入Redis，将每个秒杀商品在Redis中用一个hash结构表示。</p><p>4、<strong>使用主从版Redis实现简单的消息队列异步下单入库</strong></p><p>扣量完成后，需要进行订单入库。如果商品数量较少的时候，直接操作数据库即可。<strong>如果秒杀的商品是1万</strong>，甚至10万级别，那数据库锁冲突将带来很大的性能瓶颈。因此，<strong>利用消息队列组件，当秒杀服务将订单信息写入消息队列后，即可认为下单完成，避免直接操作数据库。</strong>消息队列组件依然可以使用Redis实现。</p>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql数据类型</title>
      <link href="/2021/04/11/mysql-shu-ju-lei-xing/"/>
      <url>/2021/04/11/mysql-shu-ju-lei-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。</p><p>长度：整数类型可以被指定长度，例如：<code>INT(11)</code>表示长度为11的INT类型。长度不会限制值的合法范围，只会影响显示字符的个数。</p><p>2、实数类型，包括FLOAT、DOUBLE、DECIMAL。</p><p>DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。</p><p>FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节</p><p>计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。</p><p>3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB</p><p>VARCHAR用于存储可变长字符串，它比定长类型更节省空间。</p><p>VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。</p><p>VARCHAR存储的内容超出设置的长度时，内容会被截断。</p><p>CHAR是定长的，根据定义的字符串长度分配足够的空间。</p><p>CHAR会根据需要使用空格进行填充方便比较。</p><p>CHAR适合存储很短的字符串，或者所有值都接近同一个长度。</p><p>CHAR存储的内容超出设置的长度时，内容同样会被截断。</p><p><strong>使用策略：</strong></p><p>对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。</p><p>对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。</p><p>使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。</p><p>尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。</p><p>4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。</p><p>有时可以使用ENUM代替常用的字符串类型。</p><p>ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。</p><p>ENUM在内部存储时，其实存的是整数。</p><p>尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。</p><p>排序是按照内部存储的整数</p><p>5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，</p><p>用整数保存时间戳通常不方便处理。</p><p>如果需要存储微秒，可以使用bigint存储。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql存储引擎</title>
      <link href="/2021/04/11/mysql-cun-chu-yin-qing/"/>
      <url>/2021/04/11/mysql-cun-chu-yin-qing/</url>
      
        <content type="html"><![CDATA[<h2 id="innodb和myisiam区别"><a href="#innodb和myisiam区别" class="headerlink" title="innodb和myisiam区别"></a>innodb和myisiam区别</h2><p><strong>Innodb引擎：</strong>支持数据库ACID事务。并且还提供了行级锁和外键。它的设计的目标就是处理大数据容量的数据库系统，InnoDB 适合频繁修改以及涉及到安全性较高的应用；。</p><p><strong>MyIASM引擎</strong>：不提供事务的支持，也不支持行级锁和外键。MyISAM 适合查询以及插入为主的应用</p><table><thead><tr><th></th><th><strong>MyISAM</strong></th><th><strong>Innodb</strong></th></tr></thead><tbody><tr><td>存储结构</td><td><strong>每张表被存放在三个文件：frm表格定义、MYD数据文件、MYI索引文件</strong></td><td><strong>所有的表都保存在同一个数据文件中</strong>（也可能是多个文件，或者是独立的表空间文件）</td></tr><tr><td>存储空间</td><td>MyISAM索引是有压缩的，存储空间较小</td><td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td></tr><tr><td>文件格式</td><td><strong>数据和索引是分别存储的，数据.MYD，索引.MYI</strong></td><td><strong>数据和索引是集中存储的，.ibd</strong></td></tr><tr><td>记录存储顺序</td><td>按记录插入顺序保存</td><td>按主键大小有序插入</td></tr><tr><td>外键</td><td>不支持</td><td>支持</td></tr><tr><td>事务</td><td>不支持</td><td>支持</td></tr><tr><td>锁支持</td><td>表级锁定</td><td>行级锁定、表级锁定，锁定力度小并发能力高</td></tr><tr><td>select count(*)</td><td>myisam更快，myisam内部维护了计数器。</td><td></td></tr><tr><td>索引的实现方式</td><td>B+树索引</td><td>B+树索引</td></tr></tbody></table><h3 id="MyISAM索引与InnoDB索引的区别"><a href="#MyISAM索引与InnoDB索引的区别" class="headerlink" title="MyISAM索引与InnoDB索引的区别"></a>MyISAM索引与InnoDB索引的区别</h3><p>InnoDB索引是<strong>聚簇索引</strong>，MyISAM索引是<strong>非聚簇索引</strong>。</p><p>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p><p>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效</p><p><strong>其他</strong></p><ul><li><strong>InnoDB支持事务，MyISAM不支持</strong></li><li><strong>InnoDB支持外键，MyISAM不支持</strong></li><li><strong>InnoDB支持行锁</strong>（某些情况下还是锁整表，如 <code>update table set a=1 where user like &#39;%lee%&#39;</code></li><li>MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用</li><li>InnoDB中不保存表的行数，如<code>select count(*) from table</code>时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当<code>count(*)</code>语句包含where条件时MyISAM也需要扫描整个表</li><li>对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引</li><li>清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表</li></ul><h2 id="InnoDB引擎的4大特性"><a href="#InnoDB引擎的4大特性" class="headerlink" title="InnoDB引擎的4大特性"></a>InnoDB引擎的4大特性</h2><h3 id="写缓冲（change-buffer）"><a href="#写缓冲（change-buffer）" class="headerlink" title="写缓冲（change buffer）"></a>写缓冲（change buffer）</h3><p>Insert Buffer 用于非聚集索引的插入和更新操作。先判断插入的非聚集索引是否在缓存池中，如果在则直接插入，否则插入到 Insert Buffer 对象里。再以一定的频率进行 Insert Buffer 和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，减少随机IO带来性能损耗，提高对非聚集索引的插入性能。</p><blockquote><pre class="line-numbers language-text"><code class="language-text">使用 Insert Buffer的两个条件- 索引是辅助索引- 索引不唯一，如果索引唯一还要去查找索引页进行检查唯一性，就失去了 Insert Buffer 离散插入的性能<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></blockquote><h3 id="二次写"><a href="#二次写" class="headerlink" title="二次写"></a>二次写</h3><p>mysql最小的io单位是16k，文件系统io最小的单位是4k，因此存在IO写入导致page损坏的风险</p><p>如果数据库发生宕机时，可以通过重做日志对该页进行恢复，但是如果该页本身已经损坏了，进行重做恢复是没有意义的。因此引入了”二次写”方案，解决部分写失败，提高数据页的稳定性。</p><p><strong>流程</strong></p><ul><li>对缓存池的脏页进行刷新时，不直接写入磁盘，而是通过 memcpy 函数将脏页复制到内存中的 doublewrite buffer。</li><li>将内存中的 doublewrite buffer 写入共享表空间的物理磁盘上（备份）。</li><li>将 doublewrite buffer 中的数据真正的刷新到表磁盘中。</li><li>如果写 doublewrite buffer 失败，那么这些数据不会写到磁盘，innodb 会载入磁盘原始数据和 redo 日志比较，并重新刷到 doublewrite buffer。</li><li>如果写 doublewrite buffer 成功，但是刷新到磁盘失败，那么 innodb 就不会通过redo日志来恢复了，而是直接刷新 double write buffer 中的数据到磁盘。</li></ul><p><strong>doublewirte的崩溃恢复</strong></p><p>如果操作系统在将页写入磁盘的过程中发生崩溃，在恢复过程中，innodb存储引擎可以从共享表的空间的doblewrite中找到该页的一个最近副本，将其复制到表空间文件，在应用redo log,就完成了恢复过程。</p><p><strong>副作用：double write带来的写负担</strong></p><p>double write是在物理文件上的一个buffer,会导致系统有更多的fsync操作,而磁盘的fsync性能是很慢的,所以会降低mysql的整体性能</p><p>但是doublewrite buffer写入磁盘共享表达空间这个过程是连续存储,是顺序写,性能非常高,牺牲这一点来保证该数据也的完整性还是很有必要的</p><p><strong>关闭double write适合的场景</strong></p><ul><li>海量的增删改</li><li>不惧怕系统数据损坏和丢失</li><li>系统写负载为主要负载</li></ul><h3 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h3><p>InnoDB 会监控对表上各个索引页的查询，如果观察到通过哈希索引可以带来性能提升，则自动建立哈希索引。自适应哈希索引通过缓存池的 B+ 树页构造而来，因此建立速度很快。</p><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul><li>无序,没有树高</li><li>降低对二级索引树的频繁访问资源</li><li>自适应</li></ul><h4 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h4><ul><li>hash自适应索引会占用innodb buffer pool;</li><li>自适应hash索引值适合搜索等值查询,如select * from table where index_col=’xxx’，而对于其他查找类型，如范围查找，是不能使用的；</li><li>极端情况下,自适应hash索引才有比较大的意义</li></ul><h3 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h3><p>数据库访问通常都遵循集中读取原则，使用一些数据大概率会使用附近的数据，这就是所谓的局部性原理，它表明提前加载是有效的，能减少磁盘的i/o。</p><p>预读机制就是发起一个i/o请求，异步的在缓冲池中预先回迁若干个页面,预计将会用到的页面回迁.</p><h2 id="存储引擎选择"><a href="#存储引擎选择" class="headerlink" title="存储引擎选择"></a>存储引擎选择</h2><p>如果没有特别的需求，使用默认的Innodb即可。</p><p>MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。</p><p>Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/109528131" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/109528131</a></p><p><a href="https://zhuanlan.zhihu.com/p/64180357" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/64180357</a></p><p><a href="https://www.nasuiyile.cn/219.html" target="_blank" rel="noopener">https://www.nasuiyile.cn/219.html</a></p><p><a href="https://www.cnblogs.com/geaozhang/p/7241744.html" target="_blank" rel="noopener">https://www.cnblogs.com/geaozhang/p/7241744.html</a></p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql日志系统</title>
      <link href="/2021/04/11/mysql-ri-zhi-xi-tong/"/>
      <url>/2021/04/11/mysql-ri-zhi-xi-tong/</url>
      
        <content type="html"><![CDATA[<h2 id="日志系统"><a href="#日志系统" class="headerlink" title="日志系统"></a>日志系统</h2><h3 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h3><ol><li><p>InnoDB引擎日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）</p></li><li><p>在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）</p></li><li><p>redo log 是物理日志，记录的是在某个数据页上做了什么修改</p></li><li><p>redo log是循环写，空间固定会用完</p></li></ol><h3 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h3><ol><li><p>server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力</p></li><li><p>binlog是逻辑日志，记录的是记录所有数据库表结构变更（CREATE、ALTER）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志</p></li><li><p>binlog采用追加写的模式</p></li><li><p><strong>用途：</strong>  </p></li></ol><ul><li><p>恢复：binlog日志恢复数据库数据  </p></li><li><p>复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  </p></li><li><p>审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击</p></li></ul><p><strong>binlog常见格式</strong></p><table><thead><tr><th>format</th><th>定义</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>statement</td><td>记录的是修改SQL语句</td><td>日志文件小，节约IO，提高性能</td><td>准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况）</td></tr><tr><td>row</td><td>记录的是每行实际数据的变更</td><td>准确性强，能准确复制数据的变更</td><td>日志文件大，较大的网络IO和磁盘IO</td></tr><tr><td>mixed</td><td>statement和row模式的混合</td><td>准确性强，文件大小适中</td><td>有可能发生主从不一致问题</td></tr></tbody></table><h3 id="两段提交"><a href="#两段提交" class="headerlink" title="两段提交"></a>两段提交</h3><ol><li><p>保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致</p></li><li><p>两段提交: 写入redo log处于prepare阶段 –（A）- 写入bin log -（B）– 提交事务处于commit状态 </p><ul><li><p>时刻A崩溃恢复: redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  </p></li><li><p>时刻B崩溃恢复: 如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，“是”提交事务，”否“回滚事务</p></li></ul></li><li><p>bin log完整性判断:  </p><ul><li><p>statement格式最后有commit  </p></li><li><p>row格式最有有一个XID event（redo log 和 bin log关联：有一个共同字段XID）</p></li></ul></li></ol><h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3><ol><li><p>undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</p></li><li><p>undo log 作用  </p><ul><li><p>提供回滚  </p></li><li><p>多个行版本控制（MVCC）</p></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql必知必会</title>
      <link href="/2021/04/10/interview-mysql/"/>
      <url>/2021/04/10/interview-mysql/</url>
      
        <content type="html"><![CDATA[<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><strong>server层</strong></p><ol><li><p>连接器：管理连接，权限验证</p></li><li><p>查询缓存</p></li><li><p>分析器：词法、语法解析</p></li><li><p>优化器：生成执行计划，索引选择</p></li><li><p>执行器：操作引擎，返回结果</p></li></ol><p><strong>存储引擎层</strong></p><ol><li>负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎</li></ol><p><strong>Innodb</strong></p><p>后台线程：负责刷新内存池中的数据，保证缓存池中的内存缓存是最近的数据，将已修改的数据刷新到磁盘文件，同时保证数据库发生异常的情况能恢复到正常情况；</p><p>内存池：内存池也可以叫做缓存池，主要为弥补磁盘的速度较慢对数据库产生的影响，查询的时候，首先将磁盘读到的页的数据放在内存池中，下次读取的时候直接从内存池中读取数据，修改数据的时候，首先修改内存池中的数据，然后后台线程按照一定的频率刷新到磁盘上。</p><h2 id="日志系统"><a href="#日志系统" class="headerlink" title="日志系统"></a>日志系统</h2><h3 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h3><ol><li>InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe），<strong>确保事务的持久性</strong>。</li><li>在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存（buffer pool），此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略<strong>将 redo log 中的内容更新到磁盘中</strong>，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）</li><li>redo log 是物理日志，记录的是在某个数据页上做了什么修改</li><li>redo log是循环写，空间固定会用完</li></ol><blockquote><p>出现 MySQL 宕机或者断电时，如果有缓存页的数据还没来得及刷入磁盘，当 MySQL 重新启动时，可以根据 redo log 日志文件，进行数据重做，将数据恢复到宕机或者断电前的状态</p><p>redo log 日志文件是持久化在磁盘上的，磁盘上可以有多个 redo log 文件，MySQL 默认有 2 个 redo log 文件，每个文件大小为 48M</p><p> redo log 日志是存储在磁盘上的，那么此时是不是立马就将 redo log 日志写入磁盘呢？显然不是的，而是先写入一个叫做 redo log buffer 的缓存中，redo log buffer 是一块不同于 buffer pool 的内存缓存区</p></blockquote><p><strong>为什么MySQL 要写到 redo log buff 内存</strong></p><p>因为一个事务中可能涉及到多次读写操作，写入Buffer中分组写入，比起一条条的写入磁盘文件，效率会高很多。</p><h3 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h3><ol><li><p>server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力</p></li><li><p>binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志</p></li><li><p>binlog采用追加写的模式</p></li><li><p><strong>用途：</strong>  </p></li></ol><ul><li>恢复：binlog日志恢复数据库数据</li><li>复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  </li><li>审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击</li></ul><p><strong>binlog常见格式</strong></p><table><thead><tr><th>format</th><th>定义</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>statement</td><td>记录的是修改SQL语句</td><td>日志文件小，节约IO，提高性能</td><td>准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况）</td></tr><tr><td>row</td><td>记录的是每行实际数据的变更</td><td>准确性强，能准确复制数据的变更</td><td>日志文件大，较大的网络IO和磁盘IO</td></tr><tr><td>mixed</td><td>statement和row模式的混合</td><td>准确性强，文件大小适中</td><td>有可能发生主从不一致问题</td></tr></tbody></table><h3 id="两段提交"><a href="#两段提交" class="headerlink" title="两段提交"></a>两段提交</h3><ol><li><p>两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致</p></li><li><p>两段提交： 写入redo log处于prepare阶段 –写入bin log –提交事务处于commit状态 </p></li></ol><ul><li>时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  </li><li>时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务</li></ul><ol start="3"><li>bin log完整性判断：  </li></ol><ul><li>statement格式最后有commit  </li><li>row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）</li></ul><p>MySQL 重启后，进行数据重做时，在 redo log 日志中由于该事务的 redo log 日志没有 commit 标识，那么就不会进行数据重做，磁盘上数据还是原来的数据，也就是事务没有提交。</p><h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3><ol><li><p>undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</p></li><li><p>undo log 作用  </p></li></ol><ul><li>提供回滚</li><li>多版本并发控制</li></ul><h3 id="宕机恢复流程？"><a href="#宕机恢复流程？" class="headerlink" title="宕机恢复流程？"></a>宕机恢复流程？</h3><ol><li><p>启动开始时检测是否发生崩溃</p></li><li><p>定位到最近的一个checkpoint</p></li><li><p>定位在这个checkpoint时flush到磁盘的数据页，检查checksum。如果不正确，说明这个页在上次写入是不完整的，从doublewrite buffer里把正确的页读出来，更新到buffer中的页</p></li><li><p>分析redo log，标识出未提交事务</p></li><li><p>顺序执行redo，读取到buffer pool中</p></li><li><p>rollback未提交的事务</p></li></ol><h3 id="Mysql抖动"><a href="#Mysql抖动" class="headerlink" title="Mysql抖动"></a>Mysql抖动</h3><p>当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。</p><p><strong>flush场景</strong></p><ol><li>InnoDB 的 redo log  buffer写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘</li><li>系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是”脏页”，就要先将脏页写到磁盘</li><li>MySQL 认为系统空闲的时候，会flush脏页</li><li>MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上</li></ol><p>InnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度</p><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>默认存储引擎</p><ul><li><p>实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。</p></li><li><p>主键索引是聚簇索引，在索引中保存了数据。</p></li><li><p>内部做了很多优化，包括预读、自适应哈希索引、插入缓冲区等。</p></li><li><p>支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。</p></li></ul><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>适用于只读数据，或者表比较小。</p><ul><li><p>提供了大量的特性，包括压缩表、空间数据索引等。</p></li><li><p>不支持事务。</p></li><li><p>不支持行级锁，只能对整张表加锁</p></li></ul><h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><ul><li>事务：InnoDB 支持事务。</li><li>并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。</li><li>外键：InnoDB 支持外键。</li><li>备份：InnoDB 支持在线热备份。</li><li>崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。</li><li>其它特性：MyISAM 支持压缩表和空间数据索引。</li></ul><h3 id="MyISAM与InnoDB索引区别"><a href="#MyISAM与InnoDB索引区别" class="headerlink" title="MyISAM与InnoDB索引区别"></a>MyISAM与InnoDB索引区别</h3><p>InnoDB索引是<strong>聚簇索引</strong>，MyISAM索引是<strong>非聚簇索引</strong>。</p><p>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM主键索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p><p>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效</p><h3 id="为什么myisam-的查询要比innoDB-快"><a href="#为什么myisam-的查询要比innoDB-快" class="headerlink" title="为什么myisam 的查询要比innoDB 快"></a>为什么myisam 的查询要比innoDB 快</h3><p>1）InnoDB 要缓存数据和索引，MyISAM只缓存索引块， 这中间还有换进换出的减少；</p><p>2）InnoDB寻址要映射到块，再到行，MyISAM记录的直接是文件的OFFSET，定位比InnoDB要快</p><p>3）InnoDB还需要维护MVCC一致</p><h3 id="b-树为什么能三层能存2000多万个，计算过程。"><a href="#b-树为什么能三层能存2000多万个，计算过程。" class="headerlink" title="b+树为什么能三层能存2000多万个，计算过程。"></a>b+树为什么能三层能存2000多万个，计算过程。</h3><p>InnoDB存储引擎最小储存单元，页大小是16K。假设一行数据的大小是1k，一个页可以存放16行数据。</p><p>在B+树中叶子节点存放数据，非叶子节点存放键值+指针。我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，<code>16384/14=1170</code>。一棵高度为2的B+树，能存放<code>1170*16=18720</code>条这样的数据记录。高度为3的B+树可以存放：<code>1170*1170*16=21902400</code>条这样的记录。</p><p>所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。</p><h3 id="Innodb引擎特性"><a href="#Innodb引擎特性" class="headerlink" title="Innodb引擎特性"></a>Innodb引擎特性</h3><h4 id="写缓冲（change-buffer）"><a href="#写缓冲（change-buffer）" class="headerlink" title="写缓冲（change buffer）"></a>写缓冲（change buffer）</h4><p>Insert Buffer用于非聚集索引的插入和更新操作。先判断插入的非聚集索引是否在缓存池中，如果在则直接插入，否则插入到 Insert Buffer 对象里。再以一定的频率进行 Insert Buffer 和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，减少随机IO带来性能损耗，提高对非聚集索引的插入性能。</p><h4 id="二次写"><a href="#二次写" class="headerlink" title="二次写"></a>二次写</h4><p>mysql最小的io单位是16k，文件系统io最小的单位是4k，因此存在IO写入导致page损坏的风险</p><p>如果数据库发生宕机时，可以通过重做日志对该页进行恢复，但是如果该页本身已经损坏了，进行重做恢复是没有意义的。因此引入了”二次写”方案，解决部分写失败，提高数据页的稳定性。</p><h4 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h4><p>InnoDB 会监控对表上各个索引页的查询，如果观察到通过哈希索引可以带来性能提升，则自动建立哈希索引。自适应哈希索引通过缓存池的 B+ 树页构造而来，因此建立速度很快。</p><h4 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h4><p>数据库访问通常都遵循集中读取原则，使用一些数据大概率会使用附近的数据，这就是所谓的局部性原理，它表明提前加载是有效的，能减少磁盘的i/o。</p><p>预读机制就是发起一个i/o请求，异步的在缓冲池中预先回迁若干个页面，预计将会用到的页面回迁。</p><h3 id="MyISAM为什么不支持事务"><a href="#MyISAM为什么不支持事务" class="headerlink" title="MyISAM为什么不支持事务"></a>MyISAM为什么不支持事务</h3><p>MyISAM存储引擎没有redo和undo文件，没法支持事务的ACID特性，锁也只有表锁</p><h3 id="数据库字段是如何存储的"><a href="#数据库字段是如何存储的" class="headerlink" title="数据库字段是如何存储的"></a>数据库字段是如何存储的</h3><ul><li>所有数据都被逻辑地存放在表空间中，表空间又由段（segment）、区（extent）、页（page）组成</li><li>表空间由各个段构成，叶子节点存储在数据段，非叶子节点存储在索引段</li><li>段由区组成</li><li>区是由连续的页组成，默认区的大小为1M，页的大小为16KB</li><li>页是InnoDB磁盘管理的最小单位。页中存储的是具体的行记录。一行记录最终以二进制的方式存储在文件里。</li></ul><blockquote><p>默认情况下用一个共享表空间 ibdata1 ，如果开启了 innodb_file_per_table 则每张表的数据将存储在单独的表空间中，也就是每张表都会有一个文件</p></blockquote><h3 id="缓存淘汰策略"><a href="#缓存淘汰策略" class="headerlink" title="缓存淘汰策略"></a>缓存淘汰策略</h3><p>全表扫描和预读机制可能将频繁访问的数据给淘汰，优化思路就是：对数据进行冷热分离，将 LRU 链表分成两部分，一部分用来存放冷数据，也就是刚从磁盘读进来的数据，另一部分用来存放热点数据，也就是经常被访问到数据。按照5：3的比例把整个LRU链表分成了young区域和old区域。</p><p>1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部</p><p>2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p><p>3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p><ul><li>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</li><li>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。</li></ul><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。</p><p>索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>索引的优点</strong></p><ul><li>加快数据的检索速度。</li><li>减少查询中分组和排序的时间</li><li>唯一性索引，可以保证数据的唯一性</li><li>将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）</li></ul><p><strong>索引的缺点</strong></p><ul><li>建立和维护索引耗费时间、空间</li></ul><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p><strong>where</strong></p><p><strong>order by</strong></p><p>使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据<strong>使用磁盘临时文件完成外部排序或者在内存中完成排序</strong>。具体取决于排序所需的内存和参数sort_buffer_size。</p><p>如果我们对该字段建立索引，由于索引本身是有序的，因此直接<strong>按照索引的顺序和映射关系逐条取出数据即可</strong>。</p><p><strong>join</strong></p><p>对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）</p><p><strong>覆盖索引</strong></p><p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p><p>如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。</p><blockquote><p>尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。</p></blockquote><h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h3><p><strong>主键索引</strong>： 不允许重复，不允许为NULL，一个表只能有一个主键。</p><p><strong>唯一索引</strong>：不允许重复，允许为NULL。</p><p><strong>普通索引</strong>：基本的索引类型，允许为NULL值。</p><p><strong>全文索引</strong>： 是目前搜索引擎使用的一种关键技术。</p><h3 id="创建索引的原则"><a href="#创建索引的原则" class="headerlink" title="创建索引的原则"></a>创建索引的原则</h3><ul><li>联合索引的最左前缀匹配原则，mysql会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立<code>(a,b,c,d)</code>顺序的索引，d是用不到索引的，如果建立<code>(a,b,d,c)</code>的索引则都可以用到，a,b,d的顺序可以任意调整。</li><li>较频繁作为查询条件的字段才去创建索引，更新频繁字段不适合创建索引</li><li>若是不能有效区分数据的列不适合做索引列（如性别），选择基数较大的列做索引</li><li><strong>使用短索引</strong>，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间。一页存储的数据越多一次IO操作获取的数据越大，效率越高。</li><li>尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加<code>(a,b)</code>的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。</li><li><strong>非空字段：</strong>应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</li><li><strong>不要过度索引</strong>。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。</li></ul><h3 id="使用索引查询一定能提高查询的性能吗"><a href="#使用索引查询一定能提高查询的性能吗" class="headerlink" title="使用索引查询一定能提高查询的性能吗"></a>使用索引查询一定能提高查询的性能吗</h3><p>使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况：</p><ul><li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%</li><li><strong>基于非唯一性索引的检索（？？？）</strong></li></ul><p>通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。</p><p><strong>索引需要空间来存储，也需要定期维护，</strong> 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。</p><h3 id="百万级别或以上的数据如何删除"><a href="#百万级别或以上的数据如何删除" class="headerlink" title="百万级别或以上的数据如何删除"></a>百万级别或以上的数据如何删除</h3><blockquote><p>索引需要额外的维护成本，因为索引文件是单独存在的文件，所以当我们对数据的增加，修改，删除，都会产生额外的对索引文件的操作，这些操作需要消耗额外的IO，会降低增/改/删的执行效率。</p></blockquote><ul><li>先删除索引（三分钟） </li><li>然后删除其中无用数据（两分钟）</li><li>删除完成后重新创建索引（约十分钟左右）</li></ul><h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>语法：<code>index(field(10))</code>，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。</p><p>前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。</p><h3 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h3><p>和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。</p><ul><li>InnoDB存储引擎的默认索引实现为B+树索引，适用于全键值、键值范围和键前缀查找。</li></ul><ul><li>哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。InnoDB 存储引擎的自适应哈希索引，当某个索引值被使用的非常频繁时，创建一个哈希索引，实现快速哈希查找。</li><li>全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。</li></ul><h3 id="B-树原理"><a href="#B-树原理" class="headerlink" title="B+树原理"></a>B+树原理</h3><h4 id="B树和B-树"><a href="#B树和B-树" class="headerlink" title="B树和B+树"></a>B树和B+树</h4><p><strong>区别</strong></p><p>B树中，键和值存放在内部节点和叶子节点；B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。</p><p>B+数的叶子节点是一个页。B+树的叶子节点有一条<strong>双向链表</strong>相连，而B树的叶子节点各自独立。</p><p><strong>B树优点</strong></p><p>B树内部节点同时存储键和值，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。</p><p><strong>B+树优点</strong></p><ul><li>B+树的内部节点只存放键，不存放值，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。</li><li>B+树的叶节点由一条双向链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用<code>O(logN)</code>时间找到最小的一个节点，然后通过链进行<code>O(N)</code>的顺序遍历即可。</li></ul><p><strong>使用B+树而不是B树</strong></p><ul><li><strong>B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。</strong>B+树的内部结点只存放索引，能容纳的数据更多，让索引树更加矮胖。</li><li><strong>B+树的查询效率更加稳定。</strong>B树搜索越靠近根节点的记录查找时间越短。B+树中，任何关键字的查找都必须走一条从根节点到叶节点的路，查找路径长度相同，查询效率相当。</li><li><strong>B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。</strong>B+树的叶子节点使用双向指针，只要遍历叶子节点就可以实现整棵树的遍历。</li></ul><h4 id="Hash索引和B-树优劣"><a href="#Hash索引和B-树优劣" class="headerlink" title="Hash索引和B+树优劣"></a>Hash索引和B+树优劣</h4><p>hash索引底层就是hash表，进行查找时，调用一次hash函数就可以获取到相应的键值</p><p>B+树底层实现是<strong>多路平衡查找树</strong>。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值</p><p>那么可以看出他们有以下的不同：</p><ul><li><p>hash索引进行等值查询更快，但是却无法进行范围查询。</p></li><li><p>hash索引不支持使用索引进行排序。</p></li><li><p>hash索引不支持模糊查询以及多列索引的最左前缀匹配。</p></li><li><p>hash索引不稳定发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定。</p></li></ul><h4 id="B-树与红黑树的比较"><a href="#B-树与红黑树的比较" class="headerlink" title="B+树与红黑树的比较"></a>B+树与红黑树的比较</h4><p>使用 B+ 树访问磁盘数据有更高的性能。B+树顺序访问性能更好。</p><p>B+ 树有更低的树高，寻道的时间与树高成正比，所以 B+ 树更适合磁盘数据的读取。</p><h4 id="B-树分裂与合并"><a href="#B-树分裂与合并" class="headerlink" title="B+树分裂与合并"></a>B+树分裂与合并</h4><p><strong>分裂</strong></p><p>只需要将这个节点分裂成两个节点。</p><p>节点分裂之后，其上层父节点的子节点个数就有可能超过 m 个。需将父节点也分裂成两个节点。</p><p><strong>合并</strong></p><p>如果某个节点的子节点个数小于 m/2，我们就将它跟相邻的兄弟节点合并。</p><p>合并之后结点的子节点个数有可能会超过 m。需要再分裂节点。</p><h3 id="索引是如何存储的"><a href="#索引是如何存储的" class="headerlink" title="索引是如何存储的"></a>索引是如何存储的</h3><p><strong>聚簇索引</strong>：将数据存储与索引放到了一块，找到索引也就找到了数据</p><p><strong>非聚簇索引</strong>：数据存储和索引分开，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要通过索引访问数据，在内存中直接搜索索引，然后通过索引找到磁盘相应数据。索引不在key buffer命中时，速度慢。</p><blockquote><p>在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。</p></blockquote><h3 id="为什么InnoDB表必须有主键"><a href="#为什么InnoDB表必须有主键" class="headerlink" title="为什么InnoDB表必须有主键"></a>为什么InnoDB表必须有主键</h3><p>InnoDB表必须有主键，并且推荐使用整型的自增主键。</p><p>1、如果没有显式定义主键，InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引；如果没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的主键索引。</p><p>2、如果使用非自增主键（如果身份证号或学号等）<br>由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页的中间某个位置，此时MySQL需要移动数据，频繁的移动、分页操作造成了大量的碎片。</p><h3 id="为什么非主键索引存储的是主键值"><a href="#为什么非主键索引存储的是主键值" class="headerlink" title="为什么非主键索引存储的是主键值"></a>为什么非主键索引存储的是主键值</h3><p>减少了出现数据页分裂时，二级索引的维护工作（当数据需要更新的时候，二级索引不需要修改，只需要修改聚簇索引）</p><p>聚簇索引其索引树的叶子节点中存的是整行数据。非聚簇索引的叶子节点内容是主键的值。</p><h3 id="非聚簇索引一定会回表查询吗？"><a href="#非聚簇索引一定会回表查询吗？" class="headerlink" title="非聚簇索引一定会回表查询吗？"></a>非聚簇索引一定会回表查询吗？</h3><p>不一定，查询语句所要求的字段全部命中了索引，就不必再进行回表查询。</p><h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>使用多个字段建立索引。</p><ul><li><p>一般情况下，将查询需求频繁或者字段选择性高的列放在前面。</p></li><li><p>组合索引的最左前缀匹配原则，mysql会一直向右匹配直到遇到范围查询。</p></li></ul><h3 id="唯一索引和非唯一索引的区别"><a href="#唯一索引和非唯一索引的区别" class="headerlink" title="唯一索引和非唯一索引的区别"></a>唯一索引和非唯一索引的区别</h3><p>1、普通索引的字段可以重复，唯一索引的字段重复。</p><p>2、数据修改操作，普通索引可以用 Change Buffer，而唯一索引不行。</p><blockquote><ul><li>在内存：普通索引找位置，插入值。唯一索引找位置，判断没有冲突，插入值。一个判断的差别，耗费微小CPU时间。</li><li>不在内存：唯一索引将数据页读入内存，判断到没有冲突，插入值。普通索引将更新记录在change buffer。</li></ul></blockquote><p>3、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。</p><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 </p><p>索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。</p><p><strong>过程</strong></p><p>读取索引树，在索引树上查找，把满足已经下推的条件的（经过查找，红色的满足）从表记录中读出</p><h3 id="COUNT-id-好还是COUNT-好"><a href="#COUNT-id-好还是COUNT-好" class="headerlink" title="COUNT(id)好还是COUNT(*)好"></a><code>COUNT(id)</code>好还是<code>COUNT(*)</code>好</h3><ul><li>当 count 统计某一列时，比如<code>count(a)</code>，是不统计 null 的。</li><li><code>count(*)</code>无论是否包含空值，都会统计。5.7.18 开始，通过遍历最小的可用二级索引来处理 <code>count(*)</code>语句。所以<code>count(id)</code> 没<code>count (*)</code>快。</li><li><code>COUNT(1)</code>与<code>count(*)</code>执行计划相同，速度没有明显差别。</li></ul><h3 id="几千万记录，数据库表结构如何平滑变更？"><a href="#几千万记录，数据库表结构如何平滑变更？" class="headerlink" title="几千万记录，数据库表结构如何平滑变更？"></a>几千万记录，数据库表结构如何平滑变更？</h3><p><strong>pt-online-schema-change</strong></p><p>假设：</p><p><code>user(uid, name, passwd)</code>要扩展到： <code>user(uid, name, passwd, age, sex)</code></p><ol><li>先创建一个扩充字段后的新表：<code>user_new(uid, name, passwd, age, sex)</code></li><li>在原表 user 上创建三个触发器，对原表 user 进行的所有 insert/delete/update 操作，都会对新表 user_new 进行相同的操作；</li><li>分批将原表 user 中的数据 insert 到新表 user_new，直至数据迁移完成；</li><li>删掉触发器，把原表移走（默认是 drop 掉）；</li><li>把新表 user_new 重命名（rename）成原表 user；扩充字段完成，整个过程不需要锁表，可以持续对外提供服务。</li></ol><blockquote><ul><li><p>变更过程中，写操作需要建立触发器，所以如果原表已经有很多触发器，方案就不行（互联网大数据高并发的在线业务，一般都禁止使用触发器）；</p></li><li><p>触发器的建立，会影响原表的性能，所以这个操作必须在流量低峰期进行；</p></li></ul></blockquote><h3 id="这个自增主键用完了该怎么办"><a href="#这个自增主键用完了该怎么办" class="headerlink" title="这个自增主键用完了该怎么办?"></a>这个自增主键用完了该怎么办?</h3><p><strong>把自增主键的类型改为BigInt类型就好了，int范围20亿，一般不会用完，用完前早就分库分表，采用分布式id了</strong></p><p>pt-online-schema-change/gh-ost</p><h2 id="数据库范式"><a href="#数据库范式" class="headerlink" title="数据库范式"></a>数据库范式</h2><p><strong>第一范式：</strong>表的每一列都是不可分割。</p><p><strong>第二范式</strong>：1NF基础上，确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关。</p><p><strong>第三范式</strong>：2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）。</p><p><strong>第四范式</strong>：消除多值依赖。例如，职工表（职工编号，职工孩子姓名，职工选修课程），在这个表中，同一个职工有多个职工孩子姓名，也会有多个职工选修课程，不符合第四范式</p><h2 id="mysql有关权限的表"><a href="#mysql有关权限的表" class="headerlink" title="mysql有关权限的表"></a>mysql有关权限的表</h2><p>MySQL服务器通过权限表来控制用户对数据库的访问，由mysql_install_db脚本初始化。</p><ol><li><p>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</p></li><li><p>db权限表：记录各个帐号在各个数据库上的操作权限。</p></li><li><p>table_priv权限表：记录数据表级的操作权限。</p></li><li><p>columns_priv权限表：记录数据列级的操作权限。</p></li><li><p>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。</p></li></ol><h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><p>虚拟的表，只包含动态检索数据的查询；不包含任何列或数据。</p><p>视图创建后，可以使用与表相同的方式利用它们。</p><blockquote><p>视图不能被索引，也不能有关联的触发器或默认值</p></blockquote><ul><li>视图是由实表产生虚表。</li><li>视图的建立和删除不影响实表。对视图内容的更新（添加，删除和修改）影响实表。</li><li>视图的列可以来自不同的表。当视图来自多个实表时，不允许添加和删除数据。</li></ul><h3 id="视图的使用场景有哪些？"><a href="#视图的使用场景有哪些？" class="headerlink" title="视图的使用场景有哪些？"></a>视图的使用场景有哪些？</h3><p><strong>常见使用场景</strong></p><ol><li><strong>简化复杂的SQL操作</strong>。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</li><li><strong>保护数据</strong>。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</li><li><strong>更改数据格式和表示</strong>。视图可返回与底层表的表示和格式不同的数据。</li></ol><h3 id="视图的优点"><a href="#视图的优点" class="headerlink" title="视图的优点"></a>视图的优点</h3><ul><li><p>简化sql查询，提高开发效率。</p></li><li><p>数据安全性。能够对机密数据提供安全保护</p></li></ul><h3 id="视图的缺点"><a href="#视图的缺点" class="headerlink" title="视图的缺点"></a>视图的缺点</h3><ul><li><strong>性能</strong>。数据库必须把视图的查询转化成对基本表的查询，如果视图是由复杂的多表查询，视图的查询需要花费一定的时间。</li><li><strong>修改限制</strong>。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。</li></ul><h3 id="游标"><a href="#游标" class="headerlink" title="游标"></a>游标</h3><ul><li>系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。</li><li>用户可以通过游标，逐一获取记录，进一步处理。</li></ul><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="what？"><a href="#what？" class="headerlink" title="what？"></a>what？</h3><p>一个不可分割的数据库操作序列，是数据库并发控制的基本单位。事务是逻辑上的一组操作，要么都执行，要么都不执行。</p><h3 id="事务的特性"><a href="#事务的特性" class="headerlink" title="事务的特性"></a>事务的特性</h3><ul><li>atomicity（原子性） ：要么全执行，要么全都不执行</li><li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态</li><li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的</li><li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的</li></ul><h3 id="怎么保证一致性的"><a href="#怎么保证一致性的" class="headerlink" title="怎么保证一致性的"></a>怎么保证一致性的</h3><ul><li><p>从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。</p></li><li><p>应用层，在事务里不能写违反约束的代码。</p></li></ul><h3 id="怎么保证原子性的？"><a href="#怎么保证原子性的？" class="headerlink" title="怎么保证原子性的？"></a>怎么保证原子性的？</h3><p>当事务回滚时，撤销所有已经成功执行的sql语句，需要记录你要回滚的相应日志信息。</p><p>例如</p><ul><li>当delete一条数据，回滚的时候，insert这条旧数据</li><li>当update一条数据，回滚的时候，根据旧值执行update操作</li><li>当insert一条数据，回滚的时候，根据主键执行delete操</li></ul><p>undo log记录了这些回滚需要的信息，当事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。</p><h3 id="怎么保证持久性的？"><a href="#怎么保证持久性的？" class="headerlink" title="怎么保证持久性的？"></a>怎么保证持久性的？</h3><ol><li>MySQL Server 层的执行器调用 InnoDB 存储引擎的数据更新接口；</li><li>存储引擎更新 Buffer Pool 中的缓存页</li><li>同时存储引擎记录一条 redo log 到 redo log buffer 中，并将该条 redo log 的状态标记为 prepare 状态；</li><li>接着存储引擎告诉执行器，可以提交事务了。执行器接到通知后，会写 binlog 日志，然后提交事务；</li><li>存储引擎接到提交事务的通知后，将 redo log 的日志状态标记为 commit 状态；</li><li>接着根据 innodb_flush_log_at_commit 参数的配置，决定是否将 redo log buffer 中的日志刷入到磁盘（真正的事务提交）。</li></ol><h3 id="什么是脏读？幻读？不可重复读？"><a href="#什么是脏读？幻读？不可重复读？" class="headerlink" title="什么是脏读？幻读？不可重复读？"></a>什么是脏读？幻读？不可重复读？</h3><p>脏读：读取未提交的事务。</p><p>不可重复读：多次读取同一数据，读取的数据不一致。</p><p>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><ul><li><strong>未提交读</strong>（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。</li><li><strong>提交读</strong>（Read Commited）：一个事务只能看见已经提交的事务所作的改变。</li><li><strong>可重复读</strong>（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。</li><li><strong>可串行化</strong>（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。</li></ul><table><thead><tr><th><strong>隔离级别</strong></th><th><strong>脏读</strong></th><th><strong>不可重复读</strong></th><th><strong>幻读</strong></th></tr></thead><tbody><tr><td>READ-UNCOMMITTED</td><td>√</td><td>√</td><td>√</td></tr><tr><td>READ-COMMITTED</td><td>×</td><td>√</td><td>√</td></tr><tr><td>REPEATABLE-READ</td><td>×</td><td>×</td><td>√</td></tr><tr><td>SERIALIZABLE</td><td>×</td><td>×</td><td>×</td></tr></tbody></table><p>事务隔离机制的实现基于锁机制和并发调度。并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p><h3 id="可重复读-MVCC如何实现？"><a href="#可重复读-MVCC如何实现？" class="headerlink" title="可重复读/MVCC如何实现？"></a>可重复读/MVCC如何实现？</h3><p>可重复读是指：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。</p><p>MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发<strong>一致性读和回滚</strong>等特性。</p><p>可重复读隔离级别下，事务在启动的时候就”拍了个快照“。</p><ul><li><p>InnoDB 里面每个事务都有一个唯一的事务 ID。它在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。</p></li><li><p>每条记录在更新的时候都会同时记录一条 undo log，这条 log 就会记录上当前事务的 transaction id，记为 row trx_id。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p></li><li><p>在可重复读隔离级别下，一个事务在启动时，InnoDB 会为事务构造一个数组，用来保存这个事务启动瞬间，当前正在”活跃“的所有事务ID。”活跃“指的是，启动了但还没提交。</p></li><li><p>视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p><ul><li><p>如果 trx_id 小于低水位，表示这个版本在事务启动前已经提交，可见；</p><p>如果 trx_id 大于高水位，表示这个版本在事务启动后生成，不可见；</p><p>如果 trx_id 大于低水位，小于高水位，分为两种情况：</p><ol><li>若 trx_id 在数组中，表示这个版本在事务启动时还未提交，不可见；</li><li>若 trx_id 不在数组中，表示这个版本在事务启动时已经提交，可见。</li></ol></li></ul></li></ul><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>并发事务可能会产生数据的不一致，需要锁机制来保证访问的次序。</p><h3 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a>锁分类</h3><p><strong>行级锁</strong> </p><p>分为共享锁和排他锁。</p><p>特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高</p><p><strong>表级锁</strong> </p><p>分为表共享锁与表排他锁。</p><p>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低</p><p><strong>页级锁（BDB引擎 ）</strong> </p><p>特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p><p><strong>锁类别，有共享锁和排他锁。</strong></p><p><strong>共享锁：</strong> 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p><p><strong>排他锁：</strong> 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。其他的排他锁，共享锁都相斥。</p><h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。</p><p>在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。</p><p>意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：</p><ul><li>一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；</li><li>一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。</li></ul><p>通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。</p><h3 id="什么时候加行锁？"><a href="#什么时候加行锁？" class="headerlink" title="什么时候加行锁？"></a>什么时候加行锁？</h3><ul><li>对于UPDATE、DELETE和INSERT语句，InnoDB会自动给相关数据集加排他锁；</li><li>对于普通SELECT语句，InnoDB不会加任何锁；</li><li>可以显示加锁：<br>共享锁：<code>select * from tableName where ...  lock in share more</code><br>排他锁：<code>select * from tableName where ...  for update</code></li></ul><h3 id="什么时候加表锁"><a href="#什么时候加表锁" class="headerlink" title="什么时候加表锁"></a>什么时候加表锁</h3><p>InnoDB默认采用行锁，没有使用索引字段查询时，会使用表锁。</p><p>第一种情况：<strong>全表更新</strong>。事务需要更新大部分或全部数据，且表又比较大。若使用行锁，会导致事务执行效率低，从而可能造成其他事务长时间锁等待和更多的锁冲突。</p><p>第二种情况：<strong>多表级联</strong>。事务涉及多个表，比较复杂的关联查询，很可能引起死锁，造成大量事务回滚。这种情况若能一次性锁定事务涉及的表，从而可以避免死锁、减少数据库因事务回滚带来的开销。</p><p>也可手动加锁：</p><pre class="line-numbers language-mysql"><code class="language-mysql">lock table xxx read/write;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="什么时候加间隙锁？"><a href="#什么时候加间隙锁？" class="headerlink" title="什么时候加间隙锁？"></a>什么时候加间隙锁？</h3><p>当我们用范围条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，加间隙锁</p><h3 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h3><p>行锁是在需要的时候才加上的，而是要等到事务结束时才释放。</p><p>启发：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p><h3 id="InnoDB存储引擎的锁的算法"><a href="#InnoDB存储引擎的锁的算法" class="headerlink" title="InnoDB存储引擎的锁的算法"></a>InnoDB存储引擎的锁的算法</h3><p>Record lock：单个行记录上的锁</p><p>Gap lock：间隙锁，锁定一个范围，不包括记录本身</p><p>Next-key lock：record+gap 锁定一个范围，包含记录本身</p><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p><p><strong>Mysql死锁策略</strong>  </p><ul><li>直接进入等待，直到超时，超时时间innodb_lock_wait_timeout   </li><li>发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑</li></ul><h4 id="常见的避免死锁的方法"><a href="#常见的避免死锁的方法" class="headerlink" title="常见的避免死锁的方法"></a><strong>常见的避免死锁的方法</strong></h4><ol><li><p>如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大减少死锁。</p></li><li><p>在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录</p></li><li><p>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p></li><li><p>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；</p></li><li><p>在RR隔离级别下，如果两个线程同时对相同条件记录用 <code>SELECT...FOR UPDATE</code> 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，<strong>将隔离级别改成RC不会产生间隙锁</strong>，就可避免问题  </p></li><li><p>可以用<strong>使用乐观锁</strong></p></li></ol><h4 id="死锁的必要条件"><a href="#死锁的必要条件" class="headerlink" title="死锁的必要条件"></a>死锁的必要条件</h4><ol><li>互斥条件：一个资源每次只能被一个进程使用。</li><li>请求与保持条件：进程因请求资源而阻塞时，保持已获得的资源的占用。</li><li>不剥夺条件：进程已占用的资源，在末使用完之前，不能强行剥夺。</li><li>循环等待条件：若干进程之间存在一种循环等待关系。</li></ol><h4 id="如何避免互相转账的死锁问题"><a href="#如何避免互相转账的死锁问题" class="headerlink" title="如何避免互相转账的死锁问题"></a>如何避免互相转账的死锁问题</h4><p><strong>1、破坏请求与保持</strong></p><p>单机下，可以使用同步方法，对两个账户同时加锁。处理请求前需要两个账户都没有锁的情况下才可以</p><p><strong>2、破坏不剥夺条件</strong></p><p>超时：在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。</p><p>非阻塞地获取锁：如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。</p><p><strong>3、破坏循环等待条件</strong></p><p>可以将需要获取的锁资源排序，按照顺序获取，这样就不会多个线程交叉获取相同的资源导致死锁，而是在获取相同的资源时就等待，直到它释放。</p><p>比如根据账号的主键 id 进行排序，从小到大的获取锁，这样就可以避免循环等待。</p><h3 id="乐观锁和悲观锁是什么？怎么实现的？"><a href="#乐观锁和悲观锁是什么？怎么实现的？" class="headerlink" title="乐观锁和悲观锁是什么？怎么实现的？"></a>乐观锁和悲观锁是什么？怎么实现的？</h3><p><strong>悲观锁：</strong>假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询数据的时候就把事务锁起来，直到提交事务。</p><p><strong>实现方式</strong></p><p>使用数据库中的锁机制</p><p> <strong>乐观锁：</strong>假设不会发生并发冲突，只在提交操作时检查是否有别的事务更新这个数据，如果被更新过，则失败重试。</p><p><strong>实现方式</strong></p><p>加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段，更新前比较是否一致</p><p> <strong>两种锁的使用场景</strong></p><p> 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p><p>一般多写的场景下用悲观锁就比较合适，乐观锁需要反复重试。</p><h3 id="数据库中加锁的具体实现？"><a href="#数据库中加锁的具体实现？" class="headerlink" title="数据库中加锁的具体实现？"></a>数据库中加锁的具体实现？</h3><p>InnoDB 行锁是通过给索引项加锁来实现的。</p><p>只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁。</p><h3 id="写锁一定阻塞读吗？"><a href="#写锁一定阻塞读吗？" class="headerlink" title="写锁一定阻塞读吗？"></a>写锁一定阻塞读吗？</h3><p>默认是 MVCC 机制，是不上锁的。</p><h3 id="mysql怎么实现分布式锁"><a href="#mysql怎么实现分布式锁" class="headerlink" title="mysql怎么实现分布式锁"></a>mysql怎么实现分布式锁</h3><h4 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h4><p><strong>实现</strong></p><ul><li>获取锁时在数据库中insert一条数据，包括id、方法名（唯一索引）、线程名（用于重入）、重入计数</li><li>获取锁如果成功则返回true</li><li>获取锁的动作放在while循环中，周期性尝试获取锁直到结束或者可以定义方法来限定时间内获取锁</li><li>释放锁的时候，delete对应的数据</li></ul><blockquote><p>做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。实现锁失效处理。</p></blockquote><p><strong>优点：</strong></p><ul><li>实现简单、易于理解</li></ul><p><strong>缺点</strong></p><ul><li>并发量大的时候请求量大，获取锁的间隔，如果较小会给系统和数据库造成压力；</li></ul><h4 id="排他锁"><a href="#排他锁" class="headerlink" title="排他锁"></a>排他锁</h4><p><strong>实现</strong></p><ul><li>获取锁可以通过，在select语句后增加<code>for update</code>，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁，我们可以认为获得排它锁的线程即可获得分布式锁；</li><li>其余实现与使用唯一索引相同；</li><li>释放锁通过<code>connection.commit()</code>操作，提交事务来实现。</li></ul><p><strong>优点</strong></p><ul><li>实现简单、易于理解</li></ul><p><strong>缺点</strong></p><ul><li>排他锁会占用连接，产生连接爆满的问题</li></ul><h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p><strong>实现</strong></p><p>一般是通过为数据库表添加一个 <code>version</code> 字段来实现读取出数据时，将此版本号一同读出.</p><p>之后更新时，对此版本号加1，在更新过程中，会对版本号进行比较，如果是一致的，没有发生改变，则会成功执行本次操作；如果版本号不一致，则会更新失败。</p><p><strong>缺点：</strong></p><ol><li>这种操作方式，使原本一次的update操作，必须变为2次操作</li><li>增加了数据库的冗余</li><li>不支持高并发，秒杀场景行锁压力大，CAS重试等等</li></ol><h2 id="存储过程"><a href="#存储过程" class="headerlink" title="存储过程"></a>存储过程</h2><p>存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。</p><p><strong>优点</strong></p><ol><li><p>存储过程是预编译过的，执行效率高。</p></li><li><p>存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。</p></li><li><p>安全性高，执行存储过程需要有一定权限的用户。</p></li><li><p>存储过程可以重复使用，减少数据库开发人员的工作量。</p></li></ol><p><strong>缺点</strong></p><ol><li><p>移植问题</p></li><li><p>重新编译问题</p></li><li><p>维护麻烦</p></li></ol><h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><h3 id="什么是触发器"><a href="#什么是触发器" class="headerlink" title="什么是触发器"></a>什么是触发器</h3><p>一类由事件驱动的特殊的存储过程。触发器是当触发某个事件时，自动执行某段代码。</p><p><strong>使用场景</strong></p><p>可以通过数据库中的相关表实现级联更改。</p><p><strong>六种触发器</strong></p><p>Before Insert、After Insert、Before Update、After Update、Before Delete、After Delete</p><h2 id="常用SQL语句"><a href="#常用SQL语句" class="headerlink" title="常用SQL语句"></a>常用SQL语句</h2><h3 id="SQL语句主要分为哪几类"><a href="#SQL语句主要分为哪几类" class="headerlink" title="SQL语句主要分为哪几类"></a>SQL语句主要分为哪几类</h3><p>数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER</p><p>数据查询语言DQL（Data Query Language）SELECT</p><p>数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE</p><p>数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK</p><h3 id="主键-超键-候选键-外键"><a href="#主键-超键-候选键-外键" class="headerlink" title="主键 超键 候选键 外键"></a>主键 超键 候选键 外键</h3><ul><li><p>主键：<strong>存储数据对象予以唯一和完整标识</strong>的数据列或属性的组合。只能有一个主键，且主键的取值不能缺失，不能为空值</p></li><li><p>外键：在一个表中存在<strong>的另一个表的主键称此表的外键</strong>。</p></li><li><p>超键：<strong>能唯一标识的属性集称为超键。</strong>候选键和主键一定是超键。</p></li><li><p>候选键：是最小超键，即没有冗余元素的超键。</p></li></ul><h3 id="SQL-约束"><a href="#SQL-约束" class="headerlink" title="SQL 约束"></a>SQL 约束</h3><p><strong>NOT NULL</strong>： 字段的内容一定不能为空。</p><p><strong>UNIQUE</strong>： 字段内容不能重复，一个表允许有多个 Unique 约束。</p><p><strong>PRIMARY KEY</strong>： 设置主键。主键的取值不能缺失，不能为空值</p><p><strong>FOREIGN KEY：</strong> 预防破坏表之间连接的动作，也能防止非法数据插入外键列。</p><p><strong>CHECK</strong>： 用于控制字段的值范围。</p><h3 id="关联查询"><a href="#关联查询" class="headerlink" title="关联查询"></a>关联查询</h3><p><strong>交叉连接</strong></p><p><strong>内连接</strong></p><ul><li><p>等值连接：ON A.id=B.id</p></li><li><p>不等值连接：ON A.id &gt; B.id</p></li><li><p>自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid</p></li></ul><p><strong>外连接</strong></p><ul><li><p>左外连接：以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN</p></li><li><p>右外连接： 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN</p></li></ul><p><strong>联合查询（UNION与UNION ALL</strong>）</p><p>把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并</p><p>如果使用UNION ALL，不会合并重复的记录行，效率 UNION ALL 高于 UNION</p><h3 id="什么是子查询"><a href="#什么是子查询" class="headerlink" title="什么是子查询"></a>什么是子查询</h3><p>一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。</p><h3 id="子查询的三种情况"><a href="#子查询的三种情况" class="headerlink" title="子查询的三种情况"></a>子查询的三种情况</h3><ul><li><p>子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、 &gt; 等运算符</p></li><li><p>子查询是多行单列的情况：结果集类似于一个数组，父查询使用in</p></li><li><p>子查询是多行多列的情况：结果集类似于一张虚拟表，select子句</p></li></ul><h3 id="in-和-exists-区别"><a href="#in-和-exists-区别" class="headerlink" title="in 和 exists 区别"></a>in 和 exists 区别</h3><p>mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。</p><ul><li><p>IN适合于外表大而子查询表小的情况。</p></li><li><p>EXISTS适合于外表小而子查询表大的情况，exists是对外表作loop循环，每次loop循环再对内表进行查询。</p></li></ul><h3 id="drop、delete、truncate"><a href="#drop、delete、truncate" class="headerlink" title="drop、delete、truncate"></a>drop、delete、truncate</h3><p>drop直接删掉表，truncate、delete删除表中数据。</p><ol><li><p>delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中。truncate table则一次性删除所有数据，不保存日志，删除行是不能恢复的。</p></li><li><p>表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。</p></li><li><p>应用范围。truncate只能对table，delete可以是table和view</p></li></ol><p><strong>使用场景：</strong> </p><p>不再需要一张表的时候，用drop </p><p>想删除部分数据行时候，用delete，并且带上where子句 </p><p>保留表而删除所有数据的时候用truncate </p><table><thead><tr><th></th><th><strong>Delete</strong></th><th><strong>Truncate</strong></th><th><strong>Drop</strong></th></tr></thead><tbody><tr><td>类型</td><td>属于DML</td><td>属于DDL</td><td>属于DDL</td></tr><tr><td>回滚</td><td>可回滚</td><td>不可回滚</td><td>不可回滚</td></tr><tr><td>删除内容</td><td>表结构还在，删除表的全部或者一部分数据行</td><td>表结构还在，删除表中的所有数据</td><td>从数据库中删除表，所有的数据行，索引和权限也会被删除</td></tr><tr><td>删除速度</td><td>删除速度慢，需要逐行删除</td><td>删除速度快</td><td>删除速度最快</td></tr></tbody></table><h2 id="SQL优化"><a href="#SQL优化" class="headerlink" title="SQL优化"></a>SQL优化</h2><h3 id="如何定位及优化SQL语句的性能问题？"><a href="#如何定位及优化SQL语句的性能问题？" class="headerlink" title="如何定位及优化SQL语句的性能问题？"></a>如何定位及优化SQL语句的性能问题？</h3><p><strong>explain命令来查看语句的执行计划</strong> 。type访问类型可以看到ALL 扫描全表数据、index 遍历索引、range 索引范围查找；key ，实际使用的索引；ref 表的连接匹配条件；rows ，估算的结果集数目；extra Using index 使用覆盖索引，Using where 使用了用where子句来过滤结果集。</p><p><strong>select_type查询类型。</strong></p><table><thead><tr><th><strong>select_type</strong></th><th><strong>description</strong></th></tr></thead><tbody><tr><td>SIMPLE</td><td>不包含任何子查询或union等查询</td></tr><tr><td>PRIMARY</td><td>包含子查询最外层查询就显示为 PRIMARY</td></tr><tr><td>SUBQUERY</td><td>在select或 where字句中包含的查询</td></tr><tr><td>DERIVED</td><td>from字句中包含的查询</td></tr><tr><td>UNION</td><td>出现在union后的查询语句中</td></tr><tr><td>UNION RESULT</td><td>从UNION中获取结果集，例如上文的第三个例子</td></tr></tbody></table><p><strong>type访问类型</strong></p><p>ALL 扫描全表数据</p><p>index 遍历索引</p><p>range 索引范围查找</p><p>index_subquery 在子查询中使用 ref</p><p>unique_subquery 在子查询中使用 eq_ref</p><p>ref_or_null 对Null进行索引的优化的 ref</p><p>fulltext 使用全文索引</p><p>ref 使用非唯一索引查找数据</p><p>eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。</p><p><strong>key ，实际使用的索引。</strong></p><p><strong>ref 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</strong></p><p><strong>rows ：估算的结果集数目，并不是一个准确的值。</strong></p><p><strong>extra 的信息非常丰富，常见的有：</strong></p><ul><li><p><strong>Using index 使用覆盖索引</strong></p></li><li><p><strong>Using where 使用了用where子句来过滤结果集</strong></p></li><li><p>Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。</p></li><li><p>Using temporary 使用了临时表</p></li></ul><h3 id="超大分页怎么处理？"><a href="#超大分页怎么处理？" class="headerlink" title="超大分页怎么处理？"></a>超大分页怎么处理？</h3><p>类似于<strong>select * from table where age &gt; 20 limit 1000000，10</strong></p><ul><li>修改为<code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</code>。这样虽然也load了一百万的数据，但是由于索引覆盖，要查询的所有字段都在索引中，所以速度会很快.</li><li>如果ID连续，我们还可以<code>select * from table where id &gt; 1000000 limit 10</code>效率也是不错的</li></ul><h3 id="mysql-分页"><a href="#mysql-分页" class="headerlink" title="mysql 分页"></a>mysql 分页</h3><p>LIMIT 接受一个或两个数字参数。返回记录行的偏移量+ 返回记录行的最大数目</p><blockquote><p> mysql&gt; SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15</p></blockquote><h3 id="慢查询日志"><a href="#慢查询日志" class="headerlink" title="慢查询日志"></a>慢查询日志</h3><p>用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。</p><h3 id="varchar怎么实现"><a href="#varchar怎么实现" class="headerlink" title="varchar怎么实现"></a>varchar怎么实现</h3><p>VARCHAR需要使用1或者2个额外字节记录字符串的长度：如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节。假设采用latin1字符集，一个<code>VARCHAR(10)</code>的列需要11个字节的存储空间。<code>VARCHAR(1000)</code>的列则需要1002个字节，因为需要2个字节存储长度信息。</p><h3 id="如果要存储用户的密码散列，应该使用什么字段进行存储？"><a href="#如果要存储用户的密码散列，应该使用什么字段进行存储？" class="headerlink" title="如果要存储用户的密码散列，应该使用什么字段进行存储？"></a>如果要存储用户的密码散列，应该使用什么字段进行存储？</h3><p>密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。</p><h3 id="SQL语句优化"><a href="#SQL语句优化" class="headerlink" title="SQL语句优化"></a>SQL语句优化</h3><ul><li>尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。</li><li>不使用SELECT *，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 </li><li>能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 </li></ul><p><strong>避免索引失效</strong></p><ul><li>使用!= 或者 &lt;&gt; 或者或者or 来连接条件导致索引失效：需要判断索引成本</li><li>筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效</li><li>模糊搜索的前缀模糊导致的索引失效</li><li>NOT IN、NOT EXISTS导致索引失效：需要判断回表成本</li><li>尽量避免在 where 子句中对字段进行 null 值判断</li></ul><h2 id="数据库优化"><a href="#数据库优化" class="headerlink" title="数据库优化"></a>数据库优化</h2><ul><li>使用索引、优化SQL 语句、分析慢查询</li><li>使用缓存，节约磁盘 IO</li><li>优化硬件，采用 SSD，使用磁盘队列技术（RAID0,RAID1,RDID5）等</li><li>采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率</li><li>主从读写分离</li><li>垂直分表，把一些不经常读的数据放在一张表里，节约磁盘 I/O</li><li>水平分表，数据路由</li></ul><h2 id="left-join-原理"><a href="#left-join-原理" class="headerlink" title="left join 原理"></a>left join 原理</h2><p><strong>Simple Nested-Loop Join</strong></p><p>双层for 循环 ，通过循环外层表的行数据，逐个与内层表的所有行数据进行比较来获取结果</p><p><strong>Index Nested-Loop Join</strong></p><p>通过外层表匹配条件，内层表索引匹配，避免和内层表的每条记录去进行比较，提升了 join的性能。</p><p><strong>Block Nested-Loop Join</strong></p><p>通过一次性缓存外层表的多条数据，以此来减少内层表的扫表次数，从而达到提升性能的目的。如果无法使用Index Nested-Loop Join的时候，默认使用的是Block Nested-Loop Join</p><blockquote><p>基于后两者的时间复杂度，考虑小表驱动大表。<strong>Simple Nested-Loop Join</strong>没有时间上的差异。</p></blockquote><p><strong>Batched Key Access</strong></p><blockquote><p><strong>MRR</strong></p><p>尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p><p>MRR能够提升性能的核心在于，查询语句在索引的是范围查询，可以得到足够多的主键id。排序后，再去主键索引查数据，才能体现出“顺序性”的优势。</p></blockquote><p>结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read（MRR） 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。</p><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><h4 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h4><ul><li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li><li>主库通过 IO 线程把 binlog 里面的内容传给从库，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）</li><li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li></ul><h4 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a>半同步复制</h4><ul><li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li><li>主库通过 IO 线程把 binlog 里面的内容传给从库，<strong>从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功</strong></li><li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li></ul><h3 id="galera复制原理"><a href="#galera复制原理" class="headerlink" title="galera复制原理"></a>galera复制原理</h3><p>Galera采用的是多主同步复制。</p><p>事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。</p><p>所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。</p><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><p>在本地针对表的分区进行操作，它可以将一张表的数据分别存储为多个文件。</p><p>分区对于应用是透明的，只是数据库对于数据的重新整理。</p><p><strong>优点</strong></p><ul><li>在执行查询的时候，优化器根据分区定义过滤部分数据分区，查询只需要查找包含需要数据的分区即可。</li><li>相关的数据存放在一起，想要一次批量删除整个分区的数据也会变得很方便。</li></ul><p><strong>缺点</strong></p><ul><li>分区字段的选择有限制。分区字段必须是整数类型或解析为整数的表达式</li><li>若查询不走分区键，则可能会扫描所有分区，效率不会提升。</li><li>若数据分布不均，分区大小差别较大，可能性能提升也有限。</li></ul><h3 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h3><p>一般情况下，应该先考虑垂直拆分，垂直可以理解为分出来的库表结构是互相独立各不相同的。</p><ul><li><p>如果有多个业务，每个业务直接关联性不大，那么久可以把每个业务拆分为单独的实例，库或表。</p></li><li><p>如果在一个实例上，有多个数据库，那么从分摊压力的角度考虑，可以把每个数据库才分到单独的实例上。</p></li><li><p>如果在一个库里面有多张表，那么可以把每张表拆分到不同的实例上。</p></li><li><p>如果你有一张表，但这个表里的字段很多，每个字段都有不同的含义，那么当该表太大的时候，就可以把每个字段独立拆分为一张新表。</p></li></ul><h3 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h3><p>水平拆分是针对一张表来说的。在经过垂直拆分之后，如果数据量仍然巨大，如注册用户已经超过10亿，那么治好通过某种算法进行水平拆分。拆分后的结果是多张具有相同表结构的表，每张表里面存储一部分数据</p><h4 id="Sharding策略"><a href="#Sharding策略" class="headerlink" title="Sharding策略"></a>Sharding策略</h4><ul><li>哈希取模：<code>hash(key)% N</code></li><li>范围： ID 范围or时间范围；</li><li>映射表：使用单独的一个数据库来存储映射关系。</li></ul><h4 id="Sharding-存在的问题"><a href="#Sharding-存在的问题" class="headerlink" title="Sharding 存在的问题"></a>Sharding 存在的问题</h4><ol><li>事务问题</li></ol><p>使用分布式事务来解决，比如 XA 接口。</p><ol start="2"><li>连接</li></ol><p>可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。</p><ol start="3"><li>ID 唯一性</li></ol><ul><li>使用全局唯一 ID（GUID）</li><li>为每个分片指定一个 ID 范围</li><li>分布式 ID 生成器（如 Twitter 的 Snowflake 算法）</li></ul><p><strong>Twitter的分布式自增ID算法Snowflake</strong> ，就是毫秒级时间戳41位、 机器ID 10位、同一毫秒内序列号12位。保证全局唯一，单机递增。</p><p><strong>时间问题回拨的解决方法：</strong></p><ol><li>当回拨时间小于15ms，就等时间追上来之后继续生成。</li><li>当时间大于15ms时间我们通过<strong>更换workid</strong>来产生之前都没有产生过的来解决回拨问题。</li></ol><p><strong>全局自增ID</strong></p><p>可以基于redis INCR实现。比较适合使用 Redis 来生成每天从0开始的流水号。比如订单号 = 日期 + 当日自增长号。可以每天在 Redis 中生成一个 Key ，使用 INCR 进行累加。</p><h3 id="mycat分库分表原理"><a href="#mycat分库分表原理" class="headerlink" title="mycat分库分表原理"></a>mycat分库分表原理</h3><p>拦截了用户发送过来的SQL语句，对SQL语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此SQL发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。</p><h3 id="分库分表的原则"><a href="#分库分表的原则" class="headerlink" title="分库分表的原则"></a>分库分表的原则</h3><p>1、能不分就不分：升级硬盘，升级内存，升级CPU，升级网络，升级数据库版本，读写分离及负载均衡等</p><p>2、数据量太大，正常的运维影响正常的业务访问：如果某张表过大，对此表做DDL的时候，mysql会锁住全表，时间会很长；整个表的热点数据，数据访问和更新频繁，经常有锁等待</p><p>3、某些数据表出现了无穷增长的情况</p><p>4、业务耦合性考虑</p><h3 id="平滑扩容"><a href="#平滑扩容" class="headerlink" title="平滑扩容"></a>平滑扩容</h3><h4 id="精确分片算法"><a href="#精确分片算法" class="headerlink" title="精确分片算法"></a>精确分片算法</h4><ul><li>业务前缀固定为4位，6-10位为分库位和分表位置，跟着是时间和自增（自增潜在一定的数据增量泄露风险，分库分表位以后保证不重复即可）</li><li>当我们需要扩容，增加数据库，增大生成范围就能满足。需要注意的问题是，新增的数据库，创建数据表数量需要保持一致（例如每个库的分片表统一都为4个表，增加表需要所有库都同步增加到相应的数量）</li><li>设置权重，可以控制各个库写入的数量</li></ul><h4 id="双倍扩容策略"><a href="#双倍扩容策略" class="headerlink" title="双倍扩容策略"></a>双倍扩容策略</h4><ul><li>扩容前每个节点的数据，有一半要迁移至一个新增节点中，对应关系比较简单。 </li><li>增两个数据库 A2/B2 作为从库，设置主从同步关系为：A=&gt;A2、B=&gt;B2，直至主从数据同步完毕（早期数据可手工同步）；</li><li>调整分片规则并使之生效</li><li>解除数据库实例的主从同步关系，并使之生效</li><li>四个节点的数据都已完整，只是有冗余（多存了和自己配对的节点的那部分数据），择机清除即可</li></ul><h4 id="range-hash"><a href="#range-hash" class="headerlink" title="range+hash"></a>range+hash</h4><p>hash是可以解决数据均匀的问题，range可以解决数据迁移问题</p><p>range划分不同的组，然后再做hash</p><p>扩容就是新增range就可以了</p><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><p><strong>mysqldump工具备份</strong></p><p>支持基于InnoDB的热备份，–single-transaction。但由于是逻辑备份，所以速度不是很快，适合备份数据量比较小的场景。</p><p><strong>使用percona提供的xtrabackup（推荐）</strong></p><p>支持InnoDB的物理热备份，支持完全备份，增量备份，而且速度非常快，而且支持InnoDB引擎的数据在不同数据库迁移</p><h2 id="sql语句中where与having的区别"><a href="#sql语句中where与having的区别" class="headerlink" title="sql语句中where与having的区别"></a>sql语句中where与having的区别</h2><ul><li><p>Where 约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。</p></li><li><p>Having返回结果集以后对结果过滤，在Having中可以使用聚合函数。</p></li></ul><p>在查询过程中聚合语句（sum,min,max,avg,count）要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。</p><pre class="line-numbers language-mysql"><code class="language-mysql">select 列 from表名join [表名]on [条件]where [查询条件]group by [分组表达式]having [分组过滤条件]order by [排序条件]limit [offset,] count;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行顺序</p><blockquote><p>   　　　　   　　　　1. FROM：对FROM子句中前两个表执行笛卡尔积生成虚拟表vt1<br>   　　　　   　　　　2. ON:对vt1表应用ON筛选器只有满足 join_condition 为真的行才被插入vt2</p><p>   　　　　   　　　　   　　　　   　　　　3. OUTER（join）：如果指定了 OUTER JOIN保留表中未找到的行将行作为外部行添加到vt2，生成t3，如果from包含两个以上表，则对上一个联结生成的结果表和下一个表重复执行步骤和步骤直接结束。<br>   　　　　   　　　　   　　　　   　　　　4. WHERE：对vt3应用 WHERE 筛选器只有使 where_condition 为true的行才被插入vt4<br>   　　　　   　　　　   　　　　   　　　　5. GROUP BY：按GROUP BY子句中的列列表对vt4中的行分组生成vt5<br>   　　　　   　　　　   　　　　   　　　　6. HAVING：对vt6应用HAVING筛选器只有使 having_condition 为true的组才插入vt7<br>   　　　　   　　　　   　　　　   　　　　7. SELECT：处理select列表产生vt8<br>   　　　　   　　　　   　　　　   　　　　8. DISINCT：将重复的行从vt8中去除产生vt9<br>   　　　　   　　　　   　　　　   　　　　9. ORDER BY：将vt9的行按order by子句中的列列表排序生成一个游标vc10</p></blockquote><h2 id="高并发时，如何避免重复插入-？"><a href="#高并发时，如何避免重复插入-？" class="headerlink" title="高并发时，如何避免重复插入 ？"></a>高并发时，如何避免重复插入 ？</h2><ul><li>幂等：保证多次同意请求后结果一致</li><li>并发控制：单表唯一索引、分布式多表分布式锁</li></ul>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka必知必会</title>
      <link href="/2021/04/08/interview-kafka/"/>
      <url>/2021/04/08/interview-kafka/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="Kafka-是什么？主要应用场景有哪些？"><a href="#Kafka-是什么？主要应用场景有哪些？" class="headerlink" title="Kafka 是什么？主要应用场景有哪些？"></a>Kafka 是什么？主要应用场景有哪些？</h3><p>Kafka 是一个分布式流式处理平台，可以作为企业级的消息引擎。</p><p>Kafka 主要有两大应用场景：</p><ol><li><strong>消息队列</strong> ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li><li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流。</li></ol><h3 id="Kafka的优势在哪里？"><a href="#Kafka的优势在哪里？" class="headerlink" title="Kafka的优势在哪里？"></a>Kafka的优势在哪里？</h3><ol><li><strong>极致的性能</strong> ：最高可以每秒处理千万级别的消息。</li><li><strong>生态系统兼容性无可匹敌</strong> ：尤其在大数据和流计算领域。</li></ol><h3 id="Kafka和rabbitmq比较"><a href="#Kafka和rabbitmq比较" class="headerlink" title="Kafka和rabbitmq比较"></a>Kafka和rabbitmq比较</h3><p><strong>rabbitmq</strong></p><ul><li>Erlang 语言编写的，轻量级、迅捷。</li><li>Exchange 模块支持非常灵活的路由配置。</li><li>队列模型：生产者将消息发送到交换器，通过匹配交换器类型、Binding Key、Routing Key后，路由到一个或者多个队列中。队列用于存储消息，消费者直接绑定队列以消费消息。</li></ul><p><strong>问题：</strong></p><ul><li>RabbitMQ 对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。</li><li>性能一般，大概每秒钟可以处理几万到十几万条消息</li></ul><p><strong>kafka</strong></p><ul><li>使用 Scala 和 Java 语言开发。</li><li>性能比较好，大约每秒钟可以处理几十万条消息，极限处理能力可以超过每秒 2000 万条消息。</li><li>发布订阅模型：生产者直接发消息到主题，每个主题可以包含多个分区。消息消费支持消费者组，多个分区会平均分配给同一个消费者组里的不同消费者。不在同一个消费者组的消费者能订阅消费同一条消息，相同消费者组的消费者存在消费竞争（负载均衡）</li><li>Kafka具有消息存储的功能，消息被消费后不会被立即删除，需要被不同的消费者组消费</li></ul><p><strong>问题：</strong></p><p>同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。</p><table><thead><tr><th><strong>对比项</strong></th><th align="center"><strong>RabbitMQ</strong></th><th align="center"><strong>Kafka</strong></th></tr></thead><tbody><tr><td><strong>吞吐量</strong></td><td align="center"><strong>低</strong></td><td align="center"><strong>高</strong></td></tr><tr><td><strong>有序性</strong></td><td align="center"><strong>全局有序性</strong></td><td align="center"><strong>分区有序性</strong></td></tr><tr><td>消息可靠性</td><td align="center">多策略组合</td><td align="center">消息持久化</td></tr><tr><td><strong>消费者模式</strong></td><td align="center">推拉</td><td align="center">拉</td></tr><tr><td><strong>消息堆积</strong></td><td align="center">无法支持较大的消息堆积</td><td align="center">支持消息堆积，并批量持久化到磁盘</td></tr><tr><td><strong>流处理</strong></td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td><strong>时效性</strong></td><td align="center"><strong>高</strong></td><td align="center"><strong>中</strong></td></tr><tr><td>运维便捷度</td><td align="center">高</td><td align="center">中</td></tr><tr><td><strong>系统依赖</strong></td><td align="center"><strong>无</strong></td><td align="center"><strong>zookeeper</strong></td></tr><tr><td>Web监控</td><td align="center">自带</td><td align="center">第三方</td></tr><tr><td><strong>优先级队列</strong></td><td align="center">支持</td><td align="center">不支持</td></tr><tr><td><strong>死信</strong></td><td align="center">支持</td><td align="center">不支持</td></tr><tr><td><strong>消息回溯</strong></td><td align="center"><strong>支持</strong></td><td align="center"><strong>不支持</strong></td></tr></tbody></table><h2 id="Producer、Consumer、Broker、Topic、Partition、Record？"><a href="#Producer、Consumer、Broker、Topic、Partition、Record？" class="headerlink" title="Producer、Consumer、Broker、Topic、Partition、Record？"></a>Producer、Consumer、Broker、Topic、Partition、Record？</h2><ol><li><strong>Producer（生产者）</strong> ： 产生消息的一方。</li><li><strong>Consumer（消费者）</strong>：消费消息的一方。</li><li><strong>Broker（代理）</strong> :  Kafka 实例。</li></ol><ul><li><strong>Topic（主题）</strong> : 通过不同的主题区分不同的业务类型的消息记录。生产者将消息发送到特定的主题，消费者通过订阅特定的主题来消费消息。</li><li><strong>Partition（分区）</strong>： 分区属于主题的一部分。一个主题可以有多个分区 ，同一主题下的分区可以分布在不同的Broker上。</li><li><strong>记录（Record）：</strong>写入到kafka并可以被消费者读取的数据。每条记录包含一个键、值和时间戳。</li></ul><h2 id="LEO、LSO、AR、ISR、HW？"><a href="#LEO、LSO、AR、ISR、HW？" class="headerlink" title="LEO、LSO、AR、ISR、HW？"></a>LEO、LSO、AR、ISR、HW？</h2><ul><li>LEO（Log End Offset）：日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。</li><li>LSO（Log Stable Offset）：该值控制了事务型消费者能够看到的消息范围。</li><li>AR（Assigned Replicas）：主题被创建后，创建的副本集合，副本个数由副本因子决定。</li><li>ISR（In-Sync Replicas）：AR中与领导者副本保持同步的副本集合。领导者副本天然在ISR中。</li><li>HW（High watermark）：高水位值，这是控制消费者可读取消息范围。一个普通消费者只能看到Leader上介于Log Start Offset和高水位（不含）之间的所有消息。</li></ul><h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><h3 id="ack-机制"><a href="#ack-机制" class="headerlink" title="ack 机制"></a>ack 机制</h3><ul><li>0：生产者不会等待 broker 的 ack，延迟最低，可能丢数据</li><li>1：服务端会等待领导者副本收到消息，成功写入PageCache后，会返回ack，此时领导者副本切换可能丢数据</li><li>-1：领导者副本所在broker收到消息后，等待所有ISR列表中的追随者副本返回结果后，再返回ack，数据不会丢失。</li></ul><p>数据从领导者副本同步到追随者副本，需要2步：</p><ul><li>数据从pageCache被刷盘到磁盘。因为只有磁盘中的数据才能被同步到副本。</li><li>数据同步到追随者副本中，并且replica成功将数据写入PageCache。在生产者得到ack后，哪怕是所有机器都停电，数据也至少会存在于领导者副本的磁盘内。</li></ul><h3 id="生产端怎么实现幂等的"><a href="#生产端怎么实现幂等的" class="headerlink" title="生产端怎么实现幂等的"></a>生产端怎么实现幂等的</h3><p><strong>幂等性生产者</strong></p><p>设置<code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code></p><p><strong>底层原理：</strong>空间去换时间，即在 Broker 端多保存一些字段。当生产者发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是把它们“丢弃”掉。</p><ul><li>ProducerID：生产者ID，在每个新的Producer初始化时，会被分配一个唯一的ProducerID，这个ProducerID对客户端使用者是不可见的。</li><li>SequenceNumber：消息序列号，对于每个ProducerID，生产者发送数据的每个主题和分区都对应一个从0开始单调递增的SequenceNumber值。</li></ul><p><strong>作用范围：</strong>它只能保证单分区上的幂等性，能够保证某个主题的一个分区上不出现重复消息。只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p><h3 id="怎么确定向哪一个分区写消息"><a href="#怎么确定向哪一个分区写消息" class="headerlink" title="怎么确定向哪一个分区写消息"></a>怎么确定向哪一个分区写消息</h3><p>获取集群的分区数据之后，根据生产者分区策略，只要如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。具体策略包括：</p><p><strong>轮询策略</strong></p><p><code>Round-robin</code> 策略，即顺序分配。</p><p>轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，最合理也最常用的分区策略。</p><p><strong>随机策略</strong></p><p><code>Randomness</code>策略。将消息放置到任意一个分区上。</p><p><strong>按消息键保序策略</strong></p><p>Kafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。</p><h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><h3 id="什么是消费者组？"><a href="#什么是消费者组？" class="headerlink" title="什么是消费者组？"></a>什么是消费者组？</h3><p>可扩展且具有容错性的消费者机制。</p><ul><li>Kafka允许你将同一份消息广播到多个消费者组里。</li><li>一个消费者组中可以包含多个消费者，他们共同消费该主题的数据。</li><li>同一个消费者组下的消费者有相同的组ID，他们被分配不同的订阅分区。</li><li>当某个消费者挂掉的时候，其他消费者会自动地承担起它负责消费的分区。 </li></ul><h3 id="如何保证消息的消费顺序？"><a href="#如何保证消息的消费顺序？" class="headerlink" title="如何保证消息的消费顺序？"></a>如何保证消息的消费顺序？</h3><p>Kafka 只能为我们保证分区中的消息有序，而不能保证主题中的消息有序。</p><ol><li>一个主题只对应一个 分区。</li><li>（推荐）发送消息的时候指定key/分区。</li></ol><h3 id="consumer-offsets-作用？"><a href="#consumer-offsets-作用？" class="headerlink" title="__consumer_offsets 作用？"></a>__consumer_offsets 作用？</h3><ul><li>位移主题，存储消费者的位移数据，位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等。</li><li>保存消费者组相关的消息</li><li>用于删除消费者组过期位移、删除消费者组的消息。tombstone 消息，即墓碑消息</li></ul><h3 id="消费者如何获取到offset"><a href="#消费者如何获取到offset" class="headerlink" title="消费者如何获取到offset"></a>消费者如何获取到offset</h3><ol><li><p>确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p></li><li><p>找出该分区 Leader 所在的 Broker，该 Broker 即为对应的 Coordinator。</p></li><li><p>重平衡后，协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。</p></li><li><p>位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等</p></li></ol><h3 id="Java-Consumer为什么采用单线程来获取消息？"><a href="#Java-Consumer为什么采用单线程来获取消息？" class="headerlink" title="Java Consumer为什么采用单线程来获取消息？"></a>Java Consumer为什么采用单线程来获取消息？</h3><p>Java Consumer是双线程的设计。用户主线程，负责获取消息；心跳线程，负责向Kafka汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的假死情况。</p><ul><li>单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现<strong>异步非阻塞式</strong>，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。</li><li>可以简化代码的开发。多线程交互的代码是非常容易出错的。</li></ul><h3 id="消息是采用-Pull-模式，还是-Push-模式？"><a href="#消息是采用-Pull-模式，还是-Push-模式？" class="headerlink" title="消息是采用 Pull 模式，还是 Push 模式？"></a>消息是采用 Pull 模式，还是 Push 模式？</h3><p>生产者将消息推送到 broker，消费者从 broker 拉取消息。</p><h3 id="消费者如何消费数据"><a href="#消费者如何消费数据" class="headerlink" title="消费者如何消费数据"></a>消费者如何消费数据</h3><blockquote><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p></blockquote><p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p><p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p><h2 id="broker"><a href="#broker" class="headerlink" title="broker"></a>broker</h2><h3 id="消息位移的作用"><a href="#消息位移的作用" class="headerlink" title="消息位移的作用"></a>消息位移的作用</h3><p>用于标识消息在分区中的位置。</p><p>一旦消息被写入到分区日志，它的位移值将不能被修改。</p><h3 id="怎么实现消息持久化"><a href="#怎么实现消息持久化" class="headerlink" title="怎么实现消息持久化"></a>怎么实现消息持久化</h3><p>Kakfa 依赖文件系统来存储和缓存消息。Kafka 直接将数据写到了文件系统的日志中。</p><p>物理上把主题分成一个或多个分区，每个分区在物理上对应一个文件夹，该文件夹下存储这个分区的所有<strong>消息和索引文件</strong>。</p><h3 id="数据索引如何实现"><a href="#数据索引如何实现" class="headerlink" title="数据索引如何实现"></a>数据索引如何实现</h3><ul><li>将数据文件分段存储。每一个段单独放在一个.log的文件中，数据文件命名是20个字符的长度，以每一个分段文件开始的最下offset来命名，其他位置用0填充。</li><li>每个log文件的大小默认是1GB，每个log文件就会对应一个同名的index文件。</li><li>index文件采用了稀疏存储的方式，每隔一定字节的数据建立一条索引，避免了索引文件占用过多的空间和资源，从而可以将索引文件保留到内存中。没有建立索引的数据在查询的过程中需要小范围内的顺序扫描。</li></ul><h3 id="磁盘容量规划考虑因素？"><a href="#磁盘容量规划考虑因素？" class="headerlink" title="磁盘容量规划考虑因素？"></a>磁盘容量规划考虑因素？</h3><ul><li>新增消息数</li><li>消息留存时间</li><li>平均消息大小</li><li>备份数</li><li>是否启用压缩</li></ul><h3 id="多副本机制？好处？"><a href="#多副本机制？好处？" class="headerlink" title="多副本机制？好处？"></a>多副本机制？好处？</h3><ul><li>Kafka副本当前分为领导者副本和追随者副本。每个分区在创建时都要选举一个副本，作为领导者副本，其余的副本自动为追随者副本。</li><li>只有领导者副本才能对外提供读写服务。追随者副本只是采用拉的方式，同步领导者副本中的数据</li><li>在领导者副本所在的Broker宕机后，Kafka 依托于 ZooKeeper ，实时感知到，并开启领导者选举，从追随者副本中选一个作为新的领导者。</li></ul><p><strong>多分区多副本好处？</strong></p><ol><li>指定多分区， 而各个分区可以分布在不同的 Broker 上， 这样便能提供比较好的并发能力（负载均衡）。</li><li>多副本提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。</li><li>读写走领导者副本：方便实现Read-your-writes</li><li>读写走领导者副本：方便实现单调读，在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在</li></ol><h3 id="Zookeeper的作用"><a href="#Zookeeper的作用" class="headerlink" title="Zookeeper的作用"></a>Zookeeper的作用</h3><ul><li>存放元数据：主题分区的相关数据都保存在 ZooKeeper 中。</li><li>成员管理：Broker节点的注册、注销以及属性变更。</li><li>Controller 选举：选举集群 Controller节点</li><li>其他管理类任务：包括但不限于主题删除、参数配置等。</li></ul><h3 id="为什么不支持读写分离"><a href="#为什么不支持读写分离" class="headerlink" title="为什么不支持读写分离"></a>为什么不支持读写分离</h3><p>CAP理论下，我们只能保证可用性和一致性取其一。</p><p>如果支持读写分离，一致性就会有一定折扣，意味着可能的数据不一致，或数据滞后。</p><h3 id="Controller发生网络分区时，Kafka会怎么样？"><a href="#Controller发生网络分区时，Kafka会怎么样？" class="headerlink" title="Controller发生网络分区时，Kafka会怎么样？"></a>Controller发生网络分区时，Kafka会怎么样？</h3><p>判断：Broker端的ActiveControllerCount。</p><p>由于Controller会给Broker发送3类请求，LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，因此，一旦出现网络分区，这些请求将不能顺利到达Broker端。</p><p>将影响主题的创建、修改、删除操作的信息同步。</p><h3 id="追随者副本消息同步的流程？"><a href="#追随者副本消息同步的流程？" class="headerlink" title="追随者副本消息同步的流程？"></a>追随者副本消息同步的流程？</h3><ul><li>追随者副本发送FETCH请求给领导者副本。</li><li>领导者副本会读取底层日志文件中的消息数据，使用FETCH请求中的fetchOffset，更新追随者副本远程副本的LEO值。领导者副本副本尝试更新分区高水位值。</li><li>追随者副本接收到FETCH响应之后，会把消息写入到底层日志，接着更新LEO和追随者副本高水位值。</li></ul><p>领导者副本和追随者副本的高水位值更新时机是不同的，追随者副本的高水位更新永远落后于领导者副本的高水位。这种时间上的错配是造成各种不一致的原因。</p><h3 id="怎么保证同步成功？"><a href="#怎么保证同步成功？" class="headerlink" title="怎么保证同步成功？"></a>怎么保证同步成功？</h3><p>leader Epoch 由两部分数据组成。</p><ul><li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li><li>起始位移（Start Offset）。领导者副本在该 Epoch 值上写入的首条消息的位移。</li></ul><p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。 领导者副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该领导者副本是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。</p><h3 id="Leader总是-1，怎么破？"><a href="#Leader总是-1，怎么破？" class="headerlink" title="Leader总是-1，怎么破？"></a>Leader总是-1，怎么破？</h3><p>表明Controller不工作了，导致无法分配leader。</p><p><strong>方法</strong></p><p>1、删除ZooKeeper中的/controller节点，触发Controller重选举。Controller重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的领导者副本不可用问题。</p><p>2、重启Controller节点上的Kafka进程，让其他节点重新注册Controller角色。</p><h3 id="如何设置Kafka能接收的最大消息的大小？"><a href="#如何设置Kafka能接收的最大消息的大小？" class="headerlink" title="如何设置Kafka能接收的最大消息的大小？"></a>如何设置Kafka能接收的最大消息的大小？</h3><ul><li>Broker端参数：<code>message.max.bytes</code>，<code>max.message.bytes</code>（主题级别），<code>replica.fetch.max.bytes</code></li><li>消费者端参数：<code>fetch.message.max.bytes</code></li></ul><h3 id="Kafka如何保证高可用"><a href="#Kafka如何保证高可用" class="headerlink" title="Kafka如何保证高可用"></a>Kafka如何保证高可用</h3><p>Kafka 的副本机制：</p><ul><li>Kafka 集群由多个 Broker组成。一个Broker可以容纳多个主题，也就是一台服务器可以传输多个 主题 数据。Kafka 为了实现可扩展性，将一个 主题 分散到多个 分区 中。</li><li>Kafka 中同一个分区下的不同副本，分为 领导者副本和 追随者副本。领导者副本 负责处理所有 读写的请求，追随者副本 作为数据备份，拉取 领导者副本的数据进行同步。</li><li>如果某个 Broker 挂掉，Kafka 会从 ISR 列表中选择一个分区作为新的 领导者副本。</li></ul><h3 id="Kafka能手动删除消息吗？"><a href="#Kafka能手动删除消息吗？" class="headerlink" title="Kafka能手动删除消息吗？"></a>Kafka能手动删除消息吗？</h3><p>一般不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。同时支持手动删除消息的。</p><ul><li>对于设置了Key且参数cleanup.policy=compact的主题而言，我们可以构造一条消息发送给Broker，依靠日志清理组件提供的功能删除掉该 Key 的消息。</li><li>对于普通主题，可以使用<code>kafka-delete-records</code>，或编写程序调用<code>Admin.deleteRecords</code>方法来删除消息。</li></ul><h3 id="如何确定合适的Kafka主题的分区数量？"><a href="#如何确定合适的Kafka主题的分区数量？" class="headerlink" title="如何确定合适的Kafka主题的分区数量？"></a>如何确定合适的Kafka主题的分区数量？</h3><p>需要根据每个分区的生产者和消费者的期望吞吐量进行估计，以便达到并行读写、负载均衡和高吞吐。</p><p>假设对于单个分区，生产者端的可达吞吐量为p，消费者端的可达吞吐量为c，期望的目标吞吐量为t，那么集群所需要的分区数量至少为<code>max(t/p,t/c)</code>。</p><p>在生产者端，单个分区的吞吐量大小会受到批量大小、数据压缩方法、 确认类型（同步/异步）、复制因子等配置参数的影响。</p><blockquote><p>假设期望读取数据的速率1GB/Sec，而一个消费者的读取速率为50MB/Sec，此时至少需要20个分区以及20个消费者。</p><p>如果期望生产数据的速率为<strong>1GB/Sec</strong>，而每个生产者的生产速率为<strong>100MB/Sec</strong>，此时就需要有10个分区。</p><p>设置20个分区，既可以保障生产速率，也可以保障的吞吐量</p></blockquote><h3 id="判断一个节点还活着的两个条件？"><a href="#判断一个节点还活着的两个条件？" class="headerlink" title="判断一个节点还活着的两个条件？"></a>判断一个节点还活着的两个条件？</h3><p>（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接</p><p>（2）如果节点是追随者副本，他必须能及时的同步 leader 的写操作，延时不能太久</p><h3 id="存储在硬盘上的消息格式是什么？"><a href="#存储在硬盘上的消息格式是什么？" class="headerlink" title="存储在硬盘上的消息格式是什么？"></a>存储在硬盘上的消息格式是什么？</h3><p>消息由一个固定长度的头部和可变长度的字节数组组成。</p><ul><li>消息长度: 4 bytes</li><li>版本号: 1 byte</li><li>CRC 校验码: 4 bytes</li><li>具体的消息: n bytes</li></ul><h2 id="实际问题"><a href="#实际问题" class="headerlink" title="实际问题"></a>实际问题</h2><h3 id="如何保证消息不丢失"><a href="#如何保证消息不丢失" class="headerlink" title="如何保证消息不丢失"></a>如何保证消息不丢失</h3><h4 id="生产者丢失消息"><a href="#生产者丢失消息" class="headerlink" title="生产者丢失消息"></a>生产者丢失消息</h4><ul><li><p>生产者调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。 为了确定消息是发送成功，我们要判断消息发送的结果。可以采用回调函数的形式，如果消息发送失败的话，我们检查失败的原因之后重新发送即可。</p></li><li><p>为 生产者的<code>retries</code>（重试次数）设置一个比较合理的值，一般是3。</p></li><li><p><strong>设置 acks = all</strong>，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交</p></li></ul><h4 id="消费者丢失消息"><a href="#消费者丢失消息" class="headerlink" title="消费者丢失消息"></a>消费者丢失消息</h4><ul><li>关闭自动提交位移，每次在真正消费完消息之后之后，手动提交 。</li></ul><h4 id="Kafka-弄丢消息"><a href="#Kafka-弄丢消息" class="headerlink" title="Kafka 弄丢消息"></a>Kafka 弄丢消息</h4><ul><li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余。</li><li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</li><li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原领导者副本太多，那么它一旦成为新的领导者副本，必然会造成消息的丢失。</li></ul><h3 id="如何保证消息不重复消费"><a href="#如何保证消息不重复消费" class="headerlink" title="如何保证消息不重复消费"></a>如何保证消息不重复消费</h3><p>去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过。</p><ol><li>利用数据库的唯一约束实现幂等</li><li>为更新的数据设置前置条件，比如版本号</li><li>GUID：在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。</li></ol><h3 id="怎么增加消费的能力？"><a href="#怎么增加消费的能力？" class="headerlink" title="怎么增加消费的能力？"></a>怎么增加消费的能力？</h3><p>1、broker 端参数 <code>num.replica.fetchers</code>表示的是 追随者副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，适当调大该参数值，加快追随者副本的同步速度。</p><p>2、在 生产者端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 <code>batch.size</code> 和 <code>linger.ms</code>。</p><p>3、压缩算法可减少网络 I/O 传输量，从而间接提升吞吐量。适配最好的两个压缩算法是 LZ4 和 zstd</p><p>4、消费者端使用多线程方案</p><h3 id="为什么性能好"><a href="#为什么性能好" class="headerlink" title="为什么性能好"></a>为什么性能好</h3><h4 id="顺序写"><a href="#顺序写" class="headerlink" title="顺序写"></a>顺序写</h4><blockquote><p>操作系统读写磁盘时，需要先寻址，再进行数据读写。如果是机械硬盘，寻址就需要较长的时间。</p></blockquote><p> Kafka 用的是顺序写，追加数据是追加到末尾，磁盘顺序写（pagecache）的性能极高。</p><h4 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h4><p>Kafka使用了零拷贝技术，使用<code>mmap+write</code>持久化数据，发送数据使用系统调用<code>sendfile</code>。</p><blockquote><p>传统的IO<code>read+write</code>方式会产生2次DMA拷贝+2次CPU拷贝，同时有4次上下文切换。</p><p>而通过<code>mmap+write</code>方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件的传输。</p><p><code>sendfile</code>方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。因为只有一次调用，减少了上下文的切换，但是用户空间对IO数据不可见，适用于静态文件服务器。</p></blockquote><h4 id="网络线程模型"><a href="#网络线程模型" class="headerlink" title="网络线程模型"></a>网络线程模型</h4><p>加强版的 Reactor 网络线程模型</p><h4 id="消息批量量处理"><a href="#消息批量量处理" class="headerlink" title="消息批量量处理"></a>消息批量量处理</h4><p>合并小的请求，然后以流的方式进行交互，直顶网络上限。</p><h3 id="kafka如何实现延迟队列？"><a href="#kafka如何实现延迟队列？" class="headerlink" title="kafka如何实现延迟队列？"></a>kafka如何实现延迟队列？</h3><p><strong>基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）</strong>。基于时间轮可以将插入和删除操作的时间复杂度都降为<code>O（1）</code>。</p><p><strong>底层使用数组实现，</strong>数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask。</p><p><strong>推进时间？</strong>Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的<code>TimingWheel</code>专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O（1）的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，<strong>这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”</strong>。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。</p><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p><strong>基于消息队列的事务实现。</strong></p><ul><li>订单系统在消息队列上开启一个事务。</li><li>然后订单系统给消息服务器<strong>发送一个“半消息”</strong>，这个半消息不是说消息内容不完整，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，<strong>对于消费者来说，这个消息是不可见的</strong></li><li>半消息发送成功后，<strong>订单系统就可以执行本地事务</strong>了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果决定提交或者回滚事务消息。</li><li>如果订单创建成功，那就<strong>提交事务消息</strong>，购物车系统就可以消费到这条消息继续后续的流程。如果订单创建失败，那就<strong>回滚事务消息</strong>，购物车系统就不会收到这条消息。这样就基本实现了“要么都成功，要么都失败”的一致性要求。</li></ul>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq必知必会</title>
      <link href="/2021/04/05/interview-rabbitmq/"/>
      <url>/2021/04/05/interview-rabbitmq/</url>
      
        <content type="html"><![CDATA[<h2 id="MQ的优缺点"><a href="#MQ的优缺点" class="headerlink" title="MQ的优缺点"></a>MQ的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>异步 - 不需要立即处理的消息可以之后慢慢处理。异步处理可以提高系统吞吐量。</li><li>解耦 - 各个系统间通过消息通信，不用关心其他系统的处理。</li><li>削锋 - 可以通过消息队列支撑突发访问压力；可以缓解短时间内的高并发请求，不会因为突发超负荷请求而完全崩溃。</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p><strong>系统复杂度提高</strong>：需要考虑很多问题，如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。</p><h2 id="RabbitMQ选型"><a href="#RabbitMQ选型" class="headerlink" title="RabbitMQ选型"></a>RabbitMQ选型</h2><p>可以支撑高并发、高吞吐、性能比较高，有非常完善便捷的后台管理界面。</p><p>支持集群化、高可用部署、消息高可靠支持，功能较为完善。</p><p>缺点：基于erlang语言开发的，分析里面的源码有一定门槛，较难进行深层次的源码定制和改造。</p><p>Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。</p><h2 id="什么是RabbitMQ"><a href="#什么是RabbitMQ" class="headerlink" title="什么是RabbitMQ"></a>什么是RabbitMQ</h2><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件，主要负责接收、存储、转发消息。</p><h2 id="消息队列中推和拉模式"><a href="#消息队列中推和拉模式" class="headerlink" title="消息队列中推和拉模式"></a>消息队列中推和拉模式</h2><h3 id="push模式"><a href="#push模式" class="headerlink" title="push模式"></a>push模式</h3><p>服务器主动发送到用户的客户端，服务端保存状态。适用于消息量不大、消费能力强要求实时性高的情况下。</p><p><strong>优点</strong></p><ul><li>及时性好，服务器端及时向客户端推送更新的动态信息</li><li>consumer离线时，面临数据堆积或者数据丢失，折中方案是设定一个超时时间，当 Consumer 宕机时间超过这个阈值时，则清理数据；但这个时间阈值也并不太容易确定。</li></ul><p><strong>缺点</strong></p><ul><li><strong>推送速率难以适应消费速率</strong>，当生产者往 Broker 发送消息的速率大于消费者消费消息的速率时，随着时间的增长消费者那边可能就“爆仓”了</li></ul><h3 id="pull模式"><a href="#pull模式" class="headerlink" title="pull模式"></a>pull模式</h3><p>客户端主动从服务端拉取数据，客户端保存拉取信息状态</p><p><strong>优点</strong></p><ul><li><strong>消费者可以根据自身的情况来发起拉取消息的请求</strong>。</li></ul><p><strong>缺点</strong></p><ul><li>消息延迟，消费者去拉取消息，只能不断地拉取，但是又不能很频繁地请求，太频繁了就变成消费者在攻击 Broker 了。</li><li><strong>消息忙请求</strong>，消息隔了几个小时才有，那么在几个小时之内消费者的请求都是无效的，在做无用功。优化方式：消费者如果尝试拉取失败，不是直接 return，而是把连接挂在那里 wait，服务端如果有新的消息到来，把连接拉起，返回最新消息。</li></ul><h2 id="RabbitMQ基本概念"><a href="#RabbitMQ基本概念" class="headerlink" title="RabbitMQ基本概念"></a>RabbitMQ基本概念</h2><p><strong>Producer：生产者</strong>，投递消息的程序</p><p><strong>Consumer：消费者</strong>，接受消息的程序</p><p><strong>Broker：服务节点</strong>，消息队列服务器实体</p><p><strong>Virtual host：</strong>虚拟broker，用于逻辑隔离，最上层消息的路由。可以理解为虚拟 broker 。其内部均含有独立的 queue、exchange 和 binding 等，拥有独立的权限系统。</p><p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p><p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p><p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p><p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p><p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p><p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成交换器类型</p><p><strong>channel、exchange 和 queue 这些是逻辑概念，还是对应着进程实体？</strong></p><ul><li>queue有自己的erlang进程;</li><li>exchange保存binding关系的查找表;</li><li>channel是实际进行路由工作的实体，根据routing_key将消息投递给queue。channel是在tcp连接上的虚拟链接，amqp命令通过channel发送，<br>一个线程允许使用多个channel，多线程共享同一个socket。</li></ul><h2 id="消息在什么时候会变成死信"><a href="#消息在什么时候会变成死信" class="headerlink" title="消息在什么时候会变成死信?"></a>消息在什么时候会变成死信?</h2><ul><li>消息拒绝并且没有设置重新入队</li><li>消息过期</li><li>消息堆积，并且队列达到最大长度，先入队的消息会变成DL</li></ul><h2 id="如何保证RabbitMQ消息的顺序性？"><a href="#如何保证RabbitMQ消息的顺序性？" class="headerlink" title="如何保证RabbitMQ消息的顺序性？"></a>如何保证RabbitMQ消息的顺序性？</h2><p>1、需要保证顺序性的消息使用一个queue对应一个 consumer。</p><p>2、消息在被创建时，都将被赋予一个全局唯一的、单调递增的、连续的序列号，可以通过一个全局计数器来实现这一点。可以在消费端实现前一条消息未消费，不处理下一条消息；也可以在生产端实现前一条消息未处理完毕，不发布下一条消息。</p><h2 id="如何保证消息不被重复消费？"><a href="#如何保证消息不被重复消费？" class="headerlink" title="如何保证消息不被重复消费？"></a>如何保证消息不被重复消费？</h2><p>1、设置操作的幂等性。</p><p>2、生产者发送每条数据的时候，里面加一个全局唯一的 id，消费者通过全局唯一ID检查是否消费过。</p><p>3、基于数据库的唯一键来保证重复数据不会重复插入多条。</p><h2 id="消息如何分发？"><a href="#消息如何分发？" class="headerlink" title="消息如何分发？"></a><strong>消息如何分发？</strong></h2><p>若该队列至少有一个消费者订阅，消息将以循环的方式发送给消费者。每条消息只会分发给一个订阅的消费者。通过路由可实现多消费的功能</p><h2 id="消息怎么路由？"><a href="#消息怎么路由？" class="headerlink" title="消息怎么路由？"></a>消息怎么路由？</h2><p>消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。</p><p>消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；</p><p>常用的交换器主要分为一下三种：</p><p>fanout：如果交换器收到消息，将会广播到所有绑定的队列上</p><p>direct：如果路由键完全匹配，消息就被投递到相应的队列</p><p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p><h2 id="消息基于什么传输？"><a href="#消息基于什么传输？" class="headerlink" title="消息基于什么传输？"></a>消息基于什么传输？</h2><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。</p><p>RabbitMQ 使用信道的方式来传输数据。信道是建立在<strong>真实的 TCP 连接内的虚拟连接</strong>，且每条 TCP 连接上的信道数量没有限制。</p><h2 id="什么情况下会出现blackholed问题？"><a href="#什么情况下会出现blackholed问题？" class="headerlink" title="什么情况下会出现blackholed问题？"></a>什么情况下会出现blackholed问题？</h2><p>blackholed问题是指，向exchange投递了 message，而由于各种原因导 致该message丢失，但发送者却不知道。可导致blackholed的情况：</p><ul><li>向未绑定 queue 的 exchange 发送 message；</li><li>exchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key却是 key_B。</li></ul><h2 id="如何防止出现blackholed问题？"><a href="#如何防止出现blackholed问题？" class="headerlink" title="如何防止出现blackholed问题？"></a>如何防止出现blackholed问题？</h2><p>如果在执行Basic.Publish时设置<code>mandatory=true</code>，则在遇到可能出现blackholed情况时，服务器会通过返回Basic.Return告之当前 message无法被正确投递。</p><h2 id="Basic-Reject的用法是什么？"><a href="#Basic-Reject的用法是什么？" class="headerlink" title="Basic.Reject的用法是什么？"></a>Basic.Reject的用法是什么？</h2><p>该信令可用于consumer对收到的message进行reject。</p><p>若在该信令中设 置<code>requeue=true</code>，则当RabbitMQ server收到该拒绝信令后，会将该 message重新发送到下一个consumer处（理论上仍 可能将该消息发送给当前consumer）。</p><p>若设置<code>requeue=false</code>，则 RabbitMQ server在收到拒绝信令后，将直接将该message从queue中移除。</p><h2 id="如何保证消息不被重复消费？-1"><a href="#如何保证消息不被重复消费？-1" class="headerlink" title="如何保证消息不被重复消费？"></a>如何保证消息不被重复消费？</h2><p><strong>重复消费场景：</strong>因为网络传输等故障，消费确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将消息分发给其他的消费者。</p><p><strong>解决思路</strong>：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；</p><p>比如：在写入消息队列的数据做唯一标识，消费消息时，根据唯一标识判断是否消费过；</p><h2 id="如何保证RabbitMQ消息的可靠传输？"><a href="#如何保证RabbitMQ消息的可靠传输？" class="headerlink" title="如何保证RabbitMQ消息的可靠传输？"></a>如何保证RabbitMQ消息的可靠传输？</h2><p>丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；</p><p><strong>生产者丢失消息：</strong>RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；</p><p>transaction机制：发送消息前，开启事务,然后发送消息，如果发送过程中出现什么异常，事务就会回滚,如果发送成功则提交事务。然而，这种方式有个缺点：吞吐量下降；</p><p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p><p><strong>消息队列丢数据：消息持久化。</strong>开启持久化磁盘的配置。</p><p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p><p>队列持久化+消息持久化。</p><p><strong>消费者丢失消息</strong></p><p>消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；</p><p>如果这时处理消息失败，就会丢失该消息；</p><p>解决方案：处理消息成功后，<strong>手动回复确认消息</strong>。</p><h2 id="为什么不应该对所有的-message-都使用持久化机制？"><a href="#为什么不应该对所有的-message-都使用持久化机制？" class="headerlink" title="为什么不应该对所有的 message 都使用持久化机制？"></a>为什么不应该对所有的 message 都使用持久化机制？</h2><p>一般仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。否则会导致性能的下降，因为写磁盘比写 RAM 慢的多。</p><p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。</p><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="如何保证高可用的？RabbitMQ-的集群"><a href="#如何保证高可用的？RabbitMQ-的集群" class="headerlink" title="如何保证高可用的？RabbitMQ 的集群"></a>如何保证高可用的？RabbitMQ 的集群</h3><p>普通集群模式： <strong>queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。</strong>消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。提高吞吐量，集群中多个节点来服务某个 queue 的读写操作。</p><p><strong>镜像集群模式</strong>：高可用模式。在镜像集群模式下，你创建的 queue，<strong>无论元数据还是 queue 里的消息都会存在于多个实例上</strong></p><p><strong>好处</strong></p><p>任何一个机器宕机了，其它机器还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。</p><p><strong>坏处</strong></p><p>这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。</p><h3 id="rabbitmq-对集群节点停止顺序有要求吗"><a href="#rabbitmq-对集群节点停止顺序有要求吗" class="headerlink" title="rabbitmq 对集群节点停止顺序有要求吗?"></a>rabbitmq 对集群节点停止顺序有要求吗?</h3><p>RabbitMQ 对集群的停止的顺序是有要求的，应该先关闭内存节点，最后再关闭磁盘节点.如果顺序恰好相反的话，可能会造成消息的丢失</p><h3 id="rabbitmq-集群有什么用"><a href="#rabbitmq-集群有什么用" class="headerlink" title="rabbitmq 集群有什么用?"></a>rabbitmq 集群有什么用?</h3><ul><li>高可用：某个服务器出现问题，整个 RabbitMQ 还可以继续使用</li><li>高容量： 集群可以承载更多的消息量</li></ul><h3 id="RAM-node-和-disk-node-的区别？"><a href="#RAM-node-和-disk-node-的区别？" class="headerlink" title="RAM node 和 disk node 的区别？"></a>RAM node 和 disk node 的区别？</h3><p>RAM node 仅将相关元数据保存到内存中，</p><p>disk node会在内存和磁盘中均进行存储。</p><p>要求在RabbitMQ cluster中至少存在一个disk node。</p><h3 id="rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？"><a href="#rabbitmq-每个节点是其他节点的完整拷贝吗？为什么？" class="headerlink" title="rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？"></a><strong>rabbitmq 每个节点是其他节点的完整拷贝吗？为什么？</strong></h3><p>不是，原因有以下两个：</p><ol><li>存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；</li><li>性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，反而可能更糟。</li></ol><h3 id="rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？"><a href="#rabbitmq-集群中唯一一个磁盘节点崩溃了会发生什么情况？" class="headerlink" title="rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？"></a><strong>rabbitmq 集群中唯一一个磁盘节点崩溃了会发生什么情况？</strong></h3><p>如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：</p><p>不能创建队列</p><p>不能创建交换器</p><p>不能创建绑定</p><p>不能添加用户</p><p>不能更改权限</p><p>不能添加和删除集群节点</p><p>唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。</p><h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h3><ul><li>非 cluster 模式下，元数据主要分为 Queue 元数据（queue 名字和属性等）、Exchange 元数据（exchange 名字、类型和属性等）、Binding 元数据（存放路由关系的查找表）、Vhost 元数据（vhost 范围内针对前三者的名字空间约束和安全属性设置）。</li><li>cluster 模式下，还包括 cluster 中 node 位置信息和 node 关系信息。元数据按照 erlang node 的类型确定是仅保存于 RAM 中，还是同时保存在 RAM 和 disk 上。元数据在cluster 中是全 node 分布的。</li></ul>]]></content>
      
      
      <categories>
          
          <category> interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq思维导图</title>
      <link href="/2021/04/04/rabbitmq-si-wei-dao-tu/"/>
      <url>/2021/04/04/rabbitmq-si-wei-dao-tu/</url>
      
        <content type="html"><![CDATA[<p><img src="rabbitmq.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq进阶</title>
      <link href="/2021/04/03/rabbitmq-jin-jie/"/>
      <url>/2021/04/03/rabbitmq-jin-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="消息传递"><a href="#消息传递" class="headerlink" title="消息传递"></a>消息传递</h2><p><strong>mandatory</strong></p><p><code>mandatory=true</code>，如果交换器无法根据自身的类型和路由键找到一个符合条件的队列，RabbitMQ会调用 <code>Basic.Return</code>命令将消息返回给生产者，生产者通过调用 <code>channel.addReturnListener</code>添加监听器接收返回结果<br><code>mandatory=false</code>，上述情形下，RabbitMQ 将消息直接丢弃</p><p><strong>immediate</strong></p><p><code>immediate=true</code>，如果交换器在消息路由到队列时发现队列上并不存在任何消费者，该消息将不会存入队列中。当与路由键匹配的所有队列都没有消费者时，该消息会通过 <code>Basic.Return</code> 返回生产者<br><strong>和mandatory相比，mandatory如果路由不到队列则返回消息，immediate如果队列中没有消费者则返回消息</strong></p><p><strong>备份交换器（Alternate Exchange）</strong></p><p>AE可以将未被路由的消息存储到 RabbitMQ 中。简化了<code>mandatory</code>+<code>addReturnListener</code>的编程逻辑。</p><pre class="line-numbers language-java"><code class="language-java">Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Object<span class="token operator">></span> args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Object<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>args<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"alternate-exchange"</span><span class="token punctuation">,</span><span class="token string">"myAe"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 声明普通交换器（AE交换器作为备份交换器）</span>channel<span class="token punctuation">.</span><span class="token function">exchangeDeclare</span><span class="token punctuation">(</span><span class="token string">"normalExchange"</span><span class="token punctuation">,</span><span class="token string">"direct"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">,</span>args<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 声明AE交换器</span>channel<span class="token punctuation">.</span><span class="token function">exchangeDeclare</span><span class="token punctuation">(</span><span class="token string">"myAe"</span><span class="token punctuation">,</span><span class="token string">"fanout"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">,</span>null<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 普通队列 绑定 普通交换器</span>channel<span class="token punctuation">.</span><span class="token function">queueBind</span><span class="token punctuation">(</span><span class="token string">"normalQueue"</span><span class="token punctuation">,</span><span class="token string">"normalExchange"</span><span class="token punctuation">,</span><span class="token string">"normalKey"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 声明 未路由队列</span>channel<span class="token punctuation">.</span><span class="token function">queueDeclare</span><span class="token punctuation">(</span><span class="token string">"unroutedQueue"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">,</span>null<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 未路由队列 绑定 AE交换器</span>channel<span class="token punctuation">.</span><span class="token function">queueBind</span><span class="token punctuation">(</span><span class="token string">"unroutedQueue"</span><span class="token punctuation">,</span><span class="token string">"myAe"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>特殊情况</p><ul><li>若备份交换器不存在，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li><li>若备份交换器没有绑定任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li><li>若备份交换器没有匹配任何队列，客户端和 RabbitMQ 服务端都不会有异常出现，消息丢失</li><li>若备份交换器和mandatory参数一起使用，该参数无效</li></ul><h2 id="过期时间（TTL）"><a href="#过期时间（TTL）" class="headerlink" title="过期时间（TTL）"></a>过期时间（TTL）</h2><p><strong>通过队列属性设置消息TTL</strong></p><pre class="line-numbers language-java"><code class="language-java">Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Object<span class="token operator">></span> args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Object<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>args<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"x-message-ttl"</span><span class="token punctuation">,</span><span class="token number">6000</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 单位毫秒</span>channel<span class="token punctuation">.</span><span class="token function">queueDeclare</span><span class="token punctuation">(</span>queueName<span class="token punctuation">,</span>durable<span class="token punctuation">,</span>exclusive<span class="token punctuation">,</span>autoDelete<span class="token punctuation">,</span>args<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>不设置TTL：该消息不会过期</li><li>TTL为0：若直接可以投递到消费者，否则立刻被丢弃</li></ul><p>消息过期：一旦过期，从队列中抹去。因为消息在队列头部，RabbitMQ只需要定期从头部开始扫描是否有过期消息即可。</p><p><strong>设置每条消息TTL</strong></p><p>在 <code>channel.basicPublish</code> 方法中加入 expiration 参数，单位毫秒</p><pre class="line-numbers language-java"><code class="language-java">AMQP<span class="token punctuation">.</span>BasicProperties<span class="token punctuation">.</span>Builder builder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AMQP<span class="token punctuation">.</span>BasicProperties<span class="token punctuation">.</span>Builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>builder<span class="token punctuation">.</span><span class="token function">deliveryMode</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>builder<span class="token punctuation">.</span><span class="token function">expiration</span><span class="token punctuation">(</span><span class="token string">"60000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>AMQP<span class="token punctuation">.</span>BasicProperties properties <span class="token operator">=</span> builder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>channel<span class="token punctuation">.</span><span class="token function">basicPublish</span><span class="token punctuation">(</span>exchangeName<span class="token punctuation">,</span>routingKey<span class="token punctuation">,</span>mandatory<span class="token punctuation">,</span>properties<span class="token punctuation">,</span><span class="token string">"ttlTestMessage"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>消息过期：消息过期后，不会马上从队列中抹去，在即将投递到消费者之前判定。每条消息过期时间不同，删除所有过期消息势必要扫描整个队列，因此不如等到消息需要消费时再判定是否过期，若过期则删除。</p><p><strong>设置队列的TTL</strong></p><p>通过 <code>channel.queueDeclare</code> 方法中的 x-expires 参数可以控制队列被自动删除前处于未使用状态的时间</p><p>RabbitMQ 会确保在过期时间到达后将队列删除，在 RabbitMQ 重启后，过期时间会重置</p><h2 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h2><p>当消息在一个队列中变成死信，会被重新发送到死信交换器（Dead-Letter-Exchange, DLX），绑定DLX的队列称为死信队列</p><p>死信原因：1.消息被拒绝； 2.消息过期； 3. 队列达到最大长度</p><p>绑定死信队列：在 channel.queueDeclare 方法中设置 x-dead-letter-exchange 参数为此队列添加 DLX</p><h2 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h2><p>消息当被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，才能拿到消费</p><p><strong>场景：</strong></p><p>订单超时支付，延时队列做异常处理；</p><p>智能设备在指定时间进行工作，延时队列做指令推送；</p><p><strong>用法：</strong></p><ul><li>每条消息设置为10秒过期时间</li><li>通过 exchange.normal 交换器把发送的消息存储到 queue.normal 队列中</li><li>消费者订阅 queue.dlx 队列</li><li>10秒后，消息过期转存到 queue.dlx ，消费者消费到了延迟10秒的这条消息</li></ul><h2 id="优先级队列"><a href="#优先级队列" class="headerlink" title="优先级队列"></a>优先级队列</h2><p>具有高优先级的队列有高的优先权，优先级高的消息优先被消费</p><pre class="line-numbers language-java"><code class="language-java">AMQP<span class="token punctuation">.</span>BasicProperties<span class="token punctuation">.</span>Builder builder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AMQP<span class="token punctuation">.</span>BasicProperties<span class="token punctuation">.</span>Builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>builder<span class="token punctuation">.</span><span class="token function">priority</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>AMQP<span class="token punctuation">.</span>BasicProperties properties <span class="token operator">=</span> builder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>channel<span class="token punctuation">.</span><span class="token function">basicPublish</span><span class="token punctuation">(</span><span class="token string">"exchange_priority"</span><span class="token punctuation">,</span><span class="token string">"rk_priority"</span><span class="token punctuation">,</span>properties<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"message"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>默认优先级为0，最高为队列设置的最大优先级</li><li>如果Broker中有消息堆积，优先级高的消息可以被优先消费</li></ul><h2 id="RPC实现"><a href="#RPC实现" class="headerlink" title="RPC实现"></a>RPC实现</h2><p>远程过程调用（Remote Procedure Call）,通过网络从远程计算上请求服务。应用部署在A服务器上，想要调用B服务器上提供的函数或者方法，需要通过网络表达调用的语义和传达调用的数据。</p><p>RPC的协议包括：Java RMI、WebService的RPC、THrift、RestfulAPI等。</p><pre class="line-numbers language-java"><code class="language-java">String callbackQueueName <span class="token operator">=</span> channel<span class="token punctuation">.</span><span class="token function">queueDeclare</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getQueue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>BasicProperties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BasicProperties<span class="token punctuation">.</span>Builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replyTo</span><span class="token punctuation">(</span>callbackQueueName<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>channel<span class="token punctuation">.</span><span class="token function">basicPublish</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span><span class="token string">"rpc_queue"</span><span class="token punctuation">,</span>props<span class="token punctuation">,</span>message<span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>RPC 处理流程：</p><ul><li>客户端启动时，创建一个匿名的回调队列</li><li>客户端为 RPC 请求设置2个属性：replyTo 告知 RPC 服务端回复请求时的目的队列；correlationId 标记一个请求</li><li>请求被发送到 rpc_queue 队列中</li><li>RPC 服务端监听 rpc_queue 队列中的请求，当请求到来时，服务端会处理并且把带有结果的消息发送给客户端。接收队列是 replyTo 设定的回调队列’’; </li><li>客户端监听回调队列，有消息时，检查 correlationId 属性，如果与请求匹配，就是返回结果</li></ul><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>持久化可以提高 RabbitMQ 的可靠性，防止在异常情况（重启、关闭、宕机）下数据丢失</p><p>持久化的各种情况</p><p>RabbitMQ 持久化分为3个部分：交换器的持久化、队列的持久化、消息的持久化</p><ul><li>若交换器不设置持久化，服务重启后，交换器元数据丢失，但消息存在，不能将消息发送到该交换器中。长期使用的交换器，建议持久化。</li><li>若队列不设置持久化，服务重启后，队列元数据丢失，消息也会丢失；若队列设置持久化，消息不设置，服务重启后，队列元数据存在，但消息丢失</li><li>若所有消息设置持久化，会严重RabbitMQ性能，需要在吞吐量和可靠性之间做权衡</li><li>生产环境会设置镜像队列保证系统的高可用性</li></ul><h2 id="生产者确认"><a href="#生产者确认" class="headerlink" title="生产者确认"></a>生产者确认</h2><p>默认情况下，生产者不知道消息有没有正确到达服务器。因此引入事务和发送方确认机制。</p><p><strong>事务机制</strong></p><p>事务方法：</p><ul><li>channel.txSelect： 用于将当前信道设置成事务模式</li><li>channel.txCommit：用于提交事务</li><li>channel.txRollback：用于事务回滚</li></ul><p>事务流程：</p><ul><li>客户端发送 Tx.Select，将信道置为事务模式</li><li>Broker回复 Tx.Select-Ok，确认已将信道置为事务模式</li><li>Basic.Publish发完消息后，客户端发送 Tx.Commit 提交事务</li><li>Broker 回复 Tx.Commit，确认事务提交</li></ul><p>事务问题：事务机制会耗尽 RabbitMQ 的性能</p><p><strong>发送方确认机制</strong></p><ol><li>生产者将信道设置成 confirm 模式</li><li>信道进入 confirm 模式后，所有在信道上发布的消息都会被指派一个唯一ID</li><li>消息被投递到所有匹配的队列后，RabbitMQ 发送一个确认给生产者</li></ol><p>发送方确认机制好处：相比于事务，它是异步非阻塞的。可以在等待信道返回确认的同时，继续发送下一条消息，当消息得到确认后，生产者可以通过回调方法处理确认消息。</p><p>发送方确认机制的优势在于不一定需要同步确认：</p><ul><li>批量确认：每发送一批消息后，调用channel.waitForCOnfirms方法，等待服务器的确认返回</li><li>异步confirm方法：提供一个回调方法，服务器确认一条或者多条消息后客户端会回调这个方法进行处理。</li></ul><p>注意：批量确认提升了confirm效率，但是返回Basic.Nack或者超时，客户端需要将这一个批次的消息全部重发，会带来明显的重复消息数量。消息经常丢失时，批量confirm性能应该不升反降。</p><h2 id="消费端要点"><a href="#消费端要点" class="headerlink" title="消费端要点"></a>消费端要点</h2><p><strong>消息分发</strong></p><ul><li>当 RabbitMQ 队列有多个消费者，消息会以轮询方式分发给消费者</li><li>但是这样会造成因为各机器性能不同而引起负载不均</li><li>消费端通过调用 channel.basicQos 方法，设置允许限制信道上的消费者保持最大未确认消息数量</li><li>一旦达到未确认消息数量上限，则停止向这个消费者发送消息，实现了“滑动窗口”效果</li><li>Basic.Qos的使用对于拉模式消费方式无效</li></ul><p><strong>消息顺序性</strong></p><p>顺序性指的是消费者消费的消息和发布者发布的消息的顺序是一致的</p><p>顺序性打破的情况：</p><ul><li>生产者使用了事务机制，事务回滚后，补发信息可能在其它线程实现</li><li>启用 publiser confirm时，发生发生超时、中断，导致错序</li><li>生产者设置了延迟队列，但是超时时间设置的不一样</li><li>消息设置了优先级，消费端收到的消息必然不是顺序性的</li></ul><p><strong>弃用 QueueingConsumer</strong></p><ul><li>队列中有大量消息，可能导致内存溢出或假死，可以使用 Basic.Qos 方法得到有效解决</li><li>QueueingConsumer会拖累一个 Connection 下的所有信道，使性能降低</li><li>同步调用 QueueingConsumer 会产生死锁</li></ul><h2 id="消息传输保障"><a href="#消息传输保障" class="headerlink" title="消息传输保障"></a>消息传输保障</h2><p><strong>消息传输保障等级</strong></p><p>At most once：最多一次。消息可能丢失，但绝不会重复传输<br>At least once：最少一次。消息绝不会丢失，但可能重复传输<br>Exactly once：恰好一次。每条消息肯定会，有且传输一次<br>最少一次：需要考虑 事务、mandatory、持久化处理、autoAck<br>最多一次：无须考虑以上问题，随便发送与接收<br>恰好一次：RabbitMQ 目前无法保障。比如消费完Ack闪断，或者生产者发送消息到RabbitMQ，返回确认消息时网络闪断。</p><p>去重一般是通过业务客户端引入GUID实现</p>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq客户端开发</title>
      <link href="/2021/04/03/rabbitmq-ke-hu-duan-kai-fa/"/>
      <url>/2021/04/03/rabbitmq-ke-hu-duan-kai-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="连接-RabbitMQ"><a href="#连接-RabbitMQ" class="headerlink" title="连接 RabbitMQ"></a>连接 RabbitMQ</h2><pre class="line-numbers language-java"><code class="language-java">ConnectionFactory factory <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ConnectionFactory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>factory<span class="token punctuation">.</span><span class="token function">setUsername</span><span class="token punctuation">(</span>USERNAME<span class="token punctuation">)</span><span class="token punctuation">;</span>factory<span class="token punctuation">.</span><span class="token function">setPassword</span><span class="token punctuation">(</span>PASSWORD<span class="token punctuation">)</span><span class="token punctuation">;</span>factory<span class="token punctuation">.</span><span class="token function">setVirtualHost</span><span class="token punctuation">(</span>virtualHost<span class="token punctuation">)</span><span class="token punctuation">;</span>facotry<span class="token punctuation">.</span><span class="token function">setHost</span><span class="token punctuation">(</span>IP_ADRESS<span class="token punctuation">)</span><span class="token punctuation">;</span>factory<span class="token punctuation">.</span><span class="token function">setPort</span><span class="token punctuation">(</span>PORT<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 通过URI方式</span><span class="token comment" spellcheck="true">// factory.setUri("amqp://userName;password@ipAddress:portNumber/virtualHost");</span>Connection conn <span class="token operator">=</span> factory<span class="token punctuation">.</span><span class="token function">newConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Channel channel <span class="token operator">=</span> conn<span class="token punctuation">.</span><span class="token function">createChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Connection 可以创建多个 Channel 实例，但是 Channel 实例不能在线程间共享，应用程序应该为每一个线程开辟一个 Channel</p><h2 id="使用交换器和队列"><a href="#使用交换器和队列" class="headerlink" title="使用交换器和队列"></a>使用交换器和队列</h2><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 持久化的、非自动删除的、绑定类型为direct的交换器</span>channel<span class="token punctuation">.</span><span class="token function">exchangeDeclare</span><span class="token punctuation">(</span>exchangeName<span class="token punctuation">,</span><span class="token string">"direct"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 非持久化的、排他的、自动删除的队列、RabbitMQ自动生成队列名</span>String queueName <span class="token operator">=</span> channel<span class="token punctuation">.</span><span class="token function">queueDeclare</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getQueue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 持久化的、非排他的、非自动删除的、确定的已知名称</span><span class="token comment" spellcheck="true">// channel.queueDeclare(queueName,true,false,false,null);</span>channel<span class="token punctuation">.</span><span class="token function">queueBind</span><span class="token punctuation">(</span>queueName<span class="token punctuation">,</span>exchangeName<span class="token punctuation">,</span>routingKey<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>exchangeDeclare定义：交换器名称、类型、是否持久化、是否自动删除、是否内置</p><p>queueDeclare定义：队列名称、是否持久化、是否排他、是否自动删除。排他队列仅对声明它的连接可见，并在连接断开时自动删除。</p><p>queueBind定义：队列名称、交换器名称、路由键</p><h2 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h2><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> messageBodyBytes <span class="token operator">=</span> <span class="token string">"Hello,world"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 普通发送</span>channel<span class="token punctuation">.</span><span class="token function">basicPublish</span><span class="token punctuation">(</span>exchangeName<span class="token punctuation">,</span>routingKey<span class="token punctuation">,</span>null<span class="token punctuation">,</span>messageBodyBytes<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 控制发送,使用mandatory</span>channel<span class="token punctuation">.</span><span class="token function">basicPublish</span><span class="token punctuation">(</span>exchangeName<span class="token punctuation">,</span>routingKey<span class="token punctuation">,</span>mandatory<span class="token punctuation">,</span>MessageProperties<span class="token punctuation">.</span>PERSiSTENT_TEXT_PLAIN<span class="token punctuation">,</span>messageBodyBytes<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费消息"><a href="#消费消息" class="headerlink" title="消费消息"></a>消费消息</h2><p>消费模式分为退模式和拉模式。推模式采用Basic.Consume,，拉模式采用Basic.Get</p><p><strong>推模式</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">boolean</span> autoAck <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>channel<span class="token punctuation">.</span><span class="token function">basicQos</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">;</span>channel<span class="token punctuation">.</span><span class="token function">basicConsume</span><span class="token punctuation">(</span>queueName<span class="token punctuation">,</span>autoAck<span class="token punctuation">,</span><span class="token string">"myConsumerTag"</span><span class="token punctuation">,</span>    <span class="token keyword">new</span> <span class="token class-name">DefaultConsumer</span><span class="token punctuation">(</span>channel<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">handleDelivery</span><span class="token punctuation">(</span>String consumerTag<span class="token punctuation">,</span>Envelope envelope<span class="token punctuation">,</span>AMQP<span class="token punctuation">.</span>BasicProperties properties<span class="token punctuation">,</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">{</span>            String routingKey <span class="token operator">=</span> envelope<span class="token punctuation">.</span><span class="token function">getRoutingKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            String contentType <span class="token operator">=</span> properties<span class="token punctuation">.</span><span class="token function">getContentType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">long</span> deliveryTag <span class="token operator">=</span> envelope<span class="token punctuation">.</span><span class="token function">getDeliveryTag</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            channel<span class="token punctuation">.</span><span class="token function">basicAck</span><span class="token punctuation">(</span>deliveryTag<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>显示设置autoAck为false，接收消息后显示ack操作，可以防止消息不必要地丢失</p><p>每个Channel都拥有独立的线程，最常用做法是一个Channel对应一个消费者</p><p>如果一个Channel维持多个消费者，其中一个消费者一直运行，其它消费者callback会被耽搁</p><p><strong>拉模式</strong></p><pre class="line-numbers language-java"><code class="language-java">GetResponse response <span class="token operator">=</span> channel<span class="token punctuation">.</span><span class="token function">basicGet</span><span class="token punctuation">(</span>QUEUE_NAME<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">pringln</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>channel<span class="token punctuation">.</span><span class="token function">basicAck</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span><span class="token function">getEnvelope</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getDeliveryTag</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果设置autoAck为false，同样需要调用channel.basicAck来确认消息已被成功接收</p><p>如果是持续订阅，且需要高吞吐量推荐使用推模式。否则单条信息获取，可以使用拉模式。</p><h2 id="消费端的确认与拒绝"><a href="#消费端的确认与拒绝" class="headerlink" title="消费端的确认与拒绝"></a>消费端的确认与拒绝</h2><p><strong>消息确认机制</strong></p><p>RabbitMQ 提供消息确认机制，消费者订阅队列时，需要制定autoAck参数<br>autoAck参数为false，RabbitMQ会等待消费者显式回复确认信号再从内存移去消息<br>autoAck参数为true，RabbitMQ会自动把发出的消息置为确认，然后删除<br><strong>拒绝消息</strong></p><p>消费者接收到消息后，可以通过 Basic.Reject 拒绝消息；批量拒绝消息可以使用Basic.Nack<br>如果requeue参数为true，服务端收到拒绝信号后，会重新把消息发送给下一个消费者<br>如果requeue参数为false，服务端收到拒绝信号后，会把消息从队列中移除<br>如果requeue参数为false，可以启用“死信队列”，分析消息追踪问题<br><strong>注意要点</strong></p><p>RabbitMQ 服务端中的队列分成了两个部分：等待投递的消息；已投递未确认的消息<br>如果 RabbitMQ 一直没有收到确认，并且消费者已经断开连接，会安排此消息重新进入队列，投递给下一个消费者<br>RabbitMQ 不会为未确认的消息设置过期时间，允许长时间消费。</p><h2 id="关闭连接"><a href="#关闭连接" class="headerlink" title="关闭连接"></a>关闭连接</h2><pre class="line-numbers language-java"><code class="language-java">channel<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>conn<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>显式关闭 Channel 不是必须的，在Connection关闭的时候 Channel 也会自动关闭</p>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq概念</title>
      <link href="/2021/04/03/rabbitmq-gai-nian/"/>
      <url>/2021/04/03/rabbitmq-gai-nian/</url>
      
        <content type="html"><![CDATA[<p>Rabbitmq是生产者与消费者模型，负责接收、存储、转发消息。</p><p><img src="moxin.png" alt></p><p><strong>Producer：生产者</strong></p><p><strong>消息</strong>包含2部分：</p><ul><li><p><strong>消息体（payload）：</strong>一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。</p></li><li><p><strong>标签（Label）：</strong>用来描述这条消息，比如一个交换器的名称和一个路由键。</p></li></ul><p><strong>Consumer：消费者</strong></p><p>当消费者消费一条消息时，只是消费消息的消息体（payload）。在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体。</p><p><strong>Broker：服务节点</strong></p><p><strong>Virtual host：</strong>虚拟主机，用于逻辑隔离，最上层消息的路由。一个Virtual host可以若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue</p><p><strong>Queue：队列</strong>，RabbitMQ的内部对象，用于存储信息。多个消费可以订阅同一个队列，但消息会被平均分摊，而不是每个消费者都会受到所有的消息。</p><p><strong>Exchange：交换器</strong>，生产者将消息发送到交换器，交换器将消息路由到一个或者多个队列中</p><p><strong>RoutingKey：路由键</strong>，生产者将消息发给交换器的时候会指定一个路由键，用来指定路由规则</p><p><strong>Binding：绑定</strong>，RabbitMQ通过绑定将交换器与队列关联起来，绑定时会指定BindingKey</p><p><strong>Connection：连接</strong>，生产者或消费者和Broker之间的一条TCP连接</p><p><strong>Channel：信道</strong>，建立在Connection上的虚拟连接，每条AMQP指令都通过信道完成</p><p><strong>交换器类型</strong></p><p>fanout：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中</p><p>direct：把消息路由到BindingKey和RoutingKey完全匹配的队列中</p><p>topic：把消息路由到BindingKey和RoutingKey相匹配的队列中</p><p>headers：根据发送消息内容中的headers进行匹配，性能比较差<br><strong>运转流程</strong><br><strong>生产者发送消息</strong></p><ul><li><p>生产者连接到 RabbitMQ Broker，建立一个连接（Connection），开启一个信道（Channel）</p></li><li><p>生产者声明一个交换器，并设置相关属性（交换机类型、持久化）</p></li><li><p>生产者声明一个队列，并设置相关属性（排他、持久化、自动删除）</p></li><li><p>生产者通过路由键将交换器和队列绑定起来</p></li><li><p>生产者发消息至RabbitMQ Broker（包含路由键、交换器信息）</p></li><li><p>相应的交换器根据接收到的路由键查找相匹配的队列</p></li><li><p>若找到队列，则把消息存入；若没有，则丢弃或者回退给生产者</p></li><li><p>关闭信道</p></li><li><p>关闭连接</p></li></ul><p><strong>消费者接收消息</strong></p><ul><li>消费者连接到 RabbitMQ Broker ，建立一个连接（Connection），开启一个信道（Channel）</li><li>消费者向 RabbitMQ Broker 请求消费对应队列中的消息</li><li>等待 RabbitMQ Broker 回应并投递相应队列中的消息，消费者接收消息</li><li>消费者确认（ack）接收到的消息</li><li>RabbitMQ 从队列中删除相应已经被确认的消息</li><li>关闭信道</li><li>关闭连接</li></ul>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql思维导图</title>
      <link href="/2021/04/02/mysql-si-wei-dao-tu/"/>
      <url>/2021/04/02/mysql-si-wei-dao-tu/</url>
      
        <content type="html"><![CDATA[<p><img src="mysql.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka思维导图</title>
      <link href="/2021/04/02/kafka-si-wei-dao-tu/"/>
      <url>/2021/04/02/kafka-si-wei-dao-tu/</url>
      
        <content type="html"><![CDATA[<p><img src="kafka.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka调优</title>
      <link href="/2021/03/30/kafka-diao-you/"/>
      <url>/2021/03/30/kafka-diao-you/</url>
      
        <content type="html"><![CDATA[<h2 id="调优目标"><a href="#调优目标" class="headerlink" title="调优目标"></a>调优目标</h2><p>吞吐量，也就是 TPS，是指 Broker 端进程或 Client 端应用程序每秒能处理的字节数或消息数。</p><p>延时，表示从 Producer 端发送消息到 Broker 端持久化完成之间的时间间隔。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="操作系统调优"><a href="#操作系统调优" class="headerlink" title="操作系统调优"></a>操作系统调优</h3><p>1、最好在挂载（Mount）文件系统时禁掉 atime 更新。atime 的全称是 access time，记录的是文件最后被访问的时间。可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。</p><p>2、建议将 swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程</p><p>3、ulimit -n 不宜太小</p><p>4、给 Kafka 预留的页缓存越大越好，预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。</p><h3 id="JVM-层调优"><a href="#JVM-层调优" class="headerlink" title="JVM 层调优"></a>JVM 层调优</h3><ol><li>设置堆大小。6～8GB</li><li>GC 收集器使用 G1 收集器。</li></ol><h3 id="Broker-端调优"><a href="#Broker-端调优" class="headerlink" title="Broker 端调优"></a>Broker 端调优</h3><p>保持客户端版本和 Broker 端版本一致。</p><h3 id="应用层调优"><a href="#应用层调优" class="headerlink" title="应用层调优"></a>应用层调优</h3><p>1、不要频繁地创建 Producer 和 Consumer 对象实例。构造这些对象的开销很大，尽量复用它们。</p><p>2、用完及时关闭。这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。3、合理利用多线程来改善性能。生产者、消费者多线程。</p><h2 id="性能指标调优"><a href="#性能指标调优" class="headerlink" title="性能指标调优"></a>性能指标调优</h2><h3 id="调优吞吐量"><a href="#调优吞吐量" class="headerlink" title="调优吞吐量"></a>调优吞吐量</h3><p>1、broker 端参数 <code>num.replica.fetchers</code>表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。</p><p>2、在 Producer 端，如果要改善吞吐量，通常的标配是增加消息批次的大小以及批次缓存时间，即 <code>batch.size</code> 和 <code>linger.ms</code>。</p><p>3、压缩算法也配置上，以减少网络 I/O 传输量，从而间接提升吞吐量。当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd</p><p>4、Consumer端使用多线程方案</p><h3 id="调优延时"><a href="#调优延时" class="headerlink" title="调优延时"></a>调优延时</h3><p>1、在 Broker 端，我们依然要增加 <code>num.replica.fetchers</code> 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时</p><p>2、设置 <code>linger.ms=0</code>，同时不要启用压缩。因为压缩操作本身要消耗 CPU 时间。</p><p>3、Consumer 端，我们保持<code>fetch.min.bytes=1</code> 即可，也就是说，只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka授权</title>
      <link href="/2021/03/29/kafka-shou-quan/"/>
      <url>/2021/03/29/kafka-shou-quan/</url>
      
        <content type="html"><![CDATA[<p>授权，一般是指对与信息安全或计算机安全相关的资源授予访问权限，特别是存取控制。</p><p>Kafka用的是 ACL 模型，规定了什么用户对什么资源有什么样的访问权限。</p><h2 id="kafka-acls-脚本"><a href="#kafka-acls-脚本" class="headerlink" title="kafka-acls 脚本"></a>kafka-acls 脚本</h2><pre class="line-numbers language-shell"><code class="language-shell"># Alice 增加了集群级别的所有权限$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Alice --operation All --topic '*' --cluster$ kafka-acls --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:'*' --allow-host '*' --deny-principal User:BadUser --deny-host 10.205.96.119 --operation Read --topic test-topic<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka认证</title>
      <link href="/2021/03/29/kafka-ren-zheng/"/>
      <url>/2021/03/29/kafka-ren-zheng/</url>
      
        <content type="html"><![CDATA[<p>认证要解决的是你要证明你是谁的问题，授权要解决的则是你能做什么的问题。</p><h2 id="Kafka-认证机制"><a href="#Kafka-认证机制" class="headerlink" title="Kafka 认证机制"></a>Kafka 认证机制</h2><p><strong>基于 SSL 的认证</strong>主要是指 Broker 和客户端的双路认证。</p><p>客户端认证 Broker 的证书，且Broker 也要认证客户端的证书。</p><p><strong>基于 SASL 的安全认证机制</strong></p><p>SASL 是提供认证和数据安全服务的框架。Kafka 支持的 SASL 机制有 5 种：</p><p>GSSAPI：也就是 Kerberos 使用的安全接口，是在 0.9 版本中被引入的。</p><p>PLAIN：是使用简单的用户名 / 密码认证的机制，在 0.10 版本中被引入。</p><p>SCRAM：主要用于解决 PLAIN 机制安全问题的新机制，是在 0.10.2 版本中被引入的。</p><p>OAUTHBEARER：是基于 OAuth 2 认证框架的新机制，在 2.0 版本中被引进。</p><p>Delegation Token：补充现有 SASL 机制的轻量级认证机制，是在 1.1.0 版本被引入的。</p><h2 id="认证机制的比较"><a href="#认证机制的比较" class="headerlink" title="认证机制的比较"></a>认证机制的比较</h2><p>可以使用 SSL 来做通信加密，使用 SASL 来做 Kafka 的认证实现。</p><p><img src="compare.jpg" alt></p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KafkaAdminClient</title>
      <link href="/2021/03/29/kafkaadminclient/"/>
      <url>/2021/03/29/kafkaadminclient/</url>
      
        <content type="html"><![CDATA[<h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><p>主题管理：包括主题的创建、删除和查询。</p><p>权限管理：包括具体权限的配置与删除。</p><p>配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主要有 Broker、主题、用户、Client-id 等。</p><p>副本日志管理：包括副本底层日志路径的变更和详情查询。</p><p>分区管理：即创建额外的主题分区。</p><p>消息删除：即删除指定位移之前的分区消息。</p><p>Delegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。</p><p>消费者组管理：包括消费者组的查询、位移查询和删除。</p><p>Preferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。</p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>AdminClient 是一个双线程的设计：前端主线程和后端 I/O 线程。</p><p>前端线程负责将用户要执行的操作转换成对应的请求，然后再将请求发送到后端 I/O 线程的队列中；</p><p>而后端 I/O 线程（kafka-admin-client-thread）从队列中读取相应的请求，然后发送到对应的 Broker 节点上，之后把执行结果保存起来，以便等待前端线程的获取。</p><p><img src="yuanli.jpg" alt></p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="创建实例"><a href="#创建实例" class="headerlink" title="创建实例"></a>创建实例</h3><pre class="line-numbers language-java"><code class="language-java">Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>AdminClientConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> <span class="token string">"kafka-host:port"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"request.timeout.ms"</span><span class="token punctuation">,</span> <span class="token number">600000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">(</span>AdminClient client <span class="token operator">=</span> AdminClient<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 执行你要做的操作……</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h3><pre class="line-numbers language-java"><code class="language-java">String newTopicName <span class="token operator">=</span> <span class="token string">"test-topic"</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">(</span>AdminClient client <span class="token operator">=</span> AdminClient<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    NewTopic newTopic <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">NewTopic</span><span class="token punctuation">(</span>newTopicName<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token keyword">short</span><span class="token punctuation">)</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//主题名称、分区数和副本数</span>    CreateTopicsResult result <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">createTopics</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span>newTopic<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    result<span class="token punctuation">.</span><span class="token function">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="查询消费者组位移"><a href="#查询消费者组位移" class="headerlink" title="查询消费者组位移"></a>查询消费者组位移</h3><pre class="line-numbers language-java"><code class="language-java">String groupID <span class="token operator">=</span> <span class="token string">"test-group"</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">(</span>AdminClient client <span class="token operator">=</span> AdminClient<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    ListConsumerGroupOffsetsResult result <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">listConsumerGroupOffsets</span><span class="token punctuation">(</span>groupID<span class="token punctuation">)</span><span class="token punctuation">;</span>    Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndMetadata<span class="token operator">></span> offsets <span class="token operator">=</span>         result<span class="token punctuation">.</span><span class="token function">partitionsToOffsetAndMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>offsets<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="获取-Broker-磁盘占用"><a href="#获取-Broker-磁盘占用" class="headerlink" title="获取 Broker 磁盘占用"></a>获取 Broker 磁盘占用</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">try</span> <span class="token punctuation">(</span>AdminClient client <span class="token operator">=</span> AdminClient<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    DescribeLogDirsResult ret <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">describeLogDirs</span><span class="token punctuation">(</span>Collections<span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span>targetBrokerId<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 指定Broker id</span>    <span class="token keyword">long</span> size <span class="token operator">=</span> 0L<span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> DescribeLogDirsResponse<span class="token punctuation">.</span>LogDirInfo<span class="token operator">></span> logDirInfoMap <span class="token operator">:</span> ret<span class="token punctuation">.</span><span class="token function">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">values</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        size <span class="token operator">+=</span> logDirInfoMap<span class="token punctuation">.</span><span class="token function">values</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>logDirInfo <span class="token operator">-</span><span class="token operator">></span> logDirInfo<span class="token punctuation">.</span>replicaInfos<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>            topicPartitionReplicaInfoMap <span class="token operator">-</span><span class="token operator">></span>            topicPartitionReplicaInfoMap<span class="token punctuation">.</span><span class="token function">values</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>replicaInfo <span class="token operator">-</span><span class="token operator">></span> replicaInfo<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">.</span><span class="token function">mapToLong</span><span class="token punctuation">(</span>Long<span class="token operator">:</span><span class="token operator">:</span>longValue<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka脚本</title>
      <link href="/2021/03/29/kafka-jiao-ben/"/>
      <url>/2021/03/29/kafka-jiao-ben/</url>
      
        <content type="html"><![CDATA[<h2 id="生产消息"><a href="#生产消息" class="headerlink" title="生产消息"></a>生产消息</h2><pre class="line-numbers language-shell"><code class="language-shell"># 使用控制台来向 Kafka 的指定主题发送消息$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="消费消息"><a href="#消费消息" class="headerlink" title="消费消息"></a>消费消息</h2><pre class="line-numbers language-shell"><code class="language-shell"># 禁掉了自动提交位移,一些简单的测试$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="测试生产者性能"><a href="#测试生产者性能" class="headerlink" title="测试生产者性能"></a>测试生产者性能</h2><pre class="line-numbers language-shell"><code class="language-shell"># 向指定主题发送了 1 千万条消息，每条消息大小是 1K$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz42175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="测试消费者性能"><a href="#测试消费者性能" class="headerlink" title="测试消费者性能"></a>测试消费者性能</h2><pre class="line-numbers language-shell"><code class="language-shell">$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topicstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="查看主题消息总数"><a href="#查看主题消息总数" class="headerlink" title="查看主题消息总数"></a>查看主题消息总数</h2><pre class="line-numbers language-shell"><code class="language-shell">$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic#最早位移test-topic:0:0test-topic:1:0$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic# 最新位移test-topic:0:5500000 + 5500000 test-topic:1:5500000# 5500000 + 5500000 =1100w<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="查看消息文件数据"><a href="#查看消息文件数据" class="headerlink" title="查看消息文件数据"></a>查看消息文件数据</h2><pre class="line-numbers language-shell"><code class="language-shell">$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log Dumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.logStarting offset: 0baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: truebaseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true......# 查看详细信息$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iterationDumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.logStarting offset: 0baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []......| offset: 14 CreateTime: 1561597044933 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="查看消费者组位移"><a href="#查看消费者组位移" class="headerlink" title="查看消费者组位移"></a>查看消费者组位移</h2><pre class="line-numbers language-shell"><code class="language-shell">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka主题管理</title>
      <link href="/2021/03/28/kafka-zhu-ti-guan-li/"/>
      <url>/2021/03/28/kafka-zhu-ti-guan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="主题增删改查"><a href="#主题增删改查" class="headerlink" title="主题增删改查"></a><strong>主题增删改查</strong></h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><pre class="line-numbers language-shell"><code class="language-shell">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从 Kafka 2.2 版本开始，社区推荐用 –bootstrap-server 参数替换 –zookeeper 参数</p><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><pre class="line-numbers language-shell"><code class="language-shell"># 查询所有主题的列表bin/kafka-topics.sh --bootstrap-server broker_host:port --list# 查询单个主题的详细数据bin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h3><pre class="line-numbers language-shell"><code class="language-shell"># 增加分区bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --partitions <新分区数># 修改主题级别参数,常规的主题级别参数，使用 --zookeeper;动态参数使用 --bootstrap-server bin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name <topic_name> --alter --add-config max.message.bytes=10485760# 变更副本数# reassign.json{"version":1, "partitions":[ {"topic":"__consumer_offsets","partition":0,"replicas":[0,1,2]},   {"topic":"__consumer_offsets","partition":1,"replicas":[0,2,1]},  {"topic":"__consumer_offsets","partition":2,"replicas":[1,0,2]},  {"topic":"__consumer_offsets","partition":3,"replicas":[1,2,0]},  ...  {"topic":"__consumer_offsets","partition":49,"replicas":[0,1,2]}]}` bin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute # 修改test主题限速bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test# 主题分区迁移kafka-reassign-partitions<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><pre class="line-numbers language-shell"><code class="language-shell">bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="特殊主体管理"><a href="#特殊主体管理" class="headerlink" title="特殊主体管理"></a>特殊主体管理</h2><h3 id="查看消费者组提交的位移数"><a href="#查看消费者组提交的位移数" class="headerlink" title="查看消费者组提交的位移数"></a>查看消费者组提交的位移数</h3><pre class="line-numbers language-shell"><code class="language-shell">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --from-beginning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="查看消费者组的状态信息"><a href="#查看消费者组的状态信息" class="headerlink" title="查看消费者组的状态信息"></a>查看消费者组的状态信息</h3><pre class="line-numbers language-shell"><code class="language-shell">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter "kafka.coordinator.group.GroupMetadataManager\$GroupMetadataMessageFormatter" --from-beginning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="常见主题错误处理"><a href="#常见主题错误处理" class="headerlink" title="常见主题错误处理"></a>常见主题错误处理</h2><h3 id="主题删除失败"><a href="#主题删除失败" class="headerlink" title="主题删除失败"></a>主题删除失败</h3><ul><li>副本所在的 Broker 宕机了；–重启即可</li><li>待删除主题的部分分区依然在执行迁移过程</li></ul><p><strong>解决</strong></p><p>第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。</p><p>第 2 步，手动删除该主题在磁盘上的分区目录。</p><p>第 3 步，在 ZooKeeper 中执行 rmr  /controller，触发 Controller 重选举，刷新 Controller 缓存。–非必须，可能造成大面积的分区 Leader 重选举</p><h3 id="consumer-offsets-占用太多的磁盘"><a href="#consumer-offsets-占用太多的磁盘" class="headerlink" title="__consumer_offsets 占用太多的磁盘"></a>__consumer_offsets 占用太多的磁盘</h3><p> jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka高水位和Leader Epoch</title>
      <link href="/2021/03/28/kafka-gao-shui-wei-he-leader-epoch/"/>
      <url>/2021/03/28/kafka-gao-shui-wei-he-leader-epoch/</url>
      
        <content type="html"><![CDATA[<h2 id="高水位"><a href="#高水位" class="headerlink" title="高水位"></a>高水位</h2><p>在分区高水位以下的消息被认为是已提交消息。kafka中，分区的高水位就是其 Leader 副本的高水位。</p><p><strong>作用</strong></p><ul><li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。</li><li>帮助 Kafka 完成副本同步。</li></ul><p><strong>LEO（Log End Offset）</strong>表示副本写入下一条消息的位移值。</p><h2 id="高水位更新机制"><a href="#高水位更新机制" class="headerlink" title="高水位更新机制"></a>高水位更新机制</h2><p><img src="water.jpg" alt></p><p><img src="watertime.jpg" alt></p><h3 id="Leader-副本高水位"><a href="#Leader-副本高水位" class="headerlink" title="Leader 副本高水位"></a><strong>Leader 副本高水位</strong></h3><p><strong>处理生产者请求</strong>的逻辑如下：</p><p>1、写入消息到本地磁盘。</p><p>2、更新分区高水位值。</p><p>i. 获取 Leader 副本所在 Broker 端保存的所有远程副本 LEO 值（LEO-1，LEO-2，……，LEO-n）。</p><p>ii. 获取 Leader 副本高水位值：currentHW。</p><p>iii. 更新 <code>currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}</code>。</p><p><strong>处理 Follower 副本拉取消息</strong>的逻辑如下：</p><p>1、读取磁盘（或页缓存）中的消息数据。</p><p>2、使用 Follower 副本发送请求中的位移值更新远程副本 LEO 值。</p><p>3、更新分区高水位值（具体步骤与处理生产者请求的步骤相同）。</p><h3 id="Follower-副本高水位"><a href="#Follower-副本高水位" class="headerlink" title="Follower 副本高水位"></a><strong>Follower 副本高水位</strong></h3><p><strong>从 Leader 拉取消息的处理逻辑</strong>如下：</p><p>1、写入消息到本地磁盘。</p><p>2、更新 LEO 值。</p><p>3、更新高水位值。</p><p>i. 获取 Leader 发送的高水位值：currentHW。</p><p>ii. 获取步骤 2 中更新过的 LEO 值：currentLEO。</p><p>iii. 更新高水位为 <code>min(currentHW, currentLEO)</code>。</p><h3 id="高水位更新说明"><a href="#高水位更新说明" class="headerlink" title="高水位更新说明"></a>高水位更新说明</h3><p>新消息写入时，先更新leader副本LEO，</p><p>follower副本新消息写入后第一次拉消息，更新了follower副本的LEO，</p><p>follower第二次拉消息，leader副本更新remote LEO、HW；follower副本更新高水位</p><p><strong>问题</strong>：Follower 端高水位的更新与 Leader 端有时间错配。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，可能发生数据丢失。</p><p><strong>背景</strong>：副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。</p><p><img src="bad.jpg" alt></p><p>1、副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 <strong>LEO 值由2调整为之前的高水位值</strong>，也就是 1。</p><p>2、副本 B 开始从 A 拉取消息前，副本 A 所在的 Broker 宕机了，副本 B 成为新的 Leader，A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。</p><p><strong>影响：</strong>位移值为 1 的消息丢失。</p><h2 id="Leader-Epoch"><a href="#Leader-Epoch" class="headerlink" title="Leader Epoch"></a>Leader Epoch</h2><p>它由两部分数据组成。</p><ul><li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li><li>起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。</li></ul><p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目。</p><p><strong>解决：</strong></p><p><img src="good.jpg" alt></p><p>Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 <strong>Leader 的 LEO 值</strong>。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。</p><p>副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。</p><p>后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka控制器</title>
      <link href="/2021/03/28/kafka-kong-zhi-qi/"/>
      <url>/2021/03/28/kafka-kong-zhi-qi/</url>
      
        <content type="html"><![CDATA[<p>控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。每个正常运转的 Kafka 集群，在任意时刻都有且只有一个控制器。</p><p><img src="zookeeper.jpg" alt></p><h2 id="控制器选举"><a href="#控制器选举" class="headerlink" title="控制器选举"></a><strong>控制器选举</strong></h2><p>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。</p><h2 id="控制器作用"><a href="#控制器作用" class="headerlink" title="控制器作用"></a><strong>控制器作用</strong></h2><ul><li>主题管理（创建、删除、增加分区）</li><li>分区重分配</li><li>Preferred 领导者选举：Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案</li><li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）：利用 Watch 机制检测变更。</li><li>数据服务：保存了最全的集群元数据信息</li></ul><p><img src="data.jpg" alt></p><h2 id="控制器故障转移"><a href="#控制器故障转移" class="headerlink" title="控制器故障转移"></a><strong>控制器故障转移</strong></h2><p>故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器。这个过程就被称为 Failover，该过程是自动完成的，无需你手动干预。</p><p><img src="Failover.jpg" alt></p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka Broker请求处理</title>
      <link href="/2021/03/28/kafka-broker-qing-qiu-chu-li/"/>
      <url>/2021/03/28/kafka-broker-qing-qiu-chu-li/</url>
      
        <content type="html"><![CDATA[<p>所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。</p><p>Kafka 使用的是 Reactor 模式处理请求。</p><p><strong>Reactor 模式</strong>是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，它会将不同的请求下发到多个工作线程中处理。工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。</p><p><img src="reactor.jpg" alt></p><p>Kafka 提供了 Broker 端参数 <code>num.network.threads</code>，用于调整该<strong>网络线程池</strong>的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 <strong>个网络线程</strong>，专门处理客户端发送的请求。</p><p><img src="work.jpg" alt></p><p>当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个<strong>共享请求队列</strong>中。Broker 端还有个 <strong>IO 线程池</strong>，负责从该队列中取出请求，执行真正的处理–如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。</p><p>Broker 端参数 <code>num.io.threads</code> 控制了IO线程池中的线程数。默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。</p><p><strong>Purgatory</strong></p><p>缓存延时请求（Delayed Request）,针对一时未满足条件不能立刻处理的请求。</p><p>比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 <code>acks=all</code>，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。一旦完成，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka副本</title>
      <link href="/2021/03/28/kafka-fu-ben/"/>
      <url>/2021/03/28/kafka-fu-ben/</url>
      
        <content type="html"><![CDATA[<p>主题可划分成若干个分，每个分区配置有若干个副本。副本（Replica），本质是一个只能<strong>追加写消息的提交日志</strong>。</p><h2 id="副本分类"><a href="#副本分类" class="headerlink" title="副本分类"></a>副本分类</h2><p>副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p><ul><li><p>所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。</p></li><li><p>追随者副本是不对外提供服务的。从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p></li><li><p>领导者副本所在的 Broker 宕机时，Kafka 依托于 ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。</p></li></ul><p><strong>优势</strong></p><p>1.方便实现“Read-your-writes”：</p><p>2.方便实现单调读（Monotonic Reads）：在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。</p><h2 id="In-sync-Replicas（ISR）"><a href="#In-sync-Replicas（ISR）" class="headerlink" title="In-sync Replicas（ISR）"></a>In-sync Replicas（ISR）</h2><p>与 Leader 同步的副本，包括 Leader 副本。</p><p>标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔。</p><h2 id="Unclean-领导者选举"><a href="#Unclean-领导者选举" class="headerlink" title="Unclean 领导者选举"></a>Unclean 领导者选举</h2><p>非同步副本落后 Leader 太多，并选择这些副本作为新 Leader。</p><p>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka消费者</title>
      <link href="/2021/03/23/kafka-consumer/"/>
      <url>/2021/03/23/kafka-consumer/</url>
      
        <content type="html"><![CDATA[<h2 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h2><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。</p><ul><li>Consumer Group 下可以有一个或多个 Consumer 实例。</li><li>Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li><li>单个分区只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。</li><li>理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数</li></ul><h3 id="重平衡"><a href="#重平衡" class="headerlink" title="重平衡"></a>重平衡</h3><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p><p>协调者（Coordinator），负责为 Group 执行 <strong>Rebalance 以及提供位移管理和组成员管理</strong>等。所有 Broker 都会在启动时，创建和开启各自的 Coordinator 组件。</p><p><strong>Consumer Group 确定 Coordinator 所在的 Broker</strong> </p><p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p><p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p><p>注： Java Consumer API，能够自动发现并连接正确的 Coordinator。</p><p><strong>Rebalance 触发条件</strong></p><ul><li>组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。</li><li>订阅主题数发生变更。</li><li>订阅主题的分区数发生变更。</li></ul><p><strong>重平衡的通知</strong></p><p>通过心跳线程来完成。</p><ul><li>0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，即调用 <code>KafkaConsumer.poll</code>方法的线程。</li><li>0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了消费过长的“假死”触发重平衡。</li></ul><p><strong>Rebalance影响</strong></p><p>1、stop the world，所有 Consumer 实例都会停止消费，等待 Rebalance 完成</p><p>2、Rebalance 效率不高，需要重新分配所有分区</p><p>3、Rebalance很慢</p><p><strong>消费者组状态机</strong></p><p><img src="state.jpeg" alt></p><p><img src="transport.jpg" alt></p><p><strong>消费者端重平衡流程</strong></p><ul><li>加入组</li></ul><p>向协调者发送 JoinGroup 请求，上报订阅的主题。通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。</p><p>协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者。</p><ul><li>等待领导者消费者（Leader Consumer）分配方案</li></ul><p>领导者统一做出分配方案，向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。</p><p>其他成员也会向协调者发送 SyncGroup 请求.</p><p>协调者统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。</p><p><strong>Broker端重平衡流程</strong></p><p>场景一：新成员入组</p><p><img src="newadd.jpg" alt></p><p>场景二：组成员主动离组。</p><p><img src="leavegroup.jpg" alt></p><p>场景三：组成员崩溃离组</p><p><img src="comsumedown.jpg" alt></p><p><strong>避免 Rebalance</strong></p><p>主要方法：<strong>避免组成员数发生减少的情况</strong>。</p><p>Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。<code>session.timeout.ms</code>+ <code>heartbeat.interval.ms</code></p><p>Consumer 端应用程序两次调用<code>poll</code> 方法的最大时间间隔。默认值是 5 分钟，Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。<code>max.poll.interval.ms</code></p><h2 id="位移主题"><a href="#位移主题" class="headerlink" title="位移主题"></a>位移主题</h2><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。自动创建的位移主题分区数是<code>offsets.topic.num.partitions</code> 50，副本数是<code>offsets.topic.replication.factor</code> 3。</p><p>1、将 Consumer 的位移数据作为一条普通的 Kafka 消息，保存到内部主题 <code>__consumer_offsets</code>中。</p><p>位移主题消息的 Key 中格式：&lt;Group ID，主题名，分区号 &gt;，消息体保存了<strong>位移值</strong>和位移提交的元数据，诸如时间戳和用户自定义的数据等。</p><p>2、保存 Consumer Group 相关信息的消息</p><p>3、用于删除 Group 过期位移、删除 Group 的消息。tombstone 消息，即墓碑消息</p><p><strong>消费位移</strong></p><p>记录了 Consumer 要消费的下一条消息的位移。Consumer 需要为分配给它的每个分区提交各自的位移数据。提交位移主要是为了表征 Consumer 的消费进度。</p><p>提交位移的配置：<code>enable.auto.commit</code> + <code>auto.commit.interval.ms</code>控制。</p><h3 id="自动提交位移"><a href="#自动提交位移" class="headerlink" title="自动提交位移"></a><strong>自动提交位移</strong></h3><ul><li><p>Kafka 会保证在开始调用 <code>poll</code> 方法时，提交上次 <code>poll</code> 返回的所有消息。</p></li><li><p>从顺序上来说，<code>poll</code>方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。</p></li><li><p>问题：重平衡出现时可能会出现重复消费</p></li></ul><pre class="line-numbers language-java"><code class="language-java">Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"auto.commit.interval.ms"</span><span class="token punctuation">,</span> <span class="token string">"2000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"foo"</span><span class="token punctuation">,</span> <span class="token string">"bar"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span>                           record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="手动提交位移"><a href="#手动提交位移" class="headerlink" title="手动提交位移"></a>手动提交位移</h3><p><strong>手动提交，需要将 <code>commitSync</code> 和 <code>commitAsync</code> 组合使用。</strong></p><p><code>commitSync()</code>会提交 <code>poll()</code>返回的最新位移。该方法会一直等待，直到位移被成功提交才会返回。</p><p>缺陷：调用 <code>commitSync()</code>时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，阻塞才会结束，影响整个应用程序的 TPS。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span>        consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span>Duration<span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">process</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 处理消息</span>    <span class="token keyword">try</span> <span class="token punctuation">{</span>        consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">CommitFailedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token function">handle</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 处理提交失败异常</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>commitAsync()</code>，立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。Kafka 提供了回调函数<code>callback</code>，供你实现提交之后的逻辑，比如记录日志或处理异常等。<br>缺陷：出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">try</span> <span class="token punctuation">{</span>    <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span>            consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span>Duration<span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">process</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 处理消息</span>        <span class="token function">commitAysnc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 使用异步提交规避阻塞</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span> <span class="token keyword">catch</span><span class="token punctuation">(</span>Exception e<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token function">handle</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 处理异常</span><span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>    <span class="token keyword">try</span> <span class="token punctuation">{</span>        consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 最后一次提交使用同步阻塞式提交</span>    <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>        consumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>和 <code>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 <code>OffsetAndMetadata</code> 对象，保存位移数据。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">private</span> Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndMetadata<span class="token operator">></span> offsets <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>……<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span>        consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span>Duration<span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record<span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token function">process</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 处理消息</span>        offsets<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token keyword">new</span> <span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>；        <span class="token keyword">if</span>（count <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span>）            consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span>offsets<span class="token punctuation">,</span> null<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 回调处理逻辑是null</span>         count<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="CommitFailedException"><a href="#CommitFailedException" class="headerlink" title="CommitFailedException"></a>CommitFailedException</h3><p>提交位移时出现了不可恢复的严重异常。原因一般是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例<br><strong>解决</strong></p><ul><li>缩短单条消息处理的时间</li><li>增加 Consumer 端允许下游系统消费一批消息的最大时长<code>max.poll.interval.ms</code> </li><li>减少下游系统一次性消费的消息总数<code>max.poll.records</code></li><li>下游系统使用多线程来加速消费</li></ul><h3 id="过期消息删除"><a href="#过期消息删除" class="headerlink" title="过期消息删除"></a><strong>过期消息删除</strong></h3><p>kafka 使用 Compact 策略来删除位移主题中的过期消息。</p><p>Kafka 提供了专门的后台线程（Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。</p><p>对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p><h3 id="重设消费者组位移"><a href="#重设消费者组位移" class="headerlink" title="重设消费者组位移"></a>重设消费者组位移</h3><p>由于kafka是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅仅是从磁盘文件上读取数据而已，消费者不会删除消息数据。</p><h4 id="重设位移策略"><a href="#重设位移策略" class="headerlink" title="重设位移策略"></a>重设位移策略</h4><p><img src="stragey.jpg" alt></p><h4 id="重设方式"><a href="#重设方式" class="headerlink" title="重设方式"></a>重设方式</h4><p>通过消费者 API 来实现。</p><pre class="line-numbers language-java"><code class="language-java">Properties consumerProperties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumerProperties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//禁止自动提交位移</span>consumerProperties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>GROUP_ID_CONFIG<span class="token punctuation">,</span> groupID<span class="token punctuation">)</span><span class="token punctuation">;</span>consumerProperties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>AUTO_OFFSET_RESET_CONFIG<span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumerProperties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumerProperties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumerProperties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> brokerList<span class="token punctuation">)</span><span class="token punctuation">;</span>String topic <span class="token operator">=</span> <span class="token string">"test"</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 要重设位移的Kafka主题 </span><span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token keyword">final</span> KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>consumerProperties<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Collections<span class="token punctuation">.</span><span class="token function">singleton</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    consumer<span class="token punctuation">.</span><span class="token function">seekToBeginning</span><span class="token punctuation">(</span>        consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>            partitionInfo <span class="token operator">-</span><span class="token operator">></span> <span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> partitionInfo<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>Collectors<span class="token punctuation">.</span><span class="token function">toList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 需要一次性构造主题的所有分区对象</span><span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// Current</span>consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>    info <span class="token operator">-</span><span class="token operator">></span> <span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> info<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>tp <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>  <span class="token keyword">long</span> committedOffset <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">committed</span><span class="token punctuation">(</span>tp<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>tp<span class="token punctuation">,</span> committedOffset<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Specified-Offset</span><span class="token keyword">long</span> targetOffset <span class="token operator">=</span> 1234L<span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span>PartitionInfo info <span class="token operator">:</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  TopicPartition tp <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> info<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>tp<span class="token punctuation">,</span> targetOffset<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">//Shift-By-N </span><span class="token keyword">for</span> <span class="token punctuation">(</span>PartitionInfo info <span class="token operator">:</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>         TopicPartition tp <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> info<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 假设向前跳123条消息</span>         <span class="token keyword">long</span> targetOffset <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">committed</span><span class="token punctuation">(</span>tp<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> 123L<span class="token punctuation">;</span>          consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>tp<span class="token punctuation">,</span> targetOffset<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">//DateTime </span><span class="token keyword">long</span> ts <span class="token operator">=</span> LocalDateTime<span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2019</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toInstant</span><span class="token punctuation">(</span>ZoneOffset<span class="token punctuation">.</span><span class="token function">ofHours</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toEpochMilli</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> Long<span class="token operator">></span> timeToSearch <span class="token operator">=</span>          consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>info <span class="token operator">-</span><span class="token operator">></span>   <span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> info<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>Collectors<span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span>Function<span class="token punctuation">.</span><span class="token function">identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tp <span class="token operator">-</span><span class="token operator">></span> ts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span>Map<span class="token punctuation">.</span>Entry<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndTimestamp<span class="token operator">></span> entry <span class="token operator">:</span>   consumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>timeToSearch<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>entry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> entry<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">//Duration</span>Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> Long<span class="token operator">></span> timeToSearch <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>info <span class="token operator">-</span><span class="token operator">></span> <span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> info<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>Collectors<span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span>Function<span class="token punctuation">.</span><span class="token function">identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tp <span class="token operator">-</span><span class="token operator">></span> System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">30</span> <span class="token operator">*</span> <span class="token number">1000</span>  <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span>Map<span class="token punctuation">.</span>Entry<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndTimestamp<span class="token operator">></span> entry <span class="token operator">:</span>      consumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>timeToSearch<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>entry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> entry<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 kafka-consumer-groups 命令行脚本来实现</p><pre class="line-numbers language-shell"><code class="language-shell"># to-earliestbin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute# Latest bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --executebin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-current --executebin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset <offset> --executebin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by <offset_N> --executebin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --executebin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="独立消费者"><a href="#独立消费者" class="headerlink" title="独立消费者"></a>独立消费者</h2><p>每个消费者实例都是独立工作的，彼此之间毫无联系。</p><h2 id="KafkaConsumer"><a href="#KafkaConsumer" class="headerlink" title="KafkaConsumer"></a>KafkaConsumer</h2><p>用户主线程，启动 Consumer 应用程序 main 方法的那个线程。</p><p>心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）</p><h3 id="多线程方案"><a href="#多线程方案" class="headerlink" title="多线程方案"></a>多线程方案</h3><p>KafkaConsumer 类不是线程安全的 （thread-safe），不能在多个线程中共享同一个 KafkaConsumer 实例，否则程序会抛出 <code>ConcurrentModificationException</code>异常</p><p>1.消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程</p><p><img src="plan1.jpg" alt></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KafkaConsumerRunner</span> <span class="token keyword">implements</span> <span class="token class-name">Runnable</span> <span class="token punctuation">{</span>     <span class="token keyword">private</span> <span class="token keyword">final</span> AtomicBoolean closed <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AtomicBoolean</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token keyword">private</span> <span class="token keyword">final</span> KafkaConsumer consumer<span class="token punctuation">;</span>     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>         <span class="token keyword">try</span> <span class="token punctuation">{</span>             consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"topic"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>             <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>closed<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      ConsumerRecords records <span class="token operator">=</span>         consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span>Duration<span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                 <span class="token comment" spellcheck="true">//  执行消息处理逻辑</span>             <span class="token punctuation">}</span>         <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">WakeupException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>             <span class="token comment" spellcheck="true">// Ignore exception if closing</span>             <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>closed<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">throw</span> e<span class="token punctuation">;</span>         <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>             consumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token punctuation">}</span>     <span class="token punctuation">}</span>     <span class="token comment" spellcheck="true">// Shutdown hook which can be called from a separate thread</span>     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">shutdown</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>         closed<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         consumer<span class="token punctuation">.</span><span class="token function">wakeup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。</p><p><img src="plan2.jpg" alt></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">final</span> KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer<span class="token punctuation">;</span><span class="token keyword">private</span> ExecutorService executors<span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">private</span> <span class="token keyword">int</span> workerNum <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>executors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ThreadPoolExecutor</span><span class="token punctuation">(</span>  workerNum<span class="token punctuation">,</span>  workerNum<span class="token punctuation">,</span>  0L<span class="token punctuation">,</span>   TimeUnit<span class="token punctuation">.</span>MILLISECONDS<span class="token punctuation">,</span>  <span class="token keyword">new</span> <span class="token class-name">ArrayBlockingQueue</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token keyword">new</span> <span class="token class-name">ThreadPoolExecutor<span class="token punctuation">.</span>CallerRunsPolicy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>  <span class="token punctuation">{</span>  ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span>Duration<span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">final</span> ConsumerRecord record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">{</span>    executors<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Worker</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>方案比较</strong></p><p><img src="compare.jpg" alt></p><h3 id="TCP-连接"><a href="#TCP-连接" class="headerlink" title="TCP 连接"></a>TCP 连接</h3><p><strong>TCP 连接是在调用 <code>KafkaConsumer.poll</code>方法时被创建的。</strong></p><p>1.发起 <code>FindCoordinator</code> 请求时。</p><p>当消费者程序首次启动调用 <code>poll</code>方法时，它需要向 Kafka 集群发送一个名为 <code>FindCoordinator</code> 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。</p><p>2.连接协调者时。</p><p>消费者知晓了真正的协调者后，会创建连向该 Broker 的 Socket 连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。</p><p>3.消费数据时。</p><p>消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP</p><p><strong>消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭。</strong></p><p>1、手动调用<code>KafkaConsumer.close()</code>方法，或者是执行 Kill 命令</p><p>2、Kafka 自动关闭是由消费者端参数 <code>connection.max.idle.ms</code> 控制的，默认值是 9 分钟</p><p>注：当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。</p><h2 id="消费进度"><a href="#消费进度" class="headerlink" title="消费进度"></a>消费进度</h2><p>消费者 Lag 或 Consumer Lag，消费者当前落后于生产者的程度，即在某主题上，Kafka 生产者生产消息和消费消息的差。</p><p><strong>监控方法</strong></p><p>1、使用 Kafka 自带的命令行工具 ·kafka-consumer-groups ·脚本。</p><pre class="line-numbers language-shell"><code class="language-shell"># Kafka 连接信息就是 < 主机名：端口 > 对，而 group 名称就是消费者程序中设置的 group.id 值.$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker连接信息> --describe --group <group名称><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="groups_shell.png" alt></p><p>2、使用 Kafka Java Consumer API 编程。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> Long<span class="token operator">></span> <span class="token function">lagOf</span><span class="token punctuation">(</span>String groupID<span class="token punctuation">,</span> String bootstrapServers<span class="token punctuation">)</span> <span class="token keyword">throws</span> TimeoutException <span class="token punctuation">{</span>    Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>CommonClientConfigs<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> bootstrapServers<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">try</span> <span class="token punctuation">(</span>AdminClient client <span class="token operator">=</span> AdminClient<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        ListConsumerGroupOffsetsResult result <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">listConsumerGroupOffsets</span><span class="token punctuation">(</span>groupID<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">//获取订阅分区的最新消息位移</span>            Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndMetadata<span class="token operator">></span> consumedOffsets <span class="token operator">=</span>                 result<span class="token punctuation">.</span><span class="token function">partitionsToOffsetAndMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span><span class="token punctuation">;</span>            props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>ENABLE_AUTO_COMMIT_CONFIG<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 禁止自动提交位移</span>            props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>GROUP_ID_CONFIG<span class="token punctuation">,</span> groupID<span class="token punctuation">)</span><span class="token punctuation">;</span>            props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token keyword">final</span> KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">//最新消费消息的位移</span>                Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> Long<span class="token operator">></span> endOffsets <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">endOffsets</span><span class="token punctuation">(</span>consumedOffsets<span class="token punctuation">.</span><span class="token function">keySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                 <span class="token keyword">return</span> endOffsets<span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>Collectors<span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span>                    entry <span class="token operator">-</span><span class="token operator">></span> entry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    entry <span class="token operator">-</span><span class="token operator">></span> entry<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> consumedOffsets<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>entry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">InterruptedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            Thread<span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">interrupt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 处理中断异常</span>            <span class="token comment" spellcheck="true">// ...</span>            <span class="token keyword">return</span> Collections<span class="token punctuation">.</span><span class="token function">emptyMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ExecutionException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 处理ExecutionException</span>            <span class="token comment" spellcheck="true">// ...</span>            <span class="token keyword">return</span> Collections<span class="token punctuation">.</span><span class="token function">emptyMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">TimeoutException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">TimeoutException</span><span class="token punctuation">(</span><span class="token string">"Timed out when getting lag for consumer group "</span> <span class="token operator">+</span> groupID<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3、使用 Kafka 自带的 JMX 监控指标。</p><p>Kafka 消费者的JMX 指标 <code>kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”</code>，其中：<code>records-lag-max</code> 和 <code>records-lead-min</code>，分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。</p><p> <strong>Lead 值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lag 越大的话，Lead 就越小。</strong></p><p>一旦 Lead 越来越小，甚至快接近于 0 了，预示着消费者端要丢消息了。</p><p>Kafka 消费者还在分区级别提供了 JMX 指标，用于监控<strong>分区级别的 Lag 和 Lead 值</strong>。JMX 名称为：<code>kafka.consumer:type=consumer-fetch-manager-metrics,partition=“{partition}”,topic=“{topic}”,client-id=“{client-id}”</code></p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka精确一次</title>
      <link href="/2021/03/23/kafka-jing-que-yi-ci/"/>
      <url>/2021/03/23/kafka-jing-que-yi-ci/</url>
      
        <content type="html"><![CDATA[<p>kafka通过<strong>幂等性（Idempotence）</strong>和<strong>事务（Transaction）</strong>实现消息精确一次（exactly once）的可靠性保障。</p><h2 id="幂等性-Producer"><a href="#幂等性-Producer" class="headerlink" title="幂等性 Producer"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或<code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code></p><p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p><ul><li>ProducerID：在每个新的Producer初始化时，会被分配一个唯一的ProducerID，这个ProducerID对客户端使用者是不可见的。</li><li>SequenceNumber：对于每个ProducerID，Producer发送数据的每个Topic和Partition都对应一个从0开始单调递增的SequenceNumber值。</li></ul><p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p><p>多分区以及多会话上的消息无重复，需要依赖<strong>事务型 Producer</strong>.</p><h2 id="事务型-Producer"><a href="#事务型-Producer" class="headerlink" title="事务型 Producer"></a><strong>事务型 Producer</strong></h2><p>事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。</p><p>设置事务型 Producer 的方法：</p><ul><li><p>开启<code>enable.idempotence = true</code>。</p></li><li><p>设置 Producer 端参数<code>transactional.id</code>。最好为其设置一个有意义的名字。</p></li></ul><pre class="line-numbers language-java"><code class="language-java">producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">{</span>    producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record1<span class="token punctuation">)</span><span class="token punctuation">;</span>    producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record2<span class="token punctuation">)</span><span class="token punctuation">;</span>    producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>    producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>isolation.level</code>支持<code>read_uncommitted</code>和<code>read_committed</code></p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka拦截器</title>
      <link href="/2021/03/23/kafka-lan-jie-qi/"/>
      <url>/2021/03/23/kafka-lan-jie-qi/</url>
      
        <content type="html"><![CDATA[<p>Kafka 拦截器分为生产者拦截器和消费者拦截器。</p><p>生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；</p><p>而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</p><p><strong>使用</strong></p><p>当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫<code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p><pre class="line-numbers language-java"><code class="language-java">Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> interceptors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 拦截器1</span>interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 拦截器2</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>INTERCEPTOR_CLASSES_CONFIG<span class="token punctuation">,</span> interceptors<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>AddTimeStampInterceptor</code> 和 <code>UpdateCounterInterceptor</code>这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code>接口。该接口是 Kafka 提供的，里面有两个核心的方法。</p><ul><li><code>onSend</code>：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”。</li><li><code>onAcknowledgement</code>：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。</li></ul><p>消费者拦截器具体的实现类要实现 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里面也有两个核心方法。</p><ul><li><code>onConsume</code>：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。</li><li><code>onCommit</code>：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。</li></ul><p><strong>场景</strong></p><p>Kafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。</p><p>如：业务消息从被生产出来到最后被消费的平均总时长统计</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 生产者</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">AvgLatencyProducerInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">ProducerInterceptor</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> Jedis jedis<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 省略Jedis初始化</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">onSend</span><span class="token punctuation">(</span>ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record<span class="token punctuation">)</span> <span class="token punctuation">{</span>        jedis<span class="token punctuation">.</span><span class="token function">incr</span><span class="token punctuation">(</span><span class="token string">"totalSentMessage"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> record<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onAcknowledgement</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">//消费者</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">AvgLatencyConsumerInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">ConsumerInterceptor</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> Jedis jedis<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//省略Jedis初始化</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">onConsume</span><span class="token punctuation">(</span>ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">long</span> lantency <span class="token operator">=</span> 0L<span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">{</span>            lantency <span class="token operator">+=</span> <span class="token punctuation">(</span>System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> record<span class="token punctuation">.</span><span class="token function">timestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        jedis<span class="token punctuation">.</span><span class="token function">incrBy</span><span class="token punctuation">(</span><span class="token string">"totalLatency"</span><span class="token punctuation">,</span> lantency<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> totalLatency <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>jedis<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"totalLatency"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> totalSentMsgs <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>jedis<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"totalSentMessage"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        jedis<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"avgLatency"</span><span class="token punctuation">,</span> String<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>totalLatency <span class="token operator">/</span> totalSentMsgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> records<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCommit</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndMetadata<span class="token operator">></span> offsets<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka消息丢失</title>
      <link href="/2021/03/23/kafka-xiao-xi-diu-shi/"/>
      <url>/2021/03/23/kafka-xiao-xi-diu-shi/</url>
      
        <content type="html"><![CDATA[<p>kafka 只对“已提交”的消息做有限度的持久化保证。</p><h2 id="避免消息丢失"><a href="#避免消息丢失" class="headerlink" title="避免消息丢失"></a>避免消息丢失</h2><p><strong>生产者</strong></p><ul><li>不要使用 <code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>。一定要使用带有回调通知的 send 方法。</li><li>设置 <code>acks = all</code>。<code>acks</code>是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li><li>设置 <code>retries</code> 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</li></ul><p><strong>broker</strong></p><ul><li>设置 <code>unclean.leader.election.enable = false</code>。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般设置成 false。</li><li>设置 <code>replication.factor &gt;= 3</code>。防止消息丢失的主要机制就是冗余，最好将消息多保存几份。</li><li>设置 <code>min.insync.replicas &gt; 1</code>。消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li><li>确保 <code>replication.factor &gt; min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li></ul><p><strong>消费者</strong></p><ul><li>确保消息消费完成再提交。Consumer 端有个参数 <code>enable.auto.commit</code>，最好把它设置成 <code>false</code>，并采用手动提交位移的方式。对于单 Consumer 多线程处理的场景而言是至关重要的</li></ul>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka生产者</title>
      <link href="/2021/03/23/kafka-producer/"/>
      <url>/2021/03/23/kafka-producer/</url>
      
        <content type="html"><![CDATA[<h2 id="消息分区机制"><a href="#消息分区机制" class="headerlink" title="消息分区机制"></a>消息分区机制</h2><h3 id="为什么分区"><a href="#为什么分区" class="headerlink" title="为什么分区"></a>为什么分区</h3><p><strong>提供负载均衡的能力，实现系统的高伸缩性。</strong></p><p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。</p><h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><p><strong>自定义分区策略</strong></p><p>编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口。其中包含<code>partition()</code>和<code>close()</code>，一般只需要实现 <code>partition</code>方法。</p><p><strong>轮询策略</strong></p><p><code>Round-robin</code> 策略，即顺序分配。</p><p>轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，最合理也最常用的分区策略，。</p><p><strong>随机策略</strong></p><p><code>Randomness</code>策略。将消息放置到任意一个分区上。</p><p><strong>按消息键保序策略</strong></p><p>Kafka 允许为每条消息定义消息键，简称为 Key。可以保证同一个 Key 的所有消息都进入到相同的分区里面，每个分区下的消息处理都是有顺序的。</p><pre class="line-numbers language-java"><code class="language-java">List<span class="token operator">&lt;</span>PartitionInfo<span class="token operator">></span> partitions <span class="token operator">=</span> cluster<span class="token punctuation">.</span><span class="token function">partitionsForTopic</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span> Math<span class="token punctuation">.</span><span class="token function">abs</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">%</span> partitions<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//可以根据 Broker 所在的 IP 地址实现定制化的分区策略</span>List<span class="token operator">&lt;</span>PartitionInfo<span class="token operator">></span> partitions <span class="token operator">=</span> cluster<span class="token punctuation">.</span><span class="token function">partitionsForTopic</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span> partitions<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>    p <span class="token operator">-</span><span class="token operator">></span> <span class="token function">isSouth</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span><span class="token function">leader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">host</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>PartitionInfo<span class="token operator">:</span><span class="token operator">:</span>partition<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">findAny</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h2><p>Kafka 的消息层次分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），日志项是真正封装消息的地方。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。</p><h3 id="V1-版本和-V2-版本区别"><a href="#V1-版本和-V2-版本区别" class="headerlink" title="V1 版本和 V2 版本区别"></a>V1 版本和 V2 版本区别</h3><p>1、把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。</p><p>2、消息的 CRC 校验工作就被移到了消息集合这一层。</p><p>3、 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本是对整个消息集合进行压缩</p><h3 id="何时压缩"><a href="#何时压缩" class="headerlink" title="何时压缩"></a>何时压缩</h3><p>1、Producer 启动后生产的每个消息集合都是经过压缩的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。</p><pre class="line-numbers language-java"><code class="language-java"> Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 开启GZIP压缩</span> props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"compression.type"</span><span class="token punctuation">,</span> <span class="token string">"gzip"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2、Broker 重新压缩消息</p><ul><li><p>Broker 端指定了和 Producer 端不同的压缩算法，需要重新解压缩 / 压缩操作。</p></li><li><p>Broker 端发生了消息格式转换（V1/V2），涉及消息的解压缩和重新压缩，丧失了的 Zero Copy 特性</p></li></ul><h3 id="解压缩"><a href="#解压缩" class="headerlink" title="解压缩"></a>解压缩</h3><p>通常来说解压缩发生在消费者程序中。</p><p> Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。</p><h3 id="压缩算法"><a href="#压缩算法" class="headerlink" title="压缩算法"></a>压缩算法</h3><p>吞吐量：LZ4 &gt; Snappy &gt; zstd 和 GZIP；</p><p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy</p><h2 id="Kafka-生产者程序"><a href="#Kafka-生产者程序" class="headerlink" title="Kafka 生产者程序"></a>Kafka 生产者程序</h2><p>第 1 步：构造生产者对象所需的参数对象。</p><p>第 2 步：利用参数对象，创建 KafkaProducer 对象实例。</p><p>第 3 步：使用 KafkaProducer 的 send 方法发送消息。</p><p>第 4 步：调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。</p><pre class="line-numbers language-java"><code class="language-java">Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“参数<span class="token number">1</span>”<span class="token punctuation">,</span> “参数<span class="token number">1</span>的值”<span class="token punctuation">)</span>；props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“参数<span class="token number">2</span>”<span class="token punctuation">,</span> “参数<span class="token number">2</span>的值”<span class="token punctuation">)</span>；……<span class="token keyword">try</span> <span class="token punctuation">(</span>Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span>……<span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">;</span>  ……<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="生产者的TCP"><a href="#生产者的TCP" class="headerlink" title="生产者的TCP"></a>生产者的TCP</h2><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会<strong>创建与 Broker 的TCP连接</strong>。它会连接 <code>bootstrap.servers</code> 参数指定的所有 Broker。</p><p><code>KafkaProducer</code>实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 <code>RecordAccumulator</code>类，维护了 <code>RecordAccumulator</code> 类的线程安全，也就实现了 KafkaProducer 类的线程安全。</p><p><strong>其他TCP连接创建</strong></p><ul><li><p>当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。</p></li><li><p>当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。</p></li></ul><p><strong>更新元数据场景</strong></p><p>1、当 Producer 尝试给一个不存在的主题发送消息时，Broker 返回不存在。 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。</p><p>2、Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值 5 分钟。</p><p><strong>关闭TCP连接</strong></p><ul><li><p>用户主动关闭</p></li><li><p>Kafka 自动关闭</p></li></ul><p>connections.max.idle.ms范围内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。</p><p>可以在 Producer 端设置 connections.max.idle.ms=-1 ，TCP 连接将成为永久长连接。</p><h2 id="幂等性-Producer"><a href="#幂等性-Producer" class="headerlink" title="幂等性 Producer"></a>幂等性 Producer</h2><p>设置<code>props.put(“enable.idempotence”, ture)</code>，或 <code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG，true)</code></p><p><strong>底层原理：</strong>用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</p><ul><li>ProducerID：在每个新的Producer初始化时，会被分配一个唯一的ProducerID，这个ProducerID对客户端使用者是不可见的。</li><li>SequenceNumber：对于每个ProducerID，Producer发送数据的每个Topic和Partition都对应一个从0开始单调递增的SequenceNumber值。</li></ul><p><strong>作用范围：</strong>它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p><p>多分区以及多会话上的消息无重复，需要<strong>事务</strong>或者依赖<strong>事务型 Producer</strong></p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB LRU 优化</title>
      <link href="/2021/03/21/innodb-lru-you-hua/"/>
      <url>/2021/03/21/innodb-lru-you-hua/</url>
      
        <content type="html"><![CDATA[<p>InnoDB内存管理用的是最近最少使用 （Least Recently Used）算法，这个算法的核心就是淘汰最久未使用的数据。为了应对全表扫描的影响，InnoDB对LRU算法做了改进。</p><p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。</p><p>1、访问young区域，因此和优化前的LRU算法一样，将其移到链表头部</p><p>2、要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p><p>3、处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p><ul><li>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</li><li>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。</li></ul>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据恢复</title>
      <link href="/2021/03/21/shu-ju-hui-fu/"/>
      <url>/2021/03/21/shu-ju-hui-fu/</url>
      
        <content type="html"><![CDATA[<h2 id="delete误删行"><a href="#delete误删行" class="headerlink" title="delete误删行"></a>delete误删行</h2><p>Flashback工具通过闪回把数据恢复回来。</p><blockquote><p>Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。前提是，确保binlog_format=row 和binlog_row_image=FULL。</p></blockquote><p><strong>具体操作</strong></p><ul><li>恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作</li><li>将确认过的临时库的数据，恢复回主库。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。</li></ul><blockquote><p>用truncate /drop table和drop database命令删除的数据记录的binlog还是<strong>statement格式</strong>。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。</p></blockquote><h2 id="truncate-drop误删库-表"><a href="#truncate-drop误删库-表" class="headerlink" title="truncate/drop误删库/表"></a>truncate/drop误删库/表</h2><p>需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。</p><ol><li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</li><li>用备份恢复出一个临时库；</li><li>从日志备份里面，取出凌晨0点之后的日志；</li><li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li></ol><blockquote><p>跳过误操作方法：</p><p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用-stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；<br>如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next=gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。</p></blockquote><h2 id="预防"><a href="#预防" class="headerlink" title="预防"></a>预防</h2><h3 id="搭建延迟复制备库"><a href="#搭建延迟复制备库" class="headerlink" title="搭建延迟复制备库"></a>搭建延迟复制备库</h3><ul><li>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</li></ul><blockquote><p>只要发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。</p></blockquote><h3 id="账号分离"><a href="#账号分离" class="headerlink" title="账号分离"></a>账号分离</h3><ul><li>我们只给业务开发同学DML权限，而不给truncate/drop权限。如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。</li><li>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li></ul><h3 id="制定操作规范"><a href="#制定操作规范" class="headerlink" title="制定操作规范"></a>制定操作规范</h3><ul><li>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。</li><li>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表</li></ul>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基础架构</title>
      <link href="/2021/03/21/ji-chu-jia-gou/"/>
      <url>/2021/03/21/ji-chu-jia-gou/</url>
      
        <content type="html"><![CDATA[<p>MySQL可以分为Server层和存储引擎层两部分。</p><ul><li>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数。</li><li>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。</li></ul><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a><strong>连接器</strong></h2><p>连接器负责跟客户端建立连接、获取权限、维持和管理连接。</p><p>尽量使用长连接，但MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。因此：</p><ol><li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a><strong>查询缓存</strong></h2><p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。</p><blockquote><p><strong>建议不要使用查询缓存。</strong></p></blockquote><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a><strong>分析器</strong></h2><p>词法分析和语法分析。</p><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a><strong>优化器</strong></h2><p>确定语句的执行方案。</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a><strong>执行器</strong></h2><p>开始执行语句。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分库分表</title>
      <link href="/2021/03/15/fen-ku-fen-biao/"/>
      <url>/2021/03/15/fen-ku-fen-biao/</url>
      
        <content type="html"><![CDATA[<h2 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h2><ul><li>有多个业务，每个业务单独分到一个实例里面。</li><li>在一个库中存在过多的表，把这些表拆分到多个库中。</li><li>把字段过多的表拆分成多个表，每张表包含一部分字段。</li></ul><h2 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h2><p>把同一张表分为多张表结构相同的表，每张表里存储一部分数据。</p><p>拆分的算法也比较多，常见的就是取模、范围、和全局表等。</p><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>1、数据量过大，影响了运维操作：备份、大表 DDL 导致主从长时间延迟</p><p>2、不同库表之间性能相互影响</p><h2 id="分表方案"><a href="#分表方案" class="headerlink" title="分表方案"></a><strong>分表方案</strong></h2><p>单表数据量增长速度过快，影响了业务接口的响应时间，但是 MySQL 实例的CPU负载并不高，这时候只需要分表，不需要分库。</p><p>表太大，要么是平均行长度太大，要么是表的记录数太多。这就产生两种不同的分表方案，<strong>即切分字段（垂直分表）和切分记录（水平分表）</strong> 。</p><h3 id="垂直分表"><a href="#垂直分表" class="headerlink" title="垂直分表"></a><strong>垂直分表</strong></h3><p>按照字段进行拆分，这里面需要考虑一个问题，如何拆分字段才能表上的DML性能最大化，常规的方案是冷热分离。</p><blockquote><p>如果用了数据库中间件就会自动实现查询重写，例如 mycat，sharding-sphere，不用中间件的话，稍微比较麻烦点，可以搞一个 route 表（主键ID, 原表名，字段名，子表名），每次解析SQL时都需要根据原表名 + 字段名去获取需要的子表，然后再改写 SQL，执行 SQL 返回结果，这种代码改造量太大，而且容易出错，故这种垂直拆分在实际业务中用的不多。</p></blockquote><p>优点<br>◆ 数据库的拆分简单明了；<br>◆ 数据维护简单；</p><p>缺点<br>◆ 部分表关联无法在数据库级别完成，需要在程序中完成；<br>◆ 对于访问极其频繁且数据量超大的表仍然存在性能瓶颈，不一定能满足要求；<br>◆ 事务处理相对更为复杂；</p><h3 id="水平分表"><a href="#水平分表" class="headerlink" title="水平分表"></a><strong>水平分表</strong></h3><p>水平拆分表就是按照表中的记录进行分片，单表不建议超过 500w。</p><p>优点：<br>◆不会存在某些超大型数据量和高负载的表遇到瓶颈的问题；<br>◆应用程序端整体架构改动相对较少；</p><p>缺点：<br>◆切分规则相对更为复杂，很难抽象出一个能够满足整个数据库的切分规则；<br>◆后期数据的维护难度有所增加，人为手工定位数据更困难；<br>◆应用系统各模块耦合度较高，可能会对后面数据的迁移拆分造成一定的困难。</p><h3 id="共同缺点"><a href="#共同缺点" class="headerlink" title="共同缺点"></a>共同缺点</h3><ol><li><p>引入分布式事务的问题。</p></li><li><p>跨节点Join 的问题。</p></li></ol><p>​    3. 跨节点合并排序分页问题。</p><h3 id="MySQL分区表"><a href="#MySQL分区表" class="headerlink" title="MySQL分区表"></a><strong>MySQL分区表</strong></h3><p>MySQL内部分表的解决方案。</p><p>好处就是 MySQL 内部实现 SQL 路由的功能，不用去改造业务代码。</p><h2 id="分库方案"><a href="#分库方案" class="headerlink" title="分库方案"></a>分库方案</h2><p>随着业务的增长，数据量的增加，<strong>很多接口响应时间变得很长，经常出现 Timeout，而且通过升级 MySQL 实例配置已经无法解决问题了，这时候就要分库</strong>，通常有两种做法：按业务拆库和按表分库。</p><h3 id="按业务分库"><a href="#按业务分库" class="headerlink" title="按业务分库"></a><strong>按业务分库</strong></h3><p>考虑拆分业务，将库存，价格相关的接口独立出来。</p><h3 id="按表分库"><a href="#按表分库" class="headerlink" title="按表分库"></a>按表分库</h3><p>将订单表 orders 拆分20个子表。查询的时候要先通过分区键 user_id 定位是哪个 RDS 实例，再定位到具体的子表，然后做 DML操作。</p><p>问题是代码改造的工作量大，而且服务调用链路变长了，对系统的稳定性有一定的影响。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/agonie201218/article/details/110823552" target="_blank" rel="noopener">https://blog.csdn.net/agonie201218/article/details/110823552</a></p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读写分离</title>
      <link href="/2021/03/15/du-xie-fen-chi/"/>
      <url>/2021/03/15/du-xie-fen-chi/</url>
      
        <content type="html"><![CDATA[<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><h3 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h3><ul><li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li><li>主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）</li><li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li></ul><h3 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a>半同步复制</h3><ul><li>在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。</li><li>主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，<strong>从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功</strong></li><li>从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。</li></ul><h2 id="主从切换"><a href="#主从切换" class="headerlink" title="主从切换"></a>主从切换</h2><h3 id="可靠性优先策略"><a href="#可靠性优先策略" class="headerlink" title="可靠性优先策略"></a>可靠性优先策略</h3><ol><li>判断备库的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；</li><li>把主库改成只读状态，把readonly设为true；</li><li>判断备库的seconds_behind_master的值，直到这个值变成0为止；</li><li>把备库改成可读写状态，把readonly 设为false；</li><li>把业务请求切到备库B。</li></ol><blockquote><p>如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟，这种情况一般业务都是不可接受的。</p></blockquote><h3 id="可用性优先策略"><a href="#可用性优先策略" class="headerlink" title="可用性优先策略"></a>可用性优先策略</h3><p>不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。</p><blockquote><p>可能出现不一致的数据。</p><p>设置binlog_format=row，会出现duplicate key error并停止；</p><p>使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了</p></blockquote><h2 id="备库并行复制策略"><a href="#备库并行复制策略" class="headerlink" title="备库并行复制策略"></a>备库并行复制策略</h2><h3 id="按库并行"><a href="#按库并行" class="headerlink" title="按库并行"></a>按库并行</h3><p>用于决定分发策略的hash表里，key就是数据库名。</p><blockquote><p>如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；</p><p>或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。</p></blockquote><h3 id="MariaDB的并行复制策略"><a href="#MariaDB的并行复制策略" class="headerlink" title="MariaDB的并行复制策略"></a>MariaDB的并行复制策略</h3><blockquote><p>利用redo log组提交特性：</p><ul><li><p>能够在同一组里提交的事务，一定不会修改同一行；</p></li><li><p>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</p></li></ul></blockquote><p>实现方法</p><ol><li>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；</li><li>commit_id直接写到binlog里面；</li><li>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；</li><li>这一组全部执行完成后，coordinator再去取下一批。</li></ol><h3 id="MySQL-5-7-22的新增并行复制策略"><a href="#MySQL-5-7-22的新增并行复制策略" class="headerlink" title="MySQL 5.7.22的新增并行复制策略"></a>MySQL 5.7.22的新增并行复制策略</h3><p>基于WRITESET的并行复制。</p><p>参数<code>binlog-transaction-dependency-tracking</code>，用来控制是否启用这个新策略。这个参数的可选值有以下三种。</p><ol><li>COMMIT_ORDER，根据同时进入prepare和commit来判断是否可以并行的策略。</li><li>WRITESET，表示的是对于事务涉及更新的每一行，计算出它的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。</li><li>WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li></ol><h2 id="主从延迟"><a href="#主从延迟" class="headerlink" title="主从延迟"></a>主从延迟</h2><h3 id="可能原因"><a href="#可能原因" class="headerlink" title="可能原因"></a>可能原因</h3><ul><li>大表 DDL</li><li>大事务</li><li>主库 DML 并发大</li><li>从库配置差</li></ul><h3 id="判断主从延迟"><a href="#判断主从延迟" class="headerlink" title="判断主从延迟"></a>判断主从延迟</h3><p>1、判断 Seconds_Behind_Master 是否等于 0。</p><p>2、对比位点，Master_Log_File 跟 Relay_Master_Log_File 相等，并且 Read_Master_Log_Pos 跟 Exec_Master_Log_Pos 相等。</p><p>3、对比GTID，对比 Retrieved_Gtid_Set 和 Executed_Gtid_Set 是否相等。</p><h2 id="主备切换"><a href="#主备切换" class="headerlink" title="主备切换"></a>主备切换</h2><h3 id="基于位点的主备切换"><a href="#基于位点的主备切换" class="headerlink" title="基于位点的主备切换"></a><strong>基于位点的主备切换</strong></h3><p>考虑到切换过程中不能丢数据，所以找位点时，找一个“稍微往前”的。再通过判断，跳过那些在从库上已经执行过的事务。</p><p>通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。</p><ul><li>主动跳过一个事务。</li><li>通过设置slave_skip_errors参数，直接设置跳过指定的错误。</li></ul><pre class="line-numbers language-mysql"><code class="language-mysql">CHANGE MASTER TOMASTER_HOST=$host_nameMASTER_PORT=$portMASTER_USER=$user_nameMASTER_PASSWORD=$passwordMASTER_LOG_FILE=$master_log_nameMASTER_LOG_POS=$master_log_pos<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="基于GTID的主备切换"><a href="#基于GTID的主备切换" class="headerlink" title="基于GTID的主备切换"></a><strong>基于GTID的主备切换</strong></h3><p>GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。在GTID模式下，每个事务都会跟一个GTID一一对应。</p><pre class="line-numbers language-mysql"><code class="language-mysql">CHANGE MASTER TOMASTER_HOST=$host_nameMASTER_PORT=$portMASTER_USER=$user_nameMASTER_PASSWORD=$passwordmaster_auto_position=1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主备切换逻辑，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b:</p><ol><li>实例B指定主库A’，基于主备协议建立连接。</li><li>实例B把set_b发给主库A’。</li><li>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。<br>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；<br>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</li><li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。</li></ol><h2 id="过期读"><a href="#过期读" class="headerlink" title="过期读"></a>过期读</h2><p>问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。</p><h3 id="强制走主库方案"><a href="#强制走主库方案" class="headerlink" title="强制走主库方案"></a><strong>强制走主库方案</strong></h3><ol><li>对于必须要拿到最新结果的请求，强制将其发到主库上</li><li>对于可以读到旧数据的请求，才将其发到从库上。</li></ol><h3 id="sleep方案"><a href="#sleep方案" class="headerlink" title="sleep方案"></a><strong>sleep方案</strong></h3><p>大多数情况下主备延迟在1秒之内，主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条<code>select sleep(1)</code>命令。</p><p>以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。</p><p><strong>缺点</strong></p><ol><li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</li><li>如果延迟超过1秒，还是会出现过期读。</li></ol><h3 id="判断主备无延迟方案"><a href="#判断主备无延迟方案" class="headerlink" title="判断主备无延迟方案"></a><strong>判断主备无延迟方案</strong></h3><ul><li><p>第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。</p></li><li><p>第二种方法，对比位点确保主备无延迟（show slave status）：<br>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；<br>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。<br>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成</p></li><li><p>第三种方法，对比GTID集合确保主备无延迟（show slave status）：</p><p>Auto_Position=1 ，表示这对主备关系使用了GTID协议。<br>Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；<br>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。</p><p>缺点：仍可能过期读。备库收到的日志都执行完成了。还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p></li></ul><h3 id="配合semi-sync方案"><a href="#配合semi-sync方案" class="headerlink" title="配合semi-sync方案"></a><strong>配合semi-sync方案</strong></h3><p>引入半同步复制，配合前面关于位点的判断。</p><blockquote><p>在一主多从场景中，如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</p><p>在持续延迟的情况下，可能出现过度等待的问题。</p></blockquote><h3 id="等主库位点方案"><a href="#等主库位点方案" class="headerlink" title="等主库位点方案"></a><strong>等主库位点方案</strong></h3><ol><li>trx1事务更新完成后，马上执行<code>show master status</code>得到当前主库执行到的File和Position；</li><li>选定一个从库执行查询语句；</li><li>在从库上执行<code>select master_pos_wait(File, Position, 1)</code>；</li><li>如果返回值是&gt;=0的正整数，则在这个从库执行查询语句；</li><li>否则，到主库执行查询语句。</li></ol><blockquote><p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p></blockquote><h3 id="等GTID方案"><a href="#等GTID方案" class="headerlink" title="等GTID方案"></a><strong>等GTID方案</strong></h3><ol><li>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</li><li>选定一个从库执行查询语句；</li><li>在从库上执行 <code>select wait_for_executed_gtid_set(gtid1, 1)</code>；</li><li>如果返回值是0，则在这个从库执行查询语句；</li><li>否则，到主库执行查询语句。</li></ol><blockquote><p>等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MVCC</title>
      <link href="/2021/03/14/mvcc/"/>
      <url>/2021/03/14/mvcc/</url>
      
        <content type="html"><![CDATA[<h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><p>多版本并发控制。</p><blockquote><p>MVCC 只在 RC 和 RR 两个隔离级别下工作。</p><p>不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p></blockquote><h2 id="Undo-log"><a href="#Undo-log" class="headerlink" title="Undo log"></a>Undo log</h2><p>undo log 是逻辑日志，将数据库逻辑地恢复到原来的样子，所有修改都被逻辑地取消了，支持事务回滚，保证了事务的原子性。</p><p>undo log 的另一个作用是 MVCC， MVCC 的实现是通过 undo 来完成的。当用户读取一行记录时，可以通过 undo log 读取之前的行版本信息，以此实现非锁定读取。保证了事务的隔离性。</p><h2 id="MVCC-的实现原理"><a href="#MVCC-的实现原理" class="headerlink" title="MVCC 的实现原理"></a>MVCC 的实现原理</h2><p>通过保存数据在某个时间点的快照来实现的：</p><p>InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。</p><p>每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询记录的版本号进行比较。</p><h2 id="MVCC-的优势"><a href="#MVCC-的优势" class="headerlink" title="MVCC 的优势"></a>MVCC 的优势</h2><p>MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。<br>通过 MVCC，保证了事务 ACID 中的隔离性特性。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>事务</title>
      <link href="/2021/03/14/shi-wu/"/>
      <url>/2021/03/14/shi-wu/</url>
      
        <content type="html"><![CDATA[<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>一个不可分割的数据库操作序列，是数据库并发控制的基本单位。</p><p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p><h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><ul><li>atomicity（原子性） ：要么全执行，要么全都不执行；</li><li>consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；</li><li>isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；</li><li>durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。</li></ul><h3 id="并发事务可能存在的问题"><a href="#并发事务可能存在的问题" class="headerlink" title="并发事务可能存在的问题"></a>并发事务可能存在的问题</h3><ul><li>脏读：读取未提交的事务。</li><li>不可重复读：多次读取同一数据，读取的数据不一致。</li><li>幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li></ul><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><ul><li>READ-UNCOMMITTED：一个事务还没提交时，它做的变更就能被别的事务看到。</li><li>READ-COMMITTED：一个事务提交之后，它做的变更才会被其他事务看到。</li><li>REPEATABLE-READ：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。</li><li>SERIALIZABLE：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ul><h3 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h3><p>数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p><ul><li><p>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</p></li><li><p>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</p></li><li><p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</p></li><li><p>“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p></li></ul><h2 id="事务可见性分析（RR）"><a href="#事务可见性分析（RR）" class="headerlink" title="事务可见性分析（RR）"></a>事务可见性分析（RR）</h2><p>事务启动瞬间，当前正在“活跃”的所有事务ID的最小值记为<strong>低水位</strong>，最大值加1记为<strong>高水位</strong>。</p><ul><li>row trx_id&lt;低水位：这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li><li>低水位&lt;row trx_id&lt;高水位：<ul><li>在活跃数组中，表示这个版本是由还没提交的事务生成的，不可见；</li><li>不在活跃数组中，表示这个版本是已经提交了的事务生成的，可见。</li></ul></li><li>row trx_id&gt;高水位：由将来启动的事务生成的，是肯定不可见的；</li></ul><p>也可以从事务启动时间来看：</p><ol><li>版本未提交，不可见；</li><li>版本已提交，但是是在视图创建后提交的，不可见；</li><li>版本已提交，而且是在视图创建前提交的，可见。</li></ol><blockquote><p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</p><p>select * from t where id=1加上lock in share mode 或for update，也是当前读。</p></blockquote><h2 id="Redo-log"><a href="#Redo-log" class="headerlink" title="Redo log"></a>Redo log</h2><p>Redo log称为重做日志，用于记录事务操作变化，记录的是数据被修改之后的值。</p><p>Redo log 由两部分组成：</p><ul><li>内存中的重做日志缓冲（redo log buffer）</li><li>重做日志文件（redo log file）</li></ul><p>每次数据更新会先更新 redo log buffer，然后根据 innodb_flush_log_at_trx_commit 来控制 redo log buffer 更新到redo log file 的时机。innodb_flush_log_at_trx_commit 有三个值可选：</p><ul><li>0：表示每次事务提交时都只是把redo log留在<strong>redo log buffer中</strong>，每隔一秒把log buffer刷到文件系统中去，并且调用文件系统的“flush”操作将缓存刷新到磁盘上去。</li><li>1（默认值）：表示每次事务提交时都将redo log刷到文件系统中，并flush到磁盘；</li><li>2：表示每次事务提交时都只是把redo log刷到文件系统，但不flush到磁盘。</li></ul><p>除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。</p><ul><li>redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。</li><li>并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。</li></ul><h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h2><p>二进制日志（binlog）记录了所有的 DDL（数据定义语句）和 DML（数据操纵语句）</p><p>Binlog 有以下几个作用：</p><ul><li>恢复：数据恢复时可以使用二进制日志</li><li>复制：通过传输二进制日志到从库，然后进行恢复，以实现主从同步</li><li>审计：可以通过二进制日志进行审计数据的变更操作</li></ul><p>sync_binlog 来控制累积多少个事务后才将二进制日志 fsync 到磁盘。</p><ul><li>sync_binlog=0，表示每次提交事务都只write，不fsync。文件系统决定什么时候fsync</li><li>sync_binlog=1，表示每次提交事务都会执行fsync</li><li>sync_binlog=N，表示每次提交事务都write，累积N个事务后才fsync</li></ul><p><strong>binlog格式</strong></p><ul><li>statement：binlog里面记录的就是SQL语句的原文。可能会导致主备不一致。不太推荐使用</li><li>row：binlog里面记录了真实删除行的主键id，不会有主备删除不同行的问题。缺点是很占空间。优点利于恢复数据。</li><li>mixed格：MySQL自己判断SQL语句是否可能引起主备不一致，是就用row格式，否则就用statement格式。</li></ul><h2 id="redolog和binlog区别"><a href="#redolog和binlog区别" class="headerlink" title="redolog和binlog区别"></a>redolog和binlog区别</h2><ul><li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p></li><li><p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</p></li><li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p></li></ul><h2 id="数据库突然断电不丢数据"><a href="#数据库突然断电不丢数据" class="headerlink" title="数据库突然断电不丢数据"></a>数据库突然断电不丢数据</h2><p>只要 innodb_flush_log_at_trx_commit 和 sync_binlog 都为 1（通常称为：双一），就能确保MySQL 机器断电重启后，数据不丢失。</p><h2 id="事务建议"><a href="#事务建议" class="headerlink" title="事务建议"></a>事务建议</h2><ul><li>循环写入的情况，如果循环次数不是太多，建议在循环前开启一个事务，循环结束后统一提交。</li><li>优化事务里的语句顺序，减少锁时间。</li><li>关注不同事务访问资源的顺序，避免死锁。</li><li>创建事务之前，关注事务隔离级别。</li><li>不在事务中混合使用存储引擎（MyISAM无法回滚）</li></ul><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>分布式事务使用两阶段提交协议：<br>第一阶段：所有分支事务都开始准备，告诉事务管理器自己已经准备好了；<br>第二阶段：确定是 rollback 还是 commit，如果有一个节点不能提交，则所有节点都要回滚。</p><h3 id="MySQL-自带的分布式事务"><a href="#MySQL-自带的分布式事务" class="headerlink" title="MySQL 自带的分布式事务"></a>MySQL 自带的分布式事务</h3><pre class="line-numbers language-mysql"><code class="language-mysql">xa start 'a','a_1'; //启动分支事务xa end 'a','a_1'; //结束分支事务xa prepare 'a','a_1'; //进入准备状态xa commit 'a','a_1';  //提交分支事务xa recover;  //返回当前数据库中处于 prepare 状态的分支事务的详细信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>锁</title>
      <link href="/2021/03/14/mysql-lock/"/>
      <url>/2021/03/14/mysql-lock/</url>
      
        <content type="html"><![CDATA[<p>锁就是协调多个用户或者客户端并发访问某一资源的机制，保证数据并发访问时的一致性和有效性。</p><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><p>MySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表。</p><pre class="line-numbers language-mysql"><code class="language-mysql">FLUSH TABLES WITH READ LOCK;UNLOCK TABLES;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞。</p><p><strong>场景</strong></p><p>一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。</p><blockquote><p>mysqldump 包含一个参数 <code>--single-transaction</code>，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以建议使用InnoDB 存储引擎。</p></blockquote><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>表级锁有两种：表锁和元数据锁。</p><h3 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h3><p><strong>场景</strong></p><ol><li>事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；</li><li>事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。</li></ol><pre class="line-numbers language-mysql"><code class="language-mysql">lock tables t14 read;lock tables t14 write;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>表读锁本线程和其它线程可以读，本线程写会报错，其它线程写会等待。</p><h3 id="元数据锁"><a href="#元数据锁" class="headerlink" title="元数据锁"></a>元数据锁</h3><p>MDL不需要显式使用，在访问一个表的时候会被自动加上。</p><p>MDL的作用是，保证读写的正确性。MDL 锁的出现解决了同一张表上事务和 DDL 并行执行时可能导致数据不一致的问题。</p><blockquote><p>对开发而言尽量避免慢查询，事务要及时提交，避免大事务。</p><p>对于 DBA 来说，也应该尽量避免在业务高峰执行 DDL 操作。并且DDL期间需要避免长事务。</p></blockquote><p>在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。</p><pre class="line-numbers language-mysql"><code class="language-mysql">ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h2><ul><li>InnoDB 支持事务：适合在并发条件下要求数据一致的场景。</li><li>InnoDB 支持行锁：有效降低由于删除或者更新导致的锁定。</li></ul><h3 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h3><p>行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。</p><p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p><h3 id="行锁-1"><a href="#行锁-1" class="headerlink" title="行锁"></a>行锁</h3><p>两种类型的行锁：</p><ul><li>共享锁（S）：允许一个事务去读一行，阻止其它事务获得相同数据集的排他锁；</li><li>排他锁（X）：允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享读锁和排他写锁。</li></ul><p>共享锁（S）：<code>select * from table_name where … lock in share mode;</code><br>排他锁（X）：<code>select * from table_name where … for update(当前读)</code>。</p><h3 id="行锁算法"><a href="#行锁算法" class="headerlink" title="行锁算法"></a>行锁算法</h3><p>Record Lock：单个记录上的索引加锁。<br>Gap Lock：间隙锁，对索引项之间的间隙加锁，但不包括记录本身。<br>Next-Key Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。</p><h3 id="加锁规则"><a href="#加锁规则" class="headerlink" title="加锁规则"></a>加锁规则</h3><p>5.x系列&lt;=5.7.24，8.0系列 &lt;=8.0.13</p><ol><li>原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。</li><li>原则2：查找过程中访问到的对象才会加锁。</li><li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li><li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li><li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li></ol><h3 id="加锁分析"><a href="#加锁分析" class="headerlink" title="加锁分析"></a>加锁分析</h3><h4 id="非索引字段查询（RC）"><a href="#非索引字段查询（RC）" class="headerlink" title="非索引字段查询（RC）"></a>非索引字段查询（RC）</h4><p>如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。</p><h4 id="唯一索引查询（RC）"><a href="#唯一索引查询（RC）" class="headerlink" title="唯一索引查询（RC）"></a>唯一索引查询（RC）</h4><p>如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。</p><h4 id="非唯一索引查询（RC）"><a href="#非唯一索引查询（RC）" class="headerlink" title="非唯一索引查询（RC）"></a>非唯一索引查询（RC）</h4><p>如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。</p><h4 id="非索引字段查询（RR）"><a href="#非索引字段查询（RR）" class="headerlink" title="非索引字段查询（RR）"></a>非索引字段查询（RR）</h4><p>RR 隔离级别下，非索引字段做条件的当前读不但会把每条记录都加上 X 锁，还会把每个 GAP 加上GAP 锁。（条件字段加索引的重要性！）</p><h4 id="唯一索引查询（RR）"><a href="#唯一索引查询（RR）" class="headerlink" title="唯一索引查询（RR）"></a>唯一索引查询（RR）</h4><p>如果能确保索引字段唯一，那其实一个等值查询，最多就返回一条记录，而且相同索引记录的值，一定不会再新增，因此不会出现 GAP 锁。</p><p>以唯一索引为条件的当前读，不会有 GAP 锁。</p><h4 id="非唯一索引查询（RR）"><a href="#非唯一索引查询（RR）" class="headerlink" title="非唯一索引查询（RR）"></a>非唯一索引查询（RR）</h4><p>新增GAP锁+对应数据的X锁</p><h2 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h2><p>借助数据库锁机制在修改数据之前锁定，再修改的方式被称为悲观并发控制。</p><p><strong>优点：</strong>利用锁机制保证了数据的顺序执行，不需要自己控制，加锁、释放完全由数据库代劳<br><strong>缺点：</strong>一旦一个事务获取了锁，其他的事务必须等待，势必会影响系统的吞吐量</p><p><strong>适用场景</strong>：写入操作比较频繁的场景</p><h2 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h2><p>假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据冲突与否进行检测。</p><p><strong>优点：</strong>由于不需要加锁，其他的事务可以同时操作数据，相比于悲观锁，系统吞吐量会提高<br><strong>缺点：</strong>锁机制，如果并发度较高，失败重试的情况会成为系统瓶颈</p><p><strong>适用场景</strong>：读取操作比较频繁的场景</p><h2 id="锁定位"><a href="#锁定位" class="headerlink" title="锁定位"></a>锁定位</h2><p>1、show processlist，查看state</p><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。</p><p><strong>“唯一键”引起的死锁</strong></p><p>会话 A获取了排它锁开始插入，之后的事务（“会话 B”，“会话 C”）再去执行时会出现 Duplicate Key（重复的值）问题，此时它们都会去申请该行记录的共享锁。如果这个时候，占据排它锁的事务出现回滚（“会话 A”），另外的两个事务会同时去申请排它锁。但是，在数据库中，排它锁和共享锁是互斥资源，也就导致了死锁。</p><p>之所以在出现 Duplicate Key 时会加上共享锁，是因为冲突检测是读操作，所以，冲突之后的轮询仍然会有共享限制。</p><p><strong>解决方法</strong></p><ol><li>检测到死锁的循环依赖，立即返回一个错误，将参数 innodb_deadlock_detect设置为 on 表示开启这个逻辑；</li><li>等查询的时间达到锁等待超时的设定后放弃锁请求。这个超时时间由 innodb_lock_wait_timeout 来控制。默认是50 秒。</li></ol><p>方案1有额外的CPU检测开销，确保无死锁时建议关闭检测。或者将一行改成逻辑上的多行来是控制并发度，减少锁冲突。以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。</p><p><strong>降低死锁概率</strong></p><ol><li>更新 SQL 的 where 条件尽量用索引；</li><li>基于 primary 或 unique key 更新数据；</li><li>减少范围更新，尤其非主键、非唯一索引上的范围更新；</li><li>加锁顺序一致，尽可能一次性锁定所有需要行；</li><li>将 RR 隔离级别调整为 RC 隔离级别。</li></ol><p><strong>分析死锁</strong></p><pre class="line-numbers language-mysql"><code class="language-mysql">SHOW FULL PROCESSLIST; //State字段，waiting for ... lockshow engine innodb status\G; //查看最后一次死锁信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>另外设置 innodb_print_all_deadlocks = on 可以在 err log 中记录全部死锁信息。</p><p>INNODB_TRX 表记录了当前处于运行状态的所有事务，包含非常详细的信息，例如：事务是否正在等待一个锁、事务是否正在执行等等。</p><p>INNODB_LOCKS 记录的是 InnoDB 事务去请求但没有获取到的锁信息和事务阻塞其他事务的锁信息。</p><p>INNODB_LOCK_WAITS记录了事务的锁等待状态。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引</title>
      <link href="/2021/03/13/suo-yin/"/>
      <url>/2021/03/13/suo-yin/</url>
      
        <content type="html"><![CDATA[<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="B-树"><a href="#B-树" class="headerlink" title="B 树"></a>B 树</h3><p>B 树每个节点都包含 key 值和 data 值。</p><p>如果 data 比较大时，每一页存储的 key 会比较少；</p><p>当数据比较多时，要经历多层节点才能查询在叶子节点的数据。</p><h3 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B+ 树"></a>B+ 树</h3><ul><li>所有叶子节点中包含了全部关键字的信息</li><li>各叶子节点用指针进行连接</li><li>非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量。</li><li>B 树是纵向扩展，最终变成一个“瘦高个”，而 B+ 树是横向扩展的，最终会变成一个“矮胖子”</li></ul><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>实际上并不是一种索引类型，而是一种存储数据的方式，且是将索引和数据存储在一起。</p><p>InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。</p><h3 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h3><p>InnoDB 存储引擎辅助索引的叶子节点存放的是键值和主键 ID。</p><p>当通过辅助索引来寻找数据时，InnoDB 存储引擎会查找到对应记录的主键，然后通过主键索引来找到对应的行数据。</p><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。</p><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>数据检索</li><li>聚合函数（max/count）</li><li>排序</li><li>避免回表（覆盖索引）</li><li>关联查询</li></ul><h3 id="普通索引和唯一索引"><a href="#普通索引和唯一索引" class="headerlink" title="普通索引和唯一索引"></a>普通索引和唯一索引</h3><h4 id="Insert-Buffer"><a href="#Insert-Buffer" class="headerlink" title="Insert Buffer"></a><strong>Insert Buffer</strong></h4><ul><li><p>对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池（Buffer Pool）中。</p></li><li><p>如果在，则直接插入；如果不在，则先放入 Insert Buffer 中</p></li><li><p>然后再以一定频率和情况进行 Insert Buffer 和辅助索引叶子节点的 merge 操作。</p></li></ul><blockquote><p><strong>要求不是唯一索引</strong></p><p>意义：将多个插入合并到一个操作中，大大提高了非聚集索引的插入性能。</p></blockquote><h4 id="Change-Buffer"><a href="#Change-Buffer" class="headerlink" title="Change Buffer"></a><strong>Change Buffer</strong></h4><p>Insert Buffer 的升级，InnoDB 存储引擎可以对 insert、delete、update操作都进行缓存。</p><blockquote><p><strong>要求不是唯一索引</strong></p><p>唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了。</p><ul><li>innodb_change_buffering：确定哪些场景使用 Change Buffer，它的值包含：none、inserts、deletes、changes、purges、all。默认为 all，表示启用所有。</li><li>innodb_change_buffer_max_size：控制 Change Buffer 最大使用内存占总 buffer pool 的百分比。默认25，表示最多可以使用 buffer pool 的 25%，最大值50。</li></ul></blockquote><p><strong>适用场景</strong></p><p>对于<strong>写多读少</strong>的业务来说，页面在<strong>写完以后马上被访问到的概率比较小</strong>，此时changebuffer的使用效果最好。这种业务模型常见的就是<strong>账单类、日志类</strong>的系统。<br>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</p><p><strong>区别</strong></p><p>1、有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值。</p><p>2、如果对数据有修改操作，则普通索引可以用 Change Buffer，而唯一索引不行。</p><p>3、数据修改时，唯一索引在 RR 隔离级别下，更容易出现死锁。</p><p>4、查询数据时，普通索引查到满足条件的第一条记录还需要继续查找下一个记录，而唯一索引查找到第一个记录就可以直接返回结果了，但是普通索引多出的查找次数所消耗的资源多数情况可以忽略不计。</p><p><strong>选择</strong></p><p>1、如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引</p><p>2、如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引。</p><h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表。</p><p>使用：</p><ul><li>where 条件中，经常同时出现的列放在联合索引中。</li><li>把选择性最大的列放在联合索引的最左边。</li></ul><p>联合索引应用：</p><pre class="line-numbers language-mysql"><code class="language-mysql">/*使用完整联合索引*/select * from t11 where a=1 and b=1 and c=1;select * from t11 where c=1 and b=1 and a=1;select * from t11 where a=2 and b in (1,2) and c=2;select * from t11 where a=1 and b=2 order by c;select * from t11 where a=1 order by b,c;select a,b,c from t11 order by a,b,c;/*使用部分联合索引idx_a_b_c*/select * from t11 where a=1 and b=1;select * from t11 where a=1 and c=1;//索引aselect * from t11 where a=2 and b in (3,4) order by c; //索引ab/*覆盖索引,不需要回表查询聚集索引中的记录*/select b,c from t11 where a=3;select c from t11 where a=1 and b=1 ;select id from t11 where a=1 and b=1 and c=1;/*不能使用联合索引*/select * from t11 where b=1; //联合索引最左匹配select * from t11 order by b;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>当表中的数据列是字符型，且大多数长度都比较长时，就可以考虑使用列值的一部分前缀作为索引，这也就被称作是前缀索引。</p><p>根据“索引选择性”（Index Selectivity）确定前缀长度。</p><p><strong>其他方式</strong></p><p>第一种方式是使用倒序存储。把有选择性的字符提到前面来。不支持范围查询。</p><p>第二种方式是使用hash字段。不支持范围查询。</p><h3 id="最左前缀"><a href="#最左前缀" class="headerlink" title="最左前缀"></a>最左前缀</h3><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p><h3 id="主键"><a href="#主键" class="headerlink" title="主键"></a>主键</h3><p>如果设置主键是自增，那么每一次都是在聚集索引的最后增加，当一页写满，就会自动开辟一个新页，不会有聚集索引树分裂这一步，效率会比随机主键高很多。这也是很多建表规范要求主键自增的原因。</p><h3 id="优化器索引选择"><a href="#优化器索引选择" class="headerlink" title="优化器索引选择"></a>优化器索引选择</h3><p><code>show index from t</code>可以看到索引的Cardinality，即索引中不重复记录数量的预估值。</p><p>Cardinality 统计信息的更新时机：</p><ul><li>表中 1/16 的数据已经发生过变化</li><li>表中数据发生变化次数超过 2000000000</li></ul><p><strong>统计方法</strong></p><p>随机取出 B+ 树索引中的 8 个叶子节点，统计每个页中不同记录的个数，计算得到每页的平均数后，乘以叶子节点总数</p><p><strong>问题</strong></p><p>通过统计信息来预估扫描行数，Cardinality不精准可能导致选错了索引。</p><p><strong>应对</strong></p><pre class="line-numbers language-mysql"><code class="language-mysql">analyze table t13;//更新统计信息<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>问题</strong></p><p>如果单次选取的数据量过大，可能也会导致“选错”索引</p><pre class="line-numbers language-mysql"><code class="language-mysql">select a from t13 where a>70000 limit 1000;//走了主键索引<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>应对</strong></p><p>force index 来强制走索引</p><pre class="line-numbers language-mysql"><code class="language-mysql">select a from t13 force index(idx_a) where a>70000 limit 1000;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>其他应对</strong></p><p>1、考虑修改语句，引导MySQL使用我们期望的索引。比如，把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p><p>2、新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>count优化</title>
      <link href="/2021/03/13/count-you-hua/"/>
      <url>/2021/03/13/count-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="count说明"><a href="#count说明" class="headerlink" title="count说明"></a>count说明</h2><h3 id="count（a）-和-count（-）"><a href="#count（a）-和-count（-）" class="headerlink" title="count（a） 和 count（*）"></a>count（a） 和 count（*）</h3><p>当 count 统计某一列时，比如<code>count(a)</code>，a 表示列名，是不统计 null 的。</p><p>而 <code>count(*)</code>无论是否包含空值，都会统计。</p><h3 id="MyISAM-InnoDB-count（-）"><a href="#MyISAM-InnoDB-count（-）" class="headerlink" title="MyISAM/InnoDB count（*）"></a>MyISAM/InnoDB count（*）</h3><p> MyISAM：如果没有 where 子句，也没检索其它列，<code>count(*)</code>会非常快。 MyISAM 引擎会把表的总行数存在磁盘上。</p><p>InnoDB ：不会保留表中的行数，因为并发事务可能同时读取到不同的行数。执行<code>count(*)</code>时都是临时去计算的，会比 MyISAM 慢很多。</p><h3 id="MySQL-5-7-18-前后-count（-）-的区别"><a href="#MySQL-5-7-18-前后-count（-）-的区别" class="headerlink" title="MySQL 5.7.18 前后 count（*） 的区别"></a>MySQL 5.7.18 前后 count（*） 的区别</h3><p>MySQL 5.7.18 之前，InnoDB 通过扫描聚簇索引来处理<code>count(*)</code>语句。</p><p>MySQL 5.7.18 开始，通过遍历最小的可用二级索引来处理 <code>count(*)</code>语句。</p><p>优化器基于成本的考虑，优先选择的是二级索引。所以<code>count(主键)</code> 其实没<code>count (*)</code>快。</p><h3 id="count（1）-count（-）"><a href="#count（1）-count（-）" class="headerlink" title="count（1）   count（*）"></a>count（1）   count（*）</h3><p>执行计划相同，速度没有明显差别</p><h2 id="count-优化"><a href="#count-优化" class="headerlink" title="count 优化"></a>count 优化</h2><p>1、<code>show table status</code>,Rows 这列就表示这张表的行数。</p><pre class="line-numbers language-mysql"><code class="language-mysql">show table status like 't1';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>估算值，可能与实际值相差 40% 到 50%。</p><p>2、用 Redis 做计数器</p><p>redis 和数据库访问存在时间先后，可能会读到错误的值。</p><p>3、增加计数表</p><p>维持了计数的准确性</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>join优化</title>
      <link href="/2021/03/13/join-you-hua/"/>
      <url>/2021/03/13/join-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="关联查询"><a href="#关联查询" class="headerlink" title="关联查询"></a>关联查询</h2><h3 id="Nested-Loop-Join"><a href="#Nested-Loop-Join" class="headerlink" title="Nested-Loop Join"></a>Nested-Loop Join</h3><p><strong>思想</strong></p><p>一次一行循环：从驱动表中读取行并取到关联字段，根据关联字段在被驱动表取出满足条件的行（使用索引），然后取两张表的结果合集。<a href="https://dev.mysql.com/doc/refman/5.7/en/nested-loop-joins.html" target="_blank" rel="noopener">manual</a></p><blockquote><p>在关联字段有索引时，才会使用 NLJ，如果没索引，就会使用 Block Nested-Loop Join。</p><p>一般 join 语句中，没有出现Using join buffer就表示使用的join 算法是 NLJ</p></blockquote><h3 id="Block-Nested-Loop-Join"><a href="#Block-Nested-Loop-Join" class="headerlink" title="Block Nested-Loop Join"></a>Block Nested-Loop Join</h3><p><strong>思想</strong>：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端。<a href="https://dev.mysql.com/doc/refman/5.7/en/bnl-bkaoptimization.html" target="_blank" rel="noopener">manual</a></p><blockquote><p>join_buffer减少了磁盘扫描次数。</p></blockquote><p><strong>主要影响</strong></p><ol><li>可能会多次扫描被驱动表，占用磁盘IO资源；</li><li>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</li><li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</li></ol><h3 id="Batched-Key-Access"><a href="#Batched-Key-Access" class="headerlink" title="Batched Key Access"></a>Batched Key Access</h3><blockquote><p><strong>MRR</strong></p><p>尽量使用顺序读盘。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p><p>MRR能够提升性能的核心在于，查询语句在索引的是范围查询，可以得到足够多的主键id。排序后，再去主键索引查数据，才能体现出“顺序性”的优势。</p></blockquote><p><strong>思想</strong></p><p>结合NLJ和BNL，将驱动表中相关列放入 join_buffer 中，批量将关联字段的值发送到 Multi-Range Read（MRR） 接口，MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作，返回结果给客户端。</p><pre class="line-numbers language-mysql"><code class="language-mysql">set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';/*开启BKA*/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>Extra显示Using join buffer （Batched Key Access）</p></blockquote><h2 id="优化关联查询"><a href="#优化关联查询" class="headerlink" title="优化关联查询"></a>优化关联查询</h2><h3 id="关联字段添加索引"><a href="#关联字段添加索引" class="headerlink" title="关联字段添加索引"></a>关联字段添加索引</h3><p>被驱动表的关联字段上添加索引，让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。</p><h3 id="小表做驱动表"><a href="#小表做驱动表" class="headerlink" title="小表做驱动表"></a>小表做驱动表</h3><p>复杂度是低于大表做驱动表的。</p><h3 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h3><blockquote><p>某条关联查询只是临时查一次，再去添加索引会浪费资源。</p></blockquote><p>尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分页查询优化</title>
      <link href="/2021/03/13/fen-ye-cha-xun-you-hua/"/>
      <url>/2021/03/13/fen-ye-cha-xun-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="自增且连续主键的分页查询"><a href="#自增且连续主键的分页查询" class="headerlink" title="自增且连续主键的分页查询"></a>自增且连续主键的分页查询</h2><p>避免前n条记录的读取<a href="https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html" target="_blank" rel="noopener">mysql manual</a>，可以采用：</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 where id >99000 limit 2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要求主链连续且自增，否则很多时候不适用。</p><h2 id="非主键字段排序的分页查询"><a href="#非主键字段排序的分页查询" class="headerlink" title="非主键字段排序的分页查询"></a>非主键字段排序的分页查询</h2><p>可能不走索引</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 order by a limit 99000,2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化：关键是让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>order/group by优化</title>
      <link href="/2021/03/13/order-group-by-you-hua/"/>
      <url>/2021/03/13/order-group-by-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="order-by-原理"><a href="#order-by-原理" class="headerlink" title="order by 原理"></a>order by 原理</h2><p>按照排序原理分<a href="https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html" target="_blank" rel="noopener">manual</a>，MySQL 排序方式分两种：</p><ul><li>通过有序索引直接返回有序数据：Using index</li><li>通过 Filesort 进行的排序：Using filesort</li></ul><p>Filesort是内存排序还是磁盘排序取决于：</p><ul><li>“排序的数据大小” &lt; sort_buffer_size: 内存排序</li><li>“排序的数据大小” &gt; sort_buffer_size: 磁盘排序</li></ul><p>通过trace中的<code>number_of_tmp_files</code>，等于 0，则表示排序过程没使用临时文件，在内存中就能完成排序。</p><p><strong>Filesort 下的排序模式</strong></p><ul><li>&lt; sort_key, rowid &gt;双路排序（回表排序模式）：取出排序字段和行 ID，在 sort buffer 中排序，排序完后再次取回其它需要的字段；</li><li>&lt; sort_key, additional_fields &gt;单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；</li><li>&lt; sort_key, packed_additional_fields &gt;打包数据排序模式：与单路排序相似，区别是将 char 和 varchar 字段存到sort buffer 中时，更加紧缩。</li></ul><p><strong>单路和双路的选择</strong></p><ul><li>max_length_for_sort_data 比查询字段的总长度大，使用单路排序模式；</li><li>max_length_for_sort_data 比查询字段的总长度小，使用回表排序模式。</li></ul><p>如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。</p><h2 id="order-by-优化"><a href="#order-by-优化" class="headerlink" title="order by 优化"></a>order by 优化</h2><h3 id="添加合适索引"><a href="#添加合适索引" class="headerlink" title="添加合适索引"></a>添加合适索引</h3><p>1、 排序字段添加索引</p><p>2、多个字段排序添加联合索引</p><p>3、先等值查询再排序，在条件字段和排序字段添加联合索引</p><h3 id="去掉不必要的返回字段"><a href="#去掉不必要的返回字段" class="headerlink" title="去掉不必要的返回字段"></a>去掉不必要的返回字段</h3><p>过多返回字段可能需要扫描索引再回表，成本全表扫描更高。</p><pre class="line-numbers language-mysql"><code class="language-mysql">select id,a,b from t1 order by a,b; /* 根据a和b字段排序查出id,a,b字段的值 */<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="修改参数"><a href="#修改参数" class="headerlink" title="修改参数"></a>修改参数</h3><p>max_length_for_sort_data：可以适当加大 max_length_for_sort_data 的值</p><p>sort_buffer_size：适当加大 sort_buffer_size 的值，尽可能让排序在内存中完成。</p><h3 id="无法使用索引"><a href="#无法使用索引" class="headerlink" title="无法使用索引"></a>无法使用索引</h3><p>1、 使用范围查询再排序：</p><pre class="line-numbers language-mysql"><code class="language-mysql">select id,a,b from t1 where a>9000 order by b;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2、ASC 和 DESC 混合使用</p><pre class="line-numbers language-mysql"><code class="language-mysql">select id,a,b from t1 order by a asc,b desc;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="group-by优化"><a href="#group-by优化" class="headerlink" title="group by优化"></a>group by优化</h2><p>默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致。</p><p>如果目的只是分组而不用排序，可以指定<code>order by null</code>禁止排序。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>批量数据导入优化</title>
      <link href="/2021/03/13/pi-liang-shu-ju-dao-ru-you-hua/"/>
      <url>/2021/03/13/pi-liang-shu-ju-dao-ru-you-hua/</url>
      
        <content type="html"><![CDATA[<p>插入行所需的时间由以下因素决定<a href="https://dev.mysql.com/doc/refman/5.7/en/insert-optimization.html" target="_blank" rel="noopener">mysql manual</a></p><ul><li>连接：30%</li><li>向服务器发送查询：20%</li><li>解析查询：20%</li><li>插入行：10% * 行的大小</li><li>插入索引：10% * 索引数</li><li>结束：10%</li></ul><h2 id="一次插入多行的值"><a href="#一次插入多行的值" class="headerlink" title="一次插入多行的值"></a>一次插入多行的值</h2><p>有大批量导入时，推荐一条insert语句插入多行数据。</p><p>原因：减少服务器通信时间</p><h2 id="关闭自动提交"><a href="#关闭自动提交" class="headerlink" title="关闭自动提交"></a>关闭自动提交</h2><p>Autocommit 开启时会为每个插入执行提交。可以在InnoDB导入数据时，关闭自动提交。</p><p>原因：合并提交可以减少客户端与服务端通信的时间，减少数据落盘的次数。</p><h2 id="参数调整"><a href="#参数调整" class="headerlink" title="参数调整"></a>参数调整</h2><p>innodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略</p><ul><li>0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘；</li><li>1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘；</li><li>2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘。</li></ul><p>sync_binlog：控制binlog的刷盘时机</p><ul><li>0：二进制日志从不同步到磁盘，依赖OS刷盘机制；</li><li>1：二进制日志每次提交都会刷盘；</li><li>n : 每n次提交落盘一次。</li></ul><p>innodb_flush_log_at_trx_commit设置为0、同时sync_binlog设置为0时，写入数据的速度是最快的。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引失效</title>
      <link href="/2021/03/13/suo-yin-shi-xiao/"/>
      <url>/2021/03/13/suo-yin-shi-xiao/</url>
      
        <content type="html"><![CDATA[<h2 id="函数操作"><a href="#函数操作" class="headerlink" title="函数操作"></a>函数操作</h2><p>对条件字段做函数操作，可能破坏了索引值的有序性，走不了索引。</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 where date(c) ='2019-05-21';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化：改成范围查询</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 where c>='2019-05-21 00:00:00' and c<='2019-05-21 23:59:59';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="隐式转换"><a href="#隐式转换" class="headerlink" title="隐式转换"></a>隐式转换</h2><p>操作符与不同类型的操作对象一起使用时，就会发生类型转换以使操作兼容。</p><pre class="line-numbers language-mysql"><code class="language-mysql">select user_name,tele_phone from user_info where tele_phone =11111111111; /* tele_phone varchar */<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>实际会做函数操作：</p><pre class="line-numbers language-mysql"><code class="language-mysql">select user_name,tele_phone from user_info where cast(tele_phone as singed int) =11111111111; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化：类型统一</p><pre class="line-numbers language-mysql"><code class="language-mysql">select user_name,tele_phone from user_info where tele_phone ='11111111111';//字符串转数字<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="模糊查询"><a href="#模糊查询" class="headerlink" title="模糊查询"></a>模糊查询</h2><p>通配符在前面</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 where a like '%1111%';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化:模糊查询必须包含条件字段前面的值</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 where a like '1111%';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="范围查询"><a href="#范围查询" class="headerlink" title="范围查询"></a>范围查询</h2><p>范围查询数据量太多，需要回表，因此不走索引。</p><pre class="line-numbers language-mysql"><code class="language-mysql">select * from t1 where b>=1 and b <=2000;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化：降低单次查询范围，分多次查询。（实际可能速度没得快太多,建议走索引）</p><pre><code>select * from t1 where b&gt;=1 and b &lt;=1000; show profiles;+----------+------------+------------------------------------------+| Query_ID | Duration   | Query                                    |+----------+------------+------------------------------------------+|        1 | 0.00534775 | select * from t1 where b&gt;=1 and b &lt;=1000 ||        2 | 0.00605625 | select * from t1 where b&gt;=1 and b &lt;=2000 |+----------+------------+------------------------------------------+2 rows in set, 1 warning (0.00 sec)</code></pre><h2 id="计算操作"><a href="#计算操作" class="headerlink" title="计算操作"></a>计算操作</h2><p>即使是简单的计算</p><pre class="line-numbers language-mysql"><code class="language-mysql">explain select * from t1 where b-1 =1000;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化：将计算操作放在等号后面</p><pre class="line-numbers language-mysql"><code class="language-mysql">explain select * from t1 where b =1000 + 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>慢查询定位与分析</title>
      <link href="/2021/03/11/man-cha-xun-ding-wei-yu-fen-xi/"/>
      <url>/2021/03/11/man-cha-xun-ding-wei-yu-fen-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="定位慢sql"><a href="#定位慢sql" class="headerlink" title="定位慢sql"></a>定位慢sql</h2><h3 id="1、查看慢查询日志确定已经执行完的慢查询"><a href="#1、查看慢查询日志确定已经执行完的慢查询" class="headerlink" title="1、查看慢查询日志确定已经执行完的慢查询"></a>1、查看慢查询日志确定已经执行完的慢查询</h3><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> set global slow_query_log = on;mysql> set global long_query_time = 1;mysql> show global variables like "datadir";mysql> show global variables like "slow_query_log_file";[root@mysqltest ~]# tail -n5 /data/mysql/data/3306/mysql-slow.logTime: 2019-05-21T09:15:06.255554+08:00User@Host: root[root] @ localhost [] Id: 8591152Query_time: 10.000260 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0SET timestamp=1558401306;select sleep(10);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到查询时间、表锁时间、扫描行数Rows_examined。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p><h3 id="2、show-processlist-查看正在执行的慢查询"><a href="#2、show-processlist-查看正在执行的慢查询" class="headerlink" title="2、show processlist 查看正在执行的慢查询"></a>2、show processlist 查看正在执行的慢查询</h3><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> show processlist\G``*************************** 10. row ***************************``Id: 7651833``User: one``Host: 192.168.1.251:52154``db: ops``Command: Query``Time: 3``State: User sleep``Info: select sleep(10)``......``10 rows in set (0.00 sec)`<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到执行时间和SQL语句</p><h2 id="分析慢查询"><a href="#分析慢查询" class="headerlink" title="分析慢查询"></a>分析慢查询</h2><h3 id="1、使用-explain-分析慢查询"><a href="#1、使用-explain-分析慢查询" class="headerlink" title="1、使用 explain 分析慢查询"></a>1、使用 explain 分析慢查询</h3><p>获取 MySQL 中 SQL 语句的执行计划.需要重点关注以下：</p><ul><li><p>select_type ：查询类型，是简单还是复杂查询</p></li><li><p>type ：查询的表连接类型</p></li><li><p>key ：实际选择的索引</p></li><li><p>rows： 预计需要扫描的行数，对 InnoDB 来说，这个值是估值</p></li><li><p>Extra ：附加信息</p></li></ul><table><thead><tr><th align="left">select_type</th><th>含义</th></tr></thead><tbody><tr><td align="left">SIMPLE</td><td>简单查询，不使用关联查询或子查询</td></tr><tr><td align="left">PRIMARY</td><td>如果包含关联查询或者子查询，则最外层的查询部分标记为primary</td></tr><tr><td align="left">UNION</td><td>联合查询中第二个及后面的查询</td></tr><tr><td align="left">DEPENDENT UNION</td><td>满足依赖外部的关联查询中第二个及以后的查询</td></tr><tr><td align="left">UNION RESULT</td><td>联合查询的结果</td></tr><tr><td align="left">SUBQUERY</td><td>子查询中的第一个查询</td></tr><tr><td align="left">DEPENDENT SUBQUERY</td><td>子查询中的第一个查询，并且依赖外部查询</td></tr><tr><td align="left">DERIVED</td><td>用到派生表的查询</td></tr><tr><td align="left">MATERIALIZED</td><td>被物化的子查询</td></tr><tr><td align="left">UNCACHEABLE SUBQUERY</td><td>一个子查询的结果不能被缓存，必须重新评估外层查询的每一行</td></tr><tr><td align="left">UNCACHEABLE UNION</td><td>关联查询第二个或后面的语句属于不可缓存的子查询</td></tr></tbody></table><table><thead><tr><th align="left">type</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">system</td><td align="left">查询对象表只有一行数据</td></tr><tr><td align="left">const</td><td align="left">基于主键或唯一索引查询，最多返回一条结果</td></tr><tr><td align="left">eq_ref</td><td align="left">最多只返回一条符合条件的记录。</td></tr><tr><td align="left">ref</td><td align="left">基于普通索引的等值查询，或者表间等值连接</td></tr><tr><td align="left">fulltext</td><td align="left">全文检索</td></tr><tr><td align="left">ref_or_null</td><td align="left">表连接类型是</td></tr><tr><td align="left">index_merge</td><td align="left">利用多个索引</td></tr><tr><td align="left">unique_subquery</td><td align="left">子查询中使用唯一索引</td></tr><tr><td align="left">index_subquery</td><td align="left">子查询中使用普通索引</td></tr><tr><td align="left">range</td><td align="left">利用索引进行范围查询</td></tr><tr><td align="left">index</td><td align="left">全索引扫描</td></tr><tr><td align="left">ALL</td><td align="left">全表扫描</td></tr></tbody></table><table><thead><tr><th align="left">Extra</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">Using filesort</td><td align="left">将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序</td></tr><tr><td align="left">Using temporary</td><td align="left">需要创建一个临时表来存储结构，通常发生对没有索引的列进行 GROUP BY 时</td></tr><tr><td align="left">Using index</td><td align="left">使用覆盖索引</td></tr><tr><td align="left">Using where</td><td align="left">使用 where 语句来处理结果</td></tr><tr><td align="left">Impossible WHERE</td><td align="left">对 where 子句判断的结果总是 false 而不能选择任何数据</td></tr><tr><td align="left">Using join buffer（BlockNested Loop）</td><td align="left">关联查询中，被驱动表的关联字段没索引</td></tr><tr><td align="left">Using index condition</td><td align="left">先条件过滤索引，再查数据</td></tr><tr><td align="left">Select tables optimized away</td><td align="left">使用某些聚合函数（比如 max、min）来访问存在索引的某个字段</td></tr></tbody></table><h3 id="2、show-profile"><a href="#2、show-profile" class="headerlink" title="2、show profile"></a>2、show profile</h3><p>了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节</p><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> select @@have_profiling;mysql> select @@profiling;mysql> set profiling=1;mysql> select * from t1 where b=1000;mysql> show profiles;  /*获取query id*/mysql> show profile for query 1;+----------------------+----------+| Status | Duration |+----------------------+----------+| starting | 0.000115 || checking permissions | 0.000013 || Opening tables | 0.000027 || init | 0.000035 || System lock | 0.000017 || optimizing | 0.000016 || statistics | 0.000025 || preparing | 0.000020 || executing | 0.000006 || Sending data | 0.000294 || end | 0.000009 || query end | 0.000012 || closing tables | 0.000011 || freeing items | 0.000024 || cleaning up | 0.000016 |+----------------------+----------+15 rows in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3、trace"><a href="#3、trace" class="headerlink" title="3、trace"></a>3、trace</h3><p>使用 trace 查看优化器如何选择执行计划</p><pre class="line-numbers language-mysql"><code class="language-mysql">mysql> set session optimizer_trace="enabled=on",end_markers_in_json=on;/* optimizer_trace="enabled=on" 表示开启 trace；end_markers_in_json=on 表示 JSON 输出开启结束标记 */mysql> select * from t1 where a >900 and b > 910 order by a;mysql> SELECT * FROM information_schema.OPTIMIZER_TRACE\G;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>TRACE包括准备阶段、优化阶段、执行阶段。trace中可以看到使用每个索引的成本。</p><p>也可以看number_of_tmp_files中判断是否使用了临时文件。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis应用</title>
      <link href="/2021/03/10/redis-ying-yong/"/>
      <url>/2021/03/10/redis-ying-yong/</url>
      
        <content type="html"><![CDATA[<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>实现：<code>set lock:codehole true ex 5 nx</code></p><p>注意：不要用于较长任务，可能超时释放</p><p>优化：设置value是一个随机值，保证不会被其他线程释放</p><p>可重入锁：基于线程的Threadlocal变量存储当前持有锁的计数。如果当前有该锁的记录，则计数加一，返回加锁成功。否则尝试加锁，若不存在锁则成功，其他线程/进程会加锁失败。</p><h2 id="延时队列"><a href="#延时队列" class="headerlink" title="延时队列"></a>延时队列</h2><p>实现：使用zset ，消息序列化成value，到期时间作为score。为保障可用性，可以使用多个线程/进程轮询到期任务进行处理（zrangebyscore）。通过zrem结果，判断任务被哪个线程/进程获取，再进一步处理。</p><p>优化：考虑将zrangebyscore 和zrem，封装lua scripting,避免获取任务的浪费操作。</p><h2 id="用户一年的签到统计"><a href="#用户一年的签到统计" class="headerlink" title="用户一年的签到统计"></a>用户一年的签到统计</h2><p>使用位图，1天的签到记录只需要占据一个位，一年365位。</p><h2 id="页面访问量"><a href="#页面访问量" class="headerlink" title="页面访问量"></a>页面访问量</h2><p>简单方案：使用set集合存储当天访问某一个用户ID， scard可以统计集合大小。</p><p>优化：用户很多时，使用HyperLogLog，提供了不精确的去重方案，节省空间。pfadd/pfcount</p><h2 id="数据去重"><a href="#数据去重" class="headerlink" title="数据去重"></a>数据去重</h2><p>场景：用户为看过的内容推荐去重；爬虫URL去重；</p><p>实现：简单去重，使用set。大数据去重，使用布隆过滤器（redis&gt;4.0）bf.add/bf.exists。</p><p>误差：布隆过滤器返回存在，实际可能不存在；返回不存在，实际一定不存在。</p><p>原理：大型位数组和几个不一样的无偏hash函数。</p><h2 id="简单限流"><a href="#简单限流" class="headerlink" title="简单限流"></a>简单限流</h2><p>场景：限制用户行为在一定时间内的次数</p><p>实现：每个用户每种行为作为key，使用zset,value和score都使用时间戳。在pipeline中，增加用户行为，移除时间窗口之前数据，<strong>获取当前剩下行为总数</strong>，并给该key增加过期时间，避免长期占用内存。通过剩下行为总数，判断是否超额。</p><p>缺点：不适合1min操作不超过100万次这种场景。</p><h2 id="漏斗限流"><a href="#漏斗限流" class="headerlink" title="漏斗限流"></a>漏斗限流</h2><p>实现：使用redis-cell（redis 4.0），其使用漏斗算法，提供了限流指令。cl.throttle。</p><p>非常棒，被拒绝还提供了重试时间。</p><h2 id="附近的人"><a href="#附近的人" class="headerlink" title="附近的人"></a>附近的人</h2><p>实现：使用GeoHash.</p><p>原理：将二维经纬度数据映射到一维整数，距离近的点映射距离也会比较近。类似逐步切分蛋糕。</p><p>注意：Geo数据将被放到一个zset中。集群环境中集合迁移，可能会影响线上服务运行，建议GEO数据使用单独的redis示例部署。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis思维导图</title>
      <link href="/2021/03/08/redis-si-wei-dao-tu/"/>
      <url>/2021/03/08/redis-si-wei-dao-tu/</url>
      
        <content type="html"><![CDATA[<p><img src="redis.png" alt="思维导图"></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka集群配置</title>
      <link href="/2020/12/10/kafka-ji-qun-pei-zhi/"/>
      <url>/2020/12/10/kafka-ji-qun-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="Broker-端参数"><a href="#Broker-端参数" class="headerlink" title="Broker 端参数"></a>Broker 端参数</h2><ul><li><p>log.dirs：Broker 需要使用的若干个文件目录路径，必须指定；最好不同路径挂载到不同的物理磁盘，提升读写性能且能能够实现故障转移</p></li><li><p>log.dir：单个路径</p></li><li><p>zookeeper.connect：zookeeper端口</p></li><li><p>listeners：访问kafka的监听器</p></li><li><p>advertised.listeners：Broker 用于对外发布的监听器</p></li><li><p>auto.create.topics.enable：是否允许自动创建 Topic，建议最好设置成 false</p></li><li><p>unclean.leader.election.enable：是否允许 Unclean Leader 选举，是否能让那些落后太多的副本竞选 Leader,建议false</p></li><li><p>auto.leader.rebalance.enable：是否允许定期进行 Leader 选举，成本太高，建议false</p></li><li><p>log.retention.{hours|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低</p></li><li><p>log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。默认-1</p></li><li><p>message.max.bytes：控制 Broker 能够接收的最大消息大小。</p></li></ul><h2 id="Topic-级别参数"><a href="#Topic-级别参数" class="headerlink" title="Topic 级别参数"></a>Topic 级别参数</h2><ul><li><p>retention.ms： Topic 消息被保存的时长。默认是 7 天。会覆盖掉 Broker 端的全局参数值。</p></li><li><p>retention.bytes： Topic 预留多大的磁盘空间。通常在多租户的 Kafka 集群中会有用武之地。默认值是 -1，表示可以无限使用磁盘空间。</p></li><li><p>max.message.bytes：Broker 能够正常接收该 Topic 的最大消息大小</p></li></ul><p>创建topic时设置:</p><pre><code>bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880</code></pre><p>修改topic(推荐)：</p><pre><code>bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760</code></pre><h2 id="JVM参数"><a href="#JVM参数" class="headerlink" title="JVM参数"></a>JVM参数</h2><p> JVM 堆大小设置成 6GB ，用默认的 G1 收集器</p><ul><li>KAFKA_HEAP_OPTS：指定堆大小。</li><li>KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。</li></ul><p>启动broker前设置：</p><pre><code>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true$&gt; bin/kafka-server-start.sh config/server.properties</code></pre><h2 id="操作系统参数"><a href="#操作系统参数" class="headerlink" title="操作系统参数"></a>操作系统参数</h2><p>文件描述符限制：<code>ulimit -n 1000000</code>，通常将它设置成一个超大的值</p><p>文件系统类型：最好选择xfs</p><p>Swap：设置成一个比较小的值，当开始使用 swap 空间时，能够观测到 Broker 性能开始出现急剧下降，避免直接OOM，从而给你进一步调优和诊断问题的时间。</p><p>提交时间（Flush 落盘时间）：适当地增加提交间隔来降低物理磁盘的写操作</p><h2 id="动态-Broker-参数配置"><a href="#动态-Broker-参数配置" class="headerlink" title="动态 Broker 参数配置"></a>动态 Broker 参数配置</h2><p><strong>配置的类别</strong></p><p>read-only。只有重启 Broker，才能修改生效。</p><p>per-broker。修改后，只会在对应的 Broker 上生效。</p><p>cluster-wide。修改后，会在整个集群范围内生效。</p><p><strong>使用场景</strong></p><ul><li>动态调整 Broker 端各种线程池大小，实时应对突发流量。</li><li>动态调整 Broker 端连接信息或安全配置信息。</li><li>动态更新 SSL Keystore 有效期。</li><li>动态调整 Broker 端 Compact 操作性能。</li><li>实时变更 JMX 指标收集器 。</li></ul><p><strong>实现</strong></p><p>Kafka 将动态 Broker 参数保存在 ZooKeeper 中，具体的 znode 路径如下图所示。</p><p><img src="atoconfig.png" alt></p><p>changes 是用来实时监测动态参数变更的；</p><p>topics 是用来保存 Kafka 主题级别参数的。不属于动态 Broker 端参数，但支持动态变更的。</p><p>users 和 clients 则是用于动态调整客户端配额的 znode 节点。连入集群的客户端的吞吐量或者是限定它们使用的 CPU 资源。</p><p>/config/brokers znode 才是保存动态 Broker 参数。第一类子节点&lt; default &gt;，保存 cluster-wide 动态参数；另一类则以 broker.id 为名，保存 Broker 的 per-broker 范围参数。</p><p><strong>设置</strong></p><pre class="line-numbers language-shell"><code class="language-shell"># 设置 cluster-wide 范围值,entity-default$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true# 查看设置$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --describe# 设置ID 为 1 的 Broker$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --add-config unclean.leader.election.enable=false# 查看设置$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --describe# 删除cluster-wide范围参数，删除动态参数要指定 delete-config$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable# 删除per-broker范围参数，删除动态参数要指定 delete-config$ bin/kafka-configs.sh --bootstrap-server kafka-host:port --entity-type brokers --entity-name 1 --alter --delete-config unclean.leader.election.enable<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>常用动态参数</strong></p><ul><li>log.retention.ms：日志留存时间</li><li>num.io.threads 和 num.network.threads:Broker 端请求处理能力经常要按需扩容。</li><li>num.replica.fetchers：执行 Follower 副本向 Leader 副本的拉取。</li></ul>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis6.0</title>
      <link href="/2020/12/09/redis6-0/"/>
      <url>/2020/12/09/redis6-0/</url>
      
        <content type="html"><![CDATA[<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a><strong>问题</strong></h3><p>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a><strong>优化</strong></h3><p>多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。</p><p>使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p><h3 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a><strong>具体流程</strong></h3><p>1、服务端和客户端建立 Socket 连接，并分配给IO线程</p><p>2、IO 线程读取并解析请求</p><p>3、主线程执行请求操作</p><p>4、IO 线程回写 Socket 和主线程清空全局队列</p><p>相关配置：</p><pre><code>io-threads-do-reads yes #启用多线程io-threads  6           #线程个数要小于 Redis 实例所在机器的 CPU 核个数</code></pre><h2 id="服务端协助的客户端缓存（Tracking）"><a href="#服务端协助的客户端缓存（Tracking）" class="headerlink" title="服务端协助的客户端缓存（Tracking）"></a>服务端协助的客户端缓存（Tracking）</h2><h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a><strong>问题</strong></h3><p>如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理。</p><h3 id="普通模式"><a href="#普通模式" class="headerlink" title="普通模式"></a>普通模式</h3><p>实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。</p><p>一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。</p><blockquote><p>服务端对于记录的 key 只会报告一次 invalidate 消息</p><p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息</p></blockquote><p><strong>设置命令</strong></p><pre><code>CLIENT TRACKING ON|OFF</code></pre><h3 id="广播模式"><a href="#广播模式" class="headerlink" title="广播模式"></a>广播模式</h3><p>服务端会给客户端广播所有 key 的失效情况</p><p>如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p><p><strong>应用场景</strong></p><p>客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。</p><p><strong>区别</strong></p><p>广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。</p><h2 id="细粒度的权限控制"><a href="#细粒度的权限控制" class="headerlink" title="细粒度的权限控制"></a>细粒度的权限控制</h2><p>1、支持创建不同用户</p><pre><code>ACL SETUSER normaluser on &gt; abc #创建并启用一个用户 normaluser，把它的密码设置为“abc” </code></pre><p>2、支持以用户为粒度设置命令操作的访问权限</p><p><img src="acl_cmd.jpg" alt="acl_cmd"></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis消息队列</title>
      <link href="/2020/11/02/redis-xiao-xi-dui-lie/"/>
      <url>/2020/11/02/redis-xiao-xi-dui-lie/</url>
      
        <content type="html"><![CDATA[<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><ul><li><p>消息保序：消费者需要按照生产者发送消息的顺序来处理消息</p></li><li><p>处理重复的消息：消费者避免多次处理重复的消息</p></li><li><p>保证消息可靠性：消费者重启后，可以重新读取消息再次进行处理</p></li></ul><h2 id="基于List"><a href="#基于List" class="headerlink" title="基于List"></a>基于List</h2><ul><li>LPUSH </li></ul><p>把要发送的消息依次写入 List</p><ul><li>BRPOP </li></ul><p>阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列。</p><ul><li>消费者程序本身能对重复消息进行判断</li></ul><p>消息队列要能给每一个消息提供全局唯一的 ID 号，消费者程序要把已经处理过的消息的 ID 号记录下来。ID号需要生产者程序在发送消息前自行生成，并在LPUSH的时候插入List。</p><ul><li>BRPOPLPUSH</li></ul><p>让消费者程序从一个 List 中读取消息，同时，把这个消息再插入到另一个 List（可以叫作备份 List）留存</p><p>缺点：不支持消费组</p><h2 id="基于-Streams（Redis-5-0）"><a href="#基于-Streams（Redis-5-0）" class="headerlink" title="基于 Streams（Redis 5.0）"></a>基于 Streams（Redis 5.0）</h2><p><img src="stream.jpg" alt></p><p>Redis Stream有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。</p><p>每个 Stream 都可以挂多个消费组，每个消费组会有个游标last_delivered_id在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。</p><p>同一个消费组可以挂接多个消费者，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者有一个组内唯一名称。</p><p>消费者内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为PEL。</p><ul><li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li><li>XREAD：用于读取消息，可以按 ID 读取数据；</li><li>XREADGROUP：按消费组形式读取消息</li><li>XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</li></ul><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>在用Redis当作队列或存储数据时，是有可能丢失数据的：AOF同步写盘会降低性能。主从集群切换也可能丢数据。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis事务</title>
      <link href="/2020/11/01/redis-shi-wu/"/>
      <url>/2020/11/01/redis-shi-wu/</url>
      
        <content type="html"><![CDATA[<h2 id="事务实现"><a href="#事务实现" class="headerlink" title="事务实现"></a>事务实现</h2><h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><ul><li>MULTI</li></ul><p>显式地表示一个事务的开启，把这些命令暂存到一个命令队列中</p><ul><li>EXEC </li></ul><p>实际执行命令队列中的所有命令</p><ul><li>DISCARD</li></ul><p>主动放弃事务执行，把暂存的命令队列清空（起不到回滚的效果）</p><ul><li>WATCH</li></ul><p>在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行。</p><h3 id="异常分析"><a href="#异常分析" class="headerlink" title="异常分析"></a>异常分析</h3><p>1、客户端发送的操作命令中存在语法错误</p><p>拒绝执行所有提交的命令操作，返回事务失败</p><p>2、命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误</p><p>Redis 对错误命令报错，但正确的命令也会执行。（事务的原子性就无法得到保证）</p><p>3、在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败</p><ul><li>如 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。</li></ul><p>使用 redis-check-aof 工具检查 AOF 日志文件，可把已完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。</p><ul><li>如 AOF 日志没有开启，那么实例重启后，数据没法恢复了，此时，也就谈不上原子性了。</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis分布式锁</title>
      <link href="/2020/10/29/redis-fen-bu-shi-suo/"/>
      <url>/2020/10/29/redis-fen-bu-shi-suo/</url>
      
        <content type="html"><![CDATA[<p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p><h2 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h2><ul><li>单命令操作（INCR/DECR）；</li><li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本</li></ul><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><ul><li><p>分布式锁的加锁和释放锁的过程，涉及多个操作。需要保证这些锁操作的原子性；</p></li><li><p>共享存储系统保存了锁变量，需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。</p></li></ul><h3 id="单个-Redis-节点的分布式锁"><a href="#单个-Redis-节点的分布式锁" class="headerlink" title="单个 Redis 节点的分布式锁"></a>单个 Redis 节点的分布式锁</h3><p><strong>加锁</strong></p><ul><li><p><code>SET key value [EX seconds | PX milliseconds]  [NX]</code></p></li><li><p>key 不存在， key 会被创建。</p></li><li><p>Value 要具有唯一性。这个是为了在解锁的时候，需要验证 Value 是和加锁的一致才删除 Key。</p></li><li><p>过期时间是为了避免操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p></li></ul><p><strong>解锁</strong></p><p>执行完业务逻辑后，使用 DEL 命令删除锁变量，从而释放锁（释放锁涉及到两条指令，这两条指令不是原子性的，通过执行一段lua脚本）。</p><p><strong>问题</strong></p><ul><li>锁过期的问题</li><li>获取不到锁直接不断尝试获取锁，比较消耗性能</li></ul><h3 id="多个-Redis-节点的高可靠分布式锁"><a href="#多个-Redis-节点的高可靠分布式锁" class="headerlink" title="多个 Redis 节点的高可靠分布式锁"></a>多个 Redis 节点的高可靠分布式锁</h3><p>分布式锁算法 Redlock</p><ul><li><p>客户端获取当前时间。</p></li><li><p>客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p></li><li><p>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时</p></li><li><p>客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁并且客户端获取锁的总耗时没有超过锁的有效时间，加锁成功</p></li><li><p>别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</p></li></ul><p><strong>缺点</strong></p><p>无法保证加锁的过程一定正确</p><h2 id="开源框架：Redission"><a href="#开源框架：Redission" class="headerlink" title="开源框架：Redission"></a>开源框架：Redission</h2><p>企业级的开源 Redis Client，也提供了分布式锁的支持。</p><ul><li>所有指令都通过 Lua 脚本执行，Redis 支持 Lua 脚本原子性执行。</li><li>设置一个 Key 的默认过期时间为 30s， Watchdog 会在你获取锁之后，每隔 10s 帮你把 Key 的超时时间设为 30s。</li></ul><p><strong>优点</strong></p><p>一直持有锁也不会出现 Key 过期了，其他线程获取到锁的问题；</p><h2 id="Zookeeper-实现"><a href="#Zookeeper-实现" class="headerlink" title="Zookeeper 实现"></a>Zookeeper 实现</h2><ul><li>使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。</li><li>创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。</li><li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。</li><li>如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。</li></ul><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><h3 id="Redis-的分布式锁"><a href="#Redis-的分布式锁" class="headerlink" title="Redis 的分布式锁"></a>Redis 的分布式锁</h3><p><strong>缺点</strong></p><ul><li>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</li><li>即便使用 Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100% 没有问题。</li><li>Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。比如，锁过期问题。</li></ul><p><strong>优点</strong></p><p> Redis 的性能很高，可以支撑高并发的获取、释放锁操作。</p><h3 id="ZK-分布式锁"><a href="#ZK-分布式锁" class="headerlink" title="ZK 分布式锁"></a>ZK 分布式锁</h3><p><strong>优点</strong></p><ul><li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</li><li>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</li></ul><p><strong>缺点</strong></p><p>如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/73807097" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73807097</a></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis缓存</title>
      <link href="/2020/10/27/redis-huan-cun/"/>
      <url>/2020/10/27/redis-huan-cun/</url>
      
        <content type="html"><![CDATA[<h2 id="redis缓存使用"><a href="#redis缓存使用" class="headerlink" title="redis缓存使用"></a>redis缓存使用</h2><ul><li><p>应用读取数据时，需要先读取 Redis；</p></li><li><p>发生缓存缺失时，需要从数据库读取数据并更新缓存。</p></li></ul><p>Redis为旁路缓存，因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p><h2 id="缓存分类"><a href="#缓存分类" class="headerlink" title="缓存分类"></a>缓存分类</h2><ul><li><p>只读缓存：加速读请求。</p></li><li><p>读写缓存：加速读写请求。读写缓存又有两种数据写回策略，可根据业务需求，在保证性能和保证数据可靠性之间进行选择。</p></li></ul><h3 id="只读缓存"><a href="#只读缓存" class="headerlink" title="只读缓存"></a>只读缓存</h3><ul><li>读取数据先调用 Redis GET 接口；若不存在，应用从数据库中读取，并写到缓存中。</li><li>写请求，直接发往后端的数据库；删改数据时，应用需要把这些缓存的数据删除。</li></ul><p><strong>优点</strong></p><p>数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。</p><p><strong>缺点</strong></p><p>每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p><h3 id="读写缓存"><a href="#读写缓存" class="headerlink" title="读写缓存"></a>读写缓存</h3><p>读写请求都会发送到缓存，在缓存中直接操作数据。最新数据在redis，考虑掉电风险。</p><h4 id="同步直写"><a href="#同步直写" class="headerlink" title="同步直写"></a>同步直写</h4><ul><li>写请求发给缓存的同时，也会发给后端数据库，等到缓存和数据库都写完数据，才给客户端返回</li><li>需要在业务应用中使用事务实现</li></ul><p><strong>缺点</strong>：降低缓存的访问性能</p><p><strong>优点</strong>：被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存</p><h4 id="异步直写"><a href="#异步直写" class="headerlink" title="异步直写"></a>异步直写</h4><ul><li>所有写请求都先在缓存中处理。</li></ul><blockquote><p>Redis 本身不提供机制将淘汰数据写回数据库</p></blockquote><p><strong>Read/Write Throught策略</strong></p><p>应用层读写只需要操作缓存，缓存层会自动从数据库中加载或写回到数据库中</p><p><strong>优点</strong></p><p>对于应用层的使用非常友好，只需要操作缓存即可</p><p><strong>缺点</strong></p><p>需要缓存层支持和后端数据库的联动。</p><p><strong>Write Back策略</strong></p><p>写操作只写缓存。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库。</p><p><strong>优点</strong></p><p>写操作飞快（只写缓存）</p><p><strong>缺点</strong></p><p>如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。</p><h2 id="缓存淘汰"><a href="#缓存淘汰" class="headerlink" title="缓存淘汰"></a>缓存淘汰</h2><p>“八二原理”：80% 的请求实际只访问了 20% 的数据。</p><p><strong>缓存大小设置</strong>：结合应用数据实际访问特征和成本开销综合考虑，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。</p><ul><li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis  4.0 后新增）。</li><li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）。</li></ul><p><strong>淘汰策略</strong></p><ul><li>volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。</li><li>volatile-ttl key 的剩余寿命 ttl 的值越小越优先被淘汰。</li><li>volatile-random 设置了过期时间的 key集合中随机的 key。</li><li>allkeys-lru全体的 key 集合中最近最少使用的。</li><li>allkeys-random 全体的 key 集合中随机的 key</li></ul><p><strong>LRU</strong></p><p>Redis 中，LRU 算法被做了简化。</p><ul><li>Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为候选集合。</li><li>Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</li><li>再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值</li></ul><p><strong>LFU</strong></p><p>从两个维度来筛选并淘汰数据：</p><ul><li><p>数据的被访问次数</p></li><li><p>数据访问的时效性，访问时间离当前时间的远近</p></li></ul><p><strong>计数规则</strong>：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</p><p><strong>counter 值的衰减机制</strong></p><p>LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</p><h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><h3 id="原因1：更新操作失败"><a href="#原因1：更新操作失败" class="headerlink" title="原因1：更新操作失败"></a>原因1：更新操作失败</h3><p>只读缓存：无法保证删改数据库和删除缓存的原子性。</p><ul><li>先删缓存，后更数据库（失败）：缓存缺失，数据库读取到旧值。</li><li>先更数据库，后删缓存（失败）：先在缓存中查询，但此时，就会读到旧值了</li></ul><p><strong>解决办法：重试机制</strong></p><ul><li>把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</li><li>如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li></ul><p><strong>解决办法：binlog监听的消息队列</strong></p><ul><li>一般大公司本身都会有监听binlog消息的消息队列存在，主要是为了做一些核对的工作。</li><li>可以借助监听binlog的消息队列来做删除缓存的操作。这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。</li></ul><p><strong>解决办法：设置缓存过期时间</strong></p><ul><li>每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。</li></ul><blockquote><p>如果对于一致性要求不是很高的情况，可以采用这种方案。</p></blockquote><h3 id="原因2：大量并发请求"><a href="#原因2：大量并发请求" class="headerlink" title="原因2：大量并发请求"></a>原因2：大量并发请求</h3><p><strong>先删缓存，后更数据库</strong></p><p><img src="buyizhi.jpg" alt="并发缓存不一致"></p><p><strong>解决办法：延迟双删</strong></p><p>在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间（保证“偷菜”完成），再进行一次缓存删除操作。</p><p>难点：sleep时间不好控制</p><p><strong>先更数据库，后删缓存</strong></p><p><img src="buyizhi2.jpg" alt="并发缓存不一致2"></p><p>其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小，不需要解决。</p><p>优点：不存在缓存缺失的问题，推荐！！</p><p><strong>缓存更新替代删除</strong></p><p>写+写并发时，必然会有数据不一致的情况。因此需要配合<strong>分布式锁</strong>使用。</p><p>写+读并发时，先更数据库可能会有短时不一致。</p><h2 id="缓存异常"><a href="#缓存异常" class="headerlink" title="缓存异常"></a>缓存异常</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>大量的应用请求无法在 Redis 缓存中进行处理，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p><p><strong>原因</strong></p><ul><li>缓存中有大量数据同时过期</li><li>Redis 缓存实例发生故障宕机了，无法处理请求</li></ul><p><strong>解决办法</strong></p><ul><li>原因1：避免给大量的数据设置相同的过期时间，数据的过期时间增加一个较小的随机数</li><li>原因1：服务降级：非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取</li><li>原因2：业务系统中实现服务熔断或请求限流机制。暂停业务应用对缓存系统的接口访问。业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</li><li>事前预防。建立Redis 缓存高可靠主从集群。</li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>某个访问非常频繁的热点数据，无法在缓存中进行处理，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p><p><strong>解决办法</strong></p><p>1、访问特别频繁的热点数据，不设置过期时间</p><p>2、使用分布式锁，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完成后，才可以从缓存获取数据。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。缓存也就成了“摆设”。</p><p><strong>原因</strong></p><ul><li><p>业务层误操作：缓存中的数据和数据库中的数据被误删除了</p></li><li><p>恶意攻击：专门访问数据库中没有的数据。</p></li></ul><p><strong>解决办法</strong></p><ul><li>针对穿透查询数据，缓存空值或缺省值。</li><li>使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。</li><li>前端进行请求检测，恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq消息可靠性</title>
      <link href="/2020/10/26/rabbitmq-xiao-xi-ke-kao-xing/"/>
      <url>/2020/10/26/rabbitmq-xiao-xi-ke-kao-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="消息丢失场景"><a href="#消息丢失场景" class="headerlink" title="消息丢失场景"></a>消息丢失场景</h2><h3 id="消息从生产者写入到消息队列的过程"><a href="#消息从生产者写入到消息队列的过程" class="headerlink" title="消息从生产者写入到消息队列的过程"></a>消息从生产者写入到消息队列的过程</h3><p><strong>问题原因</strong>：<br>网络抖动</p><p><strong>解决办法</strong>：</p><ul><li><p>事务<br>在生产者发送消息之前，通过channel.txSelect开启一个事务，接着发送消息， 如果消息投递失败，进行事务回滚channel.txRollback，然后重新发送， 如果消息投递成功，就提交事务channel.txCommit。<br>缺点：同步操作。生产者吞吐量大大降低。</p></li><li><p>发布者确认<br>一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地。</p></li></ul><ul><li>其他</li></ul><ol><li>使用mandatory 设置true：不可路由消息回发到生产者</li><li>利用备份交换机（alternate-exchange）：处理无法路由到队列的消息</li></ol><h3 id="消息在消息队列中的存储场景"><a href="#消息在消息队列中的存储场景" class="headerlink" title="消息在消息队列中的存储场景"></a>消息在消息队列中的存储场景</h3><p><strong>问题原因</strong>：</p><ul><li>持久化了Message，没有持久化队列</li><li>唯一的磁盘节点宕机</li></ul><p><strong>解决办法</strong>：<br>1、消息持久化+队列持久化<br>消息设置delivery-mode为2，队列设置为durable</p><p>2、使用HA队列<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p><p>3、集群设置&gt;=1的磁盘节点。<br>磁盘节点保存集群的运行时状态。确保有多个磁盘节点，保证故障场景下的可靠性。集群恢复时，需要注意磁盘节点的启动顺序。</p><h3 id="消息被消费者消费的过程"><a href="#消息被消费者消费的过程" class="headerlink" title="消息被消费者消费的过程"></a>消息被消费者消费的过程</h3><p><strong>问题原因</strong>：错误代码<br><strong>解决办法</strong>：<br>1、使用消费者手动确认消费<br>2、消费者程序使用事务提交和回滚批量操作。</p>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq消息重复</title>
      <link href="/2020/10/26/rabbitmq-xiao-xi-chong-fu/"/>
      <url>/2020/10/26/rabbitmq-xiao-xi-chong-fu/</url>
      
        <content type="html"><![CDATA[<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><ul><li>可靠性投递机制：mq收到生产者消息，mq在返回confirm的时候网络出现闪断，导致broker未收到应答，导致发送两次。</li><li>MQ Broker服务与消费端传输消息的过程中出现网络抖动。</li><li>消费端故障、异常。</li></ul><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="可靠性投递解决"><a href="#可靠性投递解决" class="headerlink" title="可靠性投递解决"></a>可靠性投递解决</h3><p>对每条消息，MQ系统内部必须生成一个inner-msg-id，作为去重和幂等的依据，这个内部消息ID的特性是：<br>（1）全局唯一<br>（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽<br>有了这个inner-msg-id，就能保证上半场重发，也只有1条消息落到MQ-server的DB中，实现上半场幂等。</p><h3 id="消费抖动解决"><a href="#消费抖动解决" class="headerlink" title="消费抖动解决"></a>消费抖动解决</h3><p>业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：<br>（1）对于同一个业务场景，全局唯一<br>（2）由业务消息发送方生成，业务相关，对MQ透明<br>（3）由业务消息消费方负责判重，以保证幂等</p>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq集群</title>
      <link href="/2020/10/26/rabbitmq-ji-qun/"/>
      <url>/2020/10/26/rabbitmq-ji-qun/</url>
      
        <content type="html"><![CDATA[<h2 id="集群概述"><a href="#集群概述" class="headerlink" title="集群概述"></a>集群概述</h2><hr><h3 id="集群节点类型"><a href="#集群节点类型" class="headerlink" title="集群节点类型"></a>集群节点类型</h3><ul><li>磁盘节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存和磁盘中。集群至少有一个磁盘节点。关闭集群后，重启时需要按照一定顺序启动。</li><li>内存节点：运行时状态信息（集群、队列、绑定虚拟主机、用户、策略等）存储在内存中。重启加入集群是，需要从其他节点同步。</li></ul><p><strong>统计节点</strong><br>rabbitmq管理插件包含，必须搭配磁盘节点，且一个集群只能有一个统计节点。统计节点负责收集每个节点的全部统计数据和状态数据。主节点（统计节点）故障，备用磁盘节点将被指定为统计节点。</p><h2 id="集群设置"><a href="#集群设置" class="headerlink" title="集群设置"></a>集群设置</h2><p><strong>加入集群</strong></p><pre><code>1、在第一节点上运行rabbitmq2、在第二节点上停止rabbitmq，并清除状态rabbitmqctl stop_apprabbitmqctl reset3、加入主节点，构成集群rabbitmqctl join_cluster rabbitmq@node14、再次启动第二节点rabbitmqrabbitmqctl start_app</code></pre>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq消息消费</title>
      <link href="/2020/10/26/rabbitmq-xiao-xi-xiao-fei/"/>
      <url>/2020/10/26/rabbitmq-xiao-xi-xiao-fei/</url>
      
        <content type="html"><![CDATA[<h2 id="消费方法"><a href="#消费方法" class="headerlink" title="消费方法"></a>消费方法</h2><h3 id="Basic-Get"><a href="#Basic-Get" class="headerlink" title="Basic.Get"></a><strong>Basic.Get</strong></h3><ul><li>每次接收消息必须发送一次请求 </li><li>有消息可用，RabbitMQ返回Basic.GetOk以及消息</li><li>无消息可用，RabbitMQ返回Basic.GetEmpty 应用程序需要评估RPC响应以及是否接收到消息。</li></ul><p>示例程序</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)        queue.declare()        while True:            message = queue.get()            if message:                message.pprint()                # 确认消息                message.ack()                if message.body == &#39;stop&#39;:                    break</code></pre><h3 id="Basic-Consume"><a href="#Basic-Consume" class="headerlink" title="Basic.Consume"></a><strong>Basic.Consume</strong></h3><ul><li>消费者可用时，异步方式发送消息</li><li>应用程序自动接收消息，直到Basic.Cancel</li><li>仍然需要确认消息</li></ul><p>示例程序</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">for</span> message <span class="token keyword">in</span> rabbitpy<span class="token punctuation">.</span>consume<span class="token punctuation">(</span><span class="token string">'amqp://guest:guest@localhost:5672/%2f'</span><span class="token punctuation">,</span>                                <span class="token string">'test-messages'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    message<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>）    <span class="token comment" spellcheck="true"># 消息确认</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>消费者标签</strong><br>应用程序发出Basic.Comsume时，创建唯一字符串（消费者标签），标识应用程序。RabbitMQ每次都会把该字符串和消息一同发送给应用程序。<br>客户端库对消费者标签封装，以确定如何处理消息。开发者不用处理消费者标签。</p><p>示例代码：监听消息直到，收到停止消息</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        <span class="token keyword">for</span> message <span class="token keyword">in</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'test-messages'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            message<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span><span class="token punctuation">)</span>            message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> message<span class="token punctuation">.</span>body <span class="token operator">==</span> <span class="token string">'stop'</span><span class="token punctuation">:</span>                <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a><strong>对比</strong></h3><p>Consume吞吐量更大。Get包含了每条消息的同步通信开销。</p><h2 id="消费性能优化"><a href="#消费性能优化" class="headerlink" title="消费性能优化"></a>消费性能优化</h2><h3 id="1、no-ack"><a href="#1、no-ack" class="headerlink" title="1、no-ack"></a>1、no-ack</h3><p>应用程序发送Basic.Comsume请求时，设置no-ack。表明消费者不进行消费确认。</p><p>示例代码：消费不确认</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;test-messages&#39;)        for message in queue.consume_messages(no_ack=True):            message.pprint()</code></pre><h3 id="2、预取"><a href="#2、预取" class="headerlink" title="2、预取"></a>2、预取</h3><p>QoS（Quality of service）中，可设置消费者预先接收一定数量的消息。Basic.Qos一般在Basic.Consume之前设置。</p><p>示例程序：指定QoS</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#预取数为10</span>        channel<span class="token punctuation">.</span>prefetch_count<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> message <span class="token keyword">in</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'test-messages'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            message<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span><span class="token punctuation">)</span>            message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>应用程序不需要确认每条消息，可确认所有以前未读消息。</p><p>示例程序：多消息确认</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        channel<span class="token punctuation">.</span>prefetch_count<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> message <span class="token keyword">in</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'test-messages'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            message<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span><span class="token punctuation">)</span>            unacknowledged <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">if</span> unacknowledged <span class="token operator">==</span> <span class="token number">10</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 确认所有未确认消息</span>                message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span>all_previous<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>                unacknowledged <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3、事务"><a href="#3、事务" class="headerlink" title="3、事务"></a>3、事务</h3><p>事务允许消费者应用程序提交和回滚批量操作。不适用QoS时，可以获得轻微的性能提升。</p><h2 id="拒绝消息"><a href="#拒绝消息" class="headerlink" title="拒绝消息"></a>拒绝消息</h2><h3 id="Basic-Reject"><a href="#Basic-Reject" class="headerlink" title="Basic.Reject"></a>Basic.Reject</h3><p>通知rabbitmq无法处理投递的消息（拒绝一个消息），可指示rabbitMQ丢弃消息或使用requeue重发消息。</p><p>示例程序：消息拒绝</p><pre><code>import rabbitpyfor message in rabbitpy.consume(&#39;amqp://guest:guest@localhost:5672/%2f&#39;,                                &#39;test-messages&#39;):    message.pprint()    print(&#39;Redelivered: %s&#39; % message.redelivered)    message.reject(True)</code></pre><h3 id="Basic-Nack"><a href="#Basic-Nack" class="headerlink" title="Basic.Nack"></a>Basic.Nack</h3><p>同时拒绝多个消息</p><h3 id="死信交换器（DLX）"><a href="#死信交换器（DLX）" class="headerlink" title="死信交换器（DLX）"></a>死信交换器（DLX）</h3><p>创建队列时声明该交换器用于保存被拒绝的消息。队列x-dead-letter-exchange参数(RPC请求)指定死信交换器。</p><p>示例程序：指定死信交换器</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#死信交换器</span>        rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'rejected-messages'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'dlx-example'</span><span class="token punctuation">,</span>                               dead_letter_exchange<span class="token operator">=</span><span class="token string">'rejected-messages'</span><span class="token punctuation">)</span>        queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="控制队列"><a href="#控制队列" class="headerlink" title="控制队列"></a>控制队列</h2><h3 id="临时队列"><a href="#临时队列" class="headerlink" title="临时队列"></a>临时队列</h3><p><strong>自动删除队列</strong><br>消费者完成连接和检索消息，所有消费者断开连接时，队列将被删除。</p><p>示例程序：自动删除队列auto_delete=True</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;ad-example&#39;, auto_delete=True)        queue.declare()</code></pre><p><strong>只允许单个消费者</strong><br>只有单个消费者能够消费队列中的消息。消费者断开连接后，会自动删除队列。</p><p>示例程序：独占队列exclusive</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;exclusive-example&#39;,                               exclusive=True)        queue.declare()</code></pre><p><strong>自动过期队列</strong><br>如果一段时间没有使用该队列就删除它，一般用于RPC回复队列。</p><p>示例程序：自动过期队列</p><pre><code>import rabbitpyimport timewith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;expiring-queue&#39;,                               arguments={&#39;x-expires&#39;: 1000})        queue.declare()        messages, consumers = queue.declare(passive=True)        time.sleep(2)        try:            messages, consumers = queue.declare(passive=True)        except rabbitpy.exceptions.AMQPNotFound:            print(&#39;The queue no longer exists&#39;)</code></pre><h3 id="永久队列"><a href="#永久队列" class="headerlink" title="永久队列"></a>永久队列</h3><p><strong>队列持久性</strong><br>服务器重启后队列仍然存在。<br>示例程序：持久队列</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;durable-queue&#39;,                               durable=True)        if queue.declare():            print(&#39;Queue declared&#39;)</code></pre><p><strong>队列消息自动过期</strong><br>同时指定死信交换器和消息TTL，过期消息将成为死信消息。</p><p>示例程序：消息TTL</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;expiring-msg-queue&#39;,                               arguments={&#39;x-message-ttl&#39;: 1000})         queue.declare()</code></pre><p><strong>最大队列长度</strong><br>一旦达到最大值，添加新消息时，删除队列前端的消息。</p><p>声明队列时，如果指定死信交换器，前端移除的消息将成为死信。</p><p>示例程序：最大长度队列</p><pre><code>import rabbitpywith rabbitpy.Connection() as connection:    with connection.channel() as channel:        queue = rabbitpy.Queue(channel, &#39;max-length-queue&#39;,                               arguments={&#39;x-max-length&#39;: 1000})        queue.declare()</code></pre><h3 id="队列设置参数"><a href="#队列设置参数" class="headerlink" title="队列设置参数"></a>队列设置参数</h3><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>x-dead-letter-exchange</td><td>死信交换器，路由不重发且被拒绝的消息</td></tr><tr><td>x-dead-letter-routing-key</td><td>死信消息的可选路由键</td></tr><tr><td>x-expires</td><td>队列在指定的毫秒数后删除</td></tr><tr><td>x-ha-proxy</td><td>创建HA队列</td></tr><tr><td>x-ha-nodes</td><td>HA队列分布的节点</td></tr><tr><td>x-max-length</td><td>队列的最大消息数</td></tr><tr><td>x-message-ttl</td><td>毫秒为单位的队列过期时间</td></tr><tr><td>x-max-priority</td><td>队列优先级排序</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq消息路由</title>
      <link href="/2020/10/26/rabbitmq-xiao-xi-lu-you/"/>
      <url>/2020/10/26/rabbitmq-xiao-xi-lu-you/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="direct交换器"><a href="#direct交换器" class="headerlink" title="direct交换器"></a>direct交换器</h2><hr><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>投递的消息有一个或者多个确定的目标。</li><li>检查字符串是否相等，不允许使用模式匹配。</li><li>绑定相同路由键的队列都能收到该路由键对应的消息。</li><li>适用于RPC消息通信模式下的路由应答消息</li></ul><p>示例代码：Direct交换器</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'direct-example'</span><span class="token punctuation">,</span>                                     exchange_type<span class="token operator">=</span><span class="token string">'direct'</span><span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="示例场景"><a href="#示例场景" class="headerlink" title="示例场景"></a>示例场景</h3><p>RPC worker消费图片实现面部识别，将结果发回给消息发布方。</p><p><img src="https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211436091-1891495455.jpg" alt></p><ul><li>客户端应用程序上传图像</li><li>应用程序处理请求，用唯一ID标识远程请求并创建一条消息</li><li>图像发布到交换器，消息属性的reply-to对应相应队列的名称, correlation-id对应请求ID</li><li>消息路由到队列，</li><li>消费者消费队列中的消息</li><li>结果以RPC请求形式返回前端。</li></ul><p>注意：RabbitMQ最大帧大小为131072字节，，消息体超过这个大小，就需要在AMQP协议级别分块。预先分配占用7字节，因此，每个消息体帧只能承载131065字节图片数据。</p><p>示例代码：RPC Publisher</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> rabbitpy<span class="token keyword">import</span> time<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> utils<span class="token comment" spellcheck="true"># Open the channel and connection</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span>exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>DirectExchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'rpc-replies'</span><span class="token punctuation">)</span>exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the response queue that will automatically delete, is not durable and</span><span class="token comment" spellcheck="true"># is exclusive to this publisher</span>queue_name <span class="token operator">=</span> <span class="token string">'response-queue-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>response_queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                queue_name<span class="token punctuation">,</span>                                auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                                exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the response queue</span><span class="token keyword">if</span> response_queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Response queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the response queue</span><span class="token keyword">if</span> response_queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'rpc-replies'</span><span class="token punctuation">,</span> queue_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Response queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Iterate through the images to send RPC requests for</span><span class="token keyword">for</span> img_id<span class="token punctuation">,</span> filename <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>utils<span class="token punctuation">.</span>get_images<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Sending request for image #%s: %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>img_id<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Create the message</span>    message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                               utils<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>                               <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> utils<span class="token punctuation">.</span>mime_type<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>                                <span class="token string">'correlation_id'</span><span class="token punctuation">:</span> str<span class="token punctuation">(</span>img_id<span class="token punctuation">)</span><span class="token punctuation">,</span>                                <span class="token string">'reply_to'</span><span class="token punctuation">:</span> queue_name<span class="token punctuation">}</span><span class="token punctuation">,</span>                               opinionated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Pubish the message</span>    message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'direct-rpc-requests'</span><span class="token punctuation">,</span> <span class="token string">'detect-faces'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Loop until there is a response message</span>    message <span class="token operator">=</span> None    <span class="token keyword">while</span> <span class="token operator">not</span> message<span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>        message <span class="token operator">=</span> response_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Ack the response message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Caculate how long it took from publish to response</span>    duration <span class="token operator">=</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span>                time<span class="token punctuation">.</span>mktime<span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'headers'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'first_publish'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Facial detection RPC call for image %s total duration: %s'</span> <span class="token operator">%</span>          <span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> duration<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Display the image in the IPython notebook interface</span>    utils<span class="token punctuation">.</span>display_image<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">,</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RPC requests processed'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Close the channel and connection</span>channel<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例代码：RPC worker</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> rabbitpy<span class="token keyword">import</span> time<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> detect<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> utils<span class="token comment" spellcheck="true"># Open the connection and the channel</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the worker queue</span>queue_name <span class="token operator">=</span> <span class="token string">'rpc-worker-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> queue_name<span class="token punctuation">,</span>                       auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                       durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                       exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'direct-rpc-requests'</span><span class="token punctuation">,</span> <span class="token string">'detect-faces'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Consume messages from RabbitMQ</span><span class="token keyword">for</span> message <span class="token keyword">in</span> queue<span class="token punctuation">.</span>consume_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Display how long it took for the message to get here</span>    duration <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> int<span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%s'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Received RPC request published %.2f seconds ago'</span> <span class="token operator">%</span> duration<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Write out the message body to a temp file for facial detection process</span>    temp_file <span class="token operator">=</span> utils<span class="token punctuation">.</span>write_temp_file<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">,</span>                                      message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Detect faces</span>    result_file <span class="token operator">=</span> detect<span class="token punctuation">.</span>faces<span class="token punctuation">(</span>temp_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Build response properties including the timestamp from the first publish</span>    properties <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'app_id'</span><span class="token punctuation">:</span> <span class="token string">'Chapter 6 Listing 2 Consumer'</span><span class="token punctuation">,</span>                  <span class="token string">'content_type'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token string">'correlation_id'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token string">'headers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                      <span class="token string">'first_publish'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># The result file could just be the original image if nothing detected</span>    body <span class="token operator">=</span> utils<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>result_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Remove the temp file</span>    os<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>temp_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Remove the result file</span>    os<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>result_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Publish the response response</span>    response <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> body<span class="token punctuation">,</span> properties<span class="token punctuation">,</span> opinionated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    response<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'rpc-replies'</span><span class="token punctuation">,</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'reply_to'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Acknowledge the delivery of the RPC request message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="fanout交换器"><a href="#fanout交换器" class="headerlink" title="fanout交换器"></a>fanout交换器</h2><h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><ul><li>所有发往fanout交换器中的消息会被投递到所有该交换器绑定的队列中。</li><li>消息投递不需要检测路由键，性能更好</li></ul><p>示例代码</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                    <span class="token string">'fanout-rpc-requests'</span><span class="token punctuation">,</span>                                     exchange_type<span class="token operator">=</span><span class="token string">'fanout'</span><span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="示例场景-1"><a href="#示例场景-1" class="headerlink" title="示例场景"></a>示例场景</h3><p><img src="https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211416324-1179890043.jpg" alt></p><p>示例程序：Publisher</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> rabbitpy<span class="token keyword">import</span> time<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> utils<span class="token comment" spellcheck="true"># Open the channel and connection</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the response queue that will automatically delete, is not durable and</span><span class="token comment" spellcheck="true"># is exclusive to this publisher</span>queue_name <span class="token operator">=</span> <span class="token string">'response-queue-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>response_queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                queue_name<span class="token punctuation">,</span>                                auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                                exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the response queue</span><span class="token keyword">if</span> response_queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Response queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the response queue</span><span class="token keyword">if</span> response_queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'rpc-replies'</span><span class="token punctuation">,</span> queue_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Response queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Iterate through the images to send RPC requests for</span><span class="token keyword">for</span> img_id<span class="token punctuation">,</span> filename <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>utils<span class="token punctuation">.</span>get_images<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span> <span class="token string">'Sending request for image #%s: %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>img_id<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Create the message</span>    message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                               utils<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>                               <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> utils<span class="token punctuation">.</span>mime_type<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>                                <span class="token string">'correlation_id'</span><span class="token punctuation">:</span> str<span class="token punctuation">(</span>img_id<span class="token punctuation">)</span><span class="token punctuation">,</span>                                <span class="token string">'reply_to'</span><span class="token punctuation">:</span> queue_name<span class="token punctuation">}</span><span class="token punctuation">,</span>                               opinionated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Pubish the message</span>    message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'fanout-rpc-requests'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Loop until there is a response message</span>    message <span class="token operator">=</span> None    <span class="token keyword">while</span> <span class="token operator">not</span> message<span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>        message <span class="token operator">=</span> response_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Ack the response message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Caculate how long it took from publish to response</span>    duration <span class="token operator">=</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span>                time<span class="token punctuation">.</span>mktime<span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'headers'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'first_publish'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Facial detection RPC call for image %s total duration: %s'</span> <span class="token operator">%</span>          <span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> duration<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Display the image in the IPython notebook interface</span>    utils<span class="token punctuation">.</span>display_image<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">,</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">'RPC requests processed'</span><span class="token comment" spellcheck="true"># Close the channel and connection</span>channel<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例程序：detect worker</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> rabbitpy<span class="token keyword">import</span> time<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> detect<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> utils<span class="token comment" spellcheck="true"># Open the connection and the channel</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the worker queue</span>queue_name <span class="token operator">=</span> <span class="token string">'rpc-worker-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> queue_name<span class="token punctuation">,</span>                       auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                       durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                       exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'fanout-rpc-requests'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Consume messages from RabbitMQ</span><span class="token keyword">for</span> message <span class="token keyword">in</span> queue<span class="token punctuation">.</span>consume_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Display how long it took for the message to get here</span>    duration <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> int<span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%s'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Received RPC request published %.2f seconds ago'</span> <span class="token operator">%</span> duration<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Write out the message body to a temp file for facial detection process</span>    temp_file <span class="token operator">=</span> utils<span class="token punctuation">.</span>write_temp_file<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">,</span>                                      message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Detect faces</span>    result_file <span class="token operator">=</span> detect<span class="token punctuation">.</span>faces<span class="token punctuation">(</span>temp_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Build response properties including the timestamp from the first publish</span>    properties <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'app_id'</span><span class="token punctuation">:</span> <span class="token string">'Chapter 6 Listing 2 Consumer'</span><span class="token punctuation">,</span>                  <span class="token string">'content_type'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token string">'correlation_id'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token string">'headers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                      <span class="token string">'first_publish'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># The result file could just be the original image if nothing detected</span>    body <span class="token operator">=</span> utils<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>result_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Remove the temp file</span>    os<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>temp_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Remove the result file</span>    os<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>result_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Publish the response response</span>    response <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> body<span class="token punctuation">,</span> properties<span class="token punctuation">)</span>    response<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'rpc-replies'</span><span class="token punctuation">,</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'reply_to'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Acknowledge the delivery of the RPC request message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例程序：Hash Consumer</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> hashlib<span class="token keyword">import</span> rabbitpy<span class="token comment" spellcheck="true"># Open the connection and the channel</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the worker queue</span>queue_name <span class="token operator">=</span> <span class="token string">'hashing-worker-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> queue_name<span class="token punctuation">,</span>                       auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                       durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                       exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'fanout-rpc-requests'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Consume messages from RabbitMQ</span><span class="token keyword">for</span> message <span class="token keyword">in</span> queue<span class="token punctuation">.</span>consume_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Create the hashing object</span>    hash_obj <span class="token operator">=</span> hashlib<span class="token punctuation">.</span>md5<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Print out the info, this might go into a database or log file</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Image with correlation-id of %s has a hash of %s'</span> <span class="token operator">%</span>          <span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           hash_obj<span class="token punctuation">.</span>hexdigest<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Acknowledge the delivery of the RPC request message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="topic交换器"><a href="#topic交换器" class="headerlink" title="topic交换器"></a>topic交换器</h2><h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><ul><li>消息会被投递到匹配路由键的队列中（*匹配下一.之前的所有字符,#匹配所有字符）。</li></ul><h3 id="示例场景-2"><a href="#示例场景-2" class="headerlink" title="示例场景"></a>示例场景</h3><p><img src="https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211241462-186905715.jpg" alt></p><h2 id="headers交换器"><a href="#headers交换器" class="headerlink" title="headers交换器"></a>headers交换器</h2><h3 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h3><ul><li>使用消息属性中的headers属性匹配。</li><li>queue.bind，x-match指定匹配策略，其他参数表示绑定值</li><li>绑定策略可能会使得性能降低</li></ul><p>示例代码</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                     <span class="token string">'headers-rpc-requests'</span><span class="token punctuation">,</span>                                     exchange_type<span class="token operator">=</span><span class="token string">'headers'</span><span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例程序：publisher</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> rabbitpy<span class="token keyword">import</span> time<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> utils<span class="token comment" spellcheck="true"># Open the channel and connection</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the response queue that will automatically delete, is not durable and</span><span class="token comment" spellcheck="true"># is exclusive to this publisher</span>queue_name <span class="token operator">=</span> <span class="token string">'response-queue-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>response_queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                queue_name<span class="token punctuation">,</span>                                auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                                exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the response queue</span><span class="token keyword">if</span> response_queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Response queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the response queue</span><span class="token keyword">if</span> response_queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'rpc-replies'</span><span class="token punctuation">,</span> queue_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Response queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Iterate through the images to send RPC requests for</span><span class="token keyword">for</span> img_id<span class="token punctuation">,</span> filename <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>utils<span class="token punctuation">.</span>get_images<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Sending request for image #%s: %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>img_id<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Create the message</span>    message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                               utils<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>                               <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> utils<span class="token punctuation">.</span>mime_type<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>                                <span class="token string">'correlation_id'</span><span class="token punctuation">:</span> str<span class="token punctuation">(</span>img_id<span class="token punctuation">)</span><span class="token punctuation">,</span>                                <span class="token string">'headers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'source'</span><span class="token punctuation">:</span> <span class="token string">'profile'</span><span class="token punctuation">,</span>                                            <span class="token string">'object'</span><span class="token punctuation">:</span> <span class="token string">'image'</span><span class="token punctuation">,</span>                                            <span class="token string">'action'</span><span class="token punctuation">:</span> <span class="token string">'new'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>                                <span class="token string">'reply_to'</span><span class="token punctuation">:</span> queue_name<span class="token punctuation">}</span><span class="token punctuation">,</span>                               opinionated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Pubish the message</span>    message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'headers-rpc-requests'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Loop until there is a response message</span>    message <span class="token operator">=</span> None    <span class="token keyword">while</span> <span class="token operator">not</span> message<span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>        message <span class="token operator">=</span> response_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Ack the response message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Caculate how long it took from publish to response</span>    duration <span class="token operator">=</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span>                time<span class="token punctuation">.</span>mktime<span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'headers'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'first_publish'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Facial detection RPC call for image %s total duration: %s'</span> <span class="token operator">%</span>          <span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> duration<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Display the image in the IPython notebook interface</span>    utils<span class="token punctuation">.</span>display_image<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">,</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RPC requests processed'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Close the channel and connection</span>channel<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例程序：worker</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> rabbitpy<span class="token keyword">import</span> time<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> detect<span class="token keyword">from</span> ch6 <span class="token keyword">import</span> utils<span class="token comment" spellcheck="true"># Open the connection and the channel</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span>channel <span class="token operator">=</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Create the worker queue</span>queue_name <span class="token operator">=</span> <span class="token string">'rpc-worker-%s'</span> <span class="token operator">%</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> queue_name<span class="token punctuation">,</span>                       auto_delete<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                       durable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                       exclusive<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Declare the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue declared'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Bind the worker queue</span><span class="token keyword">if</span> queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'headers-rpc-requests'</span><span class="token punctuation">,</span>              arguments<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'x-match'</span><span class="token punctuation">:</span> <span class="token string">'all'</span><span class="token punctuation">,</span>                         <span class="token string">'source'</span><span class="token punctuation">:</span> <span class="token string">'profile'</span><span class="token punctuation">,</span>                         <span class="token string">'object'</span><span class="token punctuation">:</span> <span class="token string">'image'</span><span class="token punctuation">,</span>                         <span class="token string">'action'</span><span class="token punctuation">:</span> <span class="token string">'new'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker queue bound'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Consume messages from RabbitMQ</span><span class="token keyword">for</span> message <span class="token keyword">in</span> queue<span class="token punctuation">.</span>consume_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Display how long it took for the message to get here</span>    duration <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> int<span class="token punctuation">(</span>message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%s'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Received RPC request published %.2f seconds ago'</span> <span class="token operator">%</span> duration<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Write out the message body to a temp file for facial detection process</span>    temp_file <span class="token operator">=</span> utils<span class="token punctuation">.</span>write_temp_file<span class="token punctuation">(</span>message<span class="token punctuation">.</span>body<span class="token punctuation">,</span>                                      message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Detect faces</span>    result_file <span class="token operator">=</span> detect<span class="token punctuation">.</span>faces<span class="token punctuation">(</span>temp_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Build response properties including the timestamp from the first publish</span>    properties <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'app_id'</span><span class="token punctuation">:</span> <span class="token string">'Chapter 6 Listing 2 Consumer'</span><span class="token punctuation">,</span>                  <span class="token string">'content_type'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'content_type'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token string">'correlation_id'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'correlation_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token string">'headers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                      <span class="token string">'first_publish'</span><span class="token punctuation">:</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># The result file could just be the original image if nothing detected</span>    body <span class="token operator">=</span> utils<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>result_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Remove the temp file</span>    os<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>temp_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Remove the result file</span>    os<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>result_file<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Publish the response response</span>    response <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> body<span class="token punctuation">,</span> properties<span class="token punctuation">,</span> opinionated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    response<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'rpc-replies'</span><span class="token punctuation">,</span> message<span class="token punctuation">.</span>properties<span class="token punctuation">[</span><span class="token string">'reply_to'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Acknowledge the delivery of the RPC request message</span>    message<span class="token punctuation">.</span>ack<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="交换器路由"><a href="#交换器路由" class="headerlink" title="交换器路由"></a>交换器路由</h2><p>交换器间绑定，使用RPC方法Exchange.Bind。</p><h3 id="示例场景-3"><a href="#示例场景-3" class="headerlink" title="示例场景"></a>示例场景</h3><p><img src="https://img2020.cnblogs.com/blog/1030146/202010/1030146-20201009211108563-1049881640.jpg" alt></p><p>示例代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        tpc <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'events'</span><span class="token punctuation">,</span>                                exchange_type<span class="token operator">=</span><span class="token string">'topic'</span><span class="token punctuation">)</span>        tpc<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        xch <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'distributed-events'</span><span class="token punctuation">,</span>                                exchange_type<span class="token operator">=</span><span class="token string">'x-consistent-hash'</span><span class="token punctuation">)</span>        xch<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        xch<span class="token punctuation">.</span>bind<span class="token punctuation">(</span>foo<span class="token punctuation">,</span> <span class="token string">'#'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="一致性哈希交换器"><a href="#一致性哈希交换器" class="headerlink" title="一致性哈希交换器"></a>一致性哈希交换器</h2><p>用于消息队列的负载均衡，可以提升吞吐量</p><h3 id="示例场景-4"><a href="#示例场景-4" class="headerlink" title="示例场景"></a>示例场景</h3><p>示例代码：采用路由键的哈希值来分发消息</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'image-storage'</span><span class="token punctuation">,</span>                                     exchange_type<span class="token operator">=</span><span class="token string">'x-consistent-hash'</span><span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例代码：header中的属性值作为哈希值</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'image-storage'</span><span class="token punctuation">,</span>                                     exchange_type<span class="token operator">=</span><span class="token string">'x-consistent-hash'</span><span class="token punctuation">,</span>                                     arguments<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'hash-header'</span><span class="token punctuation">:</span> <span class="token string">'image-hash'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例代码：队列的创建与绑定</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        <span class="token keyword">for</span> queue_num <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue <span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'server%s'</span> <span class="token operator">%</span> queue_num<span class="token punctuation">)</span>            queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>            queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">'image-storage'</span><span class="token punctuation">,</span> <span class="token string">'10'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq消息发布</title>
      <link href="/2020/10/26/rabbitmq-xiao-xi-fa-bu/"/>
      <url>/2020/10/26/rabbitmq-xiao-xi-fa-bu/</url>
      
        <content type="html"><![CDATA[<h2 id="可靠投递"><a href="#可靠投递" class="headerlink" title="可靠投递"></a>可靠投递</h2><hr><h3 id="mandatory"><a href="#mandatory" class="headerlink" title="mandatory"></a>mandatory</h3><p>当交换器无法路由消息，RabbitMQ将回发Basic.Return消息到发布者，同时回发完整消息。<br>Basic.Return是异步的，在消息发布后的任何时候都可能发生。<br>在rabbitpy库中，客户端自动接收Basic.Return，并触发异常</p><p>示例程序：发布失败</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> datetime<span class="token keyword">import</span> rabbitpy<span class="token comment" spellcheck="true"># Connect to the default URL of amqp://guest:guest@localhost:15672/%2F</span><span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Create the message to send</span>        body <span class="token operator">=</span> <span class="token string">'server.cpu.utilization 25.5 1350884514'</span>        message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                   body<span class="token punctuation">,</span>                                   <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> <span class="token string">'text/plain'</span><span class="token punctuation">,</span>                                    <span class="token string">'timestamp'</span><span class="token punctuation">:</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                    <span class="token string">'message_type'</span><span class="token punctuation">:</span> <span class="token string">'graphite metric'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Publish the message to the exchange with the routing key</span>        <span class="token comment" spellcheck="true"># "server-metrics" and make sure it is routed to the exchange</span>        message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'chapter2-example'</span><span class="token punctuation">,</span> <span class="token string">'server-metrics'</span><span class="token punctuation">,</span> mandatory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例程序：异常捕获</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> datetime<span class="token keyword">import</span> rabbitpy<span class="token comment" spellcheck="true"># Connect to the default URL of amqp://guest:guest@localhost:15672/%2F</span>connection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">try</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        properties <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> <span class="token string">'text/plain'</span><span class="token punctuation">,</span>                      <span class="token string">'timestamp'</span><span class="token punctuation">:</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                      <span class="token string">'message_type'</span><span class="token punctuation">:</span> <span class="token string">'graphite metric'</span><span class="token punctuation">}</span>        body <span class="token operator">=</span> <span class="token string">'server.cpu.utilization 25.5 1350884514'</span>        message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> body<span class="token punctuation">,</span> properties<span class="token punctuation">)</span>        message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'chapter2-example'</span><span class="token punctuation">,</span>                        <span class="token string">'server-metrics'</span><span class="token punctuation">,</span>                        mandatory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">except</span> rabbitpy<span class="token punctuation">.</span>exceptions<span class="token punctuation">.</span>MessageReturnedException <span class="token keyword">as</span> error<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Publish failure: %s'</span> <span class="token operator">%</span> error<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="发布者确认"><a href="#发布者确认" class="headerlink" title="发布者确认"></a>发布者确认</h3><p>发布者发送给RabbitMQ的每条消息，服务器发送一个确认（Basic.Ack）或者否认响应（Basic.Nack）。</p><p>示例程序：发布者确认</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'chapter4-example'</span><span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        channel<span class="token punctuation">.</span>enable_publisher_confirms<span class="token punctuation">(</span><span class="token punctuation">)</span>        message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                   <span class="token string">'This is an important message'</span><span class="token punctuation">,</span>                                   <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> <span class="token string">'text/plain'</span><span class="token punctuation">,</span>                                    <span class="token string">'message_type'</span><span class="token punctuation">:</span> <span class="token string">'very important'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'chapter4-example'</span><span class="token punctuation">,</span> <span class="token string">'important.message'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The message was confirmed'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>rabbitpy中没有使用回调的方法，而是在确认收到之前会一直阻塞。</p><h3 id="备用交换器"><a href="#备用交换器" class="headerlink" title="备用交换器"></a>备用交换器</h3><p>处理无法路由的消息。当不可路由的消息发布到已经定义了备用交换器的交换器中时，它将被路由到备用交换器。</p><p>示例程序：备用交换器</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        my_ae <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'my-ae'</span><span class="token punctuation">,</span>                                  exchange_type<span class="token operator">=</span><span class="token string">'fanout'</span><span class="token punctuation">)</span>        my_ae<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        args <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'alternate-exchange'</span><span class="token punctuation">:</span> my_ae<span class="token punctuation">.</span>name<span class="token punctuation">}</span>        exchange <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Exchange<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                     <span class="token string">'graphite'</span><span class="token punctuation">,</span>                                     exchange_type<span class="token operator">=</span><span class="token string">'topic'</span><span class="token punctuation">,</span>                                     arguments<span class="token operator">=</span>args<span class="token punctuation">)</span>        exchange<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span> <span class="token string">'unroutable-messages'</span><span class="token punctuation">)</span>        queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> queue<span class="token punctuation">.</span>bind<span class="token punctuation">(</span>my_ae<span class="token punctuation">,</span> <span class="token string">'#'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Queue bound to alternate-exchange'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="基于事务的批量处理"><a href="#基于事务的批量处理" class="headerlink" title="基于事务的批量处理"></a>基于事务的批量处理</h3><p>确保消息投递成功。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpy<span class="token keyword">with</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> connection<span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        tx <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Tx<span class="token punctuation">(</span>channel<span class="token punctuation">)</span>        tx<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token punctuation">)</span>        message <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Message<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                                   <span class="token string">'This is an important message'</span><span class="token punctuation">,</span>                                   <span class="token punctuation">{</span><span class="token string">'content_type'</span><span class="token punctuation">:</span> <span class="token string">'text/plain'</span><span class="token punctuation">,</span>                                    <span class="token string">'delivery_mode'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>                                    <span class="token string">'message_type'</span><span class="token punctuation">:</span> <span class="token string">'important'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        message<span class="token punctuation">.</span>publish<span class="token punctuation">(</span><span class="token string">'chapter4-example'</span><span class="token punctuation">,</span> <span class="token string">'important.message'</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> tx<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Transaction committed'</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> rabbitpy<span class="token punctuation">.</span>exceptions<span class="token punctuation">.</span>NoActiveTransactionError<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Tried to commit without active transaction'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于错误无法路由消息时，将及时返回Basic.Return。发布者应发送TX.RollbackRPC请求并等待来自代理服务器的TX.Rollback相应，然后继续后续的工作。</p><h3 id="HA队列"><a href="#HA队列" class="headerlink" title="HA队列"></a>HA队列</h3><p>允许队列在多个服务器拥有冗余副本。<br>发布者发送消息到集群中的任何节点。RabbitMQ节点同步队列中消息的状态。发布的消息被放入队列，并存储在每台服务器上。</p><p>示例代码：HA队列声明</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpyconnection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">try</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                               <span class="token string">'my-ha-queue'</span><span class="token punctuation">,</span>                               arguments<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'x-ha-policy'</span><span class="token punctuation">:</span> <span class="token string">'all'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Queue declared'</span><span class="token punctuation">)</span><span class="token keyword">except</span> rabbitpy<span class="token punctuation">.</span>exceptions<span class="token punctuation">.</span>RemoteClosedChannelException <span class="token keyword">as</span> error<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Queue declare failed: %s'</span> <span class="token operator">%</span> error<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例代码：HA队列指定节点</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpyconnection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">try</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> connection<span class="token punctuation">.</span>channel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> channel<span class="token punctuation">:</span>        arguments <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'x-ha-policy'</span><span class="token punctuation">:</span> <span class="token string">'nodes'</span><span class="token punctuation">,</span>                     <span class="token string">'x-ha-nodes'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'rabbit@node1'</span><span class="token punctuation">,</span>                                    <span class="token string">'rabbit@node2'</span><span class="token punctuation">,</span>                                    <span class="token string">'rabbit@node3'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>        queue <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>channel<span class="token punctuation">,</span>                               <span class="token string">'my-2nd-ha-queue'</span><span class="token punctuation">,</span>                               arguments<span class="token operator">=</span>arguments<span class="token punctuation">)</span>        <span class="token keyword">if</span> queue<span class="token punctuation">.</span>declare<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Queue declared'</span><span class="token punctuation">)</span><span class="token keyword">except</span> rabbitpy<span class="token punctuation">.</span>exceptions<span class="token punctuation">.</span>RemoteClosedChannelException <span class="token keyword">as</span> error<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Queue declare failed: %s'</span> <span class="token operator">%</span> error<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="消息持久化"><a href="#消息持久化" class="headerlink" title="消息持久化"></a>消息持久化</h3><p>delivery-mode=1，保存到内存；delivery-mode=2，保存到磁盘。服务器重启后，消息仍在队列中（队列必须声明为durable）。</p><p>如果rabbitmq经常等待操作系统响应读写请求，消息吞吐量将大大降低。</p><h2 id="rabbitmq回推"><a href="#rabbitmq回推" class="headerlink" title="rabbitmq回推"></a>rabbitmq回推</h2><p>发布者发布消息太快，RabbitMQ发送Channel.Flow RPC方法，阻塞发布者。发布者不能发送消息直到收到另一条Channel.Flow命令。</p><p>示例代码：检测连接状态</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> rabbitpyconnection <span class="token operator">=</span> rabbitpy<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Channel is Blocked? %s'</span> <span class="token operator">%</span> connection<span class="token punctuation">.</span>blocked<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis RBD机制</title>
      <link href="/2020/10/26/redis-rdb-ji-zhi/"/>
      <url>/2020/10/26/redis-rdb-ji-zhi/</url>
      
        <content type="html"><![CDATA[<p>RDB 就是 Redis DataBase，内存中的全量数据在某一个时刻的状态记录。</p><h2 id="快照机制"><a href="#快照机制" class="headerlink" title="快照机制"></a>快照机制</h2><h3 id="引入原因"><a href="#引入原因" class="headerlink" title="引入原因"></a>引入原因</h3><p>AOF日志进行故障恢复的时候，需要逐一执行操作日志。如果操作日志非常多，Redis 恢复得很慢，影响到正常使用。</p><h3 id="bgsave命令"><a href="#bgsave命令" class="headerlink" title="bgsave命令"></a>bgsave命令</h3><ul><li>主进程fork出子进程，共享主线程的所有内存数据。</li><li>子进程读取主线程的内存数据，并把它们写入 RDB 文件。</li><li>借助了操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作，避免了主线程的阻塞。</li><li>如果主线程要修改一块数据，这块数据就会被复制一份，生成数据副本。bgsave 子进程会把这个副本数据写入 RDB 文件。</li></ul><p><img src="rdb.jpg" alt></p><h2 id="增量快照"><a href="#增量快照" class="headerlink" title="增量快照"></a>增量快照</h2><p>做了一次全量快照后，后续的快照只对修改的数据进行快照记录，避免每次全量快照的开销。<br>需要使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。</p><h2 id="混用-AOF日志和RDB（Redis-4-0）"><a href="#混用-AOF日志和RDB（Redis-4-0）" class="headerlink" title="混用 AOF日志和RDB（Redis 4.0）"></a>混用 AOF日志和RDB（Redis 4.0）</h2><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。</p><p>AOF 日志也只用记录两次快照间的操作，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p><h2 id="备份机制选择"><a href="#备份机制选择" class="headerlink" title="备份机制选择"></a>备份机制选择</h2><p>数据不能丢失时，内存快照和 AOF 的混合使用；<br>如果允许分钟级别的数据丢失，只使用 RDB；<br>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis AOF机制</title>
      <link href="/2020/10/26/redis-aof-ji-zhi/"/>
      <url>/2020/10/26/redis-aof-ji-zhi/</url>
      
        <content type="html"><![CDATA[<p>先写内存，在写日志。<br>1、命令执行成功才会被记录日志。<br>2、避免对当前命令的阻塞。</p><h2 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h2><p>1、突然宕机，Redis用作数据库的话，命令可能没有记入日志，所以就无法用日志进行恢复了。<br>2、AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。<br>3、子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就长，可能阻塞主线程。<br>4、子进程和父进程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。</p><h2 id="日志写回策略与选择"><a href="#日志写回策略与选择" class="headerlink" title="日志写回策略与选择"></a>日志写回策略与选择</h2><ul><li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li><li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li><li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li></ul><p><strong>对比如下</strong>：<br><img src="aof.jpg" alt></p><p><strong>选择如下</strong>：</p><ul><li>高性能，选择 No；</li><li>高可靠性，选择 Always；</li><li>允许数据丢失，同时性能较好，选择 Everysec。</li></ul><h2 id="重写机制"><a href="#重写机制" class="headerlink" title="重写机制"></a>重写机制</h2><p>后台线程bgwriteaof读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。</p><p><strong>作用</strong><br>1、避免日志文件过大。<br>2、后台线程避免阻塞主线程</p><p><strong>流程</strong><br>一个拷贝，两处日志：AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程</p><p><img src="rewrite.jpg" alt></p><p>1、主线程 fork 出 bgrewriteaof 子进程，把主线程的内存拷贝一份给 bgrewriteaof 子进程<br>2、正在使用的 AOF 日志，因为可能记录了最新操作，Redis 会把这个操作写到它的缓冲区<br>3、这个操作也会被写到重写日志的缓冲区，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis网络IO模型</title>
      <link href="/2020/10/26/redis-wang-luo-io-mo-xing/"/>
      <url>/2020/10/26/redis-wang-luo-io-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h2><p>Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p><p>避免了多线程编程模式面临的共享资源的并发访问控制问题。</p><h2 id="多路复用机制"><a href="#多路复用机制" class="headerlink" title="多路复用机制"></a>多路复用机制</h2><p>一个线程处理多个 IO 流（select/epoll）：在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><p>为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis数据结构</title>
      <link href="/2020/10/26/redis-shu-ju-jie-gou/"/>
      <url>/2020/10/26/redis-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<h2 id="基本数据结构"><a href="#基本数据结构" class="headerlink" title="基本数据结构"></a>基本数据结构</h2><p>包括：String（字符串）、List（列表）、Hash（哈希）、Set（集合）和 Sorted Set（有序集合）</p><table><thead><tr><th>基本数据结构</th><th>底层实现</th></tr></thead><tbody><tr><td>string</td><td>动态字符串</td></tr><tr><td>List</td><td>双向链表、压缩列表</td></tr><tr><td>Hash</td><td>哈希表，压缩列表</td></tr><tr><td>Sorted Set</td><td>跳表，压缩列表</td></tr><tr><td>Set</td><td>哈希表、数组</td></tr></tbody></table><p>redis中的键值对采用哈希表，哈希表就是一个数组，数组的每个元素称为一个哈希桶，每个哈希桶中保存了键值对数据的指针。<br>哈希冲突采用链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br>冲突增多时，Redis 会对哈希表做渐进式 rehash操作。</p><blockquote><p>rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。渐进式 rehash时指拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</p></blockquote><h2 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h2><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">struct</span> RedisObject <span class="token punctuation">{</span>    int4 type<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 4bits，类型</span>    int4 encoding<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 4bits，存储形式</span>    int24 lru<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 24bits，LRU 信息</span>    int32 refcount<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 4bytes，引用计数</span>    <span class="token keyword">void</span> <span class="token operator">*</span>ptr<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 8bytes，对象内容的具体存储位置</span><span class="token punctuation">}</span> robj<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> RedisObject 对象头需要占据 16 字节的存储空间。</p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。</p><p>优点：</p><ol><li>相比C语言字符串，使获取字符串长度时间复杂度降为<code>O(1)</code></li><li><strong>杜绝缓冲区溢出</strong>：当SDS API需要对SDS进行修改时，API会先检查SDS当前剩余空间是否满足修改之后所需的空间，如果不满足的话API会自动将SDS的空间扩展至修改之后所需空间大小，然后再执行实际的修改操作，所以SDS不会出现缓冲区溢出问题。</li><li>减少修改字符串时带来的内存重分配次数： 在SDS中通过未使用空间解除了字符串长度和底层数组长度之间的关联，在SDS中，buf数组长度不一定是字符串长度加1，数组中可能包含未使用的字节，这些字节的数量就是由SDS的free属性记录。通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略。</li></ol><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">struct</span> SDS<span class="token operator">&lt;</span>T<span class="token operator">></span> <span class="token punctuation">{</span>    T capacity<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 数组容量</span>    T len<span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">// 数组长度，已经使用的容量</span>    byte flags<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 特殊标识位，不理睬它</span>    byte<span class="token punctuation">[</span><span class="token punctuation">]</span> content<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 数组内容</span><span class="token punctuation">}</span><span class="token keyword">struct</span> SDS <span class="token punctuation">{</span>    int8 capacity<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 1byte</span>    int8 len<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 1byte</span>    int8 flags<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 1byte</span>    byte<span class="token punctuation">[</span><span class="token punctuation">]</span> content<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 内联数组，长度为 capacity</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>embstr ：将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。</li><li>raw ：需要两次 malloc，两个对象头在内存地址上一般是不连续的。</li></ul><h3 id="空间预分配策略"><a href="#空间预分配策略" class="headerlink" title="空间预分配策略"></a>空间预分配策略</h3><ul><li>字符串在长度小于 1M 之前，扩容空间采用加倍策略。</li><li>当长度超过 1M 之后，为了避免加倍后导致浪费，多分配 1M 大小的冗余空间。</li></ul><h3 id="惰性空间释放"><a href="#惰性空间释放" class="headerlink" title="惰性空间释放"></a>惰性空间释放</h3><p>用于优化SDS的字符串收缩操作，当字符串收缩时，程序不会立即执行内存重分配来回收收缩后内存多出来的空间，而是使用free属性记录下来，以备将来使用。</p><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>redis list数据结构底层采用压缩列表ziplist或双向列表两种数据结构进行存储，首先以ziplist进行存储，在不满足ziplist的存储要求后转换为双向列表。</p><p><strong>当列表对象同时满足以下两个条件时，列表对象使用ziplist进行存储，否则用双向列表存储。</strong></p><ul><li>列表对象保存的所有字符串元素的长度小于64字节</li><li>列表对象保存的元素数量小于512个。</li></ul><h2 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h2><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul><li>hash 结构的数据</li><li>整个 Redis 数据库的所有 key 和 value 组成了一个全局字典。</li><li>还有带过期时间的 key 集合也是一个字典。</li><li>zset 集合中存储 value 和 score 值的映射关系。</li></ul><h3 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h3><p>内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。</p><p>扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁。</p><p>两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。</p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">struct</span> dict <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    dictht ht<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//哈希表</span><span class="token punctuation">}</span><span class="token keyword">struct</span> dictht <span class="token punctuation">{</span>    dictEntry <span class="token operator">*</span><span class="token operator">*</span>table<span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 二维</span>    <span class="token keyword">long</span> size<span class="token punctuation">;</span>             <span class="token comment" spellcheck="true">// 第一维数组的长度</span>    <span class="token keyword">long</span> used<span class="token punctuation">;</span>             <span class="token comment" spellcheck="true">// hash 表中的元素个数</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token keyword">struct</span> dictEntry <span class="token punctuation">{</span>    <span class="token keyword">void</span><span class="token operator">*</span> key<span class="token punctuation">;</span>    <span class="token keyword">void</span><span class="token operator">*</span> val<span class="token punctuation">;</span>    dictEntry<span class="token operator">*</span> next<span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 链接下一个 entry</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="hash表扩容机制"><a href="#hash表扩容机制" class="headerlink" title="hash表扩容机制"></a>hash表扩容机制</h3><p>1、redis字典（hash表）底层有两个数组，还有一个rehashidx用来控制rehash</p><p>2、初始默认hash长度为4，当元素个数与hash表长度一致时，就发生扩容，hash长度变为原来的二倍</p><p>3、<strong>redis中的hash则是执行的单步rehash的过程</strong>：每次的增删改查，rehashidx+1，然后执行对应原hash表rehashidx索引位置的rehash</p><h3 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h3><p>大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，<code>O(n)</code>级别的操作。</p><p>Redis还会在定时任务中对字典进行主动搬迁。</p><ol><li><p>为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表</p></li><li><p>将rehashindex的值设置为0，表示rehash工作正式开始</p></li><li><p>在rehash期间，每次对字典执行增删改查操作是，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashindex索引上的所有键值对rehash到ht[1]，当rehash工作完成以后，rehashindex的值+1</p></li><li><p>随着字典操作的不断执行，最终会在某一时间段上ht[0]的所有键值对都会被rehash到ht[1]，这时将rehashindex的值设置为-1，表示rehash操作结束</p></li></ol><h3 id="扩容条件"><a href="#扩容条件" class="headerlink" title="扩容条件"></a>扩容条件</h3><p>当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。</p><p>如果 Redis 正在做 bgsave，为了减少内存页的过多分离 （Copy On Write），Redis 尽量不去扩容 （dict_can_resize）</p><p>如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 （dict_force_resize_ratio），说明 hash 表已经过于拥挤了，就会强制扩容。</p><h2 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h2><p>压缩列表类似于一个数组，数组中的每一个元素都对应保存一个数据。</p><p>不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表占用字节数、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</p><p>压缩列表是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。</p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">struct</span> ziplist<span class="token operator">&lt;</span>T<span class="token operator">></span> <span class="token punctuation">{</span>    int32 zlbytes<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 整个压缩列表占用字节数</span>    int32 zltail_offset<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点</span>    int16 zllength<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 元素个数</span>    T<span class="token punctuation">[</span><span class="token punctuation">]</span> entries<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 元素内容列表，挨个挨个紧凑存储</span>    int8 zlend<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 标志压缩列表的结束，值恒为 0xFF</span><span class="token punctuation">}</span><span class="token keyword">struct</span> entry <span class="token punctuation">{</span>    <span class="token keyword">int</span><span class="token operator">&lt;</span>var<span class="token operator">></span> prevlen<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 前一个 entry 的字节长度</span>    <span class="token keyword">int</span><span class="token operator">&lt;</span>var<span class="token operator">></span> encoding<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 元素类型编码</span>    optional byte<span class="token punctuation">[</span><span class="token punctuation">]</span> content<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 元素内容</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。</p><h2 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h2><p>各个数据结构的查找时间复杂度</p><table><thead><tr><th>数据结构</th><th>复杂度</th></tr></thead><tbody><tr><td>哈希表</td><td><code>O(1)</code></td></tr><tr><td>跳表</td><td><code>O(logN)</code></td></tr><tr><td>双向链表</td><td><code>O(N)</code></td></tr><tr><td>压缩列表</td><td><code>O(N)</code></td></tr><tr><td>数组</td><td><code>O(N)</code></td></tr></tbody></table><h2 id="Bitmap"><a href="#Bitmap" class="headerlink" title="Bitmap"></a>Bitmap</h2><p>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。</p><p>可用于用户连续签到，可在记录海量数据时，Bitmap 能够有效地节省内存空间。</p><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>Hyperloglog 提供了一种不太精确的基数统计方法，用来统计一个集合中不重复的元素个数，比如统计网站的UV，或者应用的日活、月活，存在一定的误差。</p><h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><p>适用于位置信息服务（Location-Based Service，LBS）的应用。</p><p><strong>实现原理</strong></p><p>GEO 类型的底层数据结构就是用 Sorted Set 来实现的。Sorted Set 元素的权重分数是一个浮点数（float 类型），而一组经纬度包含的是经度和纬度两个值。因袭需要对一组经纬度进行 GeoHash 编码，基本原理就是<code>二分区间，区间编码</code>，经纬度编码需要交叉组合成一个数。</p><h2 id="Streams（5-0）"><a href="#Streams（5-0）" class="headerlink" title="Streams（5.0）"></a>Streams（5.0）</h2><p>Streams 是 Redis 专门为消息队列设计的数据类型。</p><p>对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。</p><p>Streams支持消费组。消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。</p><p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis变慢以及优化方法</title>
      <link href="/2020/10/26/redis-bian-man-yi-ji-you-hua-fang-fa/"/>
      <url>/2020/10/26/redis-bian-man-yi-ji-you-hua-fang-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="确定问题"><a href="#确定问题" class="headerlink" title="确定问题"></a>确定问题</h2><p>1、查看 Redis 的响应延迟。<br>2、基于当前环境下的 Redis 基线性能做判断<br>基线性能是系统在低压力、无干扰下的基本性能，Redis 运行时延迟是其基线性能的 2 倍及以上，可认定 Redis 变慢了。</p><h2 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h2><p>1、通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，确认是否采用了复杂度高的慢查询命令。<br>2、检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。从而造成大量 key 在同一时间过期，导致性能变慢。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>3、检查是否使用了慢查询命令：<code>KEYS *xxx</code></p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>1.a.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。<br>1.b.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p><p>2.如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数</p><p>3.获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行<code>SCAN $cursor COUNT $count</code>可以得到一批key以及下一个游标<code>$cursor</code>，然后把这个<code>$cursor</code>当作SCAN的参数，再次执行，以此往复，直到返回的<code>$cursor</code>为0时，就把整个实例中的所有key遍历出来了。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于多CPU多核架构的redis性能优化</title>
      <link href="/2020/10/26/ji-yu-duo-cpu-duo-he-jia-gou-de-redis-xing-neng-you-hua/"/>
      <url>/2020/10/26/ji-yu-duo-cpu-duo-he-jia-gou-de-redis-xing-neng-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="CPU架构"><a href="#CPU架构" class="headerlink" title="CPU架构"></a>CPU架构</h2><ul><li>一个 CPU 处理器中一般有多个物理核。</li><li>每个物理核都拥有私有的一级缓存（ L1 cache）和私有的二级缓存（L2 cache）。</li><li>不同的物理核还会共享一个共同的三级缓存</li><li>每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存</li><li>不同处理器间通过总线连接</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>1、多CPU：如果应用程序先在一个 Socket（CPU处理器） 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。（NUMA）</p><p>2、多核：Redis 主线程的运行时信息需要被重新加载到另一个 CPU 物理核上，而且，此时，另一个 CPU 物理核上的 L1、L2 缓存中并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。</p><p>3、Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间。可能存在跨CPU拷贝内存数据。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>1、把 Redis 实例和 CPU 物理核绑定了，让一个 Redis 实例固定运行在一个 CPU 物理核上<br>2、把操作系统的网络中断处理程序和 CPU 物理核绑定。Redis 实例绑定在同一个物理核上。<br>3、使用源码优化方案，既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。</p><p>注：NUMA架构下，先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis阻塞及解决办法</title>
      <link href="/2020/10/26/redis-zu-sai-ji-jie-jue-ban-fa/"/>
      <url>/2020/10/26/redis-zu-sai-ji-jie-jue-ban-fa/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="阻塞分析"><a href="#阻塞分析" class="headerlink" title="阻塞分析"></a>阻塞分析</h2><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p><strong>复杂度高的增删改查操作</strong><br>1、集合全量查询和聚合操作<br>2、bigkey 删除<br>3、清空数据库</p><h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><p>1、AOF 日志同步写</p><h3 id="主从节点"><a href="#主从节点" class="headerlink" title="主从节点"></a>主从节点</h3><p>1、从库接收 RDB 文件后、<strong>清空数据库、加载 RDB 文件</strong>；</p><h3 id="切片集群"><a href="#切片集群" class="headerlink" title="切片集群"></a>切片集群</h3><p>向其他实例传输哈希槽信息，数据迁移时遇到big key。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>关键路径：集合全量查询和聚合操作和从库加载 RDB 文件<br>非关键路径： bigkey 删除，清空数据库，以及 AOF 日志同步写。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="异步的子线程机制"><a href="#异步的子线程机制" class="headerlink" title="异步的子线程机制"></a>异步的子线程机制</h3><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别负责 <strong>AOF 日志写操作、键值对删除以及文件关闭</strong>的异步执行。</p><p>主线程通过一个链表形式的任务队列和子线程进行交互。</p><ul><li>当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成（惰性删除）。</li><li>当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</li></ul><blockquote><p>异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能。</p><p>之前的版本Big key删除可以先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p></blockquote><h3 id="分批读取"><a href="#分批读取" class="headerlink" title="分批读取"></a>分批读取</h3><p>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算</p><h3 id="控制RBD大小"><a href="#控制RBD大小" class="headerlink" title="控制RBD大小"></a>控制RBD大小</h3><p>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis切片集群</title>
      <link href="/2020/10/26/redis-qie-pian-ji-qun/"/>
      <url>/2020/10/26/redis-qie-pian-ji-qun/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p> RDB 持久化时，fork 子进程用时和 Redis 的数据量是正相关的。数据量越大，fork 操作造成的主线程阻塞的时间越长。</p><h2 id="切片集群机制"><a href="#切片集群机制" class="headerlink" title="切片集群机制"></a>切片集群机制</h2><ul><li><p>一个切片集群共有 16384 个哈希槽，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p><blockquote><p>映射方法：</p><p>按照CRC16 算法计算一个 16 bit 的值；</p><p>再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，对应相应编号的哈希槽</p></blockquote></li><li><p>Redis 实例把自己的哈希槽信息发给和它相连的其它实例，来完成哈希槽分配信息的扩散。</p></li><li><p>客户端和集群实例建立连接后，实例把哈希槽的分配信息发给客户端</p></li></ul><h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><ul><li>集群实例有新增或删除，Redis 需要重新分配哈希槽；</li><li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li></ul><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p><strong>重定向机制</strong>，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，实例返回的 MOVED 命令响应，其中包含了新实例的访问地址，客户端给对应新实例发送操作命令（客户端更新了本地缓存）。</p><p>注：如果数据在实例中迁移到一半，实例返回ASK 报错信息，表明 Slot 数据还在迁移中，并返回最新实例地址（客户端不更新本地缓存）。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis哨兵机制</title>
      <link href="/2020/10/25/redis-shao-bing-ji-zhi/"/>
      <url>/2020/10/25/redis-shao-bing-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>主库故障的相关问题：</p><p>1、确定主库故障</p><p>2、选择新的主库</p><p>3、新主库信息通知</p><h2 id="基本功能"><a href="#基本功能" class="headerlink" title="基本功能"></a>基本功能</h2><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li><p>哨兵进程周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</p></li><li><p>主库或从库对 PING 命令的响应超时了，哨兵会标记为主观下线。</p></li><li><p>需有quorum 个实例判断主库为主观下线，才能判定主库为客观下线</p></li></ul><h3 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h3><ul><li><p>筛选当前在线从库，且网络连接状况较好；</p></li><li><p>选择从库优先级最高的从库</p></li><li><p>选择从库复制进度最快的</p></li><li><p>选择从库 ID 号小的</p></li></ul><h3 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h3><ul><li>通知从库执行replicaof，与新主库同步</li><li>通知客户端，向新主库请求</li></ul><p><strong>通知客户端</strong>的实现方法</p><p>1、哨兵会把新主库的地址写入自己实例的pubsub中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址。</p><p>2、客户端需要支持主动去获取最新主从的地址进行访问。</p><h2 id="基于-pub-sub-机制的哨兵集群"><a href="#基于-pub-sub-机制的哨兵集群" class="headerlink" title="基于 pub/sub 机制的哨兵集群"></a>基于 pub/sub 机制的哨兵集群</h2><p><strong>连接关系的实现</strong></p><ul><li>哨兵-哨兵：哨兵订阅主库上的<code>__sentinel__:hello</code>，实现哨兵连接信息的发布获取</li><li>哨兵-从库：哨兵给主库发送 INFO 命令，主库接受到后，返回从库列表。从而哨兵可以连接从库</li><li>哨兵-客户端：客户端订阅哨兵消息</li></ul><p><strong>哨兵Leader竞选 （总从切换）</strong></p><p>1、拿到半数以上的赞成票；</p><p>2、拿到的票数同时还需要大于等于仲裁所需的赞成票数（quorum ）。</p><h2 id="节点间的内部通信机制"><a href="#节点间的内部通信机制" class="headerlink" title="节点间的内部通信机制"></a>节点间的内部通信机制</h2><p>redis cluster 节点间采用 gossip 协议进行通信。所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><ul><li><p>优点：元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；</p></li><li><p>缺点：元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p></li></ul><p>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</p><p>gossip 协议包含多种消息：</p><ul><li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。redis-trib.rb add-node其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。</li><li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</li><li>pong：返回ping和meeet，包括自己的状态和其他信息，也用于信息广播和更新。</li><li>fail：某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点说，某个节点宕机了。</li></ul><p>每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis主从同步</title>
      <link href="/2020/10/25/redis-zhu-cong-tong-bu/"/>
      <url>/2020/10/25/redis-zhu-cong-tong-bu/</url>
      
        <content type="html"><![CDATA[<p>主从库之间采用读写分离。<br>读操作：主库、从库都可以接收；<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。<br><img src="duxiefenli.jpg" alt="读写分离"></p><h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><p>C - Consistent ，一致性<br>A - Availability ，可用性<br>P - Partition tolerance ，分区容忍性</p><p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。</p><p>一句话概括 CAP 原理就是——网络分区发生时，一致性和可用性两难全。</p><h2 id="同步机制"><a href="#同步机制" class="headerlink" title="同步机制"></a>同步机制</h2><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系。</p><p>1、主从库间建立连接、协商同步，为全量复制做准备。<br><strong>从库和主库建立起连接，发送 psync 命令</strong>，表示要进行数据同步，<strong>主库确认回复</strong>，FULLRESYNC响应表示第一次复制采用的全量复制。<br>psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p><p>2、主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。<br>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。<br>从库接收到 RDB 文件后，会先清空当前数据库（避免之前数据的影响），然后加载 RDB 文件。</p><p>3、主库会把第二阶段执行过程中新收到的写命令（replication buffer中的修改操作），再发送给从库。<br>主库会在内存中使用 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p><p><img src="zhucongtongbu.jpg" alt="主从第一次同步"></p><h3 id="无盘复制"><a href="#无盘复制" class="headerlink" title="无盘复制"></a>无盘复制</h3><p>主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。<br>所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。</p><h2 id="主从级联"><a href="#主从级联" class="headerlink" title="主从级联"></a>主从级联</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ul><li><p>从库数量很多且都要和主库进行全量复制时，会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</p></li><li><p>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。</p></li></ul><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</p><p><img src="master_slave_slave.jpg" alt="级联的“主-从-从”模式"></p><h2 id="网络闪断"><a href="#网络闪断" class="headerlink" title="网络闪断"></a>网络闪断</h2><p>网络闪断后，主从库会采用增量复制的方式继续同步。</p><h3 id="增量复制机制"><a href="#增量复制机制" class="headerlink" title="增量复制机制"></a>增量复制机制</h3><ul><li><p>主库把断连期间收到的写操作命令写入 repl_backlog_buffer 缓冲区</p></li><li><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录写到的位置，从库会记录已经读到的位置。</p></li><li><p>连接恢复后，从库给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断 master_repl_offset 和 slave_repl_offset 之间的差距。把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库。</p></li><li><p>库还未读取的操作被主库新写的操作覆盖，需要全量复制</p></li></ul><h3 id="应对"><a href="#应对" class="headerlink" title="应对"></a>应对</h3><ul><li><p>repl_backlog_size 设置一个合理的值，避免从库还未读取的操作被主库新写的操作覆盖了</p></li><li><p>使用切片集群来分担单个主库的请求压力</p></li></ul><h2 id="主从数据不一致"><a href="#主从数据不一致" class="headerlink" title="主从数据不一致"></a>主从数据不一致</h2><p>根本原因：主从库间的命令复制是异步进行的</p><p>直接原因：</p><ul><li>主从库间的网络可能会有传输延迟</li><li>处理其它复杂度高的命令（例如集合操作命令）而阻塞同步</li><li>主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致</li></ul><p>解决方法</p><ul><li>尽量保证主从库间的网络连接状况良好</li><li>外部程序监控主从库间的复制进度（INFO replication ），依据从库和主库间的复制进度，设置客户端从库连接</li></ul><h2 id="读取数据过期"><a href="#读取数据过期" class="headerlink" title="读取数据过期"></a>读取数据过期</h2><h3 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h3><p>定期删除策略：Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除。注意避免大量key同时过期，否则可能因redis删除过期key阻塞用户请求；</p><p><strong>惰性删除策略</strong>：数据只有被再次访问时，才会被实际删除。从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，<strong>从库并不会触发数据删除</strong>。<strong>在 3.2 版本后</strong>，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。</p><h3 id="过期命令"><a href="#过期命令" class="headerlink" title="过期命令"></a>过期命令</h3><ul><li>EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li><li><strong>EXPIREAT 和 PEXPIREA</strong>：它们会直接把数据的过期时间设置为具体的一个时间点</li></ul><p>当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在<strong>当前时间的基础上加上数据的存活时间</strong>，从库上数据的过期时间就会比主库上延后了</p><h3 id="解决-1"><a href="#解决-1" class="headerlink" title="解决"></a>解决</h3><ul><li>使用 <strong>Redis 3.2 及以上版本和惰性删除策略</strong></li><li>在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据</li></ul><h3 id="同步异常"><a href="#同步异常" class="headerlink" title="同步异常"></a>同步异常</h3><p><code>protected-mode</code>：yes ，哨兵实例只能在部署的服务器本地进行访问。no ，其他服务器也可以访问这个哨兵实例。同时，bind 配置项设置为其它哨兵实例的 IP 地址。</p><p><code>cluster-node-timeout</code>:实例响应心跳消息的超时时间。主从切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）。实例超时后，就会被 Redis Cluster 判断为异常。有半数以上的实例异常，会导致整个集群挂掉。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p><code>slave-serve-stale-data</code>: 从库能否处理数据读写命令，推荐设置为 no，从库只能服务 INFO、SLAVEOF 命令，避免在从库中读到不一致的数据。</p><p><code>slave-read-only</code>：设置从库能否处理写命令， yes 时，从库只能处理读请求，无法处理写请求。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分治、贪心、动态规划</title>
      <link href="/2020/02/16/algorithm-method/"/>
      <url>/2020/02/16/algorithm-method/</url>
      
        <content type="html"><![CDATA[<h2 id="分治"><a href="#分治" class="headerlink" title="分治"></a>分治</h2><p><strong>概念</strong></p><p>一个复杂的问题分成两个或多个相同或相似的子问题，再把子问题分成更小的子问题直到最后子问题可以简单地直接求解，原问题的解即子问题的解的合并，这个思想是很多高效算法的基础，例如<strong>排序算法（快速排序，归并排序），傅里叶变换（快速傅里叶变换）</strong>等</p><p><strong>分治法使用场景</strong></p><ol><li>该问题的<strong>规模缩小</strong>到一定的程度就可以容易的解决。</li><li>该问题可以分解为若干个规模较小的相同问题，即该问题具有<strong>最优子结构性质</strong>。</li><li>利用该问题分解出的子问题的解<strong>可以合并</strong>为该问题的解。</li><li>该问题所分解出的各个子问题是<strong>相互独立</strong>的，即子问题之间不包含公共的子问题。</li></ol><p><strong>基本步骤</strong></p><ul><li>分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题</li><li>解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题</li><li>合并：将各个子问题的解合并为原问题的解</li></ul><h2 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a>贪心</h2><p>是指在对问题求解时，总是做出再当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是某种意义上的<strong>局部最优解</strong>。</p><p><strong>选择的贪心策略必须具备无后效性</strong>，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。</p><p><strong>基本思路</strong></p><p>1.建立数学模型来描述问题。</p><p>2.把求解的问题分成若干个子问题。</p><p>3.对每一子问题求解，得到子问题的局部最优解。</p><p>4.把<strong>子问题的局部最优解</strong>合成原来解问题的一个解。</p><p><strong>适用场景</strong></p><p>贪心策略的前提是：<strong>局部最优策略能导致产生全局最优解</strong>。</p><p>实际上，贪心算法使用的情况比较少，一般对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析可以做出判断。</p><p><strong>应用</strong></p><p>小船过河问题</p><h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><p>动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。</p><h3 id="适用条件"><a href="#适用条件" class="headerlink" title="适用条件"></a>适用条件</h3><ul><li>最优化原理（最优子结构性质）：一个最优化策略的子策略总是最优的。</li><li>无后效性：子问题对主问题的影响可以总结为少数“状态”的特性。某阶段的状态一旦确定，则此后过程的演变不再受此前各种状态及决策的影响。即未来与过去无关。</li><li>子问题的重叠性：子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>十大经典排序算法整理汇总（附代码）</title>
      <link href="/2020/02/16/sort-algorithms/"/>
      <url>/2020/02/16/sort-algorithms/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。</p><h2 id="性质汇总"><a href="#性质汇总" class="headerlink" title="性质汇总"></a>性质汇总</h2><table><thead><tr><th>算法</th><th>最好</th><th>最坏</th><th>平均</th><th>空间</th><th align="center">稳定性</th><th align="center">是否基于比较</th></tr></thead><tbody><tr><td>冒泡排序</td><td>$O(n)$</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(1)$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td>选择排序</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(1)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr><tr><td>插入排序</td><td>$O(n)$</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(1)$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td>快速排序</td><td>$O(n\log n)$</td><td>$O(n^2)$</td><td>$O(n\log n)$</td><td>$O(\log n)$~$O(n)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr><tr><td>归并排序</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(n)$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td>希尔排序</td><td>$O(n^{1.3})$</td><td>$O(n^2)$</td><td>$O(n\log n)$~$O(n^2)$</td><td>$O(1)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr><tr><td>计数排序</td><td>$O(n+k)$</td><td>$O(n+k)$</td><td>$O(n+k)$</td><td>$O(n+k)$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td>基数排序</td><td>$O(nk)$</td><td>$O(nk)$</td><td>$O(nk)$</td><td>$O(n+k)$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td>桶排序</td><td>$O(n)$</td><td>$O(n)$</td><td>$O(n)$</td><td>$O(n+m)$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td>堆排序</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(1)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr></tbody></table><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="主流排序算法"><a href="#主流排序算法" class="headerlink" title="主流排序算法"></a><strong>主流排序算法</strong></h3><h4 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h4><p>比较前一个数和后一个数，如果前比后大，对换他们的位置；从左往右冒泡泡</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">bubble_sort</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>    n <span class="token operator">=</span> len<span class="token punctuation">(</span>a<span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># j [0,n-1)... [0,2), [0,1)</span>            <span class="token keyword">if</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> a<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                a<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h4><p>在未排序序列中找到最小元素，存放到排序序列的起始位置。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sel_sort</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>    n <span class="token operator">=</span> len<span class="token punctuation">(</span>a<span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># [0, n), [1, n)...</span>        minindex <span class="token operator">=</span> i        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> a<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> a<span class="token punctuation">[</span>minindex<span class="token punctuation">]</span><span class="token punctuation">:</span>                minindex <span class="token operator">=</span> j        a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>minindex<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>minindex<span class="token punctuation">]</span><span class="token punctuation">,</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h4><ol><li>从第一个元素开始，该元素可以认为已经被排序  </li><li>取出下一个元素，在已经排序的元素序列中从后向前扫描  </li><li>如果被扫描的元素（已排序）大于新元素，将该元素后移一位</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">insertSort</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>i<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> l<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> l<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                l<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> l<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">=</span> l<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> l<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="快排"><a href="#快排" class="headerlink" title="快排"></a>快排</h4><ul><li>从数列中挑出一个元素作为基准数。  </li><li>分区过程，将比基准数大的放到右边，小于或等于它的数都放到左边。  </li></ul><p><strong>优化</strong></p><p>1、三数取中作基准</p><p>2、当待排序序列的长度分割到一定大小后，使用插入排序：对于很小和部分有序的数组，快排不如插排好。当待排序序列的长度分割到一定大小后，继续分割的效率比插入排序要差，此时可以使用插排而不是快排</p><p>3、在一次分割结束后，可以把与pivot相等的元素聚在一起，继续下次分割时，不用再对与pivot相等元素分割：实现的时候先放2边，然后调整到中间。</p><p><strong>复杂度分析</strong></p><p><a href="https://zhuanlan.zhihu.com/p/341201904" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/341201904</a></p><p><strong>应用</strong></p><p>TOPK问题，可基于划分得到。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">randomized_partition</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">:</span>        pivot <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>l<span class="token punctuation">,</span> r<span class="token punctuation">)</span>        nums<span class="token punctuation">[</span>pivot<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>pivot<span class="token punctuation">]</span>        i <span class="token operator">=</span> l <span class="token operator">-</span> <span class="token number">1</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>l<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">:</span>                i <span class="token operator">+=</span> <span class="token number">1</span>                nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span>        i <span class="token operator">+=</span> <span class="token number">1</span>        nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> i    <span class="token keyword">def</span> <span class="token function">randomized_quicksort</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> r <span class="token operator">&lt;=</span> l<span class="token punctuation">:</span>            <span class="token keyword">return</span>        mid <span class="token operator">=</span> self<span class="token punctuation">.</span>randomized_partition<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> r<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>randomized_quicksort<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> mid <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>randomized_quicksort<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> r<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sortArray</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>randomized_quicksort<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> nums<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h4><ol><li>先将待排序的序列建成大根堆，使得每个父节点的元素大于等于它的子节点。</li><li>此时整个序列最大值即为堆顶元素，我们将其与末尾元素交换，使末尾元素为最大值，然后再调整堆顶元素使得剩下的 n-1个元素仍为大根堆</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">max_heapify</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> heap<span class="token punctuation">,</span> root<span class="token punctuation">,</span> heap_len<span class="token punctuation">)</span><span class="token punctuation">:</span>        p <span class="token operator">=</span> root        <span class="token keyword">while</span> p <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&lt;</span> heap_len<span class="token punctuation">:</span>            l<span class="token punctuation">,</span> r <span class="token operator">=</span> p <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> p <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">2</span>            <span class="token comment" spellcheck="true"># 两个子节点取较大值，或者无右节点时取左节点</span>            <span class="token keyword">if</span> heap_len <span class="token operator">&lt;=</span> r <span class="token operator">or</span> heap<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">&lt;</span> heap<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">:</span>                nex <span class="token operator">=</span> l            <span class="token keyword">else</span><span class="token punctuation">:</span>                nex <span class="token operator">=</span> r            <span class="token comment" spellcheck="true"># 交换父节点和子节点较大值，并向下处理（一般下面已经完成有序处理）</span>            <span class="token keyword">if</span> heap<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">&lt;</span> heap<span class="token punctuation">[</span>nex<span class="token punctuation">]</span><span class="token punctuation">:</span>                heap<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">,</span> heap<span class="token punctuation">[</span>nex<span class="token punctuation">]</span> <span class="token operator">=</span> heap<span class="token punctuation">[</span>nex<span class="token punctuation">]</span><span class="token punctuation">,</span> heap<span class="token punctuation">[</span>p<span class="token punctuation">]</span>                p <span class="token operator">=</span> nex            <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 不需要处理</span>                <span class="token keyword">break</span>    <span class="token keyword">def</span> <span class="token function">build_heap</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> heap<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 倒序调整堆</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>heap<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>max_heapify<span class="token punctuation">(</span>heap<span class="token punctuation">,</span> i<span class="token punctuation">,</span> len<span class="token punctuation">(</span>heap<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">heap_sort</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 先将待排序的序列建成大根堆，使得每个父节点的元素大于等于它的子节点</span>        self<span class="token punctuation">.</span>build_heap<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 将其与末尾元素交换，使末尾元素为最大值，然后再调整堆顶元素使得剩下的 n-1个元素仍为大根堆</span>            nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span>            self<span class="token punctuation">.</span>max_heapify<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sortArray</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>heap_sort<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        <span class="token keyword">return</span> nums<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h4><ol><li>分治的思想来对序列进行排序。对一个长为 n 的待排序的序列，我们将其分解成两个长度为n/2的子序列。</li><li>每次先递归调用函数使两个子序列有序，然后我们再线性合并两个有序的子序列使整个序列有序。</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">merge_sort</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> l <span class="token operator">==</span> r<span class="token punctuation">:</span>            <span class="token keyword">return</span>        mid <span class="token operator">=</span> <span class="token punctuation">(</span>l <span class="token operator">+</span> r<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>        self<span class="token punctuation">.</span>merge_sort<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> mid<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>merge_sort<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> r<span class="token punctuation">)</span>        tmp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        i<span class="token punctuation">,</span> j <span class="token operator">=</span> l<span class="token punctuation">,</span> mid <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">while</span> i <span class="token operator">&lt;=</span> mid <span class="token operator">or</span> j <span class="token operator">&lt;=</span> r<span class="token punctuation">:</span>            <span class="token keyword">if</span> i <span class="token operator">></span> mid <span class="token operator">or</span> <span class="token punctuation">(</span>j <span class="token operator">&lt;=</span> r <span class="token operator">and</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>                j <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                i <span class="token operator">+=</span> <span class="token number">1</span>        nums<span class="token punctuation">[</span>l<span class="token punctuation">:</span> r <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp    <span class="token keyword">def</span> <span class="token function">sortArray</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>merge_sort<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> nums<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="其他排序算法"><a href="#其他排序算法" class="headerlink" title="其他排序算法"></a><strong>其他排序算法</strong></h3><pre><code>// 希尔排序（40 ms）vector&lt;int&gt; shellSort(vector&lt;int&gt;&amp; nums) {    int n = nums.size();    for (int gap = n/2; gap &gt; 0; gap /= 2) {        for (int i = gap; i &lt; n; ++i) {            for (int j = i; j-gap &gt;= 0 &amp;&amp; nums[j-gap] &gt; nums[j]; j -= gap) {                swap(nums[j-gap], nums[j]);            }        }    }    return nums;}// 计数排序（32 ms）vector&lt;int&gt; countSort(vector&lt;int&gt;&amp; nums) {    int n = nums.size();    if (!n) return {};    int minv = *min_element(nums.begin(), nums.end());    int maxv = *max_element(nums.begin(), nums.end());    int m = maxv-minv+1;    vector&lt;int&gt; count(m, 0);    for (int i = 0; i &lt; n; ++i) {        count[nums[i]-minv]++;    }    vector&lt;int&gt; res;    for (int i = 0; i &lt; m; ++i) {        for (int j = 0; j &lt; count[i]; ++j) {            res.push_back(i+minv);        }    }    return res;}// 基数排序（不适用于负数）vector&lt;int&gt; radixSort(vector&lt;int&gt;&amp; nums) {    int n = nums.size();    int maxv = *max_element(nums.begin(), nums.end());    int maxd = 0;    while (maxv &gt; 0) {        maxv /= 10;        maxd++;    }    vector&lt;int&gt; count(10, 0), rank(n, 0);    int base = 1;    while (maxd &gt; 0) {        count.assign(10, 0);        for (int i = 0; i &lt; n; ++i) {            count[(nums[i]/base)%10]++;        }        for (int i = 1; i &lt; 10; ++i) {            count[i] += count[i-1];        }        for (int i = n-1; i &gt;= 0; --i) {            rank[--count[(nums[i]/base)%10]] = nums[i];        }        for (int i = 0; i &lt; n; ++i) {            nums[i] = rank[i];        }        maxd--;        base *= 10;    }    return nums;}// 桶排序 (20 ms)vector&lt;int&gt; bucketSort(vector&lt;int&gt;&amp; nums) {    int n = nums.size();    int maxv = *max_element(nums.begin(), nums.end());    int minv = *min_element(nums.begin(), nums.end());    int bs = 1000;    int m = (maxv-minv)/bs+1;    vector&lt;vector&lt;int&gt; &gt; bucket(m);    for (int i = 0; i &lt; n; ++i) {        bucket[(nums[i]-minv)/bs].push_back(nums[i]);    }    int idx = 0;    for (int i = 0; i &lt; m; ++i) {        int sz = bucket[i].size();        bucket[i] = quickSort(bucket[i]);        for (int j = 0; j &lt; sz; ++j) {            nums[idx++] = bucket[i][j];        }    }    return nums;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
