---
title: 网络
top: false
cover: false
toc: true
mathjax: true
date: 2021-05-20 06:20:37
password:
summary:
tags:
- interview
categories:
- interview
---



## 计算机网络体系结构

![](stru.png)

![](mode.png)

### OSI 7层

物理层：通过网线、光缆等这种物理方式将电脑连接起来。发送高低电平（电信号）

数据链路层：定义了电信号的分组方式。MAC地址的封装和解封装。

网路层：引入网络地址用来区分不同的广播域/子网，进行ip的封装和解封装

传输层：建立端口到端口的通信，接受到的数据进行分段处理,在进行组装

会话层：建立和断开客户端与服务端连接

表示层：数据格式转换。如编码、数据格式转换、加密解密、压缩解压

应用层：规定应用程序的数据格式

### 四层网络

- 链路层：负责封装和解封装IP报文，发送和接受ARP/RARP报文等。
- 网络层：负责路由以及把分组报文发送给目标网络或主机。
- 传输层：负责对报文进行分组和重组，并以TCP或UDP协议格式封装报文。
- 应用层：负责向用户提供应用程序，比如HTTP、FTP、Telnet、DNS、SMTP等。

###  为什么要分层？

1、易于实现、标准化、各层独立，就可以把大问题分割成多个小问题，利于实现；

2、灵活性好：如果某一层发生变化，只要接口不变，不会影响其他层；

3、分层后，用户只关心用到的应用层，其他层用户可以复用；

- 应用层：常见协议：
  - FTP（21端口）：文件传输协议
  - SSH（22端口）：远程登陆
  - TELNET（23端口）：远程登录
  - SMTP（25端口）：发送邮件
  - POP3（110端口）：接收邮件
  - HTTP（80端口）：超文本传输协议
  - DNS（53端口）：运行在UDP上，域名解析服务
  - DHCP
- 传输层：TCP/UDP
- 网络层：IP、NAT、RIP
- 链路层：VLAN、STP

- **在OSI模型中ARP协议属于链路层，而在TCP/IP模型中，ARP协议属于网络层**

**路由器、交换机位于哪一层？**


- 路由器网络层，根据IP地址进行寻址；
- 交换机数据链路层，根据MAC地址进行寻址
- 网桥：工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。

**ICMP协议到底属于哪一层**

icmp协议是IP层的附属协议，是介于IP层和TCP层之间的协议，一般认为属于IP层协议。

请求网络地址，地址中有大量带百分号的字符串IP协议用它来与其他主机或路由器交换错误报文和其他的一些网络情况。在ICMP包重携带了控制信息和故障恢复信息。主要用于路由器主机向其他路由器或者主机发送出错报文的控制信息。

### 为什么需要IP？MAC？

**需要 IP 地址**

如果我们只用 MAC 地址，路由器需要记住每个 MAC 地址所在的子网是哪一个，因此需要极大的内存

**需要Mac地址**

 IP 地址是要设备上线以后，才能根据他进入了哪个子网来分配的，在设备还没有 IP 地址的时候，我们还需要用 MAC 地址来区分不同的设备。

### TCP和IP的区别

IP协议：

因特网协议。IP协议规定了数据传输时的基本单元和格式。定义了数据包的递交办法和[路由选择](https://www.baidu.com/s?wd=路由选择&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)。位于网络层。

TCP协议：

TCP协议提供了可靠的面向对象的数据流传输服务的规则和约定。简单的说在TCP模式中，对方发一个数据包给你，你要发一个确认数据包给对方。通过这种确认来提供可靠性。位于传输层。

### 什么叫划分子网？

从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。

### 802.3x 工作在几层，为什么

IEEE 802.3是一个工作组  ，该工作组定义了有线以太网的物理层和数据链路层的介质访问控制 （MAC）。

MAC子层的数据封装所包括的主要内容有：数据封装分为发送数据封装和接收数据封装两部分，包括[成帧](https://baike.baidu.com/item/成帧)、编制和差错检测等功能。

### 负载均衡

#### **四层负载均衡**

主要通过报文中的**目标地址和端口**，也就是NAT，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器，主要工作也就是**转发**，因此只需要一个连接。

工作于OSI模型的传输层，它主要处理消息的传递，而不管消息的内容。**四层负载均衡只针对由上游服务发送和接收的网络包，而并不检查包内的具体内容是什么。**

#### **七层负载均衡**

通过报文中的真正有意义的**应用层内容**（比如url、参数、cookie、header等），再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

主作于OSI模型的应用层，它主要处理每条消息中的真正内容。 **一个七层负载均衡器终止网络传输并读取消息中的内容。它可以基于消息中内容( 比如URL或者cookie中的信息 )来做出负载均衡的决定。**之后，七层负载均衡器建立一个新的TCP连接来选择上游服务（或者再利用一个已经存在的TCP连接，通过 HTTP keepalives 的方式）并向这个服务发出请求

#### **https怎么实现负载均衡**

7层：nginx安装ssl证书，用户请求 --https–> nginx --http–> 应用

4层：用户请求–https-> 4层负载 --https-> 应用

#### **应用场景**

- 四层模式下这些SYN攻击（DOS/DDOS攻击）都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营
- 7层负载均衡，主要还是着重于应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。

#### 优缺点

性能：理论上4层要比7层快，因为7层代理需要解析数据包的具体内容，需要消耗额外的cpu

灵活性：由于4层代理用的是NAT，所以nginx不知道请求的具体内容，所以nginx啥也干不了。 用7层代理，可以根据请求内容（url，参数，cookie，请求头）做很多事情，比如：动态代理、风控、审计

#### 结论

由于现在机器cpu性能都很好，4层代理并没有明显的性能优势，而7层代理在业务层面优势明显，所以一般直接选择7层代理

#### nginx的轮询算法

- 轮询算法
- 权重轮询
- 随机均衡
- 响应速度均衡：负载均衡向后端服务器发出一个探测请求,那个回应速度最快就使用哪个,
- 最少连接数
- 处理能力均衡:把请求分配给处理负荷最轻的服务器,适用于第七层负载均衡

## 报文头部

### 网络包的格式  

MAC头+IP头+TCP头+HTTP头+HTTP正文

### IP报文

![](ip.jpg)

（1） 版本号：IP协议的版本。对于IPv4来说值是4
（2） 头部长度：4位最大为0xF，注意该字段表示单位是字（4字节）
（3） 服务类型（Type Of Service，TOS）：3位优先权字段（现已被忽略） + 4位TOS字段 + 1位保留字段（须为0）。4位TOS字段分别表示最小延时、最大吞吐量、最高可靠性、最小费用，其中最多有一个能置为1。应用程序根据实际需要来设置 TOS值，如ssh和telnet这样的登录程序需要的是最小延时的服务，文件传输ftp需要的是最大吞吐量的服务
（4） 总长度: 指整个IP数据报的长度，单位为字节，即IP数据报的最大长度为65535字节（2的16次方）。由于MTU的限制，长度超过MTU的数据报都将被分片传输，所以实际传输的IP分片数据报的长度远远没有达到最大值

**下来的3个字段则描述如何实现分片:**
（5） 标识：唯一地标识主机发送的每一个数据报，其初始值是随机的，每发送一个数据报其值就加1。同一个数据报的所有分片都具有相同的标识值
（6） 标志: 位1保留，位2表禁止分片（DF），若设置了此位，IP模块将不对数据报进行分片，在此情况下若IP数据报超过MTU，IP模块将丢弃数据报并返回一个ICMP差错报文；位3标识更多分片（MF），除了数据报的最后一个分片，其他分片都要把它设置为1
（7） 位偏移：分片相对原始IP数据报数据部分的偏移。实际的偏移值为该值左移3位后得到的，所以除了最后一个IP数据报分片外，每个IP分片的数据部分的长度都必须是8的整数倍

（8） 生存时间：数据报到达目的地之前允许经过的路由器跳数。TTL值被发送端设置，常设置为64。数据报在转发过程中每经过一个路由该值就被路由器减1.当TTL值为0时，路由器就将该数据包丢弃，并向源端发送一个ICMP差错报文。TTL可以防止数据报陷入路由循环
（9） 协议： 区分IP协议上的上层协议。在Linux系统的/etc/protocols文件中定义了所有上层协议对应的协议字段，ICMP为1，TCP为6，UDP为17
（10） 头部校验和： 由发送端填充接收端对其使用CRC算法校验，检查IP数据报头部在传输过程中是否损坏
（11） 源IP地址和目的IP地址：表示数据报的发送端和接收端。一般情况下这两个地址在整个数据报传递过程中保持不变，不论中间经过多少个路由器。

### TCP

![](baowen.jpg)

- 源端口号和目标端口号，各16bit
- 包的序号（seq）：32 bits
- 确认序号（ack）：32 bits
- 状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。
- 窗口大小：接收窗口的大小，16 bits

### UDP

![UDP头](udp_header.png)

- 源端口（Source port）和目的端口（Destination port）
- 报文长度（Length）

16 bits，指示UDP报文（首部和数据）的总长度。16 bits，指示UDP报文（首部和数据）的总长度。最小8 bytes，只有首部，没有数据。最大值为65535 bytes。实际上，由于IPv4分组的最大数据长度为（65535 - 20 = 65515） bytes，UDP的报文长度不超过65515 bytes。

- 校验和（Checksum）

### TCP和UDP报文区别

TCP首部开销（20字节），UDP首部开销（8字节）

UDP 包的大小就应该是 `MTU1500 - IP头(20) - UDP头(8) = 1472(Bytes)`
TCP 包的大小就应该是 `MSS=MTU1500 - IP头(20) - TCP头(20) = 1460 (Bytes)`

> MTU： Maximum Transmit Unit，最大传输单元，即物理接口（数据链路层）提供给其上层（通常是IP层）最大一次传输数据的大小
>
> Maximum Segment Size ，TCP提交给IP层最大分段大小

### TCP校验怎么实现？

- 首先，把伪首部、TCP报头、TCP数据分为16位的字，如果总长度为奇数个字节，则在最后增添一个位都为0的字节。

- 把TCP报头中的校验和字段置为0（否则就陷入鸡生蛋还是蛋生鸡的问题）。

- 其次，用反码相加法累加所有的16位字（进位也要累加）。

- 最后，对计算结果取反，作为TCP的校验和。

  **如果接收方比对校验和与发送方一致，数据不一定传输成功。**

## 

## 网络层

### 什么是ARP协议 ？

Address Resolution Protocol

- **ARP协议完成了IP地址与物理地址的映射**。每一个主机都设有一个 ARP 高速缓存，里面有**所在的局域网**上的各主机和路由器的 IP 地址到硬件地址的映射表。
- 当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向**所在的局域网**发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射）
- 收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。
- 源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。
- 如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。

**在OSI模型中ARP协议属于链路层；而在TCP/IP模型中，ARP协议属于网络层。**

### IPv4怎么缓解地址不够？

NAT。通过使用少量的公有IP地址代表较多的私有IP地址的方式，将有助于减缓可用的IP地址空间的枯竭。

### IPv6和IPv4区别？

**地址长度不同**

IPv6的地址是IPv4的地址的四倍。IPv4的地址是32位，总数有43亿个左右；而IPv6的地址是128位的，大概是43亿的4次方。IPv4只有43亿个地址，远远不能让全球上百亿个设备都获得ip地址。

**地址的表示方法**

IPv4地址是以小数表示的二进制数。 IPv6地址是以十六进制表示的二进制数。

**IPv6 相比 IPv4 的首部改进**：

- 取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
- 取消了分片/重新组装相关字段。 分片与重组是耗时的过程， IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。
- 取消选项字段。 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的⾸部成为固定长度的 40 字节  

### IP寻址过程

**一、在同一个局域网内的两台主机**

1，A开始只知道B的IP地址 并不知道B的mac地址，而且二层交换机并不会按照IP地址转发数据

因此这时A会发一个ARP广播：我的IP是xxx，mac是XXX想知道IP为B的mac是多少 这个广播会被本局域网内所有主机收到 但是只有B会相应 并且向A回复一个ARP响应

2，交换机收到ARP广播后，将它转发到所有端口（网口），并且记录该广播源MAC地址（A的MAC地址）到mac地址列表B收到广播 发现和自己IP匹配 就会想A发送ARP响应

3，交换机收到B的响应 将响应帧目标MAC与自己mac地址表对比 发现对应的端口（网口是F0/1）便将响应帧转发到F0/1 同时 将响应帧的源mac地址B的MAC地址添加到mac地址列表

4，A收到B的回复帧后 ，得知B ip地址对应的mac地址 于是将信息保存到本地ARP高速缓存 同时以B的mac地址为目标地址封装成帧 发送出去 交换机再次收到A的数据 发现目标的MAC地址是B 对应端口（网口）F0/2 于是将帧转发到F0/2

5，B收到A发出的数据

**二、不在一个局域网**

1，由于 B 的 IP 地址并没有和 A 在一个网段，所以当 A 向 B 发送数据时， A 并不会直接把数据给 B ，而是交给自己的网关，所以 A 首先会 ARP 广播请求 网关 的 MAC 地址 A 得到网关的 MAC 地址后，以它为数据帧的目标 MAC 地址进行封装数据，并发送出去

2，Router1 收到该帧后，检查该帧的目标 IP ，并到自己的路由表查找如何到达该网段 发现能够到，并且下一跳地址是 routerB 的 s0 端口，于是将数据重新封装，将源地址改为 s0 端口 MAC 地址，目标 MAC 地址改为 router2 的 s0 端口 MAC 址址，并发送给 router2

3，中间 路由原理一样 

4，最后一个路由（routerN ）收到该帧，发现目标 IP 就在自己的直连网段，于是查看 ARP 缓存，如果找到该 IP 的 MAC 地址，则以该 MAC 地址封装数据发送出去，如果在 ARP 缓存没找到，则发出 ARP 广播，请求该 IP 的 MAC 地址，得到对应的 MAC 地址后，再发送给主机 B

### 路由器怎么转发

1、路由器收到一个数据包后，会检查其目的IP地址，然后**依据最长匹配原则查找路由表；**

2、如果**查找到匹配的路由表项**之后，路由器会根据该表项所指示的出接口信息和下一跳信息将数据包转发出去；

如果没有找到，会查找是否**有缺省路由**，找到的话会依据出接口信息和下一跳信息将数据包转发出去；

如果都没有找到，**数据包会被丢弃**；

### 什么是ICMP协议，它的作用是什么？

**互联网控制报文协议**。用在主机、路由器之间传递控制消息，控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。

ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。

ICMP 包头的**类型**字段，大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

### Ping的过程以及原理

 **使用ICMP查询报文**

- 源主机首先会构建一个 **ICMP 回送（Echo）请求消息**数据包
- 由 ICMP 协议将这个数据包交给 IP 层。IP 层将设置**目的地址**，**源地址**，**协议**字段设置为 `1` 表示是 `ICMP` 协议，再加上一些其他控制信息，构建一个 `IP` 数据包。
- 加入 `MAC` 头。如果在本地 ARP 映射表中存在出目标地址所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 `ARP` 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层设置MAC地址，构建一个数据帧，还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。
- 主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。
- 接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。
- 主机 `B` 会构建一个 **ICMP 回送（Echo）响应消息**数据包，回送响应数据包的**类型**字段为 `0`，**序号**为接收到的请求数据包中的序号，然后再发送出去给主机 A。
- 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。

### traceroute命令用处

traceroute是诊断网络问题时常用的工具。它可以定位从源主机到目标主机之间经过了哪些路由器，以及到达各个路由器的耗时。

**原理**

从源主机向目标主机发送IP数据报，并按顺序将TTL设置为从1开始递增的数字（假设为N），导致第N个节点（中间节点 or 目标主机）丢弃数据报并返回出错信息。源主机根据接收到的错误信息，确定到达目标主机路径上的所有节点的IP，以及对应的耗时。

### 什么是NAT ？

Network Address Translation, 网络地址转换，用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址。

### 什么是RIP? 

Routing Information Protocol, 距离矢量路由协议，每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。

**工作原理**： 路由器每30秒把自己的路由表发给邻居。路由器用邻居发来的路由表根据距离向量算法修改自己的路由表。初始时每个路由器只有到直连网距离为1的路由。

**优缺点**


- 实现简单，开销小
- 随着网络规模扩大开销也会增大；
- 最大距离为15，限制了网络的规模；
- 当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器

## 三次握手

![](woshou.jpg)

- 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。
- 客户端主动发起连接 SYN，发送的**序列号**是X，之后处于 SYN-SENT 状态。
- 服务端收到发起的连接，返回 SYN，序列号为Y，并且ACK 客户端的 SYN，ack的值为X+1，之后处于 SYN-RCVD 状态。
- 客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。
- 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。

### 客户端发送的SYN丢失

在TCP的可靠传输中，如果SYN包在传输的过程中**丢失**，此时Client段会触发**重传机制**，但是也不是无脑的一直重传过去，重传的次数是受限制的，可以通过 tcp_syn_retries 这个配置项来决定。

- 如果此时 tcp_syn_retries 的配置为3，如果过了1s还没有收到 Server 的回应，那么进行第一次的重传。
- 如果经过了2s没有收到Sever的响应进行第二次的重传，一直重传tcp_syn_retries次。
- 这里的重传三次，意味着当第一次发送SYN后，需要等待`1 +2 +4 +8`秒，如果还是没有响应，connect就会通过**ETIMEOUT**的错误返回。

### 为什么不是2次

服务器端的应答包不知道能不能到达客户端。这个时候 服务器端 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者客户端已经挂了都有可能。

如果仅是两次连接。可能出现**已失效的连接请求报文段又传到了服务器端**：

- 客户端发送完请报文发起连接，由于网络情况不好，服务器端延时很长时间后收到报文。客户端将此报文认定为失效的报文，因为中间可能已经建立连接并断开了。
- 服务器端收到报文后，会向客户端发起连接。此时两次握手完毕。
- 服务器端会认为已经建立了连接可以通信，服务器端会一直等到客户端发送的连接请求，而客户端对失效的报文回复自然不会处理。会陷入服务器端忙等的僵局，造成资源的浪费。

### 为什么不是4次

可以。但是会降低传输的效率。

四次握手是指：第二次握手：服务器端只发送ACK和acknowledge number；而服务器端的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。

### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？

Server端： 
由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。

Client端，两种情况：  

1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态  
2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。

### 初始序列号是什么？

TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；

同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。

###  序列号是随机取的吗？为什么？

1）攻击维度

如果TCP每次连接都使用固定ISN，黑客可以很方便模拟任何IP与server建立连接。

> 问题：通过抓包就可以计算出来TCP连接的ISN，那固定于不固定ISN有什么区别呢？
>
> 答：抓包只能发生在同一网络中，随机ISN能避免非同一网络的攻击

2）TCP连接稳定维度

广域网的随机性，复杂性都很高，假设clent与server连接状况不好，不停的断开。那么之前交互的报文很可能在连接已断但是还没到到server。

如果ISN是固定的，那很可能在新连接建立后，上次连接通信的报文才到达，这种情况有概率发生老报文的seq号正好是server希望收到的新连接的报文seq。这就全乱了

### accept connect listen对应三次握手什么阶段

当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听。  当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了  

客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。  内核会给客户端分配一个临时的端口。

一旦握手成功，服务端的 accept就会返回另一个 Socket。  

## 四次挥手

![](huishou.jpg)

- 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部FIN，其序列号为seq=u，客户端进入FIN-WAIT-1（终止等待1）状态。 
- 服务器收到连接释放报文，发出确认报文ACK，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

   - 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
- 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文FIN，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
- 客户端收到服务器的连接释放报文后，必须发出确认，ACK，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，才进入CLOSED状态。
     - 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。

### 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

客户端没有收到ACK确认，会重新发送FIN请求。

### 客户端TIME_WAIT状态的意义是什么？

第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。

MSL（Maximum Segment Lifetime），指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

### 2MSL作用

- 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。

- 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

超过了 2MSL ，依然没有收到FIN 的 ACK，重发 FIN，A 发送 RST，B 就知道 A 早就跑了。

### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？

建立连接的时候， 服务器收到SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以需要等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。

服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

### 服务端出现大量close_wait原因

如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后，服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。

会导致to many open files。

### 服务器保持了大量TIME_WAIT状态

一些爬虫服务器或者WEB服务器上经常会遇到这个问题，在完成一个爬取任务之后，他就 会发起主动关闭连接，从而进入TIME_WAIT的状态，然后在保持这个状态2MSL时间之后，彻底关闭回收资源。

解决方法：优化系统参数

```
#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭 
net.ipv4.tcp_tw_reuse = 1 

#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 
net.ipv4.tcp_tw_recycle = 1 
```

## 流量控制

### TCP如何实现流量控制？

![滑动窗口](huadong.png)

使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。

接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。

发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。

发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。

### 什么是零窗口（接收窗口为0时会怎样）？

如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。

### TCP的拥塞控制是怎么实现的？

拥塞控制主要由四个算法组成：**慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）**

1. 慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍

2. 拥塞避免：当拥塞窗口的大小达到慢开始门限时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.  

> 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。**（这是不使用快重传的情况）**

3. 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出**重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
4. 快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。 

### 慢启动对HTTP有什么影响？HTTP如何解决这种影响？

建立TCP连接都会受到慢启动影响，HTTP是短连接一次会话结束就会断开，可以想象客户端发起HTTP请求刚获取完web页面上的一个资源，HTTP就断开，有可能还没有经历完TCP慢启动过程这个TCP连接就断开了，所以为了提升性能，我们可以开启HTTP的持久连接也就是后面要说的keepalive。

### HTTP对TCP的缺点做了那些改进？

最常见的影响HTTP性能的包括：

- TCP连接建立，也就是三次握手阶段
- TCP慢启动
- TCP延迟确认
- Nagle算法

> - HTTP的keep alive，实现连接复用
>
> - 对于HTTP来说我们可以关闭或者调整TCP延迟确认。
> - 可以在操作系统上禁用或者在HTTP程序中设置TCP_NODELAY来禁用Nagle算法

### TCP如何最大利用带宽？

TCP速率受到三个因素影响

- 窗口：即滑动窗口大小，见[TCP如何实现流量控制？](#TCP如何实现流量控制)
- 带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。
- RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。

## TCP与UDP

### TCP与UDP的区别

1. TCP是面向连接的，UDP是无连接的；
2. TCP是可靠的，UDP不可靠；
3. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；
4. TCP是面向字节流的，UDP是面向报文的；
5. TCP有拥塞控制机制，UDP没有。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天。
6. TCP首部开销（20字节）比UDP首部开销（8字节）要大

>1：UDP发送数据之前不需要建立连接
>
>2：UDP接收方收到报文后，不需要给出任何确认
>
>4；面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。
>
>5：TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；

### 什么时候选择TCP，什么时候选UDP？

对某些实时性要求比较高的情况，选择UDP，比如游戏，媒体通信，实时视频流（直播），即使出现传输错误也可以容忍；其它大部分情况下，HTTP都是用TCP，因为要求传输的内容可靠，不出现丢失

### TCP报文确认机制

为了保证顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答

### TCP发数据过程中必须按顺序接收吗

TCP报文段作为IP数据来传输，在IP数据报的到达可能会失序，因此TCP报文段的到达也存在失序的可能。特殊情况下，TCP将对收到的数据进行重新排列，确保顺序正确后再交给应用层。

### TCP发送窗口过大会怎么样？

接收端缓存溢出或者网络拥塞

### 为什么会发生网络卡顿现象？

拥塞的一种表形式是丢包，需要超时重传。就把慢开始门限减半，然后执行拥塞避免算法。

> 当拥塞窗口的大小达到慢开始门限时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.  

### TCP粘包

#### 什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾。

#### 造成TCP粘包的原因

（1）发送方原因

TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

- 只有上一个分组得到确认，才会发送下一个分组

- 收集多个小分组，在一个确认到来时一起发送

  Nagle算法造成了发送方可能会出现粘包问题

（2）接收方原因

TCP接收到数据包时，应用层并不会立即处理。数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

#### 什么时候需要处理粘包现象？

- 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象
- 如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了

#### 如何处理粘包现象？

（1）发送方

对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

（2）应用层

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据。

### TCP 半包

#### 原因

- MSS/MTU限制
- 用程序写入数据的字节大小大于套接字发送缓冲区的大小

#### 应用层解决

（1）在包尾增加分割符，比如回车换行符进行分割。
（2）消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格
（3）将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段，而消息体实际实际要发送的二进制数据字节。

#### UDP会不会产生粘包问题呢？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。

### HTTP可以使用UDP吗？

HTTP不可以使用UDP，HTTP需要基于可靠的传输协议，而UDP不可靠

### UDP协议应用

- DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到IP 又没事，过一会儿还有机会。
- PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。  

### UDP可以实现可靠吗？

传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。

 实现确认机制、重传机制、。

### 如何在应用层保证udp可靠传输

最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理时：

- 1、实现确认机制，确保数据发送到对端
- 2、实现发送和接收缓冲区，主要是用户超时重传。
- 3、实现超时重传机制。

详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。


### 面向连接和无连接的区别

在互通之前，面向连接的协议会先建立连接。例如，TCP 会三次握手，而 UDP 不会。所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态， 用这样的数据结构来保证所谓的面向连接的特性。

- 例如，TCP 提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。
- UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达。

### TCP如何保证传输的可靠性

1. 数据包校验
2. 对失序数据包重新排序（TCP报文具有序列号）
3. 丢弃重复数据
4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；
5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；或者是快速重传；
6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出
7. 拥塞控制：当网络拥塞时，减少数据的发送

> TCP校验和是一个端到端的校验和，由发送端计算，然后由接收端验证。其目的是为了发现TCP首部和数据在发送端到
>
> 接收端之间发生的任何改动。如果接收方检测到校验和有差错，则TCP段会被直接丢弃。
>
> TCP的校验和是必需的，而UDP的校验和是可选的。

### TCP keepalive实现原理

在TCP中有一个Keep-alive的机制可以检测死连接，原理很简单，TCP会在空闲了一定时间后发送数据给对方。

1.如果主机可达，对方就会响应ACK应答，就认为是存活的。
2.如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。
3.如果可达，但应用程序崩溃，对方就发FIN消息。

4.如果对方主机不响应ack/rst，继续发送直到超时，就撤消连接。这个时间就是默认的二个小时。

### TCP的延迟ACK机制？

接收方在收到数据后，并不会立即回复ACK,而是延迟一定时间。

- 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。
- 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。

### 对于tcp来说，服务端断电和进程挂掉有什么区别？

**服务进程crash**：服务端会发送RST报文

**进程结束：**服务端发送了一个FIN报文

**主机关机**：init进程会给所有进程发送SIGTERM信号，等待一段时间（5~20秒），然后再给所有仍在运行的进程发送SIGKILL信号。同进程结束。

**主机宕机**：服务器始终不能应答

**主机宕机后重启**：收到了一个根本不存在连接上的报文，所以会响应一个RST。

### 单机最大tcp连接数

系统用一个4四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}。

client最大tcp连接数：1-65535

server最大tcp连接数：客户端ip数×客户端port数，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数）。

实际的tcp连接数：在实际环境中，受到机器资源、操作系统等的限制。内存和允许的文件描述符个数。

### SYN泛洪攻击

  SYN攻击利用的是TCP的三次握手机制，攻击端利用伪造的IP地址向被攻击端发出请求，而被攻击端发出的响应报文将永远发送不到目的地，那么被攻击端在等待关闭这个连接的过程中消耗了资源，如果有成千上万的这种连接，主机资源将被耗尽，从而达到攻击的目的。

1、降低SYN timeout时间，使得主机尽快释放半连接的占用
2、采用SYN cookie设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文
3、一个有防火墙或者代理的设备在网络中就能够缓冲SYN洪泛攻击

### MSL、TTL和RTT的区别

- MSL 是Maximum Segment Lifetime英文的缩写，是“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
- ip头中有一个TTL域，TTL是 time to live的缩写，中文可以译为“生存时间”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。
- RTT是客户到服务器往返所花时间（round-trip time，简称RTT），表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。TCP含有动态估算RTT的算法。TCP还持续估算一个给定连接的RTT，这是因为RTT受网络传输拥塞程序的变化而变化。

### 多久没收到会丢失重传，往返时间怎么预估

**每个数据包都有相应的计时器**，一旦超过 RTO 而没有收到 ACK，就重发该数据包。

- 估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为自适应重传算法
- 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

### TCP和UDP可以同时监听相同的端口吗

可以。可以看到linux是以协议、ip、端口来绑定端口的，所以不同协议相同的ip和端口也是可以绑定成功的。

### udp怎么实现多对多

UDP套接字允许广播或多播。

- **本地广播信息是不会被路由器转发**。
- **广播还是要指明接收者的端口号的**

## QUIC

QUIC 在应用层上，基于UDP传输

### 自定义连接机制

QUIC 维护连接，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化
的时候，只要 ID 不变，就不需要重新建立连接。

避免了当手机信号不稳定或者在 WIFI 和移动网络切换时，导致重连，从而进行再次的三次握手。

### 自定义重传机制

QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。

发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。

### 无阻塞的多路复用

同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。

一个连接上的多个 stream 之间没有依赖。

假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。

### 自定义流量控制



## 应用层

### DNS

#### 解析流程

从客户端到本地DNS服务器属于递归查询，而DNS服务器之间是迭代查询。

- 电脑客户端会发出一个 DNS 请求，问 www.163.com 的 IP 是啥啊，并发给本地域名服务器。本地 DNS 由你的网络服务商，如电信、移动等自动分配，它通常就在你网络服务商的某个机房。
- 本地 DNS 收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应 IP 地址的大表格。如果能找到 www.163.com，它直接就返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大，能告诉我 www.163.com 的 IP 地址吗？”根域名服务器是最高层次的，全球共有 13 套。它不直接用于域名解析，但能指明一条道路。
- **根 DNS** 收到来自本地 DNS 的请求，发现后缀是 **.com**，说：“哦，www.163.com 啊，这个域名是由.com 区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。”
- 本地 DNS 转向问**顶级域名服务器**：“老二，你能告诉我 www.163.com 的 IP 地址吗？”顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org 这些一级域名，它负责管理二级域名，比如163.com，所以它能提供一条更清晰的方向。
- 顶级域名服务器说：“我给你负责 www.163.com 区域的**权威 DNS 服务器**的地址，你去问它应该能问到。”
- 本地 DNS 转向问权威 DNS 服务器：“您好，www.163.com 对应的 IP 是啥呀？”163.com 的权威 DNS 服务器，它是域名解析结果的原出处。
- 权限 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
- 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接

#### 如果dns解析得到ip地址之后请求超时，那么会重新解析吗

浏览器就得到了域名对应的 IP 地址，并将 IP 地址缓存起来。不需要

#### DNS使用的是TCP协议还是UDP协议

**区域传送时使用TCP**： 
1.辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为**数据同步传送的数据量比一个请求和应答的数据量要多得多**。 
2.TCP是一种可靠的连接，**保证了数据的准确性**。 

**域名解析时使用UDP协议**： 
客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。**不用经过TCP三次握手，这样DNS服务器负载更低，响应更快**。虽然从理论上说，客户端也可以指定向DNS服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。

DNS 查询选择 UDP 或者 TCP 两种不同协议时的主要原因：

- UDP 协议
  - DNS 查询的数据包较小、机制简单；
  - UDP 协议的额外开销小、有着更好的性能表现；
- TCP 协议
  - DNS 查询由于 DNSSEC 和 IPv6 的引入迅速膨胀，导致 DNS 响应经常超过 MTU 造成数据的分片和丢失，我们需要依靠更加可靠的 TCP 协议完成数据的传输；
  - 随着 DNS 查询中包含的数据不断增加，TCP 协议头以及三次握手带来的额外开销比例逐渐降低，不再是占据总传输数据大小的主要部分；

#### 根DNS服务器如何承受并发

先访问DNS缓存、本地DNS服务器。同时有13台根DNS服务器作负载均衡。根DNS服务器只存储一级域名的映射，实际不做域名的解析。

#### DNS劫持是什么

域名劫持，DNS重定向（DNS direaction）,是一种DNS攻击方式。即是DNS查询没有得到正确的解析，以致引导user访问到恶意的网站，从而窃取用户隐私，或者进行某些恶意的操作。

#### DNS的防范劫持

**1.加强本地计算机病毒检查，开启防火墙等，防止恶意软件，木马病毒感染计算机**

**2.改变路由器默认密码，防止攻击者修改路由器的DNS配置指向恶意的DNS服务器**

**3.手动修改DNS，host文件，dns服务器IP**

#### DNS缺点

 **域名缓存问题**：本地做一个缓存，直接返回缓存数据。可能会导致全局负载均衡失败，因为上次进行的缓存，不一定是这次离客户最近的地方，可能会绕远路。

**出口NAT问题**：做了网络地址转化后，权威的DNS服务器，没法通过地址来判断客户到底是哪个运营商，极有可能误判运营商，导致跨运营商访问。

**解析延迟**：DNS的查询过程需要递归遍历多个DNS服务器，才能获得最终结果。可能会带来一定的延时。

**域名转发问题**：如果是A运营商将解析的请求转发给B运营商，B去权威DNS服务器查询的话，权威服务器会认为你是B运营商的，就返回了B运营商的网站地址，结果每次都会跨运营商。

### HTTPDNS

HTTPDNS使用HTTP与DNS服务器交互，代替传统的基于UDP的DNS协议，域名解析请求直接发送到HTTPDNS服务端，从而绕过运营商的Local DNS

#### 特性

**防止域名劫持**

由于 HttpDns 是通过 IP 直接请求 HTTP 获取服务器 A 记录地址，不存在向本地运营商询问 domain 解析过程，所以从根本避免了劫持问题。

**精准调度**

由于 DNS 服务器端获取的是真实客户端 IP 而非 Local DNS 的 IP，HTTPDNS能够直接获取到用户的IP地址，从而实现精确定位与导流

**用户连接失败率下降**

通过算法降低以往失败率过高的服务器排序，通过历史访问成功记录提高服务器排序。

### FTP

文件传输协议（File Transfer Protocol，FTP）是用于在网络上进行文件传输的一套标准协议，它工作在 OSI 模型的第七层， TCP 模型的第四层， 即应用层， 使用 TCP 传输而不是 UDP， 客户在和服务器建立连接前要经过一个“三次握手”的过程， 保证客户与服务器之间的连接是可靠的， 而且是面向连接， 为数据传输提供可靠保证。

#### **Port模式**

FTP 客户端首先和服务器的TCP 21端口建立连接，用来发送命令，客户端需要接收数据的时候在这个通道上发送PORT命令。

**PORT命令包含了客户端用什么端口接收数据。**在传送数据的时候，**服务器端通过自己的TCP 20端口连接至客户端的指定端口发送数据。**

FTP server必须和客户端**建立一个新的连接**用来传送数据。

#### **Passive模式**

建立连接后发送Pasv命令。服务器收到Pasv命令后，**打开一个临时端口**（端口号大于1023小于65535）并且**通知客户端在这个端口上传送数据的请求**，客户端连接FTP服务器此端口，然后FTP服务器将通过这个端口传送数据。

### SSH

SSH是一种网络协议，用于计算机之间的加密登录。SSH之所以能够保证安全，原因在于它采用了公钥加密。

整个过程是这样的：

（1）远程主机收到用户的登录请求，把自己的公钥发给用户。

（2）用户使用这个公钥，将登录密码加密后，发送回来。

（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。

如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。

#### 中间人攻击

#### 口令登录

确认host主机的真实性：首次连接确认公钥指纹。

#### 公钥登录

不需要输入密码。

就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。



## 路由协议

路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；

动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和OSPF 协议。

### 简述OSPF协议的工作原理

使用Dijikstra最短路径算法，使用分布式的链路状态协议。

 路由器互相发送直接相连的链路信息和它拥有的到其它路由器的链路信息。每个 OSPF 路由器维护相同自治系统拓扑结构的数据库。从这个数据库里，构造出最短路径树来计算出路由表。当拓扑结构发生变化时，OSPF 能迅速重新计算出路径，而只产生少量的路由协议流量。此外，所有 OSPF 路由选择协议的交换都是经过身份验证的。

## 加密算法

### DES加密算法

DES（Data Encryption Standard）数据加密标准算法，是一种双向加密算法，也是对称性加密算法。

工作原理：当需要加密的时候就用key对 data加密，生成密码形式的data作为输出结果，解密就需要再利用key对data进行解密获得原文密码作为输出。

### MD5加密算法

Message-Digest-Algorithm 信息摘要算法第五代。属于Hash算法一代，是一种单向加密算法，可以将输入的信息加密转换为128位固定长度的散列值，用于检验数据传输过程中的完整性。

**优势：**

- 防止被篡改，在传输过程中一旦被串改，那么计算出的MD5值一定不同。
- 计算速度快。加密速度快，不需要秘钥。
- 检查文件的完整性，一旦文件被更改，MD5值也是不同的。
- 防止抵赖，用于数字签名，一旦用户的文件被第三方MD5加密，若以后A说这个文件不是他写的，那么当用文件MD5后获得的签名一致，可以确认。

**缺点:**

- 作为一种散列算法，虽然很难发生散列碰撞，但是经过证实，仍然存在两种不同数据会发生碰撞。
- MD5的安全性：将用户的密码直接MD5后存储在数据库是不安全的。第一，用户普遍习惯用容易记忆的密码，生日，手机号等，**黑客容易破译此类密码。这也是加盐值的一个原因。**第二，直接MD5存入数据库，**若数据库被破解，通过MD5反查会查到密码，需要随机盐值的配合。**
- 考虑到多数人所使用的密码为常见的组合，攻击者可以将所有密码的常见组合进行单向哈希，得到一个摘要组合，然后与数据库中的摘要进行比对即可获得对应的密码。这个摘要组合也被称为rainbow table。

### SHA1加密算法

SHA-1是一种数据加密算法，该算法的思想是接收一段明文，然后以一种不可逆的方式将它转换成一段（通常更小）密文，也可以简单的理解为取一串输入码（称为预映射或信息），并把它们转化为长度较短、位数固定的输出序列即散列值（也称为信息摘要或信息认证代码）的过程。

### RSA加密算法

RSA是一种非对称加密算法。目前最有影响力的公钥加密算法，该算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，**因此可以将乘积公开作为加密密钥，即公钥，而两个大素数组合成私钥。公钥是可发布的供任何人使用，私钥则为自己所有，供解密之用。**

 解密者拥有私钥，并且将由私钥计算生成的公钥发布给加密者。加密都使用公钥进行加密，并将密文发送到解密者，解密者用私钥解密将密文解码为明文。

### 为什么密码加盐

Salt 可以是任意字母、数字、或是字母或数字的组合，但必须是随机产生的，每个用户的 Salt 都不一样，用户注册的时候，数据库中存入的不是明文密码，也不是简单的对明文密码进行散列，而是 MD5( 明文密码 + Salt)。

由于加了 Salt，即便数据库泄露了，但是由于密码都是加了 Salt 之后的散列，坏人们的数据字典已经无法直接匹配，明文密码被破解出来的概率也大大降低

## 为什么网络中会发生丢包？

**物理线路故障**

**设备故障**：如网卡是坏的，交换机的某个端口出现了物理故障，光模块等等。接收到的分组校验出错

**网络拥塞**：分组在网络中超出最大存活时间、路由器接收分组数量达到上限后，会丢弃多余分组

## 小端字节序和大端字节序，这个对什么产生影响，做什么事情会出现问题

- **大端字节序**：高位字节在前，低位字节在后，这是人类读写数值的方法。
- **小端字节序**：低位字节在前，高位字节在后

计算机电路先处理低位字节，效率比较高，因为计算都是从低位开始的。所以，计算机的内部处理大多是小端字节序。

但是，人类还是习惯读写大端字节序。所以，除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。

**只有读取的时候，才必须区分字节序，其他情况都不用考虑。**

## 传一个字符串，定义为大端和小端一样吗？如果传一个数字有影响吗？

大小端是面向多字节类型定义的，比如2字节、4字节、8字节整型、长整型、浮点型等，单字节的字符串一般不用考虑。

## 网卡接收数据流程

- **1：** 数据包从外面的网络进入物理网卡。如果目的地址不是该网卡（且该网卡没有开启混杂模式）该包会被网卡丢弃。
- **2：** 网卡将数据包通过DMA的方式写入到指定的内存地址，该地址由网卡驱动分配并初始化。
- **3：** 网卡通过硬件中断（IRQ）通知CPU，告诉它有数据来了
- **4：** CPU根据中断表，调用中断函数，中断函数会调用网卡驱动程序中相应的函数
- **5：** 先禁用网卡的中断，表示驱动程序已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知CPU了，这样可以提高效率，避免CPU不停的被中断。
- **6：** 启动软中断。这步结束后，硬件中断处理函数就结束返回了。（由于硬中断处理程序执行的过程中不能被中断，所以如果它执行时间过长，会导致CPU没法响应其它硬件的中断，于是内核引入软中断，这样可以将硬中断处理函数中耗时的部分移到软中断处理函数里面来慢慢处理。）
- **7：** 内核中的ksoftirqd进程专门负责软中断的处理，读取写到内存中的数据包
- **8：** 调用协议栈相应的函数，将数据包交给协议栈处理。
- 8.1：进入IP层，如果是目的IP不是本地IP， 进行路由；目的IP是本地IP，发送到UDP层
- 8.2：根据目的IP和端口找对应的socket，如果没有找到相应的socket，那么该数据包将会被丢弃，否则继续，通知socket数据包已经准备好
- 8.3：应用层一般有两种方式接收数据，一种是recvfrom函数阻塞在那里等着数据来，这种情况下当socket收到通知后，recvfrom就会被唤醒，然后读取接收队列的数据；另一种是通过epoll或者select监听相应的socket，当收到通知后，再调用recvfrom函数去读取接收队列的数据。
- **9：** 待内存中的所有数据包被处理完成后（即poll函数执行完成），启用网卡的硬中断，这样下次网卡再收到数据的时候就会通知CPU

## WebSocket 和 HTTP 的区别

- http 协议是用在应用层的协议，客户端与服务器通信，必须要有客户端发起然后服务器返回结果。客户端是主动的，服务器是被动的。 
- 为了解决客户端发起多个 http 请求到服务器资源浏览器必须要经过轮训问题，websocket实现了多路复用，他是全双工通信。在 webSocket 协议下客服端和浏览器可以同时发送信息。服务器已有主动权想什么时候发就可以发送信息到服务器。而且信息当中不必再带有 head 的部分信息了。

降低了服务器压力，减少了部分多余信息

## 参考

https://blog.csdn.net/weixin_41047704/article/details/85340311

https://blog.csdn.net/gdutxiaoxu/article/details/107393249

https://blog.csdn.net/weixin_38035852/article/details/81667160