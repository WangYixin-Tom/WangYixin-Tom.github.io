---
title: 网络
top: false
cover: false
toc: true
mathjax: true
date: 2021-05-20 06:20:37
password:
summary:
tags:
- interview
categories:
- interview
---



## 报文头部

### 网络包的格式  

MAC头+IP头+TCP头+HTTP头+HTTP正文

### IP报文

![](ip.jpg)

（1） 版本号：IP协议的版本。对于IPv4来说值是4
（2） 头部长度：4位最大为0xF，注意该字段表示单位是字（4字节）
（3） 服务类型（Type Of Service，TOS）：3位优先权字段（现已被忽略） + 4位TOS字段 + 1位保留字段（须为0）。4位TOS字段分别表示最小延时、最大吞吐量、最高可靠性、最小费用，其中最多有一个能置为1。应用程序根据实际需要来设置 TOS值，如ssh和telnet这样的登录程序需要的是最小延时的服务，文件传输ftp需要的是最大吞吐量的服务
（4） 总长度: 指整个IP数据报的长度，单位为字节，即IP数据报的最大长度为65535字节（2的16次方）。由于MTU的限制，长度超过MTU的数据报都将被分片传输，所以实际传输的IP分片数据报的长度远远没有达到最大值

**下来的3个字段则描述如何实现分片:**
（5） 标识：唯一地标识主机发送的每一个数据报，其初始值是随机的，每发送一个数据报其值就加1。同一个数据报的所有分片都具有相同的标识值
（6） 标志: 位1保留，位2表禁止分片（DF），若设置了此位，IP模块将不对数据报进行分片，在此情况下若IP数据报超过MTU，IP模块将丢弃数据报并返回一个ICMP差错报文；位3标识更多分片（MF），除了数据报的最后一个分片，其他分片都要把它设置为1
（7） 位偏移：分片相对原始IP数据报数据部分的偏移。实际的偏移值为该值左移3位后得到的，所以除了最后一个IP数据报分片外，每个IP分片的数据部分的长度都必须是8的整数倍

（8） 生存时间：数据报到达目的地之前允许经过的路由器跳数。TTL值被发送端设置，常设置为64。数据报在转发过程中每经过一个路由该值就被路由器减1.当TTL值为0时，路由器就将该数据包丢弃，并向源端发送一个ICMP差错报文。TTL可以防止数据报陷入路由循环
（9） 协议： 区分IP协议上的上层协议。在Linux系统的/etc/protocols文件中定义了所有上层协议对应的协议字段，ICMP为1，TCP为6，UDP为17
（10） 头部校验和： 由发送端填充接收端对其使用CRC算法校验，检查IP数据报头部在传输过程中是否损坏
（11） 源IP地址和目的IP地址：表示数据报的发送端和接收端。一般情况下这两个地址在整个数据报传递过程中保持不变，不论中间经过多少个路由器。

### TCP

![](baowen.jpg)

- 源端口号和目标端口号，各16bit
- 包的序号（seq）：32 bits
- 确认序号（ack）：32 bits
- 状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。
- 窗口大小：接收窗口的大小，16 bits

### UDP

![UDP头](udp_header.png)

- 源端口（Source port）和目的端口（Destination port）
- 报文长度（Length）

16 bits，指示UDP报文（首部和数据）的总长度。16 bits，指示UDP报文（首部和数据）的总长度。最小8 bytes，只有首部，没有数据。最大值为65535 bytes。实际上，由于IPv4分组的最大数据长度为（65535 - 20 = 65515） bytes，UDP的报文长度不超过65515 bytes。

- 校验和（Checksum）

### TCP和UDP报文区别

TCP首部开销（20字节），UDP首部开销（8字节）

UDP 包的大小就应该是 `MTU1500 - IP头(20) - UDP头(8) = 1472(Bytes)`
TCP 包的大小就应该是 `MSS=MTU1500 - IP头(20) - TCP头(20) = 1460 (Bytes)`

> MTU： Maximum Transmit Unit，最大传输单元，即物理接口（数据链路层）提供给其上层（通常是IP层）最大一次传输数据的大小
>
> Maximum Segment Size ，TCP提交给IP层最大分段大小

### TCP校验怎么实现？

- 首先，把伪首部、TCP报头、TCP数据分为16位的字，如果总长度为奇数个字节，则在最后增添一个位都为0的字节。

- 把TCP报头中的校验和字段置为0（否则就陷入鸡生蛋还是蛋生鸡的问题）。

- 其次，用反码相加法累加所有的16位字（进位也要累加）。

- 最后，对计算结果取反，作为TCP的校验和。

  **如果接收方比对校验和与发送方一致，数据不一定传输成功。**

## IP 

### IPv4怎么缓解地址不够？

NAT。通过使用少量的公有IP地址代表较多的私有IP地址的方式，将有助于减缓可用的IP地址空间的枯竭。

### IPv6和IPv4区别？

**地址长度不同**

IPv6的地址是IPv4的地址的四倍。IPv4的地址是32位，总数有43亿个左右；而IPv6的地址是128位的，大概是43亿的4次方。IPv4只有43亿个地址，远远不能让全球上百亿个设备都获得ip地址。

**地址的表示方法**

IPv4地址是以小数表示的二进制数。 IPv6地址是以十六进制表示的二进制数。

**IPv6 相比 IPv4 的首部改进**：

- 取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
- 取消了分片/重新组装相关字段。 分片与重组是耗时的过程， IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。
- 取消选项字段。 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的⾸部成为固定长度的 40 字节  

### IP寻址过程

**一、在同一个局域网内的两台主机**

1，A开始只知道B的IP地址 并不知道B的mac地址，而且二层交换机并不会按照IP地址转发数据

因此这时A会发一个ARP广播：我的IP是xxx，mac是XXX想知道IP为B的mac是多少 这个广播会被本局域网内所有主机收到 但是只有B会相应 并且向A回复一个ARP响应

2，交换机收到ARP广播后，将它转发到所有端口（网口），并且记录该广播源MAC地址（A的MAC地址）到mac地址列表B收到广播 发现和自己IP匹配 就会想A发送ARP响应

3，交换机收到B的响应 将响应帧目标MAC与自己mac地址表对比 发现对应的端口（网口是F0/1）便将响应帧转发到F0/1 同时 将响应帧的源mac地址B的MAC地址添加到mac地址列表

4，A收到B的回复帧后 ，得知B ip地址对应的mac地址 于是将信息保存到本地ARP高速缓存 同时以B的mac地址为目标地址封装成帧 发送出去 交换机再次收到A的数据 发现目标的MAC地址是B 对应端口（网口）F0/2 于是将帧转发到F0/2

5，B收到A发出的数据

**二、不在一个局域网**

1，由于 B 的 IP 地址并没有和 A 在一个网段，所以当 A 向 B 发送数据时， A 并不会直接把数据给 B ，而是交给自己的网关，所以 A 首先会 ARP 广播请求 网关 的 MAC 地址 A 得到网关的 MAC 地址后，以它为数据帧的目标 MAC 地址进行封装数据，并发送出去

2，Router1 收到该帧后，检查该帧的目标 IP ，并到自己的路由表查找如何到达该网段 发现能够到，并且下一跳地址是 routerB 的 s0 端口，于是将数据重新封装，将源地址改为 s0 端口 MAC 地址，目标 MAC 地址改为 router2 的 s0 端口 MAC 址址，并发送给 router2

3，中间 路由原理一样 

4，最后一个路由（routerN ）收到该帧，发现目标 IP 就在自己的直连网段，于是查看 ARP 缓存，如果找到该 IP 的 MAC 地址，则以该 MAC 地址封装数据发送出去，如果在 ARP 缓存没找到，则发出 ARP 广播，请求该 IP 的 MAC 地址，得到对应的 MAC 地址后，再发送给主机 B

### 路由器怎么转发

1、路由器收到一个数据包后，会检查其目的IP地址，然后**依据最长匹配原则查找路由表；**

2、如果**查找到匹配的路由表项**之后，路由器会根据该表项所指示的出接口信息和下一跳信息将数据包转发出去；

如果没有找到，会查找是否**有缺省路由**，找到的话会依据出接口信息和下一跳信息将数据包转发出去；

如果都没有找到，**数据包会被丢弃**；

## 三次握手

![](woshou.jpg)

- 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。
- 客户端主动发起连接 SYN，发送的**序列号**是X，之后处于 SYN-SENT 状态。
- 服务端收到发起的连接，返回 SYN，序列号为Y，并且ACK 客户端的 SYN，ack的值为X+1，之后处于 SYN-RCVD 状态。
- 客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。
- 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。

### 客户端发送的SYN丢失

在TCP的可靠传输中，如果SYN包在传输的过程中**丢失**，此时Client段会触发**重传机制**，但是也不是无脑的一直重传过去，重传的次数是受限制的，可以通过 tcp_syn_retries 这个配置项来决定。

- 如果此时 tcp_syn_retries 的配置为3，如果过了1s还没有收到 Server 的回应，那么进行第一次的重传。
- 如果经过了2s没有收到Sever的响应进行第二次的重传，一直重传tcp_syn_retries次。
- 这里的重传三次，意味着当第一次发送SYN后，需要等待`1 +2 +4 +8`秒，如果还是没有响应，connect就会通过**ETIMEOUT**的错误返回。

### 为什么不是2次

服务器端的应答包不知道能不能到达客户端。这个时候 服务器端 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者客户端已经挂了都有可能。

如果仅是两次连接。可能出现**已失效的连接请求报文段又传到了服务器端**：

- 客户端发送完请报文发起连接，由于网络情况不好，服务器端延时很长时间后收到报文。客户端将此报文认定为失效的报文，因为中间可能已经建立连接并断开了。
- 服务器端收到报文后，会向客户端发起连接。此时两次握手完毕。
- 服务器端会认为已经建立了连接可以通信，服务器端会一直等到客户端发送的连接请求，而客户端对失效的报文回复自然不会处理。会陷入服务器端忙等的僵局，造成资源的浪费。

### 为什么不是4次

可以。但是会降低传输的效率。

四次握手是指：第二次握手：服务器端只发送ACK和acknowledge number；而服务器端的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。

### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？

Server端： 
由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。

Client端，两种情况：  

1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态  
2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。

### 初始序列号是什么？

TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；

同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。

###  序列号是随机取的吗？为什么？

1）攻击维度

如果TCP每次连接都使用固定ISN，黑客可以很方便模拟任何IP与server建立连接。

> 问题：通过抓包就可以计算出来TCP连接的ISN，那固定于不固定ISN有什么区别呢？
>
> 答：抓包只能发生在同一网络中，随机ISN能避免非同一网络的攻击

2）TCP连接稳定维度

广域网的随机性，复杂性都很高，假设clent与server连接状况不好，不停的断开。那么之前交互的报文很可能在连接已断但是还没到到server。

如果ISN是固定的，那很可能在新连接建立后，上次连接通信的报文才到达，这种情况有概率发生老报文的seq号正好是server希望收到的新连接的报文seq。这就全乱了

### accept connect listen对应三次握手什么阶段

当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听。  当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了  

客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。  内核会给客户端分配一个临时的端口。

一旦握手成功，服务端的 accept就会返回另一个 Socket。  

## 四次挥手

![](huishou.jpg)

- 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部FIN，其序列号为seq=u，客户端进入FIN-WAIT-1（终止等待1）状态。 
- 服务器收到连接释放报文，发出确认报文ACK，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

   - 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
- 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文FIN，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
- 客户端收到服务器的连接释放报文后，必须发出确认，ACK，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，才进入CLOSED状态。
     - 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。

### 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

客户端没有收到ACK确认，会重新发送FIN请求。

### 客户端TIME_WAIT状态的意义是什么？

第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。

MSL（Maximum Segment Lifetime），指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

### 2MSL作用

服务端发送的FIN+ACK报文请求，客户端没有回应，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。

B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就就直接发送 RST，B 就知道 A 早就跑了。

### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？

建立连接的时候， 服务器收到SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以需要等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。

服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

### 服务端出现大量close_wait原因

如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后，服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。

会导致to many open files。

### 服务器保持了大量TIME_WAIT状态

一些爬虫服务器或者WEB服务器上经常会遇到这个问题，在完成一个爬取任务之后，他就 会发起主动关闭连接，从而进入TIME_WAIT的状态，然后在保持这个状态2MSL时间之后，彻底关闭回收资源。

解决方法：优化系统参数

```
#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭 
net.ipv4.tcp_tw_reuse = 1 

#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 
net.ipv4.tcp_tw_recycle = 1 
```

## 流量控制

### TCP如何实现流量控制？

![滑动窗口](huadong.png)

使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。

接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。

发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。

### 什么是零窗口（接收窗口为0时会怎样）？

如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。

### TCP的拥塞控制是怎么实现的？

拥塞控制主要由四个算法组成：**慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）**

1. 慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍

2. 拥塞避免：当拥塞窗口的大小达到慢开始门限时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.  

> 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。**（这是不使用快重传的情况）**

3. 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出**重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
4. 快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。 

### 慢启动对HTTP有什么影响？HTTP如何解决这种影响？

建立TCP连接都会受到慢启动影响，HTTP是短连接一次会话结束就会断开，可以想象客户端发起HTTP请求刚获取完web页面上的一个资源，HTTP就断开，有可能还没有经历完TCP慢启动过程这个TCP连接就断开了，所以为了提升性能，我们可以开启HTTP的持久连接也就是后面要说的keepalive。

### HTTP对TCP的缺点做了那些改进？

最常见的影响HTTP性能的包括：

- TCP连接建立，也就是三次握手阶段
- TCP慢启动
- TCP延迟确认
- Nagle算法

> - HTTP的keep alive，实现连接复用
>
> - 对于HTTP来说我们可以关闭或者调整TCP延迟确认。
> - 可以在操作系统上禁用或者在HTTP程序中设置TCP_NODELAY来禁用Nagle算法

### TCP如何最大利用带宽？

TCP速率受到三个因素影响

- 窗口：即滑动窗口大小，见[TCP如何实现流量控制？](#TCP如何实现流量控制)
- 带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。
- RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。

## TCP与UDP

### TCP与UDP的区别

1. TCP是面向连接的，UDP是无连接的；
2. TCP是可靠的，UDP不可靠；
3. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；
4. TCP是面向字节流的，UDP是面向报文的；
5. TCP有拥塞控制机制，UDP没有。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天。
6. TCP首部开销（20字节）比UDP首部开销（8字节）要大

>1：UDP发送数据之前不需要建立连接
>
>2：UDP接收方收到报文后，不需要给出任何确认
>
>4；面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。
>
>5：TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；

### 什么时候选择TCP，什么时候选UDP？

对某些实时性要求比较高的情况，选择UDP，比如游戏，媒体通信，实时视频流（直播），即使出现传输错误也可以容忍；其它大部分情况下，HTTP都是用TCP，因为要求传输的内容可靠，不出现丢失

### TCP报文确认机制

为了保证顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答

### TCP发数据过程中必须按顺序接收吗

TCP报文段作为IP数据来传输，在IP数据报的到达可能会失序，因此TCP报文段的到达也存在失序的可能。特殊情况下，TCP将对收到的数据进行重新排列，确保顺序正确后再交给应用层。

### TCP发送窗口过大会怎么样？

接收端缓存溢出或者网络拥塞

### 为什么会发生网络卡顿现象？

拥塞的一种表形式是丢包，需要超时重传。就把慢开始门限减半，然后执行拥塞避免算法。

> 当拥塞窗口的大小达到慢开始门限时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.  

### TCP粘包

#### 什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾。

#### 造成TCP粘包的原因

（1）发送方原因

TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

- 只有上一个分组得到确认，才会发送下一个分组

- 收集多个小分组，在一个确认到来时一起发送

  Nagle算法造成了发送方可能会出现粘包问题

（2）接收方原因

TCP接收到数据包时，应用层并不会立即处理。数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

#### 什么时候需要处理粘包现象？

- 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象
- 如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了

#### 如何处理粘包现象？

（1）发送方

对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

（2）应用层

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据。

### TCP 半包

#### 原因

- MSS/MTU限制
- 用程序写入数据的字节大小大于套接字发送缓冲区的大小

#### 应用层解决

（1）在包尾增加分割符，比如回车换行符进行分割。
（2）消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格
（3）将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段，而消息体实际实际要发送的二进制数据字节。

#### UDP会不会产生粘包问题呢？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。

### HTTP可以使用UDP吗？

HTTP不可以使用UDP，HTTP需要基于可靠的传输协议，而UDP不可靠

### UDP协议应用

- DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到IP 又没事，过一会儿还有机会。
- PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。  

### UDP可以实现可靠吗？

传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。

 实现确认机制、重传机制、。

### 如何在应用层保证udp可靠传输

最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理时：

- 1、实现确认机制，确保数据发送到对端
- 2、实现发送和接收缓冲区，主要是用户超时重传。
- 3、实现超时重传机制。

详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。


### 面向连接和无连接的区别

在互通之前，面向连接的协议会先建立连接。例如，TCP 会三次握手，而 UDP 不会。所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态， 用这样的数据结构来保证所谓的面向连接的特性。

- 例如，TCP 提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。
- UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达。

### TCP如何保证传输的可靠性

1. 数据包校验
2. 对失序数据包重新排序（TCP报文具有序列号）
3. 丢弃重复数据
4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；
5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；或者是快速重传；
6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出
7. 拥塞控制：当网络拥塞时，减少数据的发送

> TCP校验和是一个端到端的校验和，由发送端计算，然后由接收端验证。其目的是为了发现TCP首部和数据在发送端到
>
> 接收端之间发生的任何改动。如果接收方检测到校验和有差错，则TCP段会被直接丢弃。
>
> TCP的校验和是必需的，而UDP的校验和是可选的。

### TCP keepalive实现原理

在TCP中有一个Keep-alive的机制可以检测死连接，原理很简单，TCP会在空闲了一定时间后发送数据给对方。

1.如果主机可达，对方就会响应ACK应答，就认为是存活的。
2.如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。
3.如果可达，但应用程序崩溃，对方就发FIN消息。

4.如果对方主机不响应ack/rst，继续发送直到超时，就撤消连接。这个时间就是默认的二个小时。

### TCP的延迟ACK机制？

接收方在收到数据后，并不会立即回复ACK,而是延迟一定时间。

- 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。
- 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。

### 对于tcp来说，服务端断电和进程挂掉有什么区别？

**服务进程crash**：服务端会发送RST报文

**进程结束：**服务端发送了一个FIN报文

**主机关机**：init进程会给所有进程发送SIGTERM信号，等待一段时间（5~20秒），然后再给所有仍在运行的进程发送SIGKILL信号。同进程结束。

**主机宕机**：服务器始终不能应答

**主机宕机后重启**：收到了一个根本不存在连接上的报文，所以会响应一个RST。

### 单机最大tcp连接数

系统用一个4四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}。

client最大tcp连接数：1-65535

server最大tcp连接数：客户端ip数×客户端port数，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数）。

实际的tcp连接数：在实际环境中，受到机器资源、操作系统等的限制。内存和允许的文件描述符个数。

### SYN泛洪攻击

  SYN攻击利用的是TCP的三次握手机制，攻击端利用伪造的IP地址向被攻击端发出请求，而被攻击端发出的响应报文将永远发送不到目的地，那么被攻击端在等待关闭这个连接的过程中消耗了资源，如果有成千上万的这种连接，主机资源将被耗尽，从而达到攻击的目的。

1、降低SYN timeout时间，使得主机尽快释放半连接的占用
2、采用SYN cookie设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文
3、一个有防火墙或者代理的设备在网络中就能够缓冲SYN洪泛攻击

### MSL、TTL和RTT的区别

- MSL 是Maximum Segment Lifetime英文的缩写，是“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
- ip头中有一个TTL域，TTL是 time to live的缩写，中文可以译为“生存时间”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。
- RTT是客户到服务器往返所花时间（round-trip time，简称RTT），表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。TCP含有动态估算RTT的算法。TCP还持续估算一个给定连接的RTT，这是因为RTT受网络传输拥塞程序的变化而变化。

### 多久没收到会丢失重传，往返时间怎么预估

**每个数据包都有相应的计时器**，一旦超过 RTO 而没有收到 ACK，就重发该数据包。

- 估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为自适应重传算法
- 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

### TCP和UDP可以同时监听相同的端口吗

可以。可以看到linux是以协议、ip、端口来绑定端口的，所以不同协议相同的ip和端口也是可以绑定成功的。

## HTTP和HTTPS

### 什么是HTTP

Hyper Text Transfer Protocol（超文本传输协议），是用于从万维网 服务器传输超文本到本地浏览器的传送协议。

HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。属于TCP上层的协议，但是本身并无会话的特点，它是一个基于请求/响应模式的、无状态的协议，以一问一答的方式实现服务。

### 什么是 https

简单来说， https 是 http + ssl，对 http 通信内容进行加密，是HTTP的安全版，是使用TLS/SSL加密的HTTP协议

Https的作用：

- 内容加密 建立一个信息安全通道，来保证数据传输的安全；
- 身份认证 确认网站的真实性
- 数据完整性 防止内容被第三方冒充或者篡改

### 什么是SSL

通过Web创建安全的Internet通信。它是一种标准协议，用于加密浏览器和服务器之间的通信。它允许通过Internet安全轻松地传输账号密码、银行卡、手机号等私密信息。

SSL证书就是遵守SSL协议，由受信任的CA机构颁发的数字证书。

### HTTP和HTTPS区别？

1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；
2. HTTP信息是明文传输，HTTPS运行在SSL（Secure Socket Layer）之上，添加了加密和认证机制，更加安全；
3. HTTPS由于加密解密会带来更大的CPU和内存开销；
4. HTTPS通信需要证书，一般需要向CA购买
5. HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。

### HTTP为什么基于TCP？

http协议只定义了应用层的东西，下层的可靠性要传输层来保证，只要是可以保证可靠性传输层协议都可以承载http，比如有基于sctp的http实现。 http也不是不能通过udp承载，在手机上就有人自己开发基于reliable udp的http协议，不过都是非标准的

### http1.0 1.1 2.0 的区别

#### HTTP 1.1

- **缓存处理**，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

- **带宽优化及网络连接的使用**，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

- **错误通知的管理**，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

- **Host头处理**，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
- **长连接**，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

#### HTTP 2.0

**HTTP2.0的多路复用**
浏览器对同一域名下的并发连接数量有限制，一般为6个，HTTP1中的Keep-Alive用于长连接而不必重新建立连接，然而keep-alive必须等本次请求彻底完成后才能发送下一个请求，而HTTP2的请求与响应以二进制帧的形式交错进行，只需建立一次连接，即一轮三次握手，实现多路复用
**HTTP2.0压缩消息头**
HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key value在两端建立一个索引表，对相同的头只发送索引表中的索引。

**HTTP2.0服务端推送**
HTTP2.0中服务器会主动将资源推送给客户端，例如把js和css文件主动推送给客户端而不用客户端解析HTML后请求再响应。

### **HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？**

- HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；
- HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；默认是 **keep-alive** 的，即tcp连接可以**复用**，不用每次都要重新建立和断开 TCP 连接。
- HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；

### 浏览器对同一 Host 建立 TCP 连接到数量有没有限制？

有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接，不同的浏览器有一些区别。

### Https的连接过程？

![](https.png)

#### 证书验证阶段

- 浏览器发起请求，请求携带了浏览器支持的加密算法和哈希算法
- 服务器接收到请求之后，选择浏览器支持的加密算法和哈希算法，会返回证书，包括公钥
- 浏览器接收到证书之后，使用公钥解密，会检验证书是否合法（网站的网址、网站的公钥、证书的有效期），不合法的话，会弹出告警提示

#### 数据传输阶段

证书验证合法之后

- 浏览器会生成一个随机数，
- 使用公钥进行加密，发送给服务端
- 服务器收到浏览器发来的值，使用私钥进行解密，得到随机数
- 解析成功之后，使用随机数为秘钥的对称加密算法进行加密，传输给客户端

之后双方通信就使用第一步生成的随机数进行加密通信。

### https为什么要采用对称和非对称加密结合的方式

非对称加密在性能上不如对称加密，  对称加密安全性比较低。

所以公钥私钥主要用于传输对称加密的秘钥，而真正的双方大数据量的通信都是通过对称加密进行的。  

### 什么是中间人攻击

中间人攻击是指攻击者与通讯的两端分别创建独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方直接对话，但事实上整个会话都被攻击者完全控制。

> HTTPS 使用了 SSL 加密协议，是一种非常安全的机制，目前并没有方法直接对这个协议进行攻击，一般都是在建立 SSL 连接时，拦截客户端的请求，利用中间人获取到 CA证书、非对称加密的公钥、对称加密的密钥；有了这些条件，就可以对请求和响应进行拦截和篡改。

### https 是如何防止中间人攻击的

在https中需要证书，证书的作用是为了防止"中间人攻击"的。 如果有个中间人M拦截客户端请求,然后M向客户端提供自己的公钥，M再向服务端请求公钥,作为"中介者" 这样客户端和服务端都不知道,信息已经被拦截获取了。

这时候就需要证明服务端的公钥是正确的.证明就需要权威第三方机构CA来公正了。

### 浏览器是如何确保CA证书的合法性？

**证书包含什么信息？**

颁发机构信息、公钥、公司信息、域名、有效期、指纹…

**浏览器如何验证证书的合法性？**

- 验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；
- 判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；
- 判断证书是否被篡改。需要与CA服务器进行校验；
- 判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与CA服务器的交互，提高验证效率。

### https 可以抓包吗

常规下抓包工具代理请求后抓到的包内容是加密状态，无法直接查看。

但是，我们可以通过抓包工具来抓包。它的原理其实是模拟一个中间人。

通常 HTTPS 抓包工具的使用方法是会生成一个证书，用户需要手动把证书安装到客户端中，然后终端发起的所有请求通过该证书完成与抓包工具的交互，然后抓包工具再转发请求到服务器，最后把服务器返回的结果在控制台输出后再返回给终端，从而完成整个请求的闭环。


### 输入 xxx.com，怎么变成 https://www.xxx.com 的？

一种是原始的302跳转，服务器把所有的HTTP流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。
解决方法是引入HSTS机制，用户浏览器在访问站点的时候强制使用HTTPS。

### 什么是对称加密、非对称加密？区别是什么？

- 对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4
- 非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。私钥加密的信息，只有公钥才能解密  如：RSA
- 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）

**对称加密问题**

黑客一旦截获秘钥，它可以佯作不知，静静地等着你们两个交互。这时候互通的任何消息，它都能截获并且查看  。

**非对称加密**

私钥放在外卖网站这里，不会在互联网上传输，这样就能保证这个秘钥的私密性。

对应私钥的公钥，是可以在互联网上随意传播的，只要外卖网站把这个公钥给你，你们就可以愉快地互通了。  

客户端也需要有自己的公钥和私钥，并且客户端要把自己的公钥，给外卖网站。  

**数字证书**  

鉴别别人给你的公钥是对的。  包括公钥、证书的所有者 、CA签名、颁发者、签名算法。

### 数字签名、报文摘要的原理

- 发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。
- 摘要算法:MD5、SHA

**签名算法**

一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值得出原来的信息内容。在把信息发送出去时，把这个 Hash 值加密后，作为一个签名和信息一起发出去。 

 CA 用自己的私钥给外卖网站的公钥签名，就相当于给外卖网站背书，形成了外卖网站的证书。  

### http层的keep-alive

用于客户端告诉服务端，这个连接我还会继续使用，在使用完之后不要关闭。

在性能上对客户端和服务器端性能上有一定的提升。很少了TCP的三次握手和四次挥手，第二次传递数据就可以通过前一个连接直接进行数据交互了。

> 先发起连接断开的一方会在连接断开之后进入到TIME_WAIT的状态达到2MSL之久。如果没有开启HTTP的keep-alive，那么这个TIME_WAIT就会留在服务端，由于服务端资源是非常有限的，我们当然倾向于服务端不会同一时间hold住过多的连接，这种TIME_WAIT的状态应该尽量在客户端保持。
>
> 在HTTP1.0和HTTP1.1协议中都有对KeepAlive的支持。**其中HTTP1.0需要在request中增加"Connection： keep-alive" header才能够支持，而HTTP1.1默认支持**。

### HTTP如何保持长连接？

a)Client发出request，其中该request的HTTP版本号为1.1。

b)Web Server收到request中的HTTP协议为1.1就认为是一个长连接请求，其将在response的header中也增加"Connection： keep-alive"。同时不会关闭已建立的tcp连接。

c)Client收到Web Server的response中包含"Connection： keep-alive"，就认为是一个长连接，不close tcp连接。并用该tcp连接再发送request。

### 一个TCP支持多少个HTTP请求？

在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。所以，一个TCP连接是支持多个http请求的。

### GET与POST的区别？

1. GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；
2. GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；
3. 请求形式上：GET请求的数据附在URL之后，在HTTP请求头中，参数有长度限制；POST请求的数据在请求体中，参数无长度限制；
4. 安全性：GET请求可被缓存、收藏、保留到历史记录，参数暴露在URL中。POST不会被保存，安全性相对较高，参数在body中；
5. 参数数据类型：GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；
6. GET的长度有限制（操作系统或者浏览器的限制），而POST数据大小无限制
7. **GET产生一个TCP数据包；POST产生两个TCP数据包。**：对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）

所以 GET 和 POST 的底层也是 TCP/IP，也就是说，GET/POST 都是 TCP 链接。GET 和 POST 能做的事情是一样一样的。你要给 GET 加上 request body，给 POST 带上 url 参数，技术上是完全行的通的。不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然 GET 可以带 request body，也不能保证一定能被接收到哦。

> 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

### post里面传的都是表单吗？

**contentType用于表明发送数据流的类型，服务器根据编码类型使用特定的解析方式，获取数据流中的数据。**

在网络请求中，常用的Content-Type有如下：text/html, text/plain, text/css, text/javascript, image/jpeg, image/png, image/gif, application/x-www-form-urlencoded, multipart/form-data, application/json, application/xml 等。

**application/x-www-form-urlencoded 主要用于如下:**

- 最常见的POST提交数据方式。原生form默认的提交方式

如果设置Header的ContentType为 application/json，它会发两次请求，第一次先发Method为OPTIONS的请求到服务器，

- **application/json**

这个请求会询问服务器支持那些请求方法(比如GET,POST)等。如果这个请求支持跨域的话，就会发送第二个请求，否则的话在控制台会报错，第二个请求不会请求。

### Session与Cookie的区别？

Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案

Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。

**cookie用途**

Cookie 为 Web 应用程序保存用户相关信息提供了一种有用的方法。例如，当用户访问您的站点时，您可以利用 Cookie 保存用户首选项或其他信息，这样，当用户下次再访问您的站点时，应用程序就可以检索以前保存的信息。

### **服务端怎么设置cookie**

服务器端向客户端发送Cookie是通过HTTP响应报文实现的，在Set-Cookie中设置需要像客户端发送的cookie

### cookie关闭浏览器重新打开就没了吗？

cookie生命周期默认为浏览器会话期间，驻留内存，关闭浏览器cookie就没了
设置cookie的过期时间为永不过期，将cookie保存在硬盘上

### 浏览器禁用cookie怎么办

**URL重写**

通过request判断前端是否禁用了cookie，如果禁用了cookie，会自动将`;jsessionid=xxx`添加到要返回前端的url后，前端进行请求时就会再url后带上jsessioonid。

### cookie包含哪几项内容

- Expires、Max Age：Expires其实是cookie失效日期。在http/1.1协议中Expires已经由 Max age 选项代替。
- Domain和Path：限制 cookie 能被哪些 URL 访问。即请求的URL是Domain或其子域、且URL的路径是Path或子路径，则都可以访问该cookie
- Size：Cookie的大小
- Secure：Secure选项用来设置cookie只在确保安全的请求中（HTTPS）才会发送。
- httpOnly：这个选项用来设置cookie是否能通过 js 去访问。**带httpOnly选项时，客户端则无法通过js代码去访问（包括读取、修改、删除等）这个cookie。**

### Cookie防劫持预防?

基于XSS攻击, 窃取Cookie信息, 并冒充他人身份。
1） 方法一：
给Cookie添加HttpOnly属性, 这种属性设置后, 只能在http请求中传递, 在脚本中, document.cookie无法获取到该Cookie值. 对XSS的攻击, 有一定的防御. 但是对网络拦截，还是泄露了.
2）方法二：
在cookie中添加校验信息, 这个校验信息和当前用户外置环境有些关系,比如ip,user agent等有关. 这样当cookie被人劫持了, 并冒用, 但是在服务器端校验的时候, 发现校验值发生了变化, 因此要求重新登录, 这样也是种很好的思路, 去规避cookie劫持.
3）方法三：
cookie中session id的定时更换, 让session id按一定频率变换, 同时对用户而言, 该操作是透明的, 这样保证了服务体验的一致性.

### 从输入网址到获得页面的过程？

1. 浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；
2. 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；
3. TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；
4. 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；
5. 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；
6. 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。

### 一个 url 分为哪几部分，各个部分的含义是什么

统一资源定位符（URL）是用于完整地描述Internet上网页和其他资源的地址的一种标识方法。

URL的一般格式为（带方括号[]的为可选项）：`protocol://hostname[:port]/path/[;parameters][?query]#fragment` 

URL由三部分组成： 协议类型 ，主机名 和 路径及文件名 。

1、protocol（协议）：指定使用的传输协议， 最常用的是HTTP协议。 

2、hostname（主机名）：是指存放资源的服务器的域名系统主机名或 IP 地址。

3、port（端口号）：省略时使用协议的默认端口，各种传输协议都有默认的端口号，如http的默认端口为80。

4、path（路径）：由零或多个“/”符号隔开的字符串，一般用来表示主机上的一个目录或文件地址。

5、;parameters（参数）：这是用于指定特殊参数的可选项。
6、?query（查询）：可选，可有多个参数，用“&”符号隔开，每个参数的名和值用“=”符号隔开。
7、fragment，信息片断，字符串，用于指定网络资源中的片断。例如一个网页中有多个名词解释，可使用fragment直接定位到某一名词解释

### 百分号（URL）编码

因为早在 URL 被发明出来作为万维网地址时，就已规定只能使用英文字母、阿拉伯数字和某些标点符号，不能使用其他文字和符号。**如果 URL 中有汉字或者其他标准之外的字符，就必须编码后使用**。

**百分号编码与 Base64 异同**

**相同点**：它们都是用给定的 US-ASCII 码可打印字符去表示更广范围数据的方法。

**区别**：百分号编码是针对超出 URI 合法字符范围外的字符做编码，而 Base64 是针对二进制数据做编码；一个是对文本的编码，一个是对二进制数据的编码。

> 标准的Base64编码后可能出现字符`+`和`/`，在URL中就不能直接作为参数。

### HTTP 请求的请求行、请求头、请求包体各部分内容

请求行（Request Line）分为三个部分：请求方法、请求地址和协议及版本，以CRLF结束。

HTTP请求报文头：拥有若干个报文关属性，它们是为协助客户端及服务端交易的一些附属信息。 常见的有Accept 、Cookie 、Referer 、Cache-Control

请求体：支持格式：application/json、text/xml、文件分割

### HTTP报文头和报文体怎么分离

最后一个请求头之后是一个空行，发送回车符和换行符，通知服务器以下不再有请求头。

### HTTP 响应报文的内容

HTTP响应也由三个部分组成，分别是：状态行、响应头、响应正文。

状态行：`HTTP-Version Status-Code Reason-Phrase CRLF`，HTTP-Version表示服务器HTTP协议的版本；Status-Code表示服务器发回的响应状态代码；Reason-Phrase表示状态代码的文本描述。

响应头：响应头用于描述服务器的基本信息，以及数据的描述，服务器通过这些数据的描述信息，可以通知客户端如何处理等一会儿它回送的数据。常见的有：Expires、Last-Modified、Set-Cookie

响应体：就是响应的消息体，如果是纯数据就是返回纯数据，如果请求的是HTML页面，那么返回的就是HTML代码，如果是JS就是JS代码

### 断点续传的原理是什么

范围请求，首部字段`Range`来指定资源的byte范围。

### HTTP怎么实现分包？

HTTP协议是一种文本协议（非二进制协议），用\r\n\r\n来分割消息头和消息体，**HTTP请求的消息头中有Content-Length来告知消息体有多大，如果没有该字段就表示无消息体**

### HTTP请求有哪些常见状态码？

1. 2xx状态码：操作成功。200 OK，201状态码英文名称是Created，该状态码表示已创建。
2. 3xx状态码：重定向。301 永久重定向；302暂时重定向
3. 4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden；404 Not Found；405 (方法禁用) 禁用请求中指定的方法。
4. 5xx状态码：服务端错误。500服务器内部错误；501服务不可用； 502 Bad Gateway：请求未完成，服务器从上游服务器收到一个无效的响应。 

`502`并不是指网关（例如nginx）本身出了问题，而是从上游接收响应出了问题，比如由于上游服务自身超时导致不能产生响应数据，或者上游不按照协议约定来返回数据导致网关不能正常解析。

`504`，`Gateway Timeout`，网关超时。它表示网关没有从上游及时获取响应数据。原因在于超过了`nginx`自身的超时时间

304 Not Modified：客户端有缓冲的文件并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。

### 发生502，应该先查看什么

502错误最通常的出现情况就是后端主机宕机。

1、查看后台进程数是否够用，确定是否是因为高并发导致的

2、查看程序执行时间是否超过Nginx等待时间，应用日志。可能是数据库死锁导致的。

3、查看Nginx日志

### 发生500应该先查看什么

先看看服务的进程还在不在，然后查看日志，从日志里面找原因。

### HTTP请求中的query是什么？

query是指请求的参数，一般是指URL中？后面的参数。

### 为什么重定向？

**域名别称**
理想情况下，一项资源只有一个访问位置，也就是只有一个 URL 。但是由于种种原因，需要为资源设定不同的名称（即不同的域名，例如带有和不带有 www 前缀的URL，以及简短易记的 URL 等）。在这种情况下，实用的方法是将其重定向到那个实际的（标准的）URL，而不是复制资源

**保持链接有效**
当你重构 Web 站点的时候，资源的 URL 会发生改变。即便是你可以更新站点内部的链接来适应新的命名体系，但无法控制被外部资源使用的 URL 。

你并不想因此而使旧链接失效，因为它们会为你带来宝贵的用户（并且帮助优化你的SEO），所以需要建立从旧链接到新链接的重定向映射。

**对于耗时请求的临时响应**
一些请求的处理会需要比较长的时间，比如有时候 DELETE 请求会被安排为稍后处理。在这种情况下，会返回一个 303 (See Other)  重定向响应，该响应链接到一个页面，表示请求的操作已经被列入计划，并且最终会通知用户操作的进展情况，或者允许用户将其取消。

## QUIC

QUIC 在应用层上，基于UDP传输

### 自定义连接机制

QUIC 维护连接，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化
的时候，只要 ID 不变，就不需要重新建立连接。

避免了当手机信号不稳定或者在 WIFI 和移动网络切换时，导致重连，从而进行再次的三次握手。

### 自定义重传机制

QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。

发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。

### 无阻塞的多路复用

同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。

一个连接上的多个 stream 之间没有依赖。

假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。

### 自定义流量控制

## 计算机网络体系结构

![](stru.png)

![](mode.png)

### OSI 7层

物理层：通过网线、光缆等这种物理方式将电脑连接起来。发送高低电平（电信号）

数据链路层：定义了电信号的分组方式。通过广播的形式向局域网内所有主机发送数据，再根据数据中MAC地址和自身对比判断是否是发给自己的。

网路层：引入网络地址用来区分不同的广播域/子网

传输层：建立端口到端口的通信

会话层：建立和断开客户端与服务端连接

表示层：数据格式转换。如编码、数据格式转换、加密解密、压缩解压

应用层：规定应用程序的数据格式

### 四层网络

- 链路层：负责封装和解封装IP报文，发送和接受ARP/RARP报文等。
- 网络层：负责路由以及把分组报文发送给目标网络或主机。
- 传输层：负责对报文进行分组和重组，并以TCP或UDP协议格式封装报文。
- 应用层：负责向用户提供应用程序，比如HTTP、FTP、Telnet、DNS、SMTP等。

###  为什么要分层？

1、易于实现、标准化、各层独立，就可以把大问题分割成多个小问题，利于实现；

2、灵活性好：如果某一层发生变化，只要接口不变，不会影响其他层；

3、分层后，用户只关心用到的应用层，其他层用户可以复用；

- 应用层：常见协议：
  - FTP（21端口）：文件传输协议
  - SSH（22端口）：远程登陆
  - TELNET（23端口）：远程登录
  - SMTP（25端口）：发送邮件
  - POP3（110端口）：接收邮件
  - HTTP（80端口）：超文本传输协议
  - DNS（53端口）：运行在UDP上，域名解析服务
  - DHCP
- 传输层：TCP/UDP
- 网络层：IP、NAT、RIP
- 链路层：VLAN、STP

- **在OSI模型中ARP协议属于链路层，而在TCP/IP模型中，ARP协议属于网络层**

**路由器、交换机位于哪一层？**


- 路由器网络层，根据IP地址进行寻址；
- 交换机数据链路层，根据MAC地址进行寻址
- 网桥：工作在数据链路层，在不同或相同类型的LAN之间存储并转发数据帧，必要时进行链路层上的协议转换。

**ICMP协议到底属于哪一层**

icmp协议是IP层的附属协议，是介于IP层和TCP层之间的协议，一般认为属于IP层协议。

请求网络地址，地址中有大量带百分号的字符串IP协议用它来与其他主机或路由器交换错误报文和其他的一些网络情况。在ICMP包重携带了控制信息和故障恢复信息。主要用于路由器主机向其他路由器或者主机发送出错报文的控制信息。

### 为什么需要IP？MAC？

**需要 IP 地址**

如果我们只用 MAC 地址，路由器需要记住每个 MAC 地址所在的子网是哪一个，因此需要极大的内存

**需要Mac地址**

 IP 地址是要设备上线以后，才能根据他进入了哪个子网来分配的，在设备还没有 IP 地址的时候，我们还需要用 MAC 地址来区分不同的设备。

### TCP和IP的区别

IP协议：

因特网协议。IP协议规定了数据传输时的基本单元和格式。定义了数据包的递交办法和[路由选择](https://www.baidu.com/s?wd=路由选择&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)。位于网络层。

TCP协议：

TCP协议提供了可靠的面向对象的数据流传输服务的规则和约定。简单的说在TCP模式中，对方发一个数据包给你，你要发一个确认数据包给对方。通过这种确认来提供可靠性。位于传输层。

### 什么叫划分子网？

从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。

### 什么是ARP协议 （Address Resolution Protocol）？

- **ARP协议完成了IP地址与物理地址的映射**。每一个主机都设有一个 ARP 高速缓存，里面有**所在的局域网**上的各主机和路由器的 IP 地址到硬件地址的映射表。
- 当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向**所在的局域网**发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射）
- 收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。
- 源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。
- 如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。

**在OSI模型中ARP协议属于链路层；而在TCP/IP模型中，ARP协议属于网络层。**

### ARP报文

- 报头部分：

- - 以太网目的地址：ARP请求的目的以太网地址，全1时代表广播地址
  - 以太网源地址：ARP请求的源地址

- 数据部分：

- - 帧类型：以太网帧类型表示的是后面的数据类型，ARP请求和ARP应答这个值为0x0806
  - 硬件地址类型：硬件地址的类型，硬件地址不只以太网一种，是以太网类型时此值为1
  - 协议类型
  - 硬件地址长度
  - 协议地址长度，与协议类型相对应
  - 操作类型字段
  - 发送端以太网地址：发送端ARP请求或应答的硬件地址
  - 发送端IP地址
  - 目的端以太网地址：目的端ARP请求或应答的硬件地址
  - 目的端IP地址

### 什么是NAT （Network Address Translation, 网络地址转换)？

用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。

### 802.3x 工作在几层，为什么

IEEE 802.3是一个工作组  ，该工作组定义了有线以太网的物理层和数据链路层的介质访问控制 （MAC）。

MAC子层的数据封装所包括的主要内容有：数据封装分为发送数据封装和接收数据封装两部分，包括[成帧](https://baike.baidu.com/item/成帧)、编制和差错检测等功能。

### 什么是RIP（Routing Information Protocol, 距离矢量路由协议）? 算法是什么？

每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。

工作原理： 路由器每30秒把自己的路由表发给邻居。路由器用邻居发来的路由表根据距离向量算法修改自己的路由表。初始时每个路由器只有到直连网距离为1的路由。

**优缺点**


- 实现简单，开销小
- 随着网络规模扩大开销也会增大；
- 最大距离为15，限制了网络的规模；
- 当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器

## DNS

### 解析流程

从客户端到本地DNS服务器属于递归查询，而DNS服务器之间是迭代查询。

- 电脑客户端会发出一个 DNS 请求，问 www.163.com 的 IP 是啥啊，并发给本地域名服务器。本地 DNS 由你的网络服务商，如电信、移动等自动分配，它通常就在你网络服务商的某个机房。
- 本地 DNS 收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应 IP 地址的大表格。如果能找到 www.163.com，它直接就返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大，能告诉我 www.163.com 的 IP 地址吗？”根域名服务器是最高层次的，全球共有 13 套。它不直接用于域名解析，但能指明一条道路。
- **根 DNS** 收到来自本地 DNS 的请求，发现后缀是 **.com**，说：“哦，www.163.com 啊，这个域名是由.com 区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。”
- 本地 DNS 转向问**顶级域名服务器**：“老二，你能告诉我 www.163.com 的 IP 地址吗？”顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org 这些一级域名，它负责管理二级域名，比如163.com，所以它能提供一条更清晰的方向。
- 顶级域名服务器说：“我给你负责 www.163.com 区域的**权威 DNS 服务器**的地址，你去问它应该能问到。”
- 本地 DNS 转向问权威 DNS 服务器：“您好，www.163.com 对应的 IP 是啥呀？”163.com 的权威 DNS 服务器，它是域名解析结果的原出处。
- 权限 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
- 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接

### 如果dns解析得到ip地址之后请求超时，那么会重新解析吗

浏览器就得到了域名对应的 IP 地址，并将 IP 地址缓存起来。不需要

### DNS使用的是TCP协议还是UDP协议

**区域传送时使用TCP**： 
1.辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为**数据同步传送的数据量比一个请求和应答的数据量要多得多**。 
2.TCP是一种可靠的连接，**保证了数据的准确性**。 

**域名解析时使用UDP协议**： 
客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。**不用经过TCP三次握手，这样DNS服务器负载更低，响应更快**。虽然从理论上说，客户端也可以指定向DNS服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。

DNS 查询选择 UDP 或者 TCP 两种不同协议时的主要原因：

- UDP 协议
  - DNS 查询的数据包较小、机制简单；
  - UDP 协议的额外开销小、有着更好的性能表现；
- TCP 协议
  - DNS 查询由于 DNSSEC 和 IPv6 的引入迅速膨胀，导致 DNS 响应经常超过 MTU 造成数据的分片和丢失，我们需要依靠更加可靠的 TCP 协议完成数据的传输；
  - 随着 DNS 查询中包含的数据不断增加，TCP 协议头以及三次握手带来的额外开销比例逐渐降低，不再是占据总传输数据大小的主要部分；

### 根DNS服务器如何承受并发

先访问DNS缓存、本地DNS服务器。同时有13台根DNS服务器作负载均衡。根DNS服务器只存储一级域名的映射，实际不做域名的解析。

### DNS劫持是什么

域名劫持，DNS重定向（DNS direaction）,是一种DNS攻击方式。即是DNS查询没有得到正确的解析，以致引导user访问到恶意的网站，从而窃取用户隐私，或者进行某些恶意的操作。

### DNS的防范劫持

**1.加强本地计算机病毒检查，开启防火墙等，防止恶意软件，木马病毒感染计算机**

**2.改变路由器默认密码，防止攻击者修改路由器的DNS配置指向恶意的DNS服务器**

**3.手动修改DNS，host文件，dns服务器IP**

### DNS缺点

 **域名缓存问题**：本地做一个缓存，直接返回缓存数据。可能会导致全局负载均衡失败，因为上次进行的缓存，不一定是这次离客户最近的地方，可能会绕远路。

**出口NAT问题**：做了网络地址转化后，权威的DNS服务器，没法通过地址来判断客户到底是哪个运营商，极有可能误判运营商，导致跨运营商访问。

**解析延迟**：DNS的查询过程需要递归遍历多个DNS服务器，才能获得最终结果。可能会带来一定的延时。

**域名转发问题**：如果是A运营商将解析的请求转发给B运营商，B去权威DNS服务器查询的话，权威服务器会认为你是B运营商的，就返回了B运营商的网站地址，结果每次都会跨运营商。

## HTTPDNS

HTTPDNS使用HTTP与DNS服务器交互，代替传统的基于UDP的DNS协议，域名解析请求直接发送到HTTPDNS服务端，从而绕过运营商的Local DNS

### 特性

**防止域名劫持**

由于 HttpDns 是通过 IP 直接请求 HTTP 获取服务器 A 记录地址，不存在向本地运营商询问 domain 解析过程，所以从根本避免了劫持问题。

**精准调度**

由于 DNS 服务器端获取的是真实客户端 IP 而非 Local DNS 的 IP，HTTPDNS能够直接获取到用户的IP地址，从而实现精确定位与导流

**用户连接失败率下降**

通过算法降低以往失败率过高的服务器排序，通过历史访问成功记录提高服务器排序。

## 路由协议

路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；

动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和OSPF 协议。

### 简述OSPF协议的工作原理

使用Dijikstra最短路径算法，使用分布式的链路状态协议。

 路由器互相发送直接相连的链路信息和它拥有的到其它路由器的链路信息。每个 OSPF 路由器维护相同自治系统拓扑结构的数据库。从这个数据库里，构造出最短路径树来计算出路由表。当拓扑结构发生变化时，OSPF 能迅速重新计算出路径，而只产生少量的路由协议流量。此外，所有 OSPF 路由选择协议的交换都是经过身份验证的。

## FTP

文件传输协议（File Transfer Protocol，FTP）是用于在网络上进行文件传输的一套标准协议，它工作在 OSI 模型的第七层， TCP 模型的第四层， 即应用层， 使用 TCP 传输而不是 UDP， 客户在和服务器建立连接前要经过一个“三次握手”的过程， 保证客户与服务器之间的连接是可靠的， 而且是面向连接， 为数据传输提供可靠保证。

**Port模式**

FTP 客户端首先和服务器的TCP 21端口建立连接，用来发送命令，客户端需要接收数据的时候在这个通道上发送PORT命令。

**PORT命令包含了客户端用什么端口接收数据。**在传送数据的时候，**服务器端通过自己的TCP 20端口连接至客户端的指定端口发送数据。**

FTP server必须和客户端**建立一个新的连接**用来传送数据。

**Passive模式**

建立连接后发送Pasv命令。服务器收到Pasv命令后，**打开一个临时端口**（端口号大于1023小于65535）并且**通知客户端在这个端口上传送数据的请求**，客户端连接FTP服务器此端口，然后FTP服务器将通过这个端口传送数据。



## ICMP协议

### 什么是ICMP协议，它的作用是什么？

**互联网控制报文协议**。用在主机、路由器之间传递控制消息，控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。

ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。

ICMP 包头的**类型**字段，大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

### Ping的过程以及原理

 **使用ICMP查询报文**

- 源主机首先会构建一个 **ICMP 回送请求消息**数据包
- 由 ICMP 协议将这个数据包交给 IP 层。IP 层将设置**目的地址**，**源地址**，**协议**字段设置为 `1` 表示是 `ICMP` 协议，再加上一些其他控制信息，构建一个 `IP` 数据包。
- 加入 `MAC` 头。如果在本地 ARP 映射表中存在出目标地址所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 `ARP` 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层设置MAC地址，构建一个数据帧，还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。
- 主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。
- 接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。
- 主机 `B` 会构建一个 **ICMP 回送响应消息**数据包，回送响应数据包的**类型**字段为 `0`，**序号**为接收到的请求数据包中的序号，然后再发送出去给主机 A。
- 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。

## SSH

SSH是一种网络协议，用于计算机之间的加密登录。SSH之所以能够保证安全，原因在于它采用了公钥加密。

整个过程是这样的：

（1）远程主机收到用户的登录请求，把自己的公钥发给用户。

（2）用户使用这个公钥，将登录密码加密后，发送回来。

（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。

如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。

### 中间人攻击

#### 口令登录

确认host主机的真实性：首次连接确认公钥指纹。

#### 公钥登录

不需要输入密码。

就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。

## 加密算法

### DES加密算法

DES（Data Encryption Standard）数据加密标准算法，是一种双向加密算法，也是对称性加密算法。

工作原理：当需要加密的时候就用key对 data加密，生成密码形式的data作为输出结果，解密就需要再利用key对data进行解密获得原文密码作为输出。

### MD5加密算法

Message-Digest-Algorithm 信息摘要算法第五代。属于Hash算法一代，是一种单向加密算法，可以将输入的信息加密转换为128位固定长度的散列值，用于检验数据传输过程中的完整性。

**优势：**

- 防止被篡改，在传输过程中一旦被串改，那么计算出的MD5值一定不同。
- 计算速度快。加密速度快，不需要秘钥。
- 检查文件的完整性，一旦文件被更改，MD5值也是不同的。
- 防止抵赖，用于数字签名，一旦用户的文件被第三方MD5加密，若以后A说这个文件不是他写的，那么当用文件MD5后获得的签名一致，可以确认。

**缺点:**

- 作为一种散列算法，虽然很难发生散列碰撞，但是经过证实，仍然存在两种不同数据会发生碰撞。
- MD5的安全性：将用户的密码直接MD5后存储在数据库是不安全的。第一，用户普遍习惯用容易记忆的密码，生日，手机号等，**黑客容易破译此类密码。这也是加盐值的一个原因。**第二，直接MD5存入数据库，**若数据库被破解，通过MD5反查会查到密码，需要随机盐值的配合。**
- 考虑到多数人所使用的密码为常见的组合，攻击者可以将所有密码的常见组合进行单向哈希，得到一个摘要组合，然后与数据库中的摘要进行比对即可获得对应的密码。这个摘要组合也被称为rainbow table。

### SHA1加密算法

SHA-1是一种数据加密算法，该算法的思想是接收一段明文，然后以一种不可逆的方式将它转换成一段（通常更小）密文，也可以简单的理解为取一串输入码（称为预映射或信息），并把它们转化为长度较短、位数固定的输出序列即散列值（也称为信息摘要或信息认证代码）的过程。

### RSA加密算法

RSA是一种非对称加密算法。目前最有影响力的公钥加密算法，该算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，**因此可以将乘积公开作为加密密钥，即公钥，而两个大素数组合成私钥。公钥是可发布的供任何人使用，私钥则为自己所有，供解密之用。**

 解密者拥有私钥，并且将由私钥计算生成的公钥发布给加密者。加密都使用公钥进行加密，并将密文发送到解密者，解密者用私钥解密将密文解码为明文。

### 为什么密码加盐

Salt 可以是任意字母、数字、或是字母或数字的组合，但必须是随机产生的，每个用户的 Salt 都不一样，用户注册的时候，数据库中存入的不是明文密码，也不是简单的对明文密码进行散列，而是 MD5( 明文密码 + Salt)。

由于加了 Salt，即便数据库泄露了，但是由于密码都是加了 Salt 之后的散列，坏人们的数据字典已经无法直接匹配，明文密码被破解出来的概率也大大降低



## traceroute命令用处

traceroute是诊断网络问题时常用的工具。它可以定位从源主机到目标主机之间经过了哪些路由器，以及到达各个路由器的耗时。

**原理**

从源主机向目标主机发送IP数据报，并按顺序将TTL设置为从1开始递增的数字（假设为N），导致第N个节点（中间节点 or 目标主机）丢弃数据报并返回出错信息。源主机根据接收到的错误信息，确定到达目标主机路径上的所有节点的IP，以及对应的耗时。

## 为什么网络中会发生丢包？

**物理线路故障**

**设备故障**：如网卡是坏的，交换机的某个端口出现了物理故障，光模块等等。接收到的分组校验出错

**网络拥塞**：分组在网络中超出最大存活时间、路由器接收分组数量达到上限后，会丢弃多余分组

## 小端字节序和大端字节序，这个对什么产生影响，做什么事情会出现问题

- **大端字节序**：高位字节在前，低位字节在后，这是人类读写数值的方法。
- **小端字节序**：低位字节在前，高位字节在后

计算机电路先处理低位字节，效率比较高，因为计算都是从低位开始的。所以，计算机的内部处理大多是小端字节序。

但是，人类还是习惯读写大端字节序。所以，除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。

**只有读取的时候，才必须区分字节序，其他情况都不用考虑。**

## 传一个字符串，定义为大端和小端一样吗？如果传一个数字有影响吗？

大小端是面向多字节类型定义的，比如2字节、4字节、8字节整型、长整型、浮点型等，单字节的字符串一般不用考虑。



## WebSocket 和 HTTP 的区别

- http 协议是用在应用层的协议，客户端与服务器通信，必须要有客户端发起然后服务器返回结果。客户端是主动的，服务器是被动的。 
- 为了解决客户端发起多个 http 请求到服务器资源浏览器必须要经过轮训问题，websocket实现了多路复用，他是全双工通信。在 webSocket 协议下客服端和浏览器可以同时发送信息。服务器已有主动权想什么时候发就可以发送信息到服务器。而且信息当中不必再带有 head 的部分信息了。

降低了服务器压力，减少了部分多余信息

## 参考

https://blog.csdn.net/weixin_41047704/article/details/85340311

https://blog.csdn.net/gdutxiaoxu/article/details/107393249

https://blog.csdn.net/weixin_38035852/article/details/81667160