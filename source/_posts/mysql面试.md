---
title: mysql面试
top: false
cover: false
toc: true
mathjax: true
date: 2021-04-10 18:45:14
password:
summary:
tags:
- interview
categories:
- interview
---

## 架构

**server层**

1. 连接器：管理连接，权限验证  

2. 查询缓存  

3. 分析器：词法、语法解析

4. 优化器：生成执行计划，索引选择

5. 执行器：操作引擎，返回结果

**存储引擎层**

1. 负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎

##  日志系统

### redo log（重做日志）

1. InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe），确保事务的持久性。
2. 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存（buffer pool），此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）
3. redo log 是物理日志，记录的是在某个数据页上做了什么修改
4. redo log是循环写，空间固定会用完

> 出现 MySQL 宕机或者断电时，如果有缓存页的数据还没来得及刷入磁盘，那么当 MySQL 重新启动时，可以根据 redo log 日志文件，进行数据重做，将数据恢复到宕机或者断电前的状态
>
> redo log 日志文件是持久化在磁盘上的，磁盘上可以有多个 redo log 文件，MySQL 默认有 2 个 redo log 文件，每个文件大小为 48M
>
>  redo log 日志是存储在磁盘上的，那么此时是不是立马就将 redo log 日志写入磁盘呢？显然不是的，而是先写入一个叫做 redo log buffer 的缓存中，redo log buffer 是一块不同于 buffer pool 的内存缓存区

**为什么MySQL 要写到 redo log buff 内存**

因为一个事务中可能涉及到多次读写操作，写入Buffer中分组写入，比起一条条的写入磁盘文件，效率会高很多。

### binlog（归档日志）

1. server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力

2. binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER、TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志

3. binlog采用追加写的模式

4. **用途：**  

- 恢复：binlog日志恢复数据库数据  
- 复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  
- 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击

**binlog常见格式**

| format    | 定义                       | 优点                           | 缺点                                                         |
| --------- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |
| statement | 记录的是修改SQL语句        | 日志文件小，节约IO，提高性能   | 准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况） |
| row       | 记录的是每行实际数据的变更 | 准确性强，能准确复制数据的变更 | 日志文件大，较大的网络IO和磁盘IO                             |
| mixed     | statement和row模式的混合   | 准确性强，文件大小适中         | 有可能发生主从不一致问题                                     |

### 两段提交  

1. 两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致

2. 两段提交： 写入redo log处于prepare阶段 --写入bin log --提交事务处于commit状态 

- 时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  
- 时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务

3. bin log完整性判断:  

- statement格式最后有commit  
- row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）

MySQL 重启后，进行数据重做时，在 redo log 日志中由于该事务的 redo log 日志没有 commit 标识，那么就不会进行数据重做，磁盘上数据还是原来的数据，也就是事务没有提交。

### undo log

1. undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录

2. undo log 作用  

- 提供回滚  
- 多版本并发控制（MVCC）

### 宕机恢复流程？

1.启动开始时检测是否发生崩溃

2.定位到最近的一个checkpoint

3.定位在这个checkpoint时flush到磁盘的数据页，检查checksum。如果不正确，说明这个页在上次写入是不完整的，从doublewrite buffer里把正确的页读出来，更新到buffer中的页

4.分析redo log，标识出未提交事务

5.顺序执行redo

6.rollback未提交的事务

### Mysql抖动

当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。

**flush场景**

1. InnoDB 的 redo log 写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘
2. 系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是"脏页"，就要先将脏页写到磁盘
3. MySQL 认为系统空闲的时候，会flush脏页
4. MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上

InnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度

## 存储引擎

### MyISAM与InnoDB索引区别

InnoDB索引是**聚簇索引**，MyISAM索引是**非聚簇索引**。

InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。

InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效

### 为什么myisam 的查询要比innoDB 快

1）InnoDB 要缓存数据和索引，MyISAM只缓存索引块， 这中间还有换进换出的减少；

2）InnoDB寻址要映射到块，再到行，MyISAM记录的直接是文件的OFFSET，定位比InnoDB要快

3）InnoDB还需要维护MVCC一致； 虽然你的场景没有，但他还是需要去检查和维护MVCC (Multi-Version Concurrency Control)多版本并发控制 。

### b+树为什么能三层能存2000多万个，计算过程。

InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。假设一行数据的大小是1k，那么一个页可以存放16行这样的数据。

在B+树中叶子节点存放数据，非叶子节点存放键值+指针。我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即`16384/14=1170`。那么可以算出一棵高度为2的B+树，能存放`1170*16=18720`条这样的数据记录。根据同样的原理我们可以算出一个高度为3的B+树可以存放：`1170*1170*16=21902400`条这样的记录。

所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。

### Innodb引擎特性

#### 写缓冲（change buffer）

Insert Buffer 用于非聚集索引的插入和更新操作。先判断插入的非聚集索引是否在缓存池中，如果在则直接插入，否则插入到 Insert Buffer 对象里。再以一定的频率进行 Insert Buffer 和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，减少随机IO带来性能损耗，提高对非聚集索引的插入性能。

#### 二次写

mysql最小的io单位是16k，文件系统io最小的单位是4k，因此存在IO写入导致page损坏的风险

如果数据库发生宕机时，可以通过重做日志对该页进行恢复，但是如果该页本身已经损坏了，进行重做恢复是没有意义的。因此引入了"二次写"方案，解决部分写失败，提高数据页的稳定性。

#### 自适应哈希索引

InnoDB 会监控对表上各个索引页的查询，如果观察到通过哈希索引可以带来性能提升，则自动建立哈希索引。自适应哈希索引通过缓存池的 B+ 树页构造而来，因此建立速度很快。

#### 预读

数据库访问通常都遵循集中读取原则，使用一些数据大概率会使用附近的数据，这就是所谓的局部性原理，它表明提前加载是有效的，能减少磁盘的i/o。

预读机制就是发起一个i/o请求，异步的在缓冲池中预先回迁若干个页面，预计将会用到的页面回迁。

### MyISAM为什么不支持事务

MyISAM存储引擎没有redo和undo文件，没法支持事务的ACID特性，锁也只有表锁

## 索引

### 定义

数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。

通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。

索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。

### 优缺点

**索引的优点**

- 加快数据的检索速度。

**索引的缺点**

- 创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；
- 索引需要占物理空间。

### 使用场景

**where**

**order by**

使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据**使用磁盘临时文件完成外部排序或者在内存中完成排序**。具体取决于排序所需的内存和参数sort_buffer_size。

如果我们对该字段建立索引，由于索引本身是有序的，因此直接**按照索引的顺序和映射关系逐条取出数据即可**。

**join**

对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）

**覆盖索引**

辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。

如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。

> 尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。

### 索引类型

**主键索引**： 不允许重复，不允许为NULL，一个表只能有一个主键。

**唯一索引**：不允许重复，允许为NULL，一个表允许多唯一索引。

**普通索引**：基本的索引类型，没有唯一性的限制，允许为NULL值。

**全文索引**： 是目前搜索引擎使用的一种关键技术。

### 索引的数据结构

和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。

InnoDB存储引擎的默认索引实现为：B+树索引。

哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。

### 索引设计的原则

**适合索引的列**是出现在where子句中的列，或者连接子句中指定的列

**使用短索引**，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间

**不要过度索引**。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。

### 创建索引的原则

1） 组合索引的最左前缀匹配原则，mysql会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立`(a,b,c,d)`顺序的索引，d是用不到索引的，如果建立`(a,b,d,c)`的索引则都可以用到，a,b,d的顺序可以任意调整。

2）较频繁作为查询条件的字段才去创建索引

3）更新频繁字段不适合创建索引

4）若是不能有效区分数据的列不适合做索引列（如性别），选择基数较大的列做索引

5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加`(a,b)`的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。

6）定义有外键的数据列一定要建立索引。

### 创建索引注意点

**非空字段：**应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

**取值离散大的字段：**（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过`count()`函数查看字段的差异值

**索引字段越小越好**：数据库的数据存储以页为单位，一页存储的数据越多一次IO操作获取的数据越大，效率越高。

### 使用索引查询一定能提高查询的性能吗

使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况:

- 基于一个范围的检索，一般查询返回结果集小于表中记录数的30%
- **基于非唯一性索引的检索（？？？）**

**通常，通过索引查询数据比全表扫描要快。**但是我们也必须注意到它的代价。

**索引需要空间来存储，也需要定期维护，** 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。

### 百万级别或以上的数据如何删除

> 索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的。

所以删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）

然后删除其中无用数据（此过程需要不到两分钟）

删除完成后重新创建索引（此时数据较少了，创建索引也非常快，约十分钟左右。）

### 前缀索引

语法：``index(field(10))``，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。

前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。

实操的难度：**在于前缀截取的长度。**

我们可以利用`select count(*)/count(distinct left(password,prefixLen));`，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）

### B树和B+树的区别

B树中，键和值存放在内部节点和叶子节点；

B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。

B+数的叶子节点是一个页。B+树的叶子节点有一条**双向链表**相连，而B树的叶子节点各自独立。

### 使用B树的好处

B树可以在**内部节点同时存储键和值**，因此，**把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。**这种特性使得B树在特定数据重复多次查询的场景中更加高效。

### 使用B+树的好处

- 由于**B+树的内部节点只存放键**，不存放值，因此，**一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围**。

- B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，**B+树只需要使用`O(logN)`时间找到最小的一个节点，然后通过链进行`O(N)`的顺序遍历即可。**而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间

### Hash索引和B+树优劣

**hash索引底层就是hash表**，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。

B+树底层实现是**多路平衡查找树**。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。

那么可以看出他们有以下的不同：

- hash索引进行**等值查询更快（一般情况下），但是却无法进行范围查询**。

- hash索引**不支持使用索引进行排序**，原理同上。

- hash索引不**支持模糊查询以及多列索引的最左前缀匹配。**原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。

- hash索引任何时候都**避免不了回表查询数据**，而B+树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。
- hash**索引不稳定**。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。

因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。

### 使用B+树而不是B树

- **B树只适合随机检索，而B+树同时支持随机检索和顺序检索**；

-  **B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。**B+树的内部结点并没有指向关键字具体信息的指针，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，，IO读写次数也就降低了。

- **B+树的查询效率更加稳定。**B树搜索越靠近根节点的记录查找时间越短。B+树中，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，查找路径长度相同，导致每一个关键字的查询效率相当。

- **B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。**B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。

- **增删文件（节点）时，效率更高。**因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。

### 聚簇索引

**聚簇索引**：将数据存储与索引放到了一块，找到索引也就找到了数据

**非聚簇索引**：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，因此索引不在key buffer命中时，速度慢。

**澄清一个概念：**innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。

### 为什么InnoDB表必须有主键

InnoDB表必须有主键，并且推荐使用整型的自增主键。

1、如果设置了主键，那么InnoDB会选择主键作为聚集索引、如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引、如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引（ROWID随着行记录的写入而主键递增）。

2、如果表使用自增主键
每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，主键的顺序按照数据记录的插入顺序排列，自动有序。

当一页写满，就会自动开辟一个新的页

3、如果使用非自增主键（如果身份证号或学号等）
由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页的中间某个位置，此时MySQL需要移动数据，频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构。

### 为什么非主键索引结构叶子结点存储的是主键值

减少了出现**行移动或者数据页分裂时二级索引的维护工作**（当数据需要更新的时候，二级索引不需要修改，只需要修改聚簇索引，一个表只能有一个聚簇索引，其他的都是二级索引，这样只需要修改聚簇索引就可以了，不需要重新构建二级索引）

聚簇索引也称为主键索引，其索引树的叶子节点中存的是整行数据，表中行的物理顺序与键值的逻辑（索引）顺序相同。

非聚簇索引（普通索引）的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引。

### 非聚簇索引一定会回表查询吗？

不一定，这查询语句所要求的字段全部命中了索引，那么就不必再进行回表查询。

### **联合索引**

MySQL可以使用多个字段同时建立一个索引，叫做联合索引。

在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。

### **为什么需要注意联合索引中的顺序？**

MySQL使用索引时需要索引有序。

一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。

### 如果一张表没有主键怎么办？

- 如果我们定义了主键，那么 InnoDB 会选择主键作为聚集索引。
- 如果没有显式定义主键，则 InnoDB 会选择第一个不包含有 NULL 值的唯一索引作为主键索引。
- 如果也没有这样的唯一索引，则 InnoDB 会选择内置 6 字节长的 ROWID 作为隐藏的聚集索引，它会随着行记录的写入而主键递增。 `select _rowid name from t2;`

### 几千万记录，数据库表结构如何平滑变更？

**pt-online-schema-change**

假设：

*user(uid, name, passwd)*要扩展到： *user(uid, name, passwd, age, sex)*

**第一步**，先创建一个扩充字段后的新表：*user_new(uid, name, passwd, age, sex)*

**第二步**，在原表 user 上创建三个触发器，对原表 user 进行的所有 insert/delete/update 操作，都会对新表 user_new 进行相同的操作；

**第三步**，分批将原表 user 中的数据 insert 到新表 user_new，直至数据迁移完成；

**第四步**，删掉触发器，把原表移走（默认是 drop 掉）；
**第五步**，把新表 user_new 重命名（rename）成原表 user；扩充字段完成，整个过程不需要锁表，可以持续对外提供服务。

> （1）变更过程中，最重要的是冲突的处理，一条原则，以触发器的新数据为准，这就要求被迁移的表**必须有主键**（这个要求基本都满足）；
>
> （2）变更过程中，写操作需要建立触发器，所以如果原表已经有很多触发器，方案就不行（互联网大数据高并发的在线业务，一般都禁止使用触发器）；
> （3）触发器的建立，会影响原表的性能，所以这个操作必须在流量低峰期进行；

### 这个自增主键用完了该怎么办?

**把自增主键的类型改为BigInt类型就好了，int范围20亿，一般不会用完，用完前早就分库分表，采用分布式id了**

1、pt-online-schema-change/gh-ost

>1、创建一个新的表，表结构为修改后的数据表，用于从源数据表向新表中导入数据。
>
>2、创建触发器，用于记录从拷贝数据开始之后，对源数据表继续进行数据修改的操作记录下来，用于数据拷贝结束后，执行这些操作，保证数据不会丢失。
>
>3、拷贝数据，从源数据表中拷贝数据到新表中。
>
>4、rename源数据表为old表，把新表rename为源表名，并将old表删除。
>
>5、删除触发器。

## 数据库范式

**第一范式：**要求数据库表的每一列都是不可分割的原子数据项。

 **第二范式**： 1NF的基础上，需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。

 **第三范式**：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）。第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。

第四范式：消除多值依赖。例如，职工表（职工编号，职工孩子姓名，职工选修课程），在这个表中，同一个职工可能会有多个职工孩子姓名，同样，同一个职工也可能会有多个职工选修课程，即这里存在着多值事实，不符合第四范式

## mysql有关权限的表

MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别**user，db，table_priv，columns_priv和host**。

user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。

db权限表：记录各个帐号在各个数据库上的操作权限。

table_priv权限表：记录数据表级的操作权限。

columns_priv权限表：记录数据列级的操作权限。

host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。

## 视图

视图是虚拟的表，视图只包含使用时动态检索数据的查询；不包含任何列或数据。

使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;

视图创建后，可以使用与表相同的方式利用它们。

> 视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。

### 视图有哪些特点？

- 视图是由基本表（实表）产生的表（虚表）。
- 视图的建立和删除不影响基本表。
- 对视图内容的更新（添加，删除和修改）直接影响基本表。
- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。
- 当视图来自多个基本表时，不允许添加和删除数据。

### 视图的使用场景有哪些？

视图根本用途：简化sql查询，提高开发效率。

**常见使用场景：**

重用SQL语句；

**简化复杂的SQL操作**。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；

**保护数据**。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；

**更改数据格式和表示**。视图可返回与底层表的表示和格式不同的数据。

### 视图的优点

**查询简单化**。视图能简化用户的操作

**数据安全性**。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护

### 视图的缺点

**性能**。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由复杂的多表查询所定义，那么，视图的查询，需要花费一定的时间。

**修改限制**。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。

### 游标

游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。用户可以通过游标，逐一获取记录，进一步处理。

## MVCC

MVCC的实现，通过保存数据在某个时间点的快照来实现的。这意味着一个事务无论运行多长时间，在同一个事务里能够看到数据一致的视图。根据事务开始的时间不同，同时也意味着在同一个时刻不同事务看到的相同表里的数据可能是不同的。

**实现策略**

通过保存数据在某个时间点的快照来实现的：

InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本（存放在 UNDO LOG中）。

每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询记录的版本号进行比较。

## 事务

### 什么是数据库事务？

一个不可分割的数据库操作序列，是数据库并发控制的基本单位。

事务是逻辑上的一组操作，要么都执行，要么都不执行。

> 假如小明要给小红转账1000元：将小明的余额减少1000元，将小红的余额增加1000元。万一操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么成功，要么都失败。

### 事务的特性

- atomicity（原子性） ：要么全执行，要么全都不执行；
- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；
- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；
- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。

### 怎么保证一致性的？

从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。

但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给B账户加钱，那一致性还是无法保证。因此，还必须从应用层角度考虑。

### 怎么保证原子性的？

利用Innodb的undo log。

undo log名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。

例如

- (1)当你delete一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert这条旧数据
- (2)当你update一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行update操作
- (3)当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行delete操

undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。

### 怎么保证持久性的？

利用Innodb的redo log。

正如之前说的，Mysql是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。

**怎么解决这个问题？**

事务提交前直接把数据写入磁盘就行啊。

**这么做有什么问题？**

只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面16kb大小，你只改其中一点点东西，就要将16kb的内容刷入磁盘，听着也不合理。

毕竟一个事务里的SQL可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机IO。显然操作随机IO，速度会比较慢。

于是，决定采用redo log解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。

### 什么是脏读？幻读？不可重复读？

脏读：读取未提交的事务。

不可重复读：多次读取同一数据，读取的数据不一致。

幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

### 事务的隔离级别

| **隔离级别**     | **脏读** | **不可重复读** | **幻读** |
| ---------------- | -------- | -------------- | -------- |
| READ-UNCOMMITTED | √        | √              | √        |
| READ-COMMITTED   | ×        | √              | √        |
| REPEATABLE-READ  | ×        | ×              | √        |
| SERIALIZABLE     | ×        | ×              | ×        |

事务隔离机制的实现基于锁机制和并发调度。

并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。

### 可重复读如何实现？

可重复读是指：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。

可重复读隔离级别下，事务在启动的时候就”拍了个快照“。

- InnoDB 里面每个事务都有一个唯一的事务 ID。它在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。

- 每条记录在更新的时候都会同时记录一条 undo log，这条 log 就会记录上当前事务的 transaction id，记为 row trx_id。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

- 在可重复读隔离级别下，一个事务在启动时，InnoDB 会为事务构造一个数组，用来保存这个事务启动瞬间，当前正在”活跃“的所有事务ID。”活跃“指的是，启动了但还没提交。

- 视图数组和高水位，就组成了当前事务的一致性视图（read-view）。这个视图数组把所有的 row trx_id 分成了几种不同的情况。

  - 如果 trx_id 小于低水位，表示这个版本在事务启动前已经提交，可见；

    如果 trx_id 大于高水位，表示这个版本在事务启动后生成，不可见；

    如果 trx_id 大于低水位，小于高水位，分为两种情况：

    1. 若 trx_id 在数组中，表示这个版本在事务启动时还未提交，不可见；
    2. 若 trx_id 不在数组中，表示这个版本在事务启动时已经提交，可见。

## 锁

当数据库有并发事务的时候，可能会产生数据的不一致，需要一些机制来保证访问的次序，锁机制就是这样的一个机制。

### 锁分类

按照锁的粒度把数据库锁分为行级锁（INNODB引擎）、表级锁（MYISAM引擎）和页级锁（BDB引擎 ）。

**行级锁** 

分为共享锁 和 排他锁。

特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

**表级锁** 

分为表共享读锁（共享锁）与表独占写锁（排他锁）。

特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。

**页级锁** 

特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

**从锁的类别上来讲，有共享锁和排他锁。**

**共享锁:** 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。

**排他锁:** 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。

### 什么时候加行锁？

- 对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁；
- 对于普通SELECT语句，InnoDB不会加任何锁；
- 当然我们也可以显示的加锁：
  共享锁：`select * from tableName where ...  lock in share more`
  排他锁：`select * from tableName where ...  for update`

### 什么时候加表锁

InnoDB默认采用行锁，没有使用索引字段查询时，会使用表锁。

第一种情况：**全表更新**。事务需要更新大部分或全部数据，且表又比较大。若使用行锁，会导致事务执行效率低，从而可能造成其他事务长时间锁等待和更多的锁冲突。

第二种情况：**多表级联**。事务涉及多个表，比较复杂的关联查询，很可能引起死锁，造成大量事务回滚。这种情况若能一次性锁定事务涉及的表，从而可以避免死锁、减少数据库因事务回滚带来的开销。

也可手动加锁：

```mysql
lock table xxx read/write;
```

### 什么时候加间隙锁？

当我们用范围条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做间隙

### InnoDB存储引擎的锁的算法

Record lock：单个行记录上的锁

Gap lock：间隙锁，锁定一个范围，不包括记录本身

Next-key lock：record+gap 锁定一个范围，包含记录本身

### 死锁

**Mysql死锁策略**  

- 直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置  
- 发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑

**避免死锁的常用方法**  

- 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会  
- 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能  

### 什么是死锁？怎么解决？

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

#### **常见的避免死锁的方法**

1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。

2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；

3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；

4、在RR隔离级别下，如果两个线程同时对相同条件记录用 `SELECT...FOR UPDATE` 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，**将隔离级别改成RC不会产生间隙锁**，就可避免问题  

5、在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯，如果出现死锁，可以用 **show innodb status** 命令来确定最后一个死锁产生的原因，返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等

如果业务处理不好可以用**分布式事务锁或者使用乐观锁**

#### 死锁的必要条件

1. 互斥条件：一个资源每次只能被一个进程使用。
2. 请求与保持条件：进程因请求资源而阻塞时，保持已获得的资源的占用。
3. 不剥夺条件：进程已占用的资源，在末使用完之前，不能强行剥夺。
4. 循环等待条件：若干进程之间存在一种头循环等待关系。

#### 如何避免互相转账的死锁问题

**1、破坏请求与保持**

单机下，可以使用同步方法，对两个账户同时加锁。处理请求前需要两个账户都没有锁的情况下才可以

**2、破坏不剥夺条件**

超时：在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。

非阻塞地获取锁：如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。

**3、破坏循环等待条件**

可以将需要获取的锁资源排序，按照顺序获取，这样就不会多个线程交叉获取相同的资源导致死锁，而是在获取相同的资源时就等待，直到它释放。

比如根据账号的主键 id 进行排序，从小到大的获取锁，这样就可以避免循环等待。

### 乐观锁和悲观锁是什么？怎么实现的？

**悲观锁：**假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制

 **乐观锁：**假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。

 **两种锁的使用场景**

 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。

 多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

### 数据库中加锁的具体实现，这个锁是如何加到具体的记录行上去的？

**行锁是加在索引上的**

Innodb中的索引数据结构是 B+ 树，数据是有序排列的，从根节点到叶子节点一层层找到对应的数据。

InnoDB 行锁是通过给索引上的索引项加锁来实现的

只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！

无论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。

### 写锁一定阻塞读吗？

**默认是 MVCC 机制（“一致性非锁定读-consistent nonlocking read”）保证 RR 级别的隔离正确性，是不上锁的**。

## 存储过程

存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。

**优点**

1）存储过程是预编译过的，执行效率高。

2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。

3）安全性高，执行存储过程需要有一定权限的用户。

4）存储过程可以重复使用，减少数据库开发人员的工作量。

**缺点**

1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。

2）移植问题，数据库端代码当然是与数据库相关的。

3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。

4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。

## 触发器

### 什么是触发器 

触发器是用户定义在关系表上的一类**由事件驱动的特殊的存储过程**。触发器是指一段代码，当触发某个事件时，自动执行这些代码。

**使用场景**

**可以通过数据库中的相关表实现级联更改。**

实时监控某张表中的某个字段的更改而需要做出相应的处理。

### MySQL中都有哪些触发器？

**在MySQL数据库中有如下六种触发器：**

Before Insert、After Insert、Before Update、After Update、Before Delete、After Delete

## 常用SQL语句

### SQL语句主要分为哪几类

数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER

数据查询语言DQL（Data Query Language）SELECT

数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE

数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK

### 主键 超键 候选键 外键

- 主键：数据库表中对**存储数据对象予以唯一和完整标识**的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值

- 外键：在一个表中存在**的另一个表的主键称此表的外键**。

- 超键：**在关系中能唯一标识元组的属性集称为超键。**一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。候选键和主键一定是超键。

- 候选键：是最小超键，即没有冗余元素的超键。

### SQL 约束有哪几种？

**NOT NULL**: 用于控制字段的内容一定不能为空。

**UNIQUE**: 控件字段内容不能重复，一个表允许有多个 Unique 约束。

**PRIMARY KEY**: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。

**FOREIGN KEY:** 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。

**CHECK**: 用于控制字段的值范围。

### 关联查询

**内连接**（INNER JOIN）

**外连接**（LEFT JOIN/RIGHT JOIN）

**联合查询**（UNION与UNION ALL）

**交叉连接**（CROSS JOIN）

**内连接分为三类**

等值连接：ON A.id=B.id

不等值连接：ON A.id > B.id

自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid

**外连接（LEFT JOIN/RIGHT JOIN）**

左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN

右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN

**联合查询（UNION与UNION ALL**）

就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并

如果使用UNION ALL，不会合并重复的记录行

效率 UNION ALL 高于 UNION

### 什么是子查询

一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。

### 子查询的三种情况

- 子查询是单行单列的情况：结果集是一个值，父查询使用：=、 <、 > 等运算符

- 子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符

- 子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表

### in 和 exists 区别

mysql中的in语句是**把外表和内表作hash 连接**，而**exists语句是对外表作loop循环，每次loop循环再对内表进行查询**。

- IN适合于外表大而子查询表小的情况。

- EXISTS适合于外表小而子查询表大的情况。

not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；

而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。

### drop,delete与truncate

drop直接删掉表，truncate、delete删除表中数据。

1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。在删除的过程中，不会激活与表有关的删除触发器，执行速度快。

2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。

3.应用范围。truncate只能对table，delete可以是table和view

**使用场景:** 

不再需要一张表的时候，用drop 

想删除部分数据行时候，用delete，并且带上where子句 

保留表而删除所有数据的时候用truncate 

|          | **Delete**                               | **Truncate**                   | **Drop**                                             |
| -------- | ---------------------------------------- | ------------------------------ | ---------------------------------------------------- |
| 类型     | 属于DML                                  | 属于DDL                        | 属于DDL                                              |
| 回滚     | 可回滚                                   | 不可回滚                       | 不可回滚                                             |
| 删除内容 | 表结构还在，删除表的全部或者一部分数据行 | 表结构还在，删除表中的所有数据 | 从数据库中删除表，所有的数据行，索引和权限也会被删除 |
| 删除速度 | 删除速度慢，需要逐行删除                 | 删除速度快                     | 删除速度最快                                         |

## SQL优化

### 如何定位及优化SQL语句的性能问题？

MySQL提供了**explain命令来查看语句的执行计划** 。执行计划，显示数据库引擎对于SQL语句的执行的详细情况，其中包含了**是否使用索引，使用什么索引，使用的索引的相关信息**等。

**select_type查询类型。**

| **select_type** | **description**                           |
| --------------- | ----------------------------------------- |
| SIMPLE          | 不包含任何子查询或union等查询             |
| PRIMARY         | 包含子查询最外层查询就显示为 PRIMARY      |
| SUBQUERY        | 在select或 where字句中包含的查询          |
| DERIVED         | from字句中包含的查询                      |
| UNION           | 出现在union后的查询语句中                 |
| UNION RESULT    | 从UNION中获取结果集，例如上文的第三个例子 |

**type访问类型**

ALL 扫描全表数据

index 遍历索引

range 索引范围查找

index_subquery 在子查询中使用 ref

unique_subquery 在子查询中使用 eq_ref

ref_or_null 对Null进行索引的优化的 ref

fulltext 使用全文索引

ref 使用非唯一索引查找数据

eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。

**key ，实际使用的索引。**

**ref 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值**

**rows ：估算的结果集数目，并不是一个准确的值。**

**extra 的信息非常丰富，常见的有：**

- **Using index 使用覆盖索引**

-  **Using where 使用了用where子句来过滤结果集**

- Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。

- Using temporary 使用了临时表

### 超大分页怎么处理？

- 数据库层面,类似于**select \* from table where age > 20 limit 1000000,10**这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为`select * from table where id in (select id from table where age > 20 limit 1000000,10)`。**这样虽然也load了一百万的数据,但是由于**索引覆盖**,要查询的所有字段都在索引中,所以速度会很快. **
- 如果ID连续，我们还可以`select * from table where id > 1000000 limit 10`效率也是不错的
- 从需求的角度减少这种请求，主要是不做类似的需求（直接跳转到几百万页之后的具体某一页，只允许逐页查看或者按照给定的路线走，这样可预测、可缓存）以及防止ID泄漏且连续被人恶意攻击。

### mysql 分页

LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。

LIMIT 接受一个或两个数字参数。返回记录行的偏移量+ 返回记录行的最大数目

>  mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15

### 慢查询日志

用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。

**开启慢查询日志**

配置项：slow_query_log

可以使用`show variables like 'slow_query_log'’'`查看是否开启，如果状态值为OFF，可以使用`set GLOBAL slow_query_log = on`来开启，它会在datadir下产生一个xxx-slow.log的文件。

**设置临界时间**

配置项：long_query_time

查看：`show VARIABLES like 'long_query_time'`，单位秒

设置：set long_query_time=0.5

实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉

查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中

### 为什么要尽量设定一个主键？

主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。

设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。

### 主键使用自增ID还是UUID？

使用自增ID。 

因为在InnoDB存储引擎中，主键索引是作为**聚簇索引**存在的。主键索引的B+树叶子节点上存储了主键索引和数据，如果是自增ID，那么只需要不断向后排列即可，如果是UUID，由于新ID与上一个的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。

### 自增ID达到上限用完了之后怎么办？

分为两种情况：

1. 如果设置了主键，那么将会报错主键冲突。
2. 如果没有设置主键，数据库则会帮我们自动生成一个全局的row_id，新数据会覆盖老数据

### 字段为什么要求定义为not null？

null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。

### varchar怎么实现

VARCHAR需要使用1或者2个额外字节记录字符串的长度：如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节。假设采用latin1字符集，一个VARCHAR(10)的列需要11个字节的存储空间。VARCHAR(1000)的列则需要1002个字节，因为需要2个字节存储长度信息。

### 如果要存储用户的密码散列，应该使用什么字段进行存储？

密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。

### SQL语句优化的一些方法

- 尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。
- 不使用SELECT \*，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 
- 能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 

**避免索引失效**

- 使用!= 或者 <> 或者或者or 来连接条件导致索引失效：需要判断索引成本
- 筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效
- 模糊搜索的前缀模糊导致的索引失效
- NOT IN、NOT EXISTS导致索引失效：需要判断回表成本
- 尽量避免在 where 子句中对字段进行 null 值判断

## 数据库优化

- 优化索引、SQL 语句、分析慢查询; 
- 使用缓存，把经常访问到的数据而且不需要经常变化的数据放在缓存中，能节约磁盘 IO; 
- 优化硬件，采用 SSD，使用磁盘队列技术 (RAID0,RAID1,RDID5)等; 
- 采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率; 
- 主从读写分离
- 垂直分表，把一些不经常读的数据放在一张表里，节约 磁盘 I/O; 
- 分库分表分机器，主要的原理就是数据路由; 
- 进行架构级别的缓存，静态化和分布式

## left join 原理

**Simple Nested-Loop Join**

双层for 循环 ，通过循环外层表的行数据，逐个与内层表的所有行数据进行比较来获取结果

**Index Nested-Loop Join**

 通过外层表匹配条件 直接与内层表索引进行匹配，避免和内层表的每条记录去进行比较， 这样极大的减少了对内层表的匹配次数，极大的提升了 join的性能。

**Block Nested-Loop Join**

通过一次性缓存外层表的多条数据，以此来减少内层表的扫表次数，从而达到提升性能的目的。如果无法使用**Index Nested-Loop Join**的时候，数据库是默认使用的是**Block Nested-Loop Join算法的**

基于后两者的时间复杂度，考虑小表驱动大表。**Simple Nested-Loop Join**没有时间上的差异。

## 集群

### 主从复制

#### 异步复制

- 在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。
- 主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，主库给客户端返回 commit 成功（不管从库是否已经收到了事务的 binlog）
- 从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。

#### 半同步复制

- 在主库开启 binlog 的情况下，如果主库有增删改的语句，会记录到 binlog 中。
- 主库通过 IO 线程把 binlog 里面的内容传给从库的中继日志（relay log）中，**从库收到 binlog 后，发送给主库一个 ACK，表示收到了，主库收到这个 ACK 以后，才能给客户端返回 commit 成功**
- 从库的 SQL 线程负责读取 relay log 并应用到从库数据库中。

### galera复制原理

Galera采用的是多主同步复制。

事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。

所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。

### 分库分表后面临的问题

 **事务支持** 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。

 **跨库join** 

只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 

 **跨节点的count,order by,group by以及聚合函数问题** 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。

 **数据迁移，容量规划，扩容等问题** 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 

 **ID问题**

一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略

**UUID 使用UUID作主键是最简单的方案**，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 **Twitter的分布式自增ID算法Snowflake** 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。

**Snowflake**

64bit整数，41bit时间戳+10bit机器id+12bit序列号

## 备份

**mysqldump工具备份**

mysqldump由于是mysql自带的备份工具，所以也是最常用的mysql数据库的备份工具。支持基于InnoDB的热备份。但由于是逻辑备份，所以速度不是很快，适合备份数据量比较小的场景。

mysqldump完全备份+二进制日志 —>实现时间点恢复

如果使用的是InnoDB引擎，就不必进行对数据库加锁的操作，加一个选项既可以进行热备份：--single-transaction

**使用percona提供的xtrabackup（推荐）**

支持InnoDB的物理热备份，支持完全备份，增量备份，而且速度非常快，而且支持InnoDB引擎的数据在不同数据库迁移

## sql语句中where与having的区别

Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。

Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。

在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。

```mysql
select 列 from
表名
join [表名]
on [条件]
where [查询条件]
group by [分组表达式]
having [分组过滤条件]
order by [排序条件]
limit [offset,] count;
```

执行顺序

>    　　　　1. FROM：对FROM子句中前两个表执行笛卡尔积生成虚拟表vt1
>    　　　　2. ON: 对vt1表应用ON筛选器只有满足 join_condition 为真的行才被插入vt2
>    　　　　　　　　　　　　　　　　3. OUTER（join）：如果指定了 OUTER JOIN保留表中未找到的行将行作为外部行添加到vt2，生成t3，如果from包含两个以上表，则对上一个联结生成的结果表和下一个表重复执行步骤和步骤直接结束。
>    　　　　　　　　　　　　　　　　　　　　　　　　　　　　4. WHERE：对vt3应用 WHERE 筛选器只有使 where_condition 为true的行才被插入vt4
>    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　5. GROUP BY：按GROUP BY子句中的列列表对vt4中的行分组生成vt5
>    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　6. HAVING：对vt6应用HAVING筛选器只有使 having_condition 为true的组才插入vt7
>    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　7. SELECT：处理select列表产生vt8
>    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　8. DISTINCT：将重复的行从vt8中去除产生vt9
>    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　9. ORDER BY：将vt9的行按order by子句中的列列表排序生成一个游标vc10

## 高并发时，如何避免重复插入 ？

- 幂等：保证多次同意请求后结果一致
- 并发控制：单表唯一索引、分布式多表分布式锁

