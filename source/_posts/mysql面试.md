---
title: mysql面试
top: false
cover: false
toc: true
mathjax: true
date: 2021-04-10 18:45:14
password:
summary:
tags:
- interview
categories:
- interview
---

## 架构

**server层**

1. 连接器：管理连接，权限验证  

2. 查询缓存  

3. 分析器：词法、语法解析

4. 优化器：生成执行计划，索引选择

5. 执行器：操作引擎，返回结果

**存储引擎层**

1. 负责数据存储和提取，插件式，支持InnoDB、MyISAM多个存储引擎

##  日志系统

### redo log（重做日志）

1. InnoDB引擎的日志，redo log 保证数据库异常重启之前提交的记录不会丢失（crash-safe）

2. 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到 redo log 日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将 redo log 中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术（先写日志再写磁盘）

3. redo log 是物理日志，记录的是在某个数据页上做了什么修改

4. redo log是循环写，空间固定会用完

### binlog（归档日志）

1. server层日志，记录了MySQL对数据库执行更改的所有操作，没有crash-safe能力

2. binlog是逻辑日志，记录的是记录所有数据库表结构变更（例如CREATE、ALTER、TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志

3. binlog采用追加写的模式

4. **用途：**  

- 恢复：binlog日志恢复数据库数据  
- 复制：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log，SQL线程从relay log里面读取内容，写入从库的数据库  
- 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击

**binlog常见格式**

| format    | 定义                       | 优点                           | 缺点                                                         |
| --------- | -------------------------- | ------------------------------ | ------------------------------------------------------------ |
| statement | 记录的是修改SQL语句        | 日志文件小，节约IO，提高性能   | 准确性差，有些语句的执行结果是依赖于上下文命令可能会导致主备不一致（delete带limit，很可能会出现主备数据不一致的情况） |
| row       | 记录的是每行实际数据的变更 | 准确性强，能准确复制数据的变更 | 日志文件大，较大的网络IO和磁盘IO                             |
| mixed     | statement和row模式的混合   | 准确性强，文件大小适中         | 有可能发生主从不一致问题                                     |

### 两段提交  

1. 两段提交保证数据库binlog状态和日志redo log恢复出来的数据库状态保持一致

2. 两段提交： 写入redo log处于prepare阶段 --写入bin log --提交事务处于commit状态 

- 时刻A崩溃恢复： redo log未提交， bin log 未写，不会传到备库，这时事务会回滚  
- 时刻B崩溃恢复：如果 redo log 事务完整有commit标识则直接提交，如果 redo log 事务只有完整的prepare，则判断对应事务 bin log 是否完整，是提交事务，否则回滚事务

3. bin log完整性判断:  

- statement格式最后有commit  
- row格式最有有一个XID event（redo log 和 bin log关联：共同字段XID）

### undo log

1. undo log是逻辑日志，可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录

2. undo log 作用  

- 提供回滚  
- 多版本并发控制（MVCC）

### Mysql抖动

当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页，把内存里的数据写入磁盘。

**flush场景**

1. InnoDB 的 redo log 写满了，系统会停止所有更新操作，把 checkpoint 对应的所有脏页都 flush 到磁盘
2. 系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是"脏页"，就要先将脏页写到磁盘
3. MySQL 认为系统"空闲"的时候，会flush脏页
4. MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上

InnoDB 的刷盘速度参考两个因素：一个是脏页比例，一个是 redo log 写盘速度

## 存储引擎

### MyISAM与InnoDB索引区别

InnoDB索引是**聚簇索引**，MyISAM索引是**非聚簇索引**。

InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效；MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。

InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效

### Innodb引擎特性

#### 写缓冲（change buffer）

Insert Buffer 用于非聚集索引的插入和更新操作。先判断插入的非聚集索引是否在缓存池中，如果在则直接插入，否则插入到 Insert Buffer 对象里。再以一定的频率进行 Insert Buffer 和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，减少随机IO带来性能损耗，提高对非聚集索引的插入性能。

#### 二次写

mysql最小的io单位是16k，文件系统io最小的单位是4k，因此存在IO写入导致page损坏的风险

如果数据库发生宕机时，可以通过重做日志对该页进行恢复，但是如果该页本身已经损坏了，进行重做恢复是没有意义的。因此引入了"二次写"方案，解决部分写失败，提高数据页的稳定性。

#### 自适应哈希索引

InnoDB 会监控对表上各个索引页的查询，如果观察到通过哈希索引可以带来性能提升，则自动建立哈希索引。自适应哈希索引通过缓存池的 B+ 树页构造而来，因此建立速度很快。

#### 预读

数据库访问通常都遵循集中读取原则，使用一些数据大概率会使用附近的数据，这就是所谓的局部性原理，它表明提前加载是有效的，能减少磁盘的i/o。

预读机制就是发起一个i/o请求，异步的在缓冲池中预先回迁若干个页面,预计将会用到的页面回迁.

## 索引

### 定义

数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。

通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。

索引是一种特殊的文件，需要占据物理空间的，它们包含着对数据表里所有记录的引用指针。

### 优缺点

**索引的优点**

- 加快数据的检索速度。

**索引的缺点**

- 创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；
- 索引需要占物理空间。

### 使用场景

**where**

**order by**

使用order by按照某个字段排序时，如果该字段没有建立索引，那么会将查询出的所有符合条件的数据**使用磁盘临时文件完成外部排序或者在内存中完成排序**。具体取决于排序所需的内存和参数sort_buffer_size。

如果我们对该字段建立索引，由于索引本身是有序的，因此直接**按照索引的顺序和映射关系逐条取出数据即可**。

**join**

对join语句匹配关系（on）涉及的字段建立索引能够提高效率（一般小表驱动大表，避免了大表的全表扫描）

**覆盖索引**

辅助索引可以直接提供查询结果，不需要回表。称为覆盖索引。

如果要查询的字段都在某一索引中，那么可以直接在索引表中查询而不会访问原始数据。

> 尽可能的在select后只写必要的查询字段，以增加覆盖索引的几率。

### 索引类型

**主键索引**： 不允许重复，不允许为NULL，一个表只能有一个主键。

**唯一索引**：不允许重复，允许为NULL，一个表允许多唯一索引。

**普通索引**：基本的索引类型，没有唯一性的限制，允许为NULL值。

**全文索引**： 是目前搜索引擎使用的一种关键技术。

### 索引的数据结构

和具体存储引擎的实现有关，在MySQL中使用较多的索引有Hash索引，B+树索引等。

InnoDB存储引擎的默认索引实现为：B+树索引。

哈希索引底层的数据结构是哈希表，适合场景为绝大多数查询为单条记录查询。

### 索引设计的原则

**适合索引的列**是出现在where子句中的列，或者连接子句中指定的列

**使用短索引**，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间

**不要过度索引**。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构。

### 创建索引的原则

1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立`(a,b,c,d)`顺序的索引，d是用不到索引的，如果建立`(a,b,d,c)`的索引则都可以用到，a,b,d的顺序可以任意调整。

2）较频繁作为查询条件的字段才去创建索引

3）更新频繁字段不适合创建索引

4）若是不能有效区分数据的列不适合做索引列（如性别，男女未知，最多也就三种，区分度实在太低），选择基数较大的列做索引

5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。联合索引比单个索引的性价比更高。

6）定义有外键的数据列一定要建立索引。

### 创建索引注意点

**非空字段：**应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

**取值离散大的字段：**（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值

**索引字段越小越好**：数据库的数据存储以页为单位，一页存储的数据越多一次IO操作获取的数据越大，效率越高。

### 使用索引查询一定能提高查询的性能吗

**通常，通过索引查询数据比全表扫描要快。**但是我们也必须注意到它的代价。

**索引需要空间来存储，也需要定期维护，** 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询（INDEX RANGE SCAN）适用于两种情况:

- 基于一个范围的检索，一般查询返回结果集小于表中记录数的30%
- **基于非唯一性索引的检索（？？？）**

### 百万级别或以上的数据如何删除

> 索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，删除数据的速度和创建的索引数量是成正比的。

所以删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）

然后删除其中无用数据（此过程需要不到两分钟）

删除完成后重新创建索引（此时数据较少了，创建索引也非常快，约十分钟左右。）

### 前缀索引

语法：``index(field(10))``，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。

前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。

实操的难度：**在于前缀截取的长度。**

我们可以利用`select count(*)/count(distinct left(password,prefixLen));`，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）

### B-/+Tree索引的性能分析

 B-Tree：根据B-Tree的定义，可知检索一次最多需要访问h个节点，利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，保证一个节点存储在一个页里。

B+Tree：B+Tree更适合外存索引，由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能

### B-Tree和B+Tree的区别

在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。

B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。

### 使用B树的好处

B树可以在**内部节点同时存储键和值**，因此，**把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。**这种特性使得B树在特定数据重复多次查询的场景中更加高效。

### 使用B+树的好处

由于**B+树的内部节点只存放键**，不存放值，因此，**一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围**。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，**B+树只需要使用`O(logN)`时间找到最小的一个节点，然后通过链进行`O(N)`的顺序遍历即可。**而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间

### Hash索引和B+树优劣

首先要知道Hash索引和B+树索引的底层实现原理：

**hash索引底层就是hash表**，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是**多路平衡查找树**。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。

那么可以看出他们有以下的不同：

- hash索引进行**等值查询更快（一般情况下），但是却无法进行范围查询**。

因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。

- hash索引**不支持使用索引进行排序**，原理同上。

- hash索引不**支持模糊查询以及多列索引的最左前缀匹配。**原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。

- hash索引任何时候都**避免不了回表查询数据**，而B+树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询。
- hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。

因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。

### 使用B+树而不是B树

- **B树只适合随机检索，而B+树同时支持随机检索和顺序检索**；

-  **B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。**B+树的内部结点并没有指向关键字具体信息的指针，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，，IO读写次数也就降低了。

- **B+树的查询效率更加稳定。**B树搜索越靠近根节点的记录查找时间越短。B+树中，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，查找路径长度相同，导致每一个关键字的查询效率相当。

- **B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。**B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。

- **增删文件（节点）时，效率更高。**因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。

### 聚簇索引

**聚簇索引**：将数据存储与索引放到了一块，找到索引也就找到了数据

**非聚簇索引**：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，因此索引不在key buffer命中时，速度慢。

**澄清一个概念：**innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。

### 非聚簇索引一定会回表查询吗？

不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。

### **联合索引**

MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。

### **为什么需要注意联合索引中的顺序？**

MySQL使用索引时需要索引有序.

一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。

## 数据库范式

**第一范式：**强调的是列的原子性，即列不能够再分成其他几列。

 **第二范式**：首先是 1NF，另外包含两部分内容，**一是表必须有一个主键**；二是没有包含在主键中的**列必须完全依赖于主键，而不能只依赖于主键的一部分**。否则可拆表。

 **第三范式**：在1NF基础上，**任何非主属性不依赖于其它非主属性**[在2NF基础上消除传递依赖]。

## mysql有关权限的表

MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别**user，db，table_priv，columns_priv和host**。下面分别介绍一下这些表的结构和内容：

user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。

db权限表：记录各个帐号在各个数据库上的操作权限。

table_priv权限表：记录数据表级的操作权限。

columns_priv权限表：记录数据列级的操作权限。

host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。

## 视图

视图是虚拟的表，视图只包含使用时动态检索数据的查询;不包含任何列或数据。

使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;

视图创建后，可以使用与表相同的方式利用它们。

> 视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。

### 视图有哪些特点？

- 视图是由基本表（实表）产生的表（虚表）。
- 视图的建立和删除不影响基本表。
- 对视图内容的更新（添加，删除和修改）直接影响基本表。
- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。
- 当视图来自多个基本表时，不允许添加和删除数据。

### 视图的使用场景有哪些？

视图根本用途：简化sql查询，提高开发效率。

**常见使用场景：**

重用SQL语句；

**简化复杂的SQL操作**。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；

**保护数据**。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；

**更改数据格式和表示**。视图可返回与底层表的表示和格式不同的数据。

### 视图的优点

**查询简单化**。视图能简化用户的操作

**数据安全性**。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护

### 视图的缺点

**性能**。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由复杂的多表查询所定义，那么，视图的查询，需要花费一定的时间。

**修改限制**。修改、插入、删除视图的某些行时，数据库把它转化为对基本表某些行的修改。对于比较复杂的视图，可能是不可修改的。

### 游标

游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果。用户可以通过游标，逐一获取记录，进一步处理。

## 事务

### 什么是数据库事务？

一个不可分割的数据库操作序列，是数据库并发控制的基本单位。

事务是逻辑上的一组操作，要么都执行，要么都不执行。

> 假如小明要给小红转账1000元：将小明的余额减少1000元，将小红的余额增加1000元。万一操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么成功，要么都失败。

### 事务的特性

- atomicity（原子性） ：要么全执行，要么全都不执行；
- consistency（一致性）：在事务开始和完成时，数据都必须保持一致状态；
- isolation（隔离性） ：事务处理过程中的中间状态对外部是不可见的；
- durability（持久性） ：事务完成之后，它对于数据的修改是永久性的。

### 什么是脏读？幻读？不可重复读？

脏读：读取未提交的事务。

不可重复读：多次读取同一数据，读取的数据不一致。

幻读：幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

### 事务的隔离级别

| **隔离级别**     | **脏读** | **不可重复读** | **幻读** |
| ---------------- | -------- | -------------- | -------- |
| READ-UNCOMMITTED | √        | √              | √        |
| READ-COMMITTED   | ×        | √              | √        |
| REPEATABLE-READ  | ×        | ×              | √        |
| SERIALIZABLE     | ×        | ×              | ×        |

事务隔离机制的实现基于锁机制和并发调度。

并发调度使用的是MVCC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。

## 锁

当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。

### 锁分类

按照锁的粒度把数据库锁分为行级锁（INNODB引擎）、表级锁（MYISAM引擎）和页级锁（BDB引擎 ）。

**行级锁** 

分为共享锁 和 排他锁。

特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

**表级锁** 

分为表共享读锁（共享锁）与表独占写锁（排他锁）。

特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。

**页级锁** 

特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

**从锁的类别上来讲，有共享锁和排他锁。**

**共享锁:** 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。

**排他锁:** 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。

### InnoDB存储引擎的锁的算法

Record lock：单个行记录上的锁

Gap lock：间隙锁，锁定一个范围，不包括记录本身

Next-key lock：record+gap 锁定一个范围，包含记录本身

### 死锁

**Mysql死锁策略**  

- 直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置  
- 发起死锁检测，发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑

**避免死锁的常用方法**  

- 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会  
- 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能  

### 什么是死锁？怎么解决？

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

**常见的避免死锁的方法**

1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。

2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；

3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定粒度，通过表级锁定来减少死锁产生的概率；

4、在RR隔离级别下，如果两个线程同时对相同条件记录用 `SELECT...FOR UPDATE` 加排他锁，在没有符合该条件记录情况下，两个线程都会加间隙锁成功，程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁，这种情况下，**将隔离级别改成RC不会产生间隙锁**，就可避免问题  

5、在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯，如果出现死锁，可以用 **show innodb status** 命令来确定最后一个死锁产生的原因，返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等

如果业务处理不好可以用**分布式事务锁或者使用乐观锁**

### 乐观锁和悲观锁是什么？怎么实现的？

**悲观锁：**假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制

 **乐观锁：**假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。

 **两种锁的使用场景**

 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。

 多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

## 存储过程

存储过程是一个预编译的SQL语句，只需要创建一次，就可以调用多次。

**优点**

1）存储过程是预编译过的，执行效率高。

2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。

3）安全性高，执行存储过程需要有一定权限的用户。

4）存储过程可以重复使用，减少数据库开发人员的工作量。

**缺点**

1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。

2）移植问题，数据库端代码当然是与数据库相关的。

3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。

4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。

## 触发器

### 什么是触发器 

触发器是用户定义在关系表上的一类**由事件驱动的特殊的存储过程**。触发器是指一段代码，当触发某个事件时，自动执行这些代码。

**使用场景**

**可以通过数据库中的相关表实现级联更改。**

实时监控某张表中的某个字段的更改而需要做出相应的处理。

### MySQL中都有哪些触发器？

**在MySQL数据库中有如下六种触发器：**

Before Insert、After Insert、Before Update、After Update、Before Delete、After Delete

## 常用SQL语句

### SQL语句主要分为哪几类

数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER

数据查询语言DQL（Data Query Language）SELECT

数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE

数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK

### 主键 超键 候选键 外键

- 主键：数据库表中对**存储数据对象予以唯一和完整标识**的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值

- 外键：在一个表中存在**的另一个表的主键称此表的外键**。

- 超键：**在关系中能唯一标识元组的属性集称为超键。**一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。候选键和主键一定是超键。

- 候选键：是最小超键，即没有冗余元素的超键。

### SQL 约束有哪几种？

**NOT NULL**: 用于控制字段的内容一定不能为空。

**UNIQUE**: 控件字段内容不能重复，一个表允许有多个 Unique 约束。

**PRIMARY KEY**: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。

**FOREIGN KEY:** 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。

**CHECK**: 用于控制字段的值范围。

### 关联查询

**内连接**（INNER JOIN）

**外连接**（LEFT JOIN/RIGHT JOIN）

**联合查询**（UNION与UNION ALL）

**交叉连接**（CROSS JOIN）

**内连接分为三类**

等值连接：ON A.id=B.id

不等值连接：ON A.id > B.id

自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid

**外连接（LEFT JOIN/RIGHT JOIN）**

左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN

右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN

**联合查询（UNION与UNION ALL**）

就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并

如果使用UNION ALL，不会合并重复的记录行

效率 UNION ALL 高于 UNION

### 什么是子查询

一条SQL语句的查询结果做为另一条查询语句的条件。多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。

### 子查询的三种情况

- 子查询是单行单列的情况：结果集是一个值，父查询使用：=、 <、 > 等运算符

- 子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符

- 子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表

### in 和 exists 区别

mysql中的in语句是**把外表和内表作hash 连接**，而**exists语句是对外表作loop循环，每次loop循环再对内表进行查询**。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。

- IN适合于外表大而子查询表小的情况。

- EXISTS适合于外表小而子查询表大的情况。

not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；

而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。

### drop,delete与truncate

drop直接删掉表，truncate、delete删除表中数据。

1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。

2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。

3.应用范围。truncate只能对table，delete可以是table和view

**使用场景:** 

不再需要一张表的时候，用drop 

想删除部分数据行时候，用delete，并且带上where子句 

保留表而删除所有数据的时候用truncate 

|          | **Delete**                               | **Truncate**                   | **Drop**                                             |
| -------- | ---------------------------------------- | ------------------------------ | ---------------------------------------------------- |
| 类型     | 属于DML                                  | 属于DDL                        | 属于DDL                                              |
| 回滚     | 可回滚                                   | 不可回滚                       | 不可回滚                                             |
| 删除内容 | 表结构还在，删除表的全部或者一部分数据行 | 表结构还在，删除表中的所有数据 | 从数据库中删除表，所有的数据行，索引和权限也会被删除 |
| 删除速度 | 删除速度慢，需要逐行删除                 | 删除速度快                     | 删除速度最快                                         |

## SQL优化

### 如何定位及优化SQL语句的性能问题？

MySQL提供了**explain命令来查看语句的执行计划** 。执行计划，显示数据库引擎对于SQL语句的执行的详细情况，其中包含了**是否使用索引，使用什么索引，使用的索引的相关信息**等。

**select_type** 每个子查询的查询类型，一些常见的查询类型。

| **select_type** | **description**                           |
| --------------- | ----------------------------------------- |
| SIMPLE          | 不包含任何子查询或union等查询             |
| PRIMARY         | 包含子查询最外层查询就显示为 PRIMARY      |
| SUBQUERY        | 在select或 where字句中包含的查询          |
| DERIVED         | from字句中包含的查询                      |
| UNION           | 出现在union后的查询语句中                 |
| UNION RESULT    | 从UNION中获取结果集，例如上文的第三个例子 |

**type**(非常重要，可以看到有没有走索引) 访问类型

ALL 扫描全表数据

index 遍历索引

range 索引范围查找

index_subquery 在子查询中使用 ref

unique_subquery 在子查询中使用 eq_ref

ref_or_null 对Null进行索引的优化的 ref

fulltext 使用全文索引

ref 使用非唯一索引查找数据

eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。

**key** 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。

**ref** 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值

**rows** 返回估算的结果集数目，并不是一个准确的值。

**extra** 的信息非常丰富，常见的有：

- Using index 使用覆盖索引

-  Using where 使用了用where子句来过滤结果集

- Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。

- Using temporary 使用了临时表

### 大表数据查询，怎么优化

- 优化shema、sql语句+索引；
- 加缓存，memcached, redis；
- 主从复制，读写分离；
- 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；
- 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；

### 超大分页怎么处理？

- 数据库层面,类似于**select \* from table where age > 20 limit 1000000,10**这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为`select * from table where id in (select id from table where age > 20 limit 1000000,10)`.**这样虽然也load了一百万的数据,但是由于**索引覆盖**,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以**`select * from table where id > 1000000 limit 10`效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.

- 从需求的角度减少这种请求，主要是不做类似的需求（直接跳转到几百万页之后的具体某一页，只允许逐页查看或者按照给定的路线走，这样可预测、可缓存）以及防止ID泄漏且连续被人恶意攻击。

### mysql 分页

LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0

>  mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15

### 慢查询日志

用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。

**开启慢查询日志**

配置项：slow_query_log

可以使用`show variables like 'slow_query_log'’'`查看是否开启，如果状态值为OFF，可以使用`set GLOBAL slow_query_log = on`来开启，它会在datadir下产生一个xxx-slow.log的文件。

**设置临界时间**

配置项：long_query_time

查看：`show VARIABLES like 'long_query_time'`，单位秒

设置：set long_query_time=0.5

实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉

查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中

### 为什么要尽量设定一个主键？

主键是数据库确保**数据行在整张表唯一性**的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。

### 主键使用自增ID还是UUID？

自增ID，不要使用UUID。 

因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，**会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。**

### 字段为什么要求定义为not null？

null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。

### 如果要存储用户的密码散列，应该使用什么字段进行存储？

密码散列，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。

### SQL语句优化的一些方法

- 尽量避免全表扫描，首先应考虑在 where 、JOIN ON、 order by 涉及的列上建立索引。
- 不使用SELECT \*，只查询必须的字段，避免加载无用数据，无法使用覆盖索引。 
- 能用UNION ALL的时候就不用UNION，UNION过滤重复数据要耗费更多的cpu资源。 

**避免索引失效**

- 使用!= 或者 <> 或者或者or 来连接条件导致索引失效：需要判断索引成本
- 筛选字段上的函数、运算符，或者条件判断时前后类型不一致，导致的索引失效
- 模糊搜索的前缀模糊导致的索引失效
- NOT IN、NOT EXISTS导致索引失效：需要判断回表成本
- 尽量避免在 where 子句中对字段进行 null 值判断

## 数据库优化

- 优化索引、SQL 语句、分析慢查询; 
- 设计表的时候严格根据数据库的设计范式来设计数据库; 
- 使用缓存，把经常访问到的数据而且不需要经常变化的 数据放在缓存中，能节约磁盘 IO; 
- 优化硬件;采用 SSD，使用磁盘队列技术 (RAID0,RAID1,RDID5)等; 
- 采用 MySQL 内部自带的表分区技术，把数据分成不同的文件，能够提高磁盘的读取效率; 
- 垂直分表;把一些不经常读的数据放在一张表里，节约 磁盘 I/O; 
- 主从分离读写;采用主从复制把数据库的读操作和写入操作分离开来;
- 分库分表分机器，主要的原理就是数据路由; 
- 选择合适的表引擎，参数上的优化; 
- 进行架构级别的缓存，静态化和分布式; 

## galera复制原理

Galera采用的是多主同步复制。

事务在本节点乐观执行，然后在提交时运行一个验证过程以保证全局数据一致性。

所谓乐观执行是指，事务在一个节点提交时，被认为与其它节点上的事务没有冲突，首先在本地执行，然后再发送到所有节点做冲突检测，无冲突时在所有节点提交，否则在所有节点回滚。

## 分库分表后面临的问题

 **事务支持** 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。

 **跨库join** 

只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 

 **跨节点的count,order by,group by以及聚合函数问题** 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。

 **数据迁移，容量规划，扩容等问题** 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 

 **ID问题**

一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略

**UUID 使用UUID作主键是最简单的方案**，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 **Twitter的分布式自增ID算法Snowflake** 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。

## sql语句中where与having的区别

Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。

Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。

在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行。而where子句在查询过程中执行优先级高于聚合语句。

```mysql
select 列 from
表名
where [查询条件]
group by [分组表达式]
having [分组过滤条件]
order by [排序条件]
limit [offset,] count;
```

